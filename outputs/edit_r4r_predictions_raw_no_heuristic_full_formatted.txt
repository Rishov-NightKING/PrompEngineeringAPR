import java . util . ArrayList ; /* * * This class provides helper functions for Wifi connectivity related modules to * access WifiNative . It starts with firmware roaming . TODO ( b / 34819513 ) : Move operations * such as connection to network and legacy framework roaming here . */ public class WifiConnectivityHelper { private static final String TAG = "WifiConnectivityHelper" ; private final WifiNative mWifiNative ; private boolean mFirmwareRoamingSupported = false ; < |startfocus| > private static final int INVALID_VALUE = - 1 ; private int mMaxNumBlacklistBssid = INVALID_VALUE ; private int mMaxNumWhitelistSsid = INVALID_VALUE ; < |endfocus| > WifiConnectivityHelper ( WifiNative wifiNative ) { mWifiNative = wifiNative ; } /* * * Query firmware if it supports * { @link android . net . wifi . WifiManager#WIFI_FEATURE_CONTROL_ROAMING } . If yes , get the firmware * roaming capabilities . */ public void getFirmwareRoamingInfo ( ) { int fwFeatureSet = mWifiNative . getSupportedFeatureSet ( ) ; Log . d ( TAG , "Firmware supported feature set : " + Integer . toHexString ( fwFeatureSet ) ) ; mFirmwareRoamingSupported = ( fwFeatureSet & WIFI_FEATURE_CONTROL_ROAMING ) > 0 ;
mMaxNumWhitelistSsid = - 1 ; if ( mFirmwareRoamingSupported ) { WifiNative . RoamingCapabilities roamingCap = new WifiNative . RoamingCapabilities ( ) ; if ( mWifiNative . getRoamingCapabilities ( roamingCap ) ) { mMaxNumBlacklistBssid = roamingCap . maxBlacklistSize ; mMaxNumWhitelistSsid = roamingCap . maxWhitelistSize ; Log . d ( TAG , "Firmware roaming capabilities : max num blacklist bssid = " + mMaxNumBlacklistBssid + " max num whitelist ssid = " + mMaxNumWhitelistSsid ) ; } else { Log . e ( TAG , "Failed to get firmware roaming capabilities" ) ; < |startfocus| > } < |endfocus| > } else { Log . d ( TAG , "Firmware roaming is not supported" ) ; }
mMaxNumWhitelistSsid = roamingCap . maxWhitelistSize ; Log . d ( TAG , "Firmware roaming capabilities : max num blacklist bssid = " + mMaxNumBlacklistBssid + " max num whitelist ssid = " + mMaxNumWhitelistSsid ) ; } else { Log . e ( TAG , "Failed to get firmware roaming capabilities" ) ; } } } /* * * Return if firmware roaming is supported . */ public boolean isFirmwareRoamingSupported ( ) { return mFirmwareRoamingSupported ; } /* * < |startfocus| > * Return the maximum size of BSSID blacklist . < |endfocus| > */ public int getMaxNumBlacklistBssid ( ) { if ( mFirmwareRoamingSupported ) { return mMaxNumBlacklistBssid ; } else { Log . e ( TAG , "Firmware roaming is not supported" ) ; return - 1 ; } } /* * * Return the maximum size of SSID whitelist . */ public int getMaxNumWhitelistSsid ( ) { if ( mFirmwareRoamingSupported ) { return mMaxNumWhitelistSsid ; } else { Log . e ( TAG , "Firmware roaming is not supported" ) ; return - 1 ; } } /* * * Return the maximum size of blacklist BSSID . */ public int getMaxNumBlacklistBssid ( ) { if ( mFirmwareRoamingSupported ) { return mMaxNumBlacklistBssid ; } else { Log . e ( TAG , "Firmware roaming is not supported" ) ; return - 1 ; } } /* *
public int getMaxNumBlacklistBssid ( ) { if ( mFirmwareRoamingSupported ) { return mMaxNumBlacklistBssid ; } < |startfocus| > Log . e ( TAG , "Firmware roaming is not supported" ) ; return - 1 ; < |endfocus| > }
public int getMaxNumBlacklistBssid ( ) { if ( mFirmwareRoamingSupported ) { return mMaxNumBlacklistBssid ; } else { < |startfocus| > Log . e ( TAG , "MaxNumBlacklistBssid invalid : Firmware roaming is not supported" ) ; return - 1 ; < |endfocus| > }
public int getMaxNumWhitelistSsid ( ) { if ( mFirmwareRoamingSupported ) { return mMaxNumWhitelistSsid ; } < |startfocus| > Log . e ( TAG , "Firmware roaming is not supported" ) ; return - 1 ; < |endfocus| > }
/* * Sets up test . */ @Before public void setUp ( ) throws Exception { MockitoAnnotations . initMocks ( this ) ; setupWifiNative ( ) ; mWifiConnectivityHelper = new WifiConnectivityHelper ( mWifiNative ) ; } /* * Cleans up test . */ @After public void cleanup ( ) { validateMockitoUsage ( ) ; } private WifiConnectivityHelper mWifiConnectivityHelper ; @Mock private WifiNative mWifiNative ; @Captor ArgumentCaptor < WifiNative . RoamingConfig > mRoamingConfigCaptor ; private int mFeatureSetValue ; < |startfocus| > private static final String TAG = "WifiConnectivityHelper Unit Test" ; < |endfocus| > private static final int MAX_BSSID_BLACKLIST_SIZE = 16 ; private static final int MAX_SSID_WHITELIST_SIZE = 8 ; private void setupWifiNative ( ) { // Return firmware roaming feature as supported by default . when ( mWifiNative . getSupportedFeatureSet ( ) ) . thenReturn ( WIFI_FEATURE_CONTROL_ROAMING ) ; doAnswer ( new AnswerWithArguments ( ) { public boolean answer ( WifiNative . RoamingCapabilities roamCap ) throws Exception { roamCap . maxBlacklistSize = MAX_BSSID_BLACKLIST_SIZE ; roamCap . maxWhitelistSize = MAX_SSID_WHITELIST_SIZE ; return true ; } } ) . when ( mWifiNative ) . getRoamingCapabilities ( any ( ) ) ; }
public void verifyFirmwareRoamingCapabilityWithFailureNativeCall ( ) { doAnswer ( new AnswerWithArguments ( ) { public boolean answer ( WifiNative . RoamingCapabilities roamCap ) throws Exception { return false ; } } ) . when ( mWifiNative ) . getRoamingCapabilities ( anyObject ( ) ) ; < |startfocus| > mWifiConnectivityHelper . getFirmwareRoamingInfo ( ) ; assertEquals ( - 1 , mWifiConnectivityHelper . getMaxNumBlacklistBssid ( ) ) ; assertEquals ( - 1 , mWifiConnectivityHelper . getMaxNumWhitelistSsid ( ) ) ; < |endfocus| >
public void verifySetFirmwareRoamingConfigurationWithGoodInput ( ) { < |startfocus| > mWifiConnectivityHelper . getFirmwareRoamingInfo ( ) ; < |endfocus| > ArrayList < String > blacklist = buildBssidBlacklist ( MAX_BSSID_BLACKLIST_SIZE ) ; ArrayList < String > whitelist = buildSsidWhitelist ( MAX_SSID_WHITELIST_SIZE ) ; assertTrue ( mWifiConnectivityHelper . setFirmwareRoamingConfiguration ( blacklist , whitelist ) ) ;
* [ or other varieties of that API ] . * * * @hide */ public String createNetworkSpecifierPassphrase ( @Nullable PeerHandle peerHandle , @NonNull String passphrase ) { if ( passphrase == null || passphrase . length ( ) == 0 ) { throw new IllegalArgumentException ( "Passphrase must not be null or empty" ) ; } if ( mTerminated ) { Log . w ( TAG , "createNetworkSpecifierPassphrase : called on terminated session" ) ; return null ; < |startfocus| > } WifiAwareManager mgr = mMgr . get ( ) ; if ( mgr == null ) { Log . w ( TAG , "createNetworkSpecifierPassphrase : called post GC on WifiAwareManager" ) ; return null ; } < |endfocus| > int role = this instanceof SubscribeDiscoverySession ? WifiAwareManager . WIFI_AWARE_DATA_PATH_ROLE_INITIATOR : WifiAwareManager . WIFI_AWARE_DATA_PATH_ROLE_RESPONDER ; return mgr . createNetworkSpecifier ( mClientId , role , mSessionId , peerHandle , null , passphrase ) ; } /* * * Create a { @link android . net . NetworkRequest . Builder#setNetworkSpecifier ( String ) } for an
< |startfocus| > * Copyright ( C ) 2016 The Android Open Source Project < |endfocus| > * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ import java . lang . reflect . Method ; public class Main { // Workaround for b / 18051191 . class InnerClass { } public static void main ( String [ ] args ) throws Exception { Class < ? > c = Class . forName ( "IrreducibleLoop" ) ; Method m = c . getMethod ( "simpleLoop" , int . class ) ; Object [ ] arguments = { 42 } ; System . out . println ( m . invoke ( null , arguments ) ) ; } }
boolean waitForCallback ( int callback ) { synchronized ( mLocalLock ) { < |startfocus| > Iterator < Integer > it = mCallbackQueue . iterator ( ) ; while ( it . hasNext ( ) ) { if ( it . next ( ) == callback ) { it . remove ( ) ; return true ; } } < |endfocus| > mCurrentWaitForCallback = callback ; mBlocker = new CountDownLatch ( 1 ) ; } try { return mBlocker . await ( WAIT_FOR_AWARE_CHANGE_SECS , TimeUnit . SECONDS ) ; } catch ( InterruptedException e ) { return false ; }
boolean hasCallbackAlreadyHappened ( int callback ) { synchronized ( mLocalLock ) { < |startfocus| > return mCallbackQueue . contains ( callback ) ; < |endfocus| > } return false ;
public void testSubscribeDiscoverySuccess ( ) { if ( ! TestUtils . shouldTestWifiAware ( getContext ( ) ) ) { return ; } final String serviceName = "ValidName" ; WifiAwareSession session = attachAndGetSession ( ) ; SubscribeConfig subscribeConfig = new SubscribeConfig . Builder ( ) . setServiceName ( serviceName ) . build ( ) ; DiscoverySessionCallbackTest discoveryCb = new DiscoverySessionCallbackTest ( ) ; < |startfocus| > // 1 . subscribe < |endfocus| > session . subscribe ( subscribeConfig , discoveryCb , null ) ; assertTrue ( "Subscribe started" , discoveryCb . waitForCallback ( DiscoverySessionCallbackTest . ON_SUBSCRIBE_STARTED ) ) ; SubscribeDiscoverySession discoverySession = discoveryCb . getSubscribeDiscoverySession ( ) ; assertNotNull ( "Subscribe session" , discoverySession ) ; // 2 . update - subscribe subscribeConfig = new SubscribeConfig . Builder ( ) . setServiceName ( serviceName ) . setServiceSpecificInfo ( "extras" . getBytes ( ) ) . build ( ) ; discoverySession . updateSubscribe ( subscribeConfig ) ; assertTrue ( "Subscribe update" , discoveryCb . waitForCallback ( DiscoverySessionCallbackTest . ON_SESSION_CONFIG_UPDATED ) ) ; // 3 . destroy assertFalse ( "Subscribe not terminated" , discoveryCb . hasCallbackAlreadyHappened ( DiscoverySessionCallbackTest . ON_SESSION_TERMINATED ) ) ; discoverySession . destroy ( ) ;
assertTrue ( "Incorrect longitude : " + longitude , Math . abs ( longitude - LONGITUDE ) <= TOLERANCE ) ; retriever . release ( ) ; return true ; } private void checkOutputExist ( ) { assertTrue ( mOutFile . exists ( ) ) ; assertTrue ( mOutFile . length ( ) > 0 ) ; assertTrue ( mOutFile . delete ( ) ) ; } public void testRecorderVideo ( ) throws Exception { if ( ! hasCamera ( ) ) { return ; } mCamera = Camera . open ( 0 ) ; setSupportedResolution ( mCamera ) ; < |startfocus| > mCamera . release ( ) ; mCamera = null ; < |endfocus| > mMediaRecorder . setVideoSource ( MediaRecorder . VideoSource . CAMERA ) ; mMediaRecorder . setOutputFormat ( MediaRecorder . OutputFormat . DEFAULT ) ; mMediaRecorder . setOutputFile ( OUTPUT_PATH2 ) ; mMediaRecorder . setVideoEncoder ( MediaRecorder . VideoEncoder . DEFAULT ) ; mMediaRecorder . setPreviewDisplay ( mActivity . getSurfaceHolder ( ) . getSurface ( ) ) ; mMediaRecorder . setVideoSize ( mVideoWidth , mVideoHeight ) ; FileOutputStream fos = new FileOutputStream ( OUTPUT_PATH2 ) ; FileDescriptor fd = fos . getFD ( ) ; mMediaRecorder . setOutputFile ( fd ) ; long maxFileSize = MAX_FILE_SIZE * 10 ; recordMedia ( maxFileSize , mOutFile2 ) ;
assertNotNull ( durationStr ) ; return Integer . parseInt ( durationStr ) ; } public void testSetMaxFileSize ( ) throws Exception { testSetMaxFileSize ( 512 * 1024 , 50 * 1024 ) ; } private void testSetMaxFileSize ( long fileSize , long tolerance ) throws Exception { if ( ! hasMicrophone ( ) || ! hasCamera ( ) || ! hasAmrNb ( ) || ! hasH264 ( ) ) { MediaUtils . skipTest ( "no microphone , camera , or codecs" ) ; return ; } mCamera = Camera . open ( 0 ) ; setSupportedResolution ( mCamera ) ; < |startfocus| > mCamera . release ( ) ; mCamera = null ; < |endfocus| > mMediaRecorder . setAudioSource ( MediaRecorder . AudioSource . MIC ) ; mMediaRecorder . setVideoSource ( MediaRecorder . VideoSource . CAMERA ) ; mMediaRecorder . setOutputFormat ( MediaRecorder . OutputFormat . THREE_GPP ) ; mMediaRecorder . setAudioEncoder ( MediaRecorder . AudioEncoder . AMR_NB ) ; mMediaRecorder . setVideoEncoder ( MediaRecorder . VideoEncoder . H264 ) ; mMediaRecorder . setVideoSize ( mVideoWidth , mVideoHeight ) ; mMediaRecorder . setVideoEncodingBitRate ( 256000 ) ; mMediaRecorder . setPreviewDisplay ( mActivity . getSurfaceHolder ( ) . getSurface ( ) ) ; mMediaRecorder . setMaxFileSize ( fileSize ) ; mMediaRecorder . prepare ( ) ; mMediaRecorder . start ( ) ; mMediaRecorder . stop ( ) ; mMediaRecorder . reset ( ) ; mMediaRecorder . release ( ) ; mMediaRecorder = null ;
// Refuse to send SMS if we can't get the calling package name . Rlog . e ( TAG , "Can't get calling app package name : refusing to send SMS" ) ; tracker . onFailed ( mContext , RESULT_ERROR_GENERIC_FAILURE , 0 /* errorCode */ ) ; return ; } // Get package info via packagemanager PackageInfo appInfo ; try { // XXX this is lossy - apps can share a UID appInfo = pm . getPackageInfoAsUser ( packageNames [ 0 ] , PackageManager . GET_SIGNATURES , < |startfocus| > mContext . getUserId ( ) ) ; < |endfocus| > } catch ( PackageManager . NameNotFoundException e ) { Rlog . e ( TAG , "Can't get calling app package info : refusing to send SMS" ) ; tracker . onFailed ( mContext , RESULT_ERROR_GENERIC_FAILURE , 0 /* errorCode */ ) ; return ; } // checkDestination ( ) returns true if the destination is not a premium short code or the // sending app is approved to send to short codes . Otherwise , a message is sent to our // handler with the SmsTracker to request user confirmation before sending . if ( checkDestination ( tracker ) ) {
mMediaRecorder . setVideoEncoder ( MediaRecorder . VideoEncoder . DEFAULT ) ; mMediaRecorder . setPreviewDisplay ( mActivity . getSurfaceHolder ( ) . getSurface ( ) ) ; mMediaRecorder . setVideoSize ( mVideoWidth , mVideoHeight ) ; FileOutputStream fos = new FileOutputStream ( OUTPUT_PATH2 ) ; FileDescriptor fd = fos . getFD ( ) ; mMediaRecorder . setOutputFile ( fd ) ; long maxFileSize = MAX_FILE_SIZE * 10 ; recordMedia ( maxFileSize , mOutFile2 ) ; assertFalse ( checkLocationInFile ( OUTPUT_PATH2 ) ) ; fos . close ( ) ; < |startfocus| > mCamera . release ( ) ; < |endfocus| > } public void testRecordingAudioInRawFormats ( ) throws Exception { int testsRun = 0 ; if ( hasAmrNb ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AMR_NB , MediaRecorder . AudioEncoder . AMR_NB ) ; } if ( hasAmrWb ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AMR_WB , MediaRecorder . AudioEncoder . AMR_WB ) ; } if ( hasAac ( ) ) { testsRun += testRecordAudioInRawFormat ( MediaRecorder . OutputFormat . AAC_ADTS , MediaRecorder . AudioEncoder . AAC ) ; }
mMediaRecorder . setPreviewDisplay ( mActivity . getSurfaceHolder ( ) . getSurface ( ) ) ; mMediaRecorder . setMaxFileSize ( fileSize ) ; mMediaRecorder . prepare ( ) ; mMediaRecorder . start ( ) ; // Recording a scene with moving objects would greatly help reduce // the time for waiting . if ( ! mMaxFileSizeCond . block ( MAX_FILE_SIZE_TIMEOUT_MS ) ) { fail ( "timed out waiting for MEDIA_RECORDER_INFO_MAX_FILESIZE_REACHED" ) ; } mMediaRecorder . stop ( ) ; checkOutputFileSize ( OUTPUT_PATH , fileSize , tolerance ) ; < |startfocus| > mCamera . release ( ) ; mCamera = null ; < |endfocus| > } private void checkOutputFileSize ( final String fileName , long fileSize , long tolerance ) { assertTrue ( mOutFile . exists ( ) ) ; assertEquals ( fileSize , mOutFile . length ( ) , tolerance ) ; assertTrue ( mOutFile . delete ( ) ) ; } public void testOnErrorListener ( ) throws Exception { if ( ! hasMicrophone ( ) || ! hasAmrNb ( ) ) { MediaUtils . skipTest ( "no audio codecs or microphone" ) ; return ; } mMediaRecorder . setAudioSource ( MediaRecorder . AudioSource . DEFAULT ) ; mMediaRecorder . setOutputFormat ( MediaRecorder . OutputFormat . THREE_GPP ) ; mMediaRecorder . setAudioEncoder ( MediaRecorder . AudioEncoder . AMR_NB ) ;
assertTrue ( "Incorrect longitude : " + longitude , Math . abs ( longitude - LONGITUDE ) <= TOLERANCE ) ; retriever . release ( ) ; return true ; } private void checkOutputExist ( ) { assertTrue ( mOutFile . exists ( ) ) ; assertTrue ( mOutFile . length ( ) > 0 ) ; assertTrue ( mOutFile . delete ( ) ) ; } public void testRecorderVideo ( ) throws Exception { if ( ! hasCamera ( ) ) { return ; } mCamera = Camera . open ( 0 ) ; setSupportedResolution ( mCamera ) ; mCamera . unlock ( ) ; mMediaRecorder . setVideoSource ( MediaRecorder . VideoSource . CAMERA ) ; mMediaRecorder . setOutputFormat ( MediaRecorder . OutputFormat . DEFAULT ) ; mMediaRecorder . setOutputFile ( OUTPUT_PATH2 ) ; mMediaRecorder . setVideoEncoder ( MediaRecorder . VideoEncoder . DEFAULT ) ; mMediaRecorder . setPreviewDisplay ( mActivity . getSurfaceHolder ( ) . getSurface ( ) ) ; mMediaRecorder . setVideoSize ( mVideoWidth , mVideoHeight ) ; FileOutputStream fos = new FileOutputStream ( OUTPUT_PATH2 ) ; FileDescriptor fd = fos . getFD ( ) ; mMediaRecorder . setOutputFile ( fd ) ; long maxFileSize = MAX_FILE_SIZE * 10 ; recordMedia ( maxFileSize , mOutFile2 ) ;
|| regState == ServiceState . RIL_REG_STATE_DENIED ) { rejectCode = Integer . parseInt ( states [ 13 ] ) ; } } if ( states . length > 14 ) { if ( states [ 14 ] != null && states [ 14 ] . length ( ) > 0 ) { psc = ( int ) Long . parseLong ( states [ 14 ] , 16 ) ; } } } catch ( NumberFormatException ex ) { loge ( "error parsing RegistrationState : " + ex ) ; } } < |startfocus| > mGsmRoaming = regCodeIsRoaming ( regState ) ; mNewSS . setVoiceRegState ( regCodeToServiceState ( regState ) ) ; mNewSS . setRilVoiceRadioTechnology ( type ) ; mNewRejectCode = rejectCode ; < |endfocus| > boolean isVoiceCapable = mPhone . getContext ( ) . getResources ( ) . getBoolean ( com . android . internal . R . bool . config_voice_capable ) ; if ( ( regState == ServiceState . RIL_REG_STATE_DENIED_EMERGENCY_CALL_ENABLED || regState == ServiceState . RIL_REG_STATE_NOT_REG_EMERGENCY_CALL_ENABLED || regState == ServiceState . RIL_REG_STATE_SEARCHING_EMERGENCY_CALL_ENABLED ) && ! isVoiceCapable ) { // If voice is not supported , do not allow emergency call . mNewSS . setVoiceRegState ( ServiceState . STATE_POWER_OFF ) ; }
< |startfocus| > private int convertHalRegStateToServiceState ( int halRegState ) { < |endfocus| > switch ( halRegState ) { case RegState . NOT_REG_MT_NOT_SEARCHING_OP : return ServiceState . RIL_REG_STATE_NOT_REG ; case RegState . REG_HOME : return ServiceState . RIL_REG_STATE_HOME ; case RegState . NOT_REG_MT_SEARCHING_OP : return ServiceState . RIL_REG_STATE_SEARCHING ; case RegState . REG_DENIED : return ServiceState . RIL_REG_STATE_DENIED ; case RegState . UNKNOWN : return ServiceState . RIL_REG_STATE_UNKNOWN ; case RegState . REG_ROAMING : return ServiceState . RIL_REG_STATE_ROAMING ; case RegState . NOT_REG_MT_NOT_SEARCHING_OP_EM : return ServiceState . RIL_REG_STATE_NOT_REG_EMERGENCY_CALL_ENABLED ; case RegState . NOT_REG_MT_SEARCHING_OP_EM : return ServiceState . RIL_REG_STATE_SEARCHING_EMERGENCY_CALL_ENABLED ; case RegState . REG_DENIED_EM : return ServiceState . RIL_REG_STATE_DENIED_EMERGENCY_CALL_ENABLED ; case RegState . UNKNOWN_EM : return ServiceState . RIL_REG_STATE_UNKNOWN_EMERGENCY_CALL_ENABLED ; default : return ServiceState . REGISTRATION_STATE_NOT_REGISTERED_AND_NOT_SEARCHING ; }
if ( DBG ) { log ( "handlPollVoiceRegResultMessage : regState = " + registrationState + " radioTechnology = " + voiceRegStateResult . rat ) ; } break ; } case EVENT_POLL_STATE_GPRS : { DataRegStateResult dataRegStateResult = ( DataRegStateResult ) ar . result ; int regState = convertHalRegStateToServiceState ( dataRegStateResult . regState ) ; int dataRegState = regCodeToServiceState ( regState ) ; int newDataRat = dataRegStateResult . rat ; < |startfocus| > int oldDataRAT = mSS . getRilDataRadioTechnology ( ) ; mNewSS . setDataRegState ( dataRegState ) ; mNewSS . setRilDataRadioTechnology ( newDataRat ) ; < |endfocus| > if ( mPhone . isPhoneTypeGsm ( ) ) { mNewReasonDataDenied = dataRegStateResult . reasonDataDenied ; mNewMaxDataCalls = dataRegStateResult . maxDataCalls ; mDataRoaming = regCodeIsRoaming ( regState ) ; if ( DBG ) { log ( "handlPollStateResultMessage : GsmSST setDataRegState = " + dataRegState + " regState = " + regState + " dataRadioTechnology = " + newDataRat ) ; } } else if ( mPhone . isPhoneTypeCdma ( ) ) {
} } } @Test public void testSocketConnectTimeout ( ) throws Exception { // #connect ( SocketAddress endpoint , int timeout ) checkOperationTimesOut ( ( ) - > new Socket ( ) , s - > s . connect ( UNREACHABLE_ADDRESS , TIMEOUT_MILLIS ) ) ; // Setting SO_TIMEOUT should not affect connect timeout . checkOperationTimesOut ( ( ) - > new Socket ( ) , s - > { s . setSoTimeout ( TIMEOUT_MILLIS / 2 ) ; s . connect ( UNREACHABLE_ADDRESS , TIMEOUT_MILLIS ) ; } ) ; } @Test < |startfocus| > public void testSocketReadTimeout ( ) throws Exception { < |endfocus| > // #read ( ) try ( ServerSocket ss = new ServerSocket ( 0 ) ) { // The server socket will accept the connection without explicitly calling accept ( ) due // to TCP backlog . checkOperationTimesOut ( ( ) - > new Socket ( ) , s - > { s . connect ( ss . getLocalSocketAddress ( ) ) ; s . setSoTimeout ( TIMEOUT_MILLIS ) ; s . getInputStream ( ) . read ( ) ; } ) ; } } @Test public void testSocketWriteNeverTimeouts ( ) throws Exception {
writeCompleted . countDown ( ) ; } catch ( IOException ignored ) { } finally { writeCompleted . countDown ( ) ; } } ) ; thread . start ( ) ; // Wait for the thread to start . assertTrue ( threadStarted . await ( 500 , TimeUnit . MILLISECONDS ) ) ; // Wait for TIMEOUT_MILLIS + slop . If write does not complete by then , we assume it has // blocked . boolean blocked = < |startfocus| > ! writeCompleted . await ( ( long ) ( TIMEOUT_MILLIS * 1 . 2f ) , TimeUnit . MILLISECONDS ) ; < |endfocus| > assertTrue ( blocked ) ; // Make sure the writing thread completes after the socket is closed . sock . close ( ) ; assertTrue ( writeCompleted . await ( 5000 , TimeUnit . MILLISECONDS ) ) ; } } @Test public void testServerSocketAcceptTimeout ( ) throws Exception { // #accept ( ) checkOperationTimesOut ( ( ) - > new ServerSocket ( 0 ) , s - > { s . setSoTimeout ( TIMEOUT_MILLIS ) ; s . accept ( ) ; } ) ; } @Test public void testServerSocketChannelAcceptTimeout ( ) throws Exception { // #accept ( ) checkOperationTimesOut ( ( ) - > ServerSocketChannel . open ( ) , s - > { s . configureBlocking ( false ) ; s . socket ( ) . setSoTimeout ( TIMEOUT_MILLIS ) ; s . accept ( ) ; } ) ; } @Test public void testSocketReadTimeout ( ) throws Exception { // #read ( ) checkOperationTimesOut ( ( ) - > new Socket ( "localhost" , 0 ) , s - > { s . setSoTimeout ( TIMEOUT_MILLIS ) ; s . getInputStream ( ) . read ( ) ; } ) ; } @Test public void testSocketChannelReadTimeout ( ) throws Exception { // #read ( ) checkOperationTimesOut ( ( ) - > SocketChannel . open ( ) , s - > { s . configureBlocking ( false ) ; s . socket ( ) . setSoTimeout ( TIMEOUT_MILLIS ) ; s . read ( ByteBuffer . allocate ( 1 ) ) ; } ) ; } @Test public void testSocketWriteTimeout ( ) throws Exception { // #write ( ) checkOperationTimesOut ( ( ) - > new Socket ( "localhost" , 0 ) , s - > { s . setSoTimeout ( TIMEOUT_MILLIS ) ; s . getOutputStream ( ) . write ( 0 ) ; } ) ; } @Test public void testSocketChannelWriteTimeout ( ) throws Exception { // #write ( ) checkOperationTimesOut ( ( ) - > SocketChannel . open ( ) , s - > { s . configureBlocking ( false ) ; s . socket ( ) . setSoTimeout ( TIMEOUT_MILLIS ) ; s . write ( ByteBuffer . allocate ( 1 ) ) ; } ) ; } @Test public void testSocketConnectTimeout ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > new Socket ( ) , s - > { s . connect ( new InetSocketAddress ( "localhost" , 0 ) , TIMEOUT_MILLIS ) ; } ) ; } @Test public void testSocketChannelConnectTimeout ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > SocketChannel . open ( ) , s - > { s . configureBlocking ( false ) ; s . socket ( ) . setSoTimeout ( TIMEOUT_MILLIS ) ; s . connect ( new InetSocketAddress ( "localhost" , 0 ) ) ; } ) ; } @Test public void testSocketConnectTimeout_nonBlocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > new Socket ( ) , s - > { s . connect ( new InetSocketAddress ( "localhost" , 0 ) , TIMEOUT_MILLIS ) ; } ) ; } @Test public void testSocketChannelConnectTimeout_nonBlocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > SocketChannel . open ( ) , s - > { s . configureBlocking ( false ) ; s . socket ( ) . setSoTimeout ( TIMEOUT_MILLIS ) ; s . connect ( new InetSocketAddress ( "localhost" , 0 ) ) ; } ) ; } @Test public void testSocketConnectTimeout_blocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > new Socket ( ) , s - > { s . connect ( new InetSocketAddress ( "localhost" , 0 ) , TIMEOUT_MILLIS ) ; } ) ; } @Test public void testSocketChannelConnectTimeout_blocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > SocketChannel . open ( ) , s - > { s . configureBlocking ( false ) ; s . socket ( ) . setSoTimeout ( TIMEOUT_MILLIS ) ; s . connect ( new InetSocketAddress ( "localhost" , 0 ) ) ; } ) ; } @Test public void testSocketConnectTimeout_blocking_nonBlocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > new Socket ( ) , s - > { s . connect ( new InetSocketAddress ( "localhost" , 0 ) , TIMEOUT_MILLIS ) ; } ) ; } @Test public void testSocketChannelConnectTimeout_blocking_nonBlocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > SocketChannel . open ( ) , s - > { s . configureBlocking ( false ) ; s . socket ( ) . setSoTimeout ( TIMEOUT_MILLIS ) ; s . connect ( new InetSocketAddress ( "localhost" , 0 ) ) ; } ) ; } @Test public void testSocketConnectTimeout_nonBlocking_blocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > new Socket ( ) , s - > { s . connect ( new InetSocketAddress ( "localhost" , 0 ) , TIMEOUT_MILLIS ) ; } ) ; } @Test public void testSocketChannelConnectTimeout_nonBlocking_blocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > SocketChannel . open ( ) , s - > { s . configureBlocking ( false ) ; s . socket ( ) . setSoTimeout ( TIMEOUT_MILLIS ) ; s . connect ( new InetSocketAddress ( "localhost" , 0 ) ) ; } ) ; } @Test public void testSocketConnectTimeout_nonBlocking_nonBlocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > new Socket ( ) , s - > { s . connect ( new InetSocketAddress ( "localhost" , 0 ) , TIMEOUT_MILLIS ) ; } ) ; } @Test public void testSocketChannelConnectTimeout_nonBlocking_nonBlocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > SocketChannel . open ( ) , s - > { s . configureBlocking ( false ) ; s . socket ( ) . setSoTimeout ( TIMEOUT_MILLIS ) ; s . connect ( new InetSocketAddress ( "localhost" , 0 ) ) ; } ) ; } @Test public void testSocketConnectTimeout_blocking_blocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > new Socket ( ) , s - > { s . connect ( new InetSocketAddress ( "localhost" , 0 ) , TIMEOUT_MILLIS ) ; } ) ; } @Test public void testSocketChannelConnectTimeout_blocking_blocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > SocketChannel . open ( ) , s - > { s . configureBlocking ( false ) ; s . socket ( ) . setSoTimeout ( TIMEOUT_MILLIS ) ; s . connect ( new InetSocketAddress ( "localhost" , 0 ) ) ; } ) ; } @Test public void testSocketConnectTimeout_blocking_nonBlocking_nonBlocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > new Socket ( ) , s - > { s . connect ( new InetSocketAddress ( "localhost" , 0 ) , TIMEOUT_MILLIS ) ; } ) ; } @Test public void testSocketChannelConnectTimeout_blocking_nonBlocking_nonBlocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > SocketChannel . open ( ) , s - > { s . configureBlocking ( false ) ; s . socket ( ) . setSoTimeout ( TIMEOUT_MILLIS ) ; s . connect ( new InetSocketAddress ( "localhost" , 0 ) ) ; } ) ; } @Test public void testSocketConnectTimeout_nonBlocking_blocking_nonBlocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > new Socket ( ) , s - > { s . connect ( new InetSocketAddress ( "localhost" , 0 ) , TIMEOUT_MILLIS ) ; } ) ; } @Test public void testSocketChannelConnectTimeout_nonBlocking_blocking_nonBlocking ( ) throws Exception { // #connect ( ) checkOperationTimesOut ( ( ) - > SocketChannel . open ( ) , s - > { s . configureBlocking ( false ) ; s . socket ( ) . setSoTimeout ( TIMEOUT_MILLIS ) ; s . connect ( new InetSocketAddress ( "localhost" , 0 ) ) ; } ) ; } @Test public void testSocket
if ( roamingCap . maxBlacklistSize < 0 || roamingCap . maxWhitelistSize < 0 ) { Log . e ( TAG , "Invalid firmware roaming capabilities : max num blacklist bssid = " + roamingCap . maxBlacklistSize + " max num whitelist ssid = " + roamingCap . maxWhitelistSize ) ; } else { mFirmwareRoamingSupported = true ; mMaxNumBlacklistBssid = roamingCap . maxBlacklistSize ; mMaxNumWhitelistSsid = roamingCap . maxWhitelistSize ; < |startfocus| > Log . d ( TAG , "Firmware roaming is supported with capabilities : max num blacklist bssid = " < |endfocus| > + mMaxNumBlacklistBssid + " max num whitelist ssid = " + mMaxNumWhitelistSsid ) ; return true ; } } else { Log . e ( TAG , "Failed to get firmware roaming capabilities" ) ; } return false ;
public boolean setFirmwareRoamingConfiguration ( ArrayList < String > blacklistBssids , < |startfocus| > ArrayList < String > whitelistSsids ) { < |endfocus| > if ( ! mFirmwareRoamingSupported ) { Log . e ( TAG , "Firmware roaming is not supported" ) ; return false ; } if ( blacklistBssids == null || whitelistSsids == null ) { Log . e ( TAG , "Invalid firmware roaming configuration settings" ) ; return false ; } int blacklistSize = blacklistBssids . size ( ) ; int whitelistSize = whitelistSsids . size ( ) ; if ( blacklistSize > mMaxNumBlacklistBssid || whitelistSize > mMaxNumWhitelistSsid ) { Log . e ( TAG , "Invalid BSSID blacklist size " + blacklistSize + " SSID whitelist size " + whitelistSize + " . Max blacklist size : " + mMaxNumBlacklistBssid + " , max whitelist size : " + mMaxNumWhitelistSsid ) ; return false ; } WifiNative . RoamingConfig roamConfig = new WifiNative . RoamingConfig ( ) ; roamConfig . blacklistBssids = blacklistBssids ; roamConfig . whitelistSsids = whitelistSsids ; return mWifiNative . configureRoaming ( roamConfig ) ;
public boolean requestIcon ( String bssid , String fileName ) { < |startfocus| > if ( bssid == null || fileName == null ) { Log . e ( TAG , "Invalid arguments to requestIcon" ) ; return false ; } < |endfocus| > return mSupplicantStaIfaceHal . initiateHs20IconQuery ( bssid , fileName ) ;
* limitations under the License . */ package com . android . server . wifi ; import static org . junit . Assert . assertTrue ; import static org . mockito . Mockito . mock ; import android . os . Handler ; import android . os . Message ; import android . util . SparseArray ; import java . util . HashMap ; import java . util . Map ; /* * * Creates a mock WifiMonitor . * WARNING : This does not perfectly mock the behavior of WifiMonitor at the moment < |startfocus| > * ex . startMonitoring does nothing and will not send a connection / disconnection event < |endfocus| > */ public class MockWifiMonitor extends WifiMonitor { private final Map < String , SparseArray < Handler > > mHandlerMap = new HashMap < > ( ) ; public MockWifiMonitor ( ) { super ( mock ( WifiInjector . class ) ) ; } @Override public void registerHandler ( String iface , int what , Handler handler ) { SparseArray < Handler > ifaceHandlers = mHandlerMap . get ( iface ) ; if ( ifaceHandlers == null ) { ifaceHandlers = new SparseArray < > ( ) ; mHandlerMap . put ( iface , ifaceHandlers ) ; } ifaceHandlers . put ( what , handler ) ; } @Override
result . setResult ( mISupplicantP2pIface . startWpsPinKeypad ( groupIfName , pin ) ) ; } catch ( RemoteException e ) { Log . e ( TAG , "ISupplicantP2pIface exception : " + e ) ; supplicantServiceDiedHandler ( ) ; } return result . isSuccess ( ) ; } } /* * * Initiate WPS Pin Display setup . * * @param groupIfName Group interface name to use . * @param bssid BSSID of the AP . Use zero'ed bssid to indicate wildcard . < |startfocus| > * @return true , if operation was successful . < |endfocus| > */ public String startWpsPinDisplay ( String groupIfName , String bssid ) { if ( TextUtils . isEmpty ( groupIfName ) || TextUtils . isEmpty ( bssid ) ) return null ; synchronized ( mLock ) { if ( ! checkSupplicantP2pIfaceAndLogFailure ( "startWpsPinDisplay" ) ) return null ; if ( groupIfName == null ) { Log . e ( TAG , "Group name required when requesting WPS KEYPAD . " ) ; return null ; } // Null values should be fine , since bssid can be empty . byte [ ] macAddress = null ; if ( bssid != null ) {
public WifiNative ( String interfaceName , WifiVendorHal vendorHal , SupplicantStaIfaceHal staIfaceHal , SupplicantP2pIfaceHal p2pIfaceHal , WificondControl condControl ) { mTAG = "WifiNative - " + interfaceName ; mInterfaceName = interfaceName ; mWifiVendorHal = vendorHal ; mSupplicantStaIfaceHal = staIfaceHal ; mSupplicantP2pIfaceHal = p2pIfaceHal ; mWificondControl = condControl ; } public String getInterfaceName ( ) { return mInterfaceName ; } < |startfocus| > // Note this affects logging on for all interfaces < |endfocus| > public void enableVerboseLogging ( int verbose ) { mWificondControl . enableVerboseLogging ( verbose > 0 ? true : false ) ; mSupplicantStaIfaceHal . enableVerboseLogging ( verbose > 0 ) ; mWifiVendorHal . enableVerboseLogging ( verbose > 0 ) ; } /* ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * * Native Initialization / Deinitialization ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** / /* * * Setup wifi native for Client mode operations . * * 1 . Starts the Wifi HAL and configures it in client / STA mode . * 2 . Setup Wificond to operate in client mode and retrieve the handle to use for client * operations . * 3 . Setup the supplicant and retrieve the handle to use for client operations . * * @return true if the setup succeeds , false otherwise . */ public boolean initialize ( ) { if ( ! mWifiVendorHal . initialize ( mInterfaceName ) ) { Log . e ( mTAG , "Failed to initialize vendor interface" ) ; return false ; } if ( ! mWificondControl . setupInterfaceForClientMode ( mInterfaceName ) ) { Log . e ( mTAG , "Failed to setup interface for client mode" ) ; return false ; } if ( ! mSupplicantStaIfaceHal . initialize ( mInterfaceName ) ) { Log . e ( mTAG , "Failed to initialize supplicant interface" ) ; return false ; } return true ; } /* * * Teardown wifi native for Client mode operations . * * 1 . Teardown the supplicant . * 2 . Teardown Wificond . * 3 . Teardown the Wifi HAL . */ public void terminate ( ) { mSupplicantStaIfaceHal . terminate ( ) ; mWificondControl . tearDownClientInterface ( mInterfaceName ) ; mWifiVendorHal . terminate ( ) ; } /* ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * * Native Wifi HAL methods ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** / /* * * Start wifi HAL . * * @return true if the HAL is started , false otherwise . */ public boolean startHal ( ) { return mWifiVendorHal . startVendorHal ( ) ; } /* * * Stop wifi HAL . * * @return true if the HAL is stopped , false otherwise . */ public boolean stopHal ( ) { return mWifiVendorHal . stopVendorHal ( ) ; } /* * * Get the supported feature set . * * @return the feature set bit mask . */ public long getSupportedFeatureSet ( ) { return mWifiVendorHal . getSupportedFeatureSet ( ) ; } /* * * Get the supported feature set . * * @return the feature set bit mask . */ public boolean isHalStarted ( ) { return mWifiVendorHal . isHalStarted ( ) ; } /* * * Get the supported feature set . * * @return the feature set bit mask . */ public boolean isHalStarted ( boolean startIfNotStarted ) { return mWifiVendorHal . isHalStarted ( startIfNotStarted ) ; } /* * * Get the supported feature set . * * @return the feature set bit mask . */ public boolean isHalStarted ( boolean startIfNotStarted , boolean stopIfStarted ) { return mWifiVendorHal . isHalStarted ( startIfNotStarted , stopIfStarted ) ; } /* * * Get the supported feature set . * * @return the feature set bit mask . */ public boolean isHalStarted ( boolean startIfNotStarted , boolean stopIfStarted , boolean restart ) { return mWifiVendorHal . isHalStarted ( startIfNotStarted , stopIfStarted , restart ) ; } /* * * Get the supported feature set . * * @return the feature set bit mask . */ public boolean isHalStarted ( boolean startIfNotStarted , boolean stopIfStarted , boolean restart , boolean force ) { return mWifiVendorHal . isHalStarted ( startIfNotStarted , stopIfStarted , restart , force ) ; } /* * * Get the supported feature set . * * @return the feature set bit mask . */ public boolean isHalStarted ( boolean startIfNotStarted , boolean stopIfStarted , boolean restart , boolean force , boolean forceStop ) { return mWifiVendorHal . isHalStarted ( startIfNotStarted , stopIfStarted , restart , force , forceStop ) ; } /* * * Get the supported feature set . * * @return the feature set bit mask . */ public boolean isHalStarted ( boolean startIfNotStarted , boolean stopIfStarted , boolean restart , boolean force , boolean forceStop , boolean forceRestart ) { return mWifiVendorHal . isHalStarted ( startIfNotStarted , stopIfStarted , restart , force , forceStop , forceRestart ) ; } /* * * Get the supported feature set . * * @return the feature set bit mask . */ public boolean isHalStarted ( boolean startIfNotStarted , boolean stopIfStarted , boolean restart , boolean force , boolean forceStop , boolean forceRestart , boolean forceRestartHal ) { return mWifiVendorHal . isHalStarted ( startIfNotStarted , stopIfStarted , restart , force , forceStop , forceRestart , forceRestartHal ) ; } /* * * Get the supported feature set . * * @return the feature set bit mask . */ public boolean isHalStarted ( boolean startIfNotStarted , boolean stopIfStarted , boolean restart , boolean force , boolean forceStop , boolean forceRestart , boolean forceRestartHal , boolean forceRestartSupplicant ) { return mWifiVendorHal . isHalStarted ( startIfNotStarted , stopIfStarted , restart , force , forceStop , forceRestart , forceRestartHal , forceRestartSupplicant ) ; } /* * * Get the supported feature set . * * @return the feature set bit mask . */ public boolean isHalStarted ( boolean startIfNotStarted , boolean stopIfStarted , boolean restart , boolean force , boolean forceStop , boolean forceRestart , boolean forceRestartHal , boolean forceRestartSupplicant , boolean forceRestartWificond ) { return mWifiVendorHal . isHalStarted ( startIfNotStarted , stopIfStarted , restart , force , forceStop , forceRestart , forceRestartHal , forceRestartSupplicant , forceRestartWificond ) ; } /* * * Get the supported feature set . * * @return the feature set bit mask . */ public boolean isHalStarted ( boolean startIfNotStarted , boolean stopIfStarted , boolean restart , boolean force , boolean forceStop , boolean forceRestart , boolean forceRestartHal , boolean forceRestartSupplicant , boolean forceRestartWificond , boolean forceRestartWifiScanner ) { return mWifiVendorHal . isHalStarted ( startIfNotStarted , stopIfStarted , restart , force , forceStop , forceRestart , forceRestartHal , forceRestartSupplicant , forceRestartWificond , forceRestartWifiScanner ) ; } /* * * Get the supported feature set . * * @return the feature set bit mask . */ public boolean isHalStarted ( boolean startIfNotStarted , boolean stopIfStarted , boolean restart , boolean force
public boolean startFilteringMulticastV4Packets ( ) { return mSupplicantStaIfaceHal . stopRxFilter ( ) && mSupplicantStaIfaceHal . removeRxFilter ( SupplicantStaIfaceHal . RX_FILTER_TYPE_V4_MULTICAST ) < |startfocus| > && mSupplicantStaIfaceHal . startRxFilter ( ) ; < |endfocus| >
public boolean stopFilteringMulticastV4Packets ( ) { return mSupplicantStaIfaceHal . stopRxFilter ( ) && mSupplicantStaIfaceHal . addRxFilter ( SupplicantStaIfaceHal . RX_FILTER_TYPE_V4_MULTICAST ) < |startfocus| > && mSupplicantStaIfaceHal . stopRxFilter ( ) ; < |endfocus| >
public boolean startFilteringMulticastV6Packets ( ) { return mSupplicantStaIfaceHal . stopRxFilter ( ) && mSupplicantStaIfaceHal . removeRxFilter ( SupplicantStaIfaceHal . RX_FILTER_TYPE_V6_MULTICAST ) < |startfocus| > && mSupplicantStaIfaceHal . startRxFilter ( ) ; < |endfocus| >
public boolean stopFilteringMulticastV6Packets ( ) { return mSupplicantStaIfaceHal . stopRxFilter ( ) && mSupplicantStaIfaceHal . addRxFilter ( SupplicantStaIfaceHal . RX_FILTER_TYPE_V6_MULTICAST ) < |startfocus| > && mSupplicantStaIfaceHal . stopRxFilter ( ) ; < |endfocus| >
public boolean setSerialNumber ( String value ) { return mSupplicantStaIfaceHal . setWpsSerialNumber ( value ) ; } public void setPowerSave ( boolean enabled ) { mSupplicantStaIfaceHal . setPowerSave ( enabled ) ; } /* * * "sta" prioritizes STA connection over P2P and "p2p" prioritizes * P2P connection over STA */ public boolean setConcurrencyPriority ( boolean isStaHigherPriority ) { return mSupplicantStaIfaceHal . setConcurrencyPriority ( isStaHigherPriority ) ; } < |startfocus| > /* * WifiSupplicantControl methods . TODO : These should use HIDL now . */ < |endfocus| > /* * * Migrate all the configured networks from wpa_supplicant . * * @param configs Map of configuration key to configuration objects corresponding to all * the networks . * @param networkExtras Map of extra configuration parameters stored in wpa_supplicant . conf * @return Max priority of all the configs . */ public boolean migrateNetworksFromSupplicant ( Map < String , WifiConfiguration > configs , SparseArray < Map < String , String > > networkExtras ) { return mSupplicantStaIfaceHal . loadNetworks ( configs , networkExtras ) ; } /* *
/* * * Handler to notify the occurrence of various events during PNO scan . */ public interface PnoEventHandler { /* * * Callback to notify when one of the shortlisted networks is found during PNO scan . * @param results List of Scan results received . */ void onPnoNetworkFound ( ScanResult [ ] results ) ; /* * * Callback to notify when the PNO scan schedule fails . */ void onPnoScanFailed ( ) ; } < |startfocus| > /* scan status , keep these values in sync with gscan . h */ < |endfocus| > public static final int WIFI_SCAN_RESULTS_AVAILABLE = 0 ; public static final int WIFI_SCAN_THRESHOLD_NUM_SCANS = 1 ; public static final int WIFI_SCAN_THRESHOLD_PERCENT = 2 ; public static final int WIFI_SCAN_FAILED = 3 ; public boolean startScan ( ScanSettings settings , ScanEventHandler eventHandler ) { return mWifiVendorHal . startScan ( settings , eventHandler ) ; } public void stopScan ( ) { mWifiVendorHal . stopScan ( ) ; } public void pauseScan ( ) { mWifiVendorHal . pauseScan ( ) ; } public void restartScan ( ) { mWifiVendorHal . restartScan ( ) ; }
public void setWifiLinkLayerStats ( String iface , int enable ) { < |startfocus| > // TODO : b / 120981292 : Remove this method and calling code . < |endfocus| >
< |startfocus| > public boolean isGetChannelsForBandSupported ( ) { < |endfocus| > return mWifiVendorHal . isGetChannelsForBandSupported ( ) ;
public boolean startLoggingRingBuffer ( int verboseLevel , int flags , int maxInterval , int minDataSize , String ringName ) { return mWifiVendorHal . startLoggingRingBuffer ( verboseLevel , flags , maxInterval , minDataSize , ringName ) ; } public int getSupportedLoggerFeatureSet ( ) { return mWifiVendorHal . getSupportedLoggerFeatureSet ( ) ; } < |startfocus| > < |endfocus| > public boolean resetLogHandler ( ) { return mWifiVendorHal . resetLogHandler ( ) ; } public String getDriverVersion ( ) { return mWifiVendorHal . getDriverVersion ( ) ; } public String getFirmwareVersion ( ) { return mWifiVendorHal . getFirmwareVersion ( ) ; } public static class RingBufferStatus { String name ; int flag ; int ringBufferId ; int ringBufferByteSize ; int verboseLevel ; int writtenBytes ; int readBytes ; int writtenRecords ; // Bit masks for interpreting |flag| public static final int HAS_BINARY_ENTRIES = ( 1 < < 0 ) ;
* @hide */ public static final String KEY_NOTIFY_INTERNATIONAL_CALL_ON_WFC_BOOL = "notify_international_call_on_wfc_bool" ; /* * * Offset to be reduced from rsrp threshold while calculating signal strength level . * @hide */ public static final String KEY_SIGNAL_STRENGTH_OFFSET_INT = "signal_strength_offset_int" ; /* * * Threshold of EARFCN above which signal_strength_offset_int will be applied . < |startfocus| > * Unit of this value should be in MHz . < |endfocus| > * @hide */ public static final String KEY_SIGNAL_STRENGTH_EARFCN_THRESHOD_INT = "signal_strength_earfcn_threshold_int" ; /* * The default value for every variable . */ private final static PersistableBundle sDefaults ; static { sDefaults = new PersistableBundle ( ) ; sDefaults . putBoolean ( KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL , true ) ; sDefaults . putBoolean ( KEY_ADDITIONAL_CALL_SETTING_BOOL , true ) ; sDefaults . putBoolean ( KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL , false ) ; sDefaults . putBoolean ( KEY_ALLOW_LOCAL_DTMF_TONES_BOOL , true ) ;
"notify_international_call_on_wfc_bool" ; /* * * Offset to be reduced from rsrp threshold while calculating signal strength level . * @hide */ public static final String KEY_SIGNAL_STRENGTH_OFFSET_INT = "signal_strength_offset_int" ; /* * * Threshold of EARFCN above which signal_strength_offset_int will be applied . * Unit of this value should be in MHz . * @hide */ < |startfocus| > public static final String KEY_SIGNAL_STRENGTH_EAFCN_THRESHOLD_INT = < |endfocus| > "signal_strength_earfcn_threshold_int" ; /* * The default value for every variable . */ private final static PersistableBundle sDefaults ; static { sDefaults = new PersistableBundle ( ) ; sDefaults . putBoolean ( KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL , true ) ; sDefaults . putBoolean ( KEY_ADDITIONAL_CALL_SETTING_BOOL , true ) ; sDefaults . putBoolean ( KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL , false ) ; sDefaults . putBoolean ( KEY_ALLOW_LOCAL_DTMF_TONES_BOOL , true ) ; sDefaults . putBoolean ( KEY_APN_EXPAND_BOOL , true ) ; sDefaults . putBoolean ( KEY_AUTO_RETRY_ENABLED_BOOL , false ) ;
* * < p > Requires Permission : * { @link android . Manifest . permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE } * Or the calling app has carrier privileges . @see #hasCarrierPrivileges * * @param AID Application id . See ETSI 102 . 221 and 101 . 220 . * @param p2 P2 parameter ( described in ISO 7816 - 4 ) . Default value : 0x00 * @return an IccOpenLogicalChannelResponse object . */ < |startfocus| > public IccOpenLogicalChannelResponse iccOpenLogicalChannel ( String AID , byte p2 ) { < |endfocus| > return iccOpenLogicalChannel ( getSubId ( ) , AID , p2 ) ; } /* * * Opens a logical channel to the ICC card . * * Input parameters equivalent to TS 27 . 007 AT + CCHO command . * * < p > Requires Permission : * { @link android . Manifest . permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE } * Or the calling app has carrier privileges . @see #hasCarrierPrivileges * * @param subId The subscription to use . * @param AID Application id . See ETSI 102 . 221 and 101 . 220 . * @param p2 P2 parameter ( described in ISO 7816 - 4 ) . Default value : 0x00 * @return an IccOpenLogicalChannelResponse object . */ public IccOpenLogicalChannelResponse iccOpenLogicalChannel ( int subId , String AID , byte p2 ) { try { ITelephony telephony = getITelephony ( ) ; if ( telephony != null ) { return telephony . iccOpenLogicalChannel ( subId , AID , p2 ) ; } else { // This can happen when the ITelephony interface is not up yet . return new IccOpenLogicalChannelResponse ( 2 , - 1 , null ) ; } } catch ( RemoteException ex ) { return new IccOpenLogicalChannelResponse ( 2 , - 1 , null ) ; } catch ( NullPointerException ex ) { return new IccOpenLogicalChannelResponse ( 2 , - 1 , null ) ; } } /* * * Closes a previously opened logical channel to the ICC card . * * Input parameters equivalent to TS 27 . 007 AT + CCHC command . * * < p > Requires Permission : * { @link android . Manifest . permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE } * Or the calling app has carrier privileges . @see #hasCarrierPrivileges * * @param channel is the channel id to be closed as retruned by a successful * iccOpenLogicalChannel . * @return true if the channel was closed successfully . */ public boolean iccCloseLogicalChannel ( int channel ) { return iccCloseLogicalChannel ( getSubId ( ) , channel ) ; } /* * * Closes a previously opened logical channel to the ICC card . * * Input parameters equivalent to TS 27 . 007 AT + CCHC command . * * < p > Requires Permission : * { @link android . Manifest . permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE } * Or the calling app has carrier privileges . @see #hasCarrierPrivileges * * @param subId The subscription to use . * @param channel is the channel id to be closed as retruned by a successful * iccOpenLogicalChannel . * @return true if the channel was closed successfully . */ public boolean iccCloseLogicalChannel ( int subId , int channel ) { try { ITelephony telephony = getITelephony ( ) ; if ( telephony != null ) { return telephony . iccCloseLogicalChannel ( subId , channel ) ; } else { // This can happen when the ITelephony interface is not up yet . return false ; } } catch ( RemoteException ex ) { return false ; } catch ( NullPointerException ex ) { return false ; } } /* * * Transmit an APDU to the ICC card over a logical channel . * * Input parameters equivalent to TS 27 . 007 AT + CGLA command . * * < p > Requires Permission : * { @link android . Manifest . permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE } * Or the calling app has carrier privileges . @see #hasCarrierPrivileges * * @param channel is the channel id to be closed as returned by a successful * iccOpenLogicalChannel . * @param cla Class of the APDU command . * @param instruction Instruction of the APDU command . * @param p1 P1 value of the APDU command . * @param p2 P2 value of the APDU command . * @param p3 P3 value of the APDU command . If p3 is negative a 4 byte APDU * is sent to the SIM . * @param data Data to be sent with the APDU . */ public String iccTransmitApduLogicalChannel ( int channel , int cla , int instruction , int p1 , int p2 , int p3 , String data ) { return iccTransmitApduLogicalChannel ( getSubId ( ) , channel , cla , instruction , p1 , p2 , p3 , data ) ; } /* * * Transmit an APDU to the ICC card over a logical channel . * * Input parameters equivalent to TS 27 . 007 AT + CGLA command . * * < p > Requires Permission : * { @link android . Manifest . permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE } * Or the calling app has carrier privileges . @see #hasCarrierPrivileges * * @param subId The subscription to use . * @param channel is the channel id to be closed as returned by a successful * iccOpenLogicalChannel . * @param cla Class of the APDU command . * @param instruction Instruction of the APDU command . * @param p1 P1 value of the APDU command . * @param p2 P2 value of the APDU command . * @param p3 P3 value of the APDU command . If p3 is negative a 4 byte APDU * is sent to the SIM . * @param data Data to be sent with the APDU . */ public String iccTransmitApduLogicalChannel ( int subId , int channel , int cla , int instruction , int p1 , int p2 , int p3 , String data ) { try { ITelephony telephony = getITelephony ( ) ; if ( telephony != null ) { return telephony . iccTransmitApduLogicalChannel ( subId , channel , cla , instruction , p1 , p2 , p3 , data ) ; } else { // This can happen when the ITelephony interface is not up yet . return "" ; } } catch ( RemoteException ex ) { return "" ; } catch ( NullPointerException ex ) { return "" ; } } /* * * Transmit an APDU to the ICC card over the basic channel . * * Input parameters equivalent to TS 27 . 007 AT + CSIM command . * * < p > Requires Permission : * { @link android . Manifest . permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE } * Or the calling app has carrier privileges . @see #hasCarrierPrivileges * * @param cla Class of the APDU command . * @param instruction Instruction of the APDU command . * @param p1 P1 value of the APDU command . * @param p2 P2 value of the APDU command . * @param p3 P3 value of the APDU command . If p3 is negative a 4 byte APDU * is sent to the SIM . * @param data Data to be sent with the APDU . */ public String iccTransmitApduBasicChannel ( int cla , int instruction , int p1 , int p2 , int p3 , String data ) { return ic
* limitations under the License . */ package com . android . server . wifi . scanner ; import android . content . Context ; import android . net . wifi . WifiScanner ; import android . os . Handler ; import android . os . Looper ; import android . os . Message ; import android . util . Log ; import com . android . server . wifi . Clock ; import com . android . server . wifi . WifiNative ; /* * * WifiScanner implementation that takes advantage of the gscan HAL API < |startfocus| > * The gscan API is used to perform background scans and wificond is used for oneshot scans . < |endfocus| > * @see com . android . server . wifi . scanner . WifiScannerImpl for more details on each method . */ public class HalWifiScannerImpl extends WifiScannerImpl implements Handler . Callback { private static final String TAG = "HalWifiScannerImpl" ; private static final boolean DBG = false ; private final WifiNative mWifiNative ; private final ChannelHelper mChannelHelper ; private final WificondScannerImpl mWificondScannerDelegate ; private final boolean mHalBasedPnoSupported ; public HalWifiScannerImpl ( Context context , WifiNative wifiNative , Looper looper , Clock clock ) { mWifiNative = wifiNative ; mChannelHelper = new HalChannelHelper ( wifiNative ) ;
* limitations under the License . */ package com . android . server . wifi . scanner ; import android . content . Context ; import android . net . wifi . WifiScanner ; import android . os . Handler ; import android . os . Looper ; import android . os . Message ; import android . util . Log ; import com . android . server . wifi . Clock ; import com . android . server . wifi . WifiMonitor ; import com . android . server . wifi . WifiNative ; /* * * WifiScanner implementation that takes advantage of the gscan HAL API * The gscan API is used to perform background scans and wificond is used for onehot scans . * @see com . android . server . wifi . scanner . WifiScannerImpl for more details on each method . */ public class HalWifiScannerImpl extends WifiScannerImpl implements Handler . Callback { private static final String TAG = "HalWifiScannerImpl" ; private static final boolean DBG = false ; private final WifiNative mWifiNative ; private final ChannelHelper mChannelHelper ; private final WificondScannerImpl mWificondScannerDelegate ; private final boolean mHalBasedPnoSupported ; public HalWifiScannerImpl ( Context context , WifiNative wifiNative , WifiMonitor wifiMonitor , Looper looper , Clock clock ) {
public void describeTo ( Description description ) { < |startfocus| > description . appendText ( toString ( ) ) ; < |endfocus| >
String [ ] s ; s = params . getCipherSuites ( ) ; if ( s != null ) { setEnabledCipherSuites ( s ) ; } s = params . getProtocols ( ) ; if ( s != null ) { setEnabledProtocols ( s ) ; } if ( params . getNeedClientAuth ( ) ) { setNeedClientAuth ( true ) ; } else if ( params . getWantClientAuth ( ) ) { setWantClientAuth ( true ) ; } else { setWantClientAuth ( false ) ; } } < |startfocus| > // Android - added : Make toString explicit that this is an SSLServerSocket ( see http :/ / b / 6602228 ) < |endfocus| > @Override public String toString ( ) { return "SSL" + super . toString ( ) ; } }
public void receivedWnmFrame ( WnmData data ) { mHandler . notifyWnmFrameReceived ( data ) ; } /* * * Request the specified icon file |fileName| from the specified AP |bssid| . * @return true if the request is sent successfully , false otherwise */ public boolean queryPasspointIcon ( long bssid , String fileName ) { return mHandler . requestIcon ( bssid , fileName ) ; } /* * < |startfocus| > * Lookup the ANQP elements associated with the given AP from the cache . An empty map < |endfocus| > * will be returned if no match found in the cache . * * @param scanResult The scan result associated with the AP * @return Map of ANQP elements */ public Map < Constants . ANQPElementType , ANQPElement > getANQPElements ( ScanResult scanResult ) { // Retrieve the Hotspot 2 . 0 Vendor Specific IE . InformationElementUtil . Vsa vsa = InformationElementUtil . getHS2VendorSpecificIE ( scanResult . informationElements ) ; // Lookup ANQP data in the cache . long bssid = Utils . parseMac ( scanResult . BSSID ) ; ANQPData anqpEntry = mAnqpCache . getEntry ( ANQPNetworkKey . buildKey (
mHandler . notifyWnmFrameReceived ( data ) ; } /* * * Request the specified icon file |fileName| from the specified AP |bssid| . * @return true if the request is sent successfully , false otherwise */ public boolean queryPasspointIcon ( long bssid , String fileName ) { return mHandler . requestIcon ( bssid , fileName ) ; } /* * * Lookup the ANQP elements associated with the given AP from the cache . An empty map * will be returned if no match found in the cache . * * @param scanResult The scan result associated with the AP * @return Map of ANQP elements */ public Map < Constants . ANQPElementType , ANQPElement > getANQPElements ( ScanResult scanResult ) { // Retrieve the Hotspot 2 . 0 Vendor Specific IE . InformationElementUtil . Vsa vsa = InformationElementUtil . getHS2VendorSpecificIE ( scanResult . informationElements ) ; // Lookup ANQP data in the cache . long bssid = Utils . parseMac ( scanResult . BSSID ) ; ANQPData anqpEntry = mAnqpCache . getEntry ( ANQPNetworkKey . buildKey ( scanResult . SSID , bssid , scanResult . hessid , vsa . anqpDomainID ) ) ;
public void enter ( ) { super . enter ( ) ; < |startfocus| > CallAudioState newState = new CallAudioState ( mIsMuted , ROUTE_BLUETOOTH , mAvailableRoutes ) ; setSystemAudioState ( newState ) ; updateInternalCallAudioState ( ) ; < |endfocus| >
* { @link android . Manifest . permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE } * Or the calling app has carrier privileges . @see #hasCarrierPrivileges * * @param AID Application id . See ETSI 102 . 221 and 101 . 220 . * @return an IccOpenLogicalChannelResponse object . * @deprecated Replaced by { @link #iccOpenLogicalChannel ( String , byte ) } */ @Deprecated public IccOpenLogicalChannelResponse iccOpenLogicalChannel ( String AID ) { < |startfocus| > return iccOpenLogicalChannel ( getSubId ( ) , AID , ( byte ) 0x00 ) ; < |endfocus| > } /* * * Opens a logical channel to the ICC card . * * Input parameters equivalent to TS 27 . 007 AT + CCHO command . * * < p > Requires Permission : * { @link android . Manifest . permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE } * Or the calling app has carrier privileges . @see #hasCarrierPrivileges * * @param AID Application id . See ETSI 102 . 221 and 101 . 220 . * @param p2 P2 parameter ( described in ISO 7816 - 4 ) . Default value : 0x00 < |startfocus| >
private static LinkProperties getUniqueLocalConfig ( byte [ ] ulp , String ifname ) { LinkProperties lp = new LinkProperties ( ) ; lp . setInterfaceName ( ifname ) ; final IpPrefix local48 = getUniqueLocalPrefix ( ulp , ( short ) 0 , 48 ) ; lp . addRoute ( new RouteInfo ( local48 , null , null ) ) ; < |startfocus| > // Use 16 bits of the hashCode of the interface name as the Subnet ID . final IpPrefix local64 = getUniqueLocalPrefix ( ulp , ( short ) ifname . hashCode ( ) , 64 ) ; < |endfocus| > lp . addLinkAddress ( new LinkAddress ( local64 . getAddress ( ) , 64 ) ) ; return lp ;
private int mEvdoDbm ; // This value is the EVDO RSSI value private int mEvdoEcio ; // This value is the EVDO Ec / Io private int mEvdoSnr ; // Valid values are 0 - 8 . 8 is the highest signal to noise ratio private int mLteSignalStrength ; private int mLteRsrp ; private int mLteRsrq ; private int mLteRssnr ; private int mLteCqi ; < |startfocus| > private int mLteRsrpOffset ; // offset to be reduced from the rsrp threshold while calculating // signal strength level < |endfocus| > private int mTdScdmaRscp ; private boolean isGsm ; // This value is set by the ServiceStateTracker onSignalStrengthResult /* * * Create a new SignalStrength from a intent notifier Bundle * * This method is used by PhoneStateIntentReceiver and maybe by * external applications . * * @param m Bundle from intent notifier * @return newly created SignalStrength * * @hide */ public static SignalStrength newFromBundle ( Bundle m ) { SignalStrength ret ; ret = new SignalStrength ( ) ; ret . setFromNotifierBundle ( m ) ;
< |startfocus| > public void setLteRsrpOffset ( int lteRsrpOffset ) { mLteRsrpOffset = lteRsrpOffset ; < |endfocus| >
*/ int rssiIconLevel = SIGNAL_STRENGTH_NONE_OR_UNKNOWN , rsrpIconLevel = - 1 , snrIconLevel = - 1 ; int [ ] threshRsrp = Resources . getSystem ( ) . getIntArray ( com . android . internal . R . array . config_lteDbmThresholds ) ; if ( threshRsrp . length != 6 ) { Log . wtf ( LOG_TAG , "getLteLevel - config_lteDbmThresholds has invalid num of elements . " + " Cannot evaluate RSRP signal . " ) ; } else { if ( mLteRsrp > threshRsrp [ 5 ] ) { rsrpIconLevel = - 1 ; < |startfocus| > } else if ( mLteRsrp >= ( threshRsrp [ 4 ] - mLteOffset ) ) { < |endfocus| > rsrpIconLevel = SIGNAL_STRENGTH_GREAT ; } else if ( mLteRsrp >= ( threshRsrp [ 3 ] - mLteOffset ) ) { rsrpIconLevel = SIGNAL_STRENGTH_GOOD ; } else if ( mLteRsrp >= ( threshRsrp [ 2 ] - mLteOffset ) ) { rsrpIconLevel = SIGNAL_STRENGTH_MODERATE ; } else if ( mLteRsrp >= ( threshRsrp [ 1 ] - mLteOffset ) ) { rsrpIconLevel = SIGNAL_STRENGTH_POOR ; } else if ( mLteRsrp >= threshRsrp [ 0 ] ) { rsrpIconLevel = SIGNAL_STRENGTH_NONE_OR_UNKNOWN ; } }
"notify_international_call_on_wfc_bool" ; /* * * Offset to be reduced from rsrp threshold while calculating signal strength level . * @hide */ public static final String KEY_SIGNAL_STRENGTH_OFFSET_INT = "signal_strength_offset_int" ; /* * * List of EARFCN ranges on which signal_strength_offset_int will be applied . < |startfocus| > * Format of the String array is expected to be { "erafcn1_start - earfcn1_end" , * "earfcn2_start - earfcn2_end" . . . } < |endfocus| > * @hide */ public static final String KEY_SIGNAL_STRENGTH_EARFCNS_LIST_STRING_ARRAY = "signal_strength_earfcn_threshold_int" ; /* * The default value for every variable . */ private final static PersistableBundle sDefaults ; static { sDefaults = new PersistableBundle ( ) ; sDefaults . putBoolean ( KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL , true ) ; sDefaults . putBoolean ( KEY_ADDITIONAL_CALL_SETTING_BOOL , true ) ; sDefaults . putBoolean ( KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL , false ) ; sDefaults . putBoolean ( KEY_ALLOW_LOCAL_DTMF_TONES_BOOL , true ) ;
* @return error a { @code TETHER_ERROR } value indicating success or failure type * * { @hide } */ public int setUsbTethering ( boolean enable ) { try { return mService . setUsbTethering ( enable ) ; } catch ( RemoteException e ) { throw e . rethrowFromSystemServer ( ) ; } } /* * * Request that a local - only Wi - Fi hotspot be started . The supplied Wi - Fi < |startfocus| > * configuration will be used after switch to station mode ( STA ) , and must * be non - null . < |endfocus| > * * Local - only Wi - Fi hotspot functionality is currently mutually exclusive * with other tethering functionality . * * @param cfg The { @link android . net . wifi . WifiConfiguration } to use . * @return error a { @code TETHER_ERROR } value indicating success or failure * * @hide */ public int startLocalOnlyWifiHotspot ( WifiConfiguration cfg ) { try { return mService . startLocalOnlyWifiHotspot ( cfg ) ; } catch ( RemoteException e ) { throw e . rethrowFromSystemServer ( ) ; } } /* * * Request that a local - only Wi - Fi hotspot be started . The supplied Wi - Fi * configuration will be used after switch to station mode ( STA ) , and must * be non - null . * * Local - only Wi - Fi hotspot functionality is currently mutually exclusive * with other tethering functionality . * * @param cfg The { @link android . net . wifi . WifiConfiguration } to use . * @return error a { @code TETHER_ERROR } value indicating success or failure * * @hide */ public int startLocalOnlyWifiHotspot ( WifiConfiguration cfg ) { try { return mService . startLocalOnlyWifiHotspot ( cfg ) ; } catch ( RemoteException e ) { throw e . rethrowFromSystemServer ( ) ; } } /* *
public void verifyGetFirmwareRoamingInfoIsCalledWhenWifiEnabled ( ) { < |startfocus| > reset ( mWifiConnectivityHelper ) ; < |endfocus| > mWifiConnectivityManager . setWifiEnabled ( true ) ; verify ( mWifiConnectivityHelper ) . getFirmwareRoamingInfo ( ) ;
// SSID as the one to be selected . WifiConfiguration currentNetwork = generateWifiConfig ( 0 , CANDIDATE_NETWORK_ID , CANDIDATE_SSID , false , true , null , null ) ; when ( mWifiConfigManager . getConfiguredNetwork ( anyInt ( ) ) ) . thenReturn ( currentNetwork ) ; // Set WiFi to connected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_CONNECTED ) ; // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; < |startfocus| > verify ( mWifiStateMachine ) . startRoamToNetwork ( anyInt ( ) , anyObject ( ) ) ; < |endfocus| >
public void noFrameworkRoamingIfFirmwareControlRoaming ( ) { // Firmware controls roaming when ( mWifiConnectivityHelper . isFirmwareRoamingSupported ( ) ) . thenReturn ( true ) ; // Set WiFi to connected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_CONNECTED ) ; // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; < |startfocus| > verify ( mWifiStateMachine , times ( 0 ) ) . startRoamToNetwork ( anyInt ( ) , anyObject ( ) ) ; < |endfocus| >
* 6 . "San Francisco" location card opens . * 7 . Select "San Francisco" . * 8 . Tap on the Drive icon . * Verify : * 1 . Map points to San Francisco location . * 2 . Navigation overview is displayed . * </ pre > */ @Test @TestInfo ( id = "145493594" ) public void testMapsApp ( ) throws Exception { < |startfocus| > private static final String QUERY_STRING = "San Francisco" ; < |endfocus| > Instrumentation instrumentation = testFramework . getInstrumentation ( ) ; UiDevice mDevice = testFramework . getDevice ( ) ; AppLauncher . launch ( instrumentation , "Maps" ) ; UiObject acceptButton = mDevice . findObject ( new UiSelector ( ) . textContains ( "ACCEPT & CONTINUE" ) ) ; // "Accept & Continue" occurs only on first time Maps gets launched . if ( acceptButton . exists ( ) ) { acceptButton . clickAndWaitForNewWindow ( ) ; } // SKIP button only exist's occurs only on first time Maps gets launched . UiObject skipText = mDevice . findObject ( new UiSelector ( ) . textContains ( "SKIP" ) ) ; if ( skipText . exists ( ) ) {
scrollView . scrollIntoView ( new UiSelector ( ) . text ( QUERY_STRING ) ) ; selectedLocation = scrollView . getChildByText ( new UiSelector ( ) . className ( TextView . class . getName ( ) ) , QUERY_STRING ) ; Assert . assertTrue ( selectedLocation . exists ( ) ) ; selectedLocation . clickAndWaitForNewWindow ( ) ; // Verify the Query String is present after completing search . UiObject searchTextView = searchUiObject . getChild ( new UiSelector ( ) . className ( TextView . class . getName ( ) ) ) ; Assert . assertTrue ( searchTextView . getText ( ) . contains ( QUERY_STRING ) ) ; < |startfocus| > } else { < |endfocus| > searchEditText = mDevice . findObject ( new UiSelector ( ) . className ( EditText . class . getName ( ) ) ) ; searchEditText . setText ( QUERY_STRING ) ; UiScrollable listViewSelector = new UiScrollable ( new UiSelector ( ) . className ( ListView . class . getName ( ) ) ) ; selectedLocation = listViewSelector . getChildByText ( new UiSelector ( ) . className ( TextView . class . getName ( ) ) , QUERY_STRING ) ; selectedLocation . clickAndWaitForNewWindow ( ) ; // Verify the Query String is present after completing search . Assert . assertTrue ( searchEditText . getText ( ) . contains ( QUERY_STRING ) ) ; }
private static final String TAG = "CellBroadcastReceiver" ; static final boolean DBG = false ; // STOPSHIP : change to false before ship public static final String CELLBROADCAST_START_CONFIG_ACTION = "android . cellbroadcastreceiver . START_CONFIG" ; // Key to access the stored reminder interval default value private static final String CURRENT_INTERVAL_DEFAULT = "current_interval_default" ; public static final String ACTION_MARK_AS_READ = "com . google . android . clockwork . cmas . intent . action . MARK_AS_READ" ; public static final String EXTRA_DELIVERY_TIME = < |startfocus| > "com . google . android . clockwork . cmas . intent . extra . ID" ; < |endfocus| > @Override public void onReceive ( Context context , Intent intent ) { onReceiveWithPrivilege ( context , intent , false ) ; } protected void onReceiveWithPrivilege ( Context context , Intent intent , boolean privileged ) { if ( DBG ) log ( "onReceive " + intent ) ; String action = intent . getAction ( ) ; final long deliveryTime = intent . getLongExtra ( EXTRA_DELIVERY_TIME , - 1 ) ; if ( ACTION_MARK_AS_READ . equals ( action ) ) { new CellBroadcastContentProvider . AsyncCellBroadcastTask ( context . getContentResolver ( ) ) { @Override public void handleCellBroadcastTask ( ContentResolver contentResolver ) { if ( DBG ) log ( "marking message as read : " + deliveryTime ) ; CellBroadcastContentProvider . markMessagesRead ( contentResolver , deliveryTime ) ; } } . execute ( ) ; } }
protected void onReceiveWithPrivilege ( Context context , Intent intent , boolean privileged ) { if ( DBG ) log ( "onReceive " + intent ) ; String action = intent . getAction ( ) ; if ( ACTION_MARK_AS_READ . equals ( action ) ) { < |startfocus| > final long deliveryTime = intent . getLongExtra ( EXTRA_DELIVERY_TIME , - 1 ) ; < |endfocus| > new CellBroadcastContentProvider . AsyncCellBroadcastTask ( context . getContentResolver ( ) ) . execute ( new CellBroadcastContentProvider . CellBroadcastOperation ( ) { @Override public boolean execute ( CellBroadcastContentProvider provider ) { return provider . markBroadcastRead ( CellBroadcasts . DELIVERY_TIME , deliveryTime ) ; } } ) ; } else if ( TelephonyIntents . ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED . equals ( action ) || CarrierConfigManager . ACTION_CARRIER_CONFIG_CHANGED . equals ( action ) || CELLBROADCAST_START_CONFIG_ACTION . equals ( action ) ) { // Todo : Add the service state check once the new get service state API is done . // Do not rely on mServiceState as it gets reset to - 1 time to time because // the process of CellBroadcastReceiver gets killed every time once the job is done .
protected void onReceiveWithPrivilege ( Context context , Intent intent , boolean privileged ) { if ( DBG ) log ( "onReceive " + intent ) ; String action = intent . getAction ( ) ; final long deliveryTime = intent . getLongExtra ( EXTRA_DELIVERY_TIME , - 1 ) ; < |startfocus| > if ( ACTION_MARK_AS_READ . equals ( action ) ) { < |endfocus| > new CellBroadcastContentProvider . AsyncCellBroadcastTask ( context . getContentResolver ( ) ) . execute ( new CellBroadcastContentProvider . CellBroadcastOperation ( ) { @Override public boolean execute ( CellBroadcastContentProvider provider ) { return provider . markBroadcastRead ( CellBroadcasts . DELIVERY_TIME , deliveryTime ) ; } } ) ; } else if ( TelephonyIntents . ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED . equals ( action ) || CarrierConfigManager . ACTION_CARRIER_CONFIG_CHANGED . equals ( action ) || CELLBROADCAST_START_CONFIG_ACTION . equals ( action ) ) { // Todo : Add the service state check once the new get service state API is done . // Do not rely on mServiceState as it gets reset to - 1 time to time because // the process of CellBroadcastReceiver gets killed every time once the job is done .
/* * Intent action to display alert dialog / notification , after verifying the alert is new . */ static final String SHOW_NEW_ALERT_ACTION = "cellbroadcastreceiver . SHOW_NEW_ALERT" ; /* * Use the same notification ID for non - emergency alerts . */ static final int NOTIFICATION_ID = 1 ; /* * Sticky broadcast for latest area info broadcast received . */ static final String CB_AREA_INFO_RECEIVED_ACTION = "android . cellbroadcastreceiver . CB_AREA_INFO_RECEIVED" ; /* * * Intent extra for passing an SmsCbMessage */ private static final String EXTRA_MESSAGE = "message" ; /* * * Container for service category , serial number , location , body hash code , and ETWS primary / * secondary information for duplication detection . */ private static final class MessageServiceCategoryAndScope { private final int mServiceCategory ; private final int mSerialNumber ; private final SmsCbLocation mLocation ; private final int mBodyHash ; private final boolean mIsEtwsPrimary ; MessageServiceCategoryAndScope ( int serviceCategory , int serialNumber , SmsCbLocation location , int bodyHash , boolean isEtwsPrimary ) { mServiceCategory = serviceCategory ;
ArrayList < CellBroadcastMessage > messageList , Context context , boolean fromSaveState ) { int channelTitleId = CellBroadcastResources . getDialogTitleResource ( context , message ) ; CharSequence channelName = context . getText ( channelTitleId ) ; String messageBody = message . getMessageBody ( ) ; // Create intent to show the new messages when user selects the notification . Intent intent ; if ( context . getPackageManager ( ) . hasSystemFeature ( PackageManager . FEATURE_WATCH ) ) { < |startfocus| > // For Wear we want to mark as read intent = createWearDeleteIntent ( context , message . getDeliveryTime ( ) ) ; < |endfocus| > } else { // For phone we handle it differently intent = createDisplayMessageIntent ( context , CellBroadcastAlertDialog . class , messageList ) ; } intent . putExtra ( CellBroadcastAlertDialog . FROM_NOTIFICATION_EXTRA , true ) ; intent . putExtra ( CellBroadcastAlertDialog . FROM_SAVE_STATE_NOTIFICATION_EXTRA , fromSaveState ) ; PendingIntent pi ; if ( context . getPackageManager ( ) . hasSystemFeature ( PackageManager . FEATURE_WATCH ) ) { pi = PendingIntent . getBroadcast ( context , 0 , intent , 0 ) ; } else { pi = PendingIntent . getActivity ( context , NOTIFICATION_ID , intent ,
< |startfocus| > static Intent createMarkAsReadIntent ( Context context , long deliveryTime ) { < |endfocus| > Intent deleteIntent = new Intent ( context , CellBroadcastReceiver . class ) ; deleteIntent . setAction ( CellBroadcastReceiver . ACTION_MARK_AS_READ ) ; deleteIntent . putExtra ( CellBroadcastReceiver . EXTRA_DELIVERY_TIME , deliveryTime ) ; return deleteIntent ;
/* * * @hide */ public class NetdService { private static final String TAG = NetdService . class . getSimpleName ( ) ; private static final String NETD_SERVICE_NAME = "netd" ; private static final int BASE_TIMEOUT_MS = 100 ; private static final int MAX_TIMEOUT_MS = 1000 ; /* * * It is the caller's responsibility to check for a null return value * and to handle RemoteException errors from invocations on the returned * interface if , for example , netd dies and is restarted . < |startfocus| > * < |endfocus| > * @return an INetd instance or null . */ public static INetd getInstance ( ) { // NOTE : ServiceManager does no caching for the netd service , // because netd is not one of the defined common services . final INetd netdInstance = INetd . Stub . asInterface ( ServiceManager . getService ( NETD_SERVICE_NAME ) ) ; if ( netdInstance == null ) { Log . w ( TAG , "WARNING : returning null INetd instance . " ) ; } return netdInstance ; } /* * * Blocks until an INetd instance is available . * < |startfocus| > * < |endfocus| >
if ( netdInstance == null ) { Log . w ( TAG , "WARNING : returning null INetd instance . " ) ; } return netdInstance ; } /* * * Blocks until an INetd instance is available . * * It is the caller's responsibility to handle RemoteException errors * from invocations on the returned interface if , for example , netd * dies after this interface was returned . * * Returned instances of INetd should not be cached . * * @return an INetd instance or null . */ < |startfocus| > public static INetd get ( ) { for ( int i = 0 ; ; i ++ ) { < |endfocus| > final INetd netdInstance = getInstance ( ) ; if ( netdInstance != null ) { return netdInstance ; } // No netdInstance was received ; sleep and retry . final int timeoutMs = ( i < ( MAX_TIMEOUT_MS / BASE_TIMEOUT_MS ) ) ? ( i * BASE_TIMEOUT_MS ) : MAX_TIMEOUT_MS ; try { Thread . sleep ( timeoutMs ) ; } catch ( InterruptedException e ) { } } }
public static INetd get ( ) { for ( int i = 0 ; ; i ++ ) { final INetd netdInstance = getInstance ( ) ; if ( netdInstance != null ) { return netdInstance ; } // No netdInstance was received ; sleep and retry . final int timeoutMs = ( i < ( MAX_TIMEOUT_MS / BASE_TIMEOUT_MS ) ) ? ( i * BASE_TIMEOUT_MS ) : MAX_TIMEOUT_MS ; try { Thread . sleep ( timeoutMs ) ; < |startfocus| > } catch ( InterruptedException e ) { } < |endfocus| > }
< |startfocus| > void run ( INetd netd ) throws RemoteException ; < |endfocus| > } /* * * Blocks until an INetd instance is availabe , and retries until either * the command succeeds or a ServiceSpecificError is thrown . */
void run ( INetd netd ) throws RemoteException , ServiceSpecificException ; } /* * * Blocks until an INetd instance is availabe , and retries until either < |startfocus| > * the command succeeds or a ServiceSpecificError is thrown . < |endfocus| > */
public static void run ( NetdCommand cmd ) { while ( true ) { try { cmd . run ( get ( ) ) ; return ; < |startfocus| > } catch ( RemoteException re ) { } < |endfocus| > }
public static void run ( NetdCommand cmd ) { while ( true ) { try { cmd . run ( get ( ) ) ; return ; < |startfocus| > } catch ( RemoteException re ) { Log . e ( TAG , "Error running remote command" , re ) ; } < |endfocus| > }
ResultUnit . BYTE ) ; Stat . StatResult stat = Stat . getStat ( mbps ) ; getReportLog ( ) . printSummary ( "write throughput" , stat . mAverage , ResultType . HIGHER_BETTER , ResultUnit . MBPS ) ; } @TimeoutReq ( minutes = 80 ) public void testSingleSequentialUpdate ( ) throws Exception { final long fileSize = FileUtil . getFileSizeExceedingMemory ( getContext ( ) , BUFFER_SIZE ) ; if ( fileSize == 0 ) { // not enough space , give up return ; } < |startfocus| > final int NUMBER_REPETITION = 3 ; < |endfocus| > FileUtil . doSequentialUpdateTest ( getContext ( ) , DIR_SEQ_UPDATE , getReportLog ( ) , fileSize , BUFFER_SIZE , NUMBER_REPETITION ) ; } @TimeoutReq ( minutes = 30 ) public void testSingleSequentialRead ( ) throws Exception { final long fileSize = FileUtil . getFileSizeExceedingMemory ( getContext ( ) , BUFFER_SIZE ) ; if ( fileSize == 0 ) { // not enough space , give up return ; } long start = System . currentTimeMillis ( ) ; final File file = FileUtil . createNewFilledFile ( getContext ( ) , DIR_SEQ_RD , fileSize ) ; long finish = System . currentTimeMillis ( ) ;
private void updateSavedNetworkSelectionStatus ( ) { List < WifiConfiguration > savedNetworks = mWifiConfigManager . getSavedNetworks ( ) ; if ( savedNetworks . size ( ) == 0 ) { localLog ( "No saved networks . " ) ; return ; } StringBuffer sbuf = new StringBuffer ( "Saved Networks List : \n" ) ; for ( WifiConfiguration network : savedNetworks ) { /* * < |startfocus| > * Ignore Passpoint networks . Passpoint networks are also considered as "saved" * network , but without being persisted to the storage . They are managed < |endfocus| > * by { @link PasspointNetworkEvaluator } . */ if ( network . isPasspoint ( ) ) { continue ; } WifiConfiguration . NetworkSelectionStatus status = network . getNetworkSelectionStatus ( ) ; // If a configuration is temporarily disabled , re - enable it before trying // to connect to it . mWifiConfigManager . tryEnableNetwork ( network . networkId ) ; // TODO ( b / 30928589 ) : Enable "permanently" disabled networks if we are in DISCONNECTED // state . // Clear the cached candidate , score and seen . mWifiConfigManager . clearNetworkCandidateScanResult ( network . networkId ) ;
List < WifiConfiguration > associatedConfigurations = null ; WifiConfiguration associatedConfiguration = mWifiConfigManager . getSavedNetworkForScanDetailAndCache ( scanDetail ) ; if ( associatedConfiguration == null ) { continue ; } else { associatedConfigurations = new ArrayList < > ( Arrays . asList ( associatedConfiguration ) ) ; } for ( WifiConfiguration network : associatedConfigurations ) { /* * < |startfocus| > * Ignore Passpoint networks . Passpoint networks are also considered as "saved" * network , but without being persisted to the storage . They are being evaluated < |endfocus| > * by { @link PasspointNetworkEvaluator } . */ if ( network . isPasspoint ( ) ) { continue ; } WifiConfiguration . NetworkSelectionStatus status = network . getNetworkSelectionStatus ( ) ; status . setSeenInLastQualifiedNetworkSelection ( true ) ; if ( ! status . isNetworkEnabled ( ) ) { continue ; } else if ( network . BSSID != null && ! network . BSSID . equals ( "any" ) && ! network . BSSID . equals ( scanResult . BSSID ) ) { // App has specified the only BSSID to connect for this // configuration . So only the matching ScanResult can be a candidate .
"am stack move - top - activity - to - pinned - stack 1 0 0 500 500" ; protected static final String LAUNCHING_ACTIVITY = "LaunchingActivity" ; private static final String AM_RESIZE_DOCKED_STACK = "am stack resize - docked - stack " ; private static final String AM_MOVE_TASK = "am stack movetask " ; private static final String AM_SUPPORTS_SPLIT_SCREEN_MULTIWINDOW = "am supports - split - screen - multiwindow" ; < |startfocus| > private static final String AM_NO_HOME_SCREEN = "am no - home - screen" ; < |endfocus| > private static final String INPUT_KEYEVENT_HOME = "input keyevent 3" ; /* * A reference to the device under test . */ protected ITestDevice mDevice ; private HashSet < String > mAvailableFeatures ; protected static String getAmStartCmd ( final String activityName ) { return "am start - n " + getActivityComponentName ( activityName ) ; } protected static String getAmStartCmdOverHome ( final String activityName ) { return "am start -- activity - task - on - home - n " + getActivityComponentName ( activityName ) ; } static String getActivityComponentName ( final String activityName ) {
public int startLocalOnlyWifiHotspot ( WifiConfiguration cfg ) { < |startfocus| > if ( mMode == Mode . LOCAL_HOTSPOT || mMode == Mode . TETHERING ) { < |endfocus| > if ( VDBG ) { Log . e ( TAG , "Attempt to startLocalOnlyWifiHotspot absent corresponding stop . " ) ; } return ConnectivityManager . TETHER_ERROR_SERVICE_UNAVAIL ; } mMode = Mode . LOCAL_HOTSPOT ; return setWifiTethering ( cfg , true ) ;
public int startLocalOnlyWifiHotspot ( WifiConfiguration cfg ) { if ( mMode == Mode . LOCAL_HOTSPOT ) { if ( VDBG ) { < |startfocus| > Log . e ( TAG , "Local hotspot already started" ) ; < |endfocus| > } return ConnectivityManager . TETHER_ERROR_SERVICE_UNAVAIL ; } mMode = Mode . LOCAL_HOTSPOT ; return setWifiTethering ( cfg , true ) ;
public void stopLocalOnlyWifiHotspot ( ) { if ( mMode != Mode . LOCAL_HOTSPOT ) { if ( VDBG ) { < |startfocus| > Log . e ( TAG , "Local hotspot not running ? " ) ; < |endfocus| > } return ; } setWifiTethering ( null , false ) ;
protected boolean turnOffMasterTetherSettings ( ) { if ( ! stopIpServices ( ) ) { transitionTo ( mStopTetheringErrorState ) ; return false ; } if ( mMode == Mode . TETHERING ) { try { mNMService . setIpForwardingEnabled ( false ) ; } catch ( Exception e ) { transitionTo ( mSetIpForwardingDisabledErrorState ) ; return false ; } } else { // Reset to tethering mode ( default mode ) . mMode = Mode . TETHERING ; } < |startfocus| > transitionTo ( mInitialState ) ; return true ; < |endfocus| >
import java . util . Random ; /* * * IPv6 tethering is rather different from IPv4 owing to the absence of NAT . * This coordinator is responsible for evaluating the dedicated prefixes * assigned to the device and deciding how to divvy them up among downstream * interfaces . * * @hide */ public class IPv6TetheringCoordinator { private static final String TAG = IPv6TetheringCoordinator . class . getSimpleName ( ) ; private static final boolean DBG = false ; private static final boolean VDBG = false ; < |startfocus| > private static class Downstream { < |endfocus| > public final TetherInterfaceStateMachine tism ; public final short subnetId ; Downstream ( TetherInterfaceStateMachine tism , short subnetId ) { this . tism = tism ; this . subnetId = subnetId ; } } private final ArrayList < TetherInterfaceStateMachine > mNotifyList ; private final LinkedList < Downstream > mActiveDownstreams ; private short mNextSubnetId ; private byte [ ] mUniqueLocalPrefix ; private NetworkState mUpstreamNetworkState ; public IPv6TetheringCoordinator ( ArrayList < TetherInterfaceStateMachine > notifyList ) { mNotifyList = notifyList ; mActiveDownstreams = new LinkedList < > ( ) ;
*/ public class IPv6TetheringCoordinator { private static final String TAG = IPv6TetheringCoordinator . class . getSimpleName ( ) ; private static final boolean DBG = false ; private static final boolean VDBG = false ; private static class DownstreamState { public final TetherInterfaceStateMachine tism ; public final short subnetId ; DownstreamState ( TetherInterfaceStateMachine tism , short subnetId ) { this . tism = tism ; this . subnetId = subnetId ; } } private final ArrayList < TetherInterfaceStateMachine > mNotifyList ; < |startfocus| > private final SparseArray < TetherInterfaceStateMachine > mActiveDownstreams ; < |endfocus| > private short mNextSubnetId ; private byte [ ] mUniqueLocalPrefix ; private NetworkState mUpstreamNetworkState ; public IPv6TetheringCoordinator ( ArrayList < TetherInterfaceStateMachine > notifyList ) { mNotifyList = notifyList ; mActiveDownstreams = new SparseArray < > ( ) ; mNextSubnetId = 0 ; } public void addActiveDownstream ( TetherInterfaceStateMachine downstream ) { if ( findDownstream ( downstream ) == null ) { // Adding a new downstream appends it to the list . Adding a // downstream a second time without first removing it has no effect .
public void addActiveDownstream ( TetherInterfaceStateMachine downstream ) { if ( findDownstream ( downstream ) == null ) { // Adding a new downstream appends it to the list . Adding a // downstream a second time without first removing it has no effect . < |startfocus| > mActiveDownstreams . offer ( new DownstreamState ( downstream , mNextSubnetId ++ ) ) ; < |endfocus| > updateIPv6TetheringInterfaces ( ) ; }
private static byte [ ] generateUniqueLocalPrefix ( ) { final byte [ ] ulp = new byte [ 6 ] ; // 6 = 48bits / 8bits / byte ( new Random ( ) ) . nextBytes ( ulp ) ; < |startfocus| > final byte [ ] in6addr = Arrays . copyOf ( ulp , NetworkConstants . IPV6_ADDR_LEN ) ; < |endfocus| > in6addr [ 0 ] = ( byte ) 0xfd ; // fc00 : :/ 7 and L = 1 return in6addr ;
ActivityReceiverFilter appEndReceiver = new ActivityReceiverFilter ( ACTIVITY_EXIT_ACTION ) ; // The filter for the time event . ActivityReceiverFilter timeReceiver = new ActivityReceiverFilter ( ACTIVITY_TIME_TRACK_INFO ) ; // Run the activity . mContext . startActivity ( intent , options . toBundle ( ) ) ; // Wait until it finishes and end the reciever then . assertEquals ( RESULT_PASS , appEndReceiver . waitForActivity ( ) ) ; appEndReceiver . close ( ) ; if ( ! noHomeScreen ( ) ) { < |startfocus| > // At this time the timerReceiver should not fire , even though the activity has shut < |endfocus| > // down , because we are back to the home screen . assertEquals ( RESULT_TIMEOUT , timeReceiver . waitForActivity ( ) ) ; assertTrue ( timeReceiver . mTimeUsed == 0 ) ; } else { assertEquals ( RESULT_PASS , timeReceiver . waitForActivity ( ) ) ; } // Issuing now another activity will trigger the timing information release . final Intent dummyIntent = new Intent ( context , MockApplicationActivity . class ) ; dummyIntent . addFlags ( Intent . FLAG_ACTIVITY_NEW_TASK ) ; final Activity activity = mInstrumentation . startActivitySync ( dummyIntent ) ; // Wait until it finishes and end the reciever then .
private CdmaSubscriptionSourceManager mCdmaSSM ; public static final String INVALID_MCC = "000" ; public static final String DEFAULT_MNC = "00" ; private HbpcdUtils mHbpcdUtils = null ; /* Used only for debugging purposes . */ private String mRegistrationDeniedReason ; private String mCurrentCarrier = null ; /* list of LTE EARFCNs ( E - UTRA Absolute Radio Frequency Channel Number , * Reference : 3GPP TS 36 . 104 5 . 4 . 3 ) < |startfocus| > * pairs for which the lte rsrp boost is applied */ < |endfocus| > private ArrayList < Pair < Integer , Integer > > mEarfcnPairListForRsrpBoost = null ; private int mLteRsrpBoost = 0 ; // offset which is reduced from the rsrp threshold // while calculating signal strength level . private final Object mLteRsrpBoostLock = new Object ( ) ; // mLteRsrpBoost lock public ServiceStateTracker ( GsmCdmaPhone phone , CommandsInterface ci ) { mPhone = phone ; mCi = ci ; mRatRatcheter = new RatRatcheter ( mPhone ) ; mVoiceCapable = mPhone . getContext ( ) . getResources ( ) . getBoolean ( com . android . internal . R . bool . config_voice_capable ) ; private int mMaxDataCalls = 1 ; private int mNewMaxDataCalls = 1 ; private int mReasonDataDenied = - 1 ; private int mNewReasonDataDenied = - 1 ; private ArrayList < DataConnection > mDataConnections = new ArrayList < DataConnection > ( ) ; private RegistrantList mVoiceRoamingOnRegistrants = new RegistrantList ( ) ; private RegistrantList mVoiceRoamingOffRegistrants = new RegistrantList ( ) ; private RegistrantList mDataRoamingOnRegistrants = new RegistrantList ( ) ; private RegistrantList mDataRoamingOffRegistrants = new RegistrantList ( ) ; private RegistrantList mAttachedRegistrants = new RegistrantList ( ) ; private RegistrantList mDetachedRegistrants = new RegistrantList ( ) ; private RegistrantList mDataRegStateOrRatChangedRegistrants = new RegistrantList ( ) ; private RegistrantList mNetworkAttachedRegistrants = new RegistrantList ( ) ; private RegistrantList mPsRestrictEnabledRegistrants = new RegistrantList ( ) ; private RegistrantList mPsRestrictDisabledRegistrants = new RegistrantList ( ) ; private boolean mImsRegistered = false ; private boolean mImsRegistrationOnOff = false ; private boolean mAlarmSwitch = false ; private boolean mRadioDisabledByCarrier = false ; private PendingIntent mRadioOffIntent = null ; private static final String ACTION_RADIO_OFF = "android . intent . action . ACTION_RADIO_OFF" ; private boolean mPowerOffDelayNeed = true ; private boolean mDeviceShuttingDown = false ; private int mRilVersion = - 1 ; private RegistrantList mCdmaForSubscriptionInfoReadyRegistrants = new RegistrantList ( ) ; private CdmaSubscriptionSourceManager mCdmaSSM = null ; private int mCdmaSubscriptionAppIndex = - 1 ; private int mRadioTechnology = 0 ; private int mNewRadioTechnology = 0 ; private boolean mCspPlmnEnabled = true ; private boolean mEriTracking = false ; private boolean mRestrictedState = false ; private int mPendingRadioPowerOffAfterDataOff = 0 ; private boolean mRilConnected = false ; private int mImsRegistrationOnOffForSubId = 0 ; private int mVoiceRegState = ServiceState . STATE_OUT_OF_SERVICE ; private UiccCardApplication mUiccApplcation = null ; private UiccCard mUiccCard = null ; private boolean mIsSubscriptionFromRuim = false ; private int mRilVoiceRadioTechnology = 0 ; private int mNewRilVoiceRadioTechnology = 0 ; private int mRilDataRadioTechnology = 0 ; private int mNewRilDataRadioTechnology = 0 ; private RegistrantList mImsNetworkStateChangedRegistrants = new RegistrantList ( ) ; private RegistrantList mVoiceRadioTechChangedRegistrants = new RegistrantList ( ) ; private RegistrantList mDataRadioTechChangedRegistrants = new RegistrantList ( ) ; private RegistrantList mVoiceRegStateOrRatChangedRegistrants = new RegistrantList ( ) ; private RegistrantList mIccRefreshRegistrants = new RegistrantList ( ) ; private RegistrantList mRilCellInfoListRegistrants = new RegistrantList ( ) ; private RegistrantList mSubscriptionStatusRegistrants = new RegistrantList ( ) ; private RegistrantList mPsNetworkTypeChangedRegistrants = new RegistrantList ( ) ; private RegistrantList mEmergencyCallbackModeRegistrants = new RegistrantList ( ) ; private RegistrantList mPhoneRadioCapabilityChangedRegistrants = new RegistrantList ( ) ; private RegistrantList mCellInfoRegistrants = new RegistrantList ( ) ; private RegistrantList mPhysicalChannelConfigRegistrants = new RegistrantList ( ) ; private RegistrantList mNrStateRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyChangedRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyAvailabilityRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyRangeChangedRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyBandwidthChangedRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoAvailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegistrants = new RegistrantList ( ) ; private RegistrantList mNrFrequencyInfoUnavailableRegist
/* list of LTE EARFCNs ( E - UTRA Absolute Radio Frequency Channel Number , * Reference : 3GPP TS 36 . 104 5 . 4 . 3 ) * pairs for which the lte rsrp boost is applied */ private ArrayList < Pair < Integer , Integer > > mEarfcnPairListForRsrpBoost = null ; private int mLteRsrpBoost = 0 ; // offset which is reduced from the rsrp threshold // while calculating signal strength level . < |startfocus| > private final Object mLteRsrpBoostLock = new Object ( ) ; // mLteRsrpBoost lock < |endfocus| > public ServiceStateTracker ( GsmCdmaPhone phone , CommandsInterface ci ) { mPhone = phone ; mCi = ci ; mRatRatcheter = new RatRatcheter ( mPhone ) ; mVoiceCapable = mPhone . getContext ( ) . getResources ( ) . getBoolean ( com . android . internal . R . bool . config_voice_capable ) ; mUiccController = UiccController . getInstance ( ) ; mUiccController . registerForIccChanged ( this , EVENT_ICC_CHANGED , null ) ; mCi . setOnSignalStrengthUpdate ( this , EVENT_SIGNAL_STRENGTH_UPDATE , null ) ; mCi . registerForCellInfoList ( this , EVENT_UNSOL_CELL_INFO_LIST , null ) ; mSubscriptionController = SubscriptionController . getInstance ( ) ;
&& ServiceState . isCdma ( newDataRat ) ) ) { mCi . getSignalStrength ( obtainMessage ( EVENT_GET_SIGNAL_STRENGTH ) ) ; } // voice roaming state in done while handling EVENT_POLL_STATE_REGISTRATION_CDMA mNewSS . setDataRoaming ( regCodeIsRoaming ( regState ) ) ; if ( DBG ) { log ( "handlPollStateResultMessage : CdmaLteSST setDataRegState = " + dataRegState + " regState = " + regState + " dataRadioTechnology = " + newDataRat ) ; } } < |startfocus| > updateLteEarfcnBoost ( mNewSS , getLteEarfcn ( dataRegStateResult ) ) ; < |endfocus| > break ; } case EVENT_POLL_STATE_OPERATOR : { if ( mPhone . isPhoneTypeGsm ( ) ) { String opNames [ ] = ( String [ ] ) ar . result ; if ( opNames != null && opNames . length >= 3 ) { // FIXME : Giving brandOverride higher precedence , is this desired ? String brandOverride = mUiccController . getUiccCard ( getPhoneId ( ) ) != null ? mUiccController . getUiccCard ( getPhoneId ( ) ) . getOperatorBrandOverride ( ) : null ; if ( brandOverride != null ) {
private void updateLteEarfcnBoost ( int lteEarfcn ) { synchronized ( mLteRsrpBoostLock ) { if ( ( lteEarfcn != INVALID_LTE_EARFCN ) && containsEarfcnInEarfcnRange ( mEarfcnPairListForRsrpBoost , lteEarfcn ) ) { < |startfocus| > mNewSS . setLteEarfcnRsrpBoost ( mLteRsrpBoost ) ; < |endfocus| > } else { mNewSS . setLteEarfcnRsrpBoost ( 0 ) ; } }
&& mRingingCall . getState ( ) == ImsPhoneCall . State . IDLE ) { mForegroundCall . detach ( mPendingMO ) ; removeConnection ( mPendingMO ) ; mPendingMO . finalize ( ) ; mPendingMO = null ; mPhone . initiateSilentRedial ( ) ; return ; } else { mPendingMO = null ; int cause = getDisconnectCauseFromReasonInfo ( reasonInfo ) ; ImsPhoneConnection conn = findConnection ( imsCall ) ; if ( conn != null ) { < |startfocus| > conn . setPreciseDisconnectCause ( getPreciseDisconnectCauseFromReasonInfo ( reasonInfo ) ) ; < |endfocus| > } processCallStateChange ( imsCall , ImsPhoneCall . State . DISCONNECTED , cause ) ; } mMetrics . writeOnImsCallStartFailed ( mPhone . getPhoneId ( ) , imsCall . getCallSession ( ) , reasonInfo ) ; }
* onFeatureCapabilityChanged ( int , int [ ] , int [ ] ) } callbacks , or values received via the * { @link ImsCallProfile#EXTRA_CALL_RAT_TYPE } extra . Util we receive a value via the extras , * we will use the wifi state based on the { @code onFeatureCapabilityChanged } . Once a value * is received via the extras , we will prefer those values going forward . */ private boolean mIsWifiStateFromExtras = false ; < |startfocus| > private int mPreciseDisconnectCause = 0 ; < |endfocus| > // ** ** * Event Constants private static final int EVENT_DTMF_DONE = 1 ; private static final int EVENT_PAUSE_DONE = 2 ; private static final int EVENT_NEXT_POST_DIAL = 3 ; private static final int EVENT_WAKE_LOCK_TIMEOUT = 4 ; private static final int EVENT_DTMF_DELAY_DONE = 5 ; // ** ** * Constants private static final int PAUSE_DELAY_MILLIS = 3 * 1000 ; private static final int WAKE_LOCK_TIMEOUT_MILLIS = 60 * 1000 ; // ** ** * Inner Classes class MyHandler extends Handler {
/* * Not a preempted call */ public static final int CDMA_PREEMPTED = 1007 ; /* * Not an emergency call */ public static final int CDMA_NOT_EMERGENCY = 1008 ; /* * Access Blocked by CDMA network */ public static final int CDMA_ACCESS_BLOCKED = 1009 ; /* * Mapped from ImsReasonInfo */ /* The passed argument is an invalid */ public static final int ILLEGAL_ARGUMENT = 1200 ; // The operation is invoked in invalid call state < |startfocus| > public static final int ILLEGAL_STATE = 1201 ; < |endfocus| > // IMS service internal error public static final int INTERNAL_ERROR = 1202 ; // IMS service goes down ( service connection is lost ) public static final int IMS_SERVICE_DOWN = 1203 ; // No pending incoming call exists public static final int NO_PENDING_CALL = 1204 ; // Service unavailable ; by power off public static final int POWER_OFF = 1205 ; // Service unavailable ; by low battery public static final int LOW_BATTERY = 1206 ; // Service unavailable ; by out of service public static final int OUT_OF_SERVICE = 1207 ;
public static final int CDMA_PREEMPTED = 1007 ; /* * Not an emergency call */ public static final int CDMA_NOT_EMERGENCY = 1008 ; /* * Access Blocked by CDMA network */ public static final int CDMA_ACCESS_BLOCKED = 1009 ; /* * Mapped from ImsReasonInfo */ /* The passed argument is an invalid */ public static final int ILLEGAL_ARGUMENT = 1200 ; // The operation is invoked in invalid call state public static final int ILLEGAL_STATE = 1201 ; // IMS service internal error < |startfocus| > public static final int INTERNAL_ERROR = 1202 ; < |endfocus| > // IMS service goes down ( service connection is lost ) public static final int IMS_SERVICE_DOWN = 1203 ; // No pending incoming call exists public static final int NO_PENDING_CALL = 1204 ; // Service unavailable ; by power off public static final int POWER_OFF = 1205 ; // Service unavailable ; by low battery public static final int LOW_BATTERY = 1206 ; // Service unavailable ; by out of service ( data service state ) public static final int OUT_OF_SERVICE = 1207 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int NO_REGISTERED_NUMBER = 1208 ; // Service unavailable ; by no registered network public static final int
/* * Access Blocked by CDMA network */ public static final int CDMA_ACCESS_BLOCKED = 1009 ; /* * Mapped from ImsReasonInfo */ /* The passed argument is an invalid */ public static final int ILLEGAL_ARGUMENT = 1200 ; // The operation is invoked in invalid call state public static final int ILLEGAL_STATE = 1201 ; // IMS service internal error public static final int INTERNAL_ERROR = 1202 ; // IMS service goes down ( service connection is lost ) < |startfocus| > public static final int IMS_SERVICE_DOWN = 1203 ; < |endfocus| > // No pending incoming call exists public static final int NO_PENDING_CALL = 1204 ; // Service unavailable ; by power off public static final int POWER_OFF = 1205 ; // Service unavailable ; by low battery public static final int LOW_BATTERY = 1206 ; // Service unavailable ; by out of service ( data service state ) public static final int NETWORK_NO_SERVICE = 1207 ; /* Service unavailable ; by no LTE coverage * ( VoLTE is not supported even though IMS is registered ) */ public static final int NO_LTE_COVERAGE = 1208 ;
public static final int ILLEGAL_ARGUMENT = 1200 ; // The operation is invoked in invalid call state public static final int ILLEGAL_STATE = 1201 ; // IMS service internal error public static final int INTERNAL_ERROR = 1202 ; // IMS service goes down ( service connection is lost ) public static final int IMS_SERVICE_DOWN = 1203 ; // No pending incoming call exists public static final int NO_PENDING_CALL = 1204 ; // Service unavailable ; by power off < |startfocus| > public static final int LOCAL_POWER_OFF = 1205 ; < |endfocus| > // Service unavailable ; by low battery public static final int LOCAL_LOW_BATTERY = 1206 ; // Service unavailable ; by out of service ( data service state ) public static final int LOCAL_NETWORK_NO_SERVICE = 1207 ; /* Service unavailable ; by no LTE coverage * ( VoLTE is not supported even though IMS is registered ) */ public static final int LOCAL_NETWORK_NO_LTE_COVERAGE = 1208 ; /* * Service unavailable ; by located in roaming area */ public static final int LOCAL_NETWORK_ROAMING = 1209 ;
/* * Service unavailable ; by located in roaming area */ public static final int NETWORK_ROAMING = 1209 ; /* * Service unavailable ; by IP changed */ public static final int NETWORK_IP_CHANGED = 1210 ; /* * Service unavailable ; other */ public static final int SERVICE_UNAVAILABLE = 1211 ; /* Service unavailable ; IMS connection is lost ( IMS is not registered ) */ public static final int NOT_REGISTERED = 1212 ; /* * Max call exceeded */ < |startfocus| > public static final int MAX_LOCAL_CALLS_EXCEEDED = 1213 ; < |endfocus| > /* * Call decline */ public static final int LOCAL_CALL_DECLINE = 1214 ; /* * SRVCC is in progress */ public static final int VCC_ON_PROGRESSING = 1215 ; /* * Resource reservation is failed ( QoS precondition ) */ public static final int RESOURCE_RESERVATION_FAILED = 1216 ; /* * Retry CS call ; VoLTE service can't be provided by the network or remote end * Resolve the extra code ( EXTRA_CODE_CALL_RETRY_ * ) if the below code is set */
public static INetd get ( int maxTimeoutMs ) { int timeoutMs = BASE_TIMEOUT_MS ; while ( true ) { final INetd netdInstance = getInstance ( ) ; if ( netdInstance != null ) { return netdInstance ; } if ( maxTimeoutMs == 0 ) break ; // No netdInstance was received ; sleep and retry . < |startfocus| > if ( maxTimeoutMs > 0 ) timeoutMs = Math . min ( timeoutMs , maxTimeoutMs ) ; < |endfocus| > try { Thread . sleep ( timeoutMs ) ; } catch ( InterruptedException e ) { // If this occurs we can lose track of some time slept . } if ( maxTimeoutMs > 0 ) maxTimeoutMs -= timeoutMs ; timeoutMs = Math . min ( timeoutMs + BASE_TIMEOUT_MS , MAX_TIMEOUT_MS ) ; } return null ;
public static INetd get ( int maxTimeoutMs ) { int timeoutMs = BASE_TIMEOUT_MS ; while ( true ) { final INetd netdInstance = getInstance ( ) ; if ( netdInstance != null ) { return netdInstance ; } if ( maxTimeoutMs == 0 ) break ; // No netdInstance was received ; sleep and retry . timeoutMs = Math . min ( timeoutMs + BASE_TIMEOUT_MS , MAX_TIMEOUT_MS ) ; < |startfocus| > if ( maxTimeoutMs > 0 ) timeoutMs = Math . min ( timeoutMs , maxTimeoutMs ) ; < |endfocus| > try { Thread . sleep ( timeoutMs ) ; } catch ( InterruptedException e ) { // If this occurs we can lose track of some time slept . } if ( maxTimeoutMs > 0 ) maxTimeoutMs -= timeoutMs ; } return null ; }
public static INetd get ( int maxTimeoutMs ) { int timeoutMs = BASE_TIMEOUT_MS ; < |startfocus| > while ( true ) { < |endfocus| > final INetd netdInstance = getInstance ( ) ; if ( netdInstance != null ) { return netdInstance ; } if ( maxTimeoutMs == 0 ) break ; // No netdInstance was received ; sleep and retry . timeoutMs = Math . min ( timeoutMs + BASE_TIMEOUT_MS , MAX_TIMEOUT_MS ) ; if ( maxTimeoutMs > 0 ) timeoutMs = Math . min ( timeoutMs , maxTimeoutMs ) ; try { Thread . sleep ( timeoutMs ) ; } catch ( InterruptedException e ) { // If this occurs we can lose track of some time slept . } if ( maxTimeoutMs > 0 ) maxTimeoutMs -= timeoutMs ; } return null ;
public static void run ( NetdCommand cmd ) { while ( true ) { try { cmd . run ( get ( ) ) ; return ; } catch ( RemoteException re ) { < |startfocus| > Log . e ( TAG , "error communicating with netd : " + re ) ; < |endfocus| > } }
private AuthenticatorHelper mAuthenticatorHelper ; private BluetoothAdapter mBtAdapter ; private ConnectivityListener mConnectivityListener ; private boolean mInputSettingNeeded ; private Preference mDeveloperPref ; private PreferenceGroup mAccessoriesGroup ; private PreferenceGroup mAccountsGroup ; private Preference mAddAccessory ; private Preference mNetworkPref ; private Preference mSoundsPref ; private final BroadcastReceiver mBCMReceiver = new BroadcastReceiver ( ) { @Override public void onReceive ( Context context , Intent intent ) { updateAccessories ( ) ; } } ; < |startfocus| > private final BroadcastReceiver mBtConnectionReceiver = new BluetoothConnectionsManager ( ) ; < |endfocus| > public static MainFragment newInstance ( ) { return new MainFragment ( ) ; } @Override public void onCreate ( Bundle savedInstanceState ) { mAuthenticatorHelper = new AuthenticatorHelper ( getContext ( ) , new UserHandle ( UserHandle . myUserId ( ) ) , new AuthenticatorHelper . OnAccountsUpdateListener ( ) { @Override public void onAccountsUpdate ( UserHandle userHandle ) { updateAccounts ( ) ; } } ) ; mBtAdapter = BluetoothAdapter . getDefaultAdapter ( ) ; mConnectivityListener = new ConnectivityListener ( getContext ( ) , new ConnectivityListener . Listener ( ) { @Override public void onConnectionTypeChanged ( int connectionType ) { updateNetwork ( ) ; } } ) ; mInputSettingNeeded = getResources ( ) . getBoolean ( R . bool . has_input_settings ) ; } @Override public void onResume ( ) { super . onResume ( ) ; mAuthenticatorHelper . listenToAccountUpdates ( ) ; mConnectivityListener . start ( ) ; if ( mBtAdapter != null ) { mBtAdapter . getProfileProxy ( getContext ( ) , new BluetoothProfile . ServiceListener ( ) { @Override public void onServiceConnected ( int profile , BluetoothProfile proxy ) { if ( profile == BluetoothProfile . HEADSET ) { mBtAdapter . closeProfileProxy ( profile , proxy ) ; } } @Override public void onServiceDisconnected ( int profile ) { } } , BluetoothProfile . HEADSET ) ; } } @Override public void onPause ( ) { super . onPause ( ) ; mAuthenticatorHelper . stopListeningToAccountUpdates ( ) ; mConnectivityListener . stop ( ) ; } @Override public void onDestroy ( ) { super . onDestroy ( ) ; } @Override public void onCreatePreferences ( Bundle savedInstanceState , String rootKey ) { setPreferencesFromResource ( R . xml . main_settings , null ) ; mAccessoriesGroup = ( PreferenceGroup ) findPreference ( KEY_ACCESSORIES ) ; mAccountsGroup = ( PreferenceGroup ) findPreference ( KEY_ACCOUNTS ) ; mAddAccessory = findPreference ( KEY_ADD_ACCESSORY ) ; mNetworkPref = findPreference ( KEY_NETWORK ) ; mSoundsPref = findPreference ( KEY_SOUNDS ) ; mDeveloperPref = findPreference ( KEY_DEVELOPER ) ; if ( mDeveloperPref != null ) { mDeveloperPref . setOnPreferenceClickListener ( new Preference . OnPreferenceClickListener ( ) { @Override public boolean onPreferenceClick ( Preference preference ) { startActivity ( new Intent ( getContext ( ) , DeveloperSettingsActivity . class ) ) ; return true ; } } ) ; } } @Override public void onActivityCreated ( Bundle savedInstanceState ) { super . onActivityCreated ( savedInstanceState ) ; final SettingsActivity activity = ( SettingsActivity ) getActivity ( ) ; final ActionBar actionBar = activity . getSupportActionBar ( ) ; actionBar . setDisplayHomeAsUpEnabled ( false ) ; actionBar . setHomeButtonEnabled ( false ) ; } @Override public void onStart ( ) { super . onStart ( ) ; updateAccessories ( ) ; updateAccounts ( ) ; updateNetwork ( ) ; } @Override public void onStop ( ) { super . onStop ( ) ; } private void updateAccessories ( ) { if ( mAccessoriesGroup == null ) { return ; } mAccessoriesGroup . removeAll ( ) ; if ( mBtAdapter != null ) { final Set < BluetoothDevice > pairedDevices = mBtAdapter . getBondedDevices ( ) ; if ( pairedDevices != null ) { for ( BluetoothDevice device : pairedDevices ) { if ( device . getBluetoothClass ( ) . getDeviceClass ( ) == BluetoothClass . Device . AUDIO_VIDEO_WEARABLE_HEADSET || device . getBluetoothClass ( ) . getDeviceClass ( ) == BluetoothClass . Device . AUDIO_VIDEO_HANDSFREE ) { final Preference pref = new Preference ( getPrefContext ( ) ) ; pref . setTitle ( device . getName ( ) ) ; pref . setSummary ( device . getAddress ( ) ) ; pref . setFragment ( BluetoothDetailsFragment . class . getName ( ) ) ; pref . setPersistent ( false ) ; pref . setKey ( device . getAddress ( ) ) ; mAccessoriesGroup . addPreference ( pref ) ; } } } } if ( mAccessoriesGroup . getPreferenceCount ( ) == 0 ) { mAccessoriesGroup . setVisible ( false ) ; } else { mAccessoriesGroup . setVisible ( true ) ; } } private void updateAccounts ( ) { if ( mAccountsGroup == null ) { return ; } mAccountsGroup . removeAll ( ) ; final List < UserInfo > profiles = UserManager . get ( getContext ( ) ) . getProfiles ( UserHandle . myUserId ( ) ) ; final int profilesSize = profiles . size ( ) ; for ( int i = 0 ; i < profilesSize ; i ++ ) { final UserInfo userInfo = profiles . get ( i ) ; final UserHandle userHandle = userInfo . getUserHandle ( ) ; final List < AuthenticatorDescription > authenticatorDescs = mAuthenticatorHelper . getAuthenticatorTypes ( ) ; final int authenticatorDescsSize = authenticatorDescs . size ( ) ; for ( int j = 0 ; j < authenticatorDescsSize ; j ++ ) { final AuthenticatorDescription desc = authenticatorDescs . get ( j ) ; final Preference pref = new Preference ( getPrefContext ( ) ) ; pref . setTitle ( desc . labelId ) ; pref . setSummary ( userInfo . name ) ; pref . setFragment ( AccountSyncSettings . class . getName ( ) ) ; pref . setPersistent ( false ) ; pref . setKey ( desc . type ) ; pref . getExtras ( ) . putParcelable ( AccountSyncSettings . EXTRA_USER , userHandle ) ; mAccountsGroup . addPreference ( pref ) ; } } if ( mAccountsGroup . getPreferenceCount ( ) == 0 ) { mAccountsGroup . setVisible ( false ) ; } else { mAccountsGroup . setVisible ( true ) ; } } private void updateNetwork ( ) { if ( mNetworkPref == null ) { return ; } final int connectionType = mConnectivityListener . getCurrentConnectionType ( ) ; if ( connectionType == ConnectivityManager . TYPE_ETHERNET ) { mNetworkPref . setSummary ( R . string . ethernet_settings_title ) ; } else if ( connectionType == ConnectivityManager . TYPE_WIFI ) { mNetworkPref . setSummary ( R . string . wifi_settings_title ) ; } else if ( connectionType == ConnectivityManager . TYPE_BLUETOOTH ) { mNetworkPref . setSummary ( R . string . bluetooth_settings_title ) ; } else { mNetworkPref . setSummary ( R . string . network_settings_title ) ; } } }
public void onStart ( ) { super . onStart ( ) ; mAuthenticatorHelper . listenToAccountUpdates ( ) ; IntentFilter btChangeFilter = new IntentFilter ( ) ; btChangeFilter . addAction ( BluetoothDevice . ACTION_ACL_CONNECTED ) ; btChangeFilter . addAction ( BluetoothDevice . ACTION_ACL_DISCONNECTED ) ; btChangeFilter . addAction ( BluetoothAdapter . ACTION_STATE_CHANGED ) ; < |startfocus| > getContext ( ) . registerReceiver ( mBBCMReceiver , btChangeFilter ) ; < |endfocus| > }
List < X509Certificate > certPathList ) throws GeneralSecurityException { if ( debug != null ) { debug . println ( "ForwardBuilder . verifyCert ( SN : " + Debug . toHexString ( cert . getSerialNumber ( ) ) + "\n Issuer : " + cert . getIssuerX500Principal ( ) + " ) " + "\n Subject : " + cert . getSubjectX500Principal ( ) + " ) " ) ; } ForwardState currState = ( ForwardState ) currentState ; < |startfocus| > // BEGIN Android - removed : Android doesn't use this mechanism for checking untrusted certificates . < |endfocus| > // // Don't bother to verify untrusted certificate more . // currState . untrustedChecker . check ( cert , Collections . < String > emptySet ( ) ) ; // END Android - removed : Android doesn't use this mechanism for checking untrusted certificates . /* * check for looping - abort a loop if we encounter the same * certificate twice */ if ( certPathList != null ) { for ( X509Certificate cpListCert : certPathList ) { if ( cert . equals ( cpListCert ) ) { if ( debug != null ) { debug . println ( "loop detected ! ! " ) ; }
public void testScreenLayout ( ) throws Exception { int expectedScreenLayout = computeScreenLayout ( ) ; int expectedSize = expectedScreenLayout & Configuration . SCREENLAYOUT_SIZE_MASK ; int expectedLong = expectedScreenLayout & Configuration . SCREENLAYOUT_LONG_MASK ; // Check that all four orientations report the same configuration value . for ( int i = 0 ; i < ORIENTATIONS . length ; i ++ ) { Activity activity = startOrientationActivity ( ORIENTATIONS [ i ] ) ; if ( activity . isInMultiWindowMode ( ) ) { // activity . setRequestedOrientation has no effect in multiwindow mode . < |startfocus| > continue ; < |endfocus| > } Configuration mConfig = activity . getResources ( ) . getConfiguration ( ) ; int actualSize = mConfig . screenLayout & Configuration . SCREENLAYOUT_SIZE_MASK ; int actualLong = mConfig . screenLayout & Configuration . SCREENLAYOUT_LONG_MASK ; assertEquals ( "Expected screen size value of " + expectedSize + " but got " + actualSize + " for orientation " + ORIENTATIONS [ i ] , expectedSize , actualSize ) ; assertEquals ( "Expected screen long value of " + expectedLong + " but got " + actualLong
public void testCompare ( ) { assertTrue ( PhoneNumberUtils . compare ( null , null ) ) ; < |startfocus| > assertTrue ( PhoneNumberUtils . compare ( "2023458246" , "2023458246" ) ) ; < |endfocus| > assertFalse ( PhoneNumberUtils . compare ( "2023458246" , "6503458246" ) ) ; assertTrue ( PhoneNumberUtils . compare ( "2023458246" , "202 - 345 - 8246" ) ) ; assertTrue ( PhoneNumberUtils . compare ( "2023458246" , " + 12023458246" ) ) ; assertTrue ( PhoneNumberUtils . compare ( "2023458246" , " + 812023458246" ) ) ; assertTrue ( PhoneNumberUtils . compare ( "2023458246" , " + 1 ( 202 ) 345 - 8246" ) ) ; assertTrue ( PhoneNumberUtils . compare ( " + 17005554141" , " ** 31# + 17005554141" ) ) ;
public void testFormatNumberToE164 ( ) { assertNull ( PhoneNumberUtils . formatNumber ( "invalid#" , "US" ) ) ; assertEquals ( " + 12023458246" , PhoneNumberUtils . formatNumberToE164 ( " ( 202 ) 345 - 8246" , "US" ) ) ; < |startfocus| > < |endfocus| > assertEquals ( " + 812023458246" , PhoneNumberUtils . formatNumberToE164 ( "202 - 345 - 8246" , "JP" ) ) ;
int connectionState = mStateMachine . getConnectionState ( device ) ; if ( connectionState != BluetoothProfile . STATE_CONNECTED && connectionState != BluetoothProfile . STATE_CONNECTING ) { return false ; } mStateMachine . sendMessage ( HeadsetStateMachine . DISCONNECT , device ) ; return true ; } public List < BluetoothDevice > getConnectedDevices ( ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , "Need BLUETOOTH permission" ) ; return mStateMachine . getConnectedDevices ( ) ; } < |startfocus| > public BluetoothDevice getCurrentDevice ( ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , "Need BLUETOOTH permission" ) ; return mStateMachine . getCurrentDevice ( ) ; } < |endfocus| > private List < BluetoothDevice > getDevicesMatchingConnectionStates ( int [ ] states ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , "Need BLUETOOTH permission" ) ; return mStateMachine . getDevicesMatchingConnectionStates ( states ) ; } public int getConnectionState ( BluetoothDevice device ) { enforceCallingOrSelfPermission ( BLUETOOTH_PERM , "Need BLUETOOTH permission" ) ; return mStateMachine . getConnectionState ( device ) ; } public boolean setPriority ( BluetoothDevice device , int priority ) { enforceCallingOrSelfPermission ( BLUETOOTH_ADMIN_PERM , "Need BLUETOOTH_ADMIN permission" ) ; Settings . Global . putInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) , Settings . Global . getInt ( getContentResolver ( ) ,
< |startfocus| > private void processSlcConnected ( BluetoothDevice device ) { < |endfocus| > if ( mPhoneProxy != null ) { try { mPhoneProxy . queryPhoneState ( ) ; } catch ( RemoteException e ) { Log . e ( TAG , Log . getStackTraceString ( new Throwable ( ) ) ) ; } } else { Log . e ( TAG , "Handsfree phone proxy null for query phone state" ) ; } }
} return BluetoothProfile . STATE_DISCONNECTED ; } else { Log . e ( TAG , "Bad currentState : " + currentState ) ; return BluetoothProfile . STATE_DISCONNECTED ; } } } List < BluetoothDevice > getConnectedDevices ( ) { List < BluetoothDevice > devices = new ArrayList < BluetoothDevice > ( ) ; synchronized ( this ) { for ( int i = 0 ; i < mConnectedDevicesList . size ( ) ; i ++ ) devices . add ( mConnectedDevicesList . get ( i ) ) ; } return devices ; } < |startfocus| > BluetoothDevice getCurrentDevice ( ) { return mCurrentDevice ; } < |endfocus| > boolean isAudioOn ( ) { return ( getCurrentState ( ) == mAudioOn ) ; } boolean isAudioConnected ( BluetoothDevice device ) { synchronized ( this ) { /* Additional check for audio state included for the case when PhoneApp queries Bluetooth Audio state , before we receive the close event from the stack for the sco disconnect issued in AudioOn state . This was causing a mismatch in the Incall screen UI . */ if ( getCurrentState ( ) == mAudioOn && mCurrentDevice . equals ( device ) ) { return true ; } } return false ; } int getAudioState ( BluetoothDevice device ) { synchronized ( this ) { if ( getCurrentState ( ) == mAudioOn && mCurrentDevice . equals ( device ) ) { return BluetoothHeadset . STATE_AUDIO_CONNECTED ; } else if ( getCurrentState ( ) == mAudioConnecting && mCurrentDevice . equals ( device ) ) { return BluetoothHeadset . STATE_AUDIO_CONNECTING ; } else { return BluetoothHeadset . STATE_AUDIO_DISCONNECTED ; } } } private void broadcastAudioState ( BluetoothDevice device , int newState , int prevState ) { // Send broadcast message . Intent intent = new Intent ( BluetoothHeadset . ACTION_AUDIO_STATE_CHANGED ) ; intent . putExtra ( BluetoothDevice . EXTRA_DEVICE , device ) ; intent . putExtra ( BluetoothHeadset . EXTRA_STATE , newState ) ; intent . putExtra ( BluetoothHeadset . EXTRA_PREVIOUS_STATE , prevState ) ; intent . addFlags ( Intent . FLAG_RECEIVER_REGISTERED_ONLY_BEFORE_BOOT ) ; mService . sendBroadcast ( intent , ProfileService . BLUETOOTH_PERM ) ; } private void broadcastConnectionState ( BluetoothDevice device , int newState , int prevState ) { // Send broadcast message . Intent intent = new Intent ( BluetoothHeadset . ACTION_CONNECTION_STATE_CHANGED ) ; intent . putExtra ( BluetoothDevice . EXTRA_DEVICE , device ) ; intent . putExtra ( BluetoothProfile . EXTRA_PREVIOUS_STATE , prevState ) ; intent . putExtra ( BluetoothProfile . EXTRA_STATE , newState ) ; intent . addFlags ( Intent . FLAG_RECEIVER_REGISTERED_ONLY_BEFORE_BOOT ) ; mService . sendBroadcast ( intent , ProfileService . BLUETOOTH_PERM ) ; } private void broadcastVrStateChanged ( BluetoothDevice device , int newState ) { // Send broadcast message . Intent intent = new Intent ( BluetoothHeadset . ACTION_VENDOR_SPECIFIC_HEADSET_EVENT ) ; intent . putExtra ( BluetoothDevice . EXTRA_DEVICE , device ) ; intent . putExtra ( BluetoothHeadset . EXTRA_VENDOR_SPECIFIC_HEADSET_EVENT_CMD ,
public void exit ( ) { < |startfocus| > mWifiConfigManager . loadFromStore ( ) ; < |endfocus| > mWifiConfigManager . enableAllNetworks ( ) ;
public void exit ( ) { < |startfocus| > mWifiConfigManager . loadFromStore ( ) ; < |endfocus| >
protected boolean hasLog ( String str ) throws DeviceNotAvailableException { String logs = getDevice ( ) . executeAdbCommand ( "logcat" , " - v" , "brief" , " - d" , mService + " : I" , " * : S" ) ; return logs . contains ( str ) ; } private void clearLogcat ( ) throws DeviceNotAvailableException { getDevice ( ) . executeAdbCommand ( "logcat" , " - c" ) ; } protected boolean supportedHardware ( ) throws DeviceNotAvailableException { // Customization by third - party tiles is only a requirement for devices < |startfocus| > // supporting Quick Settings UI component . < |endfocus| > // // As there is no public API to distinguish a device with Quick Settings // from others , the check below , as well as all the tests under // CtsSystemUiHostTestCases relying on the check may have false negatives . String features = getDevice ( ) . executeShellCommand ( "pm list features" ) ; return ! features . contains ( "android . hardware . type . television" ) && ! features . contains ( "android . hardware . type . watch" ) ; } }
HandlerThread thread = new HandlerThread ( "BluetoothAdvertiseManager" ) ; thread . start ( ) ; mHandler = new Handler ( thread . getLooper ( ) ) ; } void cleanup ( ) { logd ( "cleanup ( ) " ) ; cleanupNative ( ) ; mAdvertisers . clear ( ) ; sTempRegistrationId = - 1 ; if ( mHandler != null ) { // Shut down the thread mHandler . removeCallbacksAndMessages ( null ) ; Looper looper = mHandler . getLooper ( ) ; if ( looper != null ) { looper . quit ( ) ; } mHandler = null ; } } < |startfocus| > class AdvertiserInfo { < |endfocus| > /* When id is negative , the registration is ongoing . When the registration finishes , id * becomes equal to advertiser_id */ public Integer id ; public AdvertisingSetDeathRecipient deathRecipient ; public IAdvertisingSetCallback callback ; AdvertiserInfo ( Integer id , AdvertisingSetDeathRecipient deathRecipient , IAdvertisingSetCallback callback ) { this . id = id ; this . deathRecipient = deathRecipient ; this . callback = callback ; } } IBinder toBinder ( IAdvertisingSetCallback e ) { return ( ( IInterface ) e ) . asBinder ( ) ; } class AdvertisingSetDeathRecipient implements IBinder . DeathRecipient {
import android . os . ParcelFileDescriptor ; import android . os . Process ; import android . os . SystemClock ; import android . telecom . PhoneAccount ; import android . telecom . PhoneAccountHandle ; import android . telecom . TelecomManager ; import junit . framework . TestCase ; import java . io . BufferedReader ; import java . io . FileInputStream ; import java . io . InputStream ; import java . io . InputStreamReader ; import java . nio . charset . StandardCharsets ; import java . util . ArrayList ; import java . util . Optional ; import java . util . concurrent . CountDownLatch ; import java . util . concurrent . TimeUnit ; import java . util . function . Predicate ; < |startfocus| > import java . util . stream . Collectors ; < |endfocus| > public class TestUtils { static final String TAG = "TelecomCTSTests" ; static final boolean HAS_TELECOM = Build . VERSION . SDK_INT >= Build . VERSION_CODES . LOLLIPOP ; static final long WAIT_FOR_STATE_CHANGE_TIMEOUT_MS = 10000 ; static final long WAIT_FOR_CALL_ADDED_TIMEOUT_S = 15 ; static final long WAIT_FOR_STATE_CHANGE_TIMEOUT_CALLBACK = 50 ; // Non - final to allow modification by tests not in this package ( e . g . permission - related // tests in the Telecom2 test package .
// Avoid unnecessary work on spurious updates . if ( Objects . equals ( mLastIPv6LinkProperties , v6only ) ) { return ; } RaParams params = null ; if ( v6only != null ) { params = new RaParams ( ) ; params . mtu = v6only . getMtu ( ) ; params . hasDefaultRoute = v6only . hasIPv6DefaultRoute ( ) ; for ( LinkAddress linkAddr : v6only . getLinkAddresses ( ) ) { < |startfocus| > if ( linkAddr . getPrefixLength ( ) != RFC7421_PREFIX_LENGTH ) { continue ; } < |endfocus| > final IpPrefix prefix = new IpPrefix ( linkAddr . getAddress ( ) , linkAddr . getPrefixLength ( ) ) ; params . prefixes . add ( prefix ) ; final Inet6Address dnsServer = getLocalDnsIpFor ( prefix ) ; if ( dnsServer != null ) { params . dnses . add ( dnsServer ) ; } } } // If v6only is null , we pass in null to setRaParams ( ) , which handles // deprecation of any existing RA data . setRaParams ( params ) ; mLastIPv6LinkProperties = v6only ;
*/ public static final int IPV6_HEADER_LEN = 40 ; public static final int IPV6_PROTOCOL_OFFSET = 6 ; public static final int IPV6_SRC_ADDR_OFFSET = 8 ; public static final int IPV6_DST_ADDR_OFFSET = 24 ; public static final int IPV6_ADDR_LEN = 16 ; public static final int RFC7421_PREFIX_LENGTH = 64 ; /* * < |startfocus| > * IPv6 constants . * * See also : * - https :/ / tools . ietf . org / html / rfc7421 */ /* * < |endfocus| > * ICMPv6 constants . * * See also : * - https :/ / tools . ietf . org / html / rfc4443 * - https :/ / tools . ietf . org / html / rfc4861 */ public static final int ICMPV6_HEADER_MIN_LEN = 4 ; public static final int ICMPV6_ROUTER_SOLICITATION = 133 ; public static final int ICMPV6_ROUTER_ADVERTISEMENT = 134 ; public static final int ICMPV6_NEIGHBOR_SOLICITATION = 135 ; public static final int ICMPV6_NEIGHBOR_ADVERTISEMENT = 136 ; public static final int ICMPV6_ND_OPTION_MIN_LENGTH = 8 ;
private boolean startIPv6 ( ) { try { enableInterfaceIpv6PrivacyExtensions ( ) ; setInterfaceIpv6RaRtInfoMaxPlen ( RFC7421_IP_PREFIX_LENGTH ) ; mNwService . enableIpv6 ( mInterfaceName ) ; < |startfocus| > } catch ( IllegalStateException|RemoteException|ServiceSpecificException e ) { logError ( "Unable to change interface settings : % s" , e ) ; < |endfocus| > return false ; } return true ;
* See the License for the specific language governing permissions and * limitations under the License . */ package com . android . server . connectivity . tethering ; import android . net . INetd ; import android . net . IpPrefix ; import android . net . LinkAddress ; import android . net . LinkProperties ; import android . net . NetworkCapabilities ; import android . net . NetworkState ; import android . net . RouteInfo ; import android . net . ip . RouterAdvertisementDaemon ; import android . net . ip . RouterAdvertisementDaemon . RaParams ; import android . net . util . NetdService ; import static android . net . util . NetworkConstants . RFC7421_PREFIX_LENGTH ; import android . os . INetworkManagementService ; import android . os . ServiceSpecificException ; import android . os . RemoteException ; import android . util . Log ; import android . util . Slog ; import java . net . Inet6Address ; import java . net . InetAddress ; import java . net . NetworkInterface ; import java . net . SocketException ; import java . net . UnknownHostException ; import java . util . ArrayList ; import java . util . HashSet ; import java . util . Objects ; /* * * @hide */ public class IPv6TetheringInterfaceServices { private static final String TAG = IPv6TetheringInterfaceServices . class . getSimpleName ( ) ;
import android . net . apf . ApfFilter ; import android . net . DhcpResults ; import android . net . INetd ; import android . net . InterfaceConfiguration ; import android . net . LinkAddress ; import android . net . LinkProperties ; import android . net . LinkProperties . ProvisioningChange ; import android . net . ProxyInfo ; import android . net . RouteInfo ; import android . net . StaticIpConfiguration ; import android . net . dhcp . DhcpClient ; import android . net . metrics . IpConnectivityLog ; import android . net . metrics . IpManagerEvent ; import android . net . util . MultinetworkPolicyTracker ; import android . net . util . NetdService ; import static android . net . util . NetworkConstants . RFC7421_PREFIX_LENGTH ; import android . os . INetworkManagementService ; import android . os . Message ; import android . os . RemoteException ; import android . os . ServiceManager ; import android . os . ServiceSpecificException ; import android . os . SystemClock ; import android . system . OsConstants ; import android . text . TextUtils ; import android . util . LocalLog ; import android . util . Log ; import android . util . SparseArray ; import com . android . internal . annotations . VisibleForTesting ; import com . android . internal . util . IndentingPrintWriter ; import com . android . internal . util . IState ; import com . android . internal . util . State ; import com . android . internal . util . StateMachine ; import com . android . server . net . NetlinkTracker ; import java . io . FileDescriptor ;
protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; < |startfocus| > final int dialogType = getIntent ( ) . getIntExtra ( DIALOG_TYPE_KEY , INVALID_PICK ) ; < |endfocus| > switch ( dialogType ) { case DATA_PICK : case CALLS_PICK : case SMS_PICK : createDialog ( this , dialogType ) . show ( ) ; break ; case PREFERRED_PICK : displayPreferredDialog ( extras . getInt ( PREFERRED_SIM ) ) ; break ; default : throw new IllegalArgumentException ( "Invalid dialog type " + dialogType + " sent . " ) ; }
{ "12345" , "12345" , "12345" } , { "12345" , "67890" , "67890" } , { "12345 * 00000" , "12345" , "12345 * 00000" } , { "12345 * 00000" , "67890" , "67890" } , { "12345 * 00000" , "12345 * 00000" , "12345 * 00000" } , { "12345 ; 11111 * 00000" , "12345" , "12345" } , { "12345 * 00000 ; 11111" , "12345" , "12345 * 00000" } , { "18412345 * 00000" , "18412345" , "18412345 * 00000" } , < |startfocus| > { " + 8112345 * 00000" , " + 8112345" , " + 8112345 * 00000" } } ; < |endfocus| > for ( String [ ] testAddress : testAddressMappingSet ) { mConnectionUT = new ImsPhoneConnection ( mImsPhone , testAddress [ 0 ] , mImsCT , mForeGroundCall , false ) ; doReturn ( testAddress [ 1 ] ) . when ( mImsCallProfile ) . getCallExtra ( eq ( ImsCallProfile . EXTRA_OI ) ) ; mConnectionUT . updateAddressDisplay ( mImsCall ) ; assertEquals ( testAddress [ 2 ] , mConnectionUT . getAddress ( ) ) ; } < |startfocus| > { "12345 * 00000" , "12346" , "12345 * 00000" } < |endfocus| >
* @hide */ public static final int PROPERTY_IS_DOWNGRADED_CONFERENCE = 1 < < 6 ; /* * * Set by the framework to indicate that the { @link Connection } originated from a self - managed * { @link ConnectionService } . * < p > * See { @link PhoneAccount#CAPABILITY_SELF_MANAGED } . */ public static final int PROPERTY_SELF_MANAGED = 1 < < 7 ; /* * < |startfocus| > * When set , indicates that a connection has an active RTT session associated with it . < |endfocus| > * @hide */ @TestApi public static final int PROPERTY_IS_RTT = 1 < < 8 ; // ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** // Next PROPERTY value : 1 < < 9 // ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** /* * * Connection extra key used to store the last forwarded number associated with the current * connection . Used to communicate to the user interface that the connection was forwarded via * the specified number . */ public static final String EXTRA_LAST_FORWARDED_NUMBER = "android . telecom . extra . LAST_FORWARDED_NUMBER" ; /* * * Connection extra key used to store the original connection ID of the connection . Used to * communicate to the user interface that the connection was forwarded via the specified number . */ public static final String EXTRA_ORIGINAL_CONNECTION_ID = "android . telecom . extra . ORIGINAL_CONNECTION_ID" ; /* *
private static final int STACK_EVENT = 101 ; private static final int DIALING_OUT_TIMEOUT = 102 ; private static final int START_VR_TIMEOUT = 103 ; private static final int CLCC_RSP_TIMEOUT = 104 ; private static final int CONNECT_TIMEOUT = 201 ; private static final int DIALING_OUT_TIMEOUT_VALUE = 10000 ; private static final int START_VR_TIMEOUT_VALUE = 5000 ; private static final int CLCC_RSP_TIMEOUT_VALUE = 5000 ; < |startfocus| > // Max number of HF connections at any time , default to 1 < |endfocus| > private int max_hf_connections = 1 ; private static final int NBS_CODEC = 1 ; private static final int WBS_CODEC = 2 ; // Keys are AT commands , and values are the company IDs . private static final Map < String , Integer > VENDOR_SPECIFIC_AT_COMMAND_COMPANY_ID ; // Hash for storing the Audio Parameters like NREC for connected headsets private HashMap < BluetoothDevice , HashMap > mHeadsetAudioParam = new HashMap < BluetoothDevice , HashMap > ( ) ; // Hash for storing the Remotedevice BRSF private HashMap < BluetoothDevice , Integer > mHeadsetBrsf = new HashMap < BluetoothDevice , Integer > ( ) ;
import android . preference . PreferenceManager ; import android . provider . Telephony ; import android . provider . Telephony . CellBroadcasts ; import android . telephony . CarrierConfigManager ; import android . telephony . cdma . CdmaSmsCbProgramData ; import android . util . Log ; import com . android . internal . telephony . TelephonyIntents ; import com . android . internal . telephony . cdma . sms . SmsEnvelope ; public class CellBroadcastReceiver extends BroadcastReceiver { private static final String TAG = "CellBroadcastReceiver" ; static final boolean DBG = false ; // STOPSHIP : change to false before ship < |startfocus| > public static final String CELLBROADCAST_START_CONFIG_ACTION = "com . android . cellbroadcastreceiver . intent . action . START_CONFIG" ; < |endfocus| > // Key to access the stored reminder interval default value private static final String CURRENT_INTERVAL_DEFAULT = "current_interval_default" ; public static final String ACTION_MARK_AS_READ = "com . android . cellbroadcastreceiver . intent . action . MARK_AS_READ" ; public static final String EXTRA_DELIVERY_TIME = "com . android . cellbroadcastreceiver . intent . extra . ID" ; @Override public void onReceive ( Context context , Intent intent ) { onReceiveWithPrivilege ( context , intent , false ) ; } protected void onReceiveWithPrivilege ( Context context , Intent intent , boolean privileged ) {
public boolean processMessage ( Message message ) { logStateAndMessage ( message , this ) ; switch ( message . what ) { case WifiMonitor . WPS_SUCCESS_EVENT : // Ignore intermediate success , wait for full connection break ; case WifiMonitor . NETWORK_CONNECTION_EVENT : if ( loadNetworksFromSupplicantAfterWps ( ) ) { replyToMessage ( mSourceMessage , WifiManager . WPS_COMPLETED ) ; < |startfocus| > mWifiConnectivityManager . forceConnectivityScan ( ) ; < |endfocus| > } else { replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , WifiManager . ERROR ) ; } mSourceMessage . recycle ( ) ; mSourceMessage = null ; deferMessage ( message ) ; transitionTo ( mDisconnectedState ) ; break ; case WifiMonitor . WPS_OVERLAP_EVENT : replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , WifiManager . WPS_OVERLAP_ERROR ) ; mSourceMessage . recycle ( ) ; mSourceMessage = null ; transitionTo ( mDisconnectedState ) ; break ; case WifiMonitor . WPS_FAIL_EVENT : // Arg1 has the reason for the failure if ( ( message . arg1 != WifiManager . ERROR ) || ( message . arg2 != 0 ) ) { replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , message . arg1 ) ; } else { replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , WifiManager . ERROR ) ; } mSourceMessage . recycle ( ) ; mSourceMessage = null ; transitionTo ( mDisconnectedState ) ; break ; case WifiMonitor . WPS_TIMEOUT_EVENT : replyToMessage ( mSourceMessage , WifiManager . WPS_FAILED , WifiManager . ERROR ) ; mSourceMessage . recycle ( ) ; mSourceMessage = null ; transitionTo ( mDisconnectedState ) ; break ; default : return NOT_HANDLED ; } return HANDLED ; }
public boolean connect ( Call call ) { if ( mIsConnected ) { Log . addEvent ( call , LogUtils . Events . INFO , "Already connected , ignoring request . " ) ; return true ; } if ( call . isSelfManaged ( ) && ! mInCallServiceInfo . isSelfManagedCallsSupported ( ) ) { < |startfocus| > return false ; < |endfocus| > } Intent intent = new Intent ( InCallService . SERVICE_INTERFACE ) ; intent . setComponent ( mInCallServiceInfo . getComponentName ( ) ) ; if ( call != null && ! call . isIncoming ( ) && ! call . isExternalCall ( ) ) { intent . putExtra ( TelecomManager . EXTRA_OUTGOING_CALL_EXTRAS , call . getIntentExtras ( ) ) ; intent . putExtra ( TelecomManager . EXTRA_PHONE_ACCOUNT_HANDLE , call . getTargetPhoneAccount ( ) ) ; } Log . i ( this , "Attempting to bind to InCall % s , with % s" , mInCallServiceInfo , intent ) ; mIsConnected = true ; if ( ! mContext . bindServiceAsUser ( intent , mServiceConnection , Context . BIND_AUTO_CREATE | Context . BIND_FOREGROUND_SERVICE , UserHandle . CURRENT ) ) { Log . w ( this , "Failed to connect . " ) ; mIsConnected = false ; }
public CallerInfoAsyncQuery startQuery ( int token , Context context , < |startfocus| > String number , CallerInfoAsyncQuery . OnQueryCompleteListener listener , Object cookie ) { < |endfocus| > Log . i ( TelecomSystem . getInstance ( ) , "CallerInfoAsyncQuery . startQuery number = % s cookie = % s" , Log . pii ( number ) , cookie ) ; return CallerInfoAsyncQuery . startQuery ( token , context , number , listener , cookie ) ;
public class IncomingCallNotifier extends CallsManagerListenerBase { public interface IncomingCallNotifierFactory { IncomingCallNotifier make ( Context context , CallsManagerProxy mCallsManagerProxy ) ; } /* * * Eliminates strict dependency between this class and CallsManager . */ public interface CallsManagerProxy { boolean hasCallsForOtherPhoneAccount ( PhoneAccountHandle phoneAccountHandle ) ; } // Notification for incoming calls . This is interruptive and will show up as a HUN . < |startfocus| > private static final int NOTIFICATION_INCOMING_CALL = 1 ; < |endfocus| > public final Call . ListenerBase mCallListener = new Call . ListenerBase ( ) { @Override public void onCallerInfoChanged ( Call call ) { if ( mIncomingCall != call ) { return ; } showIncomingCallNotification ( mIncomingCall ) ; } } ; private final Context mContext ; private final NotificationManager mNotificationManager ; private final Set < Call > mCalls = new ArraySet < > ( ) ; private CallsManagerProxy mCallsManagerProxy ; // The current incoming call we are displaying UX for . private Call mIncomingCall ; public IncomingCallNotifier ( Context context ) { mContext = context ; mNotificationManager =
} public boolean isConnected ( ) { return sc . isConnected ( ) ; } public boolean isBound ( ) { return sc . localAddress ( ) != null ; } public boolean isClosed ( ) { return ! sc . isOpen ( ) ; } public boolean isInputShutdown ( ) { return ! sc . isInputOpen ( ) ; } public boolean isOutputShutdown ( ) { return ! sc . isOutputOpen ( ) ; } /* * * Android - added : for testing and internal use . < |startfocus| > * * internal use only < |endfocus| > */ @Override public FileDescriptor getFileDescriptor$ ( ) { return sc . getFD ( ) ; } }
package libcore . java . nio . file . spi ; import org . junit . Test ; import java . nio . file . Paths ; import java . nio . file . spi . FileTypeDetector ; import static org . junit . Assert . assertEquals ; public class FileTypeDetectorTest { @Test public void test_probeFileType ( ) throws Exception { < |startfocus| > FileTypeDetector defaultFileTypeDetector = sun . nio . fs . DefaultFileTypeDetector . create ( ) ; < |endfocus| > assertEquals ( "text / plain" , defaultFileTypeDetector . probeContentType ( Paths . get ( "file . txt" ) ) ) ; assertEquals ( "text / x - java" , defaultFileTypeDetector . probeContentType ( Paths . get ( "file . java" ) ) ) ; } }
import java . io . FileOutputStream ; import java . io . FilenameFilter ; import java . io . IOException ; import java . io . PrintWriter ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . Collections ; import java . util . List ; /* * * CarrierConfigLoader binds to privileged carrier apps to fetch carrier config overlays . */ public class CarrierConfigLoader extends ICarrierConfigLoader . Stub { private static final String LOG_TAG = "CarrierConfigLoader" ; < |startfocus| > // Package name for default carrier config app , bundled with system image . private final String mCarrierConfigPackage ; < |endfocus| > /* * The singleton instance . */ private static CarrierConfigLoader sInstance ; // The context for phone app , passed from PhoneGlobals . private Context mContext ; // Carrier configs from default app , indexed by phoneID . private PersistableBundle [ ] mConfigFromDefaultApp ; // Carrier configs from privileged carrier config app , indexed by phoneID . private PersistableBundle [ ] mConfigFromCarrierApp ; // Service connection for binding to config app . private CarrierServiceConnection [ ] mServiceConnection ; // Broadcast receiver for Boot intents , register intent filter in construtor .
enforceTetherAccessPermission ( ) ; return mTethering . getTetheredIfaces ( ) ; } @Override public String [ ] getTetheringErroredIfaces ( ) { enforceTetherAccessPermission ( ) ; return mTethering . getErroredIfaces ( ) ; } @Override public String [ ] getTetheredDhcpRanges ( ) { enforceConnectivityInternalPermission ( ) ; return mTethering . getTetheredDhcpRanges ( ) ; } // if ro . tether . denied = true we default to no tethering // gservices could set the secure setting to 1 though to enable it on a build where it // had previously been turned off . @Override public boolean isTetheringSupported ( ) { enforceTetherAccessPermission ( ) ; < |startfocus| > int defaultVal = ( SystemProperties . get ( "ro . tether . denied" ) . equals ( "true" ) ? 0 : 1 ) ; < |endfocus| > boolean tetherEnabledInSettings = ( Settings . Global . getInt ( mContext . getContentResolver ( ) , Settings . Global . TETHER_SUPPORTED , defaultVal ) != 0 ) && ! mUserManager . hasUserRestriction ( UserManager . DISALLOW_CONFIG_TETHERING ) ; return tetherEnabledInSettings && mUserManager . adminUser ( ) && mTethering . hasTetherableConfiguration ( ) ; } @Override public void startTethering ( int type , ResultReceiver receiver , boolean showProvisioningUi ) {
private boolean updateBssidBlacklist ( String bssid , boolean enable , int reasonCode ) { if ( enable ) { return mBssidBlacklist . remove ( bssid ) != null ; < |startfocus| > } BssidBlacklistStatus status = mBssidBlacklist . get ( bssid ) ; if ( status == null ) { // First time for this BSSID status = new BssidBlacklistStatus ( ) ; mBssidBlacklist . put ( bssid , status ) ; } < |endfocus| > status . blacklistedTimeStamp = mClock . getElapsedSinceBootMillis ( ) ; status . counter ++ ; if ( ! status . isBlacklisted ) { if ( status . counter >= BSSID_BLACKLIST_THRESHOLD || reasonCode == REASON_CODE_AP_UNABLE_TO_HANDLE_NEW_STA ) { status . isBlacklisted = true ; return true ; } } return false ; }
when ( mClock . getElapsedSinceBootMillis ( ) ) . thenReturn ( SystemClock . elapsedRealtime ( ) + WifiConnectivityManager . BSSID_BLACKLIST_EXPIRE_TIME_MS ) ; mWifiConnectivityManager . forceConnectivityScan ( ) ; assertFalse ( mWifiConnectivityManager . isBssidDisabled ( bssid ) ) ; } /* * * When WifiConnectivityManager is on and Wifi client mode is enabled , framework * queries firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability . * * Expected behavior : WifiConnectivityManager#setWifiEnabled calls into < |startfocus| > * WifiConnectivityHelper#getFirmwareRoamingInfo < |endfocus| > */ @Test public void verifyGetFirmwareRoamingInfoIsCalledWhenEnableWiFiAndWcmOn ( ) { reset ( mWifiConnectivityHelper ) ; // WifiConnectivityManager is on by default mWifiConnectivityManager . setWifiEnabled ( true ) ; verify ( mWifiConnectivityHelper ) . getFirmwareRoamingInfo ( ) ; } /* * * When WifiConnectivityManager is off , verify that framework does not * query firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability when enabling Wifi client mode . * * Expected behavior : WifiConnectivityManager#setWifiEnabled does not call into * WifiConnectivityHelper#getFirmwareRoamingInfo
reset ( mWifiConnectivityHelper ) ; // WifiConnectivityManager is on by default mWifiConnectivityManager . setWifiEnabled ( true ) ; verify ( mWifiConnectivityHelper ) . getFirmwareRoamingInfo ( ) ; } /* * * When WifiConnectivityManager is off , verify that framework does not * query firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability when enabling Wifi client mode . * * Expected behavior : WifiConnectivityManager#setWifiEnabled does not call into < |startfocus| > * WifiConnectivityHelper#getFirmwareRoamingInfo < |endfocus| > */ @Test public void verifyGetFirmwareRoamingInfoIsNotCalledWhenEnableWiFiAndWcmOff ( ) { reset ( mWifiConnectivityHelper ) ; mWifiConnectivityManager . enable ( false ) ; mWifiConnectivityManager . setWifiEnabled ( true ) ; verify ( mWifiConnectivityHelper , times ( 0 ) ) . getFirmwareRoamingInfo ( ) ; } /* * Firmware supports controlled roaming . * Connect to a network from the DISCONNECTED state . * * Expected behavior : WifiConnectivityManager calls * WifiStateMachine . startConnectToNetwork ( ) with the * expected candidate network ID , and the BSSID value should be * 'any' since firmware controls the roaming . */ @Test
< |startfocus| > public void useAnyBssidForConnectionIfFirmwareControlsRoaming ( ) { < |endfocus| > // Firmware controls roaming when ( mWifiConnectivityHelper . isFirmwareRoamingSupported ( ) ) . thenReturn ( true ) ; // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; // Set WiFi to disconnected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; verify ( mWifiStateMachine ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , WifiStateMachine . SUPPLICANT_BSSID_ANY ) ;
< |startfocus| > public void noFrameworkRoamingIfConnectedAndFirmwareRoamingSupported ( ) { < |endfocus| > // Mock the currently connected network which has the same networkID and // SSID as the one to be selected . WifiConfiguration currentNetwork = generateWifiConfig ( 0 , CANDIDATE_NETWORK_ID , CANDIDATE_SSID , false , true , null , null ) ; when ( mWifiConfigManager . getConfiguredNetwork ( anyInt ( ) ) ) . thenReturn ( currentNetwork ) ; // Firmware controls roaming when ( mWifiConnectivityHelper . isFirmwareRoamingSupported ( ) ) . thenReturn ( true ) ; // Set WiFi to connected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_CONNECTED ) ; // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; verify ( mWifiStateMachine , times ( 0 ) ) . startRoamToNetwork ( anyInt ( ) , anyObject ( ) ) ;
private void refreshBssidBlacklist ( ) { < |startfocus| > boolean updated = false ; < |endfocus| > Iterator < BssidBlacklistStatus > iter = mBssidBlacklist . values ( ) . iterator ( ) ; Long currentTimeStamp = mClock . getElapsedSinceBootMillis ( ) ; while ( iter . hasNext ( ) ) { BssidBlacklistStatus status = iter . next ( ) ; if ( status . isBlacklisted && ( ( currentTimeStamp - status . blacklistedTimeStamp ) >= BSSID_BLACKLIST_EXPIRE_TIME_MS ) ) { iter . remove ( ) ; updated = true ; } } if ( updated && mConnectivityHelper . isFirmwareRoamingSupported ( ) ) { updateFirmwareBssidBlacklist ( ) ; } }
// network ( same SSID & security type ) as the currently connected one . // This might save a disconnection triggered by network switch when // the score of the currently connected BSSID is lower than a network // with a different SSID , but within the currently connected network // there is a BSSID better than the currently connected BSSID . // This is under the assumption that firmware will roam the device // to that better BSSID . score += mSameBssidAward ; < |startfocus| > sbuf . append ( " Firmware roaming same BSSID bonus : " ) < |endfocus| > . append ( mSameBssidAward ) . append ( " , " ) ; } } // When firmware roaming is supported , the same BSSID award is already // applied above , skip it . if ( ! mConnectivityHelper . isFirmwareRoamingSupported ( ) ) { // Same BSSID award . if ( currentBssid != null && currentBssid . equals ( scanResult . BSSID ) ) { score += mSameBssidAward ; sbuf . append ( " Same BSSID as the current one bonus : " ) . append ( mSameBssidAward ) . append ( " , " ) ; } } // Security award . if ( security == SECURITY_PSK ) { score += mPskAward ; sbuf . append ( " PSK bonus : " ) . append ( mPskAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP ) { score += mEapAward ; sbuf . append ( " EAP bonus : " ) . append ( mEapAward ) . append ( " , " ) ; } else if ( security == SECURITY_OWE ) { score += mOweAward ; sbuf . append ( " OWE bonus : " ) . append ( mOweAward ) . append ( " , " ) ; } else if ( security == SECURITY_SAE ) { score += mSaeAward ; sbuf . append ( " SAE bonus : " ) . append ( mSaeAward ) . append ( " , " ) ; } else if ( security == SECURITY_SUITE_B ) { score += mSuiteBAward ; sbuf . append ( " SuiteB bonus : " ) . append ( mSuiteBAward ) . append ( " , " ) ; } else if ( security == SECURITY_DPP ) { score += mDppAward ; sbuf . append ( " DPP bonus : " ) . append ( mDppAward ) . append ( " , " ) ; } else if ( security == SECURITY_OSEN ) { score += mOsenAward ; sbuf . append ( " OSEN bonus : " ) . append ( mOsenAward ) . append ( " , " ) ; } else if ( security == SECURITY_OWE_TRANSITION ) { score += mOweTransitionAward ; sbuf . append ( " OWE_TRANSITION bonus : " ) . append ( mOweTransitionAward ) . append ( " , " ) ; } else if ( security == SECURITY_WAPI_PSK ) { score += mWapiPskAward ; sbuf . append ( " WAPI_PSK bonus : " ) . append ( mWapiPskAward ) . append ( " , " ) ; } else if ( security == SECURITY_WAPI_CERT ) { score += mWapiCertAward ; sbuf . append ( " WAPI_CERT bonus : " ) . append ( mWapiCertAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_SUITE_B_192 ) { score += mEapSuiteBAward ; sbuf . append ( " EAP_SUITE_B_192 bonus : " ) . append ( mEapSuiteBAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_SUITE_B_128 ) { score += mEapSuiteBAward ; sbuf . append ( " EAP_SUITE_B_128 bonus : " ) . append ( mEapSuiteBAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_FAST ) { score += mEapFastAward ; sbuf . append ( " EAP_FAST bonus : " ) . append ( mEapFastAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_AKA ) { score += mEapAkaAward ; sbuf . append ( " EAP_AKA bonus : " ) . append ( mEapAkaAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_SIM ) { score += mEapSimAward ; sbuf . append ( " EAP_SIM bonus : " ) . append ( mEapSimAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_AKA_PRIME ) { score += mEapAkaPrimeAward ; sbuf . append ( " EAP_AKA_PRIME bonus : " ) . append ( mEapAkaPrimeAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_PAX ) { score += mEapPaxAward ; sbuf . append ( " EAP_PAX bonus : " ) . append ( mEapPaxAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_SAKE ) { score += mEapSakeAward ; sbuf . append ( " EAP_SAKE bonus : " ) . append ( mEapSakeAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_PSK ) { score += mEapPskAward ; sbuf . append ( " EAP_PSK bonus : " ) . append ( mEapPskAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_TLS ) { score += mEapTlsAward ; sbuf . append ( " EAP_TLS bonus : " ) . append ( mEapTlsAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_TTLS ) { score += mEapTtlsAward ; sbuf . append ( " EAP_TTLS bonus : " ) . append ( mEapTtlsAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_PEAP ) { score += mEapPeapAward ; sbuf . append ( " EAP_PEAP bonus : " ) . append ( mEapPeapAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_PWD ) { score += mEapPwdAward ; sbuf . append ( " EAP_PWD bonus : " ) . append ( mEapPwdAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_FAST_GTC ) { score += mEapFastGtcAward ; sbuf . append ( " EAP_FAST_GTC bonus : " ) . append ( mEapFastGtcAward ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_SUITE_B_P192 ) { score += mEapSuiteBP192Award ; sbuf . append ( " EAP_SUITE_B_P192 bonus : " ) . append ( mEapSuiteBP192Award ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_SUITE_B_P256 ) { score += mEapSuiteBP256Award ; sbuf . append ( " EAP_SUITE_B_P256 bonus : " ) . append ( mEapSuiteBP256Award ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_SUITE_B_GCM_128 ) { score += mEapSuiteBGcm128Award ; sbuf . append ( " EAP_SUITE_B_GCM_128 bonus : " ) . append ( mEapSuiteBGcm128Award ) . append ( " , " ) ; } else if ( security == SECURITY_EAP_SUITE_B_GC
data [ 0 ] = new StructCapUserData ( data [ 0 ] . effective , data [ 0 ] . permitted , data [ 0 ] . permitted ) ; data [ 1 ] = new StructCapUserData ( data [ 1 ] . effective , data [ 1 ] . permitted , data [ 1 ] . permitted ) ; Os . capset ( header , data ) ; } for ( int i = 0 ; i < 64 ; i ++ ) { < |startfocus| > int dataIndex = OsConstants . CAP_TO_INDEX ( i ) ; int bitShift = OsConstants . CAP_TO_MASK ( i ) ; if ( ( data [ dataIndex ] . inheritable & bitShift ) != 0 ) { < |endfocus| > try { Os . prctl ( OsConstants . PR_CAP_AMBIENT , OsConstants . PR_CAP_AMBIENT_RAISE , i , 0 , 0 ) ; } catch ( ErrnoException ex ) { Slog . e ( RuntimeInit . TAG , "RuntimeInit : Failed to raise ambient capability " + i , ex ) ; } } } } catch ( Exception e ) { Slog . e ( RuntimeInit . TAG , "RuntimeInit : Failed to preserve capabilities" , e ) ; }
* This is supposed to be from Telephony service . * otherwise we think it is from other applications . * @return Returns true if the country code passed in is acceptable . */ public synchronized boolean setCountryCode ( String countryCode ) { if ( DBG ) Log . d ( TAG , "Receive set country code request : " + countryCode ) ; // Empty country code . if ( TextUtils . isEmpty ( countryCode ) ) { < |startfocus| > if ( DBG ) Log . d ( TAG , "Received empty country code , reset to default country code" ) ; < |endfocus| > mTelephonyCountryCode = null ; } else { mTelephonyCountryCode = countryCode . toUpperCase ( ) ; } // If wpa_supplicant is ready we set the country code now , otherwise it will be // set once wpa_supplicant is ready . if ( mReady ) { updateCountryCode ( ) ; } return true ; } /* * * Method to get the Country Code that was sent to wpa_supplicant . * * @return Returns the local copy of the Country Code that was sent to the driver upon * setReadyForChange ( true ) .
refreshBssidBlacklist ( ) ; if ( mStateMachine . isLinkDebouncing ( ) || mStateMachine . isSupplicantTransientState ( ) ) { localLog ( listenerName + " onResults : No network selection because linkDebouncing is " + mStateMachine . isLinkDebouncing ( ) + " and supplicantTransient is " + mStateMachine . isSupplicantTransientState ( ) ) ; return false ; } localLog ( listenerName + " onResults : start network selection" ) ; WifiConfiguration candidate = < |startfocus| > mNetworkSelector . selectNetwork ( scanDetails , buildBssidBlacklist ( ) , mWifiInfo , < |endfocus| > mStateMachine . isConnected ( ) , mStateMachine . isDisconnected ( ) , mUntrustedConnectionAllowed ) ; mWifiLastResortWatchdog . updateAvailableNetworks ( mNetworkSelector . getFilteredScanDetails ( ) ) ; mWifiMetrics . countScanResults ( scanDetails ) ; if ( candidate != null ) { localLog ( listenerName + " : WNS candidate - " + candidate . SSID ) ; connectToNetwork ( candidate ) ; return true ; } else { return false ; }
< |startfocus| > public void useAnyBssidForConnectionIfFirmwareControlsRoaming ( ) { < |endfocus| > // Firmware controls roaming when ( mWifiConnectivityHelper . isFirmwareRoamingSupported ( ) ) . thenReturn ( true ) ; // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; // Set WiFi to disconnected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; verify ( mWifiStateMachine ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , WifiStateMachine . SUPPLICANT_BSSID_ANY ) ;
private void localLog ( String log ) { < |startfocus| > if ( mLocalLog != null ) { mLocalLog . log ( log ) ; } < |endfocus| >
private void updateEverything ( ) { BatteryInfo info = BatteryInfo . getBatteryInfo ( getContext ( ) , mBatteryBroadcast , mStats , SystemClock . elapsedRealtime ( ) * 1000 ) ; final View view = getView ( ) ; if ( mShowCellSignal ) { info . bindHistory ( ( UsageView ) view . findViewById ( R . id . battery_usage ) , mChargingParser , < |startfocus| > mScreenOn , mGpsParser , mFlashlightParser , mCameraParser , mWifiParser , mCpuParser , mPhoneParser ) ; < |endfocus| > } else { info . bindHistory ( ( UsageView ) view . findViewById ( R . id . battery_usage ) , mChargingParser , mScreenOn , mGpsParser , mFlashlightParser , mCameraParser , mWifiParser , mCpuParser ) ; } ( ( TextView ) view . findViewById ( R . id . charge ) ) . setText ( info . batteryPercentString ) ; ( ( TextView ) view . findViewById ( R . id . estimation ) ) . setText ( info . remainingLabel ) ; bindData ( mChargingParser , R . string . battery_stats_charging_label , R . id . charging_group ) ; bindData ( mScreenOn , R . string . battery_stats_screen_on_label , R . id . screen_on_group ) ; bindData ( mGpsParser , R . string . battery_stats_gps_on_label , R . id . gps_group ) ; }
SystemClock . elapsedRealtime ( ) * 1000 ) ; final View view = getView ( ) ; if ( mShowCellSignal ) { info . bindHistory ( ( UsageView ) view . findViewById ( R . id . battery_usage ) , mChargingParser , mScreenOn , mGpsParser , mFlashlightParser , mCameraParser , mWifiParser , mCpuParser , mPhoneParser ) ; } else { info . bindHistory ( ( UsageView ) view . findViewById ( R . id . battery_usage ) , mChargingParser , < |startfocus| > mScreenOn , mGpsParser , mFlashlightParser , mCameraParser , mWifiParser , mCpuParser ) ; < |endfocus| > } ( ( TextView ) view . findViewById ( R . id . charge ) ) . setText ( info . batteryPercentString ) ; ( ( TextView ) view . findViewById ( R . id . estimation ) ) . setText ( info . remainingLabel ) ; bindData ( mChargingParser , R . string . battery_stats_charging_label , R . id . charging_group ) ; bindData ( mScreenOn , R . string . battery_stats_screen_on_label , R . id . screen_on_group ) ; bindData ( mGpsParser , R . string . battery_stats_gps_on_label , R . id . gps_group ) ; bindData ( mFlashlightParser , R . string . battery_stats_flashlight_on_label , R . id . flashlight_group ) ; bindData ( mCameraParser , R . string . battery_stats_camera_on_label , R . id . camera_group ) ;
bindData ( mFlashlightParser , R . string . battery_stats_flashlight_on_label , R . id . flashlight_group ) ; bindData ( mCameraParser , R . string . battery_stats_camera_on_label , R . id . camera_group ) ; bindData ( mWifiParser , R . string . battery_stats_wifi_running_label , R . id . wifi_group ) ; bindData ( mCpuParser , R . string . battery_stats_wake_lock_label , R . id . cpu_group ) ; if ( mShowCellSignal ) { < |startfocus| > bindData ( mPhoneParser , R . string . battery_stats_phone_signal_label , R . id . cell_network_group ) ; < |endfocus| > } else { view . findViewById ( R . id . cell_network_group ) . setVisibility ( View . GONE ) ; }
// Wait until it finishes and end the reciever then . assertEquals ( RESULT_PASS , appEndReceiver . waitForActivity ( ) ) ; appEndReceiver . close ( ) ; if ( ! noHomeScreen ( ) ) { // At this time the timerReceiver should not fire , even though the activity has shut // down , because we are back to the home screen . assertEquals ( RESULT_TIMEOUT , timeReceiver . waitForActivity ( ) ) ; assertTrue ( timeReceiver . mTimeUsed == 0 ) ; < |startfocus| > } else { < |endfocus| > assertEquals ( RESULT_PASS , timeReceiver . waitForActivity ( ) ) ; } // Issuing now another activity will trigger the timing information release . final Intent dummyIntent = new Intent ( context , MockApplicationActivity . class ) ; dummyIntent . addFlags ( Intent . FLAG_ACTIVITY_NEW_TASK ) ; final Activity activity = mInstrumentation . startActivitySync ( dummyIntent ) ; // Wait until it finishes and end the reciever then . assertEquals ( RESULT_PASS , timeReceiver . waitForActivity ( ) ) ; timeReceiver . close ( ) ; assertTrue ( timeReceiver . mTimeUsed != 0 ) ; } /* * * Verify that the TimeTrackingAPI works properly when switching away from the monitored task . */
* getPhoneId ( DEFAULT_SUB_ID ) will return the same as getPhoneId ( getDefaultSubId ( ) ) . * * Finally , any getters which perform the mapping between subscriptions , slots and phones will * return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID . All other getters < |startfocus| > * will fail and return the appropriate error value . Ie calling getSlotIndex ( INVALID_SUBSCRIPTION_ID ) * will return INVALID_SIM_SLOT_INDEX and calling getSubInfoForSubscriber ( INVALID_SUBSCRIPTION_ID ) * will return null . < |endfocus| > * */ public class SubscriptionController extends ISub . Stub { static final String LOG_TAG = "SubscriptionController" ; static final boolean DBG = true ; static final boolean VDBG = false ; static final int MAX_LOCAL_LOG_LINES = 500 ; // TODO : Reduce to 100 when 17678050 is fixed private ScLocalLog mLocalLog = new ScLocalLog ( MAX_LOCAL_LOG_LINES ) ; /* * * Copied from android . util . LocalLog with flush ( ) adding flush and line number * TODO : Update LocalLog */ static class ScLocalLog { private LinkedList < String > mLog ; private int mMaxLines ;
import java . io . PrintWriter ; import java . util . ArrayList ; import java . util . Collections ; import java . util . Comparator ; import java . util . Iterator ; import java . util . LinkedList ; import java . util . List ; import java . util . Map ; import java . util . Map . Entry ; import java . util . Set ; import java . util . concurrent . ConcurrentHashMap ; /* * * SubscriptionController to provide an inter - process communication to * access Sms in Icc . * < |startfocus| > * Any setters which take subId , slotId or phoneId as a parameter will throw an exception if the < |endfocus| > * parameter equals the corresponding INVALID_XXX_ID or DEFAULT_XXX_ID . * * All getters will lookup the corresponding default if the parameter is DEFAULT_XXX_ID . Ie calling * getPhoneId ( DEFAULT_SUB_ID ) will return the same as getPhoneId ( getDefaultSubId ( ) ) . * * Finally , any getters which perform the mapping between subscriptions , slots and phones will * return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID . All other getters * will fail and return the appropriate error value . Ie calling getSlotId ( INVALID_SUBSCRIPTION_ID )
* * All getters will lookup the corresponding default if the parameter is DEFAULT_XXX_ID . Ie calling * getPhoneId ( DEFAULT_SUB_ID ) will return the same as getPhoneId ( getDefaultSubId ( ) ) . * * Finally , any getters which perform the mapping between subscriptions , slots and phones will * return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID . All other getters < |startfocus| > * will fail and return the appropriate error value . Ie calling getSlotId ( INVALID_SUBSCRIPTION_ID ) < |endfocus| > * will return INVALID_SLOT_ID and calling getSubInfoForSubscriber ( INVALID_SUBSCRIPTION_ID ) * will return null . * */ public class SubscriptionController extends ISub . Stub { static final String LOG_TAG = "SubscriptionController" ; static final boolean DBG = true ; static final boolean VDBG = false ; static final int MAX_LOCAL_LOG_LINES = 500 ; // TODO : Reduce to 100 when 17678050 is fixed private ScLocalLog mLocalLog = new ScLocalLog ( MAX_LOCAL_LOG_LINES ) ; /* * * Copied from android . util . LocalLog with flush ( ) adding flush and line number * * @hide */ private static class ScLocalLog { private ArrayList < String > mLines = new ArrayList < String > ( ) ; private int mMaxLines = MAX_LOCAL_LOG_LINES ;
} } /* * * @return the maximum number of subscriptions this device will support at any one time . */ @Override public int getActiveSubInfoCountMax ( ) { // FIXME : This valid now but change to use TelephonyDevController in the future return mTelephonyManager . getSimCount ( ) ; } /* * * Add a new SubInfoRecord to subinfo database if needed * @param iccId the IccId of the SIM card < |startfocus| > * @param slotId the slot which the SIM is inserted < |endfocus| > * @return 0 if success , < 0 on error . */ @Override public int addSubInfoRecord ( String iccId , int slotId ) { if ( DBG ) logdl ( " [ addSubInfoRecord ] + iccId : " + SubscriptionInfo . givePrintableIccid ( iccId ) + " slotId : " + slotId ) ; enforceModifyPhoneState ( "addSubInfoRecord" ) ; // Now that all security checks passes , perform the operation as ourselves . final long identity = Binder . clearCallingIdentity ( ) ; try { if ( iccId == null ) {
public int addSubInfoRecord ( String iccId , int slotId ) { if ( DBG ) logdl ( " [ addSubInfoRecord ] + iccId : " + SubscriptionInfo . givePrintableIccid ( iccId ) + < |startfocus| > " slotId : " + slotId ) ; < |endfocus| > enforceModifyPhoneState ( "addSubInfoRecord" ) ; // Now that all security checks passes , perform the operation as ourselves . final long identity = Binder . clearCallingIdentity ( ) ; try { if ( iccId == null ) { if ( DBG ) logdl ( " [ addSubInfoRecord ] - null iccId" ) ; return - 1 ; } ContentResolver resolver = mContext . getContentResolver ( ) ; Cursor cursor = resolver . query ( SubscriptionManager . CONTENT_URI , new String [ ] { SubscriptionManager . UNIQUE_KEY_SUBSCRIPTION_ID , SubscriptionManager . SIM_SLOT_INDEX , SubscriptionManager . NAME_SOURCE } , SubscriptionManager . ICC_ID + " = ? " , new String [ ] { iccId } , null ) ; int color = getUnusedColor ( mContext . getOpPackageName ( ) ) ; boolean setDisplayName = false ; try { if ( cursor == null || ! cursor . moveToFirst ( ) ) { setDisplayName = true ; ContentValues value = new ContentValues ( ) ; < |startfocus| > value . put ( SubscriptionManager . SIM_SLOT_INDEX , slotId ) ; < |endfocus| > value . put ( SubscriptionManager . COLOR , color ) ; value . put ( SubscriptionManager . NUMBER , SubscriptionInfo . DEFAULT_NUMBER ) ; value . put ( SubscriptionManager . DISPLAY_NAME , SubscriptionInfo . DEFAULT_NAME ) ; value . put ( SubscriptionManager . CARRIER_NAME , SubscriptionInfo . DEFAULT_NAME ) ; value . put ( SubscriptionManager . NAME_SOURCE , SubscriptionManager . NAME_SOURCE_DEFAULT_SOURCE ) ; value . put ( SubscriptionManager . ICC_ID , iccId ) ; value . put ( SubscriptionManager . MCC , Integer . MAX_VALUE ) ; value . put ( SubscriptionManager . MNC , Integer . MAX_VALUE ) ; value . put ( SubscriptionManager . DATA_ROAMING , SubscriptionManager . DATA_ROAMING_DEFAULT ) ; value . put ( SubscriptionManager . IS_EMBEDDED , 1 ) ; value . put ( SubscriptionManager . IS_OPPORTUNISTIC , 0 ) ; value . put ( SubscriptionManager . IS_METERED , SubscriptionManager . IS_METERED_DEFAULT ) ; value . put ( SubscriptionManager . GROUP_UUID , UUID . randomUUID ( ) . toString ( ) ) ; value . put ( SubscriptionManager . GROUP_OWNER , mContext . getOpPackageName ( ) ) ; value . put ( SubscriptionManager . GROUP_SUMMARY , 1 ) ; value . put ( SubscriptionManager . IS_ACTIVE , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SMS_APP , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_DATA_SUBSCRIPTION , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_VOICE_SUBSCRIPTION , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_EMERGENCY_SUBSCRIPTION , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_CARRIER_SELECTION_SUBSCRIPTION , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_CARRIER_SUBSCRIPTION , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_DATA_ROAMING_SUBSCRIPTION , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_VOICE_ROAMING_SUBSCRIPTION , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SMS_ROAMING_SUBSCRIPTION , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_SLOT , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_CARD , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_CALL , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_SMS , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_DATA , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_EMERGENCY , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_CARRIER_SELECTION , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_CARRIER , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_DATA_ROAMING , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_VOICE_ROAMING , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_SMS_ROAMING , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_CALL_ROAMING , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_CALL_EMERGENCY , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_SMS_EMERGENCY , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_DATA_EMERGENCY , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_CALL_CARRIER_SELECTION , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_SMS_CARRIER_SELECTION , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_DATA_CARRIER_SELECTION , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_CALL_CARRIER , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_SMS_CARRIER , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_DATA_CARRIER , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_CALL_DATA_ROAMING , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_SMS_DATA_ROAMING , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_CALL_VOICE_ROAMING , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_SMS_VOICE_ROAMING , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_CALL_SMS_ROAMING , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_CALL_CALL_ROAMING , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_SMS_CALL_ROAMING , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_CALL_SMS_EMERGENCY , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR_CALL_CALL_EMERGENCY , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUBSCRIPTION_FOR
public int addSubInfoRecord ( String iccId , int slotId ) { if ( DBG ) logdl ( " [ addSubInfoRecord ] + iccId : " + SubscriptionInfo . givePrintableIccid ( iccId ) + < |startfocus| > " slotId : " + slotId ) ; < |endfocus| > enforceModifyPhoneState ( "addSubInfoRecord" ) ; // Now that all security checks passes , perform the operation as ourselves . final long identity = Binder . clearCallingIdentity ( ) ; try { if ( iccId == null ) { if ( DBG ) logdl ( " [ addSubInfoRecord ] - null iccId" ) ; return - 1 ; } ContentResolver resolver = mContext . getContentResolver ( ) ; Cursor cursor = resolver . query ( SubscriptionManager . CONTENT_URI , new String [ ] { SubscriptionManager . UNIQUE_KEY_SUBSCRIPTION_ID , SubscriptionManager . SIM_SLOT_INDEX , SubscriptionManager . NAME_SOURCE } , SubscriptionManager . ICC_ID + " = ? " , new String [ ] { iccId } , null ) ; int color = getUnusedColor ( mContext . getOpPackageName ( ) ) ; boolean setDisplayName = false ; try { if ( cursor == null || ! cursor . moveToFirst ( ) ) { setDisplayName = true ; ContentValues value = new ContentValues ( ) ; < |startfocus| > value . put ( SubscriptionManager . SIM_SLOT_INDEX , slotId ) ; < |endfocus| > value . put ( SubscriptionManager . COLOR , color ) ; value . put ( SubscriptionManager . NUMBER , SubscriptionInfo . DEFAULT_PHONE_NUMBER ) ; value . put ( SubscriptionManager . DISPLAY_NAME , SubscriptionInfo . DEFAULT_DISPLAY_NAME ) ; value . put ( SubscriptionManager . CARRIER_NAME , SubscriptionInfo . DEFAULT_CARRIER_NAME ) ; value . put ( SubscriptionManager . NAME_SOURCE , SubscriptionManager . NAME_SOURCE_DEFAULT_SOURCE ) ; value . put ( SubscriptionManager . ICC_ID , iccId ) ; value . put ( SubscriptionManager . MCC , Integer . MAX_VALUE ) ; value . put ( SubscriptionManager . MNC , Integer . MAX_VALUE ) ; value . put ( SubscriptionManager . DATA_ROAMING , SubscriptionManager . DATA_ROAMING_DEFAULT ) ; value . put ( SubscriptionManager . IS_EMBEDDED , 1 ) ; value . put ( SubscriptionManager . IS_OPPORTUNISTIC , 0 ) ; value . put ( SubscriptionManager . IS_METERED , SubscriptionManager . IS_METERED_DEFAULT ) ; value . put ( SubscriptionManager . GROUP_UUID , UUID . randomUUID ( ) . toString ( ) ) ; value . put ( SubscriptionManager . GROUP_OWNER , mContext . getOpPackageName ( ) ) ; value . put ( SubscriptionManager . GROUP_SUMMARY , 1 ) ; value . put ( SubscriptionManager . IS_ACTIVE , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_NAME , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_SLOT_ID , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_SLOT_INDEX , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_ID , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_UUID , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_OWNER , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_SUMMARY , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_ACTIVE , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_METERED , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_OPPORTUNISTIC , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_EMBEDDED , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_PROVISIONED , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SWITCHABLE , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_REMOVABLE , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_VISIBLE , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_MODIFIABLE , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_ADDED , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_REMOVED , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_VISIBLE , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_MODIFIABLE , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_ADDED , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_REMOVED , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_SWITCHABLE , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_REMOVABLE , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_PROVISIONED , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_METERED , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_OPPORTUNISTIC , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_EMBEDDED , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_ROAMING , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_NETWORK_LOCKED , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_DATA_ROAMING , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_VOICE_ROAMING , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED_DATA_ROAMING_DISABLED , 1 ) ; value . put ( SubscriptionManager . IS_DEFAULT_SUB_ID_GROUP_IS_USER_SELECTED
import com . android . internal . telephony . Phone ; import com . android . internal . telephony . PhoneConstants ; import com . android . internal . telephony . SubscriptionController ; import com . android . internal . telephony . TelephonyIntents ; import java . io . FileDescriptor ; import java . io . PrintWriter ; import java . util . concurrent . atomic . AtomicInteger ; import java . util . List ; // must extend SubscriptionController as some people use it directly within - process public class SubscriptionControllerMock extends SubscriptionController { final AtomicInteger mDefaultDataSubId = new AtomicInteger ( INVALID_SUBSCRIPTION_ID ) ; final ITelephonyRegistry . Stub mTelephonyRegistry ; < |startfocus| > final int [ ] [ ] mSlotIdxToSubId ; < |endfocus| > public static SubscriptionController init ( Phone phone ) { throw new RuntimeException ( "not implemented" ) ; } public static SubscriptionController init ( Context c , CommandsInterface [ ] ci ) { throw new RuntimeException ( "not implemented" ) ; } public static SubscriptionController getInstance ( ) { throw new RuntimeException ( "not implemented" ) ; } public SubscriptionControllerMock ( Context c , ITelephonyRegistry . Stub tr , int phoneCount ) { super ( c ) ; mTelephonyRegistry = tr ; mSlotIdxToSubId = new int [ phoneCount ] [ ] ;
< |startfocus| > public SubscriptionInfo getActiveSubscriptionInfoForSimSlotIndex ( int slotIdx , String callingPackage ) { < |endfocus| > throw new RuntimeException ( "not implemented" ) ;
< |startfocus| > private boolean isInvalidSlotId ( int slotIdx ) { if ( slotIdx < 0 || slotIdx >= mSlotIdxToSubId . length ) return true ; return false ; < |endfocus| >
< |startfocus| > public int [ ] getSubId ( int slotIdx ) { if ( isInvalidSlotId ( slotIdx ) ) { < |endfocus| > return null ; } return mSlotIdxToSubId [ slotIdx ] ;
< |startfocus| > public void setSlotSubId ( int slotIdx , int subId ) { if ( isInvalidSlotId ( slotIdx ) ) { throw new RuntimeException ( "invalid slot specified" + slotIdx ) ; < |endfocus| > } if ( mSlotIdxToSubId [ slotIdx ] [ 0 ] != subId ) { mSlotIdxToSubId [ slotIdx ] [ 0 ] = subId ; try { mTelephonyRegistry . notifySubscriptionInfoChanged ( ) ; } catch ( RemoteException ex ) { } }
< |startfocus| > public SubscriptionInfo getActiveSubscriptionInfoForSimSlotIndex ( int slotIdx , < |endfocus| > String callingPackage ) { if ( ! canReadPhoneState ( callingPackage , "getActiveSubscriptionInfoForSimSlotIndex" ) ) { return null ; } // Now that all security checks passes , perform the operation as ourselves . final long identity = Binder . clearCallingIdentity ( ) ; try { List < SubscriptionInfo > subList = getActiveSubscriptionInfoList ( mContext . getOpPackageName ( ) ) ; if ( subList != null ) { for ( SubscriptionInfo si : subList ) { if ( si . getSimSlotIndex ( ) == slotIdx ) { if ( DBG ) { logd ( " [ getActiveSubscriptionInfoForSimSlotIndex ] + slotIdx = " + slotIdx + " subId = " + si ) ; } return si ; } } if ( DBG ) { logd ( " [ getActiveSubscriptionInfoForSimSlotIndex ] + slotIdx = " + slotIdx + " subId = null" ) ; } } else { if ( DBG ) { logd ( " [ getActiveSubscriptionInfoForSimSlotIndex ] + subList = null" ) ; } } } finally { Binder . restoreCallingIdentity ( identity ) ; }
< |startfocus| > public int [ ] getSubId ( int slotIdx ) { if ( VDBG ) printStackTrace ( " [ getSubId ] + slotIdx = " + slotIdx ) ; < |endfocus| > // Map default slotIdx to the current default subId . // TODO : Not used anywhere sp consider deleting as it's somewhat nebulous // as a slot maybe used for multiple different type of "connections" // such as : voice , data and sms . But we're doing the best we can and using // getDefaultSubId which makes a best guess . if ( slotIdx == SubscriptionManager . DEFAULT_SIM_SLOT_INDEX ) { slotIdx = getSlotId ( getDefaultSubId ( ) ) ; if ( VDBG ) logd ( " [ getSubId ] map default slotIdx = " + slotIdx ) ; } // Check that we have a valid SlotIdx if ( ! SubscriptionManager . isValidSlotId ( slotIdx ) ) { if ( DBG ) logd ( " [ getSubId ] - invalid slotIdx = " + slotIdx ) ; return null ; } // Check if we've got any SubscriptionInfo records using slotIdToSubId as a surrogate . int size = sSlotIdxToSubId . size ( ) ;
< |startfocus| > private int [ ] getDummySubIds ( int slotIdx ) { < |endfocus| > // FIXME : Remove notion of Dummy SUBSCRIPTION_ID . // I tested this returning null as no one appears to care , // but no connection came up on sprout with two sims . // We need to figure out why and hopefully remove DummySubsIds ! ! ! int numSubs = getActiveSubInfoCountMax ( ) ; if ( numSubs > 0 ) { int [ ] dummyValues = new int [ numSubs ] ; for ( int i = 0 ; i < numSubs ; i ++ ) { dummyValues [ i ] = SubscriptionManager . DUMMY_SUBSCRIPTION_ID_BASE - slotIdx ; } if ( VDBG ) { logd ( "getDummySubIds : slotIdx = " + slotIdx + " return " + numSubs + " DummySubIds with each subId = " + dummyValues [ 0 ] ) ; } return dummyValues ; } else { return null ; }
pw . println ( " defaultDataPhoneId = " + SubscriptionManager . from ( mContext ) . getDefaultDataPhoneId ( ) ) ; pw . println ( " defaultVoicePhoneId = " + SubscriptionManager . getDefaultVoicePhoneId ( ) ) ; pw . println ( " defaultSmsPhoneId = " + SubscriptionManager . from ( mContext ) . getDefaultSmsPhoneId ( ) ) ; pw . flush ( ) ; < |startfocus| > for ( Entry < Integer , Integer > entry : sSlotIdxToSubId . entrySet ( ) ) { pw . println ( " sSlotIdxToSubId [ " + entry . getKey ( ) + " ] : subId = " + entry . getValue ( ) ) ; < |endfocus| > } pw . flush ( ) ; pw . println ( " ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ " ) ; List < SubscriptionInfo > sirl = getActiveSubscriptionInfoList ( mContext . getOpPackageName ( ) ) ; if ( sirl != null ) { pw . println ( " ActiveSubInfoList : " ) ; for ( SubscriptionInfo entry : sirl ) { pw . println ( " " + entry . toString ( ) ) ; } } else { pw . println ( " ActiveSubInfoList : is null" ) ; } pw . flush ( ) ; pw . println ( " ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ " ) ; sirl = getAllSubInfoList ( mContext . getOpPackageName ( ) ) ; if ( sirl != null ) { pw . println ( " AllSubInfoList : " ) ; for ( SubscriptionInfo entry : sirl ) { pw . println ( " " + entry . toString ( ) ) ; } } else { pw . println ( " AllSubInfoList : is null" ) ; } pw . flush ( ) ; pw . println ( " ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ " ) ;
import com . android . internal . telephony . Phone ; import com . android . internal . telephony . PhoneConstants ; import com . android . internal . telephony . SubscriptionController ; import com . android . internal . telephony . TelephonyIntents ; import java . io . FileDescriptor ; import java . io . PrintWriter ; import java . util . concurrent . atomic . AtomicInteger ; import java . util . List ; // must extend SubscriptionController as some people use it directly within - process public class SubscriptionControllerMock extends SubscriptionController { final AtomicInteger mDefaultDataSubId = new AtomicInteger ( INVALID_SUBSCRIPTION_ID ) ; final ITelephonyRegistry . Stub mTelephonyRegistry ; < |startfocus| > final int [ ] [ ] mSlotIdxToSubId ; < |endfocus| > public static SubscriptionController init ( Phone phone ) { throw new RuntimeException ( "not implemented" ) ; } public static SubscriptionController init ( Context c , CommandsInterface [ ] ci ) { throw new RuntimeException ( "not implemented" ) ; } public static SubscriptionController getInstance ( ) { throw new RuntimeException ( "not implemented" ) ; } public SubscriptionControllerMock ( Context c , ITelephonyRegistry . Stub tr , int phoneCount ) { super ( c ) ; mTelephonyRegistry = tr ; mSlotIdxToSubId = new int [ phoneCount ] [ ] ;
< |startfocus| > public SubscriptionInfo getActiveSubscriptionInfoForSimSlotIndex ( int slotIdx , String cp ) { < |endfocus| > throw new RuntimeException ( "not implemented" ) ;
< |startfocus| > private boolean isInvalidSlotId ( int slotIdx ) { if ( slotIdx < 0 || slotIdx >= mSlotIdxToSubId . length ) return true ; return false ; < |endfocus| >
< |startfocus| > public void setSlotSubId ( int slotIdx , int subId ) { if ( isInvalidSlotId ( slotIdx ) ) { throw new RuntimeException ( "invalid slot specified" + slotIdx ) ; < |endfocus| > } if ( mSlotIdxToSubId [ slotIdx ] [ 0 ] != subId ) { mSlotIdxToSubId [ slotIdx ] [ 0 ] = subId ; try { mTelephonyRegistry . notifySubscriptionInfoChanged ( ) ; } catch ( RemoteException ex ) { } } < |startfocus| >
private static String getEtwsPrimaryMessage ( Context context , int category ) { < |startfocus| > final Resources r = context . getResources ( ) ; < |endfocus| > switch ( category ) { case ETWS_WARNING_TYPE_EARTHQUAKE : return r . getString ( R . string . etws_primary_default_message_earthquake ) ; case ETWS_WARNING_TYPE_TSUNAMI : return r . getString ( R . string . etws_primary_default_message_tsunami ) ; case ETWS_WARNING_TYPE_EARTHQUAKE_AND_TSUNAMI : return r . getString ( R . string . etws_primary_default_message_earthquake_and_tsunami ) ; case ETWS_WARNING_TYPE_TEST_MESSAGE : return r . getString ( R . string . etws_primary_default_message_test ) ; case ETWS_WARNING_TYPE_OTHER_EMERGENCY : return r . getString ( R . string . etws_primary_default_message_others ) ; default : return "" ; }
* * @param subId The subscription ID * @return true if the network for the subscription is roaming , false otherwise */ public boolean isNetworkRoaming ( int subId ) { final int phoneId = getPhoneId ( subId ) ; if ( phoneId < 0 ) { // What else can we do ? return false ; } return TelephonyManager . getDefault ( ) . isNetworkRoaming ( subId ) ; } /* * < |startfocus| > * Returns a constant indicating the state of sim for the slot idx . < |endfocus| > * * @param slotIndex * * { @See TelephonyManager#SIM_STATE_UNKNOWN } * { @See TelephonyManager#SIM_STATE_ABSENT } * { @See TelephonyManager#SIM_STATE_PIN_REQUIRED } * { @See TelephonyManager#SIM_STATE_PUK_REQUIRED } * { @See TelephonyManager#SIM_STATE_NETWORK_LOCKED } * { @See TelephonyManager#SIM_STATE_READY } * { @See TelephonyManager#SIM_STATE_NOT_READY } * { @See TelephonyManager#SIM_STATE_PERM_DISABLED } * { @See TelephonyManager#SIM_STATE_CARD_IO_ERROR } * * { @hide } */
ServiceStateTable . DATA_OPERATOR_NUMERIC , ServiceStateTable . IS_MANUAL_NETWORK_SELECTION , ServiceStateTable . RIL_VOICE_RADIO_TECHNOLOGY , ServiceStateTable . RIL_DATA_RADIO_TECHNOLOGY , ServiceStateTable . CSS_INDICATOR , ServiceStateTable . NETWORK_ID , ServiceStateTable . SYSTEM_ID , ServiceStateTable . CDMA_ROAMING_INDICATOR , ServiceStateTable . CDMA_DEFAULT_ROAMING_INDICATOR , ServiceStateTable . CDMA_ERI_ICON_INDEX , ServiceStateTable . CDMA_ERI_ICON_MODE , ServiceStateTable . IS_EMERGENCY_ONLY , ServiceStateTable . IS_DATA_ROAMING_FROM_REGISTRATION , ServiceStateTable . IS_USING_CARRIER_AGGREGATION , } ; @Override < |startfocus| > public boolean onCreate ( ) { < |endfocus| > return true ; } @Override public Uri insert ( Uri uri , ContentValues values ) { throw new RuntimeException ( "Not supported" ) ; } @Override public int delete ( Uri uri , String selection , String [ ] selectionArgs ) { throw new RuntimeException ( "Not supported" ) ; } @Override public int update ( Uri uri , ContentValues values , String selection , String [ ] selectionArgs ) { throw new RuntimeException ( "Not supported" ) ; } @Override public String getType ( Uri uri ) { if ( ServiceStateTable . CONTENT_URI . equals ( uri ) ) {
voice_operator_numeric , data_operator_alpha_long , data_operator_alpha_short , data_operator_numeric , is_manual_network_selection , ril_voice_radio_technology , ril_data_radio_technology , css_indicator , network_id , system_id , cdma_roaming_indicator , cdma_default_roaming_indicator , cdma_eri_icon_index , cdma_eri_icon_mode , is_emergency_only , is_data_roaming_from_registration , is_using_carrier_aggregation , } ) ; } < |startfocus| > throw new IllegalArgumentException ( "Invalid URI : " + uri ) ; < |endfocus| >
MESSAGE_FORMAT , MESSAGE_PRIORITY , ETWS_WARNING_TYPE , CMAS_MESSAGE_CLASS , CMAS_CATEGORY , CMAS_RESPONSE_TYPE , CMAS_SEVERITY , CMAS_URGENCY , CMAS_CERTAINTY } ; } /* * * Constants for interfacing with the ServiceStateProvider and the different fields of the * ServiceState class accessible through the provider */ public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri . parse ( "content :/ / service - state / " ) ; < |startfocus| > /* * * The MIME - type of { @link #CONTENT_URI } . */ public static final String CONTENT_TYPE = "vnd . android . cursor . dir / service_state" ; < |endfocus| > /* * * Used to push and receive updates to a field in the ServiceState for a given subId * @param field the ServiceState field to receive updates on * @param subId the subId to receive updates on * @return the Uri that will be notified by ServiceStateTracker */ public static Uri getUriForSubId ( String field , int subId ) {
CMAS_RESPONSE_TYPE , CMAS_SEVERITY , CMAS_URGENCY , CMAS_CERTAINTY } ; } /* * * Constants for interfacing with the ServiceStateProvider and the different fields of the * ServiceState class accessible through the provider */ public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri . parse ( "content :/ / service - state / " ) ; /* * * The MIME - type of { @link #CONTENT_URI } . */ public static final String CONTENT_TYPE = "vnd . android . cursor . dir / service_state" ; /* * * Used to push and receive updates to a field in the ServiceState for a given subId * @param field the ServiceState field to receive updates on * @param subId the subId to receive updates on * @return the Uri that will be notified by ServiceStateTracker */ public static Uri getUriForSubId ( String field , int subId ) { return CONTENT_URI . buildUpon ( ) . appendEncodedPath ( String . valueOf ( subId ) ) . appendEncodedPath ( field ) . build ( ) ; }
< |startfocus| > public static Uri getUriForSubId ( String field , int subId ) { < |endfocus| > return CONTENT_URI . buildUpon ( ) . appendEncodedPath ( String . valueOf ( subId ) ) . appendEncodedPath ( field ) . build ( ) ;
+ something . getClass ( ) . getName ( ) + " to byte array ! " ) ; } } public AdvertiseData buildAdvData ( JSONObject params ) throws Exception { AdvertiseData . Builder builder = new AdvertiseData . Builder ( ) ; Iterator < String > keys = params . keys ( ) ; while ( keys . hasNext ( ) ) { String key = keys . next ( ) ; < |startfocus| > /* * python don't have multi map , if advertise data should repeat use serviceUuid , * serviceUuid2 , serviceUuid3 . . . . For that use "startsWith" */ < |endfocus| > if ( key . startsWith ( "manufacturerData" ) ) { JSONArray manuf = params . getJSONArray ( key ) ; int manufId = manuf . getInt ( 0 ) ; byte [ ] data = somethingToByteArray ( manuf . get ( 1 ) ) ; builder . addManufacturerData ( manufId , data ) ; } else if ( key . startsWith ( "serviceData" ) ) { JSONArray serDat = params . getJSONArray ( key ) ; ParcelUuid uuid = ParcelUuid . fromString ( serDat . getString ( 0 ) ) ; byte [ ] data = somethingToByteArray ( serDat . get ( 1 ) ) ; builder . addServiceData ( uuid , data ) ; } else if ( key . startsWith ( "serviceUuid" ) ) { < |startfocus| > /* * python don't have multi map , if advertise data should repeat use serviceUuid , * serviceUuid2 , serviceUuid3 . . . . For that use "startsWith" */ < |endfocus| >
+ something . getClass ( ) . getName ( ) + " to byte array ! " ) ; } } public AdvertiseData buildAdvData ( JSONObject params ) throws Exception { AdvertiseData . Builder builder = new AdvertiseData . Builder ( ) ; Iterator < String > keys = params . keys ( ) ; while ( keys . hasNext ( ) ) { String key = keys . next ( ) ; < |startfocus| > /* * python don't have multi map , if advertise data should repeat use serviceUuid , * serviceUuid2 , serviceUuid3 . . . . For that use "startsWith" */ < |endfocus| > if ( key . startsWith ( "manufacturerData" ) ) { JSONArray manuf = params . getJSONArray ( key ) ; int manufId = manuf . getInt ( 0 ) ; byte [ ] data = somethingToByteArray ( manuf . get ( 1 ) ) ; builder . addManufacturerData ( manufId , data ) ; } else if ( key . startsWith ( "serviceData" ) ) { JSONArray serDat = params . getJSONArray ( key ) ; ParcelUuid uuid = ParcelUuid . fromString ( serDat . getString ( 0 ) ) ; byte [ ] data = somethingToByteArray ( serDat . get ( 1 ) ) ; builder . addServiceData ( uuid , data ) ; } else if ( key . startsWith ( "serviceUuid" ) ) { < |startfocus| > /* * python don't have multi map , if advertise data should repeat use serviceUuid , * serviceUuid2 , serviceUuid3 . . . . For that use "startsWith" */ < |endfocus| >
public PeriodicAdvertisingParameters buildPeriodicParameters ( JSONObject params ) throws Exception { PeriodicAdvertisingParameters . Builder builder = new PeriodicAdvertisingParameters . Builder ( ) ; Iterator < String > keys = params . keys ( ) ; while ( keys . hasNext ( ) ) { String key = keys . next ( ) ; if ( key . equals ( "enable" ) ) { builder . setEnable ( params . getBoolean ( key ) ) ; } else if ( key . equals ( "includeTxPower" ) ) { builder . setIncludeTxPower ( params . getBoolean ( key ) ) ; < |startfocus| > } else if ( key . equals ( "interval" ) ) { < |endfocus| > builder . setInterval ( params . getInt ( key ) ) ; } else { throw new IllegalArgumentException ( "Unknown PeriodicAdvertisingParameters field " + key ) ; } } return builder . build ( ) ; } /* * * Starts ble advertising * * @throws Exception */ @Rpc ( description = "Starts ble advertisement" ) public void bleAdvSetStartAdvertisingSet ( @RpcParameter ( name = "params" ) JSONObject parametersJson , @RpcParameter ( name = "data" ) JSONObject dataJson , @RpcParameter ( name = "scanResponse" ) JSONObject scanResponseJson , @RpcParameter ( name = "periodicParameters" ) JSONObject periodicParametersJson ,
< |startfocus| > public void useAnyBssidForConnectionIfFirmwareControlsRoaming ( ) { < |endfocus| > // Firmware controls roaming when ( mWifiConnectivityHelper . isFirmwareRoamingSupported ( ) ) . thenReturn ( true ) ; // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; // Set WiFi to disconnected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; verify ( mWifiStateMachine ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , WifiStateMachine . SUPPLICANT_BSSID_ANY ) ;
private int readHighTagNumber ( ) throws BerDataValueFormatException { // Base - 128 big - endian form , where each byte has the highest bit set , except for the last // byte int b ; int result = 0 ; do { if ( ! mBuf . hasRemaining ( ) ) { throw new BerDataValueFormatException ( "Truncated tag number" ) ; } b = mBuf . get ( ) ; result < <= 7 ; result += b & 0x7f ; if ( result < 0 ) { throw new BerDataValueFormatException ( "Tag number too large" ) ; } } while ( ( b & 0x80 ) != 0 ) ; return result ; } private int readShortFormLength ( int firstLengthByte ) throws BerDataValueFormatException { return firstLengthByte & 0x7f ; } private int readLongFormLength ( int firstLengthByte ) throws BerDataValueFormatException { // The low 7 bits of the first byte represent the number of bytes ( following the first // byte ) in which the length is in big - endian base - 256 form int byteCount = firstLengthByte & 0x7f ;
"Truncated indefinite - length contents : " + bytesRead + " bytes read" ) ; } int b = mBuf . get ( ) ; bytesRead ++ ; if ( bytesRead < 0 ) { throw new BerDataValueFormatException ( "Indefinite - length contents too long" ) ; } if ( b == 0 ) { if ( prevZeroByte ) { // End of contents reached -- we've read the value and its terminator 0x00 0x00 return bytesRead - 2 ; } prevZeroByte = true ; < |startfocus| > continue ; < |endfocus| > } else { prevZeroByte = false ; } } } }
* Copyright ( C ) 2016 The Android Open Source Project * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . android . rs . rsov . test ; import android . content . Context ; import android . renderscript . Allocation ; import android . renderscript . Element ; import android . renderscript . RenderScript ; import android . renderscript . Type ; import android . util . Log ; public class UT_global_query extends UnitTest { protected UT_global_query ( RSoVTestCore rstc , Context ctx ) { super ( rstc , "global_query" , ctx ) ; }
req . channelRequestType = channelRequestType ; req . channel = channel ; req . ifaceName = interfaceName ; req . securityRequired = ! ( ( pmk == null || pmk . length == 0 ) && ( passphrase == null || passphrase . length ( ) == 0 ) ) ; if ( req . securityRequired ) { req . cipherType = getStrongestCipherSuiteType ( capabilities . supportedCipherSuites ) ; if ( pmk != null && pmk . length != 0 ) { convertByteArrayToArrayList ( pmk , req . pmk ) ; } else { convertByteArrayToArrayList ( passphrase . getBytes ( ) , req . passphrase ) ; } < |startfocus| > } < |endfocus| > try { WifiStatus status = iface . initiateDataPathRequest ( transactionId , req ) ; if ( status . code == WifiStatusCode . SUCCESS ) { return true ; } else { Log . e ( TAG , "initiateDataPath : error : " + statusString ( status ) ) ; return false ; } } catch ( RemoteException e ) { Log . e ( TAG , "initiateDataPath : exception : " + e ) ; return false ; }
import java . io . IOException ; import java . util . concurrent . atomic . AtomicReference ; public class ToyVpnService extends VpnService implements Handler . Callback , ToyVpnConnection . Listener { private static final String TAG = ToyVpnService . class . getSimpleName ( ) ; public static final String ACTION_CONNECT = "com . example . android . toyvpn . START" ; public static final String ACTION_DISCONNECT = "com . example . android . toyvpn . STOP" ; private Handler mHandler ; < |startfocus| > private SparseArray < Thread > mThreads = new SparseArray < > ( ) ; private int mNextConnectionId = 1 ; < |endfocus| > private AtomicReference < ParcelFileDescriptor > mTunnelInterface = new AtomicReference < > ( ) ; private PendingIntent mConfigureIntent ; @Override public void onCreate ( ) { // The handler is only used to show messages . if ( mHandler == null ) { mHandler = new Handler ( this ) ; } // Create the intent to "configure" the connection ( just start ToyVpnClient ) . mConfigureIntent = PendingIntent . getActivity ( this , 0 , new Intent ( this , ToyVpnClient . class ) , PendingIntent . FLAG_UPDATE_CURRENT ) ; } @Override
public int onStartCommand ( Intent intent , int flags , int startId ) { if ( ACTION_DISCONNECT . equals ( intent . getAction ( ) ) ) { disconnect ( ) ; } else { connect ( ) ; } < |startfocus| > return START_STICKY ; < |endfocus| >
public boolean handleMessage ( Message message ) { < |startfocus| > if ( message != null ) { Toast . makeText ( this , message . what , Toast . LENGTH_SHORT ) . show ( ) ; if ( ! message . what . equals ( R . string . disconnected ) ) { updateForegroundNotification ( message . what ) ; } < |endfocus| > } return true ;
} final ParcelFileDescriptor oldInterface = mTunnelInterface . getAndSet ( tunInterface ) ; if ( oldInterface != null ) { try { Log . i ( TAG , "Closing interface : " + oldInterface ) ; oldInterface . close ( ) ; } catch ( IOException e ) { Log . e ( TAG , "Closing interface failed" , e ) ; } } } @Override public synchronized void onDisconnect ( int connectionId ) { mThreads . remove ( connectionId ) ; } @Override public void onRevoke ( ) { disconnect ( ) ; } < |startfocus| > private void connect ( ) { < |endfocus| > // Become a foreground service . Background services can be VPN services too , but they can // be killed by background check before getting a chance to receive onRevoke ( ) . updateForegroundNotification ( R . string . connecting ) ; mHandler . sendEmptyMessage ( R . string . connecting ) ; final SharedPreferences prefs = getSharedPreferences ( ToyVpnClient . Prefs . NAME , MODE_PRIVATE ) ; final ToyVpnConnection connection ; try { // Extract information from the shared preferences . connection = new ToyVpnConnection ( this , this , mNextConnectionId , prefs . getString ( ToyVpnClient . Prefs . SERVER_ADDRESS , "" ) ,
import org . junit . After ; import org . junit . Before ; import org . junit . Test ; import org . junit . runner . RunWith ; import org . mockito . ArgumentCaptor ; import org . mockito . Mock ; import org . mockito . MockitoAnnotations ; import static android . Manifest . permission . MODIFY_PHONE_STATE ; import static android . Manifest . permission . READ_PHONE_STATE ; import static com . android . internal . telephony . ims . ImsResolver . SERVICE_INTERFACE ; import static junit . framework . Assert . assertEquals ; import static junit . framework . Assert . assertNotNull ; import static junit . framework . Assert . assertNull ; import static junit . framework . Assert . fail ; < |startfocus| > import static org . mockito . Matchers . any ; < |endfocus| > import static org . mockito . Matchers . anyInt ; import static org . mockito . Matchers . anyString ; import static org . mockito . Matchers . eq ; import static org . mockito . Matchers . nullable ; import static org . mockito . Mockito . doThrow ; import static org . mockito . Mockito . never ; import static org . mockito . Mockito . times ; import static org . mockito . Mockito . verify ; import static org . mockito . Mockito . when ; /* * * Unit tests for ImsService */ @RunWith ( AndroidJUnit4 . class ) public class ImsServiceTest { private static final int TEST_SLOT_0 = 0 ; private static final int TEST_SLOT_1 = 1 ; private static final int TEST_SLOT_2 = 2 ;
// Mock the HeadsetService when ( mockServiceFactory . getHeadsetService ( ) ) . thenReturn ( mockHeadsetService ) ; when ( mockHeadsetService . getPriority ( device ) ) . thenReturn ( BluetoothProfile . PRIORITY_UNDEFINED ) ; // Mock the A2DP service when ( mockServiceFactory . getA2dpService ( ) ) . thenReturn ( mockA2dpService ) ; when ( mockA2dpService . getPriority ( device ) ) . thenReturn ( BluetoothProfile . PRIORITY_UNDEFINED ) ; // Mock the looper when ( mockAdapterService . getMainLooper ( ) ) . thenReturn ( mHandlerThread . getLooper ( ) ) ; < |startfocus| > // Tell the adapterservice that it is a mock ( see isMock documentation ) < |endfocus| > when ( mockAdapterService . isMock ( ) ) . thenReturn ( true ) ; PhonePolicy phPol = new PhonePolicy ( mockAdapterService , mockServiceFactory ) ; // Get the broadcast receiver to inject events . BroadcastReceiver injector = phPol . getBroadcastReceiver ( ) ; // Inject an event for UUIDs updated for a remote device with only HFP enabled Intent intent = new Intent ( BluetoothDevice . ACTION_UUID ) ; intent . putExtra ( BluetoothDevice . EXTRA_DEVICE , device ) ; ParcelUuid [ ] uuids = new ParcelUuid [ 2 ] ; uuids [ 0 ] = BluetoothUuid . Handsfree ; uuids [ 1 ] = BluetoothUuid . AudioSink ; intent . putExtra ( BluetoothDevice . EXTRA_UUID , uuids ) ;
import com . android . internal . telephony . MmiCode ; import com . android . internal . telephony . Phone ; import com . android . internal . telephony . PhoneConstants ; import java . util . List ; /* * * Used to display a dialog from within the Telephony service when running an USSD code */ public class MMIDialogActivity extends Activity { private static final String TAG = MMIDialogActivity . class . getSimpleName ( ) ; private Dialog mMMIDialog ; private Handler mHandler ; private CallManager mCM = PhoneGlobals . getInstance ( ) . getCallManager ( ) ; < |startfocus| > private Phone mPhone = PhoneGlobals . getPhone ( ) ; < |endfocus| > @Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; Intent intent = getIntent ( ) ; int subId = intent . getIntExtra ( PhoneConstants . SUBSCRIPTION_KEY , SubscriptionManager . DEFAULT_SUBSCRIPTION_ID ) ; mPhone = PhoneGlobals . getPhone ( subId ) ; mHandler = new Handler ( ) { @Override public void handleMessage ( Message msg ) { switch ( msg . what ) { case PhoneGlobals . MMI_COMPLETE : onMMIComplete ( ( MmiCode ) ( ( AsyncResult ) msg . obj ) . result ) ; break ; case PhoneGlobals . MMI_CANCEL : onMMICancel ( ) ; break ; } } } ; } @Override protected void onStart ( ) { super . onStart ( ) ; mPhone . registerForMmiComplete ( mHandler , PhoneGlobals . MMI_COMPLETE , null ) ; mPhone . registerForMmiComplete ( mHandler , PhoneGlobals . MMI_CANCEL , null ) ; } @Override protected void onStop ( ) { super . onStop ( ) ; mPhone . unregisterForMmiComplete ( mHandler ) ; } @Override protected void onDestroy ( ) { super . onDestroy ( ) ; if ( mMMIDialog != null ) { mMMIDialog . dismiss ( ) ; } } private void onMMIComplete ( MmiCode mmiCode ) { if ( DBG ) log ( "onMMIComplete : mmiCode = " + mmiCode ) ; mHandler . sendMessage ( mHandler . obtainMessage ( PhoneGlobals . MMI_COMPLETE , mmiCode ) ) ; } private void onMMICancel ( ) { if ( DBG ) log ( "onMMICancel : mmiCode = " + mPhone . getPendingMmiCodes ( ) ) ; mHandler . sendMessage ( mHandler . obtainMessage ( PhoneGlobals . MMI_CANCEL ) ) ; } private void log ( String msg ) { Log . d ( TAG , msg ) ; } }
// Firmware controls roaming when ( mWifiConnectivityHelper . isFirmwareRoamingSupported ( ) ) . thenReturn ( true ) ; // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; // Set WiFi to disconnected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; verify ( mWifiStateMachine ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , WifiStateMachine . SUPPLICANT_BSSID_ANY ) ; } /* < |startfocus| > * Firmware supports controlled roaming . * Connect to a network which has a config specified BSSID . < |endfocus| > * * Expected behavior : WifiConnectivityManager calls * WifiStateMachine . startConnectToNetwork ( ) with the * expected candidate network ID , and the BSSID value should be * 'any' since firmware controls the roaming . */ @Test public void useAnyBssidToConnectWhenFirmwareRoamingOnAndConfigHasBssidSpecified ( ) { // Firmware controls roaming when ( mWifiConnectivityHelper . isFirmwareRoamingSupported ( ) ) . thenReturn ( true ) ; // Set up the candidate configuration such that it has a BSSID specified . WifiConfiguration candidate = generateWifiConfig ( 0 , CANDIDATE_NETWORK_ID , CANDIDATE_SSID , false , true , null , null ) ;
anyBoolean ( ) , anyBoolean ( ) ) ) . thenReturn ( candidate ) ; // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; // Set WiFi to disconnected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; verify ( mWifiStateMachine ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , WifiStateMachine . SUPPLICANT_BSSID_ANY ) ; } /* < |startfocus| > * Firmware does not support controlled roaming . * Connect to a network which doesn't have a config specified BSSID . < |endfocus| > * * Expected behavior : WifiConnectivityManager calls * WifiStateMachine . startConnectToNetwork ( ) with the expected candidate network ID , * and the BSSID value should be the candidate scan result specified . */ @Test public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified ( ) { // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; // Set WiFi to disconnected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; verify ( mWifiStateMachine , atLeastOnce ( ) ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , CANDIDATE_BSSID ) ; } /*
public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified ( ) { // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; // Set WiFi to disconnected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; < |startfocus| > verify ( mWifiStateMachine , once ( ) ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , CANDIDATE_BSSID ) ; < |endfocus| >
@Test public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified ( ) { // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; // Set WiFi to disconnected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; verify ( mWifiStateMachine , atLeastOnce ( ) ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , CANDIDATE_BSSID ) ; } /* < |startfocus| > * Firmware does not support controlled roaming . * Connect to a network which has a config specified BSSID . < |endfocus| > * * Expected behavior : WifiConnectivityManager calls * WifiStateMachine . startConnectToNetwork ( ) with the expected candidate network ID , * and the BSSID value should be the config specified one . */ @Test public void useConfigSpecifiedBssidToConnectionWhenFirmwareRoamingOff ( ) { // Set up the candidate configuration such that it has a BSSID specified . WifiConfiguration candidate = generateWifiConfig ( 0 , CANDIDATE_NETWORK_ID , CANDIDATE_SSID , false , true , null , null ) ; candidate . BSSID = CANDIDATE_BSSID ; // config specified ScanResult candidateScanResult = new ScanResult ( ) ;
candidateScanResult . SSID = CANDIDATE_SSID ; candidateScanResult . BSSID = CANDIDATE_BSSID ; candidate . getNetworkSelectionStatus ( ) . setCandidate ( candidateScanResult ) ; when ( mWifiNS . selectNetwork ( anyObject ( ) , anyObject ( ) , anyObject ( ) , anyBoolean ( ) , anyBoolean ( ) , anyBoolean ( ) ) ) . thenReturn ( candidate ) ; // Set screen to on mWifiConnectivityManager . handleScreenStateChanged ( true ) ; // Set WiFi to disconnected state mWifiConnectivityManager . handleConnectionStateChanged ( WifiConnectivityManager . WIFI_STATE_DISCONNECTED ) ; < |startfocus| > verify ( mWifiStateMachine ) . startConnectToNetwork ( CANDIDATE_NETWORK_ID , CANDIDATE_BSSID ) ; < |endfocus| >
} updateAlwaysOnNotification ( detailedState ) ; } /* * * Chooses whether to force all connections to go though VPN . * * Used to enable / disable legacy VPN lockdown . This uses the same rule - based mechanism as * { @link #setAlwaysOnPackage ( String , boolean ) } ; previous settings from calling that function * will be replaced . * * @param lockdown whether to prevent all traffic outside of a VPN . */ < |startfocus| > public synchronized void setLockdown ( boolean lockdown ) { < |endfocus| > enforceControlPermissionOrInternalCaller ( ) ; // Explicitly disable previous settings from always - on app VPN if it was set up , to avoid // getting into a confusing state with both enabled at the same time . if ( mAlwaysOn ) { setAlwaysOnPackage ( null , false ) ; } // Apply the new lockdown rules . setVpnForcedLocked ( lockdown ) ; mLockdown = lockdown ; } /* * * Configures an always - on VPN connection through a specific application . * This connection is automatically granted and persisted after a reboot . *
* * @param lockdown whether to prevent all traffic outside of a VPN . */ public synchronized void setLockdownEnabled ( boolean lockdown ) { enforceControlPermissionOrInternalCaller ( ) ; // Explicitly disable previous settings from always - on app VPN if it was set up , to avoid // getting into a confusing state with both enabled at the same time . if ( mAlwaysOn && lockdown ) { setAlwaysOnPackage ( null , false ) ; } // Apply the new lockdown rules . setVpnForcedLocked ( lockdown ) ; < |startfocus| > mLockdown = lockdown ; < |endfocus| > } /* * * Configures an always - on VPN connection through a specific application . * This connection is automatically granted and persisted after a reboot . * * < p > The designated package should exist and declare a { @link VpnService } in its * manifest guarded by { @link android . Manifest . permission . BIND_VPN_SERVICE } , * otherwise the call will fail . * * @param packageName the package to designate as always - on VPN supplier . * @param lockdown whether to prevent traffic outside of a VPN , for example while connecting .
private void setVpnForcedLocked ( boolean enforce ) { < |startfocus| > setVpnForcedWithExemptionsLocked ( enforce , isNullOrLegacyVpn ( mPackage ) ? null : Collections . singletonList ( mPackage ) ) ; < |endfocus| >
private void setVpnForcedWithExemptionsLocked ( boolean enforce , @Nullable List < String > exemptedPackages ) { final Set < UidRange > removedRanges = new ArraySet < > ( mBlockedUsers ) ; final Set < UidRange > addedRanges ; if ( enforce ) { addedRanges = createUserAndRestrictedProfilesRanges ( mUserHandle , /* allowedApplications */ null , /* disallowedApplications */ exemptedPackages ) ; removedRanges . removeAll ( addedRanges ) ; addedRanges . removeAll ( mBlockedUsers ) ; < |startfocus| > } else { addedRanges = Collections . < UidRange > emptySet ( ) ; < |endfocus| > } setAllowOnlyVpnForUids ( false , removedRanges ) ; setAllowOnlyVpnForUids ( true , addedRanges ) ;
private void setVpnForcedWithExemptionsLocked ( boolean enforce , @Nullable List < String > exemptedPackages ) { final Set < UidRange > removedRanges = new ArraySet < > ( mBlockedUsers ) ; final Set < UidRange > addedRanges ; if ( enforce ) { addedRanges = createUserAndRestrictedProfilesRanges ( mUserHandle , /* allowedApplications */ null , /* disallowedApplications */ exemptedPackages ) ; removedRanges . removeAll ( addedRanges ) ; addedRanges . removeAll ( mBlockedUsers ) ; < |startfocus| > } else { addedRanges = Collections . emptySet ( ) ; < |endfocus| > } setAllowOnlyVpnForUids ( false , removedRanges ) ; setAllowOnlyVpnForUids ( true , addedRanges ) ;
* instances representing the type variable . However , all instances * representing a type variable must be equal ( ) to each other . * As a consequence , users of type variables must not rely on the identity * of instances of classes implementing this interface . * * @param < D > the type of generic declaration that declared the * underlying type variable . * * @since 1 . 5 */ < |startfocus| > // Android - changed : Removed AnnotatedElement due to excluded support for runtime type annotations public interface TypeVariable < D extends GenericDeclaration > extends Type { < |endfocus| > /* * * Returns an array of { @code Type } objects representing the * upper bound ( s ) of this type variable . Note that if no upper bound is * explicitly declared , the upper bound is { @code Object } . * * < p > For each upper bound B : < ul > < li > if B is a parameterized * type or a type variable , it is created , ( see { @link * java . lang . reflect . ParameterizedType ParameterizedType } for the * details ) . </ li > < li > Otherwise , B is resolved . </ li > </ ul > * * @return an array of { @code Type } s representing the upper * bound ( s ) of this type variable * @throws TypeNotPresentException if any of the * bounds refers to a non - existent type declaration * @throws MalformedParameterizedTypeException if any of the * bounds refer to a parameterized type that cannot be instantiated * for any reason * @since 1 . 5 */ Type [ ] getBounds ( ) ; /* * * Returns the { @code GenericDeclaration } object representing the * generic declaration declared this type variable . * * @return the generic declaration declared for this type variable . * @since 1 . 5 */ D getGenericDeclaration ( ) ; /* * * Returns the name of this type variable , as it occurs in the source code . * * @return the name of this type variable , as it appears in the source code */ String getName ( ) ; /* * * Returns an array of { @code AnnotatedType } objects that * represent the use of types to denote the upper bounds of the type * variable . * * @return an array of objects representing the upper bounds of the type * variable * @since 1 . 8 */ AnnotatedType [ ] getAnnotatedBounds ( ) ; }
* @param log WifiLog object to assign to the clientHandler */ @VisibleForTesting public void setWifiHandlerLogForTest ( WifiLog log ) { mClientHandler . setWifiLog ( log ) ; } /* * * Check if we are ready to start wifi . * < |startfocus| > * First check if we will be restarting system services to decrypt the device . If the device is * not encrypted , check if Wi - Fi needs to be enabled and start if needed * * This function is used only at boot time . < |endfocus| > */ public void checkAndStartWifi ( ) { // First check if we will end up restarting WifiService if ( mFrameworkFacade . inStorageManagerCryptKeeperBounce ( ) ) { Log . d ( TAG , "Device still encrypted . Need to restart SystemServer . Do not start wifi . " ) ; return ; } // Check if wi - fi needs to be enabled boolean wifiEnabled = mSettingsStore . isWifiToggleEnabled ( ) ; Slog . i ( TAG , "WifiService starting up with Wi - Fi " + ( wifiEnabled ? "enabled" : "disabled" ) ) ; registerForScanModeChange ( ) ;
public void testWifiControllerDoesNotStartWhenDeviceTriggerResetMainAtBoot ( ) { < |startfocus| > when ( mPropertyService . get ( eq ( "vold . decrypt" ) , anyString ( ) ) ) . thenReturn ( "trigger_reset_main" ) ; < |endfocus| > when ( mSettingsStore . isWifiToggleEnabled ( ) ) . thenReturn ( false ) ; mWifiServiceImpl . checkAndStartWifi ( ) ; verify ( mWifiController , never ( ) ) . start ( ) ;
public void testWifiControllerStartsWhenDeviceIsDecryptedAtBootWithWifiDisabled ( ) { < |startfocus| > when ( mPropertyService . get ( eq ( "vold . decrypt" ) , anyString ( ) ) ) . thenReturn ( "" ) ; < |endfocus| > when ( mSettingsStore . isWifiToggleEnabled ( ) ) . thenReturn ( false ) ; mWifiServiceImpl . checkAndStartWifi ( ) ; verify ( mWifiController ) . start ( ) ; verify ( mWifiController , never ( ) ) . sendMessage ( CMD_WIFI_TOGGLED ) ;
public void testWifiFullyStartsWhenDeviceIsDecryptedAtBootWithWifiEnabled ( ) { < |startfocus| > when ( mPropertyService . get ( eq ( "vold . decrypt" ) , anyString ( ) ) ) . thenReturn ( "" ) ; < |endfocus| > when ( mSettingsStore . handleWifiToggled ( true ) ) . thenReturn ( true ) ; when ( mSettingsStore . isWifiToggleEnabled ( ) ) . thenReturn ( true ) ; when ( mWifiStateMachine . syncGetWifiState ( ) ) . thenReturn ( WIFI_STATE_DISABLED ) ; mWifiServiceImpl . checkAndStartWifi ( ) ; verify ( mWifiController ) . start ( ) ; verify ( mWifiController ) . sendMessage ( CMD_WIFI_TOGGLED ) ;
public static final int SUP_DISCONNECTION_EVENT = BASE + 2 ; /* Network connection completed */ public static final int NETWORK_CONNECTION_EVENT = BASE + 3 ; /* Network disconnection completed */ public static final int NETWORK_DISCONNECTION_EVENT = BASE + 4 ; /* Scan results are available */ public static final int SCAN_RESULTS_EVENT = BASE + 5 ; /* Scheduled scan results are available */ public static final int SCHED_SCAN_RESULTS_EVENT = BASE + 6 ; /* Supplicate state changed */ < |startfocus| > public static final int SUPPLICANT_STATE_CHANGE_EVENT = BASE + 7 ; < |endfocus| > /* Password failure and EAP authentication failure */ public static final int AUTHENTICATION_FAILURE_EVENT = BASE + 8 ; /* WPS success detected */ public static final int WPS_SUCCESS_EVENT = BASE + 9 ; /* WPS failure detected */ public static final int WPS_FAIL_EVENT = BASE + 10 ; /* WPS overlap detected */ public static final int WPS_OVERLAP_EVENT = BASE + 11 ; /* WPS timeout detected */ public static final int WPS_TIMEOUT_EVENT = BASE + 12 ; /* WPS PBC overlap detected */ public static final int WPS_PBC_OVERLAP_EVENT = BASE + 13 ; /* WPS PBC timeout detected */ public static final int WPS_PBC_TIMEOUT_EVENT = BASE + 14 ; /* WPS PBC walktime detected */ public static final int WPS_PBC_WALK_TIMEOUT_EVENT = BASE + 15 ; /* WPS PIN detected */ public static final int WPS_PIN_REQ_EVENT = BASE + 16 ; /* WPS NFC detected */ public static final int WPS_NFC_WR_CFG_REQ_EVENT = BASE + 17 ; public static final int WPS_NFC_HO_S_EVENT = BASE + 18 ; public static final int WPS_NFC_HO_R_EVENT = BASE + 19 ; public static final int WPS_NFC_HO_NDEF_EVENT = BASE + 20 ; public static final int WPS_NFC_HO_F_EVENT = BASE + 21 ; public static final int WPS_NFC_HO_R_NDEF_EVENT = BASE + 22 ; public static final int WPS_NFC_HO_F_NDEF_EVENT = BASE + 23 ; public static final int WPS_NFC_HO_CFG_TOKEN_EVENT = BASE + 24 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_EVENT = BASE + 25 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_EVENT = BASE + 26 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_GEN_EVENT = BASE + 27 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_GEN_EVENT = BASE + 28 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_RSP_EVENT = BASE + 29 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_RSP_EVENT = BASE + 30 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_ERR_EVENT = BASE + 31 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_ERR_EVENT = BASE + 32 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_DONE_EVENT = BASE + 33 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_DONE_EVENT = BASE + 34 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_PWR_EVENT = BASE + 35 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_PWR_EVENT = BASE + 36 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_NDEF_EVENT = BASE + 37 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_NDEF_EVENT = BASE + 38 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_RSP_NDEF_EVENT = BASE + 39 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_RSP_NDEF_EVENT = BASE + 40 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_ERR_NDEF_EVENT = BASE + 41 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_ERR_NDEF_EVENT = BASE + 42 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_DONE_NDEF_EVENT = BASE + 43 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_DONE_NDEF_EVENT = BASE + 44 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_PWR_NDEF_EVENT = BASE + 45 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_PWR_NDEF_EVENT = BASE + 46 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_GEN_NDEF_EVENT = BASE + 47 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_GEN_NDEF_EVENT = BASE + 48 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_RSP_NDEF_GEN_EVENT = BASE + 49 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_RSP_NDEF_GEN_EVENT = BASE + 50 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_ERR_NDEF_GEN_EVENT = BASE + 51 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_ERR_NDEF_GEN_EVENT = BASE + 52 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_DONE_NDEF_GEN_EVENT = BASE + 53 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_DONE_NDEF_GEN_EVENT = BASE + 54 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_PWR_NDEF_GEN_EVENT = BASE + 55 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_PWR_NDEF_GEN_EVENT = BASE + 56 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_GEN_NDEF_GEN_EVENT = BASE + 57 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_GEN_NDEF_GEN_EVENT = BASE + 58 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_RSP_NDEF_GEN_GEN_EVENT = BASE + 59 ; public static final int WPS_NFC_HO_F_CFG_TOKEN_RSP_NDEF_GEN_GEN_EVENT = BASE + 60 ; public static final int WPS_NFC_HO_R_CFG_TOKEN_ERR_NDEF_GEN_GEN_EVENT = BASE + 61 ; public static final
public void OnPnoNetworkFound ( ) { Log . d ( TAG , "Pno scan result event" ) ; < |startfocus| > mWifiMonitor . broadcastPnoScanResultEvent ( mClientInterfaceName ) ; < |endfocus| >
android . provider . Settings . Global . SETUP_PREPAID_DATA_SERVICE_URL ) ) ; if ( ! isLteOnCdma || missingDataServiceUrl ) { prefSet . removePreference ( mLteDataServicePref ) ; } else { android . util . Log . d ( LOG_TAG , "keep ltePref" ) ; } // Hide enhanced 4G LTE mode settings when either it is not supported by platform or // 'KEY_HIDE_ENHANCED_4G_LTE_BOOL' is true . if ( ! ( ImsManager . isVolteEnabledByPlatform ( getActivity ( ) ) && ImsManager . isVolteProvisionedOnDevice ( getActivity ( ) ) ) < |startfocus| > || carrierConfig . getBoolean ( CarrierConfigManager . KEY_HIDE_ENHANCED_4G_LTE_BOOL ) ) { < |endfocus| > Preference pref = prefSet . findPreference ( BUTTON_4G_LTE_KEY ) ; if ( pref != null ) { prefSet . removePreference ( pref ) ; } } ActionBar actionBar = getActivity ( ) . getActionBar ( ) ; if ( actionBar != null ) { // android . R . id . home will be triggered in onOptionsItemSelected ( ) actionBar . setDisplayHomeAsUpEnabled ( true ) ; } // Enable link to CMAS app settings depending on the value in config . xml . if ( getResources ( ) . getBoolean ( R . bool . cmas_enabled ) ) { PreferenceScreen root = getPreferenceScreen ( ) ; Preference ps = new Preference ( getActivity ( ) ) ; ps . setTitle ( R . string . cmas_settings_title ) ; ps . setSummary ( R . string . cmas_settings_summary ) ; Intent intent = new Intent ( CMAS_SETTINGS_ACTION ) ; intent . setPackage ( getActivity ( ) . getPackageName ( ) ) ; ps . setIntent ( intent ) ; root . addPreference ( ps ) ; }
if ( ! isLteOnCdma || missingDataServiceUrl ) { prefSet . removePreference ( mLteDataServicePref ) ; } else { android . util . Log . d ( LOG_TAG , "keep ltePref" ) ; } // Hide enhanced 4G LTE mode settings when either it is not supported by platform or // 'KEY_HIDE_ENHANCED_4G_LTE_BOOL' is true . if ( ! ( ImsManager . isVolteEnabledByPlatform ( getActivity ( ) ) && ImsManager . isVolteProvisionedOnDevice ( getActivity ( ) ) ) < |startfocus| > || carrierConfig . getBoolean ( CarrierConfigManager . KEY_HIDE_ENHANCED_4G_LTE_BOOL ) ) { < |endfocus| > Preference pref = prefSet . findPreference ( BUTTON_4G_LTE_KEY ) ; if ( pref != null ) { prefSet . removePreference ( pref ) ; } } ActionBar actionBar = getActivity ( ) . getActionBar ( ) ; if ( actionBar != null ) { // android . R . id . home will be triggered in onOptionsItemSelected ( ) actionBar . setDisplayHomeAsUpEnabled ( true ) ; } // Enable link to CMAS app settings depending on the value in config . xml . final boolean isCellBroadcastAppLinkEnabled = getActivity ( ) . getResources ( ) . getBoolean ( R . bool . config_cellBroadcastAppLinks ) ;
assertFalse ( nc . hasCapability ( NET_CAPABILITY_INTERNET ) ) ; } @Test public void testNetworkCapabilitiesForTypeBluetooth ( ) { verifyUnrestrictedNetworkCapabilities ( ConnectivityManager . TYPE_BLUETOOTH , TRANSPORT_BLUETOOTH ) ; } @Test public void testNetworkCapabilitiesForTypeEthernet ( ) { verifyUnrestrictedNetworkCapabilities ( ConnectivityManager . TYPE_ETHERNET , TRANSPORT_ETHERNET ) ; } @Test public void testNoDoubleCallbackRegistration ( ) throws Exception { ConnectivityManager manager = new ConnectivityManager ( mCtx , mService ) ; < |startfocus| > // NetworkRequest request = new NetworkRequest . Builder ( ) . clearCapabilities ( ) . build ( ) ; NetworkRequest request = makeRequest ( 1234 ) ; < |endfocus| > NetworkCallback callback = new ConnectivityManager . NetworkCallback ( ) ; ApplicationInfo info = new ApplicationInfo ( ) ; info . targetSdkVersion = VERSION_CODES . N_MR1 + 1 ; when ( mCtx . getApplicationInfo ( ) ) . thenReturn ( info ) ; when ( mService . requestNetwork ( any ( ) , any ( ) , anyInt ( ) , any ( ) , anyInt ( ) ) ) . thenReturn ( request ) ; Handler handler = new Handler ( Looper . getMainLooper ( ) ) ; manager . requestNetwork ( request , callback , handler ) ; // Callback is already registered , reregistration should fail . Class < IllegalArgumentException > wantException = IllegalArgumentException . class ;
Handler handler = new Handler ( Looper . getMainLooper ( ) ) ; manager . requestNetwork ( request , callback , handler ) ; // Callback is already registered , reregistration should fail . Class < IllegalArgumentException > wantException = IllegalArgumentException . class ; expectThrowable ( ( ) - > manager . requestNetwork ( request , callback ) , wantException ) ; manager . unregisterNetworkCallback ( callback ) ; < |startfocus| > // Service release request and sends back notification Message releaseMsg = makeMessage ( request , ConnectivityManager . CALLBACK_RELEASED ) ; handler . sendMessage ( releaseMsg ) ; Thread . sleep ( 1000 ) ; // replace by waitForIdle ( ) // Unregistering the callback should make it registrable again . < |endfocus| > manager . requestNetwork ( request , callback ) ; } static Message makeMessage ( NetworkRequest req , int messageType ) { Bundle bundle = new Bundle ( ) ; bundle . putParcelable ( NetworkRequest . class . getSimpleName ( ) , req ) ; Message msg = Message . obtain ( ) ; msg . what = messageType ; msg . setData ( bundle ) ; return msg ; } static NetworkRequest makeRequest ( int requestId ) { NetworkRequest request = new NetworkRequest . Builder ( ) . clearCapabilities ( ) . build ( ) ; return new NetworkRequest ( request . networkCapabilities , ConnectivityManager . TYPE_NONE , requestId , NetworkRequest . Type . NONE ) ;
if ( maxBlacklistSize <= 0 ) { Log . wtf ( TAG , "Invalid max BSSID blacklist size : " + maxBlacklistSize ) ; return ; } ArrayList < String > blacklistedBssids = new ArrayList < String > ( buildBssidBlacklist ( ) ) ; int blacklistSize = blacklistedBssids . size ( ) ; if ( blacklistSize > maxBlacklistSize ) { Log . wtf ( TAG , "Attempt to write " + blacklistSize + " blacklisted BSSIDs , max size is " + maxBlacklistSize ) ; blacklistedBssids = new ArrayList < String > ( blacklistedBssids . subList ( 0 , < |startfocus| > maxBlacklistSize ) ) ; < |endfocus| > localLog ( "Trim down BSSID blacklist size from " + blacklistSize + " to " + blacklistedBssids . size ( ) ) ; } if ( ! mConnectivityHelper . setFirmwareRoamingConfiguration ( blacklistedBssids , new ArrayList < String > ( ) ) ) { // TODO ( b / 36488259 ) : SSID whitelist management . localLog ( "Failed to set firmware roaming configuration . " ) ; }
private void start ( ) { < |startfocus| > mConnectivityHelper . getFirmwareRoamingInfo ( ) ; < |endfocus| > startConnectivityScan ( SCAN_IMMEDIATELY ) ;
public void setWifiEnabled ( boolean enable ) { localLog ( "Set WiFi " + ( enable ? "enabled" : "disabled" ) ) ; mWifiEnabled = enable ; < |startfocus| > if ( mWifiEnabled && mWifiConnectivityManagerEnabled ) { start ( ) ; } else { stop ( ) ; } < |endfocus| >
private void localLog ( String log ) { < |startfocus| > mLocalLog . log ( log ) ; < |endfocus| >
sbuf . append ( " Same network the current one bonus : " ) . append ( mSameNetworkAward ) . append ( " , " ) ; // When firmware roaming is supported , equivalent BSSIDs ( the ones under the // same network as the currently connected one ) get the same BSSID award . if ( mConnectivityHelper . isFirmwareRoamingSupported ( ) && currentBssid != null && ! currentBssid . equals ( scanResult . BSSID ) ) { score += mSameBssidAward ; sbuf . append ( " Firmware roaming equivalent BSSID bonus : " ) < |startfocus| > . append ( mSameBssidAward ) . append ( " , " ) ; < |endfocus| > } } // Same BSSID award . if ( currentBssid != null && currentBssid . equals ( scanResult . BSSID ) ) { score += mSameBssidAward ; sbuf . append ( " Same BSSID as the current one bonus : " ) . append ( mSameBssidAward ) . append ( " , " ) ; } // Security award . if ( ! WifiConfigurationUtil . isConfigForOpenNetwork ( network ) ) { score += mSecurityAward ; sbuf . append ( " Secure network bonus : " ) . append ( mSecurityAward ) . append ( " , " ) ; } // No internet penalty .
if ( mConnectivityHelper . isFirmwareRoamingSupported ( ) && currentBssid != null && ! currentBssid . equals ( scanResult . BSSID ) ) { score += mSameBssidAward ; sbuf . append ( " Firmware roaming equivalent BSSID bonus : " ) . append ( mSameBssidAward ) . append ( " , " ) ; } } // Same BSSID award . if ( currentBssid != null && currentBssid . equals ( scanResult . BSSID ) ) { score += mSameBssidAward ; sbuf . append ( " Same BSSID as the current one bonus : " ) . append ( mSameBssidAward ) < |startfocus| > . append ( " , " ) ; < |endfocus| > } // Security award . if ( ! WifiConfigurationUtil . isConfigForOpenNetwork ( network ) ) { score += mSecurityAward ; sbuf . append ( " Secure network bonus : " ) . append ( mSecurityAward ) . append ( " , " ) ; } // No internet penalty . if ( network . numNoInternetAccessReports > 0 && ! network . validatedInternetAccess ) { score -= mNoInternetPenalty ; sbuf . append ( " No internet penalty : - " ) . append ( mNoInternetPenalty ) . append ( " , " ) ; } sbuf . append ( " ## Total score : " ) . append ( score ) . append ( "\n" ) ; return score ;
if ( mConnectivityHelper . isFirmwareRoamingSupported ( ) && currentBssid != null && ! currentBssid . equals ( scanResult . BSSID ) ) { score += mSameBssidAward ; sbuf . append ( " Firmware roaming equivalent BSSID bonus : " ) . append ( mSameBssidAward ) . append ( " , " ) ; } } // Same BSSID award . if ( currentBssid != null && currentBssid . equals ( scanResult . BSSID ) ) { score += mSameBssidAward ; sbuf . append ( " Same BSSID as the current one bonus : " ) . append ( mSameBssidAward ) < |startfocus| > . append ( " , " ) ; < |endfocus| > } // Security award . if ( ! WifiConfigurationUtil . isConfigForOpenNetwork ( network ) ) { score += mSecurityAward ; sbuf . append ( " Secure network bonus : " ) . append ( mSecurityAward ) . append ( " , " ) ; } // No internet penalty . if ( network . numNoInternetAccessReports > 0 && ! network . validatedInternetAccess ) { score -= mNoInternetPenalty ; sbuf . append ( " No internet penalty : - " ) . append ( mNoInternetPenalty ) . append ( " , " ) ; } sbuf . append ( " ## Total score : " ) . append ( score ) . append ( "\n" ) ; return score ;
public void testCTSSyscallBlocked ( ) { if ( CpuFeatures . isArm64Cpu ( ) ) { < |startfocus| > testAllowed ( 98 ) ; testBlocked ( 99 ) ; testBlocked ( 100 ) ; < |endfocus| > } else if ( CpuFeatures . isArmCpu ( ) ) { testBlocked ( 7 ) ; testAllowed ( 8 ) ; testBlocked ( 9 ) ; } else if ( CpuFeatures . isX86_64Cpu ( ) ) { testBlocked ( 31 ) ; testAllowed ( 32 ) ; testBlocked ( 33 ) ; } else if ( CpuFeatures . isX86Cpu ( ) ) { testBlocked ( 7 ) ; testAllowed ( 8 ) ; testBlocked ( 9 ) ; } else if ( CpuFeatures . isMips64Cpu ( ) ) { testBlocked ( 5030 ) ; testAllowed ( 5031 ) ; testBlocked ( 5032 ) ; } else if ( CpuFeatures . isMipsCpu ( ) ) { testBlocked ( 4032 ) ; testAllowed ( 4033 ) ; testBlocked ( 4034 ) ; } else { fail ( "Unsupported OS" ) ; } }
/* * Copyright ( C ) 2014 The Android Open Source Project * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package android . security . cts ; import android . test . AndroidTestCase ; import com . android . compatibility . common . util . CpuFeatures ; import junit . framework . TestCase ; /* * * Verify that the seccomp policy is enforced */ public class SeccompTest extends AndroidTestCase { static { System . loadLibrary ( "ctssecurity_jni" ) ; } public void testCTSSyscallBlocked ( ) { if ( CpuFeatures . isArm64Cpu ( ) ) {
mPhone . notifyOtaspChanged ( ServiceStateTracker . OTASP_SIM_UNPROVISIONED ) ; // Tear down all metered apns cleanUpAllConnections ( true , Phone . REASON_CARRIER_ACTION_DISABLE_METERED_APN ) ; } else { teardownRestrictedMeteredConnections ( ) ; setupDataOnConnectableApns ( Phone . REASON_DATA_ENABLED ) ; } } } } private void onSimNotReady ( ) { if ( DBG ) log ( "onSimNotReady" ) ; < |startfocus| > // Clear auto attach as modem is expected to do a new attach once SIM is ready mAutoAttachOnCreation . set ( false ) ; cleanUpAllConnections ( true , Phone . REASON_SIM_NOT_READY ) ; < |endfocus| > mAllApnSettings = null ; mAutoAttachOnCreationConfig = false ; } private void onSetDependencyMet ( String apnType , boolean met ) { // don't allow users to tweak hipri to work around default dependency not met if ( PhoneConstants . APN_TYPE_HIPRI . equals ( apnType ) ) return ; ApnContext apnContext = mApnContexts . get ( apnType ) ; if ( apnContext == null ) { loge ( "onSetDependencyMet : ApnContext not found in onSetDependencyMet ( " + apnType + " , " + met + " ) " ) ;
public void onChange ( boolean selfChange ) { < |startfocus| > mUserWantsSuspendOpt . set ( Settings . Global . getInt ( mContext . getContentResolver ( ) , < |endfocus| > Settings . Global . WIFI_SUSPEND_OPTIMIZATIONS_ENABLED , 1 ) == 1 ) ;
return null ; } WifiConfiguration [ ] configs = new WifiConfiguration [ ssids . length ] ; for ( int index = 0 ; index < ssids . length ; index ++ ) { int networkId = index ; for ( int k = 0 ; k < index ; k ++ ) { // If two networks have the same SSID and security type , assign them // the same network Id . if ( ssids [ index ] . equals ( ssids [ k ] ) && ( securities [ index ] == securities [ k ] ) ) { networkId = k ; break ; } } < |startfocus| > configs [ index ] = generateWifiConfig ( networkId , 0 , ssids [ index ] , false , true , null , null , securities [ index ] ) ; < |endfocus| > } return configs ;
for ( int index = 0 ; index < ssids . length ; index ++ ) { int networkId = index ; for ( int k = 0 ; k < index ; k ++ ) { // If two networks have the same SSID and security type , assign them // the same network Id . if ( ssids [ index ] . equals ( ssids [ k ] ) && ( securities [ index ] == securities [ k ] ) ) { networkId = k ; } } < |startfocus| > configs [ index ] = generateWifiConfig ( networkId , 0 , ssids [ index ] , false , true , null , null , securities [ index ] ) ; < |endfocus| > } return configs ;
public class MacroSubstitutionNamingStrategy implements TestCaseNamingStrategy { private static final String MACRO_PATTERN = "\\ { [ ^ \\ } ] { 0 , 50 } \\ } " ; // Pattern that keeps delimiters in split result private static final Pattern MACRO_SPLIT_PATTERN = Pattern . compile ( String . format ( " ( ?= % s ) | ( ? <= % s ) " , MACRO_PATTERN , MACRO_PATTERN ) ) ; private static final String MACRO_START = " { " ; private static final String MACRO_END = " } " ; < |startfocus| > // Android - changed : CTS and AJUR rely on specific format to test names , changing them // will prevent CTS and AJUR from working properly ; see b / 36541809 < |endfocus| > static final String DEFAULT_TEMPLATE = " { method } [ { index } ] " ; private TestMethod method ; public MacroSubstitutionNamingStrategy ( TestMethod testMethod ) { this . method = testMethod ; } @Override public String getTestCaseName ( int parametersIndex , Object parameters ) { TestCaseName testCaseName = method . getAnnotation ( TestCaseName . class ) ; String template = getTemplate ( testCaseName ) ; String builtName = buildNameByTemplate ( template , parametersIndex , parameters ) ; return builtName ; } private String getTemplate ( TestCaseName testCaseName ) { if ( testCaseName == null ) { return DEFAULT_TEMPLATE ; } String template = testCaseName . value ( ) ; if ( template . isEmpty ( ) ) { return DEFAULT_TEMPLATE ; } return template ; } private String buildNameByTemplate ( String template , int parametersIndex , Object parameters ) { String [ ] parts = MACRO_SPLIT_PATTERN . split ( template ) ; StringBuilder builder = new StringBuilder ( ) ; for ( String part : parts ) { if ( part . startsWith ( MACRO_START ) ) { String macro = part . substring ( 1 , part . length ( ) - 1 ) ; builder . append ( getMacroValue ( macro , parametersIndex , parameters ) ) ; } else { builder . append ( part ) ; } } return builder . toString ( ) ; } private String getMacroValue ( String macro , int parametersIndex , Object parameters ) { switch ( macro ) { case "method" : return method . getName ( ) ; case "index" : return String . valueOf ( parametersIndex ) ; case "parameters" : return String . valueOf ( parameters ) ; default : throw new IllegalArgumentException ( "Unknown macro : " + macro ) ; } } }
import org . mockito . MockitoAnnotations ; import org . mockito . stubbing . Answer ; import java . net . InetAddress ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . List ; import java . util . Random ; /* * * Unit tests for { @link com . android . server . wifi . WifiVendorHal } . */ public class WifiVendorHalTest { WifiVendorHal mWifiVendorHal ; private WifiStatus mWifiStatusSuccess ; private WifiStatus mWifiStatusFailure ; WifiLog mWifiLog ; @Mock private HalDeviceManager mHalDeviceManager ; @Mock < |startfocus| > private Looper mLooper ; < |endfocus| > @Mock private WifiVendorHal . HalDeviceManagerStatusListener mHalDeviceManagerStatusCallbacks ; @Mock private IWifiApIface mIWifiApIface ; @Mock private IWifiChip mIWifiChip ; @Mock private IWifiStaIface mIWifiStaIface ; @Mock private IWifiRttController mIWifiRttController ; private IWifiStaIfaceEventCallback mIWifiStaIfaceEventCallback ; private IWifiChipEventCallback mIWifiChipEventCallback ; @Mock private WifiNative . VendorHalDeathEventHandler mVendorHalDeathHandler ; /* * * Identity function to supply a type to its argument , which is a lambda */
break ; case CMD_DIAGS_CONNECT_TIMEOUT : mWifiDiagnostics . reportConnectionEvent ( ( Long ) message . obj , BaseWifiDiagnostics . CONNECTION_EVENT_FAILED ) ; break ; default : loge ( "Error ! unhandled message" + message ) ; break ; } return HANDLED ; } } class InitialState extends State { private void cleanup ( ) { // Tearing down the client interfaces below is going to stop our supplicant . mWifiMonitor . stopAllMonitoring ( ) ; mDeathRecipient . unlinkToDeath ( ) ; mWifiNative . tearDownInterfaces ( ) ; mWifiNative . stopHal ( ) ; } < |startfocus| > < |endfocus| > @Override public void enter ( ) { mWifiStateTracker . updateState ( WifiStateTracker . INVALID ) ; cleanup ( ) ; } @Override public boolean processMessage ( Message message ) { logStateAndMessage ( message , this ) ; switch ( message . what ) { case CMD_START_SUPPLICANT : mClientInterface = mWifiNative . setupDriverForClientMode ( ) ; if ( mClientInterface == null || ! mDeathRecipient . linkToDeath ( mClientInterface . asBinder ( ) ) ) { setWifiState ( WifiManager . WIFI_STATE_UNKNOWN ) ; cleanup ( ) ; break ; } try { mWifiMonitor . startMonitoring ( mClientInterface . getInterfaceName ( ) , mWifiNative ) ; } catch ( Exception e ) { loge ( "Exception trying to start monitor : " + e ) ; setWifiState ( WifiManager . WIFI_STATE_UNKNOWN ) ; break ; } setWifiState ( WifiManager . WIFI_STATE_ENABLING ) ; break ; case CMD_STOP_SUPPLICANT : setWifiState ( WifiManager . WIFI_STATE_DISABLED ) ; break ; case CMD_START_AP : setWifiState ( WifiManager . WIFI_STATE_ENABLING ) ; break ; case CMD_STOP_AP : setWifiState ( WifiManager . WIFI_STATE_DISABLED ) ; break ; case CMD_START_DRIVER : setWifiState ( WifiManager . WIFI_STATE_ENABLING ) ; break ; case CMD_STOP_DRIVER : setWifiState ( WifiManager . WIFI_STATE_DISABLED ) ; break ; case CMD_SET_SCAN_MODE : case CMD_SET_SCAN_TYPE : case CMD_SET_HIGH_PERF_MODE : case CMD_SET_COUNTRY_CODE : case CMD_SET_FREQUENCY_BAND : case CMD_START_PACKET_FILTERING : case CMD_STOP_PACKET_FILTERING : case CMD_START_SCAN : case CMD_DISCONNECT : case CMD_REASSOCIATE : case CMD_RECONNECT : case CMD_REMOVE_APP_CONFIGURATIONS : case CMD_REMOVE_NETWORK : case CMD_SAVE_CONFIG : case CMD_SET_AP_CONFIG : case CMD_SET_AP_CONFIG_COMPLETED : case CMD_SET_NETWORK : case CMD_SET_OPERATIONAL_MODE : case CMD_ENABLE_RSSI_POLL : case CMD_SET_SUSPEND_OPT_ENABLED : case CMD_TEST_NETWORK_DISCONNECT : case CMD_UNWANTED_NETWORK : case CMD_START_RSSI_MONITORING_OFFLOAD : case CMD_STOP_RSSI_MONITORING_OFFLOAD : case CMD_START_IP_PACKET_OFFLOAD : case CMD_STOP_IP_PACKET_OFFLOAD : case CMD_ADD_KEEPALIVE_PACKET_FILTER_TO_APF : case CMD_REMOVE_KEEPALIVE_PACKET_FILTER_FROM_APF : case CMD_START_RSSI_MONITORING_OFFLOAD : case CMD_STOP_RSSI_MONITORING_OFFLOAD : case CMD_START_IP_PACKET_OFFLOAD : case CMD_STOP_IP_PACKET_OFFLOAD : case CMD_ADD_KEEPALIVE_PACKET_FILTER_TO_APF : case CMD_REMOVE_KEEPALIVE_PACKET_FILTER_FROM_APF : case CMD_ENABLE_TDLS : case CMD_DISABLE_TDLS : case CMD_START_WPS : case CMD_START_WPS_REGISTRAR : case CMD_START_WPS_ENROLLEE : case CMD_STOP_WPS : case CMD_DISABLE_EPHEMERAL_NETWORK : case CMD_GET_SUPPORTED_FEATURES : case CMD_GET_LINK_LAYER_STATS : case CMD_RESET_SIM_NETWORKS : case CMD_BLUETOOTH_ADAPTER_STATE_CHANGE : case CMD_ADD_OR_UPDATE_NETWORK : case CMD_ENABLE_ALL_NETWORKS : case CMD_RELOAD_TLS_AND_RECONNECT : case CMD_GET_CONFIGURED_NETWORKS : case CMD_GET_PRIVILEGED_CONFIGURED_NETWORKS : case CMD_GET_MATCHING_CONFIG : case CMD_GET_SUPPORTED_FEATURES : case CMD_GET_LINK_LAYER_STATS : case CMD_RESET_SIM_NETWORKS : case CMD_BLUETOOTH_ADAPTER_STATE_CHANGE : case CMD_ADD_OR_UPDATE_NETWORK : case CMD_ENABLE_ALL_NETWORKS : case CMD_RELOAD_TLS_AND_RECONNECT : case CMD_GET_CONFIGURED_NETWORKS : case CMD_GET_PRIVILEGED_CONFIGURED_NETWORKS : case CMD_GET_MATCHING_CONFIG : case CMD_GET_SUPPORTED_FEATURES : case CMD_GET_LINK_LAYER_STATS : case CMD_RESET_SIM_NETWORKS : case CMD_BLUETOOTH_ADAPTER_STATE_CHANGE : case CMD_ADD_OR_UPDATE_NETWORK : case CMD_ENABLE_ALL_NETWORKS : case CMD_RELOAD_TLS_AND_RECONNECT : case CMD_GET_CONFIGURED_NETWORKS : case CMD_GET_PRIVILEGED_CONFIGURED_NETWORKS : case CMD_GET_MATCHING_CONFIG : case CMD_GET_SUPPORTED_FEATURES : case CMD_GET_LINK_LAYER_STATS : case CMD_RESET_SIM_NETWORKS : case CMD_BLUETOOTH_ADAPTER_STATE_CHANGE : case CMD_ADD_OR_UPDATE_NETWORK : case CMD_ENABLE_ALL_NETWORKS : case CMD_RELOAD_TLS_AND_RECONNECT : case CMD_GET_CONFIGURED_NETWORKS : case CMD_GET_PRIVILEGED_CONFIGURED_NETWORKS : case CMD_GET_MATCHING_CONFIG : case CMD_GET_SUPPORTED
sendMessage ( CMD_DISCONNECT ) ; } break ; case WifiManager . CONNECT_NETWORK : /* * * The connect message can contain a network id passed as arg1 on message or * or a config passed as obj on message . * For a new network , a config is passed to create and connect . * For an existing network , a network id is passed */ netId = message . arg1 ; config = ( WifiConfiguration ) message . obj ; < |startfocus| > mWifiConnectionStatistics . numWifiManagerJoinAttempt ++ ; < |endfocus| > // New network addition . if ( config != null ) { result = mWifiConfigManager . addOrUpdateNetwork ( config , message . sendingUid ) ; if ( ! result . isSuccess ( ) ) { loge ( "CONNECT_NETWORK adding / updating config = " + config + " failed" ) ; messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL ; replyToMessage ( message , WifiManager . CONNECT_NETWORK_FAILED , WifiManager . ERROR ) ; break ; } netId = result . getNetworkId ( ) ; } if ( ! connectToUserSelectNetwork ( netId , message . sendingUid ) ) {
/* * * The connect message can contain a network id passed as arg1 on message or * or a config passed as obj on message . * For a new network , a config is passed to create and connect . * For an existing network , a network id is passed */ netId = message . arg1 ; config = ( WifiConfiguration ) message . obj ; < |startfocus| > mWifiConnectionStatistics . numWifiManagerJoinAttempt ++ ; < |endfocus| > // New network addition . if ( config != null ) { result = mWifiConfigManager . addOrUpdateNetwork ( config , message . sendingUid ) ; if ( ! result . isSuccess ( ) ) { loge ( "CONNECT_NETWORK adding / updating config = " + config + " failed" ) ; messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL ; replyToMessage ( message , WifiManager . CONNECT_NETWORK_FAILED , WifiManager . ERROR ) ; break ; } netId = result . getNetworkId ( ) ; } if ( ! connectToUserSelectNetwork ( netId , message . sendingUid ) ) { messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL ; replyToMessage ( message , WifiManager . CONNECT_NETWORK_FAILED , WifiManager . ERROR ) ; break ; }
newNetwork || WifiConfigurationUtil . hasCredentialChanged ( existingInternalConfig , newInternalConfig ) ; // This is needed to inform IpManager about any IP configuration changes . boolean hasIpChanged = newNetwork || WifiConfigurationUtil . hasIpChanged ( existingInternalConfig , newInternalConfig ) ; boolean hasProxyChanged = newNetwork || WifiConfigurationUtil . hasProxyChanged ( existingInternalConfig , newInternalConfig ) ; < |startfocus| > // Reset the |hasEverConnected| flag if the credential parameters changed in this update . < |endfocus| > if ( hasCredentialChanged ) { newInternalConfig . getNetworkSelectionStatus ( ) . setHasEverConnected ( false ) ; } // Add it to our internal map . This will replace any existing network configuration for // updates . mConfiguredNetworks . put ( newInternalConfig ) ; if ( mDeletedEphemeralSSIDs . remove ( config . SSID ) ) { if ( mVerboseLoggingEnabled ) { Log . v ( TAG , "Removed from ephemeral blacklist : " + config . SSID ) ; } } // Stage the backup of the SettingsProvider package which backs this up . mBackupManagerProxy . notifyDataChanged ( ) ; NetworkUpdateResult result = new NetworkUpdateResult ( hasIpChanged , hasProxyChanged , hasCredentialChanged ) ; result . setIsNewNetwork ( newNetwork ) ;
public ISap getSapProxy ( ) { < |startfocus| > if ( mSapProxy != null ) { return mSapProxy ; } try { mSapProxy = ISap . getService ( SOCKET_NAME_RIL_BT ) ; < |endfocus| > if ( mSapProxy != null ) { mSapProxy . linkToDeath ( mSapProxyDeathRecipient , mSapProxyCookie . incrementAndGet ( ) ) ; mSapProxy . setCallback ( mSapCallback ) ; } else { Log . e ( TAG , "getSapProxy : mSapProxy == null" ) ; } } catch ( RemoteException | RuntimeException e ) { mSapProxy = null ; Log . e ( TAG , "getSapProxy : exception : " + e ) ; } if ( mSapProxy == null ) { // if service is not up , treat it like death notification to try to get service again mSapServerMsgHandler . sendMessageDelayed ( mSapServerMsgHandler . obtainMessage ( SapServer . SAP_PROXY_DEAD , mSapProxyCookie . get ( ) ) , SapServer . ISAP_GET_SERVICE_DELAY_MILLIS ) ; } return mSapProxy ; }
" mtu = " + mtu + " status = " + status ) ; if ( ! address . equals ( mDevice . getAddress ( ) ) ) { return ; } try { mCallback . onMtuChanged ( BluetoothGatt . this , mtu , status ) ; } catch ( Exception ex ) { Log . w ( TAG , "Unhandled exception in callback" , ex ) ; } } /* * * Callback invoked when the given connection is updated * @hide */ < |startfocus| > public void onConnectionParametersUpdated ( String address , int interval , int latency , < |endfocus| > int timeout , int status ) { if ( DBG ) Log . d ( TAG , "onConnectionUpdated ( ) - Device = " + address + " interval = " + interval + " latency = " + latency + " timeout = " + timeout + " status = " + status ) ; if ( ! address . equals ( mDevice . getAddress ( ) ) ) { return ; } try { mCallback . onConnectionUpdated ( BluetoothGatt . this , interval , latency , timeout , status ) ; } catch ( Exception ex ) { Log . w ( TAG , "Unhandled exception in callback" , ex ) ; } } } ;
/* * Copyright ( C ) 2007 The Android Open Source Project * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . android . server ; import static android . Manifest . permission . DUMP ; import static android . Manifest . permission . SHUTDOWN ; import android . content . Context ; import android . net . IIpSecService ; import android . net . INetd ; import android . os . Binder ; import android . os . Handler ; import android . os . Process ; import android . os . RemoteException ; import android . os . ServiceManager ; import android . util . Log ; import java . io . FileDescriptor ; import java . io . PrintWriter ;
import java . util . concurrent . CountDownLatch ; /* * @hide */ public class IpSecService extends IIpSecService . Stub implements Watchdog . Monitor { private static final String TAG = "IpSecService" ; private static final boolean DBG = Log . isLoggable ( TAG , Log . DEBUG ) ; private static final String NETD_TAG = "NetdConnector" ; private static final String NETD_SERVICE_NAME = "netd" ; /* * Binder context for this service */ private final Context mContext ; < |startfocus| > /* * connector object for communicating with netd */ private final NativeDaemonConnector mConnector ; private final Handler mFgHandler ; < |endfocus| > private INetd mNetdService ; private final Thread mThread ; private CountDownLatch mConnectedSignal = new CountDownLatch ( 1 ) ; /* * * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService ( Context context , String socket ) { mContext = context ; // make sure this is on the same looper as our NativeDaemonConnector for sync purposes mFgHandler = new Handler ( FgThread . get ( ) . getLooper ( ) ) ; mConnector =
private static final boolean DBG = Log . isLoggable ( TAG , Log . DEBUG ) ; private static final String NETD_TAG = "NetdConnector" ; private static final String NETD_SERVICE_NAME = "netd" ; /* * Binder context for this service */ private final Context mContext ; /* * connector object for communicating with netd */ private final NativeDaemonConnector mConnector ; private final Handler mFgHandler ; private INetd mNetdService ; < |startfocus| > private final Thread mThread ; private CountDownLatch mConnectedSignal = new CountDownLatch ( 1 ) ; < |endfocus| > /* * * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService ( Context context , String socket ) { mContext = context ; // make sure this is on the same looper as our NativeDaemonConnector for sync purposes mFgHandler = new Handler ( FgThread . get ( ) . getLooper ( ) ) ; mConnector = new NativeDaemonConnector ( new NetdCallbackReceiver ( ) , socket , 10 , NETD_TAG , 160 , null /* wakelock */ , FgThread . get ( ) . getLooper ( ) ) ;
public void systemReady ( ) { < |startfocus| > if ( DBG ) { final long start = System . currentTimeMillis ( ) ; prepareNativeDaemon ( ) ; final long delta = System . currentTimeMillis ( ) - start ; Log . d ( TAG , "Prepared in " + delta + "ms" ) ; < |endfocus| > } else { prepareNativeDaemon ( ) ; }
private void connectNativeNetdService ( ) { < |startfocus| > mNetdService = INetd . Stub . asInterface ( ServiceManager . getService ( NETD_SERVICE_NAME ) ) ; if ( ! isNetdAlive ( ) ) { Log . wtf ( TAG , "Can't connect to NativeNetdService " + NETD_SERVICE_NAME ) ; } < |endfocus| >
assertEquals ( RESULT_PASS , appEndReceiver . waitForActivity ( ) ) ; appEndReceiver . close ( ) ; if ( ! noHomeScreen ( ) ) { // At this time the timerReceiver should not fire , even though the activity has shut // down , because we are back to the home screen . Going to the home screen does not // qualify as the user leaving the activity's flow . Only when the The user switch to // another activity that is not part of the tracked flow that we consider the flow is // complete . assertEquals ( RESULT_TIMEOUT , timeReceiver . waitForActivity ( ) ) ; assertTrue ( timeReceiver . mTimeUsed == 0 ) ; } else { // With platforms that have no home screen , focus is returned to something else that is // considered a completion of the tracked activity flow , and hence time tracking is // triggered . assertEquals ( RESULT_PASS , timeReceiver . waitForActivity ( ) ) ; } // Issuing now another activity will trigger the timing information release . final Intent dummyIntent = new Intent ( context , MockApplicationActivity . class ) ; dummyIntent . addFlags ( Intent . FLAG_ACTIVITY_NEW_TASK ) ;
public void addActiveDownstream ( TetherInterfaceStateMachine downstream ) { if ( findDownstream ( downstream ) == null ) { // Adding a new downstream appends it to the list . Adding a // downstream a second time without first removing it has no effect . < |startfocus| > mActiveDownstreams . offer ( new Downstream ( downstream , mNextSubnetId ++ ) ) ; // Try to wrap cleanly after 2 ^ 15 downstreams added since boot . if ( mNextSubnetId < 0 ) mNextSubnetId = 0 ; < |endfocus| > updateIPv6TetheringInterfaces ( ) ; }
// ( which extends it ) . SYSTEM_SERVICE_NAMES . put ( android . text . ClipboardManager . class , Context . CLIPBOARD_SERVICE ) ; registerService ( Context . CONNECTIVITY_SERVICE , ConnectivityManager . class , new StaticApplicationContextServiceFetcher < ConnectivityManager > ( ) { @Override public ConnectivityManager createService ( Context context ) { IBinder b = ServiceManager . getService ( Context . CONNECTIVITY_SERVICE ) ; IConnectivityManager service = IConnectivityManager . Stub . asInterface ( b ) ; return new ConnectivityManager ( context , service ) ; } } ) ; registerService ( Context . IPSEC_SERVICE , IpSecManager . class , new StaticApplicationContextServiceFetcher < IpSecManager > ( ) { @Override < |startfocus| > public IpSecManager createService ( Context context ) { < |endfocus| > IBinder b = ServiceManager . getService ( Context . IPSEC_SERVICE ) ; IIpSecService service = IIpSecService . Stub . asInterface ( b ) ; return new IpSecManager ( context , service ) ; } } ) ; registerService ( Context . COUNTRY_DETECTOR , CountryDetector . class , new StaticServiceFetcher < CountryDetector > ( ) { @Override public CountryDetector createService ( ) { IBinder b = ServiceManager . getService ( Context . COUNTRY_DETECTOR ) ; return new CountryDetector ( ICountryDetector . Stub . asInterface ( b ) ) ; } } ) ; registerService ( Context . DEVICE_POLICY_SERVICE , DevicePolicyManager . class , new StaticApplicationContextServiceFetcher < DevicePolicyManager > ( ) { @Override public DevicePolicyManager createService ( Context context ) { IBinder b = ServiceManager . getService ( Context . DEVICE_POLICY_SERVICE ) ; IDevicePolicyManager service = IDevicePolicyManager . Stub . asInterface ( b ) ; return new DevicePolicyManager ( context , service ) ; } } ) ; registerService ( Context . DOWNLOAD_SERVICE , DownloadManager . class , new StaticApplicationContextServiceFetcher < DownloadManager > ( ) { @Override public DownloadManager createService ( Context context ) { return new DownloadManager ( context , context . getContentResolver ( ) , context . getPackageName ( ) ) ; } } ) ; registerService ( Context . BATTERY_SERVICE , BatteryManager . class , new StaticServiceFetcher < BatteryManager > ( ) { @Override public BatteryManager createService ( ) { IBinder b = ServiceManager . getService ( Context . BATTERY_SERVICE ) ; IBatteryPropertiesRegistrar service = IBatteryPropertiesRegistrar . Stub . asInterface ( b ) ; return new BatteryManager ( service ) ; } } ) ; registerService ( Context . NFC_SERVICE , NfcManager . class , new StaticApplicationContextServiceFetcher < NfcManager > ( ) { @Override public NfcManager createService ( Context context ) { return new NfcManager ( context ) ; } } ) ; registerService ( Context . DROPBOX_SERVICE , DropBoxManager . class , new StaticServiceFetcher < DropBoxManager > ( ) { @Override public DropBoxManager createService ( ) { IBinder b = ServiceManager . getService ( Context . DROPBOX_SERVICE ) ; IDropBoxManagerService service = IDropBoxManagerService . Stub . asInterface ( b ) ; return new DropBoxManager ( service ) ; } } ) ; registerService ( Context . INPUT_METHOD_SERVICE , InputMethodManager . class , new StaticApplicationContextServiceFetcher < InputMethodManager > ( ) { @Override public InputMethodManager createService ( Context context ) { return InputMethodManager . getInstance ( context ) ; } } ) ; registerService ( Context . DISPLAY_SERVICE , DisplayManager . class , new StaticApplicationContextServiceFetcher < DisplayManager > ( ) { @Override public DisplayManager createService ( Context context ) { return new DisplayManager ( context ) ; } } ) ; registerService ( Context . USER_SERVICE , UserManager . class , new StaticApplicationContextServiceFetcher < UserManager > ( ) { @Override public UserManager createService ( Context context ) { IBinder b = ServiceManager . getService ( Context . USER_SERVICE ) ; IUserManager service = IUserManager . Stub . asInterface ( b ) ; return new UserManager ( context , service ) ; } } ) ; registerService ( Context . APP_OPS_SERVICE , AppOpsManager . class , new StaticApplicationContextServiceFetcher < AppOpsManager > ( ) { @Override public AppOpsManager createService ( Context context ) { return new AppOpsManager ( context ) ; } } ) ; registerService ( Context . CAMERA_SERVICE , CameraManager . class , new StaticApplicationContextServiceFetcher < CameraManager > ( ) { @Override public CameraManager createService ( Context context ) { return new CameraManager ( context ) ; } } ) ; registerService ( Context . PRINT_SERVICE , PrintManager . class , new StaticApplicationContextServiceFetcher < PrintManager > ( ) { @Override public PrintManager createService ( Context context ) { return new PrintManager ( context , context . getPackageName ( ) , UserHandle . myUserId ( ) ) ; } } ) ; registerService ( Context . CONSUMER_IR_SERVICE , ConsumerIrManager . class , new StaticApplicationContextServiceFetcher < ConsumerIrManager > ( ) { @Override public ConsumerIrManager createService ( Context context ) { return new ConsumerIrManager ( context ) ; } } ) ; registerService ( Context . MEDIA_SESSION_SERVICE , MediaSessionManager . class , new StaticApplicationContextServiceFetcher < MediaSessionManager > ( ) { @Override public MediaSessionManager createService ( Context context ) { return new MediaSessionManager ( context ) ; } } ) ; registerService ( Context . BLUETOOTH_SERVICE , BluetoothManager . class , new StaticApplicationContextServiceFetcher < BluetoothManager > ( ) { @Override public BluetoothManager createService ( Context context ) { return new BluetoothManager ( context ) ; } } ) ; registerService ( Context . MEDIA_PROJECTION_SERVICE , MediaProjectionManager . class , new StaticApplicationContextServiceFetcher < MediaProjectionManager > ( ) { @Override public MediaProjectionManager createService ( Context context ) { return new MediaProjectionManager ( context ) ; } } ) ; registerService ( Context . HARDWARE_PROPERTIES_SERVICE , HardwarePropertiesManager . class , new StaticApplicationContextServiceFetcher < HardwarePropertiesManager > ( ) { @Override public HardwarePropertiesManager createService ( Context context ) { return new HardwarePropertiesManager ( context ) ; } } ) ; registerService ( Context . SENSOR_SERVICE , SensorManager . class , new StaticApplicationContextServiceFetcher < SensorManager > ( ) { @Override public SensorManager createService ( Context context ) { return new SystemSensorManager ( context , UserHandle . myUserId ( ) ) ; } } ) ; registerService ( Context . SHORTCUT_SERVICE , ShortcutManager . class , new StaticApplicationContextServiceFetcher < ShortcutManager > ( ) { @Override public ShortcutManager createService ( Context context ) { return new ShortcutManager ( context ) ; } } ) ; registerService ( Context . SYSTEM_HEALTH_SERVICE , SystemHealthManager . class , new StaticApplicationContextServiceFetcher < SystemHealthManager > ( ) { @Override public SystemHealthManager createService ( Context context ) { return new SystemHealthManager ( context ) ; } } ) ; registerService ( Context . TV_INPUT_SERVICE , TvInputManager . class , new StaticApplicationContextServiceFetcher < TvInputManager > ( ) { @Override public TvInputManager createService ( Context context ) { return new TvInputManager ( context , ITvInputManager . Stub . asInterface ( ServiceManager . getService ( Context . TV_INPUT_SERVICE ) ) ) ; } } ) ; registerService ( Context . NETWORK_STATS_SERVICE , NetworkStatsManager .
public IpSecManager createService ( Context context ) { IBinder b = ServiceManager . getService ( Context . IPSEC_SERVICE ) ; < |startfocus| > IIpSecService service = IIpSecService . Stub . asInterface ( b ) ; return new IpSecManager ( context , service ) ; < |endfocus| >
import android . os . RemoteException ; import android . util . Log ; import android . util . Slog ; import java . io . FileDescriptor ; import java . io . PrintWriter ; /* * @hide */ public class IpSecService extends IIpSecService . Stub { private static final String TAG = "IpSecService" ; private static final boolean DBG = Log . isLoggable ( TAG , Log . DEBUG ) ; private static final String NETD_SERVICE_NAME = "netd" ; /* * Binder context for this service */ private final Context mContext ; < |startfocus| > private static final int NETD_FETCH_TIMEOUT = 1000 ; // ms < |endfocus| > /* * * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService ( Context context , String socket ) { mContext = context ; } static IpSecService create ( Context context , String socket ) throws InterruptedException { final IpSecService service = new IpSecService ( context , socket ) ; service . connectNativeNetdService ( ) ; return service ; } public static IpSecService create ( Context context ) throws InterruptedException {
import android . util . Slog ; import java . io . FileDescriptor ; import java . io . PrintWriter ; /* * @hide */ public class IpSecService extends IIpSecService . Stub { private static final String TAG = "IpSecService" ; private static final boolean DBG = Log . isLoggable ( TAG , Log . DEBUG ) ; private static final String NETD_SERVICE_NAME = "netd" ; /* * Binder context for this service */ private final Context mContext ; private Object mLock = new Object ( ) ; < |startfocus| > private static final int NETD_FETCH_TIMEOUT = 1000 ; // ms < |endfocus| > /* * * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService ( Context context , String socket ) { mContext = context ; } static IpSecService create ( Context context , String socket ) throws InterruptedException { final IpSecService service = new IpSecService ( context , socket ) ; service . connectNativeNetdService ( ) ; return service ; } public static IpSecService create ( Context context ) throws InterruptedException { return create ( context , NETD_SERVICE_NAME ) ; } private void connectNativeNetdService ( ) throws InterruptedException { synchronized ( mLock ) { if ( mNetdService == null ) { mNetdService = INetd . Stub . asInterface ( ServiceManager . getService ( NETD_SERVICE_NAME ) ) ; } } if ( mNetdService == null ) { throw new InterruptedException ( "Failed to fetch Netd Service" ) ; } }
protected Vpn ( Looper looper , Context context , INetworkManagementService netService , int userHandle , SystemServices systemServices ) { mContext = context ; mNetd = netService ; mUserHandle = userHandle ; mLooper = looper ; mSystemServices = systemServices ; mPackage = VpnConfig . LEGACY_VPN ; mOwnerUID = getAppUid ( mPackage , mUserHandle ) ; try { netService . registerObserver ( mObserver ) ; } catch ( RemoteException e ) { Log . wtf ( TAG , "Problem registering observer" , e ) ; } mNetworkInfo = new NetworkInfo ( ConnectivityManager . TYPE_VPN , 0 , NETWORKTYPE , "" ) ; // TODO : Copy metered attribute and bandwidths from physical transport , b / 16207332 mNetworkCapabilities = new NetworkCapabilities ( ) ; mNetworkCapabilities . addTransportType ( NetworkCapabilities . TRANSPORT_VPN ) ; mNetworkCapabilities . removeCapability ( NetworkCapabilities . NET_CAPABILITY_NOT_VPN ) ; < |startfocus| > loadAlwaysOnPackage ( ) ; < |endfocus| > }
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . example . android . toyvpn ; import android . app . Activity ; import android . content . Intent ; import android . content . SharedPreferences ; import android . net . VpnService ; import android . os . Bundle ; import android . widget . TextView ; public class ToyVpnClient extends Activity { < |startfocus| > public interface Prefs { String NAME = "connection" ; String SERVER_ADDRESS = "server . address" ; String SERVER_PORT = "server . port" ; String SHARED_SECRET = "shared . secret" ; < |endfocus| > } @Override public void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; setContentView ( R . layout . form ) ; final TextView serverAddress = ( TextView ) findViewById ( R . id . address ) ; final TextView serverPort = ( TextView ) findViewById ( R . id . port ) ; final TextView sharedSecret = ( TextView ) findViewById ( R . id . secret ) ;
* * TODO : really don't do this ; a blocking read on another thread is much cleaner . */ private static final long IDLE_INTERVAL_MS = TimeUnit . MILLISECONDS . toMillis ( 100 ) ; /* * * Number of periods of length { @IDLE_INTERVAL_MS } to wait before declaring the handshake a * complete and abject failure . * * TODO : use a higher - level protocol ; hand - rolling is a fun but pointless exercise . */ < |startfocus| > private static final int MAX_HANDSHAKE_ATTEMPTS = 50 ; < |endfocus| > private final VpnService mService ; private final int mConnectionId ; private final String mServerName ; private final int mServerPort ; private final byte [ ] mSharedSecret ; private PendingIntent mConfigureIntent ; private OnEstablishListener mOnEstablishListener ; public ToyVpnConnection ( final VpnService service , final int connectionId , final String serverName , final int serverPort , final byte [ ] sharedSecret ) { mService = service ; mConnectionId = connectionId ; mServerName = serverName ; mServerPort = serverPort ; mSharedSecret = sharedSecret ; } /* * * Starts the handshake with the server . This method returns immediately ; the handshake is * performed on an arbitrary thread . */ public void handshake ( ) { new Thread ( new Runnable ( ) { @Override public void run ( ) { try { handshakeWithServer ( ) ; } catch ( IOException e ) { Log . e ( TAG , "Connection failed : " + e . getMessage ( ) ) ; } } } ) . start ( ) ; } /* * * Performs the handshake with the server . This method blocks until the connection either * succeeds or fails . */ private void handshakeWithServer ( ) throws IOException { // Create a DatagramChannel as the VPN tunnel . final DatagramChannel tunnel = DatagramChannel . open ( ) ; // Protect the tunnel before connecting to avoid loopback . if ( ! mService . protect ( tunnel . socket ( ) ) ) { throw new IllegalStateException ( "Cannot protect the tunnel" ) ; } // Connect to the server . tunnel . connect ( new InetSocketAddress ( mServerName , mServerPort ) ) ; // For simplicity , we use the same thread for both reading and writing . final ByteBuffer packet = ByteBuffer . allocate ( Short . MAX_VALUE ) ; // We keep forwarding packets till something goes wrong . boolean connected = true ; while ( connected ) { // Assume that we did not make any progress in this iteration . boolean idle = true ; // Read the outgoing packet from the input stream . int length = mService . read ( packet ) ; if ( length > 0 ) { // Write the outgoing packet to the tunnel . packet . flip ( ) ; tunnel . write ( packet ) ; packet . clear ( ) ; idle = false ; } // Read the incoming packet from the tunnel . length = tunnel . read ( packet ) ; if ( length > 0 ) { // Ignore control messages , which start with zero . if ( packet . get ( 0 ) != 0 ) { // Write the incoming packet to the output stream . packet . flip ( ) ; mService . write ( packet ) ; packet . clear ( ) ; idle = false ; } } // If we are idle or waiting for the network , sleep for a // fraction of time to avoid busy looping . if ( idle ) { Thread . sleep ( IDLE_INTERVAL_MS ) ; } } } /* * * Configures the current { @link ToyVpnConnection } . This method is called before the handshake * begins . */ public void configure ( ) throws IOException { // If the old interface has exactly the same parameters , use it ! // Configure a builder while parsing the parameters . final Builder builder = new Builder ( ) ; builder . setMtu ( 1500 ) ; builder . addAddress ( "192 . 168 . 0 . 1" , 24 ) ; builder . addDnsServer ( "8 . 8 . 8 . 8" ) ; builder . addRoute ( "0 . 0 . 0 . 0" , 0 ) ; // Create a new interface using the builder and save the parameters . mInterface = builder . establish ( ) ; mConfigureIntent = mInterface . getConfigureIntent ( ) ; mService . protect ( mInterface . getFileDescriptor ( ) ) ; } /* * * Closes the current { @link ToyVpnConnection } . This method is called after the handshake * finishes . */ public void close ( ) { try { if ( mInterface != null ) { mInterface . close ( ) ; mInterface = null ; } } catch ( Exception e ) { // ignore } } /* * * Returns the { @link PendingIntent } to start the activity to configure the current * { @link ToyVpnConnection } . */ public PendingIntent getConfigureIntent ( ) { return mConfigureIntent ; } /* * * Sets the { @link OnEstablishListener } to be notified when the current { @link ToyVpnConnection } * is established . */ public void setOnEstablishListener ( OnEstablishListener listener ) { mOnEstablishListener = listener ; } /* * * Listener for the current { @link ToyVpnConnection } to be notified when the connection is * established . */ public interface OnEstablishListener { /* * * Called when the current { @link ToyVpnConnection } is established . */ void onEstablish ( ToyVpnConnection connection ) ; } }
} catch ( Exception e ) { Log . e ( getTag ( ) , "Connection failed , exiting" , e ) ; } } private boolean run ( SocketAddress server ) throws Exception { ParcelFileDescriptor iface = null ; boolean connected = false ; // Create a DatagramChannel as the VPN tunnel . try ( DatagramChannel tunnel = DatagramChannel . open ( ) ) { // Protect the tunnel before connecting to avoid loopback . if ( ! mService . protect ( tunnel . socket ( ) ) ) { < |startfocus| > throw new IllegalStateException ( "Cannot protect the tunnel for" ) ; < |endfocus| > } // Connect to the server . tunnel . connect ( server ) ; // For simplicity , we use the same thread for both reading and // writing . Here we put the tunnel into non - blocking mode . tunnel . configureBlocking ( false ) ; // Authenticate and configure the virtual network interface . iface = handshake ( tunnel ) ; // Now we are connected . Set the flag . connected = true ; // Packets to be sent are queued in this input stream . FileInputStream in = new FileInputStream ( iface . getFileDescriptor ( ) ) ; // Allocate the buffer for a single packet . ByteBuffer packet = ByteBuffer . allocate ( 32767 ) ; // We use a timer to determine the status of the tunnel . It // works on both sides . A positive value means sending , and // any other means receiving . We start with receiving . int timer = 0 ; // We keep forwarding packets till something goes wrong . while ( true ) { // Assume that we did not make any progress in this iteration . boolean idle = true ; // Read the outgoing packet from the input stream . int length = in . read ( packet . array ( ) ) ; if ( length > 0 ) { // Write the outgoing packet to the tunnel . packet . limit ( length ) ; tunnel . write ( packet ) ; packet . clear ( ) ; // There might be more outgoing packets . idle = false ; // If we were receiving , switch to sending . if ( timer < 1 ) { timer = 1 ; } } // Read the incoming packet from the tunnel . length = tunnel . read ( packet ) ; if ( length > 0 ) { // Ignore control messages , which start with zero . if ( packet . get ( 0 ) != 0 ) { // Write the incoming packet to the output stream . out . write ( packet . array ( ) , 0 , length ) ; } packet . clear ( ) ; // There might be more incoming packets . idle = false ; // If we were sending , switch to receiving . if ( timer > 0 ) { timer = 0 ; } } // If we are idle or waiting for the network , sleep for a // fraction of time to avoid busy looping . if ( idle ) { Thread . sleep ( 100 ) ; // Increase the timer . This is inaccurate but good enough , // since everything is operated in non - blocking mode . timer += ( timer > 0 ) ? 100 : - 100 ; // We are receiving for a long time but not sending . if ( timer < - 15000 ) { // Send empty control messages . packet . put ( ( byte ) 0 ) . limit ( 1 ) ; for ( int i = 0 ; i < 3 ; ++ i ) { packet . position ( 0 ) ; tunnel . write ( packet ) ; } packet . clear ( ) ; // Switch to sending . timer = 1 ; } // We are sending for a long time but not receiving . if ( timer > 20000 ) { throw new IllegalStateException ( "Timed out" ) ; } } } } catch ( InterruptedException e ) { throw e ; } catch ( Exception e ) { Log . e ( getTag ( ) , "Connection failed , exiting" , e ) ; } finally { try { iface . close ( ) ; } catch ( Exception e ) { } } return connected ; } private ParcelFileDescriptor handshake ( DatagramChannel tunnel ) throws Exception { // To build a secured tunnel , we should perform mutual authentication // and exchange session keys for encryption . To keep things simple in // this demo , we just send the shared secret in plaintext and wait // for the server to send the parameters .
packet . position ( 0 ) ; tunnel . write ( packet ) ; } packet . clear ( ) ; // Wait for the parameters within a limited time . for ( int i = 0 ; i < MAX_HANDSHAKE_ATTEMPTS ; ++ i ) { Thread . sleep ( IDLE_INTERVAL_MS ) ; // Normally we should not receive random packets . int length = tunnel . read ( packet ) ; if ( length > 0 && packet . get ( 0 ) == 0 ) { < |startfocus| > return configure ( new String ( packet . array ( ) , 1 , length - 1 ) . trim ( ) ) ; < |endfocus| > } } throw new IllegalStateException ( "Timed out" ) ; } private ParcelFileDescriptor configure ( String parameters ) throws Exception { // Configure a builder while parsing the parameters . VpnService . Builder builder = mService . new Builder ( ) ; for ( String parameter : parameters . split ( " " ) ) { String [ ] fields = parameter . split ( " , " ) ; try { switch ( fields [ 0 ] . charAt ( 0 ) ) { case 'm' : builder . setMtu ( Short . parseShort ( fields [ 1 ] ) ) ; break ; case 'a' : builder . addAddress ( fields [ 1 ] , Integer . parseInt ( fields [ 2 ] ) ) ; break ; case 'r' : builder . addRoute ( fields [ 1 ] , Integer . parseInt ( fields [ 2 ] ) ) ; break ; case 'd' : builder . addDnsServer ( fields [ 1 ] ) ; break ; case 's' : builder . addSearchDomain ( fields [ 1 ] ) ; break ; } } catch ( Exception e ) { throw new IllegalArgumentException ( "Bad parameter : " + parameter ) ; } } // Close the old interface since the parameters have been changed .
packet . position ( 0 ) ; tunnel . write ( packet ) ; } packet . clear ( ) ; // Wait for the parameters within a limited time . for ( int i = 0 ; i < MAX_HANDSHAKE_ATTEMPTS ; ++ i ) { Thread . sleep ( IDLE_INTERVAL_MS ) ; // Normally we should not receive random packets . int length = tunnel . read ( packet ) ; if ( length > 0 && packet . get ( 0 ) == 0 ) { < |startfocus| > return configure ( new String ( packet . array ( ) , 1 , length - 1 , "UTF - 8" ) . trim ( ) ) ; < |endfocus| > } } throw new IllegalStateException ( "Timed out" ) ; } private ParcelFileDescriptor configure ( String parameters ) throws Exception { // Configure a builder while parsing the parameters . VpnService . Builder builder = mService . new Builder ( ) ; for ( String parameter : parameters . split ( " " ) ) { String [ ] fields = parameter . split ( " , " ) ; try { switch ( fields [ 0 ] . charAt ( 0 ) ) { case 'm' : builder . setMtu ( Short . parseShort ( fields [ 1 ] ) ) ; break ; case 'a' : builder . addAddress ( fields [ 1 ] , Integer . parseInt ( fields [ 2 ] ) ) ;
private void setConnectingThread ( final Thread thread ) { final Thread oldThread = mConnectingThread . getAndSet ( thread ) ; if ( oldThread != null ) { try { oldThread . interrupt ( ) ; < |startfocus| > } catch ( InterruptedException e ) { < |endfocus| > Log . e ( TAG , "Interrupting thread" , e ) ; } }
private void setConnection ( final Connection connection ) { final Connection oldConnection = mConnection . getAndSet ( connection ) ; if ( oldConnection != null ) { try { oldConnection . first . interrupt ( ) ; oldConnection . second . close ( ) ; } catch ( Exception e ) { < |startfocus| > Log . e ( TAG , "Interrupting thread" , e ) ; < |endfocus| > } }
public static int inlineMonomorphic ( Main a ) { if ( a == null ) { return 42 ; } int i = 0 ; while ( i < 100 ) { i += a . getValue ( ) ; } return i ; } // / CHECK - START : int Main . inlinePolymorphic ( Main ) inliner ( before ) // / CHECK : InvokeVirtual method_name : Main . getValue // / CHECK - START : int Main . inlinePolymorphic ( Main ) inliner ( after ) // / CHECK - NOT : InvokeVirtual method_name : Main . getValue < |startfocus| > < |endfocus| > // / CHECK - START : int Main . inlineMonomorphic ( Main ) licm ( before ) // / CHECK : < < Deopt : l\d + > > Deoptimize // / CHECK : InstanceFieldGet [ < < Deopt > > ] field_name : Main . value // / CHECK - START : int Main . inlineMonomorphic ( Main ) licm ( after ) // / CHECK : < < Deopt : l\d + > > Deoptimize // / CHECK : InstanceFieldGet [ < < Deopt > > ] field_name : Main . value public static int inlinePolymorphic ( Main a ) { return a . getValue ( ) ; } public int getValue ( ) { return value ; }
< |startfocus| > < |endfocus| > /* * * WifiStateMachine needs to enable / disable other services when wifi is in client mode . This * method allows WifiStateMachine to get these additional system services . * * At this time , this method is used to setup variables for P2P service and Wifi Aware . */ private void getAdditionalWifiServiceInterfaces ( ) { // First set up Wifi Direct if ( mP2pSupported ) { IBinder s1 = mFacade . getService ( Context . WIFI_P2P_SERVICE ) ; WifiP2pServiceImpl wifiP2pServiceImpl =
* and calls the < code > close </ code > method of the underlying output * stream . * * @exception IOException if an I / O error occurs . * @since JCE1 . 2 */ public void close ( ) throws IOException { if ( closed ) { return ; } closed = true ; try { obuffer = cipher . doFinal ( ) ; } catch ( IllegalBlockSizeException | BadPaddingException e ) { obuffer = null ; < |startfocus| > // Android - added : Throw an exception when the underlying cipher does < |endfocus| > throw new IOException ( e ) ; } try { flush ( ) ; } catch ( IOException ignored ) { } out . close ( ) ; } }
setAndBroadcastNetworkSetTime ( mSavedTime + ( currTime - mSavedAtTime ) ) ; } } private void revertToNitzTimeZone ( ) { if ( Settings . Global . getInt ( mCr , Settings . Global . AUTO_TIME_ZONE , 0 ) == 0 ) { return ; } String tmpLog = "Reverting to NITZ TimeZone : tz = " + mSavedTimeZone ; if ( DBG ) log ( tmpLog ) ; mTimeZoneLog . log ( tmpLog ) ; if ( mSavedTimeZone != null ) { setAndBroadcastNetworkSetTimeZone ( mSavedTimeZone ) ; } } /* * * Post a notification to NotificationManager for restricted state and * rejection cause for cs registration * < |startfocus| > * @param notifyType is one state of PS / CS_ * _ENABLE / DISABLE < |endfocus| > */ @VisibleForTesting public void setNotification ( int notifyType ) { if ( DBG ) log ( "setNotification : create notification " + notifyType ) ; // Needed because sprout RIL sends these when they shouldn't ? boolean isSetNotification = mPhone . getContext ( ) . getResources ( ) . getBoolean ( com . android . internal . R . bool . config_user_notification_of_restrictied_mobile_access ) ;
< |startfocus| > public void setNotification ( int notifyType ) { < |endfocus| > if ( DBG ) log ( "setNotification : create notification " + notifyType ) ; // Needed because sprout RIL sends these when they shouldn't ? boolean isSetNotification = mPhone . getContext ( ) . getResources ( ) . getBoolean ( com . android . internal . R . bool . config_user_notification_of_restrictied_mobile_access ) ; if ( ! isSetNotification ) { if ( DBG ) log ( "Ignore all the notifications" ) ; return ; } Context context = mPhone . getContext ( ) ; CarrierConfigManager configManager = ( CarrierConfigManager ) context . getSystemService ( Context . CARRIER_CONFIG_SERVICE ) ; if ( configManager != null ) { PersistableBundle bundle = configManager . getConfig ( ) ; if ( bundle != null ) { boolean disableVoiceBarringNotification = bundle . getBoolean ( CarrierConfigManager . KEY_DISABLE_VOICE_BARRING_NOTIFICATION_BOOL , false ) ; if ( disableVoiceBarringNotification && ( notifyType == CS_ENABLED || notifyType == CS_NORMAL_ENABLED || notifyType == CS_EMERGENCY_ENABLED ) ) { if ( DBG ) log ( "Voice / emergency call barred notification disabled" ) ; return ; } } } CharSequence details = "" ; CharSequence title = context . getText ( com . android . internal . R . string . RestrictedOnData ) ;
< |startfocus| > public void prepareForConnectionAttempt ( int netId ) { localLog ( "prepareForConnectionAttempt : netId = " + netId ) ; < |endfocus| > clearConnectionAttemptTimeStamps ( ) ; clearBlacklistForForcedConnection ( ) ;
long timeStamp = clock . getElapsedSinceBootMillis ( ) ; for ( int index = 0 ; index < ssids . length ; index ++ ) { ScanDetail scanDetail = new ScanDetail ( WifiSsid . createFromAsciiEncoded ( ssids [ index ] ) , bssids [ index ] , caps [ index ] , levels [ index ] , freqs [ index ] , timeStamp , 0 ) ; scanDetailList . add ( scanDetail ) ; } return scanDetailList ; } /* * * Generate an array of { @link android . net . wifi . WifiConfiguration } based on the caller < |startfocus| > * supplied network SSID and security information . < |endfocus| > * * @param ssids an array of SSIDs * @param securities an array of the network's security setting * @return the constructed array of { @link android . net . wifi . WifiConfiguration } */ public static WifiConfiguration [ ] generateWifiConfigurations ( String [ ] ssids , int [ ] securities ) { if ( ssids == null || securities == null || ssids . length != securities . length || ssids . length == 0 ) { return null ; } Map < String , Integer > netIdMap = new HashMap < > ( ) ; int netId = 0 ;
MAXIMUM_POOL_SIZE , KEEP_ALIVE_SECONDS , TimeUnit . SECONDS , workQueue ) ; for ( int i = 1 ; i < mPackages . size ( ) ; i ++ ) { final AppPrefLoader loader = new AppPrefLoader ( ) ; loader . executeOnExecutor ( executor , mPackages . valueAt ( i ) ) ; } } else { removePreference ( KEY_APP_LIST ) ; } } else { final Context context = getActivity ( ) ; < |startfocus| > UidDetail mUidDetail = new UidDetailProvider ( context ) . getUidDetail ( mAppItem . key , true ) ; mIcon = mUidDetail . icon ; mLabel = mUidDetail . label ; mPackageName = context . getPackageName ( ) ; < |endfocus| > removePreference ( KEY_UNRESTRICTED_DATA ) ; removePreference ( KEY_APP_SETTINGS ) ; removePreference ( KEY_RESTRICT_BACKGROUND ) ; removePreference ( KEY_APP_LIST ) ; }
MAXIMUM_POOL_SIZE , KEEP_ALIVE_SECONDS , TimeUnit . SECONDS , workQueue ) ; for ( int i = 1 ; i < mPackages . size ( ) ; i ++ ) { final AppPrefLoader loader = new AppPrefLoader ( ) ; loader . executeOnExecutor ( executor , mPackages . valueAt ( i ) ) ; } } else { removePreference ( KEY_APP_LIST ) ; } } else { final Context context = getActivity ( ) ; < |startfocus| > UidDetail uidDetail = new UidDetailProvider ( context ) . getUidDetail ( mAppItem . key , true ) ; mIcon = uidDetail . icon ; mLabel = uidDetail . label ; < |endfocus| > mPackageName = context . getPackageName ( ) ; removePreference ( KEY_UNRESTRICTED_DATA ) ; removePreference ( KEY_APP_SETTINGS ) ; removePreference ( KEY_RESTRICT_BACKGROUND ) ; removePreference ( KEY_APP_LIST ) ; }
private void setConnectingThread ( final Thread thread ) { final Thread oldThread = mConnectingThread . getAndSet ( thread ) ; if ( oldThread != null ) { < |startfocus| > oldThread . interrupt ( ) ; < |endfocus| > }
*/ @HasKeyId @Name ( "BoostLockedRegionPriorityFeature" ) @Description ( "Feature turning on BoostLockedRegionPriorityFeature" ) public final class BoostLockedRegionPriorityFeature implements Feature { @Nonnull public static final BooleanPropertyId ENABLE = BooleanPropertyId . create ( "jack . transformations . boost - locked - region - priority" , "Boost priority of threads acquiring certain locks" ) . addCategory ( Private . class ) . addDefaultValue ( Boolean . FALSE ) . addCategory ( DumpInLibrary . class ) ; @Nonnull < |startfocus| > public static final PropertyId < List < String > > BOOST_LOCK_CLASSNAME = < |endfocus| > PropertyId . create ( "jack . transformations . boost - locked - region - priority . classname" , "The class signatures where acquiring it as a lock should boost a thread's prioirty" , new ListCodec < > ( new ClassNameCodec ( ) ) ) . requiredIf ( BoostLockedRegionPriorityFeature . ENABLE . getValue ( ) . isTrue ( ) ) . addCategory ( Private . class ) . addCategory ( DumpInLibrary . class ) ; @Nonnull public static final PropertyId < List < MethodNameValue > > BOOST_LOCK_REQUEST_METHOD = PropertyId . create ( "jack . transformations . boost - locked - region - priority . request" , "Static methods in the specified classes that can boost a thread's prioirty" ,
Jack . getSession ( ) . getReporter ( ) . report ( Severity . FATAL , new BadBoostLockedRegionPriorityConfigurationException ( prop , e ) ) ; Jack . getSession ( ) . abortEventually ( ) ; return null ; } } @Override public void run ( @Nonnull JMethod method ) { if ( method . isNative ( ) || method . isAbstract ( ) || ! filter . accept ( this . getClass ( ) , method ) ) { return ; } < |startfocus| > if ( lockClass . length == 0 || requestClass == null || resetClass == null || requestMethodId == null || resetMethodId == null ) { < |endfocus| > return ; } TransformationRequest tr = new TransformationRequest ( method ) ; Visitor visitor = new Visitor ( method , tr ) ; visitor . accept ( method ) ; tr . commit ( ) ; } private class Visitor extends JVisitor { @Nonnull private final JMethod method ; @Nonnull private final TransformationRequest tr ; public Visitor ( @Nonnull JMethod method , @Nonnull TransformationRequest tr ) { this . method = method ; this . tr = tr ; } @Override public void endVisit ( @Nonnull JLock jLock ) { assert lockClass != null ; int lockIndex = - 1 ;
* Two objects of HIDL types are considered equal if : * 1 . Both null * 2 . Both non - null , and of the same class , and : * 2 . 1 Both are primitive arrays / enum arrays , elements are equal using == check * 2 . 2 Both are object arrays , elements are checked recursively * 2 . 3 Both are Lists , elements are checked recursively * 2 . 4 ( If both are collections other than lists or maps , undefined behavior ) < |startfocus| > * 2 . 5 . equals return true < |endfocus| > */ public static boolean deepEquals ( Object lft , Object rgt ) { if ( lft == rgt ) { return true ; } if ( lft == null || rgt == null ) { return false ; } Class < ? > lftClazz = lft . getClass ( ) ; Class < ? > rgtClazz = rgt . getClass ( ) ; if ( lftClazz != rgtClazz ) { return false ; } if ( lftClazz . isArray ( ) ) { Class < ? > lftElementType = lftClazz . getComponentType ( ) ; if ( lftElementType != rgtClazz . getComponentType ( ) ) { return false ; } if ( lftElementType . isPrimitive ( ) ) { if ( lftElementType == int . class ) { return Arrays . equals ( ( int [ ] ) lft , ( int [ ] ) rgt ) ; } else if ( lftElementType == long . class ) { return Arrays . equals ( ( long [ ] ) lft , ( long [ ] ) rgt ) ; } else if ( lftElementType == boolean . class ) { return Arrays . equals ( ( boolean [ ] ) lft , ( boolean [ ] ) rgt ) ; } else if ( lftElementType == byte . class ) { return Arrays . equals ( ( byte [ ] ) lft , ( byte [ ] ) rgt ) ; } else if ( lftElementType == char . class ) { return Arrays . equals ( ( char [ ] ) lft , ( char [ ] ) rgt ) ; } else if ( lftElementType == float . class ) { return Arrays . equals ( ( float [ ] ) lft , ( float [ ] ) rgt ) ; } else if ( lftElementType == double . class ) { return Arrays . equals ( ( double [ ] ) lft , ( double [ ] ) rgt ) ; } else if ( lftElementType == short . class ) { return Arrays . equals ( ( short [ ] ) lft , ( short [ ] ) rgt ) ; } else { throw new UnsupportedOperationException ( "Unsupported primitive type : " + lftElementType ) ; } } else { return Arrays . deepEquals ( ( Object [ ] ) lft , ( Object [ ] ) rgt ) ; } } else if ( lft instanceof List ) { List < ? > lftList = ( List < ? > ) lft ; List < ? > rgtList = ( List < ? > ) rgt ; if ( lftList . size ( ) != rgtList . size ( ) ) { return false ; } for ( int i = 0 ; i < lftList . size ( ) ; ++ i ) { if ( ! deepEquals ( lftList . get ( i ) , rgtList . get ( i ) ) ) { return false ; } } return true ; } else { return lft . equals ( rgt ) ; } }
* Two objects of HIDL types are considered equal if : * 1 . Both null * 2 . Both non - null , and of the same class , and : * 2 . 1 Both are primitive arrays / enum arrays , elements are equal using == check * 2 . 2 Both are object arrays , elements are checked recursively * 2 . 3 Both are Lists , elements are checked recursively * 2 . 4 ( If both are collections other than lists or maps , undefined behavior ) < |startfocus| > * 2 . 5 . equals return true < |endfocus| > */ public static boolean deepEquals ( Object lft , Object rgt ) { if ( lft == rgt ) { return true ; } if ( lft == null || rgt == null ) { return false ; } Class < ? > lftClazz = lft . getClass ( ) ; Class < ? > rgtClazz = rgt . getClass ( ) ; if ( lftClazz != rgtClazz ) { return false ; } if ( lftClazz . isArray ( ) ) { Class < ? > lftElementType = lftClazz . getComponentType ( ) ; if ( lftElementType != rgtClazz . getComponentType ( ) ) { return false ; } if ( lftElementType . isPrimitive ( ) || lftElementType . isEnum ( ) ) { return Arrays . equals ( ( Object [ ] ) lft , ( Object [ ] ) rgt ) ; } else { return deepEquals ( ( Object [ ] ) lft , ( Object [ ] ) rgt ) ; } } else if ( lft instanceof List ) { List < ? > lftList = ( List < ? > ) lft ; List < ? > rgtList = ( List < ? > ) rgt ; if ( lftList . size ( ) != rgtList . size ( ) ) { return false ; } for ( int i = 0 ; i < lftList . size ( ) ; ++ i ) { if ( ! deepEquals ( lftList . get ( i ) , rgtList . get ( i ) ) ) { return false ; } } return true ; } else { return lft . equals ( rgt ) ; } } private static boolean deepEquals ( Object [ ] lft , Object [ ] rgt ) { if ( lft . length != rgt . length ) { return false ; } for ( int i = 0 ; i < lft . length ; ++ i ) { if ( ! deepEquals ( lft [ i ] , rgt [ i ] ) ) { return false ; } } return true ; } /* * * Returns a hash code value for the object . * * Two objects of HIDL types are considered equal if : * 1 . Both null * 2 . Both non - null , and of the same class , and : * 2 . 1 Both are primitive arrays / enum arrays , elements are equal using == check * 2 . 2 Both are object arrays , elements are checked recursively * 2 . 3 Both are Lists , elements are checked recursively * 2 . 4 ( If both are collections other than lists or maps , undefined behavior ) * 2 . 5 . equals return true */ public static int deepHashCode ( Object obj ) { if ( obj == null ) { return 0 ; } Class < ? > clazz = obj . getClass ( ) ; if ( clazz . isArray ( ) ) { Class < ? > elementType = clazz . getComponentType ( ) ; if ( elementType . isPrimitive ( ) || elementType . isEnum ( ) ) { return Arrays . hashCode ( ( Object [ ] ) obj ) ; } else { return deepHashCode ( ( Object [ ] ) obj ) ; } } else if ( obj instanceof List ) { int hashCode = 1 ; for ( Object element : ( List < ? > ) obj ) { hashCode = 31 * hashCode + deepHashCode ( element ) ; } return hashCode ; } else { return obj . hashCode ( ) ; } } private static int deepHashCode ( Object [ ] array ) { int hashCode = 1 ; for ( Object element : array ) { hashCode = 31 * hashCode + deepHashCode ( element ) ; } return hashCode ; } }
* Two objects of HIDL types are considered equal if : * 1 . Both null * 2 . Both non - null , and of the same class , and : * 2 . 1 Both are primitive arrays / enum arrays , elements are equal using == check * 2 . 2 Both are object arrays , elements are checked recursively * 2 . 3 Both are Lists , elements are checked recursively * 2 . 4 ( If both are collections other than lists or maps , undefined behavior ) < |startfocus| > * 2 . 5 . equals return true < |endfocus| > */ public static boolean deepEquals ( Object lft , Object rgt ) { if ( lft == rgt ) { return true ; } if ( lft == null || rgt == null ) { return false ; } Class < ? > lftClazz = lft . getClass ( ) ; Class < ? > rgtClazz = rgt . getClass ( ) ; if ( lftClazz != rgtClazz ) { return false ; } if ( lftClazz . isArray ( ) ) { Class < ? > lftElementType = lftClazz . getComponentType ( ) ; if ( lftElementType != rgtClazz . getComponentType ( ) ) { return false ; } if ( lftElementType . isPrimitive ( ) || lftElementType . isEnum ( ) ) { return Arrays . equals ( ( Object [ ] ) lft , ( Object [ ] ) rgt ) ; } else { return deepEquals ( ( Object [ ] ) lft , ( Object [ ] ) rgt ) ; } } else if ( lft instanceof List ) { List < ? > lftList = ( List < ? > ) lft ; List < ? > rgtList = ( List < ? > ) rgt ; if ( lftList . size ( ) != rgtList . size ( ) ) { return false ; } for ( int i = 0 ; i < lftList . size ( ) ; ++ i ) { if ( ! deepEquals ( lftList . get ( i ) , rgtList . get ( i ) ) ) { return false ; } } return true ; } else { return lft . equals ( rgt ) ; } } private static boolean deepEquals ( Object [ ] lft , Object [ ] rgt ) { if ( lft . length != rgt . length ) { return false ; } for ( int i = 0 ; i < lft . length ; ++ i ) { if ( ! deepEquals ( lft [ i ] , rgt [ i ] ) ) { return false ; } } return true ; } /* * * Returns a hash code value for the object . * * Two objects of HIDL types are considered equal if : * 1 . Both null * 2 . Both non - null , and of the same class , and : * 2 . 1 Both are primitive arrays / enum arrays , elements are equal using == check * 2 . 2 Both are object arrays , elements are checked recursively * 2 . 3 Both are Lists , elements are checked recursively * 2 . 4 ( If both are collections other than lists or maps , undefined behavior ) * 2 . 5 . equals return true */ public static int deepHashCode ( Object obj ) { if ( obj == null ) { return 0 ; } Class < ? > clazz = obj . getClass ( ) ; if ( clazz . isArray ( ) ) { Class < ? > elementType = clazz . getComponentType ( ) ; if ( elementType . isPrimitive ( ) || elementType . isEnum ( ) ) { return Arrays . hashCode ( ( Object [ ] ) obj ) ; } else { return deepHashCode ( ( Object [ ] ) obj ) ; } } else if ( obj instanceof List ) { int hashCode = 1 ; for ( Object element : ( List < ? > ) obj ) { hashCode = 31 * hashCode + deepHashCode ( element ) ; } return hashCode ; } else { return obj . hashCode ( ) ; } } private static int deepHashCode ( Object [ ] array ) { int hashCode = 1 ; for ( Object element : array ) { hashCode = 31 * hashCode + deepHashCode ( element ) ; } return hashCode ; } }
String invokeWith = null ; if ( ( app . info . flags & ApplicationInfo . FLAG_DEBUGGABLE ) != 0 ) { // Debuggable apps may include a wrapper script with their library directory . String wrapperFileName = app . info . nativeLibraryDir + " / wrap . sh" ; StrictMode . ThreadPolicy oldPolicy = StrictMode . allowThreadDiskReads ( ) ; try { if ( new File ( wrapperFileName ) . exists ( ) ) { invokeWith = " / system / bin / logwrapper " + wrapperFileName ; } } finally { < |startfocus| > StrictMode . setThreadPolicy ( oldPolicy ) ; < |endfocus| > } } String requiredAbi = ( abiOverride != null ) ? abiOverride : app . info . primaryCpuAbi ; if ( requiredAbi == null ) { requiredAbi = Build . SUPPORTED_ABIS [ 0 ] ; } String instructionSet = null ; if ( app . info . primaryCpuAbi != null ) { instructionSet = VMRuntime . getInstructionSet ( app . info . primaryCpuAbi ) ; } app . gids = gids ; app . requiredAbi = requiredAbi ; app . instructionSet = instructionSet ; // Start the process . It will either succeed and return a result containing
loge ( "setWfcSetting ( ) : " , e ) ; } } } /* * * Change persistent WFC enabled setting for slot . */ public void setWfcSettingForSlot ( boolean enabled ) { int value = enabled ? 1 : 0 ; android . provider . Settings . Global . putInt ( mContext . getContentResolver ( ) , android . provider . Settings . Global . WFC_IMS_ENABLED , value ) ; setWfcSettingInternalForSlot ( enabled , getWfcModeForSlot ( ) ) ; } /* * * Non - persistently change WFC eanbled setting and WFC preference for slot * * @param wfcMode The WFC preference if WFC is enabled */ public void setWfcSettingInternalForSlot ( boolean enabled , int wfcMode ) { int imsFeatureValue = enabled ? ImsConfig . FeatureValueConstants . ON : ImsConfig . FeatureValueConstants . OFF ; // Force IMS to register over LTE when turning off WFC int imsWfcModeFeatureValue = enabled ? wfcMode : ImsConfig . WfcModeFeatureValueConstants . CELLULAR_PREFERRED ; try { ImsConfig config = getConfigInterface ( ) ; config . setFeatureValue ( ImsConfig . FeatureConstants . FEATURE_TYPE_VOICE_OVER_WIFI , TelephonyManager . NETWORK_TYPE_IWLAN ,
loge ( "setWfcSetting ( ) : " , e ) ; } } } /* * * Change persistent WFC enabled setting for slot . */ public void setWfcSettingForSlot ( boolean enabled ) { int value = enabled ? 1 : 0 ; android . provider . Settings . Global . putInt ( mContext . getContentResolver ( ) , android . provider . Settings . Global . WFC_IMS_ENABLED , value ) ; setWfcSettingInternalForSlot ( enabled , getWfcModeForSlot ( ) ) ; } /* * < |startfocus| > * Non - persistently change WFC enabled setting and WFC preference for slot < |endfocus| > * * @param wfcMode The WFC preference if WFC is enabled */ public void setWfcSettingInternalForSlot ( boolean enabled , int wfcMode ) { int imsFeatureValue = enabled ? ImsConfig . FeatureValueConstants . ON : ImsConfig . FeatureValueConstants . OFF ; // Force IMS to register over LTE when turning off WFC int imsWfcModeFeatureValue = enabled ? wfcMode : ImsConfig . WfcModeFeatureValueConstants . CELLULAR_PREFERRED ; try { ImsConfig config = getConfigInterface ( ) ; config . setFeatureValue ( ImsConfig . FeatureConstants . FEATURE_TYPE_VOICE_OVER_WIFI , TelephonyManager . NETWORK_TYPE_IWLAN ,
< |startfocus| > void setWfcSettingInternalForSlot ( boolean enabled , int wfcMode ) { < |endfocus| > int imsFeatureValue = enabled ? ImsConfig . FeatureValueConstants . ON : ImsConfig . FeatureValueConstants . OFF ; // Force IMS to register over LTE when turning off WFC int imsWfcModeFeatureValue = enabled ? wfcMode : ImsConfig . WfcModeFeatureValueConstants . CELLULAR_PREFERRED ; try { ImsConfig config = getConfigInterface ( ) ; config . setFeatureValue ( ImsConfig . FeatureConstants . FEATURE_TYPE_VOICE_OVER_WIFI , TelephonyManager . NETWORK_TYPE_IWLAN , imsFeatureValue , mImsConfigListener ) ; if ( enabled ) { log ( "setWfcSettingForSlot ( ) : turnOnIms" ) ; turnOnIms ( ) ; } else if ( isTurnOffImsAllowedByPlatformForSlot ( ) && ( ! isVolteEnabledByPlatformForSlot ( ) || ! isEnhanced4gLteModeSettingEnabledByUserForSlot ( ) ) ) { log ( "setWfcSettingForSlot ( ) : imsServiceAllowTurnOff - > turnOffIms" ) ; turnOffIms ( ) ; } setWfcModeInternalForSlot ( imsWfcModeFeatureValue ) ; } catch ( ImsException e ) { loge ( "setWfcSettingForSlot ( ) : " , e ) ; }
* < h3 > Developer Guides </ h3 > * < p > For more information about using Bluetooth , read the * < a href = " { @docRoot } guide / topics / connectivity / bluetooth . html" > Bluetooth </ a > developer guide . </ p > * </ div > * * { @see BluetoothServerSocket } * { @see java . io . InputStream } * { @see java . io . OutputStream } */ public final class BluetoothSocket implements Closeable { private static final String TAG = "BluetoothSocket" ; < |startfocus| > private static final boolean DBG = true ; < |endfocus| > private static final boolean VDBG = Log . isLoggable ( TAG , Log . VERBOSE ) ; /* * @hide */ public static final int MAX_RFCOMM_CHANNEL = 30 ; /* package */ static final int MAX_L2CAP_PACKAGE_SIZE = 0xFFFF ; /* * RFCOMM socket */ public static final int TYPE_RFCOMM = 1 ; /* * SCO socket */ public static final int TYPE_SCO = 2 ; /* * L2CAP socket */ public static final int TYPE_L2CAP = 3 ; /* package */ static final int EBADFD = 77 ; /* package */ static final int EADDRINUSE = 98 ; /* package */ static final int EAFNOSUPPORT = 97 ; /* package */ static final int EAGAIN = 11 ; /* package */ static final int EALREADY = 114 ; /* package */ static final int EBADF = 9 ; /* package */ static final int ECONNREFUSED = 111 ; /* package */ static final int EFAULT = 14 ; /* package */ static final int EINPROGRESS = 115 ; /* package */ static final int EINVAL = 22 ; /* package */ static final int EISCONN = 106 ; /* package */ static final int ENOMEM = 12 ; /* package */ static final int ENOTCONN = 107 ; /* package */ static final int ENOTSOCK = 88 ; /* package */ static final int EOPNOTSUPP = 95 ; /* package */ static final int EPROTONOSUPPORT = 93 ; /* package */ static final int ETIMEDOUT = 110 ; /* package */ static final int ECONNRESET = 104 ; /* package */ static final int EIO = 5 ; /* package */ static final int EHOSTUNREACH = 113 ; /* package */ static final int ENETUNREACH = 101 ; /* package */ static final int EACCES = 13 ; /* package */ static final int EMSGSIZE = 90 ; /* package */ static final int EADDRNOTAVAIL = 99 ; /* package */ static final int ECONNABORTED = 103 ; /* package */ static final int EINTR = 4 ; /* package */ static final int ENETDOWN = 100 ; /* package */ static final int ENOBUFS = 105 ; /* package */ static final int ENOTSUP = 95 ; /* package */ static final int EPERM = 1 ; /* package */ static final int EPROTO = 92 ; /* package */ static final int ESRMNT = 69 ; /* package */ static final int EADV = 68 ; /* package */ static final int ESRVRFAULT = 70 ; /* package */ static final int ETOOMANYREFS = 109 ; /* package */ static final int ELOOP = 40 ; /* package */ static final int ENAMETOOLONG = 36 ; /* package */ static final int EHOSTDOWN = 112 ; /* package */ static final int ENOENT = 2 ; /* package */ static final int ENOTDIR = 20 ; /* package */ static final int EROFS = 30 ; /* package */ static final int EXDEV = 18 ; /* package */ static final int EFAULT = 14 ; /* package */ static final int EMLINK = 31 ; /* package */ static final int ENODEV = 19 ; /* package */ static final int EPIPE = 32 ; /* package */ static final int EPROTOTYPE = 91 ; /* package */ static final int EOVERFLOW = 75 ; /* package */ static final int EISDIR = 21 ; /* package */ static final int EMLINK = 31 ; /* package */ static final int ENODEV = 19 ; /* package */ static final int EPIPE = 32 ; /* package */ static final int EPROTOTYPE = 91 ; /* package */ static final int EOVERFLOW = 75 ; /* package */ static final int EISDIR = 21 ; /* package */ static final int ENFILE = 23 ; /* package */ static final int ENOSPC = 28 ; /* package */ static final int EPROTOTYPE = 91 ; /* package */ static final int ESPIPE = 29 ; /* package */ static final int ENOTBLK = 15 ; /* package */ static final int ENOEXEC = 8 ; /* package */ static final int ENOSR = 63 ; /* package */ static final int EPROTOTYPE = 91 ; /* package */ static final int ESTALE = 116 ; /* package */ static final int EXDEV = 18 ; /* package */ static final int ENOTBLK = 15 ; /* package */ static final int ENOEXEC = 8 ; /* package */ static final int ENOSR = 63 ; /* package */ static final int EPROTOTYPE = 91 ; /* package */ static final int ESTALE = 116 ; /* package */ static final int EXDEV = 18 ; /* package */ static final int ENOTBLK = 15 ; /* package */ static final int ENOEXEC = 8 ; /* package */ static final int ENOSR = 63 ; /* package */ static final int EPROTOTYPE = 91 ; /* package */ static final int ESTALE = 116 ; /* package */ static final int EXDEV = 18 ; /* package */ static final int ENOTBLK = 15 ; /* package */ static final int ENOEXEC = 8 ; /* package */ static final int ENOSR = 63 ; /* package */ static final int EPROTOTYPE = 91 ; /* package */ static final int ESTALE = 116 ; /* package */ static final int EXDEV = 18 ; /* package */ static final int ENOTBLK = 15 ; /* package */ static final int ENOEXEC = 8 ; /* package */ static final int ENOSR = 63 ; /* package */ static final int EPROTOTYPE = 91 ; /* package */ static final int ESTALE = 116 ; /* package */ static final int EXDEV = 18 ; /* package */ static final int ENOTBLK = 15 ; /* package */ static final int ENOEXEC = 8 ; /* package */ static final int ENOSR = 63 ; /* package */ static final int EPROTOTYPE = 91 ; /* package */ static final int ESTALE = 116 ; /* package */ static final int EXDEV = 18 ; /* package */ static final int ENOTBLK = 15 ; /* package */ static final int ENOEXEC = 8 ; /* package */ static final int ENOSR = 63 ; /* package */ static final int EPROTOTYPE = 91 ; /* package */ static final int ESTALE = 116 ; /* package */ static final int EXDEV = 18 ; /* package */ static final int ENOTBLK = 15 ; /* package */ static final int ENOEXEC = 8 ; /* package */ static final int ENOSR = 63 ; /* package */ static final int EPROTOTYPE = 91 ; /* package */ static final int ESTALE = 116 ; /* package */ static final int EXDEV = 18 ; /* package */ static final int ENOTBLK = 15 ; /* package */ static final int ENOEXEC = 8 ; /* package */ static final int ENOSR = 63 ; /* package */ static final int EPROTOTYPE = 91 ; /* package */ static final int ESTALE = 116 ; /* package */ static final int EXDEV = 18 ; /* package */ static final int ENOTBLK = 15 ; /* package */ static final int ENOEXEC = 8 ; /* package */ static final int ENOSR = 63 ; /* package */ static final int EPROTOTYPE = 91 ; /* package */ static final int ESTALE = 116 ; /* package */ static final int EXDEV = 18
public NetworkCapabilities setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { if ( networkSpecifier != null && Long . bitCount ( mTransportTypes ) != 1 ) { throw new IllegalStateException ( "Must have a single transport specified to use " + "setNetworkSpecifier" ) ; } < |startfocus| > if ( networkSpecifier != null && ! ( networkSpecifier instanceof Parcelable ) ) { throw new IllegalArgumentException ( "Network specifier must be parcelable" ) ; } mNetworkSpecifier = networkSpecifier ; return this ;
public boolean equals ( Object o ) { < |startfocus| > return o instanceof MatchAllNetworkSpecifier ; < |endfocus| >
public NetworkCapabilities setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { if ( networkSpecifier != null && Long . bitCount ( mTransportTypes ) != 1 ) { throw new IllegalStateException ( "Must have a single transport specified to use " + "setNetworkSpecifier" ) ; } < |startfocus| > if ( networkSpecifier != null && ! ( networkSpecifier instanceof Parcelable ) ) { throw new IllegalArgumentException ( "Network specifier must be parcelable" ) ; } mNetworkSpecifier = networkSpecifier ; return this ; < |endfocus| >
private boolean satisfiedBySpecifier ( NetworkCapabilities nc ) { < |startfocus| > return mNetworkSpecifier == null || mNetworkSpecifier . satisfiedBy ( nc . mNetworkSpecifier ) || nc . mNetworkSpecifier instanceof MatchAllNetworkSpecifier ; < |endfocus| >
( mLinkUpBandwidthKbps * 11 ) + ( mLinkDownBandwidthKbps * 13 ) + Objects . hashCode ( mNetworkSpecifier ) * 17 + ( mSignalStrength * 19 ) ) ; } @Override public int describeContents ( ) { return 0 ; } @Override public void writeToParcel ( Parcel dest , int flags ) { dest . writeLong ( mNetworkCapabilities ) ; dest . writeLong ( mTransportTypes ) ; dest . writeInt ( mLinkUpBandwidthKbps ) ; dest . writeInt ( mLinkDownBandwidthKbps ) ; < |startfocus| > dest . writeParcelable ( mNetworkSpecifier , 0 ) ; < |endfocus| > dest . writeInt ( mSignalStrength ) ; } public static final Creator < NetworkCapabilities > CREATOR = new Creator < NetworkCapabilities > ( ) { @Override public NetworkCapabilities createFromParcel ( Parcel in ) { NetworkCapabilities netCap = new NetworkCapabilities ( ) ; netCap . mNetworkCapabilities = in . readLong ( ) ; netCap . mTransportTypes = in . readLong ( ) ; netCap . mLinkUpBandwidthKbps = in . readInt ( ) ; netCap . mLinkDownBandwidthKbps = in . readInt ( ) ; netCap . mNetworkSpecifier = in . readParcelable ( null ) ; netCap . mSignalStrength = in . readInt ( ) ; return netCap ; } @Override
( mLinkUpBandwidthKbps * 11 ) + ( mLinkDownBandwidthKbps * 13 ) + Objects . hashCode ( mNetworkSpecifier ) * 17 + ( mSignalStrength * 19 ) ) ; } @Override public int describeContents ( ) { return 0 ; } @Override public void writeToParcel ( Parcel dest , int flags ) { dest . writeLong ( mNetworkCapabilities ) ; dest . writeLong ( mTransportTypes ) ; dest . writeInt ( mLinkUpBandwidthKbps ) ; dest . writeInt ( mLinkDownBandwidthKbps ) ; < |startfocus| > dest . writeParcelable ( ( Parcelable ) mNetworkSpecifier , flags ) ; < |endfocus| > dest . writeInt ( mSignalStrength ) ; } public static final Creator < NetworkCapabilities > CREATOR = new Creator < NetworkCapabilities > ( ) { @Override public NetworkCapabilities createFromParcel ( Parcel in ) { NetworkCapabilities netCap = new NetworkCapabilities ( ) ; netCap . mNetworkCapabilities = in . readLong ( ) ; netCap . mTransportTypes = in . readLong ( ) ; netCap . mLinkUpBandwidthKbps = in . readInt ( ) ; netCap . mLinkDownBandwidthKbps = in . readInt ( ) ; netCap . mNetworkSpecifier = in . readParcelable ( null ) ; netCap . mSignalStrength = in . readInt ( ) ; return netCap ; } @Override
public StringNetworkSpecifier ( String specifier ) { < |startfocus| > Preconditions . checkNotNull ( specifier , "Network specifier must not be null" ) ; < |endfocus| > this . specifier = specifier ;
public boolean satisfiedBy ( NetworkSpecifier other ) { < |startfocus| > if ( other == null ) return false ; if ( ! ( other instanceof StringNetworkSpecifier ) ) return false ; return equals ( other ) ; < |endfocus| >
/* Copyright ( C ) 2016 The Android Open Source Project * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package android . net ; import android . os . Parcel ; import android . os . Parcelable ; import android . text . TextUtils ; import java . util . Objects ; /* * @hide */ public final class StringNetworkSpecifier extends NetworkSpecifier implements Parcelable { public final String specifier ; public StringNetworkSpecifier ( String specifier ) { if ( TextUtils . isEmpty ( specifier ) ) { throw new IllegalArgumentException ( "Network specifier must not be empty" ) ; }
public boolean satisfiedBy ( NetworkSpecifier other ) { < |startfocus| > if ( other == null ) return true ; < |endfocus| > if ( ! ( other instanceof StringNetworkSpecifier ) ) return false ; return specifier . equals ( ( ( StringNetworkSpecifier ) other ) . specifier ) ; }
< |startfocus| > private IpSecService ( Context context ) { < |endfocus| > mContext = context ;
/* * Binder context for this service */ private final Context mContext ; private Object mLock = new Object ( ) ; private static final int NETD_FETCH_TIMEOUT = 5000 ; // ms /* * * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService ( Context context , String socket ) { mContext = context ; } < |startfocus| > static IpSecService create ( Context context , String socket ) throws InterruptedException { final IpSecService service = new IpSecService ( context , socket ) ; < |endfocus| > service . connectNativeNetdService ( ) ; return service ; } public static IpSecService create ( Context context ) throws InterruptedException { return create ( context , NETD_SERVICE_NAME ) ; } public void systemReady ( ) { if ( isNetdAlive ( ) ) { Slog . d ( TAG , "IpSecService is ready" ) ; } else { Slog . wtf ( TAG , "IpSecService not ready : failed to connect to NetD Native Service ! " ) ; } } private void connectNativeNetdService ( ) { // Avoid blocking the system server to do this Thread t = new Thread ( new Runnable ( ) { @Override public void run ( ) { try { mNetdService = INetd . Stub . asInterface ( ServiceManager . getService ( NETD_SERVICE_NAME ) ) ; } catch ( Exception e ) { Slog . wtf ( TAG , "Failed to connect to NetD Native Service" , e ) ; } } } ) ; t . start ( ) ; try { t . join ( NETD_FETCH_TIMEOUT ) ; } catch ( InterruptedException e ) { Slog . wtf ( TAG , "Failed to connect to NetD Native Service" , e ) ; } } private boolean isNetdAlive ( ) { return mNetdService != null ; }
/* * * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService ( Context context , String socket ) { mContext = context ; } static IpSecService create ( Context context , String socket ) throws InterruptedException { final IpSecService service = new IpSecService ( context , socket ) ; service . connectNativeNetdService ( ) ; return service ; } < |startfocus| > public static IpSecService create ( Context context ) throws InterruptedException { return create ( context , NETD_SERVICE_NAME ) ; } < |endfocus| > public void systemReady ( ) { if ( isNetdAlive ( ) ) { Slog . d ( TAG , "IpSecService is ready" ) ; } else { Slog . wtf ( TAG , "IpSecService not ready : failed to connect to NetD Native Service ! " ) ; } } private void connectNativeNetdService ( ) { // Avoid blocking the system server to do this Thread t = new Thread ( new Runnable ( ) { @Override public void run ( ) { synchronized ( mLock ) { NetdService . get ( NETD_FETCH_TIMEOUT ) ; } }
} void unlinkDeathRecipient ( ) { if ( mBinder != null ) { mBinder . unlinkToDeath ( this , 0 ) ; } } protected void releaseResources ( ) { } protected void nullifyRecord ( ) { } public void binderDied ( ) { Log . w ( TAG , "IpSecService . SpiRecord binderDied ( " + mBinder + " ) " ) ; } } < |startfocus| > private final SparseArray < SpiRecord > mSpiRecords = new SparseArray < > ( ) ; private final SparseArray < TransformRecord > mTransformRecords = new SparseArray < > ( ) ; < |endfocus| > /* * * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService ( Context context ) { mContext = context ; } static IpSecService create ( Context context ) throws InterruptedException { final IpSecService service = new IpSecService ( context ) ; service . connectNativeNetdService ( ) ; return service ; } public void systemReady ( ) { if ( isNetdAlive ( ) ) { Slog . d ( TAG , "IpSecService is ready" ) ; } else {
} catch ( RemoteException e ) { throw e . rethrowFromSystemServer ( ) ; } synchronized ( mSpiRecords ) { mSpiRecords . put ( resourceId , new SpiRecord ( resourceId , direction , localAddress , remoteAddress , spi , binder ) ) ; } Bundle retBundle = new Bundle ( 3 ) ; retBundle . putInt ( IpSecManager . SecurityParameterIndex . KEY_STATUS , IpSecManager . Status . OK ) ; retBundle . putInt ( IpSecManager . SecurityParameterIndex . KEY_RESOURCE_ID , resourceId ) ; retBundle . putInt ( IpSecManager . SecurityParameterIndex . KEY_SPI , spi ) ; < |startfocus| > return retBundle ; < |endfocus| >
< |startfocus| > public Bundle createTransportModeTransform ( IpSecConfig c , IBinder binder ) { < |endfocus| > int resourceId = mNextTransformId . getAndIncrement ( ) ; for ( int direction : new int [ ] { IpSecTransform . DIRECTION_OUT , IpSecTransform . DIRECTION_IN } ) { IpSecAlgorithm auth = c . getAuthentication ( direction ) ; IpSecAlgorithm crypt = c . getEncryption ( direction ) ; try { int result = getNetdInstance ( ) . ipSecAddSecurityAssociation ( resourceId , c . getMode ( ) , direction , ( c . getLocalAddress ( ) != null ) ? c . getLocalAddress ( ) . getHostAddress ( ) : "" , ( c . getRemoteAddress ( ) != null ) ? c . getRemoteAddress ( ) . getHostAddress ( ) : "" , ( c . getNetwork ( ) != null ) ? c . getNetwork ( ) . getNetworkHandle ( ) : 0 , c . getSpi ( direction ) , ( auth != null ) ? auth . getName ( ) : "" , ( auth != null ) ? auth . getKey ( ) : null , ( auth != null ) ? auth . getTruncationLengthBits ( ) : 0 , ( crypt != null ) ? crypt . getName ( ) : "" , ( crypt != null ) ? crypt . getKey ( ) : null , ( crypt != null ) ? crypt . getTruncationLengthBits ( ) : 0 ) ;
public Bundle createTransportModeTransform ( IpSecConfig c , IBinder binder ) { int resourceId = mNextTransformId . getAndIncrement ( ) ; < |startfocus| > for ( int direction : new int [ ] { IpSecTransform . DIRECTION_OUT , IpSecTransform . DIRECTION_IN } ) { < |endfocus| > IpSecAlgorithm auth = c . getAuthentication ( direction ) ; IpSecAlgorithm crypt = c . getEncryption ( direction ) ; try { int result = getNetdInstance ( ) . ipSecAddSecurityAssociation ( resourceId , c . getMode ( ) , direction , ( c . getLocalAddress ( ) != null ) ? c . getLocalAddress ( ) . getHostAddress ( ) : "" , ( c . getRemoteAddress ( ) != null ) ? c . getRemoteAddress ( ) . getHostAddress ( ) : "" , ( c . getNetwork ( ) != null ) ? c . getNetwork ( ) . getNetworkHandle ( ) : 0 , c . getSpi ( direction ) , ( auth != null ) ? auth . getName ( ) : "" , ( auth != null ) ? auth . getKey ( ) : null , ( auth != null ) ? auth . getTruncationLengthBits ( ) : 0 , ( crypt != null ) ? crypt . getName ( ) : "" , ( crypt != null ) ? crypt . getKey ( ) : null , ( crypt != null ) ? crypt . getTruncationLengthBits ( ) : 0 ,
( auth != null ) ? auth . getKey ( ) : null , ( auth != null ) ? auth . getTruncationLengthBits ( ) : 0 , ( crypt != null ) ? crypt . getName ( ) : "" , ( crypt != null ) ? crypt . getKey ( ) : null , ( crypt != null ) ? crypt . getTruncationLengthBits ( ) : 0 , c . getEncapType ( ) , c . getEncapLocalPort ( ) , c . getEncapRemotePort ( ) ) ; if ( result != c . getSpi ( direction ) ) { Bundle retBundle = new Bundle ( 2 ) ; retBundle . putInt ( IpSecTransform . KEY_STATUS , IpSecManager . Status . SPI_UNAVAILABLE ) ; < |startfocus| > retBundle . putInt ( IpSecTransform . KEY_RESOURCE_ID , IpSecTransform . INVALID_SPI ) ; < |endfocus| > return retBundle ; } } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception } catch ( RemoteException e ) { throw e . rethrowFromSystemServer ( ) ; } } synchronized ( mTransformRecords ) { mTransformRecords . put ( resourceId , new TransformRecord ( c , resourceId , binder ) ) ; }
( crypt != null ) ? crypt . getKey ( ) : null , ( crypt != null ) ? crypt . getTruncationLengthBits ( ) : 0 , c . getEncapType ( ) , c . getEncapLocalPort ( ) , c . getEncapRemotePort ( ) ) ; if ( result != c . getSpi ( direction ) ) { Bundle retBundle = new Bundle ( 2 ) ; retBundle . putInt ( IpSecTransform . KEY_STATUS , IpSecManager . Status . SPI_UNAVAILABLE ) ; < |startfocus| > retBundle . putInt ( IpSecTransform . KEY_RESOURCE_ID , IpSecTransform . INVALID_SPI ) ; < |endfocus| > return retBundle ; } } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception } catch ( RemoteException e ) { throw e . rethrowFromSystemServer ( ) ; } } synchronized ( mTransformRecords ) { mTransformRecords . put ( resourceId , new TransformRecord ( c , resourceId , binder ) ) ; } Bundle retBundle = new Bundle ( 2 ) ; retBundle . putInt ( IpSecTransform . KEY_STATUS , IpSecManager . Status . OK ) ; retBundle . putInt ( IpSecTransform . KEY_RESOURCE_ID , resourceId ) ; return retBundle ;
public void deleteTransportModeTransform ( int resourceId ) { TransformRecord record ; synchronized ( mTransformRecords ) { < |startfocus| > // We want to non - destructively get so that we can check credentials before removing this record = mTransformRecords . get ( resourceId ) ; if ( record == null ) { throw new IllegalArgumentException ( "Transform " + resourceId + " is not available to be deleted" ) ; } if ( record . pid != getCallingPid ( ) || record . uid != getCallingUid ( ) ) { throw new SecurityException ( "Only the owner of an IpSec Transform may delete it ! " ) ; } // remove from the DB because releasing might fail , but it won't ever succeed later mTransformRecords . remove ( resourceId ) ; record . releaseResources ( ) ; record . nullifyRecord ( ) ; < |endfocus| > }
record = mTransformRecords . get ( resourceId ) ; if ( record == null ) { throw new IllegalArgumentException ( "Transform " + resourceId + " is not available to be deleted" ) ; } if ( record . pid != getCallingPid ( ) || record . uid != getCallingUid ( ) ) { throw new SecurityException ( "Only the owner of an IpSec Transform may delete it ! " ) ; } < |startfocus| > // remove from the DB because releasing might fail , but it won't ever succeed later mTransformRecords . remove ( resourceId ) ; record . releaseResources ( ) ; record . nullifyRecord ( ) ; < |endfocus| > }
public void applyTransportModeTransform ( ParcelFileDescriptor socket , int resourceId ) { < |startfocus| > TransformRecord info ; < |endfocus| > synchronized ( mTransformRecords ) { // FIXME : this code should be factored out into a security check + getter info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( "Transform " + resourceId + " is not active" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( "Only the owner of an IpSec Transform may apply it ! " ) ; } IpSecConfig c = info . getConfig ( ) ; try { for ( int direction : new int [ ] { IpSecTransform . DIRECTION_OUT , IpSecTransform . DIRECTION_IN } ) { getNetdInstance ( ) . ipSecApplyTransportModeTransform ( socket . getFileDescriptor ( ) , resourceId , direction , ( c . getLocalAddress ( ) != null ) ? c . getLocalAddress ( ) . getHostAddress ( ) : "" , ( c . getRemoteAddress ( ) != null ) ? c . getRemoteAddress ( ) . getHostAddress ( ) : "" , < |startfocus| > info . getConfig ( ) . getNetwork ( ) < |endfocus| > ) ; } } catch ( ServiceSpecificException e ) { throw new IllegalArgumentException ( "Unable to apply transform" , e ) ; } } }
import static org . mockito . Mockito . mock ; import android . content . Context ; import android . os . Handler ; import android . os . test . TestLooper ; import android . test . suitebuilder . annotation . SmallTest ; import org . junit . Before ; < |startfocus| > import org . junit . Test ; import org . mockito . ArgumentCaptor ; < |endfocus| > import org . mockito . Mock ; import org . mockito . MockitoAnnotations ; /* * * Unit tests for { @link android . net . wifi . WifiScanner } . */ @SmallTest public class WifiScannerTest { @Mock private Context mContext ; @Mock private IWifiScanner mService ; private WifiScanner mWifiScanner ; private TestLooper mLooper ; private Handler mHandler ; /* * * Setup before tests . */ @Before public void setUp ( ) throws Exception { MockitoAnnotations . initMocks ( this ) ; mLooper = new TestLooper ( ) ; mHandler = mock ( Handler . class ) ;
mImsRegistered = ( responseArray [ 0 ] == 1 ) ? true : false ; } break ; // GSM case EVENT_RADIO_AVAILABLE : // this is unnecessary // setPowerStateToDesired ( ) ; break ; case EVENT_SIM_READY : // Reset the mPreviousSubId so we treat a SIM power bounce // as a first boot . See b / 19194287 mOnSubscriptionsChangedListener . mPreviousSubId . set ( - 1 ) ; pollState ( ) ; // Signal strength polling stops when radio is off queueNextSignalStrengthPoll ( ) ; < |startfocus| > setNotification ( CS_ENABLED ) ; < |endfocus| > break ; case EVENT_RADIO_STATE_CHANGED : case EVENT_PHONE_TYPE_SWITCHED : if ( ! mPhone . isPhoneTypeGsm ( ) && mCi . getRadioState ( ) == CommandsInterface . RadioState . RADIO_ON ) { handleCdmaSubscriptionSource ( mCdmaSSM . getCdmaSubscriptionSource ( ) ) ; // Signal strength polling stops when radio is off . queueNextSignalStrengthPoll ( ) ; } // This will do nothing in the 'radio not available' case setPowerStateToDesired ( ) ; // These events are modem triggered , so pollState ( ) needs to be forced modemTriggeredPollState ( ) ; break ; case EVENT_RUIM_RECORDS_LOADED : // This will do nothing in the 'radio not available' case setPowerStateToDesired ( ) ; break ;
* Reference : 3GPP TS 36 . 104 5 . 4 . 3 ) inclusive ranges on which lte_rsrp_boost_int * will be applied . Format of the String array is expected to be { "erafcn1_start - earfcn1_end" , * "earfcn2_start - earfcn2_end" . . . } * @hide */ public static final String KEY_BOOSTED_LTE_EARFCNS_STRING_ARRAY = "boosted_lte_earfcns_string_array" ; < |startfocus| > /* * * Key identifying if voice call barring notification is required to be shown to user . * @hide */ public static final String KEY_DISABLE_VOICE_BARRING_NOTIFICATION_BOOL = "disable_voice_barring_notification_bool" ; < |endfocus| > /* * The default value for every variable . */ private final static PersistableBundle sDefaults ; static { sDefaults = new PersistableBundle ( ) ; sDefaults . putBoolean ( KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL , true ) ; sDefaults . putBoolean ( KEY_ADDITIONAL_CALL_SETTING_BOOL , true ) ; sDefaults . putBoolean ( KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL , false ) ; sDefaults . putBoolean ( KEY_ALLOW_LOCAL_DTMF_TONES_BOOL , true ) ;
* perform operations that pertain to network connectivity at an abstract * level , use { @link android . net . ConnectivityManager } . */ public class WifiManager { private static final String TAG = "WifiManager" ; // Supplicant error codes : /* * * The error code if there was a problem authenticating . */ public static final int ERROR_AUTHENTICATING = 1 ; // Supplicant Authentication Failure reason codes : /* * < |startfocus| > * Default reason code for error during authentication . < |endfocus| > * @hide */ public static final int ERROR_AUTH_FAILURE_NONE = 0 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was a timeout authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was a wrong password while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2 ; // Supplicant Authentication Failure reason codes : /* * < |startfocus| > * The reason code if there was an EAP failure while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3 ; // Supplicant Authentication Failure reason codes : /* * < |endfocus| > * The reason code if there was a wrong password while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2 ; // Supplicant Authentication Failure reason codes : /* *
*/ public class WifiManager { private static final String TAG = "WifiManager" ; // Supplicant error codes : /* * * The error code if there was a problem authenticating . */ public static final int ERROR_AUTHENTICATING = 1 ; // Supplicant Authentication Failure reason codes : /* * * Default reason code for error during authentication . * @hide */ public static final int ERROR_AUTH_FAILURE_NONE = 0 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was a timeout authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was a wrong password while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was EAP failure while * authenticating . * @hide */
*/ public static final int ERROR_AUTHENTICATING = 1 ; // Supplicant Authentication Failure reason codes : /* * * Default reason code for error during authentication . * @hide */ public static final int ERROR_AUTH_FAILURE_NONE = 0 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was a timeout authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was a wrong password while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was EAP failure while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3 ; /* * * Broadcast intent action indicating whether Wi - Fi scanning is allowed currently * @hide */
// Supplicant Authentication Failure reason codes : /* * * The reason code if there was a timeout authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was a wrong password while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2 ; // Supplicant Authentication Failure reason codes : /* * * The reason code if there was EAP failure while * authenticating . * @hide */ public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3 ; /* * * Broadcast intent action indicating whether Wi - Fi scanning is allowed currently * @hide */ public static final String WIFI_SCAN_AVAILABLE = "wifi_scan_available" ; /* * * Extra int indicating scan availability , WIFI_STATE_ENABLED and WIFI_STATE_DISABLED * @hide */ public static final String EXTRA_SCAN_AVAILABLE = "scan_enabled" ; /* *
( mLinkUpBandwidthKbps * 11 ) + ( mLinkDownBandwidthKbps * 13 ) + Objects . hashCode ( mNetworkSpecifier ) * 17 + ( mSignalStrength * 19 ) ) ; } @Override public int describeContents ( ) { return 0 ; } @Override public void writeToParcel ( Parcel dest , int flags ) { dest . writeLong ( mNetworkCapabilities ) ; dest . writeLong ( mTransportTypes ) ; dest . writeInt ( mLinkUpBandwidthKbps ) ; dest . writeInt ( mLinkDownBandwidthKbps ) ; < |startfocus| > dest . writeParcelable ( mNetworkSpecifier , 0 ) ; < |endfocus| > dest . writeInt ( mSignalStrength ) ; } public static final Creator < NetworkCapabilities > CREATOR = new Creator < NetworkCapabilities > ( ) { @Override public NetworkCapabilities createFromParcel ( Parcel in ) { NetworkCapabilities netCap = new NetworkCapabilities ( ) ; netCap . mNetworkCapabilities = in . readLong ( ) ; netCap . mTransportTypes = in . readLong ( ) ; netCap . mLinkUpBandwidthKbps = in . readInt ( ) ; netCap . mLinkDownBandwidthKbps = in . readInt ( ) ; netCap . mNetworkSpecifier = in . readParcelable ( null ) ; netCap . mSignalStrength = in . readInt ( ) ; return netCap ; } @Override
* distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package android . net ; /* * * Describes specific properties of a network for use in a { @link NetworkRequest } . * * Applications cannot instantiate this class by themselves , but can obtain instances of this * class via other APIs . */ public abstract class NetworkSpecifier { /* * * Returns true if a request with this { @link NetworkSpecifier } is satisfied by a network * with the given NetworkSpecifier . */ public abstract boolean satisfiedBy ( NetworkSpecifier other ) ; /* * * This constructor is used by the framework to create NetworkSpecifiers . * Apps should not be able to extend this class . */ NetworkSpecifier ( ) { } }
// STATE_DIALING , put it on hold before answering the call . if ( foregroundCall != null && foregroundCall != call && ( foregroundCall . isActive ( ) || foregroundCall . getState ( ) == CallState . DIALING || foregroundCall . getState ( ) == CallState . PULLING ) ) { if ( ! foregroundCall . getTargetPhoneAccount ( ) . equals ( call . getTargetPhoneAccount ( ) ) && < |startfocus| > ( call . isSelfManaged ( ) != foregroundCall . isSelfManaged ( ) || < |endfocus| > call . isSelfManaged ( ) ) ) { // The foreground call is from another connection service , and either : // 1 . FG call's managed state doesn't match that of the incoming call . // E . g . Incoming is self - managed and FG is managed , or incoming is managed // and foreground is self - managed . // 2 . The incoming call is self - managed . // E . g . The incoming call is Log . i ( this , "Answering call from % s CS ; disconnecting calls from % s CS . " , foregroundCall . isSelfManaged ( ) ? "selfMg" : "mg" ,
@Mock private Call mVideoCall ; @Mock private Call mRingingCall ; private IncomingCallNotifier mIncomingCallNotifier ; private NotificationManager mNotificationManager ; public void setUp ( ) throws Exception { super . setUp ( ) ; mContext = mComponentContextFixture . getTestDouble ( ) . getApplicationContext ( ) ; ApplicationInfo info = new ApplicationInfo ( ) ; info . targetSdkVersion = Build . VERSION_CODES . N_MR1 ; doReturn ( info ) . when ( mContext ) . getApplicationInfo ( ) ; doReturn ( null ) . when ( mContext ) . getTheme ( ) ; < |startfocus| > // mContext . getApplicationInfo ( ) . targetSdkVersion < |endfocus| > mNotificationManager = ( NotificationManager ) mContext . getSystemService ( Context . NOTIFICATION_SERVICE ) ; mIncomingCallNotifier = new IncomingCallNotifier ( mContext ) ; mIncomingCallNotifier . setCallsManagerProxy ( mCallsManagerProxy ) ; when ( mAudioCall . getVideoState ( ) ) . thenReturn ( VideoProfile . STATE_AUDIO_ONLY ) ; when ( mAudioCall . getTargetPhoneAccountLabel ( ) ) . thenReturn ( "Bar" ) ; when ( mVideoCall . getVideoState ( ) ) . thenReturn ( VideoProfile . STATE_BIDIRECTIONAL ) ; when ( mVideoCall . getTargetPhoneAccountLabel ( ) ) . thenReturn ( "Bar" ) ; when ( mRingingCall . isSelfManaged ( ) ) . thenReturn ( true ) ; when ( mRingingCall . isIncoming ( ) ) . thenReturn ( true ) ;
@Mock WifiTrafficPoller mWifiTrafficPoller ; @Mock WifiStateMachine mWifiStateMachine ; @Mock HandlerThread mHandlerThread ; TestLooper mLooper ; @Mock AsyncChannel mAsyncChannel ; @Mock Resources mResources ; @Mock FrameworkFacade mFrameworkFacade ; @Mock WifiLockManager mLockManager ; @Mock WifiMulticastLockManager mWifiMulticastLockManager ; @Mock WifiLastResortWatchdog mWifiLastResortWatchdog ; @Mock WifiBackupRestore mWifiBackupRestore ; @Mock WifiMetrics mWifiMetrics ; @Spy FakeWifiLog mLog ; @Mock WifiPermissionsUtil mWifiPermissionsUtil ; < |startfocus| > @Mock PropertyService mPropertyService ; < |endfocus| > @Mock WifiSettingsStore mSettingsStore ; @Mock ContentResolver mContentResolver ; PowerManager mPowerManager ; private class WifiAsyncChannelTester { private static final String TAG = "WifiAsyncChannelTester" ; public static final int CHANNEL_STATE_FAILURE = - 1 ; public static final int CHANNEL_STATE_DISCONNECTED = 0 ; public static final int CHANNEL_STATE_HALF_CONNECTED = 1 ; public static final int CHANNEL_STATE_FULLY_CONNECTED = 2 ; private int mState = CHANNEL_STATE_DISCONNECTED ; private WifiAsyncChannel mChannel ; private WifiLog mAsyncTestLog ; private class WifiAsyncChannelHandler extends Handler { public WifiAsyncChannelHandler ( Looper looper ) { super ( looper ) ; } @Override public void handleMessage ( Message msg ) { switch ( msg . what ) { case AsyncChannel . CMD_CHANNEL_HALF_CONNECTED : if ( msg . arg1 == AsyncChannel . STATUS_SUCCESSFUL ) { mState = CHANNEL_STATE_HALF_CONNECTED ; } else { mState = CHANNEL_STATE_FAILURE ; } notifyAll ( ) ; break ; case AsyncChannel . CMD_CHANNEL_FULLY_CONNECTED : if ( msg . arg1 == AsyncChannel . STATUS_SUCCESSFUL ) { mState = CHANNEL_STATE_FULLY_CONNECTED ; } else { mState = CHANNEL_STATE_FAILURE ; } notifyAll ( ) ; break ; case AsyncChannel . CMD_CHANNEL_DISCONNECTED : mState = CHANNEL_STATE_DISCONNECTED ; notifyAll ( ) ; break ; default : mAsyncTestLog . err ( "WifiAsyncChannelHandler . handleMessage ignoring msg = " + msg ) ; break ; } } }
/* Copyright ( C ) 2016 The Android Open Source Project ** ** This software is licensed under the terms of the GNU General Public ** License version 2 , as published by the Free Software Foundation , and ** may be copied , distributed , and modified under those terms . ** ** This program is distributed in the hope that it will be useful , ** but WITHOUT ANY WARRANTY ; without even the implied warranty of ** MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE . See the ** GNU General Public License for more details . */ #include "android / skin / qt / emulator - qt - window . h" #include "android / skin / qt / extended - pages / common . h" #include "android / skin / qt / extended - pages / virtual - sensors - page . h" #include "android / skin / qt / qt - settings . h" #include "android / skin / qt / stylesheet . h" #include "android / skin / qt / virtualscene - control - window . h" #include "android / skin / qt / virtualscene - common . h" #include "android / skin / qt / virtualscene - qt - window . h" #include "android / skin / winsys . h" #include "android / utils / debug . h" #include "android / utils / system . h" #include "ui_virtualscene - control - window . h" #include < QApplication > #include < QDesktopWidget > #include < QMessageBox > #include < QScreen > #include < QTimer > #include < QWindow > #include < QtCore > #include < QtGui > #include < QtWidgets > #include < memory > #include < utility > #include < vector > #define DEBUG 1 #if DEBUG #define D ( . . . ) VERBOSE_PRINT ( virtualscene , __VA_ARGS__ ) #else #define D ( . . . ) ( ( void ) 0 ) #endif using android : : base : : System ; namespace { constexpr int kDefaultWindowWidth = 800 ; constexpr int kDefaultWindowHeight = 600 ; constexpr int kDefaultSceneWidth = 800 ; constexpr int kDefaultSceneHeight = 600 ; constexpr int kDefaultSceneX = 0 ; constexpr int kDefaultSceneY = 0 ; constexpr int kDefaultSceneRotation = 0 ; constexpr int kDefaultSceneZoom = 100 ; constexpr int kDefaultSceneZoomMin = 10 ; constexpr int kDefaultSceneZoomMax = 200 ; constexpr int kDefaultSceneZoomStep = 10 ; constexpr int kDefaultSceneZoomStepSmall = 1 ; constexpr int kDefaultSceneZoomStepLarge = 50 ; constexpr int kDefaultSceneZoomStepDefault = 10 ; constexpr int kDefaultSceneZoomStepMin = 1 ; constexpr int kDefaultSceneZoomStepMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultSceneZoomStepDefaultMin = 1 ; constexpr int kDefaultSceneZoomStepDefaultMax = 100 ; constexpr int kDefaultSceneZoomStepDefaultDefault = 10 ; constexpr int kDefaultScene
} /* * * Creates a new advertising set . If operation succeed , device will start advertising . This * method returns immediately , the operation status is delivered through * { @code callback . onAdvertisingSetStarted ( ) } . * < p > * @param parameters advertising set parameters . * @param advertiseData Advertisement data to be broadcasted . Size must not exceed * { @link BluetoothAdapter#getLeMaximumAdvertisingDataLength } . If the < |startfocus| > * advertisement is connectable , three bytes will be appended with flags . < |endfocus| > * @param scanResponse Scan response associated with the advertisement data . Size must not exceed * { @link BluetoothAdapter#getLeMaximumAdvertisingDataLength } * @param periodicData Periodic advertising data . Size must not exceed * { @link BluetoothAdapter#getLeMaximumAdvertisingDataLength } * @param timeoutMillis Advertising time limit . May not exceed 180000 * @param callback Callback for advertising set . * @param handler thread upon which the callbacks will be invoked . */ public void startAdvertisingSet ( AdvertisingSetParameters parameters , AdvertiseData advertiseData , AdvertiseData scanResponse , PeriodicAdvertisingParameters periodicParameters , AdvertiseData periodicData , int timeoutMillis , AdvertisingSetCallback callback , Handler handler ) {
} /* * * Creates a new advertising set . If operation succeed , device will start advertising . This * method returns immediately , the operation status is delivered through * { @code callback . onAdvertisingSetStarted ( ) } . * < p > * @param parameters advertising set parameters . * @param advertiseData Advertisement data to be broadcasted . Size must not exceed * { @link BluetoothAdapter#getLeMaximumAdvertisingDataLength } . If the < |startfocus| > * advertisement is connectable , three bytes will be appended with flags . < |endfocus| > * @param scanResponse Scan response associated with the advertisement data . Size must not exceed * { @link BluetoothAdapter#getLeMaximumAdvertisingDataLength } * @param periodicData Periodic advertising data . Size must not exceed * { @link BluetoothAdapter#getLeMaximumAdvertisingDataLength } * @param timeoutMillis Advertising time limit . May not exceed 180000 * @param callback Callback for advertising set . * @param handler thread upon which the callbacks will be invoked . */ public void startAdvertisingSet ( AdvertisingSetParameters parameters , AdvertiseData advertiseData , AdvertiseData scanResponse , PeriodicAdvertisingParameters periodicParameters , AdvertiseData periodicData , int timeoutMillis , AdvertisingSetCallback callback , Handler handler ) {
/* * Copyright ( C ) 2010 The Android Open Source Project * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package android . telephony ; import android . annotation . SdkConstant ; import android . annotation . SdkConstant . SdkConstantType ; import android . content . Context ; import android . os . RemoteException ; import android . os . ServiceManager ; import android . os . SystemProperties ; import android . util . Log ; import com . android . internal . telephony . ITelephony ; import com . android . internal . telephony . ITelephonyRegistry ; import com . android . internal . telephony . PhoneConstants ; import com . android . internal . telephony . TelephonyProperties ; import java . util . List ; /* * * Provides access to information about the telephony services on * the device . Applications can use the methods in this class to * determine telephony services and states , as well as to access some * types of subscriber information . Applications can also register * a listener to receive notification of telephony state changes . * < p > * You do not instantiate this class directly ; instead , you retrieve * a reference to an instance through * { @link android . content . Context#getSystemService * Context . getSystemService ( Context . TELEPHONY_SERVICE ) } . * < p > * Note that access to some telephony information is * permission - protected . Your application cannot access the protected * information unless it has the appropriate permissions declared in * its manifest file . Where permissions apply , they are noted in the * the methods through which you access the protected information . */ public class TelephonyManager { private static final String TAG = "TelephonyManager" ; private Context mContext ; private ITelephonyRegistry mRegistry ; /* * * Broadcast Action : The phone service state has changed . The intent will have the following * extra values : </ p > * < ul > * < li > < em > state </ em > - An int with one of the following values : * { @link #STATE_IN_SERVICE } , * { @link #STATE_OUT_OF_SERVICE } , * { @link #STATE_EMERGENCY_ONLY } * { @link #STATE_POWER_OFF } * < li > < em > inService </ em > - A boolean value indicating if the phone is in service . </ li > * </ ul > * * < p class = "note" > * Requires the READ_PHONE_STATE permission . * * < p class = "note" > This is a protected intent that can only be sent * by the system . */ @SdkConstant ( SdkConstantType . BROADCAST_INTENT_ACTION ) public static final String ACTION_SERVICE_STATE_CHANGED = "android . intent . action . SERVICE_STATE" ; /* * * Broadcast Action : The radio technology has changed . The intent will have the following * extra values : </ p > * < ul > * < li > < em > phoneName </ em > - A string version of the new phone name . </ li > * </ ul > * * < p class = "note" > * You can < em > not </ em > receive this through components declared * in manifests , only by explicitly registering for it with * { @link android . content . Context#registerReceiver ( android . content . BroadcastReceiver , * android . content . IntentFilter ) Context . registerReceiver ( ) } . * * < p class = "note" > * Requires no permission . * * < p class = "note" > This is a protected intent that can only be sent * by the system . */ @SdkConstant ( SdkConstantType . BROADCAST_INTENT_ACTION ) public static final String ACTION_RADIO_TECHNOLOGY_CHANGED = "android . intent . action . RADIO_TECHNOLOGY" ; /* * * Broadcast Action : The emergency callback mode is changed . * < p > * < ul > * < li > < em > phoneinECMState </ em > - A boolean value , true = phone in ECM , false = ECM off </ li > * </ ul > * < p class = "note" > * You can < em > not </ em > receive this through components declared * in manifests , only by exlicitly registering for it with * { @link android . content . Context#registerReceiver ( android . content . BroadcastReceiver , * android . content . IntentFilter ) Context . registerReceiver ( ) } . * * < p class = "note" > * Requires no permission . * * < p class = "note" > This is a protected intent that can only be sent * by the system . */ @SdkConstant ( SdkConstantType . BROADCAST_INTENT_ACTION ) public static final String ACTION_EMERGENCY_CALLBACK_MODE_CHANGED = "android . intent . action . EMERGENCY_CALLBACK_MODE_CHANGED" ; /* * * Broadcast Action : The phone's signal strength has changed . The intent will have the * following extra values : </ p > * < ul > * < li > < em > phoneName </ em > - A string version of the phone name . </ li > * < li > < em > asu </ em > - A numeric value for the signal strength . * An ASU is 0 - 31 or - 1 if unknown ( for GSM , dBm = - 113 - 2 * asu ) . * The following special values are defined : </ li > * < li > 0 means " - 113 dBm or less" . </ li > * < li > 31 means " - 51 dBm or greater" . </ li > * < li > 99 is a special value , where the signal strength is unknown . </ li > * </ ul > * * < p class = "note" > * You can < em > not </ em > receive this through components declared * in manifests , only by explicitly registering for it with * { @link android . content . Context#registerReceiver ( android . content
} public void testChangeFontScaleNoRelaunch ( ) throws Exception { // Should receive onConfigurationChanged ( ) and no relaunch testChangeFontScale ( NO_RELAUNCH_ACTIVITY_NAME , false ) ; } private void testRotation ( String activityName , int rotationStep , int numRelaunch , int numConfigChange ) throws Exception { executeShellCommand ( getAmStartCmd ( activityName ) ) ; final String [ ] waitForActivitiesVisible = new String [ ] { activityName } ; mAmWmState . computeState ( mDevice , waitForActivitiesVisible ) ; < |startfocus| > setDeviceRotation ( 4 - rotationStep ) ; < |endfocus| > mAmWmState . computeState ( mDevice , waitForActivitiesVisible ) ; final int actualStackId = mAmWmState . getAmState ( ) . getTaskByActivityName ( activityName ) . mStackId ; final int displayId = mAmWmState . getAmState ( ) . getStackById ( actualStackId ) . mDisplayId ; final int newDeviceRotation = getDeviceRotation ( displayId ) ; if ( newDeviceRotation == INVALID_DEVICE_ROTATION ) { CLog . logAndDisplay ( LogLevel . WARN , "Got an invalid device rotation value . " + "Continuing the test despite of that , but it is likely to fail . " ) ;
Objects . hashCode ( mNetworkSpecifier ) * 17 + ( mSignalStrength * 19 ) ) ; } @Override public int describeContents ( ) { return 0 ; } @Override public void writeToParcel ( Parcel dest , int flags ) { dest . writeLong ( mNetworkCapabilities ) ; dest . writeLong ( mTransportTypes ) ; dest . writeInt ( mLinkUpBandwidthKbps ) ; dest . writeInt ( mLinkDownBandwidthKbps ) ; if ( mNetworkSpecifier != null && ! NetworkSpecifier . isWhitelistedNetworkSpecifier ( mNetworkSpecifier ) ) { < |startfocus| > throw new IllegalStateException ( "Invalid network specifier" ) ; < |endfocus| > } dest . writeParcelable ( ( Parcelable ) mNetworkSpecifier , flags ) ; dest . writeInt ( mSignalStrength ) ; } public static final Creator < NetworkCapabilities > CREATOR = new Creator < NetworkCapabilities > ( ) { @Override public NetworkCapabilities createFromParcel ( Parcel in ) { NetworkCapabilities netCap = new NetworkCapabilities ( ) ; netCap . mNetworkCapabilities = in . readLong ( ) ; netCap . mTransportTypes = in . readLong ( ) ; netCap . mLinkUpBandwidthKbps = in . readInt ( ) ; netCap . mLinkDownBandwidthKbps = in . readInt ( ) ; try { netCap . mNetworkSpecifier = in . readParcelable ( null ) ; < |startfocus| > if ( netCap . mNetworkSpecifier != null && ! NetworkSpecifier . isWhitelistedNetworkSpecifier ( netCap . mNetworkSpecifier ) ) { throw new IllegalStateException ( "Invalid network specifier" ) ; } < |endfocus| > } catch ( ClassCastException e ) { throw new IllegalStateException ( "Invalid network specifier" , e ) ; } netCap . mSignalStrength = in . readInt ( ) ; return netCap ; } @Override public NetworkCapabilities [ ] newArray ( int size ) { return new NetworkCapabilities [ size ] ; } } ; }
new Creator < NetworkCapabilities > ( ) { @Override public NetworkCapabilities createFromParcel ( Parcel in ) { NetworkCapabilities netCap = new NetworkCapabilities ( ) ; netCap . mNetworkCapabilities = in . readLong ( ) ; netCap . mTransportTypes = in . readLong ( ) ; netCap . mLinkUpBandwidthKbps = in . readInt ( ) ; netCap . mLinkDownBandwidthKbps = in . readInt ( ) ; try { netCap . mNetworkSpecifier = in . readParcelable ( null ) ; < |startfocus| > } catch ( BadParcelableException e ) { Log . e ( TAG , "BadParcelableException : e = " + e ) ; < |endfocus| > netCap . mNetworkSpecifier = null ; } netCap . mSignalStrength = in . readInt ( ) ; return netCap ; } @Override public NetworkCapabilities [ ] newArray ( int size ) { return new NetworkCapabilities [ size ] ; } } ; @Override public String toString ( ) { int [ ] types = getTransportTypes ( ) ; String transports = ( types . length > 0 ) ? " Transports : " + transportNamesOf ( types ) : "" ; types = getCapabilities ( ) ; String capabilities = ( types . length > 0 ? " Capabilities : " : "" ) ;
*/ @Override public void onPullExternalCall ( ) { if ( ( getConnectionProperties ( ) & Connection . PROPERTY_IS_EXTERNAL_CALL ) != Connection . PROPERTY_IS_EXTERNAL_CALL ) { Log . w ( this , "onPullExternalCall - cannot pull non - external call" ) ; return ; } if ( mOriginalConnection != null ) { mOriginalConnection . pullExternalCall ( ) ; } } @Override public void onStartRtt ( RttTextStream textStream ) { < |startfocus| > if ( ! isImsConnection ( ) ) { Log . w ( this , "onStartRtt - not in IMS , so RTT cannot be enabled . " ) ; return ; } ImsPhone imsPhone = ( ImsPhone ) getPhone ( ) ; < |endfocus| > imsPhone . sendRttModifyRequest ( textStream ) ; } @Override public void onStopRtt ( ) { // This is not supported by carriers / vendor yet . No - op for now . } @Override public void handleRttUpgradeResponse ( RttTextStream textStream ) { Phone phone = getPhone ( ) ; if ( ! ( phone instanceof ImsPhone ) ) {
if ( phone instanceof ImsPhone ) { ImsPhone imsPhone = ( ImsPhone ) phone ; imsPhone . sendRttModifyRequest ( textStream ) ; } else { Log . w ( this , "onStartRtt - not in IMS , so RTT cannot be enabled . " ) ; } } @Override public void onStopRtt ( ) { // This is not supported by carriers / vendor yet . No - op for now . } @Override public void handleRttUpgradeResponse ( RttTextStream textStream ) { < |startfocus| > if ( ! isImsConnection ( ) ) { < |endfocus| > Log . w ( this , "handleRttUpgradeResponse - not in IMS , so RTT cannot be enabled . " ) ; return ; } ImsPhone imsPhone = ( ImsPhone ) getPhone ( ) ; imsPhone . sendRttModifyResponse ( textStream ) ; } public void performHold ( ) { Log . v ( this , "performHold" ) ; // TODO : Can dialing calls be put on hold as well since they take up the // foreground call slot ? if ( Call . State . ACTIVE == mConnectionState ) { Log . v ( this , "Holding active call" ) ; try {
/* * Copyright ( C ) 2016 The Android Open Source Project * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package android . net . wifi . aware ; import android . net . NetworkSpecifier ; import android . os . Parcel ; import android . os . Parcelable ; import java . util . Arrays ; import java . util . Objects ; /* * * Network specifier object used to request a Wi - Fi Aware network . Apps do not create these objects * directly but obtain them using * { @link WifiAwareSession#createNetworkSpecifierOpen ( int , byte [ ] ) } or
public boolean satisfiedBy ( NetworkSpecifier other ) { < |startfocus| > return equals ( other ) ; // Match All is taken care of already in { @code xxx } < |endfocus| >
< |startfocus| > public static List < TimeZone > getTimeZonesWithUniqueOffsets ( String country ) { < |endfocus| > synchronized ( sLastUniqueLockObj ) { if ( ( country != null ) && country . equals ( sLastUniqueCountry ) ) { if ( DBG ) { Log . d ( TAG , "getTimeZonesWithUniqueOffsets ( " + country + " ) : return cached version" ) ; } return sLastUniqueZoneOffsets ; } } Collection < TimeZone > zones = getTimeZones ( country ) ; ArrayList < TimeZone > uniqueTimeZones = new ArrayList < > ( ) ; for ( TimeZone zone : zones ) { // See if we already have this offset , // Using slow but space efficient and these are small . boolean found = false ; for ( int i = 0 ; i < uniqueTimeZones . size ( ) ; i ++ ) { if ( uniqueTimeZones . get ( i ) . getRawOffset ( ) == zone . getRawOffset ( ) ) { found = true ; break ; } } if ( ! found ) { if ( DBG ) { Log . d ( TAG , "getTimeZonesWithUniqueOffsets : add unique offset = " + zone . getRawOffset ( ) ) ; } uniqueTimeZones . add ( zone ) ; } } synchronized ( sLastUniqueLockObj ) { sLastUniqueCountry = country ; sLastUniqueZoneOffsets = uniqueTimeZones ; } return uniqueTimeZones ; }
private static String getCounterLabel ( int counterIndex ) { switch ( counterIndex ) { case ON_POST_DIAL_WAIT : return "onPostDialWait" ; case ON_CALL_EVENT : return "onCallEvent" ; case ON_PULL_EXTERNAL_CALL : return "onPullExternalCall" ; case ON_EXTRAS_CHANGED : return "onExtrasChanged" ; case ON_START_RTT : < |startfocus| > return "onStartRtt" ; case ON_RTT_REQUEST_RESPONSE : return "onRttRequestResponse" ; case ON_STOP_RTT : return "onStopRtt" ; < |endfocus| > default : return "Callback" ; }
mKeepaliveCallback , mConfig . getLocalAddress ( ) , mConfig . getEncapLocalPort ( ) , mConfig . getRemoteAddress ( ) ) ; try { // FIXME : this is still a horrible way to fudge the synchronous callback mKeepaliveSyncLock . wait ( 2000 ) ; } catch ( InterruptedException e ) { } } if ( mKeepaliveStatus != ConnectivityManager . PacketKeepalive . SUCCESS ) { throw new UnsupportedOperationException ( "Packet Keepalive cannot be started" ) ; } } /* Package */ < |startfocus| > void setResourceId ( int resourceId ) { mResourceId = resourceId ; } /* Package */ < |endfocus| > int getResourceId ( ) { return mResourceId ; } /* Package */ void stopKeepalive ( ) { if ( mKeepalive == null ) { return ; } mKeepalive . stop ( ) ; synchronized ( mKeepaliveSyncLock ) { if ( mKeepaliveStatus == ConnectivityManager . PacketKeepalive . SUCCESS ) { try { mKeepaliveSyncLock . wait ( 2000 ) ; } catch ( InterruptedException e ) { } } } } /* * * Builder object to facilitate the creation of IpSecTransform objects . *
protected void releaseResources ( ) { try { getNetdInstance ( ) . ipSecDeleteSecurityAssociation ( mResourceId , mDirection , mLocalAddress , mRemoteAddress , mSpi ) ; } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception } catch ( RemoteException e ) { < |startfocus| > Log . e ( TAG , "Failed to delete SA : " + e ) ; < |endfocus| > }
INetd getNetdInstance ( ) { final INetd netd = NetdService . getInstance ( ) ; if ( netd == null ) { < |startfocus| > throw new RemoteException ( "Failed to Get Netd Instance" ) . rethrowFromSystemServer ( ) ; < |endfocus| > } return netd ;
} return netd ; } boolean isNetdAlive ( ) { synchronized ( mLock ) { final INetd netd = getNetdInstance ( ) ; if ( netd == null ) { return false ; } try { return netd . isAlive ( ) ; } catch ( RemoteException re ) { return false ; } } } @Override /* * Get a new SPI and maintain the reservation in the system server */ public Bundle reserveSecurityParameterIndex ( < |startfocus| > int direction , String remoteAddress , int requestedSpi , IBinder binder ) throws RemoteException { < |endfocus| > int resourceId = mNextResourceId . getAndIncrement ( ) ; int spi = IpSecManager . INVALID_SECURITY_PARAMETER_INDEX ; String localAddress = "" ; Bundle retBundle = new Bundle ( 3 ) ; try { spi = getNetdInstance ( ) . ipSecAllocateSpi ( resourceId , direction , localAddress , remoteAddress , requestedSpi ) ; Log . d ( TAG , "Allocated SPI " + spi ) ; retBundle . putInt ( KEY_STATUS , IpSecManager . Status . OK ) ; retBundle . putInt ( KEY_RESOURCE_ID , resourceId ) ; retBundle . putInt ( KEY_SPI , spi ) ;
* Create a transport mode transform , which represent two security associations ( one in each * direction ) in the kernel . The transform will be cached by the system server and must be freed * when no longer needed . It is possible to free one , deleting the SA from underneath sockets * that are using it , which will result in all of those sockets becoming unable to send or * receive data . */ @Override < |startfocus| > public Bundle createTransportModeTransform ( IpSecConfig c , IBinder binder ) throws RemoteException { < |endfocus| > // TODO : Basic input validation here since it's coming over the Binder int resourceId = mNextResourceId . getAndIncrement ( ) ; for ( int direction : DIRECTIONS ) { IpSecAlgorithm auth = c . getAuthentication ( direction ) ; IpSecAlgorithm crypt = c . getEncryption ( direction ) ; try { int result = getNetdInstance ( ) . ipSecAddSecurityAssociation ( resourceId , c . getMode ( ) , direction , ( c . getLocalAddress ( ) != null ) ? c . getLocalAddress ( ) . getHostAddress ( ) : "" , ( c . getRemoteAddress ( ) != null ) ? c . getRemoteAddress ( ) . getHostAddress ( ) : "" , auth . getName ( ) , auth . getKey ( ) , crypt . getName ( ) , crypt . getKey ( ) , c . getSpiResourceId ( direction ) , c . getMarkValue ( ) , c . getMarkMask ( ) ) ; if ( result != 0 ) { throw new IllegalArgumentException ( "Failed to add Security Association with result : " + result ) ; } } catch ( ServiceSpecificException e ) { throw new IllegalArgumentException ( "Failed to add Security Association with " + e . errorCode + " : " + e . getMessage ( ) ) ; } }
* system server . If this is called on an inactive ( or non - existent ) transform , it will not * return an error . It's safe to de - allocate transforms that may have already been deleted for * other reasons . */ @Override public void deleteTransportModeTransform ( int resourceId ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord record ; < |startfocus| > // We want to non - destructively get so that we can check credentials before removing this < |endfocus| > record = mTransformRecords . get ( resourceId ) ; if ( record == null ) { throw new IllegalArgumentException ( "Transform " + resourceId + " is not available to be deleted" ) ; } if ( record . pid != getCallingPid ( ) || record . uid != getCallingUid ( ) ) { throw new SecurityException ( "Only the owner of an IpSec Transform may delete it ! " ) ; } // TODO : if releaseResources ( ) throws RemoteException , we can try again to clean up on binder death . // Need to make sure that path is actually functional record . releaseResources ( ) ; mTransformRecords . remove ( resourceId ) ; } }
*/ @Override public void deleteTransportModeTransform ( int resourceId ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord record ; // We want to non - destructively get so that we can check credentials before removing this record = mTransformRecords . get ( resourceId ) ; if ( record == null ) { throw new IllegalArgumentException ( "Transform " + resourceId + " is not available to be deleted" ) ; } < |startfocus| > if ( record . pid != Binder . getCallingPid ( ) || record . uid != Binder . getCallingUid ( ) ) { < |endfocus| > throw new SecurityException ( "Only the owner of an IpSec Transform may delete it ! " ) ; } // TODO : if releaseResources ( ) throws RemoteException , we can try again to clean up on binder death . // Need to make sure that path is actually functional record . releaseResources ( ) ; mTransformRecords . remove ( resourceId ) ; record . nullifyRecord ( ) ; } } /* * * Apply an active transport mode transform to a socket , which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override
if ( record == null ) { throw new IllegalArgumentException ( "Transform " + resourceId + " is not available to be deleted" ) ; } if ( record . pid != getCallingPid ( ) || record . uid != getCallingUid ( ) ) { throw new SecurityException ( "Only the owner of an IpSec Transform may delete it ! " ) ; } < |startfocus| > // TODO : if releaseResources ( ) throws RemoteException , we can try again to clean up on binder death . // Need to make sure that path is actually functional < |endfocus| > record . releaseResources ( ) ; mTransformRecords . remove ( resourceId ) ; record . nullifyRecord ( ) ; } } /* * * Apply an active transport mode transform to a socket , which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override public void applyTransportModeTransform ( ParcelFileDescriptor socket , int resourceId ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord info ; // FIXME : this code should be factored out into a security check + getter info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( "Transform " + resourceId + " is not available to be applied" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( "Only the owner of an IpSec Transform may apply it ! " ) ; } if ( info . mode != IpSecTransform . MODE_TRANSPORT ) { throw new IllegalArgumentException ( "Only a transport mode transform may be applied to a socket" ) ; } if ( info . socket != null ) { throw new IllegalStateException ( "Transform " + resourceId + " is already applied to a socket" ) ; } info . socket = socket ; } } /* * * Remove an active transport mode transform from a socket , which will remove the IPsec security * association as a correspondent policy from the provided socket */ @Override public void removeTransportModeTransform ( ParcelFileDescriptor socket ) throws RemoteException { synchronized ( mTransformRecords ) { for ( TransformRecord info : mTransformRecords . values ( ) ) { if ( info . socket == socket ) { info . socket = null ; return ; } } throw new IllegalArgumentException ( "No transform is applied to the provided socket" ) ; } } /* * * Apply an active tunnel mode transform to a socket , which will apply the IPsec security * association as a policy to the provided socket */ @Override public void applyTunnelModeTransform ( ParcelFileDescriptor socket , int resourceId , int direction ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord info ; // FIXME : this code should be factored out into a security check + getter info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( "Transform " + resourceId + " is not available to be applied" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( "Only the owner of an IpSec Transform may apply it ! " ) ; } if ( info . mode != IpSecTransform . MODE_TUNNEL ) { throw new IllegalArgumentException ( "Only a tunnel mode transform may be applied to a socket" ) ; } if ( info . socket != null ) { throw new IllegalStateException ( "Transform " + resourceId + " is already applied to a socket" ) ; } info . socket = socket ; info . direction = direction ; } } /* * * Remove an active tunnel mode transform from a socket , which will remove the IPsec security * association as a policy from the provided socket */ @Override public void removeTunnelModeTransform ( ParcelFileDescriptor socket ) throws RemoteException { synchronized ( mTransformRecords ) { for ( TransformRecord info : mTransformRecords . values ( ) ) { if ( info . socket == socket ) { info . socket = null ; return ; } } throw new IllegalArgumentException ( "No transform is applied to the provided socket" ) ; } } /* * * Apply an active tunnel mode transform to a socket , which will apply the IPsec security * association as a policy to the provided socket */ @Override public void applyTunnelModeTransform ( ParcelFileDescriptor socket , int resourceId , int direction ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord info ; // FIXME : this code should be factored out into a security check + getter info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( "Transform " + resourceId + " is not available to be applied" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( "Only the owner of an IpSec Transform may apply it ! " ) ; } if ( info . mode != IpSecTransform . MODE_TUNNEL ) { throw new IllegalArgumentException ( "Only a tunnel mode transform may be applied to a socket" ) ; } if ( info . socket != null ) { throw new IllegalStateException ( "Transform " + resourceId + " is already applied to a socket" ) ; } info . socket = socket ; info . direction = direction ; } } /* * * Remove an active tunnel mode transform from a socket , which will remove the IPsec security * association as a policy from the provided socket */ @Override public void removeTunnelModeTransform ( ParcelFileDescriptor socket ) throws RemoteException { synchronized ( mTransformRecords ) { for ( TransformRecord info : mTransformRecords . values ( ) ) { if ( info . socket == socket ) { info . socket = null ; return ; } } throw new IllegalArgumentException ( "No transform is applied to the provided socket" ) ; } } /* * * Apply an active tunnel mode transform to a socket , which will apply the IPsec security * association as a policy to the provided socket */ @Override public void applyTunnelModeTransform ( ParcelFileDescriptor socket , int resourceId , int direction ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord info ; // FIXME : this code should be factored out into a security check + getter info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( "Transform " + resourceId + " is not available to be applied" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( "Only the owner of an IpSec Transform may apply it ! " ) ; } if ( info . mode != IpSecTransform . MODE_TUNNEL ) { throw new IllegalArgumentException ( "Only a tunnel mode transform may be applied to a socket" ) ; } if ( info . socket != null ) { throw new IllegalStateException ( "Transform " + resourceId + " is already applied to a socket" ) ; } info . socket = socket ; info . direction = direction ; } } /* * * Remove an active tunnel mode transform from a socket , which will remove the IPsec security * association as a policy from the provided socket */ @Override public void removeTunnelModeTransform ( ParcelFileDescriptor socket ) throws RemoteException { synchronized ( mTransformRecords ) { for ( TransformRecord info : mTransformRecords . values ( ) ) { if ( info . socket == socket ) { info . socket = null ; return ; } } throw new IllegalArgumentException ( "No transform is applied to the provided socket" ) ; } } /* * * Apply an active tunnel mode transform to a socket , which will apply the IPsec security * association as a policy to the provided socket */ @Override public void applyTunnelModeTransform ( ParcelFileDescriptor socket , int resourceId , int direction ) throws RemoteException { synchronized ( mTransformRecords ) { TransformRecord info ; // FIXME : this code should be factored out into a security check + getter info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( "Transform " + resourceId + " is not available to be applied" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( "Only the owner of an IpSec Transform may apply it ! " ) ; } if ( info . mode != IpSecTransform . MODE_TUNNEL ) { throw new IllegalArgumentException ( "Only a tunnel mode
// TODO : if releaseResources ( ) throws RemoteException , we can try again to clean up on binder death . // Need to make sure that path is actually functional record . releaseResources ( ) ; mTransformRecords . remove ( resourceId ) ; record . nullifyRecord ( ) ; } } /* * * Apply an active transport mode transform to a socket , which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override < |startfocus| > public void applyTransportModeTransform ( ParcelFileDescriptor socket , int resourceId ) throws RemoteException { < |endfocus| > synchronized ( mTransformRecords ) { TransformRecord info ; // FIXME : this code should be factored out into a security check + getter info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( "Transform " + resourceId + " is not active" ) ; } // TODO : make this a function . if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( "Only the owner of an IpSec Transform may apply it ! " ) ; }
} } } /* * * Remove a transport mode transform from a socket , applying the default ( empty ) policy . This * will ensure that NO IPsec policy is applied to the socket ( would be the equivalent of * applying a policy that performs no IPsec ) . Today the resourceId parameter is passed but not * used : reserved for future improved input validation . */ @Override < |startfocus| > public void removeTransportModeTransform ( ParcelFileDescriptor socket , int resourceId ) throws RemoteException { < |endfocus| > try { getNetdInstance ( ) . ipSecRemoveTransportModeTransform ( socket . getFileDescriptor ( ) ) ; } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception } } @Override protected void dump ( FileDescriptor fd , PrintWriter pw , String [ ] args ) { mContext . enforceCallingOrSelfPermission ( DUMP , TAG ) ; pw . println ( "IpSecService Log : " ) ; pw . println ( "NetdNativeService Connection : " + ( isNetdAlive ( ) ? "alive" : "dead" ) ) ; pw . println ( ) ; } }
// and a remote IP address int spi ; // Encryption Algorithm IpSecAlgorithm encryption ; // Authentication Algorithm IpSecAlgorithm authentication ; } Flow [ ] flow = new Flow [ ] { new Flow ( ) , new Flow ( ) } ; // For tunnel mode IPv4 UDP Encapsulation // IpSecTransform#ENCAP_ESP_ * , such as ENCAP_ESP_OVER_UDP_IKE int encapType ; int encapLocalPort ; int encapRemotePort ; // A bitmask of PROPERTY_ * indicating which of the fields // of this class are valid . long properties ; // An interval , in seconds between the NattKeepalive packets int nattKeepaliveInterval ; // Transport or Tunnel public int getMode ( ) { return mode ; } public InetAddress getLocalAddress ( ) { return localAddress ; } public int getSpi ( int direction ) { return flow [ direction ] . spi ; } public InetAddress getRemoteAddress ( ) { return remoteAddress ; } public IpSecAlgorithm getEncryption ( int direction ) { return flow [ direction ] . encryption ; } public IpSecAlgorithm getAuthentication ( int direction ) {
out . writeParcelable ( flow [ IpSecTransform . DIRECTION_OUT ] . encryption , flags ) ; out . writeParcelable ( flow [ IpSecTransform . DIRECTION_OUT ] . authentication , flags ) ; out . writeInt ( encapType ) ; out . writeInt ( encapLocalPort ) ; out . writeInt ( encapRemotePort ) ; } // Package Private : Used by the IpSecTransform . Builder ; // there should be no public constructor for this object < |startfocus| > IpSecConfig ( ) { } < |endfocus| > private static InetAddress readInetAddressFromParcel ( Parcel in ) { String addrString = in . readString ( ) ; if ( addrString == null ) { return null ; } try { return InetAddress . getByName ( addrString ) ; } catch ( UnknownHostException e ) { Log . wtf ( TAG , "Invalid IpAddress " + addrString ) ; return null ; } } private IpSecConfig ( Parcel in ) { properties = in . readLong ( ) ; localAddress = readInetAddressFromParcel ( in ) ; remoteAddress = readInetAddressFromParcel ( in ) ;
* You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package android . net ; import static android . content . Context . IPSEC_SERVICE ; import android . annotation . IntDef ; import android . annotation . NonNull ; import android . annotation . SystemApi ; import android . content . Context ; import android . os . Binder ; import android . os . Bundle ; import android . os . IBinder ; import android . os . RemoteException ; import android . os . ServiceManager ; import android . util . Log ; import com . android . internal . util . Preconditions ; import dalvik . system . CloseGuard ; import java . io . IOException ; import java . lang . annotation . Retention ; import java . lang . annotation . RetentionPolicy ; import java . net . InetAddress ; /* * * This class represents an IpSecTransform , which encapsulates both properties and state of IPsec . *
private IpSecTransform ( Context context , IpSecConfig config ) { mContext = context ; mConfig = config ; mResourceId = INVALID_RESOURCE_ID ; } private IIpSecService getIpSecService ( ) { IBinder b = ServiceManager . getService ( IPSEC_SERVICE ) ; if ( b == null ) { throw new RemoteException ( "Failed to connect to IpSecService" ) . rethrowAsRuntimeException ( ) ; } return IIpSecService . Stub . asInterface ( b ) ; } < |startfocus| > /* * @hide */ public static final String KEY_RESOURCE_ID = "resourceId" ; < |endfocus| > private void checkResultStatus ( int status ) throws IOException , IpSecManager . ResourceUnavailableException , IpSecManager . SpiUnavailableException { switch ( status ) { case IpSecManager . Status . OK : return ; case IpSecManager . Status . RESOURCE_UNAVAILABLE : throw new IpSecManager . ResourceUnavailableException ( "Failed to allocate a new IpSecTransform" ) ; case IpSecManager . Status . SPI_UNAVAILABLE : Log . wtf ( TAG , "Attempting to use an SPI that was somehow not reserved" ) ; // Fall through default :
mConfig = config ; mResourceId = INVALID_RESOURCE_ID ; } private IIpSecService getIpSecService ( ) { IBinder b = ServiceManager . getService ( IPSEC_SERVICE ) ; if ( b == null ) { throw new RemoteException ( "Failed to connect to IpSecService" ) . rethrowAsRuntimeException ( ) ; } return IIpSecService . Stub . asInterface ( b ) ; } /* * @hide */ public static final String KEY_STATUS = "status" ; /* * @hide */ public static final String KEY_RESOURCE_ID = "resourceId" ; < |startfocus| > private void checkResultStatus ( int status ) < |endfocus| > throws IOException , IpSecManager . ResourceUnavailableException , IpSecManager . SpiUnavailableException { switch ( status ) { case IpSecManager . Status . OK : return ; case IpSecManager . Status . RESOURCE_UNAVAILABLE : throw new IpSecManager . ResourceUnavailableException ( "Failed to allocate a new IpSecTransform" ) ; case IpSecManager . Status . SPI_UNAVAILABLE : Log . wtf ( TAG , "Attempting to use an SPI that was somehow not reserved" ) ; // Fall through default : throw new IllegalStateException ( "Unknown status code " + status ) ; } } /* * * @hide */ public static final class ResourceUnavailableException extends Exception { public ResourceUnavailableException ( String message ) { super ( message ) ; } } /* * * @hide */ public static final class SpiUnavailableException extends Exception { public SpiUnavailableException ( String message ) { super ( message ) ; } } /* * * @hide */ public static final class SecurityParameterIndex { private final int mSpi ; private final int mResourceId ; private final IpSecAlgorithm mAuth ; private final IpSecAlgorithm mCrypt ; private final IpSecTransform mTransform ; private final IpSecManager mManager ; private final IpSecConfig mConfig ; private final int mMode ; private final int mDirection ; private final int mEncapType ; private final int mEncapLocalPort ; private final int mEncapRemotePort ; private final InetAddress mEncapLocalAddress ; private final InetAddress mEncapRemoteAddress ; private final int mMarkValue ; private final int mMarkMask ; private final int mTtl ; private final int mTos ; private final int mNetwork ; private final int mResourceId ; private final int mReplayWindowSize ; private final int mReplayWindow ; private final int mSequenceNumber ; private final int mSequenceNumberMask ; private final int mSequenceNumberHigh ; private final int mSequenceNumberHighMask ; private final int mSequenceNumberLow ; private final int mSequenceNumberLowMask ; private final int mIvLength ; private final int mIv ; private final int mIvMask ; private final int mIvOffset ; private final int mIvOffsetMask ; private final int mIvBitLength ; private final int mIvBitOffset ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffsetMask ; private final int mIvBitLengthMask ; private final int mIvBitOffset
} private IIpSecService getIpSecService ( ) { IBinder b = ServiceManager . getService ( IPSEC_SERVICE ) ; if ( b == null ) { throw new RemoteException ( "Failed to connect to IpSecService" ) . rethrowAsRuntimeException ( ) ; } return IIpSecService . Stub . asInterface ( b ) ; } /* * @hide */ public static final String KEY_STATUS = "status" ; /* * @hide */ public static final String KEY_RESOURCE_ID = "resourceId" ; < |startfocus| > private void checkStatusOrThrow ( int status ) < |endfocus| > throws IOException , IpSecManager . ResourceUnavailableException , IpSecManager . SpiUnavailableException { switch ( status ) { case IpSecManager . Status . OK : return ; case IpSecManager . Status . RESOURCE_UNAVAILABLE : throw new IpSecManager . ResourceUnavailableException ( "Failed to allocate a new IpSecTransform" ) ; case IpSecManager . Status . SPI_UNAVAILABLE : Log . wtf ( TAG , "Attempting to use an SPI that was somehow not reserved" ) ; // Fall through default : throw new IllegalStateException ( "Failed to Create a Transform with status code " + status ) ; } } private IpSecTransform activate ( )
private static final boolean DBG = Log . isLoggable ( TAG , Log . DEBUG ) ; private static final String NETD_SERVICE_NAME = "netd" ; private static final int [ ] DIRECTIONS = new int [ ] { IpSecTransform . DIRECTION_OUT , IpSecTransform . DIRECTION_IN } ; /* * Binder context for this service */ private final Context mContext ; private Object mLock = new Object ( ) ; private static final int NETD_FETCH_TIMEOUT = 5000 ; // ms < |startfocus| > private AtomicInteger mNextTransformId = new AtomicInteger ( 0xFADED000 ) ; < |endfocus| > private abstract class ManagedResource implements IBinder . DeathRecipient { final int pid ; final int uid ; private IBinder mBinder ; ManagedResource ( IBinder binder ) { super ( ) ; mBinder = binder ; pid = getCallingPid ( ) ; uid = getCallingUid ( ) ; try { mBinder . linkToDeath ( this , 0 ) ; } catch ( RemoteException e ) { binderDied ( ) ; } } /* * * When this record is no longer needed for managing system resources this function should * unlink all references held by the record to allow efficient garbage collection . */ private abstract class ManagedResource implements IBinder . DeathRecipient { final int pid ; final int uid ; private IBinder mBinder ; ManagedResource ( IBinder binder ) { super ( ) ; mBinder = binder ; pid = getCallingPid ( ) ; uid = getCallingUid ( ) ; try { mBinder . linkToDeath ( this , 0 ) ; } catch ( RemoteException e ) { binderDied ( ) ; } }
/* * Binder context for this service */ private final Context mContext ; private Object mLock = new Object ( ) ; private static final int NETD_FETCH_TIMEOUT = 5000 ; // ms private AtomicInteger mNextTransformId = new AtomicInteger ( 0xFADED000 ) ; private abstract class ManagedResource implements IBinder . DeathRecipient { final int pid ; final int uid ; private IBinder mBinder ; ManagedResource ( IBinder binder ) { super ( ) ; mBinder = binder ; < |startfocus| > pid = Binder . getCallingPid ( ) ; uid = Binder . getCallingUid ( ) ; < |endfocus| > try { mBinder . linkToDeath ( this , 0 ) ; } catch ( RemoteException e ) { binderDied ( ) ; } } /* * * When this record is no longer needed for managing system resources this function should * unlink all references held by the record to allow efficient garbage collection . */ public final void release ( ) { // Release all the underlying system resources first releaseResources ( ) ; if ( mBinder != null ) { mBinder . unlinkToDeath ( this , 0 ) ; } mBinder = null ;
protected void releaseResources ( ) { < |startfocus| > for ( int direction : IpSecTransform . DIRECTIONS ) { < |endfocus| > try { getNetdInstance ( ) . ipSecDeleteSecurityAssociation ( mResourceId , direction , ( mConfig . getLocalAddress ( ) != null ) ? mConfig . getLocalAddress ( ) . getHostAddress ( ) : "" , ( mConfig . getRemoteAddress ( ) != null ) ? mConfig . getRemoteAddress ( ) . getHostAddress ( ) : "" , mConfig . getSpi ( direction ) ) ; } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception } catch ( RemoteException e ) { throw e . rethrowFromSystemServer ( ) ; } }
mResourceId , direction , ( mConfig . getLocalAddress ( ) != null ) ? mConfig . getLocalAddress ( ) . getHostAddress ( ) : "" , ( mConfig . getRemoteAddress ( ) != null ) ? mConfig . getRemoteAddress ( ) . getHostAddress ( ) : "" , mConfig . getSpi ( direction ) ) ; } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception } catch ( RemoteException e ) { < |startfocus| > throw e . rethrowFromSystemServer ( ) ; < |endfocus| > } }
retBundle . putInt ( IpSecManager . SecurityParameterIndex . KEY_RESOURCE_ID , resourceId ) ; retBundle . putInt ( IpSecManager . SecurityParameterIndex . KEY_SPI , spi ) ; synchronized ( mSpiRecords ) { mSpiRecords . put ( resourceId , new SpiRecord ( resourceId , direction , localAddress , remoteAddress , spi , binder ) ) ; } } catch ( ServiceSpecificException e ) { < |startfocus| > retBundle . putInt ( IpSecManager . SecurityParameterIndex . KEY_STATUS , IpSecManager . Status . SPI_UNAVAILABLE ) ; retBundle . putInt ( IpSecManager . SecurityParameterIndex . KEY_RESOURCE_ID , resourceId ) ; retBundle . putInt ( IpSecManager . SecurityParameterIndex . KEY_SPI , spi ) ; < |endfocus| > } catch ( RemoteException e ) { throw e . rethrowFromSystemServer ( ) ; } return retBundle ;
public void deleteTransportModeTransform ( int resourceId ) { 	synchronized ( mTransformRecords ) { 		TransformRecord record ; 		 < |startfocus| > // We want to non - destructively get so that we can check credentials before removing this < |endfocus| > 		record = mTransformRecords . get ( resourceId ) ; 		if ( record == null ) { 			throw new IllegalArgumentException ( "Transform " + resourceId + " is not available to be deleted" ) ; 		 } 		if ( record . pid != getCallingPid ( ) || record . uid != getCallingUid ( ) ) { 			throw new SecurityException ( "Only the owner of an IpSec Transform may delete it ! " ) ; 		 } 		 // remove from the DB because releasing might fail , but it won't ever succeed later 		mTransformRecords . remove ( resourceId ) ; 		record . releaseResources ( ) ; 		record . nullifyRecord ( ) ; 	 }
record = mTransformRecords . get ( resourceId ) ; if ( record == null ) { throw new IllegalArgumentException ( "Transform " + resourceId + " is not available to be deleted" ) ; } if ( record . pid != getCallingPid ( ) || record . uid != getCallingUid ( ) ) { throw new SecurityException ( "Only the owner of an IpSec Transform may delete it ! " ) ; } < |startfocus| > // remove from the DB because releasing might fail , but it won't ever succeed later mTransformRecords . remove ( resourceId ) ; record . releaseResources ( ) ; record . nullifyRecord ( ) ; < |endfocus| > }
info = mTransformRecords . get ( resourceId ) ; if ( info == null ) { throw new IllegalArgumentException ( "Transform " + resourceId + " is not active" ) ; } if ( info . pid != getCallingPid ( ) || info . uid != getCallingUid ( ) ) { throw new SecurityException ( "Only the owner of an IpSec Transform may apply it ! " ) ; } IpSecConfig c = info . getConfig ( ) ; try { < |startfocus| > for ( int direction : IpSecTransform . DIRECTIONS ) { < |endfocus| > getNetdInstance ( ) . ipSecApplyTransportModeTransform ( socket . getFileDescriptor ( ) , resourceId , direction , ( c . getLocalAddress ( ) != null ) ? c . getLocalAddress ( ) . getHostAddress ( ) : "" , ( c . getRemoteAddress ( ) != null ) ? c . getRemoteAddress ( ) . getHostAddress ( ) : "" , c . getSpi ( direction ) ) ; } } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception
* < h3 > Developer Guides </ h3 > * < p > For more information about using Bluetooth , read the * < a href = " { @docRoot } guide / topics / connectivity / bluetooth . html" > Bluetooth </ a > developer guide . </ p > * </ div > * * { @see BluetoothServerSocket } * { @see java . io . InputStream } * { @see java . io . OutputStream } */ public final class BluetoothSocket implements Closeable { private static final String TAG = "BluetoothSocket" ; < |startfocus| > private static final boolean DBG = true ; < |endfocus| > private static final boolean VDBG = Log . isLoggable ( TAG , Log . VERBOSE ) ; /* * @hide */ public static final int MAX_RFCOMM_CHANNEL = 30 ; /* package */ static final int MAX_L2CAP_PACKAGE_SIZE = 0xFFFF ; /* * RFCOMM socket */ public static final int TYPE_RFCOMM = 1 ; /* * SCO socket */ public static final int TYPE_SCO = 2 ; /* * L2CAP socket */ public static final int TYPE_L2CAP = 3 ; /* package */ static final int EBADFD = 77 ; /* package */ static final int EADDRINUSE = 98 ; /* package */ static final int ECONNREFUSED = 111 ; /* package */ static final int ECONNRESET = 104 ; /* package */ static final int EHOSTUNREACH = 113 ; /* package */ static final int EIO = 5 ; /* package */ static final int EISCONN = 106 ; /* package */ static final int ELOOP = 40 ; /* package */ static final int ENODEV = 19 ; /* package */ static final int ENOMEM = 12 ; /* package */ static final int ENOTCONN = 107 ; /* package */ static final int ENOTSUPPORTED = 95 ; /* package */ static final int ETIMEDOUT = 110 ; /* package */ static final int EHOSTDOWN = 112 ; /* package */ static final int EALREADY = 114 ; /* package */ static final int EINPROGRESS = 115 ; /* package */ static final int EALREADY_BONDED = 484 ; /* package */ static final int EINVAL = 22 ; /* package */ static final int EREMOTE_DEVICE_DOWN = 488 ; /* package */ static final int EACCESS_DENIED = 489 ; /* package */ static final int ECONN_FAILED = 491 ; /* package */ static final int EINVALID_PDU = 492 ; /* package */ static final int EINVALID_HANDLE = 493 ; /* package */ static final int EINVALID_PARAMETER = 494 ; /* package */ static final int ECONNECT_FAILED = 495 ; /* package */ static final int ECONNECT_TIMEOUT = 496 ; /* package */ static final int ECONNECTION_LOST = 497 ; /* package */ static final int EINVALID_ATTRIBUTE_VALUE = 498 ; /* package */ static final int EINSUFFICIENT_RESOURCES = 499 ; /* package */ static final int EINSUFFICIENT_AUTHENTICATION = 500 ; /* package */ static final int EINSUFFICIENT_ENCRYPTION = 501 ; /* package */ static final int EINVALID_CLASS_OF_DEVICE = 502 ; /* package */ static final int EINVALID_L2CAP_PARAMETERS = 503 ; /* package */ static final int EINVALID_UUID = 504 ; /* package */ static final int EINVALID_L2CAP_CID = 505 ; /* package */ static final int EINVALID_RFCOMM_PARAMETERS = 506 ; /* package */ static final int EINVALID_RFCOMM_CID = 507 ; /* package */ static final int EINVALID_SCO_PARAMETERS = 508 ; /* package */ static final int EINVALID_SCO_CID = 509 ; /* package */ static final int EINVALID_L2CAP_MTU = 510 ; /* package */ static final int EINVALID_RFCOMM_MTU = 511 ; /* package */ static final int EINVALID_SCO_MTU = 512 ; /* package */ static final int EINVALID_L2CAP_MPS = 513 ; /* package */ static final int EINVALID_RFCOMM_MPS = 514 ; /* package */ static final int EINVALID_SCO_MPS = 515 ; /* package */ static final int EINVALID_L2CAP_FCS = 516 ; /* package */ static final int EINVALID_RFCOMM_FCS = 517 ; /* package */ static final int EINVALID_SCO_FCS = 518 ; /* package */ static final int EINVALID_L2CAP_FLOW_CONTROL_MODE = 519 ; /* package */ static final int EINVALID_L2CAP_RETRANSMISSION_MODE = 520 ; /* package */ static final int EINVALID_L2CAP_I_FRAME_FLOW_CONTROL = 521 ; /* package */ static final int EINVALID_L2CAP_MAX_TRANSMISSION_UNIT = 522 ; /* package */ static final int EINVALID_L2CAP_MAX_PDU_SIZE = 523 ; /* package */ static final int EINVALID_L2CAP_EXTENDED_FLOW_SPEC = 524 ; /* package */ static final int EINVALID_L2CAP_EXTENDED_WINDOW_SIZE = 525 ; /* package */ static final int EINVALID_L2CAP_RETRANSMISSION_TIMEOUT = 526 ; /* package */ static final int EINVALID_L2CAP_MONITOR_TIMEOUT = 527 ; /* package */ static final int EINVALID_L2CAP_RETRANSMISSION_ATTEMPTS = 528 ; /* package */ static final int EINVALID_L2CAP_MAX_TRANSMISSION_TIME = 529 ; /* package */ static final int EINVALID_L2CAP_MAX_RETRANSMISSION_TIME = 530 ; /* package */ static final int EINVALID_L2CAP_MAX_PDU_SIZE_EXTENDED = 531 ; /* package */ static final int EINVALID_L2CAP_EXTENDED_FEATURES_MASK = 532 ; /* package */ static final int EINVALID_L2CAP_FIXED_CHANNEL = 533 ; /* package */ static final int EINVALID_L2CAP_FIXED_CHANNEL_SERVICE = 534 ; /* package */ static final int EINVALID_L2CAP_FIXED_CHANNEL_SERVICE_CLASS = 535 ; /* package */ static final int EINVALID_L2CAP_FIXED_CHANNEL_SERVICE_CLASS_UUID = 536 ; /* package */ static final int EINVALID_L2CAP_FIXED_CHANNEL_SERVICE_CLASS_UUID_SIZE = 537 ; /* package */ static final int EINVALID_L2CAP_FIXED_CHANNEL_SERVICE_CLASS_UUID_TYPE = 538 ; /* package */ static final int EINVALID_L2CAP_FIXED_CHANNEL_SERVICE_CLASS_UUID_VALUE = 539 ; /* package */ static final int EINVALID_L2CAP_FIXED_CHANNEL_SERVICE_CLASS_UUID_VALUE_SIZE = 540 ; /* package */ static final int EINVALID_L2CAP_FIXED_CHANNEL_SERVICE_CLASS_UUID_VALUE_TYPE = 541 ; /* package */ static final int EINVALID_L2
/* * Copyright ( C ) 2015 The Android Open Source Project * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package android . net . cts ; import android . content . Context ; import android . net . ConnectivityManager ; import android . net . IpSecAlgorithm ; import android . net . IpSecManager ; import android . net . IpSecTransform ; import android . net . Network ; import android . test . AndroidTestCase ; import java . io . IOException ; import java . net . DatagramPacket ; import java . net . DatagramSocket ; import java . net . InetAddress ; import java . net . UnknownHostException ;
< |startfocus| > public void testAllocSpi ( ) { < |endfocus| > for ( InetAddress addr : GOOGLE_DNS_LIST ) { IpSecManager . SecurityParameterIndex randomSpi = null , droidSpi = null ; try { randomSpi = mISM . reserveSecurityParameterIndex ( IpSecTransform . DIRECTION_OUT , addr , IpSecManager . INVALID_SECURITY_PARAMETER_INDEX ) ; assertTrue ( randomSpi . getSpi ( ) != IpSecManager . INVALID_SECURITY_PARAMETER_INDEX ) ; droidSpi = mISM . reserveSecurityParameterIndex ( IpSecTransform . DIRECTION_IN , addr , DROID_SPI ) ; assertTrue ( droidSpi . getSpi ( ) == DROID_SPI ) ; } catch ( IpSecManager . ResourceUnavailableException | IpSecManager . SpiUnavailableException ru ) { assertTrue ( false ) ; } // This * should * throw an SpiUnavailableException try { mISM . reserveSecurityParameterIndex ( IpSecTransform . DIRECTION_IN , addr , DROID_SPI ) ; assertTrue ( false ) ; // we expect an exception in the above call } catch ( IpSecManager . ResourceUnavailableException ru ) { assertTrue ( false ) ; } catch ( IpSecManager . SpiUnavailableException sp ) { } randomSpi . close ( ) ; droidSpi . close ( ) ; }
try { randomSpi = mISM . reserveSecurityParameterIndex ( IpSecTransform . DIRECTION_OUT , addr , IpSecManager . INVALID_SECURITY_PARAMETER_INDEX ) ; assertTrue ( randomSpi . getSpi ( ) != IpSecManager . INVALID_SECURITY_PARAMETER_INDEX ) ; droidSpi = mISM . reserveSecurityParameterIndex ( IpSecTransform . DIRECTION_IN , addr , DROID_SPI ) ; assertTrue ( droidSpi . getSpi ( ) == DROID_SPI ) ; } catch ( IpSecManager . ResourceUnavailableException | IpSecManager . SpiUnavailableException ru ) { fail ( "Unexpected exception" ) ; } < |startfocus| > // This * should * throw an SpiUnavailableException < |endfocus| > try { mISM . reserveSecurityParameterIndex ( IpSecTransform . DIRECTION_IN , addr , DROID_SPI ) ; fail ( "Expected an exception" ) ; // we expect an exception in the above call } catch ( IpSecManager . ResourceUnavailableException ru ) { fail ( "Unexpected exception" ) ; } catch ( IpSecManager . SpiUnavailableException sp ) { } randomSpi . close ( ) ; droidSpi . close ( ) ; }
public void testCreateTransform ( ) { < |startfocus| > InetAddress remote = InetAddress . getLoopbackAddress ( ) ; IpSecManager . SecurityParameterIndex outSpi = mISM . reserveSecurityParameterIndex ( IpSecTransform . DIRECTION_OUT , remote , IpSecManager . INVALID_SECURITY_PARAMETER_INDEX ) ; < |endfocus| > IpSecManager . SecurityParameterIndex inSpi = mISM . reserveSecurityParameterIndex ( IpSecTransform . DIRECTION_IN , remote , IpSecManager . INVALID_SECURITY_PARAMETER_INDEX ) ; IpSecTransform firstTransform = new IpSecTransform . Builder ( mContext ) . setSpi ( IpSecTransform . DIRECTION_OUT , outSpi ) . setEncryption ( IpSecTransform . DIRECTION_OUT , new IpSecAlgorithm ( IpSecAlgorithm . ALGO_CRYPT_AES_CBC , CRYPT_KEY ) ) . setAuthentication ( IpSecTransform . DIRECTION_OUT , new IpSecAlgorithm ( IpSecAlgorithm . ALGO_AUTH_HMAC_SHA256 , AUTH_KEY , AUTH_KEY . length * 8 ) ) . setSpi ( IpSecTransform . DIRECTION_IN , inSpi ) . setEncryption ( IpSecTransform . DIRECTION_IN , new IpSecAlgorithm ( IpSecAlgorithm . ALGO_CRYPT_AES_CBC , CRYPT_KEY ) ) . setAuthentication (
TimeZone biasMatch = null ; for ( int i = 0 ; i < candidates . size ( ) ; i ++ ) { TimeZone match = candidates . get ( i ) ; if ( ! offsetMatchesAtTime ( match , offsetSeconds , isDst , whenMillis ) ) { continue ; } if ( firstMatch == null ) { firstMatch = match ; if ( bias == null ) { // Terminate early if there is no bias . break ; } } if ( match . getID ( ) . equals ( bias . getID ( ) ) ) { < |startfocus| > biasMatch = match ; break ; } } if ( biasMatch != null ) { return biasMatch ; } else if ( firstMatch != null ) { return firstMatch ; } else { return null ; }
import java . nio . file . Path ; import java . nio . file . SimpleFileVisitor ; import java . nio . file . attribute . BasicFileAttributes ; import java . util . Arrays ; import java . util . HashMap ; import java . util . HashSet ; import java . util . List ; import java . util . Map ; import java . util . Set ; import java . util . stream . Collectors ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertNull ; import static org . junit . Assert . fail ; public class TimeZoneFinderTest { < |startfocus| > private Path testDir ;/ / 22nd July 2017 , 13 : 14 : 15 ( DST time in UK ) < |endfocus| > private static final int HOUR_MILLIS = 60 * 60 * 1000 ; // Zones used in the tests . NEW_YORK_TZ and LONDON_TZ chosen because they never overlap but both // have DST . private static final TimeZone NEW_YORK_TZ = TimeZone . getTimeZone ( "America / New_York" ) ; private static final TimeZone LONDON_TZ = TimeZone . getTimeZone ( "Europe / London" ) ; // A zone that matches LONDON_TZ for WHEN_NO_DST . It does not have DST so differs for WHEN_DST .
} @Test public void xmlParsing_emptyFile ( ) throws Exception { checkThrowsParserException ( "" ) ; } @Test public void xmlParsing_unexpectedRootElement ( ) throws Exception { checkThrowsParserException ( " < foo > </ foo > \n" ) ; } @Test public void xmlParsing_missingCountryZones ( ) throws Exception { checkThrowsParserException ( " < timezones > </ timezones > \n" ) ; } @Test public void xmlParsing_noCountriesOk ( ) throws Exception { < |startfocus| > parse ( " < timezones > \n" < |endfocus| > + " < countryzones > \n" + " </ countryzones > \n" + " </ timezones > \n" ) ; } @Test public void xmlParsing_unexpectedElementsIgnored ( ) throws Exception { String unexpectedElement = " < unexpected - element > \n < a / > </ unexpected - element > \n" ; TimeZoneFinder finder = parse ( " < timezones > \n" + " " + unexpectedElement + " < countryzones > \n" + " < country code = \"gb\" > \n" + " < id > Europe / London </ id > \n" + " </ country > \n" + " </ countryzones > \n" + " </ timezones > \n" ) ;
checkThrowsParserException ( " < foo > </ foo > \n" ) ; } @Test public void xmlParsing_missingCountryZones ( ) throws Exception { checkThrowsParserException ( " < timezones > </ timezones > \n" ) ; } @Test public void xmlParsing_noCountriesOk ( ) throws Exception { parse ( " < timezones > \n" + " < countryzones > \n" + " </ countryzones > \n" + " </ timezones > \n" ) ; } @Test public void xmlParsing_unexpectedElementsIgnored ( ) throws Exception { String unexpectedElement = " < unexpected - element > \n < a / > </ unexpected - element > \n" ; < |startfocus| > TimeZoneFinder finder = parse ( " < timezones > \n" < |endfocus| > + " " + unexpectedElement + " < countryzones > \n" + " < country code = \"gb\" > \n" + " < id > Europe / London </ id > \n" + " </ country > \n" + " </ countryzones > \n" + " </ timezones > \n" ) ; assertZonesEqual ( zones ( "Europe / London" ) , finder . lookupTimeZonesByCountry ( "gb" ) ) ; finder = parse ( " < timezones > \n" + " < countryzones > \n" + " " + unexpectedElement + " < country code = \"gb\" > \n" + " < id > Europe / London </ id > \n" + " </ country > \n" + " </ countryzones > \n" + " </ timezones > \n" ) ; assertZonesEqual ( zones ( "Europe / London" ) , finder . lookupTimeZonesByCountry ( "gb" ) ) ; } @Test public void xmlParsing_commentsIgnored ( ) throws Exception { TimeZoneFinder finder = parse ( " < timezones > \n" + " < !- - comment -- > \n" + " < countryzones > \n" + " < !- - comment -- > \n" + " < country code = \"gb\" > \n" + " < !- - comment -- > \n" + " < id > Europe / London </ id > \n" + " < !- - comment -- > \n" + " </ country > \n" + " < !- - comment -- > \n" + " </ countryzones > \n" + " < !- - comment -- > \n" + " </ timezones > \n" ) ; assertZonesEqual ( zones ( "Europe / London" ) , finder . lookupTimeZonesByCountry ( "gb" ) ) ; } @Test public void xmlParsing_commentsInsideIdTagIgnored ( ) throws Exception { TimeZoneFinder finder = parse ( " < timezones > \n" + " < countryzones > \n" + " < country code = \"gb\" > \n" + " < id > Europe / London < !- - comment -- > </ id > \n" + " </ country > \n" + " </ countryzones > \n" + " </ timezones > \n" ) ; assertZonesEqual ( zones ( "Europe / London" ) , finder . lookupTimeZonesByCountry ( "gb" ) ) ; } private static TimeZoneFinder parse ( String xml ) throws Exception { return new TimeZoneFinder ( new ByteArrayInputStream ( xml . getBytes ( Charsets . UTF_8 ) ) ) ; } private static void checkThrowsParserException ( String xml ) throws Exception { try { parse ( xml ) ; fail ( ) ; } catch ( XmlPullParserException expected ) { } } private static void assertZonesEqual ( Set < String > expected , Set < String > actual ) { assertEquals ( expected , actual ) ; } private static Set < String > zones ( String . . . zones ) { return ImmutableSet . copyOf ( zones ) ; } }
mHandler . sendMessageDelayed ( msg1 , 1000 ) ; } } break ; case MSG_INCOMING_CONNECTION_RETRY : if ( mBatchs . size ( ) == 0 ) { Log . i ( TAG , "Start Obex Server" ) ; createServerSession ( mPendingConnection ) ; mIncomingRetries = 0 ; mPendingConnection = null ; } else { if ( mIncomingRetries == 20 ) { Log . w ( TAG , "Retried 20 seconds , reject connection" ) ; try { mPendingConnection . close ( ) ; } catch ( IOException e ) { Log . e ( TAG , "close tranport error" ) ; } < |startfocus| > if ( mServerSocket != null ) { mServerSocket . prepareForNewConnect ( ) ; } < |endfocus| > mIncomingRetries = 0 ; mPendingConnection = null ; } else { Log . i ( TAG , "OPP busy ! Retry after 1 second" ) ; mIncomingRetries = mIncomingRetries + 1 ; Message msg2 = Message . obtain ( mHandler ) ; msg2 . what = MSG_INCOMING_CONNECTION_RETRY ; mHandler . sendMessageDelayed ( msg2 , 1000 ) ; } } break ; }
protected void releaseResources ( ) { < |startfocus| > for ( int direction : DIRECTIONS ) { < |endfocus| > try { getNetdInstance ( ) . ipSecDeleteSecurityAssociation ( mResourceId , direction , ( mConfig . getLocalAddress ( ) != null ) ? mConfig . getLocalAddress ( ) . getHostAddress ( ) : "" , ( mConfig . getRemoteAddress ( ) != null ) ? mConfig . getRemoteAddress ( ) . getHostAddress ( ) : "" , mConfig . getSpi ( direction ) ) ; } catch ( ServiceSpecificException e ) { // FIXME : get the error code and throw is at an IOException from Errno Exception } catch ( RemoteException e ) { throw e . rethrowFromSystemServer ( ) ; } }
protected void setUp ( ) throws Exception { super . setUp ( ) ; mCM = ( ConnectivityManager ) getContext ( ) . getSystemService ( Context . CONNECTIVITY_SERVICE ) ; mISM = ( IpSecManager ) getContext ( ) . getSystemService ( Context . IPSEC_SERVICE ) ; } /* * Allocate a random SPI * Allocate a specific SPI using previous randomly created SPI value * Realloc the same SPI that was specifically created ( expect SpiUnavailable ) * Close SPIs */ public void testAllocSpi ( ) throws Exception { for ( InetAddress addr : GOOGLE_DNS_LIST ) { IpSecManager . SecurityParameterIndex randomSpi = null , droidSpi = null ; < |startfocus| > randomSpi = mISM . reserveSecurityParameterIndex ( IpSecTransform . DIRECTION_OUT , addr ) ; assertTrue ( "Failed to receive a valid SPI" , randomSpi . getSpi ( ) != IpSecManager . INVALID_SECURITY_PARAMETER_INDEX ) ; < |endfocus| > droidSpi = mISM . reserveSecurityParameterIndex ( IpSecTransform . DIRECTION_IN , addr , DROID_SPI ) ; assertTrue ( "Failed to allocate specified SPI , " + DROID_SPI , droidSpi . getSpi ( ) == DROID_SPI ) ; try {
// This is a success case because we expect a dupe SPI to throw } randomSpi . close ( ) ; droidSpi . close ( ) ; } } /* * Alloc outbound SPI * Alloc inbound SPI * Create transport mode transform * open socket * apply transform to socket * send data on socket * release transform * send data ( expect exception ) */ public void testCreateTransform ( ) throws Exception { InetAddress local = InetAddress . getLoopbackAddress ( ) ; IpSecManager . SecurityParameterIndex outSpi = < |startfocus| > mISM . reserveSecurityParameterIndex ( IpSecTransform . DIRECTION_OUT , local ) ; < |endfocus| > IpSecManager . SecurityParameterIndex inSpi = mISM . reserveSecurityParameterIndex ( IpSecTransform . DIRECTION_IN , local , outSpi . getSpi ( ) ) ; IpSecTransform transform = new IpSecTransform . Builder ( mContext ) . setSpi ( IpSecTransform . DIRECTION_OUT , outSpi ) . setEncryption ( IpSecTransform . DIRECTION_OUT , new IpSecAlgorithm ( IpSecAlgorithm . CRYPT_AES_CBC , CRYPT_KEY ) ) . setAuthentication ( IpSecTransform . DIRECTION_OUT , new IpSecAlgorithm ( IpSecAlgorithm . AUTH_HMAC_SHA256 , AUTH_KEY ) ) . buildTransportModeTransform ( ) ;
if ( length == 1 ) { return symbol . charAt ( 0 ) ; } if ( length > 1 ) { char first = symbol . charAt ( 0 ) ; char second = symbol . charAt ( 1 ) ; if ( first == '\u200E' || first == '\u200F' || first == '\u061C' ) { return second ; } if ( length == 2 && ( second == '\u200E' || second == '\u200F' || second == '\u061C' ) ) { return first ; } } < |startfocus| > < |endfocus| > return fallback ;
public NetworkCapabilities setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { if ( networkSpecifier != null && Long . bitCount ( mTransportTypes ) != 1 ) { throw new IllegalStateException ( "Must have a single transport specified to use " + "setNetworkSpecifier" ) ; } < |startfocus| > if ( networkSpecifier != null && ! ( networkSpecifier instanceof Parcelable ) ) { throw new IllegalArgumentException ( "Network specifier must be parcelable" ) ; } mNetworkSpecifier = networkSpecifier ; return this ; < |endfocus| >
* it should document their particulars . For example , Bluetooth may use some sort of * device id while WiFi could used ssid and / or bssid . Cellular may use carrier spn . * * @param networkSpecifier An { @code String } of opaque format used to specify the bearer * specific network specifier where the bearer has a choice of * networks . */ public Builder setNetworkSpecifier ( String networkSpecifier ) { < |startfocus| > return setNetworkSpecifier ( new StringNetworkSpecifier ( networkSpecifier ) ) ; < |endfocus| > } /* * * Sets the optional bearer specific network specifier . * This has no meaning if a single transport is also not specified , so calling * this without a single transport set will generate an exception , as will * subsequently adding or removing transports after this is set . * </ p > * * @param networkSpecifier A concrete , parcelable framework class that extends * NetworkSpecifier . * * @hide */ public Builder setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { if ( networkSpecifier instanceof MatchAllNetworkSpecifier ) { < |startfocus| > throw new IllegalArgumentException ( "MatchAllNetworkSpecifier not supported for network specifier" ) ; < |endfocus| > } mNetworkSpecifier = networkSpecifier ; return this ; } /* * * Sets the optional bearer specific network specifier . * This has no meaning if a single transport is also not specified , so calling * this without a single transport set will generate an exception , as will * subsequently adding or removing transports after this is set . * </ p > * * @param networkSpecifier A concrete , parcelable framework class that extends * NetworkSpecifier . * * @hide */ public Builder setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { if ( networkSpecifier instanceof MatchAllNetworkSpecifier ) { < |startfocus| > throw new IllegalArgumentException ( "MatchAllNetworkSpecifier not supported for network specifier" ) ; < |endfocus| > } mNetworkSpecifier = networkSpecifier ; return this ; } /* * * Sets the optional bearer specific network specifier . * This has no meaning if a single transport is also not specified , so calling * this without a single transport set will generate an exception , as will * subsequently adding or removing transports after this is set . * </ p > * * @param networkSpecifier A concrete , parcelable framework class that extends * NetworkSpecifier . * * @hide */ public Builder setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { if ( networkSpecifier instanceof MatchAllNetworkSpecifier ) { < |startfocus| > throw new IllegalArgumentException ( "MatchAllNetworkSpecifier not supported for network specifier" ) ; < |endfocus| > } mNetworkSpecifier = networkSpecifier ; return this ; } /* * * Sets the optional bearer specific network specifier . * This has no meaning if a single transport is also not specified , so calling * this without a single transport set will generate an exception , as will * subsequently adding or removing transports after this is set . * </ p > * * @param networkSpecifier A concrete , parcelable framework class that extends * NetworkSpecifier . * * @hide */ public Builder setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { if ( networkSpecifier instanceof MatchAllNetworkSpecifier ) { < |startfocus| > throw new IllegalArgumentException ( "MatchAllNetworkSpecifier not supported for network specifier" ) ; < |endfocus| > } mNetworkSpecifier = networkSpecifier ; return this ; } /* * * Sets the optional bearer specific network specifier . * This has no meaning if a single transport is also not specified , so calling * this without a single transport set will generate an exception , as will * subsequently adding or removing transports after this is set . * </ p > * * @param networkSpecifier A concrete , parcelable framework class that extends * NetworkSpecifier . * * @hide */ public Builder setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { if ( networkSpecifier instanceof MatchAllNetworkSpecifier ) { < |startfocus| > throw new IllegalArgumentException ( "MatchAllNetworkSpecifier not supported for network specifier" ) ; < |endfocus| > } mNetworkSpecifier = networkSpecifier ; return this ; } /* * * Sets the optional bearer specific network specifier . * This has no meaning if a single transport is also not specified , so calling * this without a single transport set will generate an exception , as will * subsequently adding or removing transports after this is set . * </ p > * * @param networkSpecifier A concrete , parcelable framework class that extends * NetworkSpecifier . * * @hide */ public Builder setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { if ( networkSpecifier instanceof MatchAllNetworkSpecifier ) { < |startfocus| > throw new IllegalArgumentException ( "MatchAllNetworkSpecifier not supported for network specifier" ) ; < |endfocus| > } mNetworkSpecifier = networkSpecifier ; return this ; } /* * * Sets the optional bearer specific network specifier . * This has no meaning if a single transport is also not specified , so calling * this without a single transport set will generate an exception , as will * subsequently adding or removing transports after this is set . * </ p > * * @param networkSpecifier A concrete , parcelable framework class that extends * NetworkSpecifier . * * @hide */ public Builder setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { if ( networkSpecifier instanceof MatchAllNetworkSpecifier ) { < |startfocus| > throw new IllegalArgumentException ( "MatchAllNetworkSpecifier not supported for network specifier" ) ; < |endfocus| > } mNetworkSpecifier = networkSpecifier ; return this ; } /* * * Sets the optional bearer specific network specifier . * This has no meaning if a single transport is also not specified , so calling * this without a single transport set will generate an exception , as will * subsequently adding or removing transports after this is set . * </ p > * * @param networkSpecifier A concrete , parcelable framework class that extends * NetworkSpecifier . * * @hide */ public Builder setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { if ( networkSpecifier instanceof MatchAllNetworkSpecifier ) { < |startfocus| > throw new IllegalArgumentException ( "MatchAllNetworkSpecifier not supported for network specifier" ) ; < |endfocus| > } mNetworkSpecifier = networkSpecifier ; return this ; } /* * * Sets the optional bearer specific network specifier . * This has no meaning if a single transport is also not specified , so calling * this without a single transport set will generate an exception , as will * subsequently adding or removing transports after this is set . * </ p > * * @param networkSpecifier A concrete , parcelable framework class that extends * NetworkSpecifier . * * @hide */ public Builder setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { if ( networkSpecifier instanceof MatchAllNetworkSpecifier ) { < |startfocus| > throw new IllegalArgumentException ( "MatchAllNetworkSpecifier not supported for network specifier" ) ; < |endfocus| > } mNetworkSpecifier = networkSpecifier ; return this ; } /* * * Sets the optional bearer specific network specifier . * This has no meaning if a single transport is also not specified , so calling * this without a single transport set will generate an exception , as will * subsequently adding or removing transports after this is set . * </ p > * * @param networkSpecifier A concrete , parcelable framework class that extends * NetworkSpecifier . * * @hide */ public Builder setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { if ( networkSpecifier instanceof MatchAllNetworkSpecifier ) { < |startfocus| > throw new IllegalArgumentException ( "MatchAllNetworkSpecifier not supported for network specifier" ) ; < |endfocus| > } mNetworkSpecifier = networkSpecifier ; return this ; } /* * * Sets the optional bearer specific network specifier . * This has no meaning if a single transport is also not specified , so calling * this without a single transport set will generate an exception , as will * subsequently adding or removing transports after this is set . * </ p > * * @param networkSpecifier A concrete , parcelable framework class that extends * NetworkSpecifier . * * @hide */ public Builder setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { if ( networkSpecifier instanceof MatchAllNetworkSpecifier ) { < |startfocus| > throw new IllegalArgumentException ( "MatchAllNetworkSpecifier not supported
} /* * * Sets the optional bearer specific network specifier . * This has no meaning if a single transport is also not specified , so calling * this without a single transport set will generate an exception , as will * subsequently adding or removing transports after this is set . * </ p > * * @param networkSpecifier A concrete , parcelable framework class that extends * NetworkSpecifier . * * @hide */ < |startfocus| > public Builder setNetworkSpecifier ( NetworkSpecifier networkSpecifier ) { < |endfocus| > if ( networkSpecifier instanceof MatchAllNetworkSpecifier ) { throw new IllegalArgumentException ( "NetworkRequests must not use MatchAllNetworkSpecifier" ) ; } mNetworkCapabilities . setNetworkSpecifier ( networkSpecifier ) ; return this ; } /* * * Sets the signal strength . This is a signed integer , with higher values indicating a * stronger signal . The exact units are bearer - dependent . For example , Wi - Fi uses the same * RSSI units reported by WifiManager . * < p > * Note that when used to register a network callback , this specifies the minimum acceptable
* distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package android . net ; /* * * Describes specific properties of a network for use in a { @link NetworkRequest } . * < |startfocus| > * Applications cannot instantiate this class by themselves , but can obtain instances of * subclasses of this class via other APIs . < |endfocus| > * * @hide */ public abstract class NetworkSpecifier { /* * * Validate that the input NetworkSpecifier is one of the whitelisted types . * * @hide */ public static boolean isWhitelistedNetworkSpecifier ( NetworkSpecifier ns ) { return ns instanceof MatchAllNetworkSpecifier || ns instanceof StringNetworkSpecifier ; } /* * * @hide */ public NetworkSpecifier ( ) { } /* * * Returns true if a request with this { @link NetworkSpecifier } is satisfied by a network * with the given NetworkSpecifier . * * @hide */
/* * * Describes specific properties of a network for use in a { @link NetworkRequest } . * * Applications cannot instantiate this class by themselves , but can obtain instances of this * class via other APIs . * * @hide */ public abstract class NetworkSpecifier { /* * * Validate that the input NetworkSpecifier is one of the whitelisted types . * * @hide */ < |startfocus| > public static boolean isWhitelistedNetworkSpecifier ( NetworkSpecifier ns ) { return ns instanceof MatchAllNetworkSpecifier || ns instanceof StringNetworkSpecifier ; } /* * * @hide */ < |endfocus| > public NetworkSpecifier ( ) { } /* * * Returns true if a request with this { @link NetworkSpecifier } is satisfied by a network * with the given NetworkSpecifier . * * @hide */ public abstract boolean satisfiedBy ( NetworkSpecifier other ) ; }
|| wiFiEnabledState == WifiManager . WIFI_STATE_DISABLED ) { if ( startConsentUi ( packageName , Binder . getCallingUid ( ) , WifiManager . ACTION_REQUEST_ENABLE ) ) { return true ; } } } else if ( wiFiEnabledState == WifiManager . WIFI_STATE_ENABLING || wiFiEnabledState == WifiManager . WIFI_STATE_ENABLED ) { if ( startConsentUi ( packageName , Binder . getCallingUid ( ) , WifiManager . ACTION_REQUEST_DISABLE ) ) { return true ; } } } < |startfocus| > mWifiController . sendMessage ( CMD_WIFI_TOGGLED ) ; < |endfocus| > return true ; } /* * * see { @link WifiManager#getWifiState ( ) } * @return One of { @link WifiManager#WIFI_STATE_DISABLED } , * { @link WifiManager#WIFI_STATE_DISABLING } , * { @link WifiManager#WIFI_STATE_ENABLED } , * { @link WifiManager#WIFI_STATE_ENABLING } , * { @link WifiManager#WIFI_STATE_UNKNOWN } */ @Override public int getWifiEnabledState ( ) { enforceAccessPermission ( ) ; mLog . trace ( "getWifiEnabledState uid = % " ) . c ( Binder . getCallingUid ( ) ) . flush ( ) ;
* the grouping separator , and so on ) needed by < code > DecimalFormat </ code > * to format numbers . < code > DecimalFormat </ code > creates for itself an instance of * < code > DecimalFormatSymbols </ code > from its locale data . If you need to change any * of these symbols , you can get the < code > DecimalFormatSymbols </ code > object from * your < code > DecimalFormat </ code > and modify it . * < |startfocus| > * @author Mark Davis * @author Alan Liu * @see java . util . Locale * @see DecimalFormat < |endfocus| > */ public class DecimalFormatSymbols implements Cloneable , Serializable { // Android - changed : Removed reference to DecimalFormatSymbolsProvider but suggested // getInstance ( ) be used instead in case Android supports it in future . /* * * Create a DecimalFormatSymbols object for the default * { @link java . util . Locale . Category#FORMAT FORMAT } locale . * It is recommended that the { @link #getInstance ( Locale ) getInstance } method is used * instead . * < p > This is equivalent to calling * { @link #DecimalFormatSymbols ( Locale ) DecimalFormatSymbols ( Locale . getDefault ( Locale . Category . FORMAT ) ) } . * @see java . util . Locale#getDefault ( java . util . Locale . Category ) * @see java . util . Locale . Category#FORMAT */ public DecimalFormatSymbols ( ) { initialize ( Locale . getDefault ( Locale . Category . FORMAT ) ) ; }
public void testBluetoothDirWrite ( ) { try { File file = new File ( " / data / misc / bluetooth / test . file" ) ; assertTrue ( "File not created" , file . createNewFile ( ) ) ; file . delete ( ) ; < |startfocus| > } catch ( Exception e ) { fail ( "Exception creating file / data / misc / bluetooth / test . file" ) ; e . printStackTrace ( ) ; < |endfocus| > }
assertEquals ( TimeZoneDistroInstaller . INSTALL_SUCCESS , installer . stageInstallWithErrorCode ( stagedDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder ( NEWER_RULES_VERSION , 1 ) . setTzLookupXml ( null ) . buildUnvalidated ( ) ; assertEquals ( TimeZoneDistroInstaller . INSTALL_FAIL_BAD_DISTRO_STRUCTURE , installer . stageInstallWithErrorCode ( incompleteDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; assertNoInstalledDistro ( ) ; } < |startfocus| > /* * Tests that a distro with a missing tzlookup file will not update the content . */ < |endfocus| > public void testStageInstallWithErrorCode_badTzLookupFile ( ) throws Exception { TimeZoneDistro stagedDistro = createValidTimeZoneDistro ( NEW_RULES_VERSION , 1 ) ; assertEquals ( TimeZoneDistroInstaller . INSTALL_SUCCESS , installer . stageInstallWithErrorCode ( stagedDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ; TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder ( NEWER_RULES_VERSION , 1 ) . setTzLookupXml ( " < foo / > " ) . buildUnvalidated ( ) ; assertEquals ( TimeZoneDistroInstaller . INSTALL_FAIL_VALIDATION_ERROR , installer . stageInstallWithErrorCode ( incompleteDistro . getBytes ( ) ) ) ; assertInstallDistroStaged ( stagedDistro ) ;
/* * * Attempts to strip RTL , LTR and Arabic letter markers from { @code symbol } . * If the string contains a single non - marker character ( and any number of marker characters ) , * then that character is returned , otherwise { @code fallback } is returned . * < |startfocus| > * As an implementation detail { @code fallback } is also return when { @code symbol } contains * U + 0000 , which is tolerated , as that would indicate a considerable problem with the input . * < |endfocus| > * @hide */ // VisibleForTesting public static char maybeStripMarkers ( String symbol , char fallback ) { final int length = symbol . length ( ) ; if ( length == 1 ) { char c = symbol . charAt ( 0 ) ; if ( c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000' ) { return c ; } } else if ( length > 1 ) { char nonMarker = 0 ; for ( char c : symbol . toCharArray ( ) ) { if ( c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000' ) { if ( nonMarker == 0 ) { nonMarker = c ; } else if ( nonMarker != c ) { return fallback ; } } } if ( nonMarker != 0 ) { return nonMarker ; } } return fallback ; }
/* * * Attempts to strip RTL , LTR and Arabic letter markers from { @code symbol } . * If the string contains a single non - marker character ( and any number of marker characters ) , * then that character is returned , otherwise { @code fallback } is returned . * < |startfocus| > * As an implementation detail { @code fallback } is also return when { @code symbol } contains * U + 0000 , as that would indicate a considerable problem with the input . * < |endfocus| > * @hide */ // VisibleForTesting public static char maybeStripMarkers ( String symbol , char fallback ) { final int length = symbol . length ( ) ; if ( length == 1 ) { char c = symbol . charAt ( 0 ) ; if ( c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000' ) { return c ; } } else if ( length > 1 ) { char nonMarker = 0 ; for ( char c : symbol . toCharArray ( ) ) {
public static char maybeStripMarkers ( String symbol , char fallback ) { final int length = symbol . length ( ) ; if ( length == 1 ) { char c = symbol . charAt ( 0 ) ; if ( c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000' ) { return c ; } } else if ( length > 1 ) { char nonMarker = 0 ; < |startfocus| > for ( int i = 0 ; i < length ; i ++ ) { char c = symbol . charAt ( i ) ; < |endfocus| > if ( c == '\u200E' || c == '\u200F' || c == '\u061C' ) { continue ; } if ( nonMarker != 0 || c == '\u0000' ) { // more than one non - marker character or U + 0000 in the input string . return fallback ; } nonMarker = c ; } if ( nonMarker != 0 ) { return nonMarker ; } } return fallback ;
public static char maybeStripMarkers ( String symbol , char fallback ) { final int length = symbol . length ( ) ; if ( length >= 1 ) { boolean sawNonMarker = false ; < |startfocus| > final char nonMarker = 0 ; < |endfocus| > for ( int i = 0 ; i < length ; i ++ ) { char c = symbol . charAt ( i ) ; if ( c == '\u200E' || c == '\u200F' || c == '\u061C' ) { continue ; } if ( sawNonMarker ) { // More than one non - marker character . return fallback ; } sawNonMarker = true ; nonMarker = c ; } if ( sawNonMarker ) { return nonMarker ; } } return fallback ;
private final StateMachine mTetherMasterSM ; private final OffloadController mOffloadController ; private final UpstreamNetworkMonitor mUpstreamNetworkMonitor ; private volatile TetheringConfiguration mConfig ; private String mCurrentUpstreamIface ; private Notification . Builder mTetheredNotificationBuilder ; private int mLastNotificationId ; public enum Mode { IDLE ( "idle" ) , TETHERING ( "tethering" ) , LOCAL_HOTSPOT ( "local_only_hotspot" ) ; public final String description ; Mode ( String description ) { this . description = description ; } } private boolean mRndisEnabled ; // track the RNDIS function enabled state private boolean mUsbTetherRequested ; // true if USB tethering should be started < |startfocus| > // when RNDIS is enabled < |endfocus| > // True iff WiFi tethering should be started when soft AP is ready . private boolean mWifiTetherRequested ; public Tethering ( Context context , INetworkManagementService nmService , INetworkStatsService statsService , INetworkPolicyManager policyManager , Looper looper , MockableSystemProperties systemProperties ) { mContext = context ; mNMService = nmService ; mStatsService = statsService ; mPolicyManager = policyManager ; mLooper = looper ; mSystemProperties = systemProperties ; mTetherMasterSM = new TetherMasterSM ( "TetherMaster" , mLooper ) ; mTetherMasterSM . start ( ) ; mOffloadController = new OffloadController ( mContext , mNMService , mTetherMasterSM ) ; mUpstreamNetworkMonitor = new UpstreamNetworkMonitor ( mContext , mTetherMasterSM , mNMService ) ; mTetherInterfaceSM = new HashMap < > ( ) ; mNotificationUpdater = new NotificationUpdater ( mContext , mTetherMasterSM , mUpstreamNetworkMonitor ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_UPSTREAM_CHANGED , mUpstreamNetworkMonitor ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_RETRY_UPSTREAM , mUpstreamNetworkMonitor ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , mNotificationUpdater ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_MODE_UNREQUESTED , mNotificationUpdater ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_UPSTREAM_CHANGED , mNotificationUpdater ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_RETRY_UPSTREAM , mNotificationUpdater ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_CELL_CONNECTION_RENEW , mNotificationUpdater ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_REQUEST_RECONNECT , mNotificationUpdater ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_AVOID_CONFIRMATION , mNotificationUpdater ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_CLEAR_ERROR , mNotificationUpdater ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_NOTIFICATION_TIMED_OUT , mNotificationUpdater ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_START_TETHERING_ERROR , mNotificationUpdater ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_STOP_TETHERING_ERROR , mNotificationUpdater ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_CONNECTION_CHANGED , mNotificationUpdater ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_MODE_DEAD , mNotificationUpdater ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_UPSTREAM_CHANGED , mOffloadController ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_UPSTREAM_CHANGED , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_MODE_UNREQUESTED , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_START_TETHERING_ERROR , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_STOP_TETHERING_ERROR , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_SET_DUN_APN , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_CONNECTION_CHANGED , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_MODE_DEAD , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , mOffloadController ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_MODE_UNREQUESTED , mOffloadController ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_CONNECTION_CHANGED , mOffloadController ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_MODE_DEAD , mOffloadController ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_UPSTREAM_CHANGED , mOffloadController ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_UPSTREAM_CHANGED , mUpstreamNetworkMonitor ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_UPSTREAM_CHANGED , mNotificationUpdater ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_UPSTREAM_CHANGED , mOffloadController ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_UPSTREAM_CHANGED , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_MODE_UNREQUESTED , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_START_TETHERING_ERROR , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_STOP_TETHERING_ERROR , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_SET_DUN_APN , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_CONNECTION_CHANGED , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_MODE_DEAD , this ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , mOffloadController ) ; mTetherMasterSM . registerForMessage ( TetherMasterSM .
return ConnectivityManager . TETHER_ERROR_UNKNOWN_IFACE ; } // Ignore the error status of the interface . If the interface is available , // the errors are referring to past tethering attempts anyway . if ( tetherState . lastState != IControlsTethering . STATE_AVAILABLE ) { Log . e ( TAG , "Tried to Tether an unavailable iface : " + iface + " , ignoring" ) ; return ConnectivityManager . TETHER_ERROR_UNAVAIL_IFACE ; } < |startfocus| > tetherState . stateMachine . sendMessage ( TetherInterfaceStateMachine . CMD_TETHER_REQUESTED , mode ) ; < |endfocus| > return ConnectivityManager . TETHER_ERROR_NO_ERROR ; }
private final StateMachine mTetherMasterSM ; private final OffloadController mOffloadController ; private final UpstreamNetworkMonitor mUpstreamNetworkMonitor ; private volatile TetheringConfiguration mConfig ; private String mCurrentUpstreamIface ; private Notification . Builder mTetheredNotificationBuilder ; private int mLastNotificationId ; public enum Mode { IDLE , TETHERING , LOCAL_HOTSPOT ; } private boolean mRndisEnabled ; // track the RNDIS function enabled state private boolean mUsbTetherRequested ; // true if USB tethering should be started < |startfocus| > // when RNDIS is enabled < |endfocus| > // True iff WiFi tethering should be started when soft AP is ready . private boolean mWifiTetherRequested ; public Tethering ( Context context , INetworkManagementService nmService , INetworkStatsService statsService , INetworkPolicyManager policyManager , Looper looper , MockableSystemProperties systemProperties ) { mContext = context ; mNMService = nmService ; mStatsService = statsService ; mPolicyManager = policyManager ; mLooper = looper ; mSystemProperties = systemProperties ;
public void addActiveDownstream ( TetherInterfaceStateMachine downstream ) { if ( findDownstream ( downstream ) == null ) { // Adding a new downstream appends it to the list . Adding a // downstream a second time without first removing it has no effect . < |startfocus| > if ( mActiveDownstreams . offer ( new Downstream ( downstream , mNextSubnetId ) ) ) { mNextSubnetId = ( short ) Math . max ( 0 , mNextSubnetId + 1 ) ; // always positive } < |endfocus| > updateIPv6TetheringInterfaces ( ) ; }
// Make a local copy , so we can modify it . final RaParams deprecated = new RaParams ( deprecatedParams ) ; // Remove any ULA DNS servers . removeULAs ( deprecated . dnses ) ; // Process newly deprecated information . mDeprecatedInfoTracker . putPrefixes ( deprecated . prefixes ) ; mDeprecatedInfoTracker . putDnses ( deprecated . dnses ) ; } // Make a local copy , so we can modify it . final RaParams params = ( newParams != null ) ? new RaParams ( newParams ) : null ; if ( params != null ) { // Remove any ULA DNS servers . removeULAs ( params . dnses ) ; // Process information that is no longer deprecated . < |startfocus| > mDeprecatedInfoTracker . removePrefixes ( params . prefixes ) ; mDeprecatedInfoTracker . removeDnses ( params . dnses ) ; < |endfocus| > } mRaParams = params ; assembleRaLocked ( ) ; } maybeNotifyMulticastTransmitter ( ) ;
when ( mResources . getStringArray ( com . android . internal . R . array . config_mobile_hotspot_provision_app ) ) . thenReturn ( new String [ ] { "malformedApp" } ) ; assertTrue ( ! mTethering . isTetherProvisioningRequired ( ) ) ; } private void sendWifiApStateChanged ( int state ) { final Intent intent = new Intent ( WifiManager . WIFI_AP_STATE_CHANGED_ACTION ) ; intent . putExtra ( WifiManager . EXTRA_WIFI_AP_STATE , state ) ; mServiceContext . sendStickyBroadcastAsUser ( intent , UserHandle . ALL ) ; } @Test < |startfocus| > public void workingLocalOnlyHotspot ( ) throws Exception { < |endfocus| > when ( mConnectivityManager . isTetheringSupported ( ) ) . thenReturn ( true ) ; when ( mWifiManager . setWifiApEnabled ( any ( WifiConfiguration . class ) , anyBoolean ( ) ) ) . thenReturn ( true ) ; // Emulate externally - visible WifiManager effects , causing the // per - interface state machine starts up , and telling us that hotspot // mode is to be started . mTethering . interfaceStatusChanged ( mTestIfname , true ) ; sendWifiApStateChanged ( WifiManager . WIFI_AP_STATE_ENABLED ) ; mLooper . dispatchAll ( ) ; verify ( mNMService , times ( 1 ) ) . listInterfaces ( ) ; verify ( mNMService , times ( 1 ) ) . getInterfaceConfig ( mTestIfname ) ;
intent . putExtra ( WifiManager . EXTRA_WIFI_AP_STATE , state ) ; mServiceContext . sendStickyBroadcastAsUser ( intent , UserHandle . ALL ) ; } @Test public void workingWifiHotspot ( ) throws Exception { when ( mConnectivityManager . isTetheringSupported ( ) ) . thenReturn ( true ) ; when ( mWifiManager . setWifiApEnabled ( any ( WifiConfiguration . class ) , anyBoolean ( ) ) ) . thenReturn ( true ) ; // Emulate externally - visible WifiManager effects , causing the < |startfocus| > // per - interface state machine starts up , and telling us that hotspot // mode is to be started . < |endfocus| > mTethering . interfaceStatusChanged ( mTestIfname , true ) ; sendWifiApStateChanged ( WifiManager . WIFI_AP_STATE_ENABLED ) ; mLooper . dispatchAll ( ) ; verify ( mNMService , times ( 1 ) ) . listInterfaces ( ) ; verify ( mNMService , times ( 1 ) ) . getInterfaceConfig ( mTestIfname ) ; verify ( mNMService , times ( 1 ) ) . setInterfaceConfig ( eq ( mTestIfname ) , any ( InterfaceConfiguration . class ) ) ; verify ( mNMService , times ( 1 ) ) . tetherInterface ( mTestIfname ) ; verify ( mNMService , times ( 1 ) ) . setIpForwardingEnabled ( true ) ; verify ( mNMService , times ( 1 ) ) . startTethering ( any ( String [ ] . class ) ) ; verifyNoMoreInteractions ( mNMService ) ;
private void combineSpecifiers ( NetworkCapabilities nc ) { < |startfocus| > if ( mNetworkSpecifier != null && ! mNetworkSpecifier . equals ( nc . mNetworkSpecifier ) ) { < |endfocus| > throw new IllegalStateException ( "Can't combine two networkSpecifiers" ) ; } setNetworkSpecifier ( nc . mNetworkSpecifier ) ;
private void combineSpecifiers ( NetworkCapabilities nc ) { if ( mNetworkSpecifier != null && ! mNetworkSpecifier . equals ( nc . mNetworkSpecifier ) ) { throw new IllegalStateException ( "Can't combine two networkSpecifiers" ) ; } < |startfocus| > setNetworkSpecifier ( nc . mNetworkSpecifier ) ; < |endfocus| >
public NetworkRequest pendingRequestForNetwork ( NetworkCapabilities networkCapabilities , PendingIntent operation ) { checkNotNull ( operation , "PendingIntent cannot be null . " ) ; networkCapabilities = new NetworkCapabilities ( networkCapabilities ) ; enforceNetworkRequestPermissions ( networkCapabilities ) ; enforceMeteredApnPolicy ( networkCapabilities ) ; ensureRequestableCapabilities ( networkCapabilities ) ; < |startfocus| > if ( networkCapabilities . getNetworkSpecifier ( ) != null ) { throw new IllegalArgumentException ( "Network specifier is not supported for pending requests . " ) ; } < |endfocus| > NetworkRequest networkRequest = new NetworkRequest ( networkCapabilities , TYPE_NONE , nextNetworkRequestId ( ) , NetworkRequest . Type . REQUEST ) ; NetworkRequestInfo nri = new NetworkRequestInfo ( networkRequest , operation ) ; if ( DBG ) log ( "pendingRequest for " + nri ) ; mHandler . sendMessage ( mHandler . obtainMessage ( EVENT_REGISTER_NETWORK_REQUEST_WITH_INTENT , nri ) ) ; return networkRequest ;
NetworkCapabilities nc = new NetworkCapabilities ( networkCapabilities ) ; if ( ! ConnectivityManager . checkChangePermission ( mContext ) ) { // Apps without the CHANGE_NETWORK_STATE permission can't use background networks , so // make all their listens include NET_CAPABILITY_FOREGROUND . That way , they will get // onLost and onAvailable callbacks when networks move in and out of the background . // There is no need to do this for requests because an app without CHANGE_NETWORK_STATE // can't request networks . nc . addCapability ( NET_CAPABILITY_FOREGROUND ) ; } < |startfocus| > NetworkRequest networkRequest = new NetworkRequest ( nc , TYPE_NONE , nextNetworkRequestId ( ) , NetworkRequest . Type . LISTEN ) ; NetworkRequestInfo nri = new NetworkRequestInfo ( messenger , networkRequest , binder ) ; if ( VDBG ) log ( "listenForNetwork for " + nri ) ; mHandler . sendMessage ( mHandler . obtainMessage ( EVENT_REGISTER_NETWORK_LISTENER , nri ) ) ; return networkRequest ; < |endfocus| >
public void pendingListenForNetwork ( NetworkCapabilities networkCapabilities , PendingIntent operation ) { checkNotNull ( operation , "PendingIntent cannot be null . " ) ; if ( ! hasWifiNetworkListenPermission ( networkCapabilities ) ) { enforceAccessPermission ( ) ; } < |startfocus| > < |endfocus| > NetworkRequest networkRequest = new NetworkRequest ( new NetworkCapabilities ( networkCapabilities ) , TYPE_NONE , nextNetworkRequestId ( ) , NetworkRequest . Type . LISTEN ) ; NetworkRequestInfo nri = new NetworkRequestInfo ( networkRequest , operation ) ; if ( VDBG ) log ( "pendingListenForNetwork for " + nri ) ; mHandler . sendMessage ( mHandler . obtainMessage ( EVENT_REGISTER_NETWORK_LISTENER , nri ) ) ;
public void setNetworkSpecifier ( String specifier ) { if ( TextUtils . isEmpty ( specifier ) ) { mNetworkCapabilities . setNetworkSpecifier ( null ) ; } else { mNetworkCapabilities . setNetworkSpecifier ( new StringNetworkSpecifier ( specifier ) ) ; } mNetworkAgent . sendNetworkCapabilities ( mNetworkCapabilities ) ;
public void testNetworkSpecifier ( ) { NetworkRequest rEmpty1 = newWifiRequestBuilder ( ) . build ( ) ; NetworkRequest rEmpty2 = newWifiRequestBuilder ( ) . setNetworkSpecifier ( ( String ) null ) . build ( ) ; NetworkRequest rEmpty3 = newWifiRequestBuilder ( ) . setNetworkSpecifier ( "" ) . build ( ) ; NetworkRequest rEmpty4 = newWifiRequestBuilder ( ) . setNetworkSpecifier ( ( NetworkSpecifier ) null ) . build ( ) ; NetworkRequest rFoo = newWifiRequestBuilder ( ) . setNetworkSpecifier ( "foo" ) . build ( ) ; NetworkRequest rBar = newWifiRequestBuilder ( ) . setNetworkSpecifier ( "bar" ) . build ( ) ; < |startfocus| > NetworkRequest rBar = newWifiRequestBuilder ( ) . setNetworkSpecifier ( new StringNetworkSpecifier ( "bar" ) ) . build ( ) ; < |endfocus| > TestNetworkCallback cEmpty1 = new TestNetworkCallback ( ) ; TestNetworkCallback cEmpty2 = new TestNetworkCallback ( ) ; TestNetworkCallback cEmpty3 = new TestNetworkCallback ( ) ; TestNetworkCallback cEmpty4 = new TestNetworkCallback ( ) ; TestNetworkCallback cFoo = new TestNetworkCallback ( ) ; TestNetworkCallback cBar = new TestNetworkCallback ( ) ; TestNetworkCallback [ ] emptyCallbacks = new TestNetworkCallback [ ] { cEmpty1 , cEmpty2 , cEmpty3 } ; mCm . registerNetworkCallback ( rEmpty1 , cEmpty1 ) ; mCm . registerNetworkCallback ( rEmpty2 , cEmpty2 ) ; mCm . registerNetworkCallback ( rEmpty3 , cEmpty3 ) ;
mCm . registerNetworkCallback ( rEmpty3 , cEmpty3 ) ; mCm . registerNetworkCallback ( rEmpty4 , cEmpty4 ) ; mCm . registerNetworkCallback ( rFoo , cFoo ) ; mCm . registerNetworkCallback ( rBar , cBar ) ; mWiFiNetworkAgent = new MockNetworkAgent ( TRANSPORT_WIFI ) ; mWiFiNetworkAgent . connect ( false ) ; cEmpty1 . expectAvailableCallbacks ( mWiFiNetworkAgent ) ; cEmpty2 . expectAvailableCallbacks ( mWiFiNetworkAgent ) ; cEmpty3 . expectAvailableCallbacks ( mWiFiNetworkAgent ) ; cEmpty4 . expectAvailableCallbacks ( mWiFiNetworkAgent ) ; assertNoCallbacks ( cFoo , cBar ) ; < |startfocus| > mWiFiNetworkAgent . setNetworkSpecifier ( new StringNetworkSpecifier ( "foo" ) ) ; < |endfocus| > cFoo . expectAvailableCallbacks ( mWiFiNetworkAgent ) ; for ( TestNetworkCallback c : emptyCallbacks ) { c . expectCallback ( CallbackState . NETWORK_CAPABILITIES , mWiFiNetworkAgent ) ; } cFoo . expectCallback ( CallbackState . NETWORK_CAPABILITIES , mWiFiNetworkAgent ) ; cFoo . assertNoCallback ( ) ; mWiFiNetworkAgent . setNetworkSpecifier ( new StringNetworkSpecifier ( "bar" ) ) ; cFoo . expectCallback ( CallbackState . LOST , mWiFiNetworkAgent ) ; cBar . expectAvailableCallbacks ( mWiFiNetworkAgent ) ; for ( TestNetworkCallback c : emptyCallbacks ) { c . expectCallback ( CallbackState . NETWORK_CAPABILITIES , mWiFiNetworkAgent ) ; }
cEmpty2 . expectAvailableCallbacks ( mWiFiNetworkAgent ) ; cEmpty3 . expectAvailableCallbacks ( mWiFiNetworkAgent ) ; cEmpty4 . expectAvailableCallbacks ( mWiFiNetworkAgent ) ; assertNoCallbacks ( cFoo , cBar ) ; mWiFiNetworkAgent . setNetworkSpecifier ( new StringNetworkSpecifier ( "foo" ) ) ; cFoo . expectAvailableCallbacks ( mWiFiNetworkAgent ) ; for ( TestNetworkCallback c : emptyCallbacks ) { c . expectCallback ( CallbackState . NETWORK_CAPABILITIES , mWiFiNetworkAgent ) ; } cFoo . expectCallback ( CallbackState . NETWORK_CAPABILITIES , mWiFiNetworkAgent ) ; cFoo . assertNoCallback ( ) ; < |startfocus| > mWiFiNetworkAgent . setNetworkSpecifier ( new StringNetworkSpecifier ( "bar" ) ) ; < |endfocus| > cFoo . expectCallback ( CallbackState . LOST , mWiFiNetworkAgent ) ; cBar . expectAvailableCallbacks ( mWiFiNetworkAgent ) ; for ( TestNetworkCallback c : emptyCallbacks ) { c . expectCallback ( CallbackState . NETWORK_CAPABILITIES , mWiFiNetworkAgent ) ; } cBar . expectCallback ( CallbackState . NETWORK_CAPABILITIES , mWiFiNetworkAgent ) ; cBar . assertNoCallback ( ) ; mWiFiNetworkAgent . setNetworkSpecifier ( null ) ; cBar . expectCallback ( CallbackState . LOST , mWiFiNetworkAgent ) ; for ( TestNetworkCallback c : emptyCallbacks ) { c . expectCallback ( CallbackState . NETWORK_CAPABILITIES , mWiFiNetworkAgent ) ; } assertNoCallbacks ( cEmpty1 , cEmpty2 , cEmpty3 , cFoo , cBar ) ;
} ; class ParcelableSpecifier extends NonParcelableSpecifier implements Parcelable { @Override public int describeContents ( ) { return 0 ; } @Override public void writeToParcel ( Parcel p , int flags ) { } } NetworkRequest . Builder builder ; builder = new NetworkRequest . Builder ( ) . addTransportType ( TRANSPORT_ETHERNET ) ; try { builder . setNetworkSpecifier ( new NonParcelableSpecifier ( ) ) ; Parcel parcelW = Parcel . obtain ( ) ; builder . build ( ) . writeToParcel ( parcelW , 0 ) ; fail ( "Non - parcelable specifier did not throw exception" ) ; } catch ( Exception e ) { // expected }
private int phoneIdForRequest ( NetworkRequest netRequest ) { NetworkSpecifier specifier = netRequest . networkCapabilities . getNetworkSpecifier ( ) ; int subId ; if ( specifier == null ) { subId = mDefaultDataSubscription ; } else if ( specifier instanceof StringNetworkSpecifier ) { < |startfocus| > try { subId = Integer . parseInt ( ( ( StringNetworkSpecifier ) specifier ) . specifier ) ; } catch ( NumberFormatException e ) { subId = INVALID_SUBSCRIPTION_ID ; } < |endfocus| > } else { subId = INVALID_SUBSCRIPTION_ID ; } int phoneId = INVALID_PHONE_INDEX ; if ( subId == INVALID_SUBSCRIPTION_ID ) return phoneId ; for ( int i = 0 ; i < mNumPhones ; i ++ ) { if ( mPhoneSubscriptions [ i ] == subId ) { phoneId = i ; break ; } } return phoneId ;
* You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package android . net ; < |startfocus| > import android . net . wifi . aware . WifiAwareNetworkSpecifier ; < |endfocus| > /* * * Describes specific properties of a network for use in a { @link NetworkRequest } . * * Applications cannot instantiate this class by themselves , but can obtain instances of * subclasses of this class via other APIs . */ public abstract class NetworkSpecifier { public NetworkSpecifier ( ) { } /* * * Returns true if a request with this { @link NetworkSpecifier } is satisfied by a network * with the given NetworkSpecifier . * * @hide */ public abstract boolean satisfiedBy ( NetworkSpecifier other ) ; }
public void resize ( int newSize ) { < |startfocus| > int oldSize = mSize ; mSize = newSize ; ensureCapacity ( mSize ) ; if ( newSize < oldSize ) { Arrays . fill ( mValues , newSize , oldSize , 0 ) ; } < |endfocus| >
public void resize ( int newSize ) { int oldSize = mSize ; mSize = newSize ; ensureCapacity ( mSize ) ; if ( oldSize < newSize ) { Arrays . fill ( mValues , oldSize , newSize , 0 ) ; < |startfocus| > } < |endfocus| >
public void resize ( int newSize ) { // TODO throw on negative Size int oldSize = mSize ; mSize = newSize ; ensureCapacity ( mSize ) ; if ( newSize < oldSize ) { Arrays . fill ( mValues , newSize , oldSize , 0 ) ; } < |startfocus| > < |endfocus| >
public void resize ( int newSize ) { // TODO throw on negative Size int oldSize = mSize ; mSize = newSize ; ensureCapacity ( mSize ) ; if ( newSize < oldSize ) { Arrays . fill ( mValues , newSize , oldSize , 0 ) ; < |startfocus| > } < |endfocus| >
// changes network state . http :/ / b / 29964605 enforceMeteredApnPolicy ( networkCapabilities ) ; } ensureRequestableCapabilities ( networkCapabilities ) ; if ( timeoutMs < 0 ) { throw new IllegalArgumentException ( "Bad timeout specified" ) ; } if ( networkCapabilities . getNetworkSpecifier ( ) instanceof MatchAllNetworkSpecifier ) { throw new IllegalArgumentException ( "NetworkRequest with MatchAllNetworkSpecifier" ) ; } < |startfocus| > NetworkSpecifier ns = networkCapabilities . getNetworkSpecifier ( ) ; if ( ns != null && ns . hasUid ( ) && ns . getUid ( ) != Binder . getCallingUid ( ) ) { throw new SecurityException ( . . . ) ; } < |endfocus| > NetworkRequest networkRequest = new NetworkRequest ( networkCapabilities , legacyType , nextNetworkRequestId ( ) , type ) ; NetworkRequestInfo nri = new NetworkRequestInfo ( messenger , networkRequest , binder ) ; if ( DBG ) log ( "requestNetwork for " + nri ) ; mHandler . sendMessage ( mHandler . obtainMessage ( EVENT_REGISTER_NETWORK_REQUEST , nri ) ) ; if ( timeoutMs > 0 ) { mHandler . sendMessageDelayed ( mHandler . obtainMessage ( EVENT_TIMEOUT_NETWORK_REQUEST , nri ) , timeoutMs ) ; } return networkRequest ;
public static void main ( String [ ] args ) { // Set up minint32 , maxint32 and some others . int [ ] xi = new int [ 8 ] ; xi [ 0 ] = 0x80000000 ; xi [ 1 ] = 0x7fffffff ; < |startfocus| > xi [ 2 ] = - 999 ; < |endfocus| > xi [ 3 ] = - 13 ; xi [ 4 ] = - 1 ; xi [ 5 ] = 0 ; xi [ 6 ] = 1 ; xi [ 7 ] = 999 ; doitInt ( xi ) ; expectEquals32 ( 0x80000000 , xi [ 0 ] ) ; expectEquals32 ( 0x7fffffff , xi [ 1 ] ) ; expectEquals32 ( 999 , xi [ 2 ] ) ; expectEquals32 ( 13 , xi [ 3 ] ) ; expectEquals32 ( 1 , xi [ 4 ] ) ; expectEquals32 ( 0 , xi [ 5 ] ) ; expectEquals32 ( 1 , xi [ 6 ] ) ; expectEquals32 ( 999 , xi [ 7 ] ) ; // Set up minint64 , maxint64 and some others . long [ ] xl = new long [ 8 ] ; xl [ 0 ] = 0x8000000000000000L ; xl [ 1 ] = 0x7fffffffffffffffL ; xl [ 2 ] = - 999 ; xl [ 3 ] = - 13 ; xl [ 4 ] = - 1 ; xl [ 5 ] = 0 ; xl [ 6 ] = 1 ;
try { provider . isSameFile ( null , filesSetup . getDataFilePath ( ) ) ; fail ( ) ; } catch ( NullPointerException expected ) { } try { provider . isSameFile ( filesSetup . getDataFilePath ( ) , null ) ; fail ( ) ; } catch ( NullPointerException expected ) { } } @Test public void test_getFileStore ( ) throws IOException { try { provider . getFileStore ( filesSetup . getDataFilePath ( ) ) ; fail ( ) ; } catch ( SecurityException expected ) { } } < |startfocus| > @Test public void test_getFileStore_NPE ( ) throws IOException { < |endfocus| > try { provider . getFileStore ( null ) ; fail ( ) ; } catch ( SecurityException expected ) { } } @Test public void test_isHidden ( ) throws IOException { assertFalse ( provider . isHidden ( filesSetup . getDataFilePath ( ) ) ) ; // Files can't be hidden using the "dos" view , which is unsupported since it relies // on a custom xattr , which may or may not be available on all FSs . // // Note that this weirdly asymmetric : setting the hidden attribute uses xattrs to // store the value , but reading it uses a different mechanism .
} else { return false ; } } @Rpc ( description = "request a network" ) public String connectivityRequestNetwork ( @RpcParameter ( name = "configJson" ) JSONObject configJson ) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson ( configJson ) ; mNetworkCallback = new NetworkCallback ( NetworkCallback . EVENT_ALL ) ; mManager . requestNetwork ( networkRequest , mNetworkCallback ) ; String key = mNetworkCallback . mId ; mNetworkCallbackMap . put ( key , mNetworkCallback ) ; return key ; } < |startfocus| > @Rpc ( description = "request a Wi - Fi Aware network" ) < |endfocus| > public String connectivityRequestWifiAwareNetwork ( @RpcParameter ( name = "configJson" ) JSONObject configJson ) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson ( configJson ) ; if ( networkRequest . networkCapabilities . getNetworkSpecifier ( ) instanceof StringNetworkSpecifier ) { String ns = ( ( StringNetworkSpecifier ) networkRequest . networkCapabilities . getNetworkSpecifier ( ) ) . specifier ; JSONObject j = new JSONObject ( ns ) ; networkRequest . networkCapabilities . setNetworkSpecifier ( WifiAwareManagerFacade . getNetworkSpecifier ( j ) ) ; } mNetworkCallback = new NetworkCallback ( NetworkCallback . EVENT_ALL ) ; mManager . requestNetwork ( networkRequest , mNetworkCallback ) ; String key = mNetworkCallback . mId ; mNetworkCallbackMap . put ( key , mNetworkCallback ) ; return key ; }
mManager . requestNetwork ( networkRequest , mNetworkCallback ) ; String key = mNetworkCallback . mId ; mNetworkCallbackMap . put ( key , mNetworkCallback ) ; return key ; } @Rpc ( description = "request a Wi - Fi Aware network" ) public String connectivityRequestWifiAwareNetwork ( @RpcParameter ( name = "configJson" ) JSONObject configJson ) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson ( configJson ) ; < |startfocus| > if ( networkRequest . networkCapabilities . getNetworkSpecifier ( ) instanceof StringNetworkSpecifier ) { String ns = ( ( StringNetworkSpecifier ) networkRequest . networkCapabilities . getNetworkSpecifier ( ) ) . specifier ; < |endfocus| > JSONObject j = new JSONObject ( ns ) ; networkRequest . networkCapabilities . setNetworkSpecifier ( WifiAwareManagerFacade . getNetworkSpecifier ( j ) ) ; } mNetworkCallback = new NetworkCallback ( NetworkCallback . EVENT_ALL ) ; mManager . requestNetwork ( networkRequest , mNetworkCallback ) ; String key = mNetworkCallback . mId ; mNetworkCallbackMap . put ( key , mNetworkCallback ) ; return key ; } @Rpc ( description = "Stop listening for connectivity changes" ) public void connectivityStopTrackingConnectivityStateChange ( ) { if ( mTrackingConnectivityStateChange ) { mTrackingConnectivityStateChange = false ; mContext . unregisterReceiver ( mConnectivityReceiver ) ; } }
String key = mNetworkCallback . mId ; mNetworkCallbackMap . put ( key , mNetworkCallback ) ; return key ; } @Rpc ( description = "request a Wi - Fi Aware network" ) public String connectivityRequestWifiAwareNetwork ( @RpcParameter ( name = "configJson" ) JSONObject configJson ) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson ( configJson ) ; if ( networkRequest . networkCapabilities . getNetworkSpecifier ( ) instanceof StringNetworkSpecifier ) { String ns = ( ( StringNetworkSpecifier ) networkRequest . networkCapabilities . getNetworkSpecifier ( ) ) . specifier ; JSONObject j = new JSONObject ( ns ) ; < |startfocus| > networkRequest . networkCapabilities . setNetworkSpecifier ( WifiAwareManagerFacade . getNetworkSpecifier ( j ) ) ; < |endfocus| > } mNetworkCallback = new NetworkCallback ( NetworkCallback . EVENT_ALL ) ; mManager . requestNetwork ( networkRequest , mNetworkCallback ) ; String key = mNetworkCallback . mId ; mNetworkCallbackMap . put ( key , mNetworkCallback ) ; return key ; } @Rpc ( description = "Stop listening for connectivity changes" ) public void connectivityStopTrackingConnectivityStateChange ( ) { if ( mTrackingConnectivityStateChange ) { mTrackingConnectivityStateChange = false ; mContext . unregisterReceiver ( mConnectivityReceiver ) ; } } @Rpc ( description = "request a Wi - Fi Aware network" ) public String connectivityRequestWifiAwareNetwork ( @RpcParameter ( name = "configJson" ) JSONObject configJson ) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson ( configJson ) ; if ( networkRequest . networkCapabilities . getNetworkSpecifier ( ) instanceof StringNetworkSpecifier ) { String ns = ( ( StringNetworkSpecifier ) networkRequest . networkCapabilities . getNetworkSpecifier ( ) ) . specifier ; JSONObject j = new JSONObject ( ns ) ; < |startfocus| > networkRequest . networkCapabilities . setNetworkSpecifier ( WifiAwareManagerFacade . getNetworkSpecifier ( j ) ) ; < |endfocus| > } mNetworkCallback = new NetworkCallback ( NetworkCallback . EVENT_ALL ) ; mManager . requestNetwork ( networkRequest , mNetworkCallback ) ; String key = mNetworkCallback . mId ; mNetworkCallbackMap . put ( key , mNetworkCallback ) ; return key ; }
return key ; } @Rpc ( description = "request a Wi - Fi Aware network" ) public String connectivityRequestWifiAwareNetwork ( @RpcParameter ( name = "configJson" ) JSONObject configJson ) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson ( configJson ) ; if ( networkRequest . networkCapabilities . getNetworkSpecifier ( ) instanceof StringNetworkSpecifier ) { String ns = ( ( StringNetworkSpecifier ) networkRequest . networkCapabilities . getNetworkSpecifier ( ) ) . specifier ; JSONObject j = new JSONObject ( ns ) ; < |startfocus| > networkRequest . networkCapabilities . setNetworkSpecifier ( WifiAwareManagerFacade . getNetworkSpecifier ( j ) ) ; < |endfocus| > } mNetworkCallback = new NetworkCallback ( NetworkCallback . EVENT_ALL ) ; mManager . requestNetwork ( networkRequest , mNetworkCallback ) ; String key = mNetworkCallback . mId ; mNetworkCallbackMap . put ( key , mNetworkCallback ) ; return key ; } @Rpc ( description = "Stop listening for connectivity changes" ) public void connectivityStopTrackingConnectivityStateChange ( ) { if ( mTrackingConnectivityStateChange ) { mTrackingConnectivityStateChange = false ; mContext . unregisterReceiver ( mConnectivityReceiver ) ; } } @Rpc ( description = "Get the extra information about the network state provided by lower network layers . " ) public String connectivityGetNetworkExtraInfo ( ) { return mNetworkExtraInfo ; } @Rpc ( description = "Get the network state" ) public String connectivityGetNetworkState ( ) { return mNetworkState ; } @Rpc ( description = "Get the network type" ) public String connectivityGetNetworkType ( ) { return mNetworkType ; } @Rpc ( description = "Get the network subtype" ) public String connectivityGetNetworkSubtype ( ) { return mNetworkSubtype ; } @Rpc ( description = "Get the network type name" ) public String connectivityGetNetworkTypeName ( ) { return mNetworkTypeName ; } @Rpc ( description = "Get the network subtype name" ) public String connectivityGetNetworkSubtypeName ( ) { return mNetworkSubtypeName ; } @Rpc ( description = "Get the network reason" ) public String connectivityGetNetworkReason ( ) { return mNetworkReason ; } @Rpc ( description = "Get the network extra info" ) public String connectivityGetNetworkExtraInfo ( ) { return mNetworkExtraInfo ; } @Rpc ( description = "Get the network available" ) public boolean connectivityGetNetworkAvailable ( ) { return mNetworkAvailable ; } @Rpc ( description = "Get the network failover" ) public boolean connectivityGetNetworkFailover ( ) { return mNetworkFailover ; } @Rpc ( description = "Get the network roaming" ) public boolean connectivityGetNetworkRoaming ( ) { return mNetworkRoaming ; } @Rpc ( description = "Get the network metered" ) public boolean connectivityGetNetworkMetered ( ) { return mNetworkMetered ; } @Rpc ( description = "Get the network active" ) public boolean connectivityGetNetworkActive ( ) { return mNetworkActive ; } @Rpc ( description = "Get the network capabilities" ) public String connectivityGetNetworkCapabilities ( ) { return mNetworkCapabilities ; } @Rpc ( description = "Get the network link properties" ) public String connectivityGetNetworkLinkProperties ( ) { return mNetworkLinkProperties ; } @Rpc ( description = "Get the network transport names" ) public String connectivityGetNetworkTransportNames ( ) { return mNetworkTransportNames ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @Rpc ( description = "Get the network transport types" ) public String connectivityGetNetworkTransportTypes ( ) { return mNetworkTransportTypes ; } @
public Uri insert ( Uri uri , ContentValues values ) { if ( uri . isPathPrefixMatch ( CONTENT_URI ) ) { // Parse the subId int subId = 0 ; try { subId = Integer . parseInt ( uri . getLastPathSegment ( ) ) ; } catch ( NumberFormatException e ) { < |startfocus| > Log . d ( TAG , "no subId provided , using default . " ) ; subId = getDefaultSubId ( ) ; < |endfocus| > } Log . d ( TAG , "subId = " + subId ) ; // create the new service state ServiceState newSS = new ServiceState ( ) ; newSS . setVoiceRegState ( values . getAsInteger ( VOICE_REG_STATE ) ) ; newSS . setDataRegState ( values . getAsInteger ( DATA_REG_STATE ) ) ; newSS . setVoiceOperatorName ( values . getAsString ( VOICE_OPERATOR_ALPHA_LONG ) , values . getAsString ( VOICE_OPERATOR_ALPHA_SHORT ) , values . getAsString ( VOICE_OPERATOR_NUMERIC ) ) ; newSS . setDataOperatorName ( values . getAsString ( DATA_OPERATOR_ALPHA_LONG ) , values . getAsString ( DATA_OPERATOR_ALPHA_SHORT ) , values . getAsString ( DATA_OPERATOR_NUMERIC ) ) ; newSS . setIsManualSelection ( values . getAsBoolean ( IS_MANUAL_NETWORK_SELECTION ) ) ; }
private static byte getRandomNonZeroByte ( ) { final byte random = ( byte ) ( new Random ( ) ) . nextInt ( ) ; < |startfocus| > // Don't pick the subnet - router anycast address , since that might be // to the upstream already . < |endfocus| > return ( random != 0 ) ? random : 0x1 ;
public boolean processMessage ( Message message ) { maybeLogMessage ( this , message . what ) ; boolean retValue = true ; switch ( message . what ) { case CMD_TETHER_REQUESTED : < |startfocus| > final Mode mode ; try { mode = ( Mode ) message . obj ; } catch ( ClassCastException e ) { Log . e ( TAG , "Invalid tethering interface mode given . " ) ; break ; } < |endfocus| > Log . e ( TAG , "CMD_TETHER_REQUESTED with mode " + mode + " when already operating in mode " + mMode ) ; break ; case CMD_TETHER_UNREQUESTED : transitionTo ( mInitialState ) ; if ( DBG ) Log . d ( TAG , "Untethered ( unrequested ) " + mIfaceName ) ; break ; case CMD_INTERFACE_DOWN : transitionTo ( mUnavailableState ) ; if ( DBG ) Log . d ( TAG , "Untethered ( ifdown ) " + mIfaceName ) ; break ; case CMD_TETHER_CONNECTION_CHANGED : if ( mMode != Mode . TETHERING ) { // Upstream changes are not of interest in our current mode . break ; } String newUpstreamIfaceName = ( String ) ( message . obj ) ; if ( newUpstreamIfaceName == null ) {
a . resize ( 15 ) ; a . set ( 14 , 30 ) ; verify ( new int [ ] { 1 , 2 , 0 , 0 , 0 , 20 , 10 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 30 } , a ) ; int [ ] backingArray = new int [ ] { 1 , 2 , 3 , 4 } ; a = IntArray . wrap ( backingArray ) ; a . set ( 0 , 10 ) ; assertEquals ( 10 , backingArray [ 0 ] ) ; backingArray [ 1 ] = 20 ; backingArray [ 2 ] = 30 ; verify ( backingArray , a ) ; assertEquals ( 2 , a . indexOf ( 30 ) ) ; a . add ( 50 ) ; verify ( new int [ ] { 10 , 20 , 30 , 4 , 50 } , a ) ;
a . resize ( 15 ) ; a . set ( 14 , 30 ) ; verify ( new long [ ] { 1 , 2 , 0 , 0 , 0 , 20 , 10 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 30 } , a ) ; long [ ] backingArray = new long [ ] { 1 , 2 , 3 , 4 } ; a = LongArray . wrap ( backingArray ) ; a . set ( 0 , 10 ) ; assertEquals ( 10 , backingArray [ 0 ] ) ; backingArray [ 1 ] = 20 ; backingArray [ 2 ] = 30 ; verify ( backingArray , a ) ; assertEquals ( 2 , a . indexOf ( 30 ) ) ; a . add ( 50 ) ; verify ( new long [ ] { 10 , 20 , 30 , 4 , 50 } , a ) ;
* @throws ResourceUnavailableException indicating that too many SPIs are currently allocated * for this user * @throws SpiUnavailableException indicating that a particular SPI cannot be reserved */ public SecurityParameterIndex reserveSecurityParameterIndex ( int direction , InetAddress remoteAddress ) throws ResourceUnavailableException { try { return new SecurityParameterIndex ( mService , direction , remoteAddress , IpSecManager . INVALID_SECURITY_PARAMETER_INDEX ) ; < |startfocus| > } catch ( SpiUnavailableException unlikely ) { /* because we choose the SPI , there will alwayse be one */ return null ; < |endfocus| > } } /* * * Reserve an SPI for traffic bound towards the specified remote address . * * < p > If successful , this SPI is guaranteed available until released by a call to { @link * SecurityParameterIndex#close ( ) } . * * @param direction { @link IpSecTransform#DIRECTION_IN } or { @link IpSecTransform#DIRECTION_OUT } * @param remoteAddress address of the remote . SPIs must be unique for each remoteAddress .
* @throws ResourceUnavailableException indicating that too many SPIs are currently allocated * for this user * @throws SpiUnavailableException indicating that a particular SPI cannot be reserved */ public SecurityParameterIndex reserveSecurityParameterIndex ( int direction , InetAddress remoteAddress ) throws ResourceUnavailableException { try { return new SecurityParameterIndex ( mService , direction , remoteAddress , IpSecManager . INVALID_SECURITY_PARAMETER_INDEX ) ; < |startfocus| > } catch ( SpiUnavailableException impossible ) { /* because we choose the SPI , there will alwayse be one */ throw new ResourceUnavailableException ( "No free SPIs" ) ; < |endfocus| > } } /* * * Reserve an SPI for traffic bound towards the specified remote address . * * < p > If successful , this SPI is guaranteed available until released by a call to { @link * SecurityParameterIndex#close ( ) } . * * @param direction { @link IpSecTransform#DIRECTION_IN } or { @link IpSecTransform#DIRECTION_OUT } * @param remoteAddress address of the remote . SPIs must be unique for each remoteAddress .
} } if ( hostName != null ) { hostAddr = InetAddress . getByName ( hostName ) ; serverSocket = new ServerSocket ( port , 0 , hostAddr ) ; } else { serverSocket = new ServerSocket ( port ) ; } // use as workaround for unspecified behaviour of isAnyLocalAddress ( ) InetAddress iAddress = null ; if ( hostName != null ) { iAddress = serverSocket . getInetAddress ( ) ; } else { < |startfocus| > iAddress = InetAddress . getLoopbackAddress ( ) ; < |endfocus| > } address = iAddress . getHostName ( ) + " : " + serverSocket . getLocalPort ( ) ; return address ; } /* * * Stops listening for connection on current address . */ @Override public void stopListening ( ) throws IOException { if ( serverSocket != null ) { serverSocket . close ( ) ; } } /* * * Accepts transport connection for currently listened address and performs handshaking * for specified timeout . * * @param acceptTimeout timeout for accepting in milliseconds * @param handshakeTimeout timeout for handshaking in milliseconds */ @Override public void accept ( long acceptTimeout , long handshakeTimeout ) throws IOException { if ( serverSocket == null ) { throw new IOException ( "Not listening for connections" ) ; } Socket socket = serverSocket . accept ( ) ; socket . setSoTimeout ( ( int ) handshakeTimeout ) ; socket . setTcpNoDelay ( true ) ; socket . setKeepAlive ( true ) ; socket . setSoLinger ( true , 0 ) ; socket . setReceiveBufferSize ( BUFFER_SIZE ) ; socket . setSendBufferSize ( BUFFER_SIZE ) ; transport = new SocketTransport ( socket ) ; } /* * * Returns transport for currently accepted connection . * * @return transport for currently accepted connection */ @Override public Transport getTransport ( ) { return transport ; } }
expectEquals ( 8070450532247928832L , geoLongMulLastValue ( 2147483647L ) ) ; expectEquals ( 0L , geoLongMulLastValue ( - 2147483648L ) ) ; expectEquals ( 8070450532247928832L , geoLongMulLastValue ( 9223372036854775807L ) ) ; expectEquals ( 0L , geoLongMulLastValue ( - 9223372036854775808L ) ) ; float [ ] a = new float [ 16 ] ; narrowingSubscript ( a ) ; for ( int i = 0 ; i < 16 ; i ++ ) { expectEquals ( 2 . 0f , a [ i ] ) ; } < |startfocus| > int [ ] xx = new int [ 2 ] ; int [ ] yy = new int [ 469 ] ; reduc ( ) ; < |endfocus| > expectEquals ( - 469 , xx [ 0 ] ) ; expectEquals ( - 938 , xx [ 1 ] ) ; for ( int i = 0 ; i < 469 ; i ++ ) { expectEquals ( 2 , yy [ i ] ) ; } System . out . println ( "passed" ) ;
mSentSinceLastRecv = 0 ; putRecoveryAction ( RecoveryAction . GET_DATA_CALL_LIST ) ; } else { if ( VDBG_STALL ) log ( "updateDataStallInfo : NONE" ) ; } } private boolean isPhoneStateIdle ( ) { for ( int i = 0 ; i < TelephonyManager . getDefault ( ) . getPhoneCount ( ) ; i ++ ) { Phone phone = PhoneFactory . getPhone ( i ) ; if ( phone != null && phone . getState ( ) != PhoneConstants . State . IDLE ) { < |startfocus| > log ( "isPhoneStateIdle : Voice call active on phone : " + i ) ; < |endfocus| > return false ; } } return true ; } private void onDataStallAlarm ( int tag ) { if ( mDataStallAlarmTag != tag ) { if ( DBG ) { log ( "onDataStallAlarm : ignore , tag = " + tag + " expecting " + mDataStallAlarmTag ) ; } return ; } updateDataStallInfo ( ) ; int hangWatchdogTrigger = Settings . Global . getInt ( mResolver , Settings . Global . PDP_WATCHDOG_TRIGGER_PACKET_COUNT , NUMBER_SENT_PACKETS_OF_HANG ) ; boolean suspectedStall = DATA_STALL_NOT_SUSPECTED ;
chosenIface = iface ; break ; } } } if ( chosenIface == null ) { Log . e ( TAG , "could not find iface of type " + interfaceType ) ; return ; } final int result ; switch ( requestedState ) { case IControlsTethering . STATE_UNAVAILABLE : case IControlsTethering . STATE_AVAILABLE : result = untether ( chosenIface ) ; break ; case IControlsTethering . STATE_TETHERED : case IControlsTethering . STATE_LOCAL_HOTSPOT : result = tether ( chosenIface , requestedState ) ; break ; default : < |startfocus| > result = - 1 ; < |endfocus| > } if ( result != ConnectivityManager . TETHER_ERROR_NO_ERROR ) { Slog . wtf ( TAG , "unable start or stop tethering on iface " + chosenIface ) ; return ; }
// by sending CMD_CLEAR_ERROR if ( error == ConnectivityManager . TETHER_ERROR_MASTER_ERROR ) { mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_CLEAR_ERROR , who ) ; } switch ( state ) { case IControlsTethering . STATE_UNAVAILABLE : case IControlsTethering . STATE_AVAILABLE : mUpstreamWantingIfaces . remove ( iface ) ; mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_UNREQUESTED , who ) ; break ; case IControlsTethering . STATE_TETHERED : < |startfocus| > mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , who ) ; break ; < |endfocus| > case IControlsTethering . STATE_LOCAL_HOTSPOT : mUpstreamWantingIfaces . remove ( iface ) ; mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_TETHER_MODE_REQUESTED , who ) ; break ; } sendTetherStateChangedBroadcast ( ) ;
case CMD_START_TETHERING_ERROR : case CMD_STOP_TETHERING_ERROR : case CMD_SET_DNS_FORWARDERS_ERROR : mLastError = ConnectivityManager . TETHER_ERROR_MASTER_ERROR ; transitionTo ( mInitialState ) ; break ; default : return false ; } return true ; } } class LocalHotspotState extends State { @Override public void enter ( ) { if ( DBG ) Log . d ( TAG , "Local hotspot " + mIfaceName ) ; setInterfaceState ( IControlsTethering . STATE_LOCAL_HOTSPOT ) ; } @Override public void exit ( ) { } @Override public boolean processMessage ( Message message ) { maybeLogMessage ( this , message . what ) ; switch ( message . what ) { case CMD_TETHER_REQUESTED : Log . e ( TAG , "CMD_TETHER_REQUESTED while in local hotspot mode . " ) ; break ; case CMD_TETHER_CONNECTION_CHANGED : // Ignored in local hotspot state . break ; default : return false ; } return true ; } } class TetheredState extends State { @Override public void enter ( ) { if ( DBG ) Log . d ( TAG , "Tethered " + mIfaceName ) ;
private final Object mPublicSync ; private final Context mContext ; private final ArrayMap < String , TetherState > mTetherStates ; private final BroadcastReceiver mStateReceiver ; private final INetworkManagementService mNMService ; private final INetworkStatsService mStatsService ; private final INetworkPolicyManager mPolicyManager ; private final Looper mLooper ; private final MockableSystemProperties mSystemProperties ; private final StateMachine mTetherMasterSM ; private final OffloadController mOffloadController ; private final UpstreamNetworkMonitor mUpstreamNetworkMonitor ; private final HashSet < String > mIfacesWantingUpstream ; private volatile TetheringConfiguration mConfig ; private String mCurrentUpstreamIface ; private Notification . Builder mTetheredNotificationBuilder ; private int mLastNotificationId ; private boolean mRndisEnabled ; // track the RNDIS function enabled state private boolean mUsbTetherRequested ; // true if USB tethering should be started // when RNDIS is enabled // True iff WiFi tethering should be started when soft AP is ready . private boolean mWifiTetherRequested ; public Tethering ( Context context , INetworkManagementService nmService , INetworkStatsService statsService , INetworkPolicyManager policyManager , Looper looper , MockableSystemProperties systemProperties ) {
if ( error == ConnectivityManager . TETHER_ERROR_MASTER_ERROR ) { mTetherMasterSM . sendMessage ( TetherMasterSM . CMD_CLEAR_ERROR , who ) ; } int which ; switch ( state ) { case IControlsTethering . STATE_UNAVAILABLE : case IControlsTethering . STATE_AVAILABLE : which = TetherMasterSM . EVENT_IFACE_SERVING_STATE_INACTIVE ; break ; case IControlsTethering . STATE_TETHERED : case IControlsTethering . STATE_LOCAL_HOTSPOT : which = TetherMasterSM . EVENT_IFACE_SERVING_STATE_ACTIVE ; break ; default : < |startfocus| > Log . wtf ( TAG , "Unknown interface state : " + state ) ; < |endfocus| > return ; } mTetherMasterSM . sendMessage ( which , state , 0 , who ) ; sendTetherStateChangedBroadcast ( ) ;
capabilities | = PhoneAccount . CAPABILITY_VIDEO_CALLING_RELIES_ON_PRESENCE ; } if ( mIsVideoCapable && isCarrierEmergencyVideoCallsAllowed ( ) ) { capabilities | = PhoneAccount . CAPABILITY_EMERGENCY_VIDEO_CALLING ; } mIsVideoPauseSupported = isCarrierVideoPauseSupported ( ) ; Bundle phoneAccountExtras = new Bundle ( ) ; if ( isCarrierInstantLetteringSupported ( ) ) { capabilities | = PhoneAccount . CAPABILITY_CALL_SUBJECT ; phoneAccountExtras = getPhoneAccountExtras ( phoneAccountExtras ) ; } phoneAccountExtras . putString ( PhoneAccount . EXTRA_SORT_ORDER , slotId ) ; < |startfocus| > mIsMergeCallSupported = isCarrierMergeCallSupported ( ) ; < |endfocus| > mIsVideoConferencingSupported = isCarrierVideoConferencingSupported ( ) ; mIsMergeOfWifiCallsAllowedWhenVoWifiOff = isCarrierMergeOfWifiCallsAllowedWhenVoWifiOff ( ) ; if ( isEmergency && mContext . getResources ( ) . getBoolean ( R . bool . config_emergency_account_emergency_calls_only ) ) { capabilities | = PhoneAccount . CAPABILITY_EMERGENCY_CALLS_ONLY ; } if ( icon == null ) { // TODO : Switch to using Icon . createWithResource ( ) once that supports tinting . Resources res = mContext . getResources ( ) ; Drawable drawable = res . getDrawable ( DEFAULT_SIM_ICON , null ) ;
for ( Map . Entry < Class < ? extends UnitTest > , Integer > entry : allUnitTests . entrySet ( ) ) { int testApiVersion = entry . getValue ( ) ; // Only add test if test API version is not greater than build API version . if ( testApiVersion <= thisApiVersion ) { validUnitTests . add ( entry . getKey ( ) ) ; } } return validUnitTests ; } @Parameter ( 0 ) < |startfocus| > public Class < ? extends UnitTest > mTestClass ; < |endfocus| > @Test @MediumTest public void testRSUnitTest ( ) throws Exception { Context ctx = InstrumentationRegistry . getTargetContext ( ) ; UnitTest test = mTestClass . getDeclaredConstructor ( Context . class ) . newInstance ( ctx ) ; test . runTest ( ) ; Assert . assertTrue ( test . getSuccess ( ) ) ; } }
private static void allocateReachableObjects ( ArrayList < MockClass > reachableObjs ) { < |startfocus| > for ( int i = 0 ; i < reachableObjNum ; i ++ ) { < |endfocus| > reachableObjs . add ( new MockClass ( true ) ) ; }
private static void allocateUnreachableObjects ( ) { < |startfocus| > for ( int i = 0 ; i < unreachableObjNum ; i ++ ) { < |endfocus| > new MockClass ( false ) ; }
private static void allocateUnreachableObjects ( ) { < |startfocus| > for ( int i = 0 ; i < unreachableObjNum ; i ++ ) { < |endfocus| > new MockClass ( false ) ; }
} if ( ! mBinaryTestProfilingLibraryPath . isEmpty ( ) ) { jsonObject . put ( BINARY_TEST_PROFILING_LIBRARY_PATH , new JSONArray ( mBinaryTestProfilingLibraryPath ) ) ; CLog . i ( "Added % s to the Json object" , BINARY_TEST_PROFILING_LIBRARY_PATH ) ; } < |startfocus| > if ( mBinaryTestType . equals ( BINARY_TEST_TYPE_HAL_HIDL_GTEST ) ) { CLog . i ( "Set flags to stop the framework and native servers for % s" , BINARY_TEST_TYPE_HAL_HIDL_GTEST ) ; mBinaryTestStopNativeServers = true ; } if ( mBinaryTestDisableFramework ) { jsonObject . put ( BINARY_TEST_DISABLE_FRAMEWORK , mBinaryTestDisableFramework ) ; CLog . i ( "Added % s to the Json object" , BINARY_TEST_DISABLE_FRAMEWORK ) ; } if ( mBinaryTestStopNativeServers ) { jsonObject . put ( BINARY_TEST_STOP_NATIVE_SERVERS , mBinaryTestStopNativeServers ) ; CLog . i ( "Added % s to the Json object" , BINARY_TEST_STOP_NATIVE_SERVERS ) ; } if ( ! mHalHidlReplayTestTracePaths . isEmpty ( ) ) { jsonObject . put ( HAL_HIDL_REPLAY_TEST_TRACE_PATHS , new JSONArray ( mHalHidlReplayTestTracePaths ) ) ; < |endfocus| >
import android . util . Log ; import java . util . Arrays ; import java . util . Objects ; /* * * Network specifier object used to request a Wi - Fi Aware network . Apps do not create these objects * directly but obtain them using * { @link WifiAwareSession#createNetworkSpecifierOpen ( int , byte [ ] ) } or * { @link DiscoverySession#createNetworkSpecifierOpen ( PeerHandle ) } or their secure ( Passphrase ) * versions . * * @hide */ < |startfocus| > public final class WifiAwareNetworkSpecifier extends NetworkSpecifier implements Parcelable { < |endfocus| > /* * * TYPE : in band , specific peer : role , client_id , session_id , peer_id , pmk / passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB = 0 ; /* * * TYPE : in band , any peer : role , client_id , session_id , pmk / passphrase optional * [ only permitted for RESPONDER ] * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB_ANY_PEER = 1 ; /* * * TYPE : out - of - band : role , client_id , peer_mac , pmk / passphrase optional
mMediaInterface . folderItemsRsp ( bdaddr , AvrcpConstants . RSP_INV_RANGE , null ) ; return ; } result_items = checkIndexOutofBounds ( bdaddr , items , startItem , endItem ) ; /* check for index out of bound errors */ if ( result_items == null ) { Log . w ( TAG , "result_items is null . " ) ; mMediaInterface . folderItemsRsp ( bdaddr , AvrcpConstants . RSP_INV_RANGE , null ) ; return ; } FolderItemsData folderDataNative = new FolderItemsData ( result_items . size ( ) ) ; < |startfocus| > /* variables to temporarily add attrs */ < |endfocus| > ArrayList < String > attrArray = new ArrayList < String > ( ) ; ArrayList < Integer > attrId = new ArrayList < Integer > ( ) ; for ( int itemIndex = 0 ; itemIndex < result_items . size ( ) ; itemIndex ++ ) { // get the queue id long qid = result_items . get ( itemIndex ) . getQueueId ( ) ; byte [ ] uid = ByteBuffer . allocate ( AvrcpConstants . UID_SIZE ) . putLong ( qid ) . array ( ) ; // get the array of uid from 2d to array 1D array for ( int idx = 0 ; idx < AvrcpConstants . UID_SIZE ; idx ++ ) {
String value = null ; int attribId = isAllAttribRequested ? ( idx + 1 ) : folderItemsReqObj . mAttrIDs [ idx ] ; if ( attribId >= AvrcpConstants . ATTRID_TITLE && attribId <= AvrcpConstants . ATTRID_PLAY_TIME ) { value = getAttrValue ( attribId , result_items , itemIndex ) ; if ( value != null ) { attrArray . add ( value ) ; attrId . add ( attribId ) ; attrCnt ++ ; } } else { < |startfocus| > Log . w ( TAG , "invalid attribute id is requested : " + attribId ) ; < |endfocus| > } } /* add num attr actually received from media player for a particular item */ folderDataNative . mAttributesNum [ itemIndex ] = attrCnt ; } } /* copy filtered attr ids and attr values to response parameters */ if ( folderItemsReqObj . mNumAttr != AvrcpConstants . NUM_ATTR_NONE ) { folderDataNative . mAttrIds = new int [ attrId . size ( ) ] ; for ( int attrIndex = 0 ; attrIndex < attrId . size ( ) ; attrIndex ++ ) folderDataNative . mAttrIds [ attrIndex ] = attrId . get ( attrIndex ) ;
if ( oldLp != null && newLp . isIdenticalDnses ( oldLp ) ) { return ; // no updating necessary } Collection < InetAddress > dnses = newLp . getDnsServers ( ) ; if ( DBG ) log ( "Setting DNS servers for network " + netId + " to " + dnses ) ; try { mNetd . setDnsConfigurationForNetwork ( netId , NetworkUtils . makeStrings ( dnses ) , newLp . getDomains ( ) ) ; } catch ( Exception e ) { < |startfocus| > } < |endfocus| > flushVmDnsCache ( ) ;
/* * * The URL used for fallback HTTP captive portal detection when previous HTTP * and HTTPS captive portal detection attemps did not return a conclusive answer . * * @hide */ public static final String CAPTIVE_PORTAL_FALLBACK_URL = "captive_portal_fallback_url" ; /* * * A comma - separated list of URLs used for captive portal detection in addition to the * fallback HTTP url associated with CAPTIVE_PORTAL_FALLBACK_URL . * * @hide */ public static final String CAPTIVE_PORTAL_OTHER_FALLBACK_URLS = "captive_portal_other_fallback_urls" ; /* * * Whether to use HTTPS for network validation . This is enabled by default and the setting * needs to be set to 0 to disable it . This setting is a misnomer because captive portals * don't actually use HTTPS , but it's consistent with the other settings . * * @hide */ public static final String CAPTIVE_PORTAL_USE_HTTPS = "captive_portal_use_https" ; /* *
private URL [ ] makeCaptivePortalFallbackUrls ( Context context ) { String joinedUrls = getSetting ( context , Settings . Global . CAPTIVE_PORTAL_FALLBACK_URL , DEFAULT_FALLBACK_URL ) + " , " + getSetting ( context , Settings . Global . CAPTIVE_PORTAL_OTHER_FALLBACK_URLS , DEFAULT_OTHER_FALLBACK_URLS ) ; List < URL > urls = new ArrayList < > ( ) ; for ( String s : joinedUrls . split ( " , " ) ) { URL u = makeURL ( s ) ; if ( u == null ) { continue ; } urls . add ( u ) ; } if ( urls . isEmpty ( ) ) { Log . e ( TAG , String . format ( "could not create any url from % s" , joinedUrls ) ) ; } return urls . toArray ( new URL [ urls . size ( ) ] ) ;
* Inc . , 51 Franklin St , Fifth Floor , Boston , MA 02110 - 1301 USA . * * Please contact Oracle , 500 Oracle Parkway , Redwood Shores , CA 94065 USA * or visit www . oracle . com if you need additional information or have any * questions . */ package java . util ; import java . util . function . Consumer ; import java . util . function . Function ; import java . util . function . Predicate ; import java . util . function . Supplier ; < |startfocus| > // Android - changed : removed paragraph about value - based class semantics . < |endfocus| > /* * * A container object which may or may not contain a non - null value . * If a value is present , { @code isPresent ( ) } will return { @code true } and * { @code get ( ) } will return the value . * * < p > Additional methods that depend on the presence or absence of a contained * value are provided , such as { @link #orElse ( java . lang . Object ) orElse ( ) } * ( return a default value if value not present ) and * { @link #ifPresent ( java . util . function . Consumer ) ifPresent ( ) } ( execute a block
* supported on this device . * * @param secondaryPhy Secondary advertising physical channel , can only be * one of { @link BluetoothDevice#PHY_LE_1M } , * { @link BluetoothDevice#PHY_LE_2M } or * { @link BluetoothDevice#PHY_LE_CODED } . * @throws IllegalArgumentException If the secondaryPhy is invalid . */ public Builder setSecondaryPhy ( int secondaryPhy ) { if ( secondaryPhy != BluetoothDevice . PHY_LE_1M && < |startfocus| > secondaryPhy != BluetoothDevice . PHY_LE_2M && < |endfocus| > secondaryPhy != BluetoothDevice . PHY_LE_CODED ) { throw new IllegalArgumentException ( "bad secondaryPhy " + secondaryPhy ) ; } this . secondaryPhy = secondaryPhy ; return this ; } /* * * Set advertising interval . * * @param interval Bluetooth LE Advertising interval , in 0 . 625ms unit . Valid * range is from 160 ( 100ms ) to 16777215 ( 10 , 485 . 759375 s ) . * Recommended values are : * { @link AdvertisingSetParameters#INTERVAL_LOW } , * { @link AdvertisingSetParameters#INTERVAL_MEDIUM } , or
public String getDisplayName ( boolean daylightTime , int style , Locale locale ) { < |startfocus| > // BEGIN Android - changed : implement using android . icu . text . TimeZoneNames < |endfocus| > TimeZoneNames . NameType nameType ; switch ( style ) { case SHORT : nameType = daylightTime ? TimeZoneNames . NameType . SHORT_DAYLIGHT : TimeZoneNames . NameType . SHORT_STANDARD ; break ; case LONG : nameType = daylightTime ? TimeZoneNames . NameType . LONG_DAYLIGHT : TimeZoneNames . NameType . LONG_STANDARD ; break ; default : throw new IllegalArgumentException ( "Illegal style : " + style ) ; } long now = System . currentTimeMillis ( ) ; String canonicalID = android . icu . util . TimeZone . getCanonicalID ( getID ( ) ) ; if ( canonicalID != null ) { TimeZoneNames names = TimeZoneNames . getInstance ( locale ) ; String displayName = names . getDisplayName ( canonicalID , nameType , now ) ; if ( displayName != null ) { return displayName ; } } // We get here if this is a custom timezone or ICU doesn't have name data for the specific // style and locale . int offsetMillis = getRawOffset ( ) ;
// Android - changed : implement using android . icu . text . TimeZoneNames TimeZoneNames . NameType nameType ; switch ( style ) { case SHORT : nameType = daylightTime ? TimeZoneNames . NameType . SHORT_DAYLIGHT : TimeZoneNames . NameType . SHORT_STANDARD ; break ; case LONG : nameType = daylightTime ? TimeZoneNames . NameType . LONG_DAYLIGHT : TimeZoneNames . NameType . LONG_STANDARD ; break ; default : throw new IllegalArgumentException ( "Illegal style : " + style ) ; } < |startfocus| > long now = System . currentTimeMillis ( ) ; String canonicalID = android . icu . util . TimeZone . getCanonicalID ( getID ( ) ) ; < |endfocus| > if ( canonicalID != null ) { TimeZoneNames names = TimeZoneNames . getInstance ( locale ) ; String displayName = names . getDisplayName ( canonicalID , nameType , now ) ; if ( displayName != null ) { return displayName ; } } // We get here if this is a custom timezone or ICU doesn't have name data for the specific // style and locale . int offsetMillis = getRawOffset ( ) ; if ( daylightTime ) { offsetMillis += getDSTSavings ( ) ; }
boolean isRingerAudible = isVolumeOverZero && shouldRingForContact && isRingtonePresent ; // Acquire audio focus under any of the following conditions : // 1 . Should ring for contact and there's an HFP device attached // 2 . Volume is over zero , we should ring for the contact , and there's a audible ringtone // present . boolean shouldAcquireAudioFocus = < |startfocus| > ( isVolumeOverZero && shouldRingForContact && isRingtonePresent ) || ( isHfpDeviceAttached && shouldRingForContact ) ; < |endfocus| > // Don't do call waiting operations or vibration unless these are false . boolean isTheaterModeOn = mSystemSettingsUtil . isTheaterModeOn ( mContext ) ; boolean letDialerHandleRinging = mInCallController . doesConnectedDialerSupportRinging ( ) ; boolean endEarly = isTheaterModeOn || letDialerHandleRinging ; if ( endEarly ) { if ( letDialerHandleRinging ) { Log . addEvent ( foregroundCall , LogUtils . Events . SKIP_RINGING ) ; } return shouldAcquireAudioFocus ;
Log . addEvent ( foregroundCall , LogUtils . Events . START_RINGER ) ; // Because we wait until a contact info query to complete before processing a // call ( for the purposes of direct - to - voicemail ) , the information about custom // ringtones should be available by the time this code executes . We can safely // request the custom ringtone from the call and expect it to be current . mRingtonePlayer . play ( mRingtoneFactory , foregroundCall ) ; } else { < |startfocus| > Log . i ( this , "startRinging : skipping because ringer would not be audible . isVolumeOverZero : " + isVolumeOverZero + " shouldRingForContact : " + shouldRingForContact + " isRingtonePresent : " + isRingtonePresent ) ; < |endfocus| > } if ( shouldVibrate ( mContext , foregroundCall ) && ! mIsVibrating && shouldRingForContact ) { mVibratingCall = foregroundCall ; mVibrator . vibrate ( VIBRATION_PATTERN , VIBRATION_PATTERN_REPEAT , VIBRATION_ATTRIBUTES ) ; mIsVibrating = true ; } else if ( mIsVibrating ) { Log . addEvent ( foregroundCall , LogUtils . Events . SKIP_VIBRATION , "already vibrating" ) ; } return shouldAcquireAudioFocus ;
private URL nextFallbackUrl ( ) { if ( mCaptivePortalFallbackUrls . length == 0 ) { return null ; } < |startfocus| > int idx = Math . abs ( mNextFallbackUrlSeed ) % mCaptivePortalFallbackUrls . length ; mNextFallbackUrlSeed += new Random ( ) . nextInt ( ) ; // randomely change url without memory . < |endfocus| > return mCaptivePortalFallbackUrls [ idx ] ;
when ( mFakeCallsManager . hasOngoingCalls ( ) ) . thenReturn ( true ) ; assertTrue ( mTSIBinder . isInCall ( DEFAULT_DIALER_PACKAGE ) ) ; } @SmallTest public void testNotIsInCall ( ) throws Exception { when ( mFakeCallsManager . hasOngoingCalls ( ) ) . thenReturn ( false ) ; assertFalse ( mTSIBinder . isInCall ( DEFAULT_DIALER_PACKAGE ) ) ; } @SmallTest public void testIsInCallFail ( ) throws Exception { doThrow ( new SecurityException ( ) ) . when ( mContext ) . enforceCallingOrSelfPermission ( anyString ( ) , any ( ) ) ; try { < |startfocus| > mTSIBinder . isInCall ( "blah" ) ; fail ( ) ; < |endfocus| > } catch ( SecurityException e ) { // desired result } verify ( mFakeCallsManager , never ( ) ) . hasOngoingCalls ( ) ; } @SmallTest public void testIsInManagedCall ( ) throws Exception { when ( mFakeCallsManager . hasOngoingManagedCalls ( ) ) . thenReturn ( true ) ; assertTrue ( mTSIBinder . isInManagedCall ( DEFAULT_DIALER_PACKAGE ) ) ; } @SmallTest public void testNotIsInManagedCall ( ) throws Exception { when ( mFakeCallsManager . hasOngoingManagedCalls ( ) ) . thenReturn ( false ) ; assertFalse ( mTSIBinder . isInManagedCall ( DEFAULT_DIALER_PACKAGE ) ) ; } @SmallTest
assertTrue ( mTSIBinder . isInManagedCall ( DEFAULT_DIALER_PACKAGE ) ) ; } @SmallTest public void testNotIsInManagedCall ( ) throws Exception { when ( mFakeCallsManager . hasOngoingManagedCalls ( ) ) . thenReturn ( false ) ; assertFalse ( mTSIBinder . isInManagedCall ( DEFAULT_DIALER_PACKAGE ) ) ; } @SmallTest public void testIsInManagedCallFail ( ) throws Exception { doThrow ( new SecurityException ( ) ) . when ( mContext ) . enforceCallingOrSelfPermission ( anyString ( ) , any ( ) ) ; try { < |startfocus| > mTSIBinder . isInManagedCall ( "blah" ) ; < |endfocus| > } catch ( SecurityException e ) { // desired result } verify ( mFakeCallsManager , never ( ) ) . hasOngoingCalls ( ) ; } /* * * Register phone accounts for the supplied PhoneAccountHandles to make them * visible to all users ( via the isVisibleToCaller method in TelecomServiceImpl . * @param handles the handles for which phone accounts should be created for . */ private void makeAccountsVisibleToAllUsers ( PhoneAccountHandle . . . handles ) { for ( PhoneAccountHandle ph : handles ) { when ( mFakePhoneAccountRegistrar . getPhoneAccountUnchecked ( eq ( ph ) ) ) . thenReturn ( < |startfocus| >
for ( int i = 0 ; i <= 255 ; ++ i ) { s . setTrafficClass ( i ) ; // b / 30909505 // Linux does not set ECN bits for IP_TOS , but sets for IPV6_TCLASS . We should // accept either output . int actual = s . getTrafficClass ( ) ; assertTrue ( i == actual || // IPV6_TCLASS < |startfocus| > ( ( ( i & ~INET_ECN_MASK ) == ( actual & ~INET_ECN_MASK ) ) && ( ( actual & INET_ECN_MASK ) == 0 ) ) ) ; // IP_TOS < |endfocus| > } } } public void testReadAfterClose ( ) throws Exception { MockServer server = new MockServer ( ) ; server . enqueue ( new byte [ ] { 5 , 3 } , 0 ) ; Socket socket = new Socket ( "localhost" , server . port ) ; InputStream in = socket . getInputStream ( ) ; assertEquals ( 5 , in . read ( ) ) ; assertEquals ( 3 , in . read ( ) ) ; assertEquals ( - 1 , in . read ( ) ) ; assertEquals ( - 1 , in . read ( ) ) ; socket . close ( ) ; in . close ( ) ; /* * Rather astonishingly , read ( ) doesn't throw even though the stream is
} } } } private void connectToAddress ( InetAddress address , int port , int timeout ) throws IOException { if ( address . isAnyLocalAddress ( ) ) { doConnect ( InetAddress . getLocalHost ( ) , port , timeout ) ; } else { doConnect ( address , port , timeout ) ; } } public void setOption ( int opt , Object val ) throws SocketException { if ( isClosedOrPending ( ) ) { throw new SocketException ( "Socket Closed" ) ; } < |startfocus| > // Android - removed : alternative implementation < |endfocus| > /* boolean on = true ; switch ( opt ) { // check type safety b4 going native . These should never * fail , since only java . Socket * has access to * PlainSocketImpl . setOption ( ) . // case SO_LINGER : if ( val == null || ( ! ( val instanceof Integer ) && ! ( val instanceof Boolean ) ) ) throw new SocketException ( "Bad parameter for option" ) ; if ( val instanceof Boolean ) { // true only if disabling - enabling should be Integer on = false ; } break ; case SO_TIMEOUT :
if ( address . isAnyLocalAddress ( ) ) { doConnect ( InetAddress . getLocalHost ( ) , port , timeout ) ; } else { doConnect ( address , port , timeout ) ; } } public void setOption ( int opt , Object val ) throws SocketException { if ( isClosedOrPending ( ) ) { throw new SocketException ( "Socket Closed" ) ; } // Android - removed : alternative implementation /* boolean on = true ; switch ( opt ) { < |startfocus| > // check type safety b4 going native . These should never < |endfocus| > * fail , since only java . Socket * has access to * PlainSocketImpl . setOption ( ) . // case SO_LINGER : if ( val == null || ( ! ( val instanceof Integer ) && ! ( val instanceof Boolean ) ) ) throw new SocketException ( "Bad parameter for option" ) ; if ( val instanceof Boolean ) { // true only if disabling - enabling should be Integer on = false ; } break ; case SO_TIMEOUT : if ( val == null || ( ! ( val instanceof Integer ) ) ) throw new SocketException ( "Bad parameter for SO_TIMEOUT" ) ; < |startfocus| > * int tmp = 0 ; if ( on ) { tmp = ( ( Integer ) val ) . intValue ( ) ; if ( tmp < 0 ) throw new IllegalArgumentException ( "timeout < 0" ) ; } if ( socket != null ) socket . setSoTimeout ( tmp ) ; timeout = tmp ; break ; < |endfocus| >
} else { doConnect ( address , port , timeout ) ; } } public void setOption ( int opt , Object val ) throws SocketException { if ( isClosedOrPending ( ) ) { throw new SocketException ( "Socket Closed" ) ; } // Android - removed : alternative implementation /* boolean on = true ; switch ( opt ) { // check type safety b4 going native . These should never * fail , since only java . Socket * has access to * PlainSocketImpl . setOption ( ) . < |startfocus| > // < |endfocus| > case SO_LINGER : if ( val == null || ( ! ( val instanceof Integer ) && ! ( val instanceof Boolean ) ) ) throw new SocketException ( "Bad parameter for option" ) ; if ( val instanceof Boolean ) { // true only if disabling - enabling should be * Integer on = false ; } break ; case SO_TIMEOUT : if ( val == null || ( ! ( val instanceof Integer ) ) ) throw new SocketException ( "Bad parameter for SO_TIMEOUT" ) ; int tmp = ( ( Integer ) val ) . intValue ( ) ; if ( tmp < 0 ) throw new IllegalArgumentException ( "timeout < 0" ) ;
} // Android - removed : alternative implementation /* boolean on = true ; switch ( opt ) { // check type safety b4 going native . These should never * fail , since only java . Socket * has access to * PlainSocketImpl . setOption ( ) . // case SO_LINGER : if ( val == null || ( ! ( val instanceof Integer ) && ! ( val instanceof Boolean ) ) ) throw new SocketException ( "Bad parameter for option" ) ; if ( val instanceof Boolean ) { < |startfocus| > /* true if disabling - enabling should be Integer * but I'm ambivalent in this case < |endfocus| > on = false ; } break ; case SO_TIMEOUT : if ( val == null || ( ! ( val instanceof Integer ) ) ) throw new SocketException ( "Bad parameter for SO_TIMEOUT" ) ; int tmp = ( ( Integer ) val ) . intValue ( ) ; if ( tmp < 0 ) throw new IllegalArgumentException ( "timeout < 0" ) ; timeout = tmp ; break ; case IP_TOS : if ( val == null || ! ( val instanceof Integer ) ) { throw new SocketException ( "bad argument for IP_TOS" ) ; }
break ; default : throw new SocketException ( "unrecognized TCP option : " + opt ) ; } socketSetOption ( opt , on , val ) ; */ if ( opt == SO_TIMEOUT ) { timeout = ( Integer ) val ; } socketSetOption ( opt , val ) ; } public Object getOption ( int opt ) throws SocketException { if ( isClosedOrPending ( ) ) { throw new SocketException ( "Socket Closed" ) ; } if ( opt == SO_TIMEOUT ) { return new Integer ( timeout ) ; } < |startfocus| > // Android - removed : alternative implementation < |endfocus| > /* int ret = 0 ; // * The native socketGetOption ( ) knows about 3 options . * The 32 bit value it returns will be interpreted according * to what we're asking . A return of - 1 means it understands * the option but its turned off . It will raise a SocketException * if "opt" isn't one it understands . // switch ( opt ) { case TCP_NODELAY : ret = socketGetOption ( opt , null ) ; return Boolean . valueOf ( ret != - 1 ) ; case SO_OOBINLINE : ret = socketGetOption ( opt , null ) ; return Boolean . valueOf ( ret != - 1 ) ; case SO_LINGER : ret = socketGetOption ( opt , null ) ; return ( ret == - 1 ) ? Boolean . FALSE : ( Object ) ( new Integer ( ret ) ) ; case SO_SNDBUF : case SO_RCVBUF : case SO_KEEPALIVE : case SO_REUSEADDR : case SO_BROADCAST : case IP_TOS : ret = socketGetOption ( opt , null ) ; if ( ret == - 1 ) { return Boolean . FALSE ; } return new Integer ( ret ) ; case SO_BINDADDR : InetAddressContainer in = new InetAddressContainer ( ) ; ret = socketGetOption ( opt , in ) ; return in . addr ; case SO_RCVLOWAT : case SO_SNDLOWAT : ret = socketGetOption ( opt , null ) ; return new Integer ( ret ) ; case SO_RCVTIMEO : case SO_SNDTIMEO : ret = socketGetOption ( opt , null ) ; return new Integer ( ret ) ; default : throw new SocketException ( "Option not supported" ) ; } */ < |startfocus| > // Android - changed : alternative implementation < |endfocus| > int ret = 0 ; // * The native socketGetOption ( ) knows about 3 options . * The 32 bit value it returns will be interpreted according * to what we're asking . A return of - 1 means it understands * the option but its turned off . It will raise a SocketException * if "opt" isn't one it understands . // switch ( opt ) { case TCP_NODELAY : ret = socketGetOption ( opt , null ) ; return Boolean . valueOf ( ret != - 1 ) ; case SO_OOBINLINE : ret = socketGetOption ( opt , null ) ; return Boolean . valueOf ( ret != - 1 ) ; case SO_LINGER : ret = socketGetOption ( opt , null ) ; return ( ret == - 1 ) ? Boolean . FALSE : ( Object ) ( new Integer ( ret ) ) ; case SO_SNDBUF : case SO_RCVBUF : case SO_KEEPALIVE : case SO_REUSEADDR : case SO_BROADCAST : case IP_TOS : ret = socketGetOption ( opt , null ) ; if ( ret == - 1 ) { return Boolean . FALSE ; } return new Integer ( ret ) ; case SO_BINDADDR : InetAddressContainer in = new InetAddressContainer ( ) ; ret = socketGetOption ( opt , in ) ; return in . addr ; case SO_RCVLOWAT : case SO_SNDLOWAT : ret = socketGetOption ( opt , null ) ; return new Integer ( ret ) ; case SO_RCVTIMEO : case SO_SNDTIMEO : ret = socketGetOption ( opt , null ) ; return new Integer ( ret ) ; default : throw new SocketException ( "Option not supported" ) ; } } protected void socketSetOption ( int opt , Object val ) throws SocketException { if ( isClosedOrPending ( ) ) { throw new SocketException ( "Socket Closed" ) ; } if ( opt == SO_TIMEOUT ) { int tmp = 0 ; if ( val == null || ! ( val instanceof Integer ) ) { throw new SocketException ( "bad argument for SO_TIMEOUT" ) ; } tmp = ( ( Integer ) val ) . intValue ( ) ; if ( tmp < 0 ) throw new IllegalArgumentException ( "timeout < 0" ) ; timeout = tmp ; return ; } // < |startfocus| > // Android - removed : alternative implementation < |endfocus| > /* int on = 1 ; if ( val == null || ! ( val instanceof Integer ) ) { on = 0 ; } if ( on == 0 ) { socketSetOption ( opt , false , null ) ; return ; } switch ( opt ) { case TCP_NODELAY : case SO_OOBINLINE : case SO_LINGER : case SO_SNDBUF : case SO_RCVBUF : case SO_KEEPALIVE : case SO_REUSEADDR : case SO_BROADCAST : case IP_TOS : break ; default : throw new SocketException ( "unrecognized TCP option : " + opt ) ; } socketSetOption ( opt , on , val ) ; */ < |startfocus| > // Android - changed : alternative implementation < |endfocus| > int on = 1 ; if ( val == null || ! ( val instanceof Integer ) ) { on = 0 ; } if ( on == 0 ) { socketSetOption ( opt , false , null ) ; return ; } switch ( opt ) { case TCP_NODELAY : case SO_OOBINLINE : case SO_LINGER : case SO_SNDBUF : case SO_RCVBUF : case SO_KEEPALIVE : case SO_REUSEADDR : case SO_BROADCAST : case IP_TOS : break ; default : throw new SocketException ( "unrecognized TCP option : " + opt ) ; } socketSetOption ( opt , on , val ) ; } protected void socketSetOption ( int opt , boolean on , Object val ) throws SocketException { if ( isClosedOrPending ( ) ) { throw new SocketException ( "Socket Closed" ) ; } int value = 0 ; if ( on ) { value = 1 ; } if ( opt == SO_LINGER ) { if ( val == null || ! ( val instanceof Integer ) ) { value = - 1 ; } else { value = ( ( Integer ) val ) . intValue ( ) ; } } else if ( val instanceof Integer ) { value = ( ( Integer ) val ) . intValue ( ) ; } socketSetOption0 ( opt , on , value ) ; } /* * "value" is ignored unless "opt" is SO_LINGER . * "value" is the amount of time to linger . */ private native void socketSetOption0 ( int opt , boolean on , int value ) throws SocketException ; private native int socketGetOption ( int opt , Object iaContainerObj ) throws SocketException ; public void setTcpNoDelay ( boolean on ) throws SocketException { if ( isClosedOrPending ( ) ) { throw new SocketException ( "Socket Closed" ) ; } socketSetOption ( TCP_NODELAY , on ) ; } public boolean getTcpNoDelay ( ) throws SocketException { if ( isClosedOrPending ( ) ) { throw new SocketException ( "Socket Closed" ) ; } return socketGetOption ( TCP_NODELAY , null ) != - 1 ; } public void setSoLinger ( boolean on , int linger ) throws SocketException { if ( isClosedOrPending ( ) ) { throw new SocketException ( "Socket Closed" ) ; } if ( ! on ) { linger = - 1 ; } socketSetOption ( SO_LINGER , on , linger ) ; } public int getSoLinger ( ) throws SocketException { if ( isClosedOrPending ( ) ) { throw new SocketException ( "Socket Closed" ) ; } return socketGetOption ( SO_LINGER , null ) ; } public void sendUrgentData ( int data ) throws IOException { if ( ! getOOBInline ( ) ) { throw new SocketException ( "OOB not allowed" ) ; } // Android - changed : alternative implementation // < |startfocus| > // Android - removed : alternative implementation < |endfocus| > /* // Java only reads 1 byte ,
/* * Copyright ( C ) 2011 The Android Open Source Project * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package java . net ; import java . io . IOException ; import java . io . InputStream ; import java . io . OutputStream ; import java . nio . channels . SocketChannel ; /* * * A socket that implements the TCP protocol . * * @see ServerSocket */ public class Socket { private boolean isCreated ; private boolean isBound ; private boolean isConnected ; private boolean isClosed ; private boolean isInputShutdown ; private boolean isOutputShutdown ; private InetAddress address ; private int port ; private int localport ; private SocketImpl impl ; private boolean oldImpl ; private int timeout ; private boolean shut_rd = false ; private boolean shut_wr = false ; private Object readMonitor = new Object ( ) ; private Object writeMonitor = new Object ( ) ; /* * * Constructs a new unconnected socket . When a SocketImplFactory is * defined it creates the internal socket implementation , otherwise the * default socket implementation will be used . * * @see SocketImpl * @see SocketImplFactory */ public Socket ( ) { this ( new PlainSocketImpl ( ) ) ; } /* * * Constructs a new unconnected socket using the given proxy type . When a * SocketImplFactory is defined it creates the internal socket * implementation , otherwise the default socket implementation will be * used . * * @param proxy * the proxy that will be used for this socket connection . * @throws IllegalArgumentException * if the proxy is of an invalid type or { @code null } . * @see SocketImpl * @see SocketImplFactory * @since 1 . 5 */ public Socket ( Proxy proxy ) { if ( proxy == null || proxy . type ( ) != Proxy . Type . SOCKS ) { throw new IllegalArgumentException ( "Invalid Proxy" ) ; } this . impl = new SocksSocketImpl ( ( SocketImpl ) proxy . address ( ) ) ; } /* * * Constructs a new socket connected to the given remote host at the given * remote port . When a SocketImplFactory is defined it creates the internal * socket implementation , otherwise the default socket implementation will * be used . * * @param host * the remote host address the socket has to be connected to . * @param port * the remote port the socket has to be connected to . * @throws UnknownHostException * if the host is not known . * @throws IOException * if an error occurs while creating the socket . * @see SocketImpl * @see SocketImplFactory */ public Socket ( String host , int port ) throws UnknownHostException , IOException { this ( InetAddress . getByName ( host ) , port , null , 0 ) ; } /* * * Constructs a new socket connected to the given remote host at the given * remote port . When a SocketImplFactory is defined it creates the internal * socket implementation , otherwise the default socket implementation will * be used . * * @param address * the remote host address the socket has to be connected to . * @param port * the remote port the socket has to be connected to . * @throws IOException * if an error occurs while creating the socket . * @see SocketImpl * @see SocketImplFactory */ public Socket ( InetAddress address , int port ) throws IOException { this ( address , port , null , 0 ) ; } /* * * Constructs a new socket connected to the given remote host at the given * remote port and bound to the given local address and port . When a * SocketImplFactory is defined it creates the internal socket * implementation , otherwise the default socket implementation will be * used . * * @param host * the remote host address the socket has to be connected to . * @param port * the remote port the socket has to be connected to . * @param localAddr * the local address and port the socket is bound to . * @throws IOException * if an error occurs while creating the socket . * @see SocketImpl * @see SocketImplFactory */ public Socket ( String host , int port , InetAddress localAddr , int localPort ) throws IOException { this ( InetAddress . getByName ( host ) , port , localAddr , localPort ) ; } /* * * Constructs a new socket connected to the given remote host at the given * remote port and bound to the given local address and port . When a * SocketImplFactory is defined it creates the internal socket * implementation , otherwise the default socket implementation will be * used . * * @param address * the remote host address the socket has to be connected to . * @param port * the remote port the socket has to be connected to . * @param localAddr * the local address and port the socket is bound to . * @throws IOException * if an error occurs while creating the socket . * @see SocketImpl * @see SocketImplFactory */ public Socket ( InetAddress address , int port , InetAddress localAddr , int localPort ) throws IOException { this ( new PlainSocketImpl ( ) ) ; if ( address == null ) { throw new IllegalArgumentException ( "address == null" ) ; } if ( port < 0 || port > 65535 ) { throw new IllegalArgumentException ( "port < 0 || port > 65535" ) ; } if ( localPort < 0 || localPort > 65535 ) { throw new IllegalArgumentException ( "localPort < 0 || localPort > 65535" ) ; } if ( localAddr != null && ! ( localAddr . isAnyLocalAddress ( ) || localAddr . isLoopbackAddress ( ) ) ) { throw new IllegalArgumentException ( "localAddr is not a valid address" ) ; } this . address = address ;
} if ( opt == SO_TIMEOUT ) { return new Integer ( timeout ) ; } // Android - removed : alternative implementation /* int ret = 0 ; * The native socketGetOption ( ) knows about 3 options . * The 32 bit value it returns will be interpreted according * to what we're asking . A return of - 1 means it understands * the option but its turned off . It will raise a SocketException * if "opt" isn't one it understands . < |startfocus| > // < |endfocus| > switch ( opt ) { case TCP_NODELAY : ret = socketGetOption ( opt , null ) ; return Boolean . valueOf ( ret != - 1 ) ; case SO_OOBINLINE : ret = socketGetOption ( opt , null ) ; return Boolean . valueOf ( ret != - 1 ) ; case SO_LINGER : ret = socketGetOption ( opt , null ) ; return ( ret == - 1 ) ? Boolean . FALSE : ( Object ) ( new Integer ( ret ) ) ; case SO_REUSEADDR : ret = socketGetOption ( opt , null ) ; return Boolean . valueOf ( ret != - 1 ) ; case SO_BINDADDR : InetAddressContainer in = new InetAddressContainer ( ) ;
} abstract void socketCreate ( boolean isServer ) throws IOException ; abstract void socketConnect ( InetAddress address , int port , int timeout ) throws IOException ; abstract void socketBind ( InetAddress address , int port ) throws IOException ; abstract void socketListen ( int count ) throws IOException ; abstract void socketAccept ( SocketImpl s ) throws IOException ; abstract int socketAvailable ( ) throws IOException ; abstract void socketClose0 ( boolean useDeferredClose ) throws IOException ; abstract void socketShutdown ( int howto ) throws IOException ; < |startfocus| > // Android - changed : socket { Get , Set } Option work directly with Object values < |endfocus| > abstract void socketSetOption ( int cmd , Object value ) throws SocketException ; abstract Object socketGetOption ( int opt ) throws SocketException ; abstract void socketSendUrgentData ( int data ) throws IOException ; public final static int SHUT_RD = 0 ; public final static int SHUT_WR = 1 ; }
public static void main ( String [ ] args ) { < |startfocus| > System . out . println ( "" + test ( ) ) ; < |endfocus| >
* @see #checkAccess ( ) * @see #getThreadGroup ( ) * @see #MAX_PRIORITY * @see #MIN_PRIORITY * @see ThreadGroup#getMaxPriority ( ) */ public final void setPriority ( int newPriority ) { ThreadGroup g ; checkAccess ( ) ; if ( newPriority > MAX_PRIORITY || newPriority < MIN_PRIORITY ) { // Android - changed : Improve exception message when the new priority // is out of bounds . < |startfocus| > throw new IllegalArgumentException ( "Priority out of range : " + newPriority ) ; < |endfocus| > } if ( ( g = getThreadGroup ( ) ) != null ) { if ( newPriority > g . getMaxPriority ( ) ) { newPriority = g . getMaxPriority ( ) ; } synchronized ( this ) { this . priority = newPriority ; if ( isAlive ( ) ) { nativeSetPriority ( newPriority ) ; } } } } /* * * Returns this thread's priority . * * @return this thread's priority . * @see #setPriority */ public final int getPriority ( ) { return priority ; } /* *
private static void DisableReporting ( ) { < |startfocus| > if ( doDisableReporting == null ) { < |endfocus| > return ; } try { doDisableReporting . invoke ( null ) ; } catch ( Exception e ) { throw new Error ( "Unable to disable reporting ! " ) ; }
private static void ensureTestWatcherInitialized ( ) { try { // Make sure the TestWatcher class can be found from the Object < init > function . addToBootClassLoader ( LISTENER_LOCATION ) ; // Load TestWatcher from the bootclassloader and make sure it is initialized . Class < ? > testwatcher_class = Class . forName ( "art . test . TestWatcher" , true , null ) ; < |startfocus| > // Bind the native functions of testwatcher_class . DoEnableReporting = testwatcher_class . getDeclaredMethod ( "EnableReporting" ) ; DoDisableReporting = testwatcher_class . getDeclaredMethod ( "DisableReporting" ) ; < |endfocus| > } catch ( Exception e ) { throw new Error ( "Exception while making testwatcher" , e ) ; } }
// / CHECK - DAG : VecMul loop : < < Loop > > outer_loop : none // / CHECK - DAG : VecAdd loop : < < Loop > > outer_loop : none // // / CHECK - START - ARM64 : void Main . SimdMulAdd ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( after ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMultiplyAccumulate kind : Add loop : < < Loop > > outer_loop : none < |startfocus| > public static void SimdMulAdd ( int [ ] array1 , int [ ] array2 ) { < |endfocus| > for ( int j = 0 ; j < 100 ; j ++ ) { array2 [ j ] += 12345 * array1 [ j ] ; } } // / CHECK - START - ARM64 : void Main . SimdMulSub ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( before ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMul loop : < < Loop > > outer_loop : none // / CHECK - DAG : VecSub loop : < < Loop > > outer_loop : none //
// / CHECK - DAG : VecAdd loop : < < Loop > > outer_loop : none // // / CHECK - START - ARM64 : void Main . SimdMulAdd ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( after ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMultiplyAccumulate kind : Add loop : < < Loop > > outer_loop : none public static void SimdMulAdd ( int [ ] array1 , int [ ] array2 ) { for ( int j = 0 ; j < 100 ; j ++ ) { < |startfocus| > array2 [ j ] += 12345 * array1 [ j ] ; < |endfocus| > } } // / CHECK - START - ARM64 : void Main . SimdMulSub ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( before ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMul loop : < < Loop > > outer_loop : none // / CHECK - DAG : VecSub loop : < < Loop > > outer_loop : none // // / CHECK - START - ARM64 : void Main . SimdMulSub ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( after ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMultiplyAccumulate kind : Sub loop : < < Loop > > outer_loop : none public static void SimdMulSub ( int [ ] array1 , int [ ] array2 ) { for ( int j = 0 ; j < 100 ; j ++ ) { < |startfocus| > array2 [ j ] -= 12345 * array1 [ j ] ; < |endfocus| > } }
// // / CHECK - START - ARM64 : void Main . SimdMulAdd ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( after ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMultiplyAccumulate kind : Add loop : < < Loop > > outer_loop : none public static void SimdMulAdd ( int [ ] array1 , int [ ] array2 ) { for ( int j = 0 ; j < 100 ; j ++ ) { < |startfocus| > array2 [ j ] += 12345 * array1 [ j ] ; < |endfocus| > } } // / CHECK - START - ARM64 : void Main . SimdMulSub ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( before ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMul loop : < < Loop > > outer_loop : none // / CHECK - DAG : VecSub loop : < < Loop > > outer_loop : none // // / CHECK - START - ARM64 : void Main . SimdMulSub ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( after ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none
handleRadioProxyExceptionForRR ( rr , "setSimCardPower" , e ) ; } } } @Override public void setCarrierInfoForImsiEncryption ( PublicKey publicKey , String keyIdentifier , Message result ) { IRadio radioProxy = getRadioProxy ( result ) ; if ( radioProxy != null ) { android . hardware . radio . V1_1 . IRadio radioProxy11 = android . hardware . radio . V1_1 . IRadio . castFrom ( radioProxy ) ; if ( radioProxy11 == null ) { < |startfocus| > if ( result != null ) { AsyncResult . forMessage ( result , null , CommandException . fromRilErrno ( REQUEST_NOT_SUPPORTED ) ) ; result . sendToTarget ( ) ; } < |endfocus| > } else { RILRequest rr = obtainRequest ( RIL_REQUEST_SET_CARRIER_INFO_IMSI_ENCRYPTION , result , mRILDefaultWorkSource ) ; if ( RILJ_LOGD ) riljLog ( rr . serialString ( ) + " > " + requestToString ( rr . mRequest ) ) ; try { radioProxy11 . setCarrierInfoForImsiEncryption ( rr . mSerial , publicKeyToArrayList ( publicKey ) , keyIdentifier ) ; } catch ( RemoteException | RuntimeException e ) { handleRadioProxyExceptionForRR ( rr , "setCarrierInfoForImsiEncryption" , e ) ; } } } } @Override
if ( DBG ) { log ( "reportNetworkConnectivity ( " + nai . network . netId + " , " + hasConnectivity + " ) by " + uid ) ; } synchronized ( nai ) { // Validating a network that has not yet connected could result in a call to // rematchNetworkAndRequests ( ) which is not meant to work on such networks . if ( ! nai . everConnected ) return ; if ( isNetworkWithLinkPropertiesBlocked ( nai . linkProperties , uid , false ) ) return ; nai . networkMonitor . sendMessage ( NetworkMonitor . CMD_FORCE_REEVALUATION , uid ) ; < |startfocus| > } < |endfocus| >
if ( items == null ) { Log . i ( TAG , "null queue from " + mediaController . getPackageName ( ) + " , constructing current - item list" ) ; MediaMetadata metadata = mediaController . getMetadata ( ) ; // Because we are database - unaware , we can just number the item here whatever we want // because they have to re - poll it every time . MediaSession . QueueItem current = getCurrentQueueItem ( mediaController , 1 ) ; items = new ArrayList < MediaSession . QueueItem > ( ) ; items . add ( current ) ; < |startfocus| > return items ; < |endfocus| > } mNowPlayingList = items ; return items ; } /* Constructs a queue item representing the current playing metadata from an * active controller with queue id |qid| . */ private MediaSession . QueueItem getCurrentQueueItem ( MediaController controller , long qid ) { MediaMetadata metadata = controller . getMetadata ( ) ; if ( metadata == null ) { Log . w ( TAG , "Controller has no metadata ! ? Making an empty one" ) ; metadata = ( new MediaMetadata . Builder ( ) ) . build ( ) ; } MediaDescription . Builder bob = new MediaDescription . Builder ( ) ; bob . setMediaId ( metadata . getString ( MediaMetadata . METADATA_KEY_MEDIA_ID ) ) ; bob . setTitle ( metadata . getString ( MediaMetadata . METADATA_KEY_TITLE ) ) ; bob . setSubtitle ( metadata . getString ( MediaMetadata . METADATA_KEY_ARTIST ) ) ; bob . setDescription ( metadata . getString ( MediaMetadata . METADATA_KEY_ALBUM ) ) ; bob . setIconBitmap ( metadata . getBitmap ( MediaMetadata . METADATA_KEY_ALBUM_ART ) ) ; bob . setIconUri ( metadata . getDescription ( ) . getIconUri ( ) ) ; MediaSession . QueueItem item = new MediaSession . QueueItem ( bob . build ( ) , qid ) ; return item ; }
if ( mediaController == null ) { Log . e ( TAG , "mediaController = null , sending no available players response" ) ; mMediaInterface . getItemAttrRsp ( bdaddr , AvrcpConstants . RSP_NO_AVBL_PLAY , null ) ; return ; } // We don't have the cached list , fetch it from Media Controller items = mediaController . getQueue ( ) ; if ( items == null ) { < |startfocus| > // We're presenting a queue with only 1 item ( the current one ) mMediaInterface . getTotalNumOfItemsRsp ( bdaddr , AvrcpConstants . RSP_NO_ERROR , 0 , 0 ) ; < |endfocus| > } // Cache the response for later mNowPlayingList = items ; mMediaInterface . getTotalNumOfItemsRsp ( bdaddr , AvrcpConstants . RSP_NO_ERROR , 0 , items . size ( ) ) ;
if ( ( length == 10 || length == 26 || length == 58 ) && password . matches ( " [ 0 - 9A - Fa - f ] * " ) ) { wifiConfiguration . wepKeys [ 0 ] = password ; } else if ( length == 5 || length == 13 || length == 16 ) { wifiConfiguration . wepKeys [ 0 ] = '"' + password + '"' ; } } else { < |startfocus| > if ( wifiSecurity == WifiSecurity . PSK && password . length ( ) < FormPageDisplayer . PSK_MIN_LENGTH ) { < |endfocus| > return ; } if ( password . matches ( " [ 0 - 9A - Fa - f ] { 64 } " ) ) { wifiConfiguration . preSharedKey = password ; } else { wifiConfiguration . preSharedKey = '"' + password + '"' ; } }
private void getNumSlots ( APDU apdu ) { p1p2Unused ( apdu ) ; // dataUnused ( apdu ) ; // TODO ( ascull ) : how to handle the cases of APDU properly ? prepareToSend ( apdu , ( short ) 4 ) ; final byte buffer [ ] = apdu . getBuffer ( ) ; < |startfocus| > Util . setShort ( buffer , ( short ) 0 , ( short ) 0 ) ; < |endfocus| > Util . setShort ( buffer , ( short ) 2 , mSlots . getNumSlots ( ) ) ; apdu . sendBytes ( ( short ) 0 , ( byte ) 4 ) ;
@Override public void onPullExternalCall ( ) { if ( ( getConnectionProperties ( ) & Connection . PROPERTY_IS_EXTERNAL_CALL ) != Connection . PROPERTY_IS_EXTERNAL_CALL ) { Log . w ( this , "onPullExternalCall - cannot pull non - external call" ) ; return ; } if ( mOriginalConnection != null ) { mOriginalConnection . pullExternalCall ( ) ; } } @Override public void onStartRtt ( RttTextStream textStream ) { if ( isImsConnection ( ) ) { < |startfocus| > ( ( ImsPhoneConnection ) mOriginalConnection ) . getImsCall ( ) . startRtt ( textStream ) ; < |endfocus| > } else { Log . w ( this , "onStartRtt - not in IMS , so RTT cannot be enabled . " ) ; } } @Override public void onStopRtt ( ) { // This is not supported by carriers / vendor yet . No - op for now . } @Override public void handleRttUpgradeResponse ( RttTextStream textStream ) { if ( ! isImsConnection ( ) ) { Log . w ( this , "handleRttUpgradeResponse - not in IMS , so RTT cannot be enabled . " ) ; return ; } ImsPhone imsPhone = ( ImsPhone ) getPhone ( ) ;
private Attribute sourceDebugExtension ( DirectClassFile cf , int offset , int length , ParseObserver observer ) { ByteArray bytes = cf . getBytes ( ) . slice ( offset , offset + length ) ; CstString smapString = new CstString ( bytes ) ; Attribute result = new AttSourceDebugExtension ( smapString ) ; if ( observer != null ) { String decoded = smapString . getString ( ) ; observer . parsed ( bytes , offset , length , "sourceDebugExtension : " + decoded ) ; } < |startfocus| > return result ; < |endfocus| >
import com . android . dx . rop . cst . CstMethodRef ; import com . android . dx . rop . cst . CstNat ; import com . android . dx . rop . cst . CstType ; import com . android . dx . rop . type . StdTypeList ; import com . android . dx . rop . type . Type ; import com . android . dx . rop . type . TypeList ; import com . android . dx . util . Warning ; import java . util . ArrayList ; /* * * Utility methods that translate various classfile attributes * into forms suitable for use in creating { @code dex } files . */ /* package */ class AttributeTranslator { < |startfocus| > < |endfocus| > /* * * This class is uninstantiable . */ private AttributeTranslator ( ) { // This space intentionally left blank . } /* * * Gets the list of thrown exceptions for a given method . * * @param method { @code non - null ; } the method in question * @return { @code non - null ; } the list of thrown exceptions */ public static TypeList getExceptions ( Method method ) { AttributeList attribs = method . getAttributes ( ) ; AttExceptions exceptions = ( AttExceptions ) attribs . findFirst ( AttExceptions . ATTRIBUTE_NAME ) ; if ( exceptions == null ) {
public static long $opt$noinline$mulNeg ( long left , long right ) { if ( doThrow ) throw new Error ( ) ; return - ( left * right ) ; } // / CHECK - START - ARM64 : void Main . SimdMulAdd ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( before ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMul loop : < < Loop > > outer_loop : none // / CHECK - DAG : VecAdd loop : < < Loop > > outer_loop : none < |startfocus| > // < |endfocus| > // / CHECK - START - ARM64 : void Main . SimdMulAdd ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( after ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMultiplyAccumulate kind : Add loop : < < Loop > > outer_loop : none public static void SimdMulAdd ( int [ ] array1 , int [ ] array2 ) { for ( int j = 0 ; j < 100 ; j ++ ) { array2 [ j ] += 12345 * array1 [ j ] ; } }
private static void throttle ( byte [ ] bArray , short bOff , short failureCount ) { short highWord = 0 ; short lowWord = 0 ; < |startfocus| > final short thirtySecondsInMilliseconds = 0x7530 ; // = 1000 * 30 < |endfocus| > if ( failureCount == 0 ) { // 0s } else if ( failureCount > 0 && failureCount <= 10 ) { if ( failureCount % 5 == 0 ) { // 30s lowWord = thirtySecondsInMilliseconds ; } else { // 0s } } else if ( failureCount < 30 ) { // 30s lowWord = thirtySecondsInMilliseconds ; } else if ( failureCount < 140 ) { // 30 * ( 2 ^ ( ( x - 30 ) / 10 ) ) final short shift = ( short ) ( ( short ) ( failureCount - 30 ) / 10 ) ; highWord = ( short ) ( thirtySecondsInMilliseconds > > ( 16 - shift ) ) ; lowWord = ( short ) ( thirtySecondsInMilliseconds < < shift ) ; } else { // 1 day in ms = 1000 * 60 * 60 * 24 = 0x526 5C00 highWord = 0x0526 ;
IpSecTransform . DIRECTION_IN , new IpSecAlgorithm ( IpSecAlgorithm . CRYPT_AES_CBC , CRYPT_KEY ) ) . setAuthentication ( IpSecTransform . DIRECTION_IN , new IpSecAlgorithm ( IpSecAlgorithm . AUTH_HMAC_SHA256 , AUTH_KEY , CRYPT_KEY . length * 8 ) ) . buildTransportModeTransform ( local ) ; // Hack to ensure the socket doesn't block indefinitely on failure DatagramSocket localSocket = new DatagramSocket ( 8888 ) ; localSocket . setSoTimeout ( 500 ) ; < |startfocus| > ParcelFileDescriptor pfd = ParcelFileDescriptor . fromDatagramSocket ( localSocket ) ; FileDescriptor udpSocket = pfd . getFileDescriptor ( ) ; < |endfocus| > mISM . applyTransportModeTransform ( udpSocket , transform ) ; byte [ ] data = new String ( "Best test data ever ! " ) . getBytes ( "UTF - 8" ) ; byte [ ] in = new byte [ data . length ] ; Os . sendto ( udpSocket , data , 0 , data . length , 0 , local , 8888 ) ; Os . read ( udpSocket , in , 0 , in . length ) ; assertTrue ( "Encapsulated data did not match . " , Arrays . equals ( data , in ) ) ; mISM . removeTransportModeTransform ( udpSocket , transform ) ; Os . close ( udpSocket ) ; transform . close ( ) ; } }
if ( mEnableTerminal != null ) { updateSwitchPreference ( mEnableTerminal , context . getPackageManager ( ) . getApplicationEnabledSetting ( TERMINAL_APP_PACKAGE ) == PackageManager . COMPONENT_ENABLED_STATE_ENABLED ) ; } updateSwitchPreference ( mBugreportInPower , Settings . Secure . getInt ( cr , Settings . Global . BUGREPORT_IN_POWER_MENU , 0 ) != 0 ) ; updateSwitchPreference ( mKeepScreenOn , Settings . Global . getInt ( cr , Settings . Global . STAY_ON_WHILE_PLUGGED_IN , 0 ) != 0 ) ; < |startfocus| > updateSwitchPreference ( mBtHciSnoopLog , SystemProperties . getBoolean ( BLUETOOTH_BTSNOOP_ENABLE_PROPERTY , false ) ) ; < |endfocus| > updateSwitchPreference ( mDebugViewAttributes , Settings . Global . getInt ( cr , Settings . Global . DEBUG_VIEW_ATTRIBUTES , 0 ) != 0 ) ; updateSwitchPreference ( mForceAllowOnExternal , Settings . Global . getInt ( cr , Settings . Global . FORCE_ALLOW_ON_EXTERNAL , 0 ) != 0 ) ; updateHdcpValues ( ) ; updatePasswordSummary ( ) ; updateDebuggerOptions ( ) ; updateMockLocation ( ) ; updateStrictModeVisualOptions ( ) ; updatePointerLocationOptions ( ) ; updateShowTouchesOptions ( ) ; updateFlingerOptions ( ) ; updateHardwareUiOptions ( ) ; updateMsaaOptions ( ) ; updateTrackFrameTimeOptions ( ) ; updateShowNonRectClipOptions ( ) ; updateShowHwScreenUpdatesOptions ( ) ; updateShowHwLayersUpdatesOptions ( ) ; updateDebugHwOverdrawOptions ( ) ;
// Check that this is a valid device address ( i . e . not broadcast ) . if ( ( val [ 0 ] & 0x01 ) != 0 ) { // Invalid since this is a broadcast address . errorLog ( "Invalid device address = " + Utils . getAddressStringFromByte ( val ) + " . Ignore this address . " ) ; break ; } mAddress = val ; < |startfocus| > debugLog ( "Address is : " + Utils . getAddressStringFromByte ( mAddress ) ) ; intent = new Intent ( BluetoothAdapter . ACTION_BT_BD_ADDR_CHANGED ) ; intent . putExtra ( BluetoothAdapter . EXTRA_BT_BD_ADDR , Utils . getAddressStringFromByte ( mAddress ) ) ; < |endfocus| > intent . addFlags ( Intent . FLAG_RECEIVER_REGISTERED_ONLY_BEFORE_BOOT ) ; mService . sendBroadcastAsUser ( intent , UserHandle . ALL , mService . BLUETOOTH_PERM ) ; break ; case AbstractionLayer . BT_PROPERTY_CLASS_OF_DEVICE : mBluetoothClass = Utils . byteArrayToInt ( val , 0 ) ; debugLog ( "BT Class : " + mBluetoothClass ) ; break ; case AbstractionLayer . BT_PROPERTY_ADAPTER_SCAN_MODE : int mode = Utils . byteArrayToInt ( val , 0 ) ;
* This extra represents the previous connection state . */ public static final String EXTRA_PREVIOUS_CONNECTION_STATE = "android . bluetooth . adapter . extra . PREVIOUS_CONNECTION_STATE" ; /* * * Broadcast Action : The Bluetooth adapter state has changed in LE only mode . * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android . bluetooth . adapter . action . BLE_STATE_CHANGED" ; /* * * Broadcast Action : The notifys Bluetooth BD ( mac ) address * updated event . * * @hide */ < |startfocus| > public static final String ACTION_BT_BD_ADDR_CHANGED = "android . bluetooth . adapter . action . BT_BD_ADDR_CHANGED" ; < |endfocus| > /* * * Extra used by { @link #ACTION_BT_BD_ADDR_CHANGED } * * This extra represents the BD Address . * * @hide */ public static final String EXTRA_BT_BD_ADDR = "android . bluetooth . adapter . extra . BT_BD_ADDR" ; /* * * Broadcast Action : The notifys Bluetooth ACL connected event . This will be
/* * * Broadcast Action : The Bluetooth adapter state has changed in LE only mode . * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android . bluetooth . adapter . action . BLE_STATE_CHANGED" ; /* * * Broadcast Action : The notifys Bluetooth BD ( mac ) address * updated event . * * @hide */ < |startfocus| > public static final String ACTION_BT_BD_ADDR_CHANGED = "android . bluetooth . adapter . action . BT_BD_ADDR_CHANGED" ; < |endfocus| > /* * * Extra used by { @link #ACTION_BT_BD_ADDR_CHANGED } * * This extra represents the BD Address . * * @hide */ public static final String EXTRA_BT_BD_ADDR = "android . bluetooth . adapter . extra . BT_BD_ADDR" ; /* * * Broadcast Action : The notifys Bluetooth ACL connected event . This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT connection
*/ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android . bluetooth . adapter . action . BLE_STATE_CHANGED" ; /* * * Broadcast Action : The notifys Bluetooth BD ( mac ) address * updated event . * * @hide */ public static final String ACTION_BT_BD_ADDR_CHANGED = "android . bluetooth . adapter . action . BT_BD_ADDR_CHANGED" ; /* * * Extra used by { @link #ACTION_BT_BD_ADDR_CHANGED } * * This extra represents the BD Address . * * @hide */ < |startfocus| > public static final String EXTRA_BT_BD_ADDR = "android . bluetooth . adapter . extra . BT_BD_ADDR" ; < |endfocus| > /* * * Broadcast Action : The notifys Bluetooth ACL connected event . This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT connection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of { @link BluetoothDevice#ACTION_ACL_CONNECTED } which * is not available in STATE_BLE_ON . * * @hide */ public static final String ACTION_BLE_ACL_CONNECTED = "android . bluetooth . adapter . action . BLE_ACL_CONNECTED" ; /* * * Broadcast Action : The notifys Bluetooth ACL disconnected event . This will be * by BLE Always on enabled application to know the ACL_DISCONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT disconnection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of { @link BluetoothDevice#ACTION_ACL_DISCONNECTED } which * is not available in STATE_BLE_ON . * * @hide */ public static final String ACTION_BLE_ACL_DISCONNECTED = "android . bluetooth . adapter . action . BLE_ACL_DISCONNECTED" ; /* * * Broadcast Action : The notifys Bluetooth ACL disconnected event . This will be * by BLE Always on enabled application to know the ACL_DISCONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT disconnection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of { @link BluetoothDevice#ACTION_ACL_DISCONNECTED } which * is not available in STATE_BLE_ON . * * @hide */ public static final String ACTION_BLE_ACL_DISCONNECTED = "android . bluetooth . adapter . action . BLE_ACL_DISCONNECTED" ; /* * * Broadcast Action : The notifys Bluetooth ACL disconnected event . This will be * by BLE Always on enabled application to know the ACL_DISCONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT disconnection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of { @link BluetoothDevice#ACTION_ACL_DISCONNECTED } which * is not available in STATE_BLE_ON . * * @hide */ public static final String ACTION_BLE_ACL_DISCONNECTED = "android . bluetooth . adapter . action . BLE_ACL_DISCONNECTED" ; /* * * Broadcast Action : The notifys Bluetooth ACL disconnected event . This will be * by BLE Always on enabled application to know the ACL_DISCONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT disconnection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of { @link BluetoothDevice#ACTION_ACL_DISCONNECTED } which * is not available in STATE_BLE_ON . * * @hide */ public static final String ACTION_BLE_ACL_DISCONNECTED = "android . bluetooth . adapter . action . BLE_ACL_DISCONNECTED" ; /* * * Broadcast Action : The notifys Bluetooth ACL disconnected event . This will be * by BLE Always on enabled application to know the ACL_DISCONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT disconnection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of { @link BluetoothDevice#ACTION_ACL_DISCONNECTED } which * is not available in STATE_BLE_ON . * * @hide */ public static final String ACTION_BLE_ACL_DISCONNECTED = "android . bluetooth . adapter . action . BLE_ACL_DISCONNECTED" ; /* * * Broadcast Action : The notifys Bluetooth ACL disconnected event . This will be * by BLE Always on enabled application to know the ACL_DISCONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT disconnection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of { @link BluetoothDevice#ACTION_ACL_DISCONNECTED } which * is not available in STATE_BLE_ON . * * @hide */ public static final String ACTION_BLE_ACL_DISCONNECTED = "android . bluetooth . adapter . action . BLE_ACL_DISCONNECTED" ; /* * * Broadcast Action : The notifys Bluetooth ACL disconnected event . This will be * by BLE Always on enabled application to know the ACL_DISCONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT disconnection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of { @link BluetoothDevice#ACTION_ACL_DISCONNECTED } which * is not available in STATE_BLE_ON . * * @hide */ public static final String ACTION_BLE_ACL_DISCONNECTED = "android . bluetooth . adapter . action . BLE_ACL_DISCONNECTED" ; /* * * Broadcast Action : The notifys Bluetooth ACL disconnected event . This will be * by BLE Always on enabled application to know the ACL_DISCONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT disconnection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of { @link BluetoothDevice#ACTION_ACL_DISCONNECTED } which * is not available in STATE_BLE_ON . * * @hide */ public static final String ACTION_BLE_ACL_DISCONNECTED = "android . bluetooth . adapter . action . BLE_ACL_DISCONNECTED" ; /* * * Broadcast Action : The notifys Bluetooth ACL disconnected event . This will be * by BLE Always on enabled application to know the ACL_DISCONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT disconnection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of { @link BluetoothDevice#ACTION_ACL_DISCONNECTED } which * is not available in STATE_BLE_ON . * * @hide */ public static final String ACTION_BLE_ACL_DISCONNECTED = "android . bluetooth . adapter . action . BLE_ACL_DISCONNECTED" ; /* * * Broadcast Action : The notifys Bluetooth ACL disconnected event . This will be * by BLE Always on enabled application to know the ACL_DISCONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT disconnection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of { @link BluetoothDevice#ACTION_ACL_DISCONNECTED } which * is not available in STATE_BLE_ON . * * @hide */ public static final String ACTION_BLE_ACL_DISCONNECTED = "android . bluetooth . adapter . action . BLE_ACL_DISCONNECTED" ; /* * * Broadcast Action
/* * * Broadcast Action : The notifys Bluetooth BD ( mac ) address * updated event . * * @hide */ public static final String ACTION_BT_BD_ADDR_CHANGED = "android . bluetooth . adapter . action . BT_BD_ADDR_CHANGED" ; /* * * Extra used by { @link #ACTION_BT_BD_ADDR_CHANGED } * * This extra represents the BD Address . * * @hide */ < |startfocus| > public static final String EXTRA_BT_ADDR = "android . bluetooth . adapter . extra . BT_ADDR" ; < |endfocus| > /* * * Broadcast Action : The notifys Bluetooth ACL connected event . This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON . This denotes GATT connection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of { @link BluetoothDevice#ACTION_ACL_CONNECTED } which * works in Bluetooth state STATE_ON * @hide */ public static final String ACTION_BLE_ACL_CONNECTED =
String newName = intent . getStringExtra ( BluetoothAdapter . EXTRA_LOCAL_NAME ) ; if ( DBG ) Slog . d ( TAG , "Bluetooth Adapter name changed to " + newName ) ; if ( newName != null ) { storeNameAndAddress ( newName , null ) ; } } else if ( BluetoothAdapter . ACTION_BT_BD_ADDR_CHANGED . equals ( action ) ) { String newAddress = intent . getStringExtra ( BluetoothAdapter . EXTRA_BT_BD_ADDR ) ; if ( newAddress != null ) { < |startfocus| > if ( DBG ) Slog . d ( TAG , "Bluetooth Adapter BD Address changed to " + newAddress ) ; < |endfocus| > storeNameAndAddress ( null , newAddress ) ; } else { if ( DBG ) Slog . e ( TAG , "No Bluetooth Adapter BD Address parameter found" ) ; } }
if ( newName != null ) { storeNameAndAddress ( newName , null ) ; } } else if ( BluetoothAdapter . ACTION_BT_BD_ADDR_CHANGED . equals ( action ) ) { String newAddress = intent . getStringExtra ( BluetoothAdapter . EXTRA_BT_BD_ADDR ) ; if ( newAddress != null ) { if ( DBG ) Slog . d ( TAG , "Bluetooth Adapter BD Address changed to " + newAddress ) ; storeNameAndAddress ( null , newAddress ) ; } else { < |startfocus| > if ( DBG ) Slog . e ( TAG , "No Bluetooth Adapter BD Address parameter found" ) ; < |endfocus| > } } < |startfocus| >
public void testAospServiceContexts ( ) throws Exception { /* obtain service_contexts file from running device */ deviceSvcFile = File . createTempFile ( "service_contexts" , " . tmp" ) ; deviceSvcFile . deleteOnExit ( ) ; mDevice . pullFile ( " / service_contexts" , deviceSvcFile ) ; /* retrieve the AOSP service_contexts file from jar */ aospSvcFile = copyResourceToTempFile ( " / general_service_contexts" ) ; < |startfocus| > /* retrieve NMR1 AOSP service_contexts file from jar */ if ( ! isFileStartsWith ( aospSvcFile , deviceSvcFile ) ) { < |endfocus| > aospSvcFile = copyResourceToTempFile ( " / ab3857191_service_contexts" ) ; assertFileStartsWith ( aospSvcFile , deviceSvcFile ) ; } } /* * * Tests that the file_contexts . bin file on the device is valid . * * @throws Exception */ @CddTest ( requirement = "9 . 7" ) public void testValidFileContexts ( ) throws Exception { /* retrieve the checkfc executable from jar */ checkFc = copyResourceToTempFile ( " / checkfc" ) ; checkFc . setExecutable ( true ) ; /* obtain file_contexts . bin file from running device */
* Copyright ( C ) 2016 The Android Open Source Project * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package art ; import java . util . Base64 ; public class Test985 { static class Transform { private void Start ( ) { System . out . println ( "hello - private" ) ; } private void Finish ( ) { System . out . println ( "goodbye - private" ) ; } public void sayHi ( Runnable r ) { System . out . println ( "Pre Start private method call" ) ; Start ( ) ;
byte result = Consts . READ_WRONG_KEY ; if ( Util . arrayCompare ( keyBuffer , keyOffset , mKey , ( short ) 0 , Consts . SLOT_KEY_BYTES ) == 0 ) { return Consts . READ_SUCCESS ; } JCSystem . beginTransaction ( ) ; if ( result == Consts . READ_WRONG_KEY ) { if ( mFailureCount != 0x7fff ) { mFailureCount += 1 ; } if ( throttle ( sRemainingBackoff , ( short ) 0 , mFailureCount ) ) { // mBackoffTimer . startTimer ( // sRemainingBackoff , ( short ) 0 , DSTimer . DST_POWEROFFMODE_FALLBACK ) ; } Util . arrayCopyNonAtomic ( sRemainingBackoff , ( short ) 0 , outBuffer , outOffset , ( byte ) 4 ) ; < |startfocus| > } else { // This attempt was successful so reset the failures mFailureCount = 0 ; // mBackoffTimer . stopTimer ( ) ; Util . arrayCopyNonAtomic ( mValue , ( short ) 0 , outBuffer , outOffset , Consts . SLOT_VALUE_BYTES ) ; < |endfocus| > } JCSystem . commitTransaction ( ) ; return result ;
// / CHECK - NOT : InstanceFieldSet // / CHECK - NOT : ConstructorFence // / CHECK - NOT : InstanceFieldGet // Make sure the constructor fence gets eliminated when the allocation is eliminated . static double calcCircleArea ( double radius ) { return new Circle ( radius ) . getArea ( ) ; } // / CHECK - START : double Main . calcEllipseArea ( double , double ) load_store_elimination ( before ) // / CHECK : NewInstance // / CHECK : InstanceFieldSet < |startfocus| > /* // TODO : The super constructor fence should not be eliminated already . // CHECK : ConstructorFence */ < |endfocus| > // / CHECK : InstanceFieldSet // / CHECK : ConstructorFence // / CHECK : InstanceFieldGet // / CHECK : InstanceFieldGet // / CHECK - START : double Main . calcEllipseArea ( double , double ) load_store_elimination ( after ) // / CHECK - NOT : NewInstance // / CHECK - NOT : InstanceFieldSet // / CHECK - NOT : ConstructorFence // / CHECK - NOT : InstanceFieldGet // Multiple constructor fences can accumulate through inheritance , make sure // they are all eliminated when the allocation is eliminated . static double calcEllipseArea ( double vertex , double covertex ) { return new Ellipse ( vertex , covertex ) . getArea ( ) ; }
static double calcEllipseArea ( double vertex , double covertex ) { return new Ellipse ( vertex , covertex ) . getArea ( ) ; } // / CHECK - START : double Main . calcCircleAreaOrCircumference ( double , boolean ) load_store_elimination ( before ) // / CHECK : NewInstance // / CHECK : InstanceFieldSet // / CHECK : ConstructorFence // / CHECK : InstanceFieldGet // / CHECK - START : double Main . calcCircleAreaOrCircumference ( double , boolean ) load_store_elimination ( after ) // / CHECK : NewInstance // / CHECK - NOT : ConstructorFence < |startfocus| > static double someResult ; < |endfocus| > // // The object allocation will not be eliminated by LSE because of aliased stores . // However the object is still a singleton , so it never escapes the current thread . // There should not be a constructor fence here after LSE . static double calcCircleAreaOrCircumference ( double radius , boolean area_or_circumference ) { CalcCircleAreaOrCircumference calc = new CalcCircleAreaOrCircumference ( area_or_circumference ? CalcCircleAreaOrCircumference . TYPE_AREA : CalcCircleAreaOrCircumference . TYPE_CIRCUMFERENCE ) ; if ( area_or_circumference ) { // Area .
// / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMul loop : < < Loop > > outer_loop : none // / CHECK - DAG : VecAdd loop : < < Loop > > outer_loop : none // // / CHECK - START - ARM64 : void Main . SimdMulAdd ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( after ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - NOT : VecMul // / CHECK - NOT : VecAdd < |startfocus| > // / CHECK - DAG : VecMultiplyAccumulate kind : Add loop : < < Loop > > outer_loop : none < |endfocus| > public static void SimdMulAdd ( int [ ] array1 , int [ ] array2 ) { for ( int j = 0 ; j < 100 ; j ++ ) { array2 [ j ] += 12345 * array1 [ j ] ; } } // / CHECK - START - ARM64 : void Main . SimdMulSub ( int [ ] , int [ ] ) instruction_simplifier_arm64 ( before ) // / CHECK - DAG : Phi loop : < < Loop : B\d + > > outer_loop : none // / CHECK - DAG : VecMul loop : < < Loop > > outer_loop : none
* Copyright ( C ) 2015 The Android Open Source Project * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; you may not use this file except * in compliance with the License . You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software distributed under the License * is distributed on an "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express * or implied . See the License for the specific language governing permissions and limitations under * the License . */ package com . android . rs . test ; import android . content . Context ; import android . renderscript . Allocation ; import android . renderscript . Element ; import android . renderscript . RenderScript ; import android . renderscript . RSIllegalArgumentException ; import android . renderscript . ScriptIntrinsicBlur ; import android . renderscript . Type ; import android . util . Log ; public class UT_blur_validation extends UnitTest { private static final int ARRAY_SIZE = 256 ; private static final String TAG = "ScriptIntrinsicBlur validation" ;
output2D . destroy ( ) ; scriptBlur . destroy ( ) ; pRS . destroy ( ) ; passTest ( ) ; return ; } Log . e ( TAG , "setting 1d output does not trigger exception" ) ; pRS . finish ( ) ; input1D . destroy ( ) ; input2D . destroy ( ) ; output1D . destroy ( ) ; output2D . destroy ( ) ; scriptBlur . destroy ( ) ; pRS . destroy ( ) ; failTest ( ) ; return ; } Log . e ( TAG , "setting 1d input does not trigger exception" ) ; < |startfocus| > pRS . finish ( ) ; input1D . destroy ( ) ; input2D . destroy ( ) ; output1D . destroy ( ) ; output2D . destroy ( ) ; scriptBlur . destroy ( ) ; pRS . destroy ( ) ; < |endfocus| > failTest ( ) ;
/* Copyright ( C ) 2016 The Android Open Source Project ** ** This software is licensed under the terms of the GNU General Public ** License version 2 , as published by the Free Software Foundation , and ** may be copied , distributed , and modified under those terms . ** ** This program is distributed in the hope that it will be useful , ** but WITHOUT ANY WARRANTY ; without even the implied warranty of ** MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE . See the ** GNU General Public License for more details . */ #include "android / skin / qt / extended - pages / car - data - emulation - page . h" #include "android / car - data - emulation / car - data - emulation . h" #include "android / car - data - emulation / car - data - emulation - agent . h" #include "android / car - data - emulation / car - data - emulation - service . h" #include "android / car - data - emulation / car - data - emulation - setup . h" #include "android / car - data - emulation / car - data - emulation - setup - service . h" #include "android / car - data - emulation / car - data - emulation - setup - ui . h" #include "android / car - data - emulation / car - data - emulation - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - agent . h" #include "android / car - data - emulation / car - data - emulation - ui - service . h" #include "android / car - data - emulation / car - data - emulation - ui - setup . h" #include "android / car - data - emulation / car - data - emulation - ui - setup - service . h" #include "android / car - data - emulation / car - data - emulation - ui - setup - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - agent . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - service . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - setup . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - setup - service . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - setup - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - agent . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - service . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - setup . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - setup - service . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - setup - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - agent . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - service . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - setup . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - setup - service . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - setup - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - agent . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - service . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - setup . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - setup - service . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - setup - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - ui - agent . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - ui - service . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - ui - setup . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - ui - setup - service . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - ui - setup - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - ui - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - ui - ui - agent . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - ui - ui - service . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - ui - ui - setup . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - ui - ui - setup - service . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - ui - ui - setup - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - ui - ui - ui . h" #include "android / car - data - emulation / car - data - emulation - ui - ui - ui - ui - ui - ui - ui - ui - agent . h" #include "android / car - data - em
ProcessBuilder pb1 = new ProcessBuilder ( checkFc . getAbsolutePath ( ) , " - c" , aospFcFile . getAbsolutePath ( ) , deviceFcFile . getAbsolutePath ( ) ) ; pb1 . redirectOutput ( ProcessBuilder . Redirect . PIPE ) ; pb1 . redirectErrorStream ( true ) ; Process p1 = pb1 . start ( ) ; p1 . waitFor ( ) ; BufferedReader result1 = new BufferedReader ( new InputStreamReader ( p1 . getInputStream ( ) ) ) ; String line1 = result1 . readLine ( ) ; assertTrue ( "The file_contexts . bin file did not include the AOSP entries : \n" < |startfocus| > + line1 + "\n" , line1 . equals ( "equal" ) || line1 . equals ( "subset" ) ) ; < |endfocus| > } } /* * * Tests that the property_contexts file on the device contains * the standard AOSP entries . * * @throws Exception */ @CddTest ( requirement = "9 . 7" ) public void testAospPropertyContexts ( ) throws Exception { /* obtain property_contexts file from running device */ devicePcFile = File . createTempFile ( "property_contexts" , " . tmp" ) ; devicePcFile . deleteOnExit ( ) ; ProcessBuilder pb2 = new ProcessBuilder ( checkPc . getAbsolutePath ( ) , " - c" , aospPcFile . getAbsolutePath ( ) , devicePcFile . getAbsolutePath ( ) ) ; pb2 . redirectOutput ( ProcessBuilder . Redirect . PIPE ) ; pb2 . redirectErrorStream ( true ) ; Process p2 = pb2 . start ( ) ; p2 . waitFor ( ) ; BufferedReader result2 = new BufferedReader ( new InputStreamReader ( p2 . getInputStream ( ) ) ) ; String line2 = result2 . readLine ( ) ; assertTrue ( "The property_contexts file did not include the AOSP entries : \n" + line2 + "\n" , line2 . equals ( "equal" ) || line2 . equals ( "subset" ) ) ; } }
BufferedWriter writer = new BufferedWriter ( new FileWriter ( sourceList . getAbsolutePath ( ) ) ) ; for ( String f : files ) { writer . write ( f ) ; writer . write ( '\n' ) ; } writer . close ( ) ; commandLine . add ( '@' + sourceList . getAbsolutePath ( ) ) ; } @Override @Nonnull public AndroidToolchain setAndroidMinApiLevel ( @Nonnull String minApiLevel ) throws Exception { this . minApiLevel = minApiLevel ; return this ; } < |startfocus| > protected abstract boolean isDesugarEnabled ( ) ; < |endfocus| > }
public void run ( ) { RenderScript pRS = RenderScript . create ( mCtx ) ; final int width = 100 ; final int height = 100 ; < |startfocus| > input1D = Allocation . createSized ( pRS , Element . U8 ( pRS ) , width * height , Allocation . USAGE_SCRIPT ) ; < |endfocus| > final Allocation output1D = Allocation . createTyped ( pRS , input1D . getType ( ) ) ; Type . Builder typeBuilder = new Type . Builder ( pRS , Element . U8 ( pRS ) ) ; typeBuilder . setX ( width ) ; typeBuilder . setY ( height ) ; Type ty = typeBuilder . create ( ) ; final Allocation input2D = Allocation . createTyped ( pRS , ty ) ; final Allocation output2D = Allocation . createTyped ( pRS , ty ) ; ScriptIntrinsicBlur scriptBlur = ScriptIntrinsicBlur . create ( pRS , Element . U8 ( pRS ) ) ; scriptBlur . setRadius ( 25f ) ; boolean failed = false ; try { scriptBlur . setInput ( input1D ) ; } catch ( RSIllegalArgumentException e ) { scriptBlur . setInput ( input2D ) ; try { scriptBlur . forEach ( output1D ) ; } catch ( RSIllegalArgumentException e1 ) { scriptBlur . forEach ( output2D ) ;
* the License . */ package com . android . rs . test_compat ; import android . content . Context ; import android . content . res . Resources ; import android . support . v8 . renderscript . Allocation ; import android . support . v8 . renderscript . Element ; import android . support . v8 . renderscript . RenderScript ; import android . support . v8 . renderscript . RSIllegalArgumentException ; import android . support . v8 . renderscript . ScriptIntrinsicBlur ; import android . support . v8 . renderscript . Type ; import android . util . Log ; public class UT_blur_validation extends UnitTest { < |startfocus| > private static final int ARRAY_SIZE = 256 ; < |endfocus| > private static final String TAG = "ScriptIntrinsicBlur validation" ; protected UT_blur_validation ( RSTestCore rstc , Resources res , Context ctx ) { super ( rstc , TAG , ctx ) ; } public void run ( ) { RenderScript pRS = RenderScript . create ( mCtx ) ; final int width = 100 ; final int height = 100 ; Allocation input1D = Allocation . createSized ( pRS , Element . U8 ( pRS ) , width * height , Allocation . USAGE_SCRIPT ) ; final Allocation output1D = Allocation . createTyped ( pRS , input1D . getType ( ) ) ;
public void onReceive ( Context context , Intent intent ) { String action = intent . getAction ( ) ; if ( action . equals ( BluetoothDevice . ACTION_BOND_STATE_CHANGED ) ) { int bondState = intent . getIntExtra ( BluetoothDevice . EXTRA_BOND_STATE , BluetoothDevice . ERROR ) ; if ( ( bondState != BluetoothDevice . BOND_NONE ) && ( bondState != BluetoothDevice . BOND_BONDED ) ) { return ; } } else if ( action . equals ( ACTION_DISMISS_PAIRING ) ) { < |startfocus| > Log . d ( TAG , "Notification cancelled for " + mDevice . getAddress ( ) + " ( " + < |endfocus| > mDevice . getName ( ) + " ) " ) ; } else { int bondState = intent . getIntExtra ( BluetoothDevice . EXTRA_BOND_STATE , BluetoothDevice . ERROR ) ; Log . d ( TAG , "Dismiss pairing for " + mDevice . getAddress ( ) + " ( " + mDevice . getName ( ) + " ) , BondState : " + bondState ) ; } stopForeground ( true ) ; stopSelf ( ) ;
public void sendUssd ( String ussdMessage ) throws ImsException { logi ( "sendUssd : : ussdMessage = " + ussdMessage ) ; synchronized ( mLockObj ) { if ( mSession == null ) { loge ( "sendUssd : : " ) ; throw new ImsException ( "No call session" , ImsReasonInfo . CODE_LOCAL_CALL_TERMINATED ) ; } mSession . sendUssd ( ussdMessage ) ; } } /* * < |startfocus| > * TODO : Delete this method and replace it with a thread that listens to the opened pipe . */ public void sendRttMessage ( String rttMessage ) { } /* * < |endfocus| > * Sends a user - requested RTT upgrade request . */ public void sendRttModifyRequest ( ) { logi ( "sendRttModifyRequest" ) ; synchronized ( mLockObj ) { if ( mSession == null ) { loge ( "sendRttModifyRequest : : no session" ) ; } if ( mCallProfile . mMediaProfile . isRttCall ( ) ) { logi ( "sendRttModifyRequest : : Already RTT call , ignoring . " ) ; return ; } // Make a copy of the current ImsCallProfile and modify it to enable RTT Parcel p = Parcel . obtain ( ) ; mCallProfile . writeToParcel ( p , 0 ) ; p . setDataPosition ( 0 ) ; ImsCallProfile newCallProfile = ImsCallProfile . readFromParcel ( p ) ; p . recycle ( ) ; newCallProfile . mMediaProfile . setRttMode ( ImsStreamMediaProfile . RTT_MODE_FULL ) ; mSession . sendRttModifyRequest ( newCallProfile ) ; } } /* * * Sends a user - requested RTT downgrade request . */ public void sendRttModifyResponse ( boolean status ) { logi ( "sendRttModifyResponse" ) ; synchronized ( mLockObj ) { if ( mSession == null ) { loge ( "sendRttModifyResponse : : no session" ) ; } if ( ! mCallProfile . mMediaProfile . isRttCall ( ) ) { logi ( "sendRttModifyResponse : : Not an RTT call , ignoring . " ) ; return ; } mSession . sendRttModifyResponse ( status ) ; } } /* * * Sends an RTT message over the current RTT call . */ public void sendRttMessage ( String rttMessage ) { logi ( "sendRttMessage" ) ; synchronized ( mLockObj ) { if ( mSession == null ) { loge ( "sendRttMessage : : no session" ) ; } if ( ! mCallProfile . mMediaProfile . isRttCall ( ) ) { logi ( "sendRttMessage : : Not an RTT call , ignoring . " ) ; return ; } mSession . sendRttMessage ( rttMessage ) ; } } /* * * Sends a user - requested RTT downgrade request . */ public void sendRttModifyResponse ( boolean status ) { logi ( "sendRttModifyResponse" ) ; synchronized ( mLockObj ) { if ( mSession == null ) { loge ( "sendRttModifyResponse : : no session" ) ; } if ( ! mCallProfile . mMediaProfile . isRttCall ( ) ) { logi ( "sendRttModifyResponse : : Not an RTT call , ignoring . " ) ; return ; } mSession . sendRttModifyResponse ( status ) ; } } /* * * Sends an RTT message over the current RTT call . */ public void sendRttMessage ( String rttMessage ) { logi ( "sendRttMessage" ) ; synchronized ( mLockObj ) { if ( mSession == null ) { loge ( "sendRttMessage : : no session" ) ; } if ( ! mCallProfile . mMediaProfile . isRttCall ( ) ) { logi ( "sendRttMessage : : Not an RTT call , ignoring . " ) ; return ; } mSession . sendRttMessage ( rttMessage ) ; } } /* * * Sends a user - requested RTT downgrade request . */ public void sendRttModifyResponse ( boolean status ) { logi ( "sendRttModifyResponse" ) ; synchronized ( mLockObj ) { if ( mSession == null ) { loge ( "sendRttModifyResponse : : no session" ) ; } if ( ! mCallProfile . mMediaProfile . isRttCall ( ) ) { logi ( "sendRttModifyResponse : : Not an RTT call , ignoring . " ) ; return ; } mSession . sendRttModifyResponse ( status ) ; } } /* * * Sends an RTT message over the current RTT call . */ public void sendRttMessage ( String rttMessage ) { logi ( "sendRttMessage" ) ; synchronized ( mLockObj ) { if ( mSession == null ) { loge ( "sendRttMessage : : no session" ) ; } if ( ! mCallProfile . mMediaProfile . isRttCall ( ) ) { logi ( "sendRttMessage : : Not an RTT call , ignoring . " ) ; return ; } mSession . sendRttMessage ( rttMessage ) ; } } /* * * Sends a user - requested RTT downgrade request . */ public void sendRttModifyResponse ( boolean status ) { logi ( "sendRttModifyResponse" ) ; synchronized ( mLockObj ) { if ( mSession == null ) { loge ( "sendRttModifyResponse : : no session" ) ; } if ( ! mCallProfile . mMediaProfile . isRttCall ( ) ) { logi ( "sendRttModifyResponse : : Not an RTT call , ignoring . " ) ; return ; } mSession . sendRttModifyResponse ( status ) ; } } /* * * Sends an RTT message over the current RTT call . */ public void sendRttMessage ( String rttMessage ) { logi ( "sendRttMessage" ) ; synchronized ( mLockObj ) { if ( mSession == null ) { loge ( "sendRttMessage : : no session" ) ; } if ( ! mCallProfile . mMediaProfile . isRttCall ( ) ) { logi ( "sendRttMessage : : Not an RTT call , ignoring . " ) ; return ; } mSession . sendRttMessage ( rttMessage ) ; } } /* * * Sends a user - requested RTT downgrade request . */ public void sendRttModifyResponse ( boolean status ) { logi ( "sendRttModifyResponse" ) ; synchronized ( mLockObj ) { if ( mSession == null ) { loge ( "sendRttModifyResponse : : no session" ) ; } if ( ! mCallProfile . mMediaProfile . isRttCall ( ) ) { logi ( "sendRttModifyResponse : : Not an RTT call , ignoring . " ) ; return ; } mSession . sendRttModifyResponse ( status ) ; } } /* * * Sends an RTT message over the current RTT call . */ public void sendRttMessage ( String rttMessage ) { logi ( "sendRttMessage" ) ; synchronized ( mLockObj ) { if ( mSession == null ) { loge ( "sendRttMessage : : no session" ) ; } if ( ! mCallProfile . mMediaProfile . isRttCall ( ) ) { logi ( "sendRttMessage : : Not an RTT call , ignoring . " ) ; return ; } mSession . sendRttMessage ( rttMessage ) ; } } /* * * Sends a user - requested RTT downgrade request . */ public void sendRttModifyResponse ( boolean status ) { logi ( "sendRttModifyResponse" ) ; synchronized ( mLockObj ) { if ( mSession == null ) { loge ( "sendRttModifyResponse : : no session" ) ; } if ( ! mCallProfile . mMediaProfile . isRttCall ( ) ) { logi ( "sendRttModifyResponse : : Not an RTT call , ignoring . " ) ; return ; } mSession . sendRttModifyResponse ( status ) ; } } /* * * Sends an RTT message over the current RTT call . */ public void sendRttMessage ( String rttMessage ) { logi ( "sendRttMessage" ) ; synchronized ( mLockObj ) { if ( mSession == null ) { loge ( "sendRttMessage : : no session" ) ; } if ( ! mCallProfile . mMediaProfile . isRttCall ( ) ) { logi ( "sendRttMessage : : Not an RTT call , ignoring . " ) ; return ; } m
< |startfocus| > public static List < TimeZone > getTimeZonesWithUniqueOffsets ( String country ) { < |endfocus| > synchronized ( sLastUniqueLockObj ) { if ( ( country != null ) && country . equals ( sLastUniqueCountry ) ) { if ( DBG ) { Log . d ( TAG , "getTimeZonesWithUniqueOffsets ( " + country + " ) : return cached version" ) ; } return sLastUniqueZoneOffsets ; } } Collection < TimeZone > zones = getTimeZones ( country ) ; ArrayList < TimeZone > uniqueTimeZones = new ArrayList < > ( ) ; for ( TimeZone zone : zones ) { // See if we already have this offset , // Using slow but space efficient and these are small . boolean found = false ; for ( int i = 0 ; i < uniqueTimeZones . size ( ) ; i ++ ) { if ( uniqueTimeZones . get ( i ) . getRawOffset ( ) == zone . getRawOffset ( ) ) { found = true ; break ; } } if ( ! found ) { if ( DBG ) { Log . d ( TAG , "getTimeZonesWithUniqueOffsets : add unique offset = " + zone . getRawOffset ( ) ) ; } uniqueTimeZones . add ( zone ) ; } } if ( DBG ) { Log . d ( TAG , "getTimeZonesWithUniqueOffsets ( " + country + " ) : cache unique version" ) ; } synchronized ( sLastUniqueLockObj ) { sLastUniqueCountry = country ; sLastUniqueZoneOffsets = uniqueTimeZones ; } return uniqueTimeZones ; }
return mgr . isVolteProvisioned ( ) ; } } return true ; } /* * * Indicates whether VoLTE is provisioned on this slot . */ public boolean isVolteProvisionedOnDeviceForSlot ( ) { if ( getBooleanCarrierConfigForSlot ( CarrierConfigManager . KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL ) ) { return isVolteProvisioned ( ) ; } return true ; } /* * * Indicates whether VoWifi is provisioned on device . * < |startfocus| > * When CarrierConfig KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL is true , and VoLTE is not < |endfocus| > * provisioned on device , this method returns false . * * @deprecated Does not support MSIM devices . Please use * { @link #isWfcProvisionedOnDeviceForSlot ( ) } instead . */ public static boolean isWfcProvisionedOnDevice ( Context context ) { if ( getBooleanCarrierConfig ( context , CarrierConfigManager . KEY_CARRIER_VOLTE_OVERRIDE_WFC_PROVISIONING_BOOL ) ) { if ( ! isVolteProvisionedOnDevice ( context ) ) { return false ; } } if ( getBooleanCarrierConfig ( context , CarrierConfigManager . KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL ) ) {
return false ; } } if ( getBooleanCarrierConfig ( context , CarrierConfigManager . KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL ) ) { ImsManager mgr = ImsManager . getInstance ( context , SubscriptionManager . getDefaultVoicePhoneId ( ) ) ; if ( mgr != null ) { return mgr . isWfcProvisioned ( ) ; } } return true ; } /* * * Indicates whether VoWifi is provisioned on slot . * < |startfocus| > * When CarrierConfig KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL is true , and VoLTE is not < |endfocus| > * provisioned on device , this method returns false . */ public boolean isWfcProvisionedOnDeviceForSlot ( ) { if ( getBooleanCarrierConfigForSlot ( CarrierConfigManager . KEY_CARRIER_VOLTE_OVERRIDE_WFC_PROVISIONING_BOOL ) ) { if ( ! isVolteProvisionedOnDeviceForSlot ( ) ) { return false ; } } if ( getBooleanCarrierConfigForSlot ( CarrierConfigManager . KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL ) ) { return isWfcProvisioned ( ) ; } return true ; } /* * * Indicates whether VT is provisioned on device * * @deprecated Does not support MSIM devices . Please use
private void sendTetherStateChangedBroadcast ( ) { if ( ! getConnectivityManager ( ) . isTetheringSupported ( ) ) return ; < |startfocus| > final ArrayList < String > availableList = new ArrayList < > ( ) ; final ArrayList < String > tetherList = new ArrayList < > ( ) ; final ArrayList < String > hotspotList = new ArrayList < > ( ) ; final ArrayList < String > erroredList = new ArrayList < > ( ) ; < |endfocus| > boolean wifiTethered = false ; boolean usbTethered = false ; boolean bluetoothTethered = false ; final TetheringConfiguration cfg = mConfig ; synchronized ( mPublicSync ) { for ( int i = 0 ; i < mTetherStates . size ( ) ; i ++ ) { TetherState tetherState = mTetherStates . valueAt ( i ) ; String iface = mTetherStates . keyAt ( i ) ; if ( tetherState . lastError != ConnectivityManager . TETHER_ERROR_NO_ERROR ) { erroredList . add ( iface ) ; } else if ( tetherState . lastState == IControlsTethering . STATE_AVAILABLE ) { availableList . add ( iface ) ; } else if ( tetherState . lastState == IControlsTethering . STATE_LOCAL_HOTSPOT ) { hotspotList . add ( iface ) ;
import android . telephony . CarrierConfigManager ; import android . os . Message ; import android . os . Messenger ; import com . android . internal . util . AsyncChannel ; import org . junit . Before ; import org . junit . Test ; import org . junit . runner . RunWith ; import org . mockito . Mock ; import org . mockito . MockitoAnnotations ; import org . mockito . ArgumentCaptor ; import java . util . List ; @RunWith ( AndroidJUnit4 . class ) @SmallTest public class NsdManagerTest { @Mock Context mContext ; @Mock INsdManager mService ; MockServiceHandler mServiceHandler ; < |startfocus| > static final long mTimeoutMs = 100 ; < |endfocus| > @Before public void setUp ( ) throws Exception { MockitoAnnotations . initMocks ( this ) ; mServiceHandler = spy ( MockServiceHandler . make ( mContext ) ) ; when ( mService . getMessenger ( ) ) . thenReturn ( new Messenger ( mServiceHandler ) ) ; } @Test public void testResolveService ( ) { NsdManager manager = makeManager ( ) ; NsdServiceInfo request = new NsdServiceInfo ( "a name" , "a type" ) ; NsdServiceInfo reply = new NsdServiceInfo ( "resolved name" , "resolved type" ) ; NsdManager . ResolveListener listener = mock ( NsdManager . ResolveListener . class ) ; manager . resolveService ( request , listener ) ;
public void testResolveService ( ) { NsdManager manager = makeManager ( ) ; < |startfocus| > NsdServiceInfo request = new NsdServiceInfo ( "a name" , "a type" ) ; NsdServiceInfo reply = new NsdServiceInfo ( "resolved name" , "resolved type" ) ; < |endfocus| > NsdManager . ResolveListener listener = mock ( NsdManager . ResolveListener . class ) ; manager . resolveService ( request , listener ) ; int key1 = verifyRequest ( NsdManager . RESOLVE_SERVICE ) ; int err = 33 ; sendResponse ( NsdManager . RESOLVE_SERVICE_FAILED , err , key1 , null ) ; verify ( listener , timeout ( mTimeoutMs ) . times ( 1 ) ) . onResolveFailed ( request , err ) ; manager . resolveService ( request , listener ) ; int key2 = verifyRequest ( NsdManager . RESOLVE_SERVICE ) ; sendResponse ( NsdManager . RESOLVE_SERVICE_SUCCEEDED , 0 , key2 , reply ) ; verify ( listener , timeout ( mTimeoutMs ) . times ( 1 ) ) . onServiceResolved ( reply ) ;
< |startfocus| > public static MockServiceHandler create ( Context context ) { < |endfocus| > HandlerThread t = new HandlerThread ( "mock - service - handler" ) ; t . start ( ) ; return new MockServiceHandler ( t . getLooper ( ) , context ) ;
mConnected . countDown ( ) ; return ; case AsyncChannel . CMD_CHANNEL_DISCONNECTED : Log . e ( TAG , "Channel lost" ) ; return ; default : break ; } final NsdServiceInfo ns = getNsdService ( key ) ; final Object listener = getListener ( key ) ; if ( listener == null ) { < |startfocus| > // Expected for replies / timouts to resolveService ( ) if ( what != RESOLVE_SERVICE_SUCCEEDED && what != RESOLVE_SERVICE_FAILED && what != RESOLVE_SERVICE_TIMEOUT ) { Log . d ( TAG , "Stale key " + key ) ; } < |endfocus| > return ; } if ( DBG ) { Log . d ( TAG , "received " + nameOf ( what ) + " for key " + key + " , service " + ns ) ; } switch ( what ) { case DISCOVER_SERVICES_STARTED : String s = getNsdServiceInfoType ( ( NsdServiceInfo ) message . obj ) ; ( ( DiscoveryListener ) listener ) . onDiscoveryStarted ( s ) ; break ; case DISCOVER_SERVICES_FAILED : removeListener ( key ) ; ( ( DiscoveryListener ) listener ) . onStartDiscoveryFailed ( getNsdServiceInfoType ( ns ) , message . arg1 ) ; break ; case SERVICE_FOUND :
"android . bluetooth . adapter . extra . PREVIOUS_CONNECTION_STATE" ; /* * * Broadcast Action : The Bluetooth adapter state has changed in LE only mode . * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android . bluetooth . adapter . action . BLE_STATE_CHANGED" ; /* * * Intent used to broadcast the change in MAC address of the * local Bluetooth adapter . * < p > Always contains the extra field { @link < |startfocus| > * #EXTRA_BLUETOOTH_ADDRESS } containing the MAC address . < |endfocus| > * *
* < p > Always contains the extra field { @link * #EXTRA_BLUETOOTH_ADDRESS } containing the MAC address . * *
String newName = intent . getStringExtra ( BluetoothAdapter . EXTRA_LOCAL_NAME ) ; if ( DBG ) Slog . d ( TAG , "Bluetooth Adapter name changed to " + newName ) ; if ( newName != null ) { storeNameAndAddress ( newName , null ) ; } } else if ( BluetoothAdapter . ACTION_BLUETOOTH_ADDRESS_CHANGED . equals ( action ) ) { String newAddress = intent . getStringExtra ( BluetoothAdapter . EXTRA_BLUETOOTH_ADDRESS ) ; if ( newAddress != null ) { < |startfocus| > if ( DBG ) Slog . d ( TAG , "Bluetooth Adapter Address changed to " + newAddress ) ; < |endfocus| > storeNameAndAddress ( null , newAddress ) ; } else { if ( DBG ) Slog . e ( TAG , "No Bluetooth Adapter Address parameter found" ) ; } }
if ( newName != null ) { storeNameAndAddress ( newName , null ) ; } } else if ( BluetoothAdapter . ACTION_BLUETOOTH_ADDRESS_CHANGED . equals ( action ) ) { String newAddress = intent . getStringExtra ( BluetoothAdapter . EXTRA_BLUETOOTH_ADDRESS ) ; if ( newAddress != null ) { if ( DBG ) Slog . d ( TAG , "Bluetooth Adapter MAC Address changed to " + newAddress ) ; storeNameAndAddress ( null , newAddress ) ; } else { < |startfocus| > if ( DBG ) Slog . e ( TAG , "No Bluetooth Adapter MAC Address parameter found" ) ; < |endfocus| > } } < |startfocus| >
mErrorRecoveryRetryCounter = 0 ; mContentResolver = context . getContentResolver ( ) ; // Observe BLE scan only mode settings change . registerForBleScanModeChange ( ) ; mCallbacks = new RemoteCallbackList < IBluetoothManagerCallback > ( ) ; mStateChangeCallbacks = new RemoteCallbackList < IBluetoothStateChangeCallback > ( ) ; IntentFilter filter = new IntentFilter ( BluetoothAdapter . ACTION_LOCAL_NAME_CHANGED ) ; filter . setPriority ( IntentFilter . SYSTEM_HIGH_PRIORITY ) ; mContext . registerReceiver ( mReceiver , filter ) ; < |startfocus| > filter = new IntentFilter ( BluetoothAdapter . ACTION_BLUETOOTH_ADDRESS_CHANGED ) ; filter . setPriority ( IntentFilter . SYSTEM_HIGH_PRIORITY ) ; mContext . registerReceiver ( mReceiver , filter ) ; < |endfocus| > loadStoredNameAndAddress ( ) ; if ( isBluetoothPersistedStateOn ( ) ) { if ( DBG ) Slog . d ( TAG , "Startup : Bluetooth persisted state is ON . " ) ; mEnableExternal = true ; } String airplaneModeRadios = Settings . Global . getString ( mContentResolver , Settings . Global . AIRPLANE_MODE_RADIOS ) ; if ( airplaneModeRadios == null || airplaneModeRadios . contains ( Settings . Global . RADIO_BLUETOOTH ) ) { mContentResolver . registerContentObserver ( Settings . Global . getUriFor ( Settings . Global . AIRPLANE_MODE_ON ) , true , mAirplaneModeObserver ) ; }
"android . bluetooth . adapter . action . BLE_STATE_CHANGED" ; /* * * Intent used to broadcast the change in MAC address of the * local Bluetooth adapter . * < p > Always contains the extra field { @link #EXTRA_BT_ADDR } * containing the MAC address . * *
Log . d ( TAG , "Notification cancel " + mDevice . getAddress ( ) + " ( " + mDevice . getName ( ) + " ) " ) ; mDevice . cancelPairingUserInput ( ) ; } else { int bondState = intent . getIntExtra ( BluetoothDevice . EXTRA_BOND_STATE , BluetoothDevice . ERROR ) ; Log . d ( TAG , "Dismiss pairing for " + mDevice . getAddress ( ) + " ( " + mDevice . getName ( ) + " ) , BondState : " + bondState ) ; } stopForeground ( true ) ; stopSelf ( ) ; } } ; < |startfocus| > @Override public void onCreate ( ) { } < |endfocus| > @Override public int onStartCommand ( Intent intent , int flags , int startId ) { if ( intent == null ) { Log . e ( TAG , "Can't start : null intent ! " ) ; stopSelf ( ) ; return START_NOT_STICKY ; } Resources res = getResources ( ) ; Notification . Builder builder = new Notification . Builder ( this ) . setSmallIcon ( android . R . drawable . stat_sys_data_bluetooth ) . setTicker ( res . getString ( R . string . bluetooth_notif_ticker ) ) ; PendingIntent pairIntent = PendingIntent . getActivity ( this , 0 ,
} /* * * This method can assume EXTENDED_YEAR has been set . * @param millis milliseconds of the date fields ( local midnight millis ) * @param millisInDay milliseconds of the time fields ; may be out * or range . * @return total zone offset ( raw + DST ) for the given moment < |startfocus| > * @deprecated This method suffers from a potential integer overflow and may be removed in a * future release . Overriding this method in subclasses will not have the desired effect . * See ICU ticket #11632 . < |endfocus| > */ protected int computeZoneOffset ( long millis , int millisInDay ) { int [ ] offsets = new int [ 2 ] ; long wall = millis + millisInDay ; if ( zone instanceof BasicTimeZone ) { int duplicatedTimeOpt = ( repeatedWallTime == WALLTIME_FIRST ) ? BasicTimeZone . LOCAL_FORMER : BasicTimeZone . LOCAL_LATTER ; int nonExistingTimeOpt = ( skippedWallTime == WALLTIME_FIRST ) ? BasicTimeZone . LOCAL_LATTER : BasicTimeZone . LOCAL_FORMER ;
< |startfocus| > * Copyright ( C ) 2016 The Android Open Source Project < |endfocus| > * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ public class Main { public static void main ( String [ ] args ) { System . loadLibrary ( args [ 0 ] ) ; testGetFieldId ( TestClass . class , "intField" , "I" ) ; testGetFieldId ( TestClass . class , "intField" , "int" ) ; testGetFieldId ( TestClass . class , "intField" , "Lint ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "I" ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / Object ; " ) ; testGetFieldId ( TestClass . class , "stringField" , "Ljava / lang / String ; " ) ; testGetFieldId ( TestClass . class , "
* < tr > < td > Android 7 . 0 ( Nougat ) </ td > * < td > < a href = "http :/ / site . icu - project . org / download / 56" > ICU 56 . 1 </ a > </ td > * < td > < a href = "http :/ / cldr . unicode . org / index / downloads / cldr - 28" > CLDR 28 </ a > </ td > * < td > < a href = "http :/ / www . unicode . org / versions / Unicode8 . 0 . 0 / " > Unicode 8 . 0 </ a > </ td > </ tr > < |startfocus| > * < tr > < td > Android O </ td > < |endfocus| > * < td > < a href = "http :/ / site . icu - project . org / download / 58" > ICU 58 . 2 </ a > </ td > * < td > < a href = "http :/ / cldr . unicode . org / index / downloads / cldr - 30" > CLDR 30 . 0 . 3 </ a > </ td > * < td > < a href = "http :/ / www . unicode . org / versions / Unicode9 . 0 . 0 / " > Unicode 9 . 0 </ a > </ td > </ tr > * </ table > * * < a name = "default_locale" > </ a > < h4 > Be wary of the default locale </ h3 > * < p > Note that there are many convenience methods that automatically use the default locale , but
// Disable native bind notify for now to avoid infinite loops . setNativeBindNotify ( false ) ; String transSym = SymbolMap . getOrDefault ( method , nativeSym ) ; System . out . println ( method + " = " + nativeSym + " - > " + transSym ) ; setNativeBindNotify ( true ) ; return transSym ; } public static void doTest ( ) throws Exception { Method say_hi_method = Transform . class . getDeclaredMethod ( "sayHi" ) ; < |startfocus| > // Test we will autobind normally . < |endfocus| > Transform . sayHi2 ( ) ; // Test we can get in the middle of autobind setNativeTransform ( say_hi_method , "NoReallySayGoodbye" ) ; Transform . sayHi ( ) ; // Test we can get in between manual bind . setNativeTransform ( say_hi_method , "Java_art_Test986_00024Transform_sayHi2" ) ; rebindTransformClass ( ) ; Transform . sayHi ( ) ; // Test we can get rid of transform removeNativeTransform ( say_hi_method ) ; rebindTransformClass ( ) ; Transform . sayHi ( ) ; Main . bindAgentJNIForClass ( Main . class ) ; Main . bindAgentJNIForClass ( Test986 . class ) ; } // Functions called from native code .
// Test we can get in the middle of autobind setNativeTransform ( say_hi_method , "NoReallySayGoodbye" ) ; Transform . sayHi ( ) ; // Test we can get in between manual bind . setNativeTransform ( say_hi_method , "Java_art_Test986_00024Transform_sayHi2" ) ; rebindTransformClass ( ) ; Transform . sayHi ( ) ; // Test we can get rid of transform removeNativeTransform ( say_hi_method ) ; rebindTransformClass ( ) ; Transform . sayHi ( ) ; < |startfocus| > Main . bindAgentJNIForClass ( Main . class ) ; Main . bindAgentJNIForClass ( Test986 . class ) ; < |endfocus| > } // Functions called from native code . public static void doSayHi ( ) { System . out . println ( "Hello" ) ; } public static void doSayHi2 ( ) { System . out . println ( "Hello - 2" ) ; } public static void doSayBye ( ) { System . out . println ( "Bye" ) ; } private static native void setNativeBindNotify ( boolean enable ) ; private static native void setupNativeBindNotify ( ) ; private static void rebindTransformClass ( ) { rebindTransformClass ( Transform . class ) ; } private static native void rebindTransformClass ( Class < ? > trans ) ; }
< |startfocus| > private void ensureValidNetworkSpecifier ( NetworkSpecifier ns ) { MatchAllNetworkSpecifier . checkNotMatchAllNetworkSpecifier ( ns ) ; if ( ns != null ) { ns . assertValidFromUid ( Binder . getCallingUid ( ) ) ; < |endfocus| > }
* Copyright ( C ) 2009 The Android Open Source Project * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package android . net . cts ; import static com . android . server . NetworkManagementSocketTagger . resetKernelUidStats ; import java . net . ServerSocket ; import android . net . TrafficStats ; import android . os . Process ; import android . test . AndroidTestCase ; import android . util . Log ; import android . net . LocalSocket ; import java . io . File ; import java . io . BufferedReader ; import java . io . FileNotFoundException ; import java . io . FileReader ; import java . io . FileWriter ;
String line ; Pattern ctrlDataPattern = Pattern . compile ( PATTERN ) ; while ( ( line = qtaguidReader . readLine ( ) ) != null ) { Matcher refCountMatcher = ctrlDataPattern . matcher ( line ) ; if ( refCountMatcher . matches ( ) ) { if ( refCountMatcher . group ( TAG_INDEX ) . contains ( Long . toHexString ( fullTag ) ) && refCountMatcher . group ( UID_INDEX ) . contains ( Integer . toString ( uid ) ) ) { refcnt_res = Integer . parseInt ( refCountMatcher . group ( REFCNT_INDEX ) ) ; Log . d ( TAG , "result refcnt : " + refcnt_res ) ; break ; } } } < |startfocus| > qtaguidReader . close ( ) ; } catch ( FileNotFoundException e ) { fail ( "Not able to access qtaguid / ctrl : " + e ) ; } catch ( IOException e ) { fail ( "file read error" ) ; } < |endfocus| > return refcnt_res ;
if ( refCountMatcher . group ( TAG_INDEX ) . contains ( Long . toHexString ( fullTag ) ) && refCountMatcher . group ( UID_INDEX ) . contains ( Integer . toString ( uid ) ) ) { refcnt_res = Integer . parseInt ( refCountMatcher . group ( REFCNT_INDEX ) ) ; Log . d ( TAG , "result refcnt : " + refcnt_res ) ; break ; } } } qtaguidReader . close ( ) ; } catch ( FileNotFoundException e ) { fail ( "Not able to access qtaguid / ctrl : " + e ) ; } catch ( IOException e ) { fail ( "file read error" ) ; } return refcnt_res ;
public boolean imsIsEnhanced4gLteModeSettingEnabledByPlatform ( ) { < |startfocus| > return mImsManager . isVolteEnabledByPlatformForSlot ( ) ; < |endfocus| >
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . android . internal . util ; import android . annotation . Nullable ; import libcore . util . Objects ; import java . nio . ByteBuffer ; import java . util . Arrays ; import java . util . UUID ; /* * < |startfocus| > * A utility class for handling unsigned integers and unsigned arithmetics , as well as syntactic sugar methods * for ByteBuffer . Useful for networking and packet manipulations . < |endfocus| > * { @hide } */ public final class BitUtils { private BitUtils ( ) { } public static boolean maskedEquals ( long a , long b , long mask ) { return ( a & mask ) == ( b & mask ) ; } public static boolean maskedEquals ( byte a , byte b , byte mask ) { return ( a & mask ) == ( b & mask ) ; } public static boolean maskedEquals ( byte [ ] a , byte [ ] b , @Nullable byte [ ] mask ) { if ( a == null || b == null ) return a == b ;
} try { // Verification of TestClass . test ( ) used to crash when processing // the final abstract ( erroneous ) class . Class < ? > tc = Class . forName ( "TestClass" ) ; Method test = tc . getDeclaredMethod ( "test" ) ; test . invoke ( null ) ; System . out . println ( "UNREACHABLE ! " ) ; } catch ( InvocationTargetException ite ) { if ( ite . getCause ( ) instanceof InstantiationError ) { System . out . println ( < |startfocus| > ite . getCause ( ) . getClass ( ) . getName ( ) + " : " + ite . getCause ( ) . getMessage ( ) ) ; < |endfocus| > } else { ite . printStackTrace ( System . out ) ; } } catch ( Throwable t ) { t . printStackTrace ( System . out ) ; }
} return findPreviousZoneTransitionTime ( tz , upperOffset , mid , lower ) ; } /* * * Compute the milliseconds in the day from the fields . This is a * value from 0 to 23 : 59 : 59 . 999 inclusive , unless fields are out of * range , in which case it can be an arbitrary value . This value * reflects local zone wall time . < |startfocus| > * @deprecated This method suffers from a potential integer overflow and may be removed in a future * release . Overriding this method in subclasses will not have the desired effect . See ICU * ticket #11632 . < |endfocus| > */ @Deprecated protected int computeMillisInDay ( ) { // Do the time portion of the conversion . int millisInDay = 0 ; // Find the best set of fields specifying the time of day . There // are only two possibilities here ; the HOUR_OF_DAY or the // AM_PM and the HOUR . int hourOfDayStamp = stamp [ HOUR_OF_DAY ] ; int hourStamp = Math . max ( stamp [ HOUR ] , stamp [ AM_PM ] ) ;
} return findPreviousZoneTransitionTime ( tz , upperOffset , mid , lower ) ; } /* * * Compute the milliseconds in the day from the fields . This is a * value from 0 to 23 : 59 : 59 . 999 inclusive , unless fields are out of * range , in which case it can be an arbitrary value . This value * reflects local zone wall time . < |startfocus| > * @deprecated This method suffers from a potential integer overflow and may be removed in a future * release . Overriding this method in subclasses will not have the desired effect . See ICU * ticket #11632 . < |endfocus| > */ protected int computeMillisInDay ( ) { // Do the time portion of the conversion . int millisInDay = 0 ; // Find the best set of fields specifying the time of day . There // are only two possibilities here ; the HOUR_OF_DAY or the // AM_PM and the HOUR . int hourOfDayStamp = stamp [ HOUR_OF_DAY ] ; int hourStamp = Math . max ( stamp [ HOUR ] , stamp [ AM_PM ] ) ;
* empty String if no provider was explicitly specified . */ private String verifiedProvider ; /* * * If verifiedPublicKey is not null , result of the verification using * verifiedPublicKey and verifiedProvider . If true , verification was * successful , if false , it failed . */ private boolean verificationResult ; /* * * Default constructor . */ public X509CertImpl ( ) { } < |startfocus| > // BEGIN Android - added : Constructor to retain original encoded form for PKCS7 . < |endfocus| > /* * * Unmarshals a certificate from its encoded form , parsing the * encoded bytes . This form of constructor is used by agents which * need to examine and use certificate contents . That is , this is * one of the more commonly used constructors . Note that the buffer * must include only a certificate , and no "garbage" may be left at * the end . If you need to ignore data at the end of a certificate , * use another constructor . * * @param certData the encoded bytes , with no trailing padding .
* * @param certData the encoded bytes , with no trailing padding . * @exception CertificateException on parsing and initialization errors . */ public X509CertImpl ( byte [ ] certData ) throws CertificateException { try { parse ( new DerValue ( certData ) ) ; } catch ( IOException e ) { signedCert = null ; throw new CertificateException ( "Unable to initialize , " + e , e ) ; } } // END Android - added : Needed To retain original encoded form in PKCS7 . < |startfocus| > // BEGIN Android - removed : unused code . < |endfocus| > /* /* * * unmarshals an X . 509 certificate from an input stream . If the * certificate is RFC1421 hex - encoded , then it must begin with * the line X509Factory . BEGIN_CERT and end with the line * X509Factory . END_CERT . * * @param in an input stream holding at least one certificate that may * be either DER - encoded or RFC1421 hex - encoded version of the * DER - encoded certificate . * @exception CertificateException on parsing and initialization errors . *
public void onRestoreInstanceState ( Bundle savedInstanceState ) { if ( savedInstanceState != null ) { super . onRestoreInstanceState ( savedInstanceState ) ; DialogState dialogState = mDialogState . valueOf ( savedInstanceState . getString ( DIALOG_STATE ) ) ; String msg = savedInstanceState . getString ( DIALOG_MSG_STRING ) ; updateDialog ( dialogState , msg ) ; if ( dialogState == DialogState . WPS_START ) { < |startfocus| > WpsInfo wpsConfig = new WpsInfo ( ) ; wpsConfig . setup = mWpsSetup ; mWifiManager . startWps ( wpsConfig , mWpsListener ) ; < |endfocus| > } }
import java . util . Arrays ; import java . nio . ByteBuffer ; import javax . obex . ServerRequestHandler ; import javax . obex . ResponseCodes ; import javax . obex . ApplicationParameter ; import javax . obex . Operation ; import javax . obex . HeaderSet ; public class BluetoothPbapObexServer extends ServerRequestHandler { private static final String TAG = "BluetoothPbapObexServer" ; private static final boolean D = BluetoothPbapService . DEBUG ; private static final boolean V = BluetoothPbapService . VERBOSE ; private static final int UUID_LENGTH = 16 ; < |startfocus| > public static final int INVALID_VALUE_PARAMETER = - 1 ; < |endfocus| > // The length of suffix of vcard name - " . vcf" is 5 private static final int VCARD_NAME_SUFFIX_LENGTH = 5 ; // 128 bit UUID for PBAP private static final byte [ ] PBAP_TARGET = new byte [ ] { 0x79 , 0x61 , 0x35 , ( byte ) 0xf0 , ( byte ) 0xf0 , ( byte ) 0xc5 , 0x11 , ( byte ) 0xd8 , 0x09 , 0x66 , 0x08 , 0x00 , 0x20 , 0x0c , ( byte ) 0x9a , 0x66 } ;
pushResult = ResponseCodes . OBEX_HTTP_INTERNAL_ERROR ; } if ( ! closeStream ( outputStream , op ) ) { pushResult = ResponseCodes . OBEX_HTTP_INTERNAL_ERROR ; } return pushResult ; } private final int handleAppParaForResponse ( AppParamValue appParamValue , int size , HeaderSet reply , Operation op , String name ) { byte [ ] misnum = new byte [ 1 ] ; ApplicationParameter ap = new ApplicationParameter ( ) ; < |startfocus| > long folderVersionCounterbitMask = 0x0008 ; long databaseIdentifierBitMask = 0x0004 ; < |endfocus| > boolean needSendCallHistoryVersionCounters = false ; if ( isNameMatchTarget ( name , MCH ) || isNameMatchTarget ( name , ICH ) || isNameMatchTarget ( name , OCH ) || isNameMatchTarget ( name , CCH ) ) needSendCallHistoryVersionCounters = checkPbapFeatureSupport ( folderVersionCounterbitMask ) ; boolean needSendPhonebookVersionCounters = false ; if ( isNameMatchTarget ( name , PB ) ) needSendPhonebookVersionCounters = checkPbapFeatureSupport ( folderVersionCounterbitMask ) ; // In such case , PCE only want the number of index . // So response not contain any Body header . if ( mNeedPhonebookSize ) { < |startfocus| > int phonebookSize = mVcardManager . getPhonebookSize ( mCurrentPath ) ; if ( phonebookSize < 0 ) { return ResponseCodes . OBEX_HTTP_INTERNAL_ERROR ; } < |endfocus| >
boolean status = sdpManager . removeSdpRecord ( mSdpHandle ) ; Log . d ( TAG , "RemoveSDPrecord returns " + status ) ; mSdpHandle = - 1 ; } mSdpHandle = SdpManager . getDefaultManager ( ) . createPbapPseRecord ( "OBEX Phonebook Access Server" , mServerSockets . getRfcommChannel ( ) , mServerSockets . getL2capPsm ( ) , SDP_PBAP_SERVER_VERSION , SDP_PBAP_SUPPORTED_REPOSITORIES , SDP_PBAP_SUPPORTED_FEATURES ) ; < |startfocus| > // Here we might have changed crucial data , hence reset DB // identifier < |endfocus| > updateDbIdentifier ( ) ; if ( DEBUG ) Log . d ( TAG , "PBAP server with handle : " + mSdpHandle ) ; }
intent . putExtra ( BluetoothDevice . EXTRA_PACKAGE_NAME , getPackageName ( ) ) ; mIsWaitingAuthorization = true ; sendOrderedBroadcast ( intent , BLUETOOTH_ADMIN_PERM ) ; if ( VERBOSE ) Log . v ( TAG , "waiting for authorization for connection from : " + sRemoteDeviceName ) ; // In case car kit time out and try to use HFP for // phonebook // access , while UI still there waiting for user to // confirm mSessionStatusHandler . sendMessageDelayed ( mSessionStatusHandler . obtainMessage ( USER_TIMEOUT ) , USER_CONFIRM_TIMEOUT_VALUE ) ; < |startfocus| > // We will continue the process when we receive // BluetoothDevice . ACTION_CONNECTION_ACCESS_REPLY from Settings app . < |endfocus| > } return true ;
public final int composeAndSendCallLogVcards ( Operation op , final int startPoint , final int endPoint , final boolean vcardType21 , String ownerVCard , int needSendBody , int pbSize , boolean ignorefilter , byte [ ] filter , byte [ ] vcardselector , String vcardselectorop , boolean vcardselect ) { if ( startPoint < 1 || startPoint > endPoint ) { Log . e ( TAG , "internal error : startPoint or endPoint is not correct . " ) ; return ResponseCodes . OBEX_HTTP_INTERNAL_ERROR ; } String recordSelection = BluetoothPbapObexServer . SELECTION_CALL_LOG_BY_ID + " BETWEEN ? AND ? " ; String [ ] recordSelectionArgs = new String [ ] { String . valueOf ( startPoint ) , String . valueOf ( endPoint ) } ; String typeSelection = null ; if ( vcardselect ) { typeSelection = BluetoothPbapObexServer . SELECTION_CALL_TYPE ; } String selection ; if ( typeSelection == null ) { selection = recordSelection ; } else { selection = " ( " + typeSelection + " ) AND ( " + recordSelection + " ) " ; } if ( V ) Log . v ( TAG , "Call log query selection is : " + selection ) ; < |startfocus| > /* return composeCallLogsAndSendSelectedVCards ( op , selection , vcardType21 , needSendBody , pbSize , null , ignorefilter , filter , vcardselector , vcardselectorop ) ;* / < |endfocus| > return composeCallLogsAndSendSelectedVCards ( op , selection , vcardType21 , needSendBody , pbSize , null , ignorefilter , filter , vcardselector , vcardselectorop , vcardselect ) ; } final int composeAndSendPhonebookVcards ( Operation op , final int startPoint , final int endPoint , final boolean vcardType21 , String ownerVCard , int needSendBody , int pbSize , boolean ignorefilter , byte [ ] filter , byte [ ] vcardselector , String vcardselectorop , boolean vcardselect ) { if ( startPoint < 1 || startPoint > endPoint ) { Log . e ( TAG , "internal error : startPoint or endPoint is not correct . " ) ; return ResponseCodes . OBEX_HTTP_INTERNAL_ERROR ; }
public String onValueReceived ( String rawValue , int type , String label , boolean isPrimary ) { < |startfocus| > // 'p' and 'w' are the standard characters for pause and // wait // ( see RFC 3601 ) // so use those when exporting phone numbers via vCard . < |endfocus| > String numberWithControlSequence = rawValue . replace ( PhoneNumberUtils . PAUSE , 'p' ) . replace ( PhoneNumberUtils . WAIT , 'w' ) ; return numberWithControlSequence ;
public String onValueReceived ( String rawValue , int type , String label , boolean isPrimary ) { < |startfocus| > // 'p' and 'w' are the standard characters for pause and // wait // ( see RFC 3601 ) // so use those when exporting phone numbers via vCard . < |endfocus| > String numberWithControlSequence = rawValue . replace ( PhoneNumberUtils . PAUSE , 'p' ) . replace ( PhoneNumberUtils . WAIT , 'w' ) ; return numberWithControlSequence ;
private boolean checkprop ( String vcard , String prop ) { String lines [ ] = vcard . split ( SEPARATOR ) ; boolean isPresent = false ; for ( String line : lines ) { if ( ! Character . isWhitespace ( line . charAt ( 0 ) ) && ! line . startsWith ( " = " ) ) { String currentProp = line . split ( " [ ; : ] " ) [ 0 ] ; if ( prop . equals ( currentProp ) ) { < |startfocus| > Log . e ( TAG , "bit . prop . equals current prop : " + prop ) ; < |endfocus| > isPresent = true ; return isPresent ; } } } return isPresent ;
private boolean CheckVcardSelector ( String vcard , String vcardselectorop ) { boolean selectedIn = true ; for ( PropertyMask bit : PropertyMask . values ( ) ) { if ( checkbit ( bit . pos , selector ) ) { < |startfocus| > Log . e ( TAG , "checking for prop : " + bit . prop ) ; < |endfocus| > if ( vcardselectorop . equals ( "0" ) ) { if ( checkprop ( vcard , bit . prop ) ) { Log . e ( TAG , "bit . prop . equals current prop : " + bit . prop ) ; selectedIn = true ; break ; } else { selectedIn = false ; } } else if ( vcardselectorop . equals ( "1" ) ) { if ( ! checkprop ( vcard , bit . prop ) ) { Log . e ( TAG , "bit . prop . notequals current prop" + bit . prop ) ; selectedIn = false ; return selectedIn ; } else { selectedIn = true ; } } } } return selectedIn ; }
private boolean CheckVcardSelector ( String vcard , String vcardselectorop ) { boolean selectedIn = true ; for ( PropertyMask bit : PropertyMask . values ( ) ) { if ( checkbit ( bit . pos , selector ) ) { Log . e ( TAG , "checking for prop : " + bit . prop ) ; if ( vcardselectorop . equals ( "0" ) ) { if ( checkprop ( vcard , bit . prop ) ) { < |startfocus| > Log . e ( TAG , "bit . prop . equals current prop : " + bit . prop ) ; < |endfocus| > selectedIn = true ; break ; } else { selectedIn = false ; } } else if ( vcardselectorop . equals ( "1" ) ) { if ( ! checkprop ( vcard , bit . prop ) ) { Log . e ( TAG , "bit . prop . notequals current prop" + bit . prop ) ; selectedIn = false ; return selectedIn ; } else { selectedIn = true ; } } } } return selectedIn ;
boolean status = sdpManager . removeSdpRecord ( mSdpHandle ) ; Log . d ( TAG , "RemoveSDPrecord returns " + status ) ; mSdpHandle = - 1 ; } mSdpHandle = SdpManager . getDefaultManager ( ) . createPbapPseRecord ( "OBEX Phonebook Access Server" , mServerSockets . getRfcommChannel ( ) , mServerSockets . getL2capPsm ( ) , SDP_PBAP_SERVER_VERSION , SDP_PBAP_SUPPORTED_REPOSITORIES , SDP_PBAP_SUPPORTED_FEATURES ) ; < |startfocus| > // fetch DbIdentifier to check if significant change has happened to Db getPbapDbParams ( ) ; < |endfocus| > if ( DEBUG ) Log . d ( TAG , "PBAP server with handle : " + mSdpHandle ) ; }
private boolean initialize ( ) { Log . d ( TAG , "Start initialize ( ) " ) ; mPMCStatusLogger = new PMCStatusLogger ( TAG + " . log" , TAG ) ; // Check if any Bluetooth devices are connected ArrayList < BluetoothDevice > results = new ArrayList < BluetoothDevice > ( ) ; Set < BluetoothDevice > bondedDevices = mBluetoothAdapter . getBondedDevices ( ) ; < |startfocus| > if ( bondedDevices == null ) return false ; < |endfocus| > for ( BluetoothDevice bd : bondedDevices ) { if ( bd . isConnected ( ) ) { results . add ( bd ) ; } } if ( results . isEmpty ( ) ) { Log . e ( TAG , "No device is connected" ) ; return false ; } Log . d ( TAG , "Finish initialize ( ) " ) ; return true ;
private boolean initialize ( ) { Log . d ( TAG , "Start initialize ( ) " ) ; mPMCStatusLogger = new PMCStatusLogger ( TAG + " . log" , TAG ) ; // Check if any BT devices are connected ArrayList < BluetoothDevice > results = new ArrayList < BluetoothDevice > ( ) ; < |startfocus| > Set < BluetoothDevice > bondedDevices = mBluetoothAdapter . getBondedDevices ( ) ; if ( bondedDevices == null ) { Log . e ( TAG , "No device is connected" ) ; return false ; } for ( BluetoothDevice bd : bondedDevices ) { < |endfocus| > if ( bd . isConnected ( ) ) { results . add ( bd ) ; } } if ( results . isEmpty ( ) ) { Log . e ( TAG , "No device is connected" ) ; return false ; } Log . d ( TAG , "Finish initialize ( ) " ) ; return true ;
boolean bt_off_mute = false ; Bundle extras = intent . getExtras ( ) ; if ( extras == null ) { Log . e ( TAG , "No parameters specified" ) ; return ; } // Always initialize ( ) if ( ! initialize ( ) ) { mPMCStatusLogger . logStatus ( "initialize ( ) Failed" ) ; return ; } // Check if it is baseline Bluetooth is on but not stream if ( extras . containsKey ( "Bluetooth_ON_NotPlay" ) ) { < |startfocus| > Log . v ( TAG , "NotPlay is specified for baseline case of only Bluetooth on" ) ; < |endfocus| > // Do nothing further mPMCStatusLogger . logStatus ( "READY" ) ; mPMCStatusLogger . logStatus ( "SUCCEED" ) ; return ; } if ( ! extras . containsKey ( "PlayTime" ) ) { Log . e ( TAG , "No Play Time specified" ) ; return ; } tmpStr = extras . getString ( "PlayTime" ) ; Log . d ( TAG , "Play Time = " + tmpStr ) ; playTime = Integer . valueOf ( tmpStr ) ; if ( ! extras . containsKey ( "MusicURL" ) ) { Log . e ( TAG , "No Music URL specified" ) ; return ; }
Log . e ( TAG , "No Play Time specified" ) ; return ; } tmpStr = extras . getString ( "PlayTime" ) ; Log . d ( TAG , "Play Time = " + tmpStr ) ; playTime = Integer . valueOf ( tmpStr ) ; if ( ! extras . containsKey ( "MusicURL" ) ) { Log . e ( TAG , "No Music URL specified" ) ; return ; } musicUrl = extras . getString ( "MusicURL" ) ; Log . d ( TAG , "Music URL = " + musicUrl ) ; < |startfocus| > // playTime and musicUrl are necessary < |endfocus| > if ( playTime == 0 || musicUrl . isEmpty ( ) || musicUrl == null ) { Log . d ( TAG , "Invalid paramters" ) ; return ; } // Check if it is the baseline for BT off but streaming with speakers muted if ( extras . containsKey ( "BT_OFF_Mute" ) ) { Log . v ( TAG , "Mute is specified for BT off baseline case" ) ; bt_off_mute = true ; } else { if ( ! extras . containsKey ( "CodecType" ) ) { Log . e ( TAG , "No Codec Type specified" ) ; return ; }
public void testClientsCanConnect ( ) { NsdService service = makeService ( ) ; NsdManager client1 = connectClient ( service ) ; NsdManager client2 = connectClient ( service ) ; < |startfocus| > // TODO : disconnect client1 // TODO : disconnect client2 < |endfocus| >
} public MockPrintStream ( OutputStream os ) { super ( os ) ; } @Override public void clearError ( ) { super . clearError ( ) ; } @Override public void setError ( ) { super . setError ( ) ; } } /* * * { @link java . io . PrintStream#PrintStream ( String ) } */ public void test_Constructor_Ljava_lang_String ( ) throws IOException { PrintStream os = new PrintStream ( testFilePath ) ; os . print ( UNICODE_STRING ) ; os . close ( ) ; < |startfocus| > assertFileContents ( UNICODE_STRING . getBytes ( Charset . defaultCharset ( ) ) , testFile ) ; < |endfocus| > } /* * * { @link java . io . PrintStream#PrintStream ( String , String ) } */ public void test_Constructor_Ljava_lang_String_Ljava_lang_String ( ) throws Exception { // Test that a bogus charset is mentioned in the exception try { new PrintStream ( testFilePath , "Bogus" ) ; fail ( "Exception expected" ) ; } catch ( UnsupportedEncodingException e ) { assertNotNull ( e . getMessage ( ) ) ; } { PrintStream os = new PrintStream ( testFilePath , "utf - 8" ) ; os . print ( UNICODE_STRING ) ; os . close ( ) ;
public void test_ConstructorLjava_io_OutputStreamZLjava_lang_String ( ) throws Exception { try { new PrintStream ( new ByteArrayOutputStream ( ) , false , " % Illegal_name ! " ) ; fail ( "Expected UnsupportedEncodingException" ) ; } catch ( UnsupportedEncodingException e ) { // expected } { ByteArrayOutputStream bos = new ByteArrayOutputStream ( ) ; < |startfocus| > PrintStream printStream = new PrintStream ( bos , true /* autoFlush */ , "utf - 8" ) ; < |endfocus| > printStream . print ( UNICODE_STRING ) ; printStream . close ( ) ; assertByteArraysEqual ( UNICODE_STRING . getBytes ( StandardCharsets . UTF_8 ) , bos . toByteArray ( ) ) ; } { ByteArrayOutputStream bos = new ByteArrayOutputStream ( ) ; PrintStream printStream = new PrintStream ( bos , true /* autoFlush */ , "utf - 16" ) ; printStream . print ( UNICODE_STRING ) ; printStream . close ( ) ; assertByteArraysEqual ( UNICODE_STRING . getBytes ( StandardCharsets . UTF_16 ) , bos . toByteArray ( ) ) ; }
confirmConfiguration ( ) ; return ; } // Thread - unsafe access to mApfFilter but just used for debugging . final ApfFilter apfFilter = mApfFilter ; final ProvisioningConfiguration provisioningConfig = mConfiguration ; IndentingPrintWriter pw = new IndentingPrintWriter ( writer , " " ) ; pw . println ( mTag + " APF dump : " ) ; pw . increaseIndent ( ) ; if ( apfFilter != null ) { apfFilter . dump ( pw ) ; } else { < |startfocus| > if ( provisioningConfig != null ) { pw . println ( "No active ApfFilter ; provisioned capabilities : " + provisioningConfig . mApfCapabilities ) ; } else { pw . println ( "N / A -- no ProvisioningConfiguration available" ) ; } < |endfocus| > } pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + " current ProvisioningConfiguration : " ) ; pw . increaseIndent ( ) ; pw . println ( ( provisioningConfig != null ) ? provisioningConfig : "N / A" ) ; pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + " StateMachine dump : " ) ; pw . increaseIndent ( ) ; mLocalLog . readOnlyLocalLog ( ) . dump ( fd , pw , args ) ; pw . decreaseIndent ( ) ; pw . println ( ) ;
return ; } // Thread - unsafe access to mApfFilter but just used for debugging . final ApfFilter apfFilter = mApfFilter ; final ProvisioningConfiguration provisioningConfig = mConfiguration ; IndentingPrintWriter pw = new IndentingPrintWriter ( writer , " " ) ; pw . println ( mTag + " APF dump : " ) ; pw . increaseIndent ( ) ; if ( apfFilter != null ) { apfFilter . dump ( pw ) ; } else { < |startfocus| > if ( provisioningConfig != null ) { pw . println ( "No active ApfFilter ; provisioned capabilities : " + provisioningConfig . mApfCapabilities ) ; } else { pw . println ( "N / A -- no ProvisioningConfiguration available" ) ; } < |endfocus| > } pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + " current ProvisioningConfiguration : " ) ; pw . increaseIndent ( ) ; pw . println ( ( provisioningConfig != null ) ? provisioningConfig : "N / A" ) ; pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + " StateMachine dump : " ) ; pw . increaseIndent ( ) ; mLocalLog . readOnlyLocalLog ( ) . dump ( fd , pw , args ) ; pw . decreaseIndent ( ) ; pw . println ( ) ;
pw . increaseIndent ( ) ; if ( apfFilter != null ) { apfFilter . dump ( pw ) ; } else { if ( provisioningConfig != null ) { pw . println ( "No active ApfFilter ; provisioned capabilities : " + provisioningConfig . mApfCapabilities ) ; } else { pw . println ( "N / A -- no ProvisioningConfiguration available" ) ; } } pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + " current ProvisioningConfiguration : " ) ; pw . increaseIndent ( ) ; < |startfocus| > pw . println ( Objects . toString ( provisioningConfig , "N / A" ) ) ; < |endfocus| > pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + " StateMachine dump : " ) ; pw . increaseIndent ( ) ; mLocalLog . readOnlyLocalLog ( ) . dump ( fd , pw , args ) ; pw . decreaseIndent ( ) ; pw . println ( ) ; pw . println ( mTag + " connectivity packet log : " ) ; pw . println ( ) ; pw . println ( "Debug with python and scapy via : " ) ; pw . println ( "shell$ python" ) ; pw . println ( " > > > from scapy import all as scapy" ) ;
private int putListener ( Object listener , NsdServiceInfo s ) { checkListener ( listener ) ; final int key ; synchronized ( mMapLock ) { int valueIndex = mListenerMap . indexOfValue ( listener ) ; checkArgument ( valueIndex == - 1 , "listener already in use" ) ; < |startfocus| > key = mListenerKey ++ ; < |endfocus| > mListenerMap . put ( key , listener ) ; mServiceMap . put ( key , s ) ; } return key ;
public void onOwnAddressRead ( AdvertisingSet advertisingSet , int addressType , String address ) { Log . d ( "onOwnAddressRead" + mEventType + " " + setIndex ) ; Bundle results = new Bundle ( ) ; < |startfocus| > results . putInt ( "set_id" , setIndex ) ; < |endfocus| > results . putInt ( "address_type" , addressType ) ; results . putString ( "address" , address ) ; mEventFacade . postEvent ( mEventType + setIndex + "onOwnAddressRead" , results ) ;
public void run ( ) { < |startfocus| > byte [ ] annotatedDexContent = Base64 . getDecoder ( ) . decode ( base64DexWithExtensionClass ) ; InMemoryDexClassLoader classLoader = new InMemoryDexClassLoader ( ByteBuffer . wrap ( annotatedDexContent ) , ClassLoader . getSystemClassLoader ( ) ) ; < |endfocus| > Class < ? > klass = null ; try { klass = classLoader . loadClass ( classWithSourceDebugExtension ) ; } catch ( ClassNotFoundException e ) { logWriter . println ( " -- > Debuggee : Could not find class " + classWithSourceDebugExtension ) ; } synchronizer . sendMessage ( JPDADebuggeeSynchronizer . SGNL_READY ) ; logWriter . println ( " -- > Debuggee : SourceDebugExtensionDebuggee . . . " ) ; synchronizer . receiveMessage ( JPDADebuggeeSynchronizer . SGNL_CONTINUE ) ; }
import android . media . MediaDescription ; import android . media . MediaMetadata ; import android . media . AudioManager ; import android . media . session . MediaSessionManager ; import android . os . Bundle ; import android . os . Looper ; import android . test . AndroidTestCase ; import android . util . Log ; import java . nio . ByteBuffer ; import java . util . List ; import java . util . Arrays ; import java . util . ArrayList ; import static org . mockito . Mockito . isA ; import static org . mockito . Mockito . anyInt ; import static org . mockito . Mockito . mock ; import static org . mockito . Mockito . when ; public class AvrcpTest extends AndroidTestCase { < |startfocus| > @Override public void setUp ( ) { < |endfocus| > if ( Looper . myLooper ( ) == null ) Looper . prepare ( ) ; } public void testCanBuild ( ) { Avrcp a = Avrcp . make ( getContext ( ) ) ; } public void testFailedBrowseStart ( ) { Context mockContext = mock ( Context . class ) ; AudioManager mockAudioManager = mock ( AudioManager . class ) ; PackageManager mockPackageManager = mock ( PackageManager . class ) ; when ( mockAudioManager . getStreamMaxVolume ( AudioManager . STREAM_MUSIC ) ) . thenReturn ( 100 ) ; when ( mockContext . getSystemService ( Context . AUDIO_SERVICE ) ) . thenReturn ( mockAudioManager ) ; when ( mockContext . getPackageManager ( ) ) . thenReturn ( mockPackageManager ) ;
protected void setWifiConfigurationPassword ( WifiConfiguration wifiConfiguration , WifiSecurity wifiSecurity , String password ) { if ( wifiSecurity == WifiSecurity . WEP ) { int length = password . length ( ) ; // WEP - 40 , WEP - 104 , and 256 - bit WEP ( WEP - 232 ? ) < |startfocus| > if ( ( length == 10 || length == 26 || length == 58 ) < |endfocus| > && password . matches ( " [ 0 - 9A - Fa - f ] * " ) ) { wifiConfiguration . wepKeys [ 0 ] = password ; } else if ( length == 5 || length == 13 || length == 16 || length == 32 ) { wifiConfiguration . wepKeys [ 0 ] = '"' + password + '"' ; } } else { if ( wifiSecurity == WifiSecurity . PSK && password . length ( ) < FormPageDisplayer . PSK_MIN_LENGTH ) { return ; } if ( password . matches ( " [ 0 - 9A - Fa - f ] { 64 } " ) ) { wifiConfiguration . preSharedKey = password ; } else { wifiConfiguration . preSharedKey = '"' + password + '"' ; } }
protected void setWifiConfigurationPassword ( WifiConfiguration wifiConfiguration , WifiSecurity wifiSecurity , String password ) { if ( wifiSecurity == WifiSecurity . WEP ) { int length = password . length ( ) ; // WEP - 40 , WEP - 104 , and 256 - bit WEP ( WEP - 232 ? ) if ( ( length == 10 || length == 26 || length == 58 ) && password . matches ( " [ 0 - 9A - Fa - f ] * " ) ) { wifiConfiguration . wepKeys [ 0 ] = password ; < |startfocus| > } else if ( length == 5 || length == 13 || length == 16 ) { < |endfocus| > wifiConfiguration . wepKeys [ 0 ] = '"' + password + '"' ; } } else { if ( wifiSecurity == WifiSecurity . PSK && password . length ( ) < FormPageDisplayer . PSK_MIN_LENGTH ) { return ; } if ( password . matches ( " [ 0 - 9A - Fa - f ] { 64 } " ) ) { wifiConfiguration . preSharedKey = password ; } else { wifiConfiguration . preSharedKey = '"' + password + '"' ; } }
0x8888888877777777L ) ) ; assertEqual ( 5L , $noinline$LongNonmatCondCst_LongVarVar2 ( 0x7FFFFFFFFFFFFFFFL , 5L , 7L ) ) ; assertEqual ( 7L , $noinline$LongNonmatCondCst_LongVarVar2 ( 2L , 5L , 7L ) ) ; assertEqual ( 7L , $noinline$LongNonmatCondCst_LongVarVar3 ( 2L , 5L , 7L ) ) ; assertEqual ( 5L , $noinline$LongNonmatCondCst_LongVarVar4 ( 0L , 5L , 7L ) ) ; assertEqual ( 7L , $noinline$LongNonmatCondCst_LongVarVar4 ( 0xFFFFFFFF00000000L , 5L , 7L ) ) ; < |startfocus| > assertEqual ( 7L , $noinline$LongNonmatCondCst_LongVarVar5 ( 0L , 5L , 7L ) ) ; assertEqual ( 5L , $noinline$LongNonmatCondCst_LongVarVar5 ( 0xFFFFFFFF00000000L , 5L , 7L ) ) ; < |endfocus| > assertEqual ( 5L , $noinline$LongNonmatCondCst_LongVarVar6 ( 0L , 5L , 7L ) ) ; assertEqual ( 5L , $noinline$LongNonmatCondCst_LongVarVar6 ( 2L , 5L , 7L ) ) ; assertEqual ( 7L , $noinline$LongNonmatCondCst_LongVarVar6 ( - 9000L , 5L , 7L ) ) ; assertEqual ( 5L , $noinline$LongNonmatCondCst_LongVarVar7 ( 0L , 5L , 7L ) ) ; assertEqual ( 5L , $noinline$LongNonmatCondCst_LongVarVar7 ( 2L , 5L , 7L ) ) ; assertEqual ( 7L , $noinline$LongNonmatCondCst_LongVarVar7 ( - 9000L , 5L , 7L ) ) ;
protected SuggestionCursor getCurrentSuggestions ( ) { 	if ( mSearchActivityView . getSuggestions ( ) == null ) { 		return null ; 	 } 	 < |startfocus| > 	return mSearchActivityView . getSuggestions ( ) . getResult ( ) ; 	 < |endfocus| > }
// Make sure that core apps are optimized according to their own "reason" . // If the core apps are not preopted in the B OTA , and REASON_AB_OTA is not speed // ( by default is speed - profile ) they will be interepreted / JITed . This in itself is // not a problem as we will end up doing profile guided compilation . However , some // core apps may be loaded by system server which doesn't JIT and we need to make < |startfocus| > // sure we are not interpreting all their code in that process . < |endfocus| > int compilationReason = p . coreApp ? PackageManagerService . REASON_CORE_APP : PackageManagerService . REASON_AB_OTA ; mDexoptCommands . addAll ( generatePackageDexopts ( p , compilationReason ) ) ; } for ( PackageParser . Package p : others ) { // We assume here that there are no core apps left . if ( p . coreApp ) { throw new IllegalStateException ( "Found a core app that's not important" ) ; } mDexoptCommands . addAll ( generatePackageDexopts ( p , PackageManagerService . REASON_FIRST_BOOT ) ) ; } completeSize = mDexoptCommands . size ( ) ;
classLoader = getClassLoaderInitializedWithDexFile ( ) ; } else { classLoader = getClassLoaderInitializedWithClassFile ( ) ; } Class < ? > klass = null ; try { klass = classLoader . loadClass ( classWithSourceDebugExtension ) ; } catch ( ClassNotFoundException e ) { logWriter . println ( " -- > Debuggee : Could not find class " + classWithSourceDebugExtension ) ; } // Create an instance of classWithSourceDebugExtension so the < |startfocus| > // SourceDebugExntension metadata can be reported back to the debugger . < |endfocus| > Object o = null ; if ( klass != null ) { try { o = klass . getConstructor ( ) . newInstance ( ) ; } catch ( Exception e ) { logWriter . println ( " -- > Debuggee : Failed to instantiate " + classWithSourceDebugExtension + " : " + e ) ; } } synchronizer . sendMessage ( JPDADebuggeeSynchronizer . SGNL_READY ) ; logWriter . println ( " -- > Debuggee : SourceDebugExtensionDebuggee . . . " ) ; synchronizer . receiveMessage ( JPDADebuggeeSynchronizer . SGNL_CONTINUE ) ;
/* * * The MBMS middleware should send this when a download of single file has completed or * failed . Mandatory extras are * { @link #EXTRA_RESULT } * { @link #EXTRA_INFO } * { @link #EXTRA_REQUEST } * { @link #EXTRA_TEMP_LIST } * { @link #EXTRA_FINAL_URI } * * TODO : future systemapi */ public static final String ACTION_DOWNLOAD_COMPLETE = < |startfocus| > "android . telephony . mbms . action . DOWNLOAD_COMPLETE" ; < |endfocus| > /* * * The MBMS middleware should send this when it wishes to request { @code content :/ / } URIs to * serve as temp files for downloads or when it wishes to resume paused downloads . Mandatory * extras are * { @link #EXTRA_REQUEST } * * Optional extras are * { @link #EXTRA_FD_COUNT } ( 0 if not present ) * { @link #EXTRA_PAUSED_LIST } ( empty if not present ) * * TODO : future systemapi */ public static final String ACTION_FILE_DESCRIPTOR_REQUEST =
* * Optional extras are * { @link #EXTRA_FD_COUNT } ( 0 if not present ) * { @link #EXTRA_PAUSED_LIST } ( empty if not present ) * * TODO : future systemapi */ public static final String ACTION_FILE_DESCRIPTOR_REQUEST = "android . telephony . mbms . ACTION_FILE_DESCRIPTOR_REQUEST" ; /* * < |startfocus| > * The MBMS middleware sends this when it wishes to cleanup temporary files in the app's filesystem . * Mandatory extras are < |endfocus| > * { @link #EXTRA_TEMP_FILES_IN_USE } * * TODO : future systemapi */ public static final String ACTION_CLEANUP = "android . telephony . mbms . ACTION_CLEANUP" ; /* * * Integer extra indicating the result code of the download . * TODO : put in link to error list * TODO : future systemapi ( here and and all extras ) */ public static final String EXTRA_RESULT = "android . telephony . mbms . EXTRA_RESULT" ; /* * * Extra containing the { @link android . telephony . mbms . FileInfo } for which the download result
* * TODO : future systemapi */ public static final String ACTION_FILE_DESCRIPTOR_REQUEST = "android . telephony . mbms . ACTION_FILE_DESCRIPTOR_REQUEST" ; /* * * The MBMS middleware should send this when it wishes to signal that there may be orphaned * files in the app's filesystem . Mandatory extras are * { @link #EXTRA_TEMP_FILES_IN_USE } * * TODO : future systemapi */ public static final String ACTION_CLEANUP = < |startfocus| > "android . telephony . mbms . action . CLEANUP_TEMP_FILES" ; < |endfocus| > /* * * Integer extra indicating the result code of the download . * TODO : put in link to error list * TODO : future systemapi ( here and and all extras ) */ public static final String EXTRA_RESULT = "android . telephony . mbms . EXTRA_RESULT" ; /* * * Extra containing the { @link android . telephony . mbms . FileInfo } for which the download result * is for . Must not be null . */ public static final String EXTRA_INFO = "android . telephony . mbms . EXTRA_INFO" ; /* *
* files in the app's filesystem . Mandatory extras are * { @link #EXTRA_TEMP_FILES_IN_USE } * * TODO : future systemapi */ public static final String ACTION_CLEANUP = "android . telephony . mbms . ACTION_CLEANUP" ; /* * * Integer extra indicating the result code of the download . * TODO : put in link to error list * TODO : future systemapi ( here and and all extras ) */ < |startfocus| > public static final String EXTRA_RESULT = "android . telephony . mbms . extra . RESULT" ; < |endfocus| > /* * * Extra containing the { @link android . telephony . mbms . FileInfo } for which the download result * is for . Must not be null . */ public static final String EXTRA_INFO = "android . telephony . mbms . EXTRA_INFO" ; /* * * Extra containing the { @link DownloadRequest } for which the download result or file * descriptor request is for . Must not be null . */ public static final String EXTRA_REQUEST = "android . telephony . mbms . EXTRA_REQUEST" ; /* *
* decoded downloaded file resides . Must not be null . */ public static final String EXTRA_FINAL_URI = "android . telephony . mbms . EXTRA_FINAL_URI" ; /* * * Extra containing an integer indicating the number of temp files requested . */ public static final String EXTRA_FD_COUNT = "android . telephony . mbms . EXTRA_FD_COUNT" ; /* * * Extra containing a list of { @link Uri } s that the middleware is requesting write access to . */ public static final String EXTRA_PAUSED_LIST = "android . telephony . mbms . EXTRA_PAUSED_LIST" ; /* * * Extra containing a list of { @link android . telephony . mbms . UriPathPair } s , used in the * response to { @link #ACTION_FILE_DESCRIPTOR_REQUEST } . These are temp files that are meant * to be used for new file downloads . */ public static final String EXTRA_FREE_URI_LIST = "android . telephony . mbms . EXTRA_FREE_URI_LIST" ; /* * * Extra containing a list of { @link android . telephony . mbms . UriPathPair } s , used in the
* decoded downloaded file resides . Must not be null . */ public static final String EXTRA_FINAL_URI = "android . telephony . mbms . EXTRA_FINAL_URI" ; /* * * Extra containing an integer indicating the number of temp files requested . */ public static final String EXTRA_FD_COUNT = "android . telephony . mbms . EXTRA_FD_COUNT" ; /* * * Extra containing a list of { @link Uri } s that the middleware is requesting write access to . */ < |startfocus| > public static final String EXTRA_PAUSED_LIST = "android . telephony . mbms . EXTRA_PAUSED_LIST" ; < |endfocus| > /* * * Extra containing a list of { @link android . telephony . mbms . UriPathPair } s , used in the * response to { @link #ACTION_FILE_DESCRIPTOR_REQUEST } . These are temp files that are meant * to be used for new file downloads . */ public static final String EXTRA_FREE_URI_LIST = "android . telephony . mbms . EXTRA_FREE_URI_LIST" ; /* * * Extra containing a list of { @link android . telephony . mbms . UriPathPair } s , used in the * response to { @link #ACTION_FILE_DESCRIPTOR_REQUEST } . These are temp files that are meant * to be used for new file downloads . */ public static final String EXTRA_FREE_URI_LIST = "android . telephony . mbms . EXTRA_FREE_URI_LIST" ; /* * * Extra containing a list of { @link android . telephony . mbms . UriPathPair } s , used in the * response to { @link #ACTION_FILE_DESCRIPTOR_REQUEST } . These are temp files that are meant * to be used for new file downloads . */ public static final String EXTRA_FREE_URI_LIST = "android . telephony . mbms . EXTRA_FREE_URI_LIST" ; /* * * Extra containing a list of { @link android . telephony . mbms . UriPathPair } s , used in the
* still using . */ public static final String EXTRA_TEMP_FILES_IN_USE = "android . telephony . mbms . EXTRA_TEMP_FILES_IN_USE" ; public static final int RESULT_SUCCESSFUL = 1 ; public static final int RESULT_CANCELLED = 2 ; public static final int RESULT_EXPIRED = 3 ; // TODO - more results ! private final Context mContext ; private int mSubId = INVALID_SUBSCRIPTION_ID ; private IMbmsDownloadService mService ; < |startfocus| > private final IMbmsDownloadManagerCallback mCallback ; < |endfocus| > private final String mDownloadAppName ; public MbmsDownloadManager ( Context context , IMbmsDownloadManagerCallback callback , String downloadAppName , int subId ) { mContext = context ; mCallback = callback ; mDownloadAppName = downloadAppName ; mSubId = subId ; } /* * * Create a new MbmsDownloadManager using the system default data subscription ID . * * Note that this call will bind a remote service and that may take a bit . This * may throw an Illegal ArgumentException or RemoteException . * * @hide */
< |startfocus| > private MbmsDownloadManager ( Context context , IMbmsDownloadManagerListener callback , < |endfocus| > String downloadAppName , int subId ) { mContext = context ; mCallback = callback ; mDownloadAppName = downloadAppName ; mSubId = subId ;
< |startfocus| > private MbmsStreamingManager ( Context context , IMbmsStreamingManagerListener listener , String streamingAppName , int subId ) { < |endfocus| > mContext = context ; mAppName = streamingAppName ; mCallbackToApp = listener ; mSubId = subId ;
< |startfocus| > public MbmsStreamingManager ( Context context , IMbmsStreamingManagerListener listener , String streamingAppName , int subscriptionId ) { < |endfocus| > mContext = context ; mAppName = streamingAppName ; mCallbackToApp = listener ; mSubscriptionId = subscriptionId ;
mBrightnessMode != brightnessMode ) { if ( DEBUG ) Slog . v ( TAG , "setLight #" + mId + " : color = #" + Integer . toHexString ( color ) + " : brightnessMode = " + brightnessMode ) ; mLastColor = mColor ; mColor = color ; mMode = mode ; mOnMS = onMS ; mOffMS = offMS ; mBrightnessMode = brightnessMode ; < |startfocus| > mInitialized = true ; Trace . traceBegin ( Trace . TRACE_TAG_POWER , "setLight ( " + mId + " , 0x" + Integer . toHexString ( color ) + " ) " ) ; try { setLight_native ( mNativePointer , mId , color , mode , onMS , offMS , brightnessMode ) ; } finally { Trace . traceEnd ( Trace . TRACE_TAG_POWER ) ; } < |endfocus| > }
public static boolean contactsLoaded = false ; private static HashMap < String , ArrayList < String > > email = new HashMap < String , ArrayList < String > > ( ) ; private static HashMap < String , ArrayList < String > > phone = new HashMap < String , ArrayList < String > > ( ) ; private static HashMap < String , ArrayList < String > > address = new HashMap < String , ArrayList < String > > ( ) ; private static HashMap < String , String > name = new HashMap < String , String > ( ) ; private static HashSet < String > ContactSet = new HashSet < String > ( ) ; < |startfocus| > < |endfocus| > public static boolean hasFilter ( byte [ ] filter ) { return filter != null && filter . length > 0 ; } public static boolean isNameAndNumberOnly ( byte [ ] filter ) { // For vcard 2 . 0 : VERSION , N , TEL is mandatory // For vcard 3 . 0 , VERSION , N , FN , TEL is mandatory // So we only need to make sure that no other fields except optionally // NICKNAME is set // Check that an explicit filter is not set . If not , this means // return everything if ( ! hasFilter ( filter ) ) {
} public NetworkStats readNetworkStatsDetail ( int limitUid , String [ ] limitIfaces , int limitTag , NetworkStats lastStats ) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal ( limitUid , limitIfaces , limitTag , lastStats ) ; NetworkStats . Entry entry = null ; // for recycling synchronized ( sStackedIfaces ) { < |startfocus| > // For 464xlat traffic , xt_qtaguid sees every IPv4 packets twice , once as an IPv4 packet // unwrapped on the stacked interface , and once as wrapped inside an IPv6 packet on the // base interface . For correct stats accounting on the base interface , every 464xlat // packets needs to be subtracted for the root UID on the base interface both for tx // and rx traffic ( http :/ / b / 12249687 , http :/ b / 33681750 ) . final int size = sStackedIfaces . size ( ) ; for ( int i = 0 ; i < size ; i ++ ) { final String stackedIface = sStackedIfaces . keyAt ( i ) ; final String baseIface = sStackedIfaces . valueAt ( i ) ; NetworkStats . Entry adjust = < |endfocus| >
NetworkStats lastStats ) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal ( limitUid , limitIfaces , limitTag , lastStats ) ; NetworkStats . Entry entry = null ; // for recycling synchronized ( sStackedIfaces ) { // For 464xlat traffic , xt_qtaguid sees every IPv4 packets twice , once as an IPv4 packet // unwrapped on the stacked interface , and once as wrapped inside an IPv6 packet on the // base interface . For correct stats accounting on the base interface , every 464xlat < |startfocus| > // packets needs to be subtracted for the root UID on the base interface both for tx < |endfocus| > // and rx traffic ( http :/ / b / 12249687 , http :/ b / 33681750 ) . final int size = sStackedIfaces . size ( ) ; for ( int i = 0 ; i < size ; i ++ ) { final String stackedIface = sStackedIfaces . keyAt ( i ) ; final String baseIface = sStackedIfaces . valueAt ( i ) ; NetworkStats . Entry adjust = new NetworkStats . Entry ( baseIface , 0 , 0 , 0 , 0L , 0L , 0L , 0L , 0L ) ;
NetworkStats lastStats ) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal ( limitUid , limitIfaces , limitTag , lastStats ) ; NetworkStats . Entry entry = null ; // for recycling synchronized ( sStackedIfaces ) { // For 464xlat traffic , xt_qtaguid sees every IPv4 packets twice , once as an IPv4 packet // unwrapped on the stacked interface , and once as wrapped inside an IPv6 packet on the // base interface . For correct stats accounting on the base interface , every 464xlat < |startfocus| > // packets needs to be subtracted for the root UID on the base interface both for tx < |endfocus| > // and rx traffic ( http :/ / b / 12249687 , http :/ b / 33681750 ) . final int size = sStackedIfaces . size ( ) ; for ( int i = 0 ; i < size ; i ++ ) { final String stackedIface = sStackedIfaces . keyAt ( i ) ; final String baseIface = sStackedIfaces . valueAt ( i ) ; NetworkStats . Entry adjust = new NetworkStats . Entry ( baseIface , 0 , 0 , 0 , 0L , 0L , 0L , 0L , 0L ) ;
readNetworkStatsDetailInternal ( limitUid , limitIfaces , limitTag , lastStats ) ; NetworkStats . Entry entry = null ; // for recycling synchronized ( sStackedIfaces ) { // For 464xlat traffic , xt_qtaguid sees every IPv4 packets twice , once as an IPv4 packet // unwrapped on the stacked interface , and once as wrapped inside an IPv6 packet on the // base interface . For correct stats accounting on the base interface , every 464xlat < |startfocus| > // packets needs to be subtracted for the root UID on the base interface both for tx < |endfocus| > // and rx traffic ( http :/ / b / 12249687 , http :/ b / 33681750 ) . final int size = sStackedIfaces . size ( ) ; for ( int i = 0 ; i < size ; i ++ ) { final String stackedIface = sStackedIfaces . keyAt ( i ) ; final String baseIface = sStackedIfaces . valueAt ( i ) ; NetworkStats . Entry adjust = new NetworkStats . Entry ( baseIface , 0 , 0 , 0 , 0L , 0L , 0L , 0L , 0L ) ; for ( int j = 0 ; j < stats . size ( ) ; j ++ ) { < |startfocus| >
readNetworkStatsDetailInternal ( limitUid , limitIfaces , limitTag , lastStats ) ; NetworkStats . Entry entry = null ; // for recycling synchronized ( sStackedIfaces ) { // For 464xlat traffic , xt_qtaguid sees every IPv4 packets twice , once as an IPv4 packet // unwrapped on the stacked interface , and once as wrapped inside an IPv6 packet on the // base interface . For correct stats accounting on the base interface , every 464xlat < |startfocus| > // packets needs to be subtracted for the root UID on the base interface both for tx < |endfocus| > // and rx traffic ( http :/ / b / 12249687 , http :/ b / 33681750 ) . final int size = sStackedIfaces . size ( ) ; for ( int i = 0 ; i < size ; i ++ ) { final String stackedIface = sStackedIfaces . keyAt ( i ) ; final String baseIface = sStackedIfaces . valueAt ( i ) ; NetworkStats . Entry adjust = new NetworkStats . Entry ( baseIface , 0 , 0 , 0 , 0L , 0L , 0L , 0L , 0L ) ; for ( int j = 0 ; j < stats . size ( ) ; j ++ ) { < |startfocus| > if ( stackedIface . equals ( stats . getValues ( j , null ) . iface ) ) { adjust . rxPackets += stats . getValues ( j , null ) . rxPackets ; adjust . txPackets += stats . getValues ( j , null ) . txPackets ; } < |endfocus| > }
for ( int j = 0 ; j < stats . size ( ) ; j ++ ) { entry = stats . getValues ( j , entry ) ; if ( Objects . equals ( entry . iface , stackedIface ) ) { adjust . rxBytes -= ( entry . rxBytes + entry . rxPackets * IPV4V6_HEADER_DELTA ) ; adjust . txBytes -= ( entry . txBytes + entry . txPackets * IPV4V6_HEADER_DELTA ) ; adjust . rxPackets -= entry . rxPackets ; adjust . txPackets -= entry . txPackets ; } } stats . combineValues ( adjust ) ; } } // For 464xlat traffic , xt_qtaguid only counts the bytes of the inner IPv4 packet sent on // the stacked interface with prefix "v4 - " and drops the IPv6 header size after unwrapping . // To account correctly for on - the - wire traffic , adds the 20 additional bytes difference // for all packets ( http :/ / b / 12249687 , http :/ b / 33681750 ) . for ( int i = 0 ; i < stats . size ( ) ; i ++ ) { entry = stats . getValues ( i , entry ) ;
adjust . rxPackets -= entry . rxPackets ; adjust . txPackets -= entry . txPackets ; // TODO : does Entry#operations need to be adjusted too ? } } stats . combineValues ( adjust ) ; } } // For 464xlat traffic , xt_qtaguid only counts the bytes of the inner IPv4 packet sent on // the stacked interface with prefix "v4 - " and drops the IPv6 header size after unwrapping . < |startfocus| > // To account correctly for on - the - wire traffic , adds the 20 additional bytes difference < |endfocus| > // for all packets ( http :/ / b / 12249687 , http :/ b / 33681750 ) . for ( int i = 0 ; i < stats . size ( ) ; i ++ ) { entry = stats . getValues ( i , entry ) ; if ( entry . iface != null && entry . iface . startsWith ( CLATD_INTERFACE_PREFIX ) ) { entry . rxBytes = entry . rxPackets * IPV4V6_HEADER_DELTA ; entry . txBytes = entry . txPackets * IPV4V6_HEADER_DELTA ; entry . rxPackets = 0 ; entry . txPackets = 0 ; stats . combineValues ( entry ) ; } } return stats ; }
private static final String CLATD_INTEFACE_PREFIX = "v4 - " ; /* * Path to { @code / proc / net / xt_qtaguid / iface_stat_all } . */ private final File mStatsXtIfaceAll ; /* * Path to { @code / proc / net / xt_qtaguid / iface_stat_fmt } . */ private final File mStatsXtIfaceFmt ; /* * Path to { @code / proc / net / xt_qtaguid / stats } . */ private final File mStatsXtUid ; < |startfocus| > // TODO : for testability , do not use a static variable . < |endfocus| > @GuardedBy ( "sStackedIfaces" ) private static final ArrayMap < String , String > sStackedIfaces = new ArrayMap < > ( ) ; public static void noteStackedIface ( String stackedIface , String baseIface ) { synchronized ( sStackedIfaces ) { if ( baseIface != null ) { sStackedIfaces . put ( stackedIface , baseIface ) ; } else { sStackedIfaces . remove ( stackedIface ) ; } } } public NetworkStatsFactory ( ) { this ( new File ( " / proc / " ) ) ; } @VisibleForTesting public NetworkStatsFactory ( File procRoot ) {
// from root UID on the base interface . NetworkStats . Entry adjust = new NetworkStats . Entry ( baseIface , 0 , 0 , 0 , 0L , 0L , 0L , 0L , 0L ) ; for ( int j = 0 ; j < stats . size ( ) ; j ++ ) { entry = stats . getValues ( j , entry ) ; if ( Objects . equals ( entry . iface , stackedIface ) ) { < |startfocus| > adjust . add ( entry . txBytes , entry . txPackets , entry . rxBytes , entry . rxPackets ) ; < |endfocus| > } } stats . combineValues ( adjust ) ; } } // Double sigh , all rx traffic on clat needs to be tweaked to // account for the dropped IPv6 header size post - unwrap . for ( int i = 0 ; i < stats . size ( ) ; i ++ ) { entry = stats . getValues ( i , entry ) ; if ( entry . iface != null && entry . iface . startsWith ( CLATD_INTEFACE_PREFIX ) ) { // Delta between IPv4 header ( 20b ) and IPv6 header ( 40b ) entry . rxBytes = entry . rxPackets * 20 ;
private void sendNsdStateChangeBroadcast ( boolean isEnabled ) { final Intent intent = new Intent ( NsdManager . ACTION_NSD_STATE_CHANGED ) ; intent . addFlags ( Intent . FLAG_RECEIVER_REGISTERED_ONLY_BEFORE_BOOT ) ; < |startfocus| > intent . putExtra ( NsdManager . EXTRA_NSD_STATE , isEnabled ? NsdManager . NSD_STATE_ENABLED : NsdManager . NSD_STATE_DISABLED ) ; < |endfocus| > mContext . sendStickyBroadcastAsUser ( intent , UserHandle . ALL ) ;
for ( String conscryptAlg : conscryptAlgs ) { Provider . Service service = getService ( bc , conscryptAlg ) ; if ( service != null ) { bcClasses . add ( service . getClassName ( ) ) ; } } assertTrue ( bcClasses . size ( ) > 0 ) ; // Sanity check // 3 . Determine which IDs in BC point to that set of classes Set < String > shouldBeOverriddenBcIds = new HashSet < > ( ) ; < |startfocus| > for ( String key : bc . keySet ( ) ) { < |endfocus| > if ( key . contains ( " " ) ) { continue ; } if ( key . startsWith ( "Alg . Alias . " ) ) { key = key . substring ( "Alg . Alias . " . length ( ) ) ; } Provider . Service service = getService ( bc , key ) ; if ( bcClasses . contains ( service . getClassName ( ) ) ) { shouldBeOverriddenBcIds . add ( key ) ; } } // 4 . Check each of those IDs to ensure that it's present in Conscrypt Set < String > nonOverriddenIds = new TreeSet < > ( ) ; for ( String shouldBeOverridenBcId : shouldBeOverriddenBcIds ) {
return s ; } catch ( IOException e ) { // should not occur throw new RuntimeException ( "AVA error : " + e , e ) ; } } private static DerValue parseHexString ( Reader in , int format ) throws IOException { int c ; ByteArrayOutputStream baos = new ByteArrayOutputStream ( ) ; byte b = 0 ; int cNdx = 0 ; while ( true ) { c = in . read ( ) ; if ( isTerminator ( c , format ) ) { break ; } < |startfocus| > // BEGIN Android - added : AVA : Support DerValue hex strings that contain ' ' or '\n' < |endfocus| > if ( c == ' ' || c == '\n' ) { do { if ( c != ' ' && c != '\n' ) { throw new IOException ( "AVA parse , invalid hex " + "digit : " + ( char ) c ) ; } c = in . read ( ) ; } while ( ! isTerminator ( c , format ) ) ; break ; } int cVal = hexDigits . indexOf ( Character . toUpperCase ( ( char ) c ) ) ; if ( cVal == - 1 ) { throw new IOException ( "AVA parse , invalid hex " +
while ( true ) { c = in . read ( ) ; if ( isTerminator ( c , format ) ) { break ; } // Android - changed : Skip trailing whitespace . if ( c == ' ' || c == '\n' ) { do { if ( c != ' ' && c != '\n' ) { throw new IOException ( "AVA parse , invalid hex " + "digit : " + ( char ) c ) ; } c = in . read ( ) ; } while ( ! isTerminator ( c , format ) ) ; break ; } < |startfocus| > < |endfocus| > int cVal = hexDigits . indexOf ( Character . toUpperCase ( ( char ) c ) ) ; if ( cVal == - 1 ) { throw new IOException ( "AVA parse , invalid hex " + "digit : " + ( char ) c ) ; } if ( ( cNdx % 2 ) == 1 ) { b = ( byte ) ( ( b * 16 ) + ( byte ) ( cVal ) ) ; baos . write ( b ) ; } else { b = ( byte ) ( cVal ) ; } cNdx ++ ; } // throw exception if no hex digits // END Android - added : AVA : Support DerValue hex strings that contain ' ' or '\n' in line 285 .
temp . append ( hexString ) ; embeddedHex . clear ( ) ; } do { c = in . read ( ) ; } while ( ( c == '\n' ) || ( c == ' ' ) ) ; if ( c != - 1 ) { throw new IOException ( "AVA had characters other than " + "whitespace after terminating quote" ) ; } // encode as PrintableString unless value contains // non - PrintableString chars < |startfocus| > // Android - changed : Do not trim ( ) DerValue strings . < |endfocus| > if ( this . oid . equals ( ( Object ) PKCS9Attribute . EMAIL_ADDRESS_OID ) || ( this . oid . equals ( ( Object ) X500Name . DOMAIN_COMPONENT_OID ) && PRESERVE_OLD_DC_ENCODING == false ) ) { // EmailAddress and DomainComponent must be IA5String return new DerValue ( DerValue . tag_IA5String , temp . toString ( ) ) ; } else if ( isPrintableString ) { return new DerValue ( temp . toString ( ) ) ; } else { return new DerValue ( DerValue . tag_UTF8String , temp . toString ( ) ) ; } } private DerValue parseString
* This class is not a general repository for OIDs , or for such string names . * Note that the mappings between algorithm IDs and algorithm names is * not one - to - one . * * * @author David Brownell * @author Amit Kapoor * @author Hemma Prafullchandra */ public class AlgorithmId implements Serializable , DerEncoder { /* * use serialVersionUID from JDK 1 . 1 . for interoperability */ private static final long serialVersionUID = 7205873507486557157L ; /* * * The object identitifer being used for this algorithm . */ private ObjectIdentifier algid ; // The ( parsed ) parameters private AlgorithmParameters algParams ; private boolean constructedFromDer = true ; /* * * Parameters for this algorithm . These are stored in unparsed * DER - encoded form ; subclasses can be made to automaticaly parse
private static final String OCSPNOCHECK = ROOT + " . " + OCSPNoCheckExtension . NAME ; private static final int NetscapeCertType_data [ ] = { 2 , 16 , 840 , 1 , 113730 , 1 , 1 } ; /* * Map ObjectIdentifier ( oid ) - > OIDInfo ( info ) */ private final static Map < ObjectIdentifier , OIDInfo > oidMap ; /* * Map String ( friendly name ) - > OIDInfo ( info ) */ private final static Map < String , OIDInfo > nameMap ; < |startfocus| > // BEGIN Android - changed : Specify Class objects rather for oidMap rather than String literals + reflection . < |endfocus| > static { oidMap = new HashMap < ObjectIdentifier , OIDInfo > ( ) ; nameMap = new HashMap < String , OIDInfo > ( ) ; addInternal ( SUB_KEY_IDENTIFIER , PKIXExtensions . SubjectKey_Id , SubjectKeyIdentifierExtension . class ) ; addInternal ( KEY_USAGE , PKIXExtensions . KeyUsage_Id , KeyUsageExtension . class ) ; addInternal ( PRIVATE_KEY_USAGE , PKIXExtensions . PrivateKeyUsage_Id , PrivateKeyUsageExtension . class ) ; addInternal ( SUB_ALT_NAME , PKIXExtensions . SubjectAlternativeName_Id , SubjectAlternativeNameExtension . class ) ; addInternal ( ISSUER_ALT_NAME , PKIXExtensions . IssuerAlternativeName_Id , IssuerAlternativeNameExtension . class ) ; addInternal ( BASIC_CONSTRAINTS , PKIXExtensions . BasicConstraints_Id ,
SubjectInfoAccessExtension . class ) ; addInternal ( AUTH_INFO_ACCESS , PKIXExtensions . AuthInfoAccess_Id , AuthorityInfoAccessExtension . class ) ; addInternal ( ISSUING_DIST_POINT , PKIXExtensions . IssuingDistributionPoint_Id , IssuingDistributionPointExtension . class ) ; addInternal ( DELTA_CRL_INDICATOR , PKIXExtensions . DeltaCRLIndicator_Id , DeltaCRLIndicatorExtension . class ) ; addInternal ( FRESHEST_CRL , PKIXExtensions . FreshestCRL_Id , FreshestCRLExtension . class ) ; addInternal ( OCSPNOCHECK , PKIXExtensions . OCSPNoCheck_Id , OCSPNoCheckExtension . class ) ; } < |startfocus| > // END Android - changed : Hardcode class names in OIDMap to fix proguard issues < |endfocus| > /* * * Add attributes to the table . For internal use in the static * initializer . */ private static void addInternal ( String name , ObjectIdentifier oid , Class clazz ) { OIDInfo info = new OIDInfo ( name , oid , clazz ) ; oidMap . put ( oid , info ) ; nameMap . put ( name , info ) ; } /* * * Inner class encapsulating the mapping info and Class loading . */ private static class OIDInfo { final ObjectIdentifier oid ; final String name ; private volatile Class < ? > clazz ; OIDInfo ( String name , ObjectIdentifier oid , Class < ? > clazz ) { this . oid = oid ; this . name = name ; this . clazz = clazz ; } Class < ? > getClazz ( ) { if ( clazz == null ) { synchronized ( this ) { if ( clazz == null ) { try { clazz = Class . forName ( clazz . getName ( ) ) ; } catch ( ClassNotFoundException e ) { // ignore } } } } return clazz ; } } }
private AVAComparator ( ) { // empty } static Comparator < AVA > getInstance ( ) { return INSTANCE ; } /* * * AVA's containing a standard keyword are ordered alphabetically , * followed by AVA's containing an OID keyword , ordered numerically */ public int compare ( AVA a1 , AVA a2 ) { boolean a1Has2253 = a1 . hasRFC2253Keyword ( ) ; boolean a2Has2253 = a2 . hasRFC2253Keyword ( ) ; < |startfocus| > // BEGIN Android - changed : Keep sort order of RDN from prev impl < |endfocus| > if ( a1Has2253 ) { if ( a2Has2253 ) { return a1 . toRFC2253CanonicalString ( ) . compareTo ( a2 . toRFC2253CanonicalString ( ) ) ; } else { return - 1 ; } } else { if ( a2Has2253 ) { return 1 ; } else { int [ ] a1Oid = a1 . getObjectIdentifier ( ) . toIntArray ( ) ; int [ ] a2Oid = a2 . getObjectIdentifier ( ) . toIntArray ( ) ; int pos = 0 ; int len = ( a1Oid . length > a2Oid . length ) ? a2Oid . length : a1Oid . length ; while ( pos < len ) { if ( a1Oid [ pos ] > a2Oid [ pos ] ) { return 1 ; } else if ( a1Oid [ pos ] < a2Oid [ pos ] ) { return - 1 ; } pos ++ ; } if ( a1Oid . length > a2Oid . length ) { return 1 ; } else if ( a1Oid . length < a2Oid . length ) { return - 1 ; } else { return 0 ; } } } } }
* distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . android . nfc ; import android . content . BroadcastReceiver ; import android . content . Context ; import android . content . Intent ; import android . content . pm . PackageManager ; /* * * Boot completed receiver . used to diable the application if the device doesn't * support NFC when device boots . * */ public class NfcBootCompletedReceiver extends BroadcastReceiver { @Override public void onReceive ( Context context , Intent intent ) { String action = intent . getAction ( ) ; if ( action == null ) { return ; } if ( action . equals ( Intent . ACTION_BOOT_COMPLETED ) ) { PackageManager pm = context . getPackageManager ( ) ; if ( ! pm . hasSystemFeature ( PackageManager . FEATURE_NFC ) ) { pm . setApplicationEnabledSetting ( context . getPackageName ( ) , PackageManager . COMPONENT_ENABLED_STATE_DISABLED , 0 ) ; } } } }
public void onReceive ( Context context , Intent intent ) { String action = intent . getAction ( ) ; if ( action == null ) { return ; } < |startfocus| > if ( Intent . ACTION_BOOT_COMPLETED . equals ( action ) ) { < |endfocus| > PackageManager pm = context . getPackageManager ( ) ; if ( ! pm . hasSystemFeature ( PackageManager . FEATURE_NFC ) ) { pm . setApplicationEnabledSetting ( context . getPackageName ( ) , PackageManager . COMPONENT_ENABLED_STATE_DISABLED , 0 ) ; } }
public void onReceive ( Context context , Intent intent ) { String action = intent . getAction ( ) ; if ( action == null ) { return ; } if ( action . equals ( Intent . ACTION_BOOT_COMPLETED ) ) { PackageManager pm = context . getPackageManager ( ) ; < |startfocus| > if ( ! pm . hasSystemFeature ( PackageManager . FEATURE_NFC_ANY ) ) { < |endfocus| > pm . setApplicationEnabledSetting ( context . getPackageName ( ) , PackageManager . COMPONENT_ENABLED_STATE_DISABLED , 0 ) ; } }
NetworkStats lastStats ) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal ( limitUid , limitIfaces , limitTag , lastStats ) ; NetworkStats . Entry entry = null ; // for recycling synchronized ( sStackedIfaces ) { // Sigh , xt_qtaguid ends up double - counting tx traffic going through // clatd interfaces , so we need to subtract it here . final int size = sStackedIfaces . size ( ) ; for ( int i = 0 ; i < size ; i ++ ) { final String stackedIface = sStackedIfaces . keyAt ( i ) ; final String baseIface = sStackedIfaces . valueAt ( i ) ; < |startfocus| > // Count up tx ( http :/ / b / 12249687 ) and rx ( http :/ b / 33681750 ) traffic and subtract // from root UID on the base interface . NetworkStats . Entry adjust = < |endfocus| > new NetworkStats . Entry ( baseIface , 0 , 0 , 0 , 0L , 0L , 0L , 0L , 0L ) ; for ( int j = 0 ; j < stats . size ( ) ; j ++ ) { entry = stats . getValues ( j , entry ) ; if ( Objects . equals ( entry . iface , stackedIface ) ) {
*/ public static native String getOsVersion ( ) ; /* * * @return hardware id extracted from uname ( ) native call */ public static native String getHardwareId ( ) ; /* * * @return kernel version extracted from uname ( ) native call */ public static native String getKernelVersion ( ) ; /* * * @return sysprop ro . boot . avb_version */ public static native String getBootAvbVersion ( ) ; /* * < |startfocus| > * @return sysprop ro . boot . vbmeta . avb_version < |endfocus| > */ public static native String getBootVbmetaAvbVersion ( ) ; }
private void setLightLocked ( int color , int mode , int onMS , int offMS , int brightnessMode ) { 	if ( shouldBeInLowPersistenceMode ( ) ) { 		brightnessMode = BRIGHTNESS_MODE_LOW_PERSISTENCE ; 	 } else if ( brightnessMode == BRIGHTNESS_MODE_LOW_PERSISTENCE ) { 		brightnessMode = mLastBrightnessMode ; 	 } 	 < |startfocus| > 	if ( ! mInitialized || color != mColor || mode != mMode || onMS != mOnMS || offMS != mOffMS || mBrightnessMode != brightnessMode ) { 	 < |endfocus| > 	if ( DEBUG ) Slog . v ( TAG , "setLight #" + mId + " : color = #" + Integer . toHexString ( color ) + " : brightnessMode = " + brightnessMode ) ; 	mInitialized = true ; 	mLastColor = mColor ; 	mColor = color ; 	mMode = mode ; 	mOnMS = onMS ; 	mOffMS = offMS ; 	mBrightnessMode = brightnessMode ; 	Trace . traceBegin ( Trace . TRACE_TAG_POWER , "setLight ( " + mId + " , 0x" + Integer . toHexString ( color ) + " ) " ) ; 	try {
private int putListener ( Object listener , NsdServiceInfo s ) { checkListener ( listener ) ; final int key ; synchronized ( mMapLock ) { int valueIndex = mListenerMap . indexOfValue ( listener ) ; checkArgument ( valueIndex == - 1 , "listener already in use" ) ; < |startfocus| > key = mListenerKey ++ ; < |endfocus| > mListenerMap . put ( key , listener ) ; mServiceMap . put ( key , s ) ; } return key ;
public int initialize ( IMbmsStreamingManagerCallback listener , String appName , int subId ) { String appKey = appName + subId ; if ( ! mAppCallbacks . containsKey ( appKey ) ) { mAppCallbacks . put ( appKey , listener ) ; } else { return MbmsException . ERROR_ALREADY_INITIALIZED ; } < |startfocus| > return 0 ; < |endfocus| >
@Override public boolean isTrue ( ) throws UiObjectNotFoundException { return device . findObject ( new UiSelector ( ) . resourceId ( Res . GOOGLE_PLAY_INPUT_RES ) ) . exists ( ) ; } } ) ; if ( inputTextFieldExists ) { UiObject inputTextField = device . findObject ( new UiSelector ( ) . resourceId ( Res . GOOGLE_PLAY_INPUT_RES ) ) ; inputTextField . clearTextField ( ) ; inputTextField . setText ( application ) ; device . pressEnter ( ) ; } } /* * < |startfocus| > * Selects an application listed in the Play Store . < |endfocus| > */ public static void selectFromGooglePlay ( Instrumentation instrumentation , String appDescription ) throws Exception { final UiDevice device = UiDevice . getInstance ( instrumentation ) ; final String playStore = "Play Store" ; final String application = appDescription ; boolean isListed = new Wait ( ) . until ( new Wait . ExpectedCondition ( ) { @Override public boolean isTrue ( ) throws UiObjectNotFoundException { return device . findObject ( new UiSelector ( ) . description ( application ) ) . exists ( ) ; } } ) ; if ( isListed ) { device . findObject ( new UiSelector ( ) . description ( application ) ) . clickAndWaitForNewWindow ( ) ;
public class RSBackwardCompatibilityTests { private static final String TAG = "RSBackwardCompatibilityTests" ; /* * * Returns the list of subclasses of UnitTest to run . * * Filters out any tests with API version greater than current API version . */ @Parameters ( name = " { 0 } " ) public static Iterable < ? > getParams ( ) throws Exception { int thisApiVersion = android . os . Build . VERSION . SDK_INT ; < |startfocus| > if ( thisApiVersion < 19 ) { Log . w ( TAG , "API version is less than 19 , no tests running" ) ; < |endfocus| > } Context ctx = InstrumentationRegistry . getTargetContext ( ) ; List < UnitTest > validUnitTests = new ArrayList < > ( ) ; for ( Class < ? extends UnitTest > testClass : RSTests . getTestClassesForCurrentAPIVersion ( ) ) { UnitTest test = testClass . getDeclaredConstructor ( Context . class ) . newInstance ( ctx ) ; validUnitTests . add ( test ) ; } checkDuplicateNames ( validUnitTests ) ; return validUnitTests ; } /* * * Throws RuntimeException if any tests have the same name . */ private static void checkDuplicateNames ( List < UnitTest > tests ) {
* To run the test , please use command * * adb shell am instrument - w com . android . rs . testforward / android . support . test . runner . AndroidJUnitRunner */ @RunWith ( Parameterized . class ) public class RSForwardCompatibilityTests { private static final String TAG = "RSForwardCompatibilityTests" ; /* * * Returns the list of subclasses of UnitTest to run . */ @Parameters ( name = " { 0 } " ) public static Iterable < ? > getParams ( ) throws Exception { Context ctx = InstrumentationRegistry . getTargetContext ( ) ; Iterable < Class < ? extends UnitTest > > unitTestClasses = RSUtils . getProperSubclasses ( UnitTest . class ) ; List < UnitTest > ret = new ArrayList < > ( ) ; for ( Class < ? extends UnitTest > testClass : unitTestClasses ) { UnitTest test = testClass . getDeclaredConstructor ( Context . class ) . newInstance ( ctx ) ; ret . add ( test ) ; } return ret ; } @Parameter ( 0 ) public UnitTest mTest ; @Test @MediumTest public void testRSUnitTest ( ) throws Exception { String thisDeviceName = android . os . Build . DEVICE ; int thisApiVersion = android . os . Build . VERSION . SDK_INT ;
*/ @Parameters ( name = " { 0 } " ) public static Iterable < ? > getParams ( ) throws Exception { Context ctx = InstrumentationRegistry . getTargetContext ( ) ; Iterable < Class < ? extends UnitTest > > unitTestClasses = RSUtils . getProperSubclasses ( UnitTest . class ) ; List < UnitTest > ret = new ArrayList < > ( ) ; for ( Class < ? extends UnitTest > testClass : unitTestClasses ) { UnitTest test = testClass . getDeclaredConstructor ( Context . class ) . newInstance ( ctx ) ; ret . add ( test ) ; } < |startfocus| > return ret ; < |endfocus| > } @Parameter ( 0 ) public UnitTest mTest ; @Test @MediumTest public void testRSUnitTest ( ) throws Exception { String thisDeviceName = android . os . Build . DEVICE ; int thisApiVersion = android . os . Build . VERSION . SDK_INT ; Log . i ( TAG , String . format ( "RenderScript forward compatibility testing ( % s ) " + "on device % s , API version % d" , mTest . toString ( ) , thisDeviceName , thisApiVersion ) ) ; mTest . runTest ( ) ; switch ( mTest . getResult ( ) ) { case UT_NOT_STARTED : case UT_RUNNING :
import java . util . ArrayList ; import java . util . HashSet ; import java . util . List ; import java . util . Set ; /* * * RSTestBackward , functional test for platform RenderScript APIs . * To run the test , please use command * * adb shell am instrument - w com . android . rs . testbackward / android . support . test . runner . AndroidJUnitRunner */ @RunWith ( Parameterized . class ) public class RSBackwardCompatibilityTests { private static final String TAG = "RSBackwardCompatibilityTests" ; /* * < |startfocus| > * Returns the list of subclasses of UnitTest to run . * * Filters out any tests with API version greater than current API version . */ < |endfocus| > @Parameters ( name = " { 0 } " ) public static Iterable < ? > getParams ( ) throws Exception { int thisApiVersion = android . os . Build . VERSION . SDK_INT ; if ( thisApiVersion < 19 ) { Log . w ( TAG , "API version is less than 19 , no tests running" ) ; } Context ctx = InstrumentationRegistry . getTargetContext ( ) ; ArrayList < UnitTest > validUnitTests = new ArrayList < > ( ) ;
public class RSBackwardCompatibilityTests { private static final String TAG = "RSBackwardCompatibilityTests" ; /* * * Returns the list of subclasses of UnitTest to run . * * Filters out any tests with API version greater than current API version . */ @Parameters ( name = " { 0 } " ) public static Iterable < ? > getParams ( ) throws Exception { int thisApiVersion = android . os . Build . VERSION . SDK_INT ; < |startfocus| > if ( thisApiVersion < 21 ) { Log . w ( TAG , "API version is less than 21 , no tests running" ) ; < |endfocus| > } Context ctx = InstrumentationRegistry . getTargetContext ( ) ; ArrayList < UnitTest > validUnitTests = new ArrayList < > ( ) ; for ( Class < ? extends UnitTest > testClass : RSTests . getTestClassesForCurrentAPIVersion ( ) ) { UnitTest test = testClass . getDeclaredConstructor ( Context . class ) . newInstance ( ctx ) ; validUnitTests . add ( test ) ; } checkDuplicateNames ( validUnitTests ) ; return validUnitTests ; } /* * * Throws RuntimeException if any tests have the same name . */ private static void checkDuplicateNames ( List < UnitTest > tests ) {
} Context ctx = InstrumentationRegistry . getTargetContext ( ) ; ArrayList < UnitTest > validUnitTests = new ArrayList < > ( ) ; for ( Class < ? extends UnitTest > testClass : RSTests . getTestClassesForCurrentAPIVersion ( ) ) { UnitTest test = testClass . getDeclaredConstructor ( Context . class ) . newInstance ( ctx ) ; validUnitTests . add ( test ) ; } checkDuplicateNames ( validUnitTests ) ; return validUnitTests ; } /* * < |startfocus| > * Throws RuntimeException if any tests have the same name . */ < |endfocus| > private static void checkDuplicateNames ( List < UnitTest > tests ) { Set < String > names = new HashSet < > ( ) ; for ( UnitTest test : tests ) { String name = test . toString ( ) ; if ( names . contains ( name ) ) { throw new RuntimeException ( "duplicate name : " + name ) ; } names . add ( name ) ; } } @Parameter ( 0 ) public UnitTest mTest ; @Test @MediumTest public void testRSUnitTest ( ) throws Exception { String thisDeviceName = android . os . Build . DEVICE ; int thisApiVersion = android . os . Build . VERSION . SDK_INT ;
import com . android . rs . unittest .* ; import java . util . ArrayList ; /* * * This class is auto - generated by frameworks / rs / tests / java_api / RSUnitTests / RSUnitTests . py . * To change unit tests version , please run the Python script above . */ public class RSTests { public static Iterable < Class < ? extends UnitTest > > getTestClassesForCurrentAPIVersion ( ) { int thisApiVersion = android . os . Build . VERSION . SDK_INT ; ArrayList < Class < ? extends UnitTest > > validClasses = new ArrayList < > ( ) ; < |startfocus| > if ( thisApiVersion >= 19 ) { < |endfocus| > validClasses . add ( UT_alloc . class ) ; validClasses . add ( UT_array_alloc . class ) ; validClasses . add ( UT_array_init . class ) ; validClasses . add ( UT_atomic . class ) ; validClasses . add ( UT_bitfield . class ) ; validClasses . add ( UT_bug_char . class ) ; validClasses . add ( UT_check_dims . class ) ; validClasses . add ( UT_clamp . class ) ; validClasses . add ( UT_clamp_relaxed . class ) ; validClasses . add ( UT_constant . class ) ; validClasses . add ( UT_convert . class ) ; validClasses . add ( UT_convert_relaxed . class ) ; validClasses . add ( UT_copy_test . class ) ; validClasses . add ( UT_element . class ) ;
import android . content . Context ; import android . support . test . InstrumentationRegistry ; import android . support . test . filters . MediumTest ; import android . util . Log ; import org . junit . Assert ; import org . junit . Test ; import org . junit . runner . RunWith ; import org . junit . runners . Parameterized ; import org . junit . runners . Parameterized . Parameter ; import org . junit . runners . Parameterized . Parameters ; /* * * RSTestForward , functional test for platform RenderScript APIs . * To run the test , please use command * * adb shell am instrument - w com . android . rs . testforward / android . support . test . runner . AndroidJUnitRunner < |startfocus| > * < |endfocus| > */ @RunWith ( Parameterized . class ) public class RSForwardCompatibilityTests { private static final String TAG = "RSForwardCompatibilityTests" ; /* * * Returns the list of subclasses of UnitTest to run . */ @Parameters ( name = " { 0 } " ) public static Iterable < ? > getParams ( ) throws Exception { return RSUtils . getProperSubclasses ( UnitTest . class ) ; } @Parameter ( 0 ) public Class < ? extends UnitTest > mTestClass ; @Test @MediumTest public void testRSUnitTest ( ) throws Exception { Context ctx = InstrumentationRegistry . getTargetContext ( ) ;
import org . junit . runners . Parameterized ; import org . junit . runners . Parameterized . Parameter ; import org . junit . runners . Parameterized . Parameters ; /* * * RSTestForward , functional test for platform RenderScript APIs . * To run the test , please use command * * adb shell am instrument - w com . android . rs . testforward / android . support . test . runner . AndroidJUnitRunner */ @RunWith ( Parameterized . class ) public class RSForwardCompatibilityTests { private static final String TAG = "RSForwardCompatibilityTests" ; /* * < |startfocus| > * Returns the list of subclasses of UnitTest to run . */ < |endfocus| > @Parameters ( name = " { 0 } " ) public static Iterable < ? > getParams ( ) throws Exception { return RSUtils . getProperSubclasses ( UnitTest . class ) ; } @Parameter ( 0 ) public Class < ? extends UnitTest > mTestClass ; @Test @MediumTest public void testRSUnitTest ( ) throws Exception { Context ctx = InstrumentationRegistry . getTargetContext ( ) ; UnitTest test = mTestClass . getDeclaredConstructor ( Context . class ) . newInstance ( ctx ) ; test . runTest ( ) ; switch ( test . getResult ( ) ) { case UT_NOT_STARTED : case UT_RUNNING : fail ( "Test did not complete" ) ; break ; case UT_PASSED : break ; case UT_FAILED : fail ( "Test failed" ) ; break ; } } }
return RSUtils . getProperSubclasses ( UnitTest . class ) ; } @Parameter ( 0 ) public Class < ? extends UnitTest > mTestClass ; @Test @MediumTest public void testRSUnitTest ( ) throws Exception { Context ctx = InstrumentationRegistry . getTargetContext ( ) ; UnitTest test = mTestClass . getDeclaredConstructor ( Context . class ) . newInstance ( ctx ) ; test . runTest ( ) ; switch ( test . getResult ( ) ) { case UT_NOT_STARTED : case UT_RUNNING : Log . w ( TAG , "unexpected unit test result : " + test . getResult ( ) . toString ( ) ) ; break ; } < |startfocus| > Assert . assertTrue ( test . getSuccess ( ) ) ; < |endfocus| > } }
/* * Copyright ( C ) 2016 The Android Open Source Project * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . android . rs . testforward ; import com . android . rs . unittest . UnitTest ; import android . content . Context ; import android . support . test . InstrumentationRegistry ; import dalvik . system . DexFile ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Enumeration ; public class RSUtils { /* * Returns a list of all proper subclasses of the input class */
MetricsLogger . histogram ( context , "ota_stashed_in_MiBs" , bytesStashedInMiB ) ; } if ( temperatureStart != - 1 ) { MetricsLogger . histogram ( context , "ota_temperature_start" , temperatureStart ) ; } if ( temperatureEnd != - 1 ) { MetricsLogger . histogram ( context , "ota_temperature_end" , temperatureEnd ) ; } if ( temperatureMax != - 1 ) { MetricsLogger . histogram ( context , "ota_temperature_max" , temperatureMax ) ; } if ( errorCode != - 1 ) { < |startfocus| > MetricsLogger . histogram ( context , "ota_blockbased_error_code" , errorCode ) ; < |endfocus| > } if ( causeCode != - 1 ) { MetricsLogger . histogram ( context , "ota_blockbased_cause_code" , causeCode ) ; } } catch ( IOException e ) { Log . e ( TAG , "Failed to read lines in last_install" , e ) ; }
} else if ( line . startsWith ( "source_build" ) ) { sourceVersion = scaled ; } else if ( line . startsWith ( "bytes_written" ) ) { bytesWrittenInMiB = ( bytesWrittenInMiB == - 1 ) ? scaled : bytesWrittenInMiB + scaled ; } else if ( line . startsWith ( "bytes_stashed" ) ) { bytesStashedInMiB = ( bytesStashedInMiB == - 1 ) ? scaled : bytesStashedInMiB + scaled ; } else if ( line . startsWith ( "temperatureStart" ) ) { temperatureStart = scaled ; < |startfocus| > } else if ( line . startsWith ( "temperatureEnd" ) ) { < |endfocus| > temperatureEnd = scaled ; } else if ( line . startsWith ( "temperatureMax" ) ) { temperatureMax = scaled ; } else if ( line . startsWith ( "error" ) ) { errorCode = scaled ; } else if ( line . startsWith ( "cause" ) ) { causeCode = scaled ; } } // Don't report data to tron if corresponding entry isn't found in last_install . if ( timeTotal != - 1 ) { < |startfocus| >
void sendTrackChangeWithId ( int trackChangedNT , MediaController mediaController ) { if ( DEBUG ) Log . d ( TAG , "sendTrackChangeWithId" ) ; byte [ ] track ; try { < |startfocus| > if ( mediaController == null ) { mMediaInterface . trackChangedRsp ( trackChangedNT , AvrcpConstants . NO_TRACK_SELECTED ) ; return ; } < |endfocus| > String mediaId = mediaController . getMetadata ( ) . getDescription ( ) . getMediaId ( ) ; long qid = MediaSession . QueueItem . UNKNOWN_ID ; List < MediaSession . QueueItem > items = mNowPlayingList ; /* traverse now playing list for current playing item */ for ( QueueItem item : items ) { if ( item . getDescription ( ) . getMediaId ( ) . equals ( mediaId ) ) { qid = item . getQueueId ( ) ; if ( DEBUG ) Log . d ( TAG , "sendTrackChangeWithId : Found matching qid = " + qid ) ; break ; } } /* for any item associated with NowPlaying , uid is queueId */ track = ByteBuffer . allocate ( AvrcpConstants . UID_SIZE ) . putLong ( qid ) . array ( ) ; } catch ( NullPointerException e ) { Log . w ( TAG , "NullPointerException getting uid , sending no track selected" ) ; }
} else if ( ! isPlayerAlreadyAddressed ( selectedId ) ) { // register new Media Controller Callback and update the current IDs if ( ! updateCurrentController ( selectedId , mCurrBrowsePlayerID ) ) { status = AvrcpConstants . RSP_INTERNAL_ERR ; Log . e ( TAG , "register for new Address player failed : " + mCurrAddrPlayerID ) ; } < |startfocus| > } else { MediaPlayerInfo info = getAddressedPlayerInfo ( ) ; Log . i ( TAG , "addressed player " + info + "is already focused" ) ; < |endfocus| > } if ( DEBUG ) Log . d ( TAG , "setAddressedPlayer for selectedId : " + selectedId + " , status : " + status ) ; // Sending address player response to remote setAddressedPlayerRspNative ( bdaddr , status ) ;
mUnbinding = false ; mEnable = false ; mState = BluetoothAdapter . STATE_OFF ; mQuietEnableExternal = false ; mEnableExternal = false ; mAddress = null ; mName = null ; mErrorRecoveryRetryCounter = 0 ; mContentResolver = context . getContentResolver ( ) ; // Observe BLE scan only mode settings change . registerForBleScanModeChange ( ) ; mCallbacks = new RemoteCallbackList < IBluetoothManagerCallback > ( ) ; mStateChangeCallbacks = new RemoteCallbackList < IBluetoothStateChangeCallback > ( ) ; IntentFilter filter = new IntentFilter ( BluetoothAdapter . ACTION_LOCAL_NAME_CHANGED ) ; filter . setPriority ( IntentFilter . SYSTEM_HIGH_PRIORITY ) ; mContext . registerReceiver ( mReceiver , filter ) ; < |startfocus| > IntentFilter filter2 = new IntentFilter ( BluetoothAdapter . ACTION_BD_ADDR_CHANGED ) ; filter2 . setPriority ( IntentFilter . SYSTEM_HIGH_PRIORITY ) ; mContext . registerReceiver ( mReceiver , filter2 ) ; < |endfocus| > loadStoredNameAndAddress ( ) ; if ( isBluetoothPersistedStateOn ( ) ) { if ( DBG ) Slog . d ( TAG , "Startup : Bluetooth persisted state is ON . " ) ; mEnableExternal = true ; } String airplaneModeRadios = Settings . Global . getString ( mContentResolver , Settings . Global . AIRPLANE_MODE_RADIOS ) ; if ( airplaneModeRadios == null || airplaneModeRadios . contains ( Settings . Global . RADIO_BLUETOOTH ) ) { mAirplaneMode = true ; } mContext . registerReceiver ( mReceiver , new IntentFilter ( Intent . ACTION_AIRPLANE_MODE_CHANGED ) ) ; mHandler . sendMessage ( mHandler . obtainMessage ( MESSAGE_BLUETOOTH_SERVICE_CONNECTED ) ) ; // bind and init will happen when we get MESSAGE_BLUETOOTH_SERVICE_CONNECTED Intent intent = new Intent ( IBluetooth . class . getName ( ) ) ; boolean addService = mContext . bindServiceAsUser ( intent , mConnection , Context . BIND_AUTO_CREATE , UserHandle . CURRENT ) ; if ( DBG ) Slog . d ( TAG , "BluetoothManagerService : Trying to bind to IBluetooth service" + ( addService ? " succeeded" : " failed" ) ) ; if ( addService ) { mHandler . sendMessageDelayed ( mHandler . obtainMessage ( MESSAGE_TIMEOUT_BIND ) , TIMEOUT_BIND_MS ) ; } else { Slog . e ( TAG , "BluetoothManagerService : Failed to bind to IBluetooth service" ) ; } }
protected int adjustDexoptNeeded ( int dexoptNeeded ) { if ( dexoptNeeded == DexFile . NO_DEXOPT_NEEDED ) { // Ensure compilation by pretending a compiler filter change on the < |startfocus| > // apk location . < |endfocus| > return - DexFile . DEX2OAT_FOR_FILTER ; } return dexoptNeeded ; }
private static final int CRASH_LOG_MAX_SIZE = 100 ; private static final String REASON_AIRPLANE_MODE = "airplane mode" ; private static final String REASON_RESTARTED = "automatic restart" ; private static final String REASON_START_CRASH = "turn - on crash" ; private static final String REASON_SYSTEM_BOOT = "system boot" ; private static final String REASON_UNEXPECTED = "unexpected crash" ; private static final String REASON_USER_SWITCH = "user switch" ; < |startfocus| > private static final String REASON_SYSTEM_RESTORE = "restored user setting" ; < |endfocus| > private static final int TIMEOUT_BIND_MS = 3000 ; // Maximum msec to wait for a bind // Maximum msec to wait for service restart private static final int SERVICE_RESTART_TIME_MS = 200 ; // Maximum msec to wait for restart due to error private static final int ERROR_RESTART_TIME_MS = 3000 ; // Maximum msec to delay MESSAGE_USER_SWITCHED private static final int USER_SWITCHED_TIME_MS = 200 ; // Delay for the addProxy function in msec private static final int ADD_PROXY_DELAY_MS = 100 ;
// / CHECK - DAG : < < Add : d\d + > > VecAdd [ < < Load > > , < < Repl > > ] // / CHECK - NOT : IntermediateAddress // / CHECK - DAG : VecStore [ < < Array > > , < < Address1 > > , < < Add > > ] // / CHECK - START - ARM64 : void Main . checkIntCase ( int [ ] ) disassembly ( after ) // / CHECK : IntermediateAddressIndex < |startfocus| > // / CHECK - NEXT : add w { { [ 0 - 9 ] + } } , w { { [ 0 - 9 ] + } } , w { { [ 0 - 9 ] + } } , lsl #2 < |endfocus| > public static void checkIntCase ( int [ ] a ) { for ( int i = 0 ; i < 128 ; i ++ ) { a [ i ] += 5 ; } } // / CHECK - START - ARM64 : void Main . checkByteCase ( byte [ ] ) instruction_simplifier_arm64 ( before ) // / CHECK - DAG : < < Array : l\d + > > ParameterValue // / CHECK - DAG : < < Const5 : i\d + > > IntConstant 5 // / CHECK - DAG : < < Repl : d\d + > > VecReplicateScalar [ < < Const5 > > ] // -- -- -- -- -- -- -- Loop // / CHECK - DAG : < < Index : i\d + > > Phi
// / CHECK - DAG : < < Add : d\d + > > VecAdd [ < < Load > > , < < Repl > > ] // / CHECK - NOT : IntermediateAddress // / CHECK - DAG : VecStore [ < < Array > > , < < Address1 > > , < < Add > > ] // / CHECK - START - ARM64 : void Main . checkByteCase ( byte [ ] ) disassembly ( after ) // / CHECK : IntermediateAddressIndex // / CHECK - NEXT : add w { { [ 0 - 9 ] + } } , w { { [ 0 - 9 ] + } } , #0x { { [ 0 - 9a - fA - F ] + } } // / CHECK : VecLoad < |startfocus| > // / CHECK - NEXT : ldr q { { [ 0 - 9 ] + } } , [ x { { [ 0 - 9 ] + } } , x { { [ 0 - 9 ] + } } ] < |endfocus| > // / CHECK : VecStore // / CHECK - NEXT : str q { { [ 0 - 9 ] + } } , [ x { { [ 0 - 9 ] + } } , x { { [ 0 - 9 ] + } } ] public static void checkByteCase ( byte [ ] a ) { for ( int i = 0 ; i < 128 ; i ++ ) { a [ i ] += 5 ; } }
// / CHECK : < < Add : d\d + > > VecAdd [ < < Load > > , < < Repl > > ] // / CHECK - NOT : IntermediateAddress // / CHECK : VecStore [ < < Array > > , < < Address1 > > , < < Add > > ] // / CHECK - START - ARM64 : void Main . checkIntCase ( int [ ] ) disassembly ( after ) < |startfocus| > // / CHECK : IntermediateAddressIndex // / CHECK - NEXT : add w { { [ 0 - 9 ] + } } , w { { [ 0 - 9 ] + } } , w { { [ 0 - 9 ] + } } , lsl # { { [ 0 - 9 ] } } < |endfocus| > public static void checkIntCase ( int [ ] a ) { for ( int i = 0 ; i < 128 ; i ++ ) { a [ i ] += 5 ; } } // / CHECK - START - ARM64 : void Main . checkByteCase ( byte [ ] ) instruction_simplifier_arm64 ( before ) // / CHECK : < < Array : l\d + > > ParameterValue // / CHECK : < < Const5 : i\d + > > IntConstant 5 // / CHECK : < < Repl : d\d + > > VecReplicateScalar [ < < Const5 > > ] // -- -- -- -- -- -- -- Loop // / CHECK : < < Index : i\d + > > Phi // / CHECK : If
public static void checkInt2Float ( int [ ] a , float [ ] b ) { for ( int i = 0 ; i < 128 ; i ++ ) { < |startfocus| > b [ i ] = ( float ) a [ i ] ; < |endfocus| > } }
public static void checkInt2Float ( int [ ] a , float [ ] b ) { for ( int i = 0 ; i < 128 ; i ++ ) { < |startfocus| > b [ i ] = ( float ) a [ i ] ; < |endfocus| > }
public static int calcArraySum ( int [ ] a , byte [ ] b , float [ ] c ) { int sum = 0 ; for ( int i = 0 ; i < 128 ; i ++ ) { < |startfocus| > sum += a [ i ] + b [ i ] + ( int ) c [ i ] ; < |endfocus| > } return sum ;
* Agreement between Taligent and Sun . This technology is protected * by multiple US and International patents . * * This notice and attribution to Taligent may not be removed . * Taligent is a registered trademark of Taligent , Inc . * */ package java . awt . font ; import java . io . InvalidObjectException ; import java . text . AttributedCharacterIterator . Attribute ; import java . util . Map ; import java . util . HashMap ; < |startfocus| > // Android - removed : List of classes for use with attribute keys ; "Summary of attributes" section . < |endfocus| > /* * * The < code > TextAttribute </ code > class defines attribute keys and * attribute values used for text rendering . * < p > * < code > TextAttribute </ code > instances are used as attribute keys to * identify attributes in classes handling text attributes . Other * constants defined in this class can be used as attribute values . * < p > * For each text attribute , the documentation provides : * < UL > * < LI > the type of its value , * < LI > the relevant predefined constants , if any .
if ( instance != null ) { return instance ; } else { throw new InvalidObjectException ( "unknown attribute name" ) ; } } // Serialization compatibility with Java 2 platform v1 . 2 . // 1 . 2 will throw an InvalidObjectException if ever asked to // deserialize INPUT_METHOD_UNDERLINE . // This shouldn't happen in real life . static final long serialVersionUID = 7744112784117861702L ; // // For use with Font . // < |startfocus| > // Android - removed : links to java . awk . Font constants not present on Android from documentation . < |endfocus| > /* * * Attribute key for the font name . Values are instances of * < b > < code > String </ code > </ b > . The default value is * < code > "Default" </ code > , which causes the platform default font * family to be used . * * < p > The < code > Font </ code > class defines constants for the logical * font names . * * < p > This defines the value passed as < code > name </ code > to the * < code > Font </ code > constructor . Both logical and physical
* and the rendering system might not render text at these sizes . * Negative sizes are illegal and result in the default size . * * < p > Note that the appearance and metrics of a 12pt font with a * 2x transform might be different than that of a 24 point font * with no transform . */ public static final TextAttribute SIZE = new TextAttribute ( "size" ) ; < |startfocus| > // Android - removed : Sections of documentation about TransformAttribute . < |endfocus| > /* * * Attribute key for the transform of a font . Values are * instances of < b > < code > TransformAttribute </ code > </ b > . The * default value is < code > TransformAttribute . IDENTITY </ code > . * * < p > The primary intent is to support scaling and skewing , though * other effects are possible . </ p > * * < p > Some transforms will cause the baseline to be rotated and / or * shifted . The text and the baseline are transformed together so * that the text follows the new baseline . For example , with text * rotated 90 degrees counter - clockwise , the baseline is rotated * 90 degrees clockwise . * * < p > The transform attribute is applied to the text before the * font attribute . For example , a font with a point size of 24 * and a transform attribute of 2x will be rendered as if it were * a font with a point size of 48 . * * < p > The transform attribute is not supported by all * implementations . If the transform attribute is not supported , * the text will be rendered without the transform . * * @see java . awt . font . TextAttribute#TRANSFORM * @see java . awt . font . TransformAttribute * @see java . awt . font . TextLayout#getBaselineTransform ( ) * @see java . awt . font . TextLayout#getOutline ( java . awt . geom . AffineTransform ) * @see java . awt . font . TextLayout#getCaretShapes ( int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , int , java . awt . geom . AffineTransform , java . awt . geom . Rectangle2D ) * @see java . awt . font . TextLayout#getCaretShapes ( int , int , int , int , int , int , int , int , int , int
* and descent can never become negative , however . */ public static final TextAttribute SUPERSCRIPT = new TextAttribute ( "superscript" ) ; /* * * Standard superscript . * @see #SUPERSCRIPT */ public static final Integer SUPERSCRIPT_SUPER = Integer . valueOf ( 1 ) ; /* * * Standard subscript . * @see #SUPERSCRIPT */ public static final Integer SUPERSCRIPT_SUB = Integer . valueOf ( - 1 ) ; < |startfocus| > // Android - removed : Documentation sections about java . awt . Font . < |endfocus| > /* * * Attribute key used to provide the font to use to render text . * * The default * value is null , indicating that normal resolution of a * < code > Font </ code > from attributes should be performed . * * < p > < code > TextLayout </ code > and * < code > AttributedCharacterIterator </ code > work in terms of * < code > Maps </ code > of < code > TextAttributes </ code > . Normally , * all the attributes are examined and used to select and * configure a < code > Font </ code > instance . If a < code > FONT </ code >
* default value for < code > JUSTIFICATION </ code > . * @see #JUSTIFICATION */ public static final Float JUSTIFICATION_FULL = Float . valueOf ( 1 . 0f ) ; /* * * Do not allow the line to be justified . * @see #JUSTIFICATION */ public static final Float JUSTIFICATION_NONE = Float . valueOf ( 0 . 0f ) ; // // For use by input method . // < |startfocus| > // Android - removed : Documentation sections about java . awt . im . InputMethodHighlight < |endfocus| > /* * * Attribute key for input method highlight styles . * * The default value is < code > null </ code > , * which means that input method styles should not be applied * before rendering . * * @see java . text . Annotation */ public static final TextAttribute INPUT_METHOD_HIGHLIGHT = new TextAttribute ( "input method highlight" ) ; /* * * Attribute key for input method underlines . Values * are instances of < b > < code > Integer </ code > </ b > . The default * value is < code >- 1 </ code > , which means no underline . * @see java . text . Annotation */ public static final TextAttribute INPUT_METHOD_UNDERLINE = new TextAttribute ( "input method underline" ) ; /* * * Attribute key for the number of characters used to expand * tabs . Values are instances of < b > < code > Number </ code > </ b > . * The default value is 8 . * @see java . text . AttributedCharacterIterator#getAttribute ( java . text . AttributedCharacterIterator . Attribute ) */ public static final TextAttribute INPUT_METHOD_SEGMENT = new TextAttribute ( "input method segment" ) ; /* * * Attribute key for the justification of a paragraph . Values * are instances of < b > < code > Number </ code > </ b > . The default * value is < code > 0 . 5 </ code > . * @see java . text . AttributedCharacterIterator#getAttribute ( java . text . AttributedCharacterIterator . Attribute ) */ public static final TextAttribute JUSTIFICATION = new TextAttribute ( "justification" ) ; /* * * Justify the line to the full requested width . * @see #JUSTIFICATION */ public static final Float JUSTIFICATION_FULL = Float . valueOf ( 1 . 0f ) ; /* * * Do not allow the line to be justified . * @see #JUSTIFICATION */ public static final Float JUSTIFICATION_NONE = Float . valueOf ( 0 . 0f ) ; /* * * Attribute key for the run direction of the line . Values * are instances of < b > < code > Boolean </ code > </ b > . The default * value is < code > Boolean . FALSE </ code > , which means lines are * left - to - right . * @see java . text . AttributedCharacterIterator#getAttribute ( java . text . AttributedCharacterIterator . Attribute ) */ public static final TextAttribute RUN_DIRECTION = new TextAttribute ( "run direction" ) ; /* * * Run direction is left - to - right . * @see #RUN_DIRECTION */ public static final Boolean RUN_DIRECTION_LTR = Boolean . FALSE ; /* * * Run direction is right - to - left . * @see #RUN_DIRECTION */ public static final Boolean RUN_DIRECTION_RTL = Boolean . TRUE ; /* * * Attribute key for the embedding level of the text . Values * are instances of < b > < code > Integer </ code > </ b > . The default * value is < code > 0 </ code > . * @see java . text . AttributedCharacterIterator#getAttribute ( java . text . AttributedCharacterIterator . Attribute ) */ public static final TextAttribute BIDI_EMBEDDING = new TextAttribute ( "bidi embedding" ) ; /* * * Attribute key for the justification of a paragraph . Values * are instances of < b > < code > Number </ code > </ b > . The default * value is < code > 0 . 5 </ code > . * @see java . text . AttributedCharacterIterator#getAttribute ( java . text . AttributedCharacterIterator . Attribute ) */ public static final TextAttribute JUSTIFICATION = new TextAttribute ( "justification" ) ; /* * * Justify the line to the full requested width . * @see #JUSTIFICATION */ public static final Float JUSTIFICATION_FULL = Float . valueOf ( 1 . 0f ) ; /* * * Do not allow the line to be justified . * @see #JUSTIFICATION */ public static final Float JUSTIFICATION_NONE = Float . valueOf ( 0 . 0f ) ; /* * * Attribute key for the run direction of the line . Values * are instances of < b > < code > Boolean </ code > </ b > . The default * value is < code > Boolean . FALSE </ code > , which means lines are * left - to - right . * @see java . text . AttributedCharacterIterator#getAttribute ( java . text . AttributedCharacterIterator . Attribute ) */ public static final TextAttribute RUN_DIRECTION = new TextAttribute ( "run direction" ) ; /* * * Run direction is left - to - right . * @see #RUN_DIRECTION */ public static final Boolean RUN_DIRECTION_LTR = Boolean . FALSE ; /* * * Run direction is right - to - left . * @see #RUN_DIRECTION */ public static final Boolean RUN_DIRECTION_RTL = Boolean . TRUE ; /* * * Attribute key for the embedding level of the text . Values * are instances of < b > < code > Integer </ code > </ b > . The default * value is < code > 0 </ code > . * @see java . text . AttributedCharacterIterator#getAttribute ( java . text . AttributedCharacterIterator . Attribute ) */ public static final TextAttribute BIDI_EMBEDDING = new TextAttribute ( "bidi embedding" ) ; /* * * Attribute key for the numeric shaping mode . Values * are instances of < b > < code > Integer </ code > </ b > . The default * value is < code > 0 </ code > . * @see java . text . AttributedCharacterIterator#getAttribute ( java . text . AttributedCharacterIterator . Attribute ) */ public static final TextAttribute NUMERIC_SHAPING = new TextAttribute ( "numeric shaping" ) ; /* * * Attribute key for the justification of a paragraph . Values * are instances of < b > < code > Number </ code > </ b > . The default * value is < code > 0 . 5 </ code > . * @see java . text . AttributedCharacterIterator#getAttribute ( java . text . AttributedCharacterIterator . Attribute ) */ public static final TextAttribute JUSTIFICATION = new TextAttribute ( "justification" ) ; /* * * Justify the line to the full requested width . * @see #JUSTIFICATION */ public static final Float JUSTIFICATION_FULL = Float . valueOf ( 1 . 0f ) ; /* * * Do not allow the line to be justified . * @see #JUSTIFICATION */ public static final Float JUSTIFICATION_NONE = Float . valueOf ( 0 . 0f ) ; /* * * Attribute key for the run direction of the line . Values * are instances of < b > < code > Boolean </ code > </ b > . The default * value is < code > Boolean . FALSE </ code > , which means lines are * left - to - right . * @see java . text . AttributedCharacterIterator#getAttribute ( java . text . AttributedCharacterIterator . Attribute ) */ public static final TextAttribute RUN_DIRECTION = new TextAttribute ( "run direction" ) ; /* * * Run direction is left - to - right . * @see #RUN_DIRECTION */ public static final Boolean RUN_DIRECTION_LTR = Boolean . FALSE ; /* * * Run direction is right - to - left . * @see #RUN_DIRECTION */ public static final Boolean RUN_DIRECTION_RTL = Boolean . TRUE ; /* * * Attribute key for the embedding level of the text . Values * are instances of < b > < code > Integer </ code > </ b > . The default * value is < code > 0 </ code > . * @see java . text . AttributedCharacterIterator#getAttribute ( java . text . AttributedCharacterIterator . Attribute ) */ public static final TextAttribute BIDI_EMBEDDING = new TextAttribute ( "bidi embedding" ) ; /* * * Attribute key for the numeric shaping mode . Values * are instances of < b > < code > Integer </
mHandler . removeMessages ( MESSAGE_RESTART_BLUETOOTH_SERVICE ) ; if ( mEnable && mBluetooth != null ) { waitForOnOff ( true , false ) ; mEnable = false ; handleDisable ( ) ; waitForOnOff ( false , false ) ; } else { mEnable = false ; handleDisable ( ) ; } break ; case MESSAGE_RESTORE_ON_SETTING : try { if ( ( msg . arg1 == RESTORE_SETTING_TO_OFF ) && mEnable ) { < |startfocus| > if ( DBG ) Slog . d ( TAG , "Restore to disable Bluetooth" ) ; disable ( REASON_RESTORE_USER_SETTING , true ) ; < |endfocus| > } else if ( ( msg . arg1 == RESTORE_SETTING_TO_ON ) && ! mEnable ) { if ( DBG ) Slog . d ( TAG , "Restore to enable Bluetooth" ) ; enable ( REASON_RESTORE_USER_SETTING ) ; } } catch ( RemoteException e ) { Slog . e ( TAG , "Unable to change Bluetooth On setting" , e ) ; } break ; case MESSAGE_REGISTER_ADAPTER : { IBluetoothManagerCallback callback = ( IBluetoothManagerCallback ) msg . obj ; mCallbacks . register ( callback ) ; break ; } case MESSAGE_UNREGISTER_ADAPTER :
} else { mEnable = false ; handleDisable ( ) ; } break ; case MESSAGE_RESTORE_ON_SETTING : try { if ( ( msg . arg1 == RESTORE_SETTING_TO_OFF ) && mEnable ) { if ( DBG ) Slog . d ( TAG , "Restore to disable Bluetooth" ) ; disable ( REASON_RESTORE_USER_SETTING , true ) ; } else if ( ( msg . arg1 == RESTORE_SETTING_TO_ON ) && ! mEnable ) { < |startfocus| > if ( DBG ) Slog . d ( TAG , "Restore to enable Bluetooth" ) ; enable ( REASON_RESTORE_USER_SETTING ) ; < |endfocus| > } } catch ( RemoteException e ) { Slog . e ( TAG , "Unable to change Bluetooth On setting" , e ) ; } break ; case MESSAGE_REGISTER_ADAPTER : { IBluetoothManagerCallback callback = ( IBluetoothManagerCallback ) msg . obj ; mCallbacks . register ( callback ) ; break ; } case MESSAGE_UNREGISTER_ADAPTER : { IBluetoothManagerCallback callback = ( IBluetoothManagerCallback ) msg . obj ; mCallbacks . unregister ( callback ) ; break ; } case MESSAGE_REGISTER_STATE_CHANGE_CALLBACK : {
private static final int MESSAGE_BLUETOOTH_STATE_CHANGE = 60 ; private static final int MESSAGE_TIMEOUT_BIND = 100 ; private static final int MESSAGE_TIMEOUT_UNBIND = 101 ; private static final int MESSAGE_GET_NAME_AND_ADDRESS = 200 ; private static final int MESSAGE_USER_SWITCHED = 300 ; private static final int MESSAGE_USER_UNLOCKED = 301 ; private static final int MESSAGE_ADD_PROXY_DELAYED = 400 ; private static final int MESSAGE_BIND_PROFILE_SERVICE = 401 ; < |startfocus| > private static final int MESSAGE_RESTORE_USER_SETTING = 500 ; < |endfocus| > private static final int RESTORE_SETTING_TO_ON = 1 ; private static final int RESTORE_SETTING_TO_OFF = 0 ; private static final int MAX_SAVE_RETRIES = 3 ; private static final int MAX_ERROR_RESTART_RETRIES = 6 ; // Bluetooth persisted setting is off private static final int BLUETOOTH_OFF = 0 ; // Bluetooth persisted setting is on // and Airplane mode won't affect Bluetooth state at start up private static final int BLUETOOTH_ON_BLUETOOTH = 1 ; // Bluetooth persisted setting is on
Intent . EXTRA_SETTING_NEW_VALUE ) ; if ( DBG ) Slog . d ( TAG , "ACTION_SETTING_RESTORED with BLUETOOTH_ON , prevValue = " + prevValue + " , newValue = " + newValue ) ; if ( ( newValue != null ) && ( prevValue != null ) && ! prevValue . equals ( newValue ) ) { < |startfocus| > mHandler . obtainMessage ( MESSAGE_RESTORE_ON_SETTING , newValue . equals ( "0" ) ? RESTORE_SETTING_TO_OFF : RESTORE_SETTING_TO_ON , 0 ) . sendToTarget ( ) ; < |endfocus| > } } }
if ( ( msg . arg1 == RESTORE_SETTING_TO_OFF ) && mEnable ) { if ( DBG ) Slog . d ( TAG , "Restore Bluetooth state to disabled" ) ; disable ( REASON_RESTORE_USER_SETTING , true ) ; } else if ( ( msg . arg1 == RESTORE_SETTING_TO_ON ) && ! mEnable ) { if ( DBG ) Slog . d ( TAG , "Restore Bluetooth state to enabled" ) ; enable ( REASON_RESTORE_USER_SETTING ) ; } } catch ( RemoteException e ) { < |startfocus| > Slog . e ( TAG , "Unable to change Bluetooth On setting" , e ) ; < |endfocus| > } break ; case MESSAGE_REGISTER_ADAPTER : { IBluetoothManagerCallback callback = ( IBluetoothManagerCallback ) msg . obj ; mCallbacks . register ( callback ) ; break ; } case MESSAGE_UNREGISTER_ADAPTER : { IBluetoothManagerCallback callback = ( IBluetoothManagerCallback ) msg . obj ; mCallbacks . unregister ( callback ) ; break ; } case MESSAGE_REGISTER_STATE_CHANGE_CALLBACK : { IBluetoothStateChangeCallback callback = ( IBluetoothStateChangeCallback ) msg . obj ; mStateChangeCallbacks . register ( callback ) ; break ; } case MESSAGE_UNREGISTER_STATE_CHANGE_CALLBACK : {
* @hide */ public class ServiceInfo implements Parcelable { // arbitrary limit on the number of locale - > name pairs we support final static int MAP_LIMIT = 50 ; /* * * User displayable names listed by language . Unmodifiable . */ final Map < Locale , String > names ; /* * * The class name for this service - used to catagorize and filter */ final String className ; /* * * The language for this service content */ final Locale locale ; /* * < |startfocus| > < |endfocus| > * The carrier's identifier for the service . */ final String serviceId ; /* * * The start time indicating when this service will be available . */ final Date sessionStartTime ; /* * * The end time indicating when this sesion stops being available . */ final Date sessionEndTime ; public ServiceInfo ( Map < Locale , String > newNames , String newClassName , Locale newLocale , String newServiceId , Date start , Date end ) {
/* * * Initialize streaming service for this app and subId , registering the listener . * * @param listener The callback to use to communicate with the app . * @param appName The package name of the calling app . * @param subscriptionId The subscription ID to use . * @return { @link MbmsException#ERROR_ALREADY_INITIALIZED } or { @link MbmsException#SUCCESS } . */ @Override public int initialize ( IMbmsStreamingManagerCallback listener , String appName , < |startfocus| > int subscriptionId ) throws RemoteException { < |endfocus| > return 0 ; } /* * * Registers serviceClasses of interest with the appName / subId key . * Starts async fetching data on streaming services of matching classes to be reported * later via { @link IMbmsStreamingManagerCallback#streamingServicesUpdated ( List ) } * * Note that subsequent calls with the same appName and subId will replace * the service class list . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS .
/* * * Initialize streaming service for this app and subId , registering the listener . * * @param listener The callback to use to communicate with the app . * @param appName The package name of the calling app . * @param subscriptionId The subscription ID to use . * @return { @link MbmsException#ERROR_ALREADY_INITIALIZED } or { @link MbmsException#SUCCESS } . */ @Override public int initialize ( IMbmsStreamingManagerCallback listener , String appName , < |startfocus| > int subscriptionId ) throws RemoteException { < |endfocus| > return 0 ; } /* * * Registers serviceClasses of interest with the appName / subId key . * Starts async fetching data on streaming services of matching classes to be reported * later via { @link IMbmsStreamingManagerCallback#streamingServicesUpdated ( List ) } * * Note that subsequent calls with the same appName and subId will replace * the service class list . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @param serviceClasses The service classes of interest . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_ALREADY_INITIALIZED } * if the app is already initialized , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#SUCCESS } otherwise . */ @Override public int initialize ( IMbmsStreamingManagerCallback listener , String appName , int subscriptionId , List < String > serviceClasses ) throws RemoteException { return 0 ; } /* * * Asynchronously fetches the list of streaming services available to the app . * The results will be returned via { @link IMbmsStreamingManagerCallback#streamingServicesUpdated ( List ) } * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#SUCCESS } otherwise . */ @Override public int getStreamingServices ( String appName , int subscriptionId ) throws RemoteException { return 0 ; } /* * * Asynchronously fetches the list of streaming services available to the app . * The results will be returned via { @link IMbmsStreamingManagerCallback#streamingServicesUpdated ( List ) } * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @param serviceClasses The service classes of interest . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#SUCCESS } otherwise . */ @Override public int getStreamingServices ( String appName , int subscriptionId , List < String > serviceClasses ) throws RemoteException { return 0 ; } /* * * Starts streaming the service identified by the serviceId . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @param serviceId The service id of the service to start streaming . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#ERROR_UNABLE_TO_START_SERVICE } * if the service could not be started , { @link MbmsException#SUCCESS } otherwise . */ @Override public int startStreaming ( String appName , int subscriptionId , String serviceId ) throws RemoteException { return 0 ; } /* * * Stops streaming the service identified by the serviceId . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @param serviceId The service id of the service to stop streaming . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#ERROR_UNABLE_TO_STOP_SERVICE } * if the service could not be stopped , { @link MbmsException#SUCCESS } otherwise . */ @Override public int stopStreaming ( String appName , int subscriptionId , String serviceId ) throws RemoteException { return 0 ; } /* * * Resets the streaming manager . * * This will cause the middleware to forget about all state associated with the appName / subId * pair . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#SUCCESS } otherwise . */ @Override public int dispose ( String appName , int subscriptionId ) throws RemoteException { return 0 ; } /* * * Sets the temp file root directory for the appName / subId pair . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @param fileRoot The root directory to use . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#SUCCESS } otherwise . */ @Override public int setTempFileRootDirectory ( String appName , int subscriptionId , File fileRoot ) throws RemoteException { return 0 ; } /* * * Sets the temp file root directory for the appName / subId pair . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @param fileRoot The root directory to use . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#SUCCESS } otherwise . */ @Override public int setTempFileRootDirectory ( String appName , int subscriptionId , String fileRoot ) throws RemoteException { return 0 ; } /* * * Sets the temp file root directory for the appName / subId pair . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS . * @param fileRoot The root directory to use . * @return { @link MbmsException#ERROR_MIDDLEWARE_NOT_YET_READY } if the middleware * is not yet ready to process the request , { @link MbmsException#ERROR_UNABLE_TO_INITIALIZE } * if the app is not initialized , { @link MbmsException#SUCCESS } otherwise . */ @Override public int setTempFileRootDirectory (
*/ @Override public int initialize ( IMbmsStreamingManagerCallback listener , String appName , int subscriptionId ) throws RemoteException { return 0 ; } /* * * Registers serviceClasses of interest with the appName / subId key . * Starts async fetching data on streaming services of matching classes to be reported * later via { @link IMbmsStreamingManagerCallback#streamingServicesUpdated ( List ) } * < |startfocus| > * Note that subsequent calls with the same appName and subId will replace < |endfocus| > * the service class list . * * @param appName The package name of the calling app . * @param subscriptionId The subscription id for eMBMS * @param serviceClasses The service classes that the app wishes to get info on . The strings * may contain arbitrary data as negotiated between the app and the * carrier . */ @Override public int getStreamingServices ( String appName , int subscriptionId , List < String > serviceClasses ) throws MbmsException { return 0 ; } @Override public StreamingService startStreaming ( String appName , int subId ,
security . checkWrite ( name ) ; } } */ if ( name == null ) { // Android - changed : different exception message in ctor when file == null . // throw new NullPointerException ( ) ; throw new NullPointerException ( "file == null" ) ; } if ( file . isInvalid ( ) ) { throw new FileNotFoundException ( "Invalid file path" ) ; } this . path = name ; this . mode = imode ; // BEGIN Android - changed : Use IoBridge . open ( ) instead of open . < |startfocus| > fd = IoBridge . open ( file . getPath ( ) , imode ) ; < |endfocus| > if ( syncMetadata ) { try { fd . sync ( ) ; } catch ( IOException e ) { // Ignored } } guard . open ( "close" ) ; // END Android - changed : Use IoBridge . open ( ) instead of open . } /* * * Returns the opaque file descriptor object associated with this * stream . * * @return the file descriptor object associated with this stream . * @exception IOException if an I / O error occurs . * @see java . io . FileDescriptor */
if ( VDBG ) Log . d ( TAG , "Tether Mode requested by " + who ) ; handleInterfaceServingStateActive ( message . arg1 , who ) ; who . sendMessage ( TetherInterfaceStateMachine . CMD_TETHER_CONNECTION_CHANGED , mCurrentUpstreamIface ) ; // If there has been a change and an upstream is now // desired , kick off the selection process . final boolean previousUpstreamWanted = updateUpstreamWanted ( ) ; if ( ! previousUpstreamWanted && mUpstreamWanted ) { chooseUpstreamType ( true ) ; } break ; } < |startfocus| > case EVENT_IFACE_SERVING_STATE_INACTIVE : { < |endfocus| > TetherInterfaceStateMachine who = ( TetherInterfaceStateMachine ) message . obj ; if ( VDBG ) Log . d ( TAG , "Tether Mode unrequested by " + who ) ; handleInterfaceServingStateInactive ( who ) ; if ( mNotifyList . isEmpty ( ) ) { turnOffMasterTetherSettings ( ) ; // transitions appropriately } else { if ( DBG ) { Log . d ( TAG , "TetherModeAlive still has " + mNotifyList . size ( ) + " live requests : " ) ; for ( TetherInterfaceStateMachine o : mNotifyList ) { < |startfocus| > } } } } < |endfocus| >
// // / CHECK - START : int Main . getSum21 ( ) instruction_simplifier$after_bce ( after ) // / CHECK - DAG : < < Int : i\d + > > IntConstant 21 loop : none // / CHECK - DAG : Return [ < < Int > > ] loop : none private static int getSum21 ( ) { int k = 0 ; int sum = 0 ; for ( int i = 0 ; i < 6 ; i ++ ) { k ++ ; sum += k ; } return sum ; } < |startfocus| > // Ensure double induction does not "overshoot" . < |endfocus| > private static int getIncr2 ( int [ ] arr ) { for ( int i = 0 ; i < 12 ; ) { arr [ i ++ ] = 30 ; arr [ i ++ ] = 29 ; } int sum = 0 ; for ( int i = 0 ; i < 12 ; i ++ ) { sum += arr [ i ] ; } return sum ; } // TODO : handle as closed / empty eventually ? static int mainIndexReturnedN ( int n ) { int i ; for ( i = 0 ; i < n ; i ++ ) ; return i ; }
// To account correctly for on - the - wire traffic , add the 20 additional bytes difference // for all packets ( http :/ / b / 12249687 , http :/ b / 33681750 ) . for ( int i = 0 ; i < stats . size ( ) ; i ++ ) { entry = stats . getValues ( i , entry ) ; if ( entry . iface == null || ! entry . iface . startsWith ( CLATD_INTERFACE_PREFIX ) ) { continue ; } < |startfocus| > synchronized ( sStackedIfaces ) { if ( ! sStackedIfaces . containsKey ( entry . iface ) ) { continue ; } entry . rxBytes = entry . rxPackets * IPV4V6_HEADER_DELTA ; entry . txBytes = entry . txPackets * IPV4V6_HEADER_DELTA ; entry . rxPackets = 0 ; entry . txPackets = 0 ; stats . combineValues ( entry ) ; } < |endfocus| > } return stats ; } private NetworkStats readNetworkStatsDetailInternal ( int limitUid , String [ ] limitIfaces , int limitTag , NetworkStats lastStats ) throws IOException { if ( USE_NATIVE_PARSING ) { final NetworkStats stats ; if ( lastStats != null ) { stats = lastStats ; stats . setElapsedRealtime ( SystemClock . elapsedRealtime ( ) ) ; } else {
// base interface . For correct stats accounting on the base interface , every 464xlat // packets needs to be subtracted for the root UID on the base interface both for tx // and rx traffic ( http :/ / b / 12249687 , http :/ b / 33681750 ) . final int size = sStackedIfaces . size ( ) ; for ( int i = 0 ; i < size ; i ++ ) { final String stackedIface = sStackedIfaces . keyAt ( i ) ; final String baseIface = sStackedIfaces . valueAt ( i ) ; < |startfocus| > NetworkStats . Entry adjust = new NetworkStats . Entry ( baseIface , 0 , 0 , 0 , 0L , 0L , 0L , 0L , 0L ) ; for ( int j = 0 ; j < stats . size ( ) ; j ++ ) { entry = stats . getValues ( j , entry ) ; if ( Objects . equals ( entry . iface , stackedIface ) ) { adjust . rxBytes -= ( entry . rxBytes + entry . rxPackets * IPV4V6_HEADER_DELTA ) ; adjust . txBytes -= ( entry . txBytes + entry . txPackets * IPV4V6_HEADER_DELTA ) ; adjust . rxPackets -= entry . rxPackets ; adjust . txPackets -= entry . txPackets ; < |endfocus| >
assertStatsEntry ( stats , "lo" , 0 , SET_DEFAULT , 0x0 , 1288L , 1288L ) ; NetworkStatsFactory . noteStackedIface ( "v4 - wlan0" , null ) ; } public void testDoubleClatAccounting100MBDownload ( ) throws Exception { // Downloading 100mb from an ipv4 only destination in a foreground activity long appRxBytesBefore = 328684029L ; long appRxBytesAfter = 439237478L ; < |startfocus| > assertEquals ( "App traffic should be ~100MB" , 110553449 , appRxBytesAfter - appRxBytesBefore ) ; < |endfocus| > long rootRxBytesBefore = 1394011L ; long rootRxBytesAfter = 1398634L ; assertEquals ( "Root traffic should be ~0" , 4623 , rootRxBytesAfter - rootRxBytesBefore ) ; NetworkStatsFactory . noteStackedIface ( "v4 - wlan0" , "wlan0" ) ; NetworkStats stats ; // Stats snapshot before the download stats = parseDetailedStats ( R . raw . xt_qtaguid_with_clat_100mb_download_before ) ; assertStatsEntry ( stats , "v4 - wlan0" , 10106 , SET_FOREGROUND , 0x0 , appRxBytesBefore , 5199872L ) ; assertStatsEntry ( stats , "wlan0" , 0 , SET_DEFAULT , 0x0 , rootRxBytesBefore , 647888L ) ;
public void testDoubleClatAccounting100MBDownload ( ) throws Exception { // Downloading 100mb from an ipv4 only destination in a foreground activity long appRxBytesBefore = 328684029L ; long appRxBytesAfter = 439237478L ; assertEquals ( "App traffix should be ~100MB" , 110553449 , appRxBytesAfter - appRxBytesBefore ) ; long rootRxBytesBefore = 1394011L ; long rootRxBytesAfter = 1398634L ; < |startfocus| > assertEquals ( "Root traffic should be ~0" , 4623 , rootRxBytesAfter - rootRxBytesBefore ) ; < |endfocus| > NetworkStatsFactory . noteStackedIface ( "v4 - wlan0" , "wlan0" ) ; NetworkStats stats ; // Stats snapshot before the download stats = parseDetailedStats ( R . raw . xt_qtaguid_with_clat_100mb_download_before ) ; assertStatsEntry ( stats , "v4 - wlan0" , 10106 , SET_FOREGROUND , 0x0 , appRxBytesBefore , 5199872L ) ; assertStatsEntry ( stats , "wlan0" , 0 , SET_DEFAULT , 0x0 , rootRxBytesBefore , 647888L ) ; // Stats snapshot after the download stats = parseDetailedStats ( R . raw . xt_qtaguid_with_clat_100mb_download_after ) ;
public void onConnected ( ) { Log . d ( TAG , "BrowsablePlayerListBuilder : " + mCurrentPlayer . packageName + " OK" ) ; mCurrentBrowser . disconnect ( ) ; mCurrentBrowser = null ; mBrowsePlayerInfoList . add ( mCurrentPlayer ) ; MediaPlayerInfo info = getMediaPlayerInfo ( mCurrentPlayer . packageName ) ; < |startfocus| > MediaController controller = ( info == null ) ? null : info . getMediaController ( ) ; < |endfocus| > // Refresh the media player entry so it notices we can browse if ( controller != null ) { addMediaPlayerController ( controller . getWrappedInstance ( ) ) ; } else { addMediaPlayerPackage ( mCurrentPlayer . packageName ) ; } mPlayersChanged = true ; connectNextPlayer ( ) ;
} shr32 ( ) ; for ( int i = 0 ; i < 128 ; i ++ ) { expectEquals ( 0x3fffffff , a [ i ] , "shr32" ) ; } shr33 ( ) ; for ( int i = 0 ; i < 128 ; i ++ ) { expectEquals ( 0x1fffffff , a [ i ] , "shr33" ) ; } shrMinus254 ( ) ; for ( int i = 0 ; i < 128 ; i ++ ) { < |startfocus| > expectEquals ( 0x07ffffff , a [ i ] , "shrMinus254" ) ; < |endfocus| > } // Bit - wise not operator . not ( ) ; for ( int i = 0 ; i < 128 ; i ++ ) { expectEquals ( 0xf8000000 , a [ i ] , "not" ) ; } // Done . System . out . println ( "passed" ) ;
} shr64 ( ) ; for ( int i = 0 ; i < 128 ; i ++ ) { expectEquals ( 0x3fffffffffffffffL , a [ i ] , "shr64" ) ; } shr65 ( ) ; for ( int i = 0 ; i < 128 ; i ++ ) { expectEquals ( 0x1fffffffffffffffL , a [ i ] , "shr65" ) ; } shrMinus254 ( ) ; for ( int i = 0 ; i < 128 ; i ++ ) { < |startfocus| > expectEquals ( 0x07ffffffffffffffL , a [ i ] , "shrMinus254" ) ; < |endfocus| > } // Bit - wise not operator . not ( ) ; for ( int i = 0 ; i < 128 ; i ++ ) { expectEquals ( 0xf800000000000000L , a [ i ] , "not" ) ; } // Done . System . out . println ( "passed" ) ;
*/ @SdkConstant ( SdkConstantType . BROADCAST_INTENT_ACTION ) public static final String ACTION_REPORT = "android . bluetooth . input . profile . action . REPORT" ; /* * * @hide */ @SdkConstant ( SdkConstantType . BROADCAST_INTENT_ACTION ) public static final String ACTION_VIRTUAL_UNPLUG_STATUS = "android . bluetooth . input . profile . action . VIRTUAL_UNPLUG_STATUS" ; /* * * @hide */ @SdkConstant ( SdkConstantType . BROADCAST_INTENT_ACTION ) public static final String ACTION_IDLE_TIME_CHANGED = < |startfocus| > "codeaurora . bluetooth . input . profile . action . IDLE_TIME_CHANGED" ; < |endfocus| > /* * * Return codes for the connect and disconnect Bluez / Dbus calls . * @hide */ public static final int INPUT_DISCONNECT_FAILED_NOT_CONNECTED = 5000 ; /* * * @hide */ public static final int INPUT_CONNECT_FAILED_ALREADY_CONNECTED = 5001 ; /* * * @hide */ public static final int INPUT_CONNECT_FAILED_ATTEMPT_FAILED = 5002 ; /* * * @hide */ public static final int INPUT_OPERATION_GENERIC_FAILURE = 5003 ; /* * * @hide */ public static final int INPUT_OPERATION_SUCCESS = 5004 ; /* * * @hide */
/* * * @hide */ public static final String EXTRA_REPORT = "android . bluetooth . BluetoothInputDevice . extra . REPORT" ; /* * * @hide */ public static final String EXTRA_STATUS = "android . bluetooth . BluetoothInputDevice . extra . STATUS" ; /* * * @hide */ public static final String EXTRA_VIRTUAL_UNPLUG_STATUS = "android . bluetooth . BluetoothInputDevice . extra . VIRTUAL_UNPLUG_STATUS" ; /* * * @hide */ < |startfocus| > public static final String EXTRA_IDLE_TIME = "codeaurora . bluetooth . BluetoothInputDevice . extra . IDLE_TIME" ; < |endfocus| > private Context mContext ; private ServiceListener mServiceListener ; private BluetoothAdapter mAdapter ; private IBluetoothInputDevice mService ; final private IBluetoothStateChangeCallback mBluetoothStateChangeCallback = new IBluetoothStateChangeCallback . Stub ( ) { public void onBluetoothStateChange ( boolean up ) { if ( DBG ) Log . d ( TAG , "onBluetoothStateChange : up = " + up ) ; if ( ! up ) { if ( VDBG ) Log . d ( TAG , "Unbinding service . . . " ) ; synchronized ( mConnection ) { try { mService = null ; mContext . unbindService ( mConnection ) ; } catch ( Exception re ) { Log . e ( TAG , "" , re ) ; } } } else { synchronized ( mConnection ) { try { if ( mService == null ) { if ( VDBG ) Log . d ( TAG , "Binding service . . . " ) ; doBind ( ) ; } } catch ( Exception re ) { Log . e ( TAG , "" , re ) ; } } } } } ;
*/ public boolean getEmergencyCallbackMode ( int subId ) { try { ITelephony telephony = getITelephony ( ) ; if ( telephony == null ) { return false ; } return telephony . getEmergencyCallbackMode ( subId ) ; } catch ( RemoteException e ) { Log . e ( TAG , "Error calling ITelephony#getEmergencyCallbackMode" , e ) ; } return false ; } /* * * Get the most recently available signal strength information . * Get the most recent SignalStrength information reported by the modem . Due * to power saving this information may not always be current . * @return the most recent cached signal strength info from the modem * @hide */ @Nullable public SignalStrength getSignalStrength ( ) { try { ITelephony service = getITelephony ( ) ; if ( service != null ) { return service . getSignalStrength ( getSubId ( ) , getOpPackageName ( ) ) ; } } catch ( RemoteException e ) {
* class . The testcase checks that no any unexpected ERROR is returned and that * the JSR45 metadata matches the expected value . */ public void testSourceDebugExtension001 ( ) { doTest ( "testSourceDebugExtension001" , "Lorg / apache / harmony / jpda / tests / jdwp / Events / SourceDebugExtensionMockClass ; " , JDWPConstants . Error . NONE ) ; } /* * * This testcase exercises ReferenceType . SourceDebugExtension command . * * The class queried is a primitive type which on ART does not < |startfocus| > * have an associated dex cache . < |endfocus| > */ public void testSourceDebugExtension002 ( ) { doTest ( "testSourceDebugExtension001" , "I" , JDWPConstants . Error . ABSENT_INFORMATION ) ; } /* * * This testcase exercises ReferenceType . SourceDebugExtension command . * * The class queried is a primitive array which on ART does not * have an associated dex cache . */ public void testSourceDebugExtension003 ( ) { doTest ( "testSourceDebugExtension003" , " [ I" , JDWPConstants . Error . ABSENT_INFORMATION ) ; } /* * * This testcase exercises ReferenceType . SourceDebugExtension command . *
* the server name from the certificate mismatch . */ defaultHostnameVerifier = ( HostnameVerifier ) Class . forName ( "com . android . okhttp . internal . tls . OkHostnameVerifier" ) . getField ( "INSTANCE" ) . get ( null ) ; originalDefaultHostnameVerifierClass = defaultHostnameVerifier . getClass ( ) ; } catch ( Exception e ) { throw new AssertionError ( "Failed to obtain okhttp HostnameVerifier" , e ) ; } } } /* * * The < code > hostnameVerifier </ code > for this object . */ < |startfocus| > protected HostnameVerifier hostnameVerifier ; < |endfocus| > /* * * Sets the default < code > HostnameVerifier </ code > inherited by a * new instance of this class . * < P > * If this method is not called , the default * < code > HostnameVerifier </ code > assumes the connection should not * be permitted . * * @param v the default host name verifier * @throws IllegalArgumentException if the < code > HostnameVerifier </ code > * parameter is null . * @throws SecurityException if a security manager exists and its * < code > checkPermission </ code > method does not allow
// missing server , so no trusted time available return false ; } // We can't do this at initialization time : ConnectivityService might not be running yet . synchronized ( this ) { if ( mCM == null ) { mCM = ( ConnectivityManager ) sContext . getSystemService ( Context . CONNECTIVITY_SERVICE ) ; } } final NetworkInfo ni = mCM == null ? null : mCM . getActiveNetworkInfo ( ) ; < |startfocus| > if ( ni == null || ! ni . isConnected ( ) ) { < |endfocus| > if ( LOGD ) Log . d ( TAG , "forceRefresh : no connectivity" ) ; return false ; } if ( LOGD ) Log . d ( TAG , "forceRefresh ( ) from cache miss" ) ; final SntpClient client = new SntpClient ( ) ; if ( client . requestTime ( mServer , ( int ) mTimeout ) ) { mHasCache = true ; mCachedNtpTime = client . getNtpTime ( ) ; mCachedNtpElapsedRealtime = client . getNtpTimeReference ( ) ; mCachedNtpCertainty = client . getRoundTripTime ( ) / 2 ; return true ; } else { return false ; }
private void onPollNetworkTime ( int event ) { // If Automatic time is not set , don't bother . < |startfocus| > final NetworkInfo netInfo = mConnManager == null ? null : mConnManager . getActiveNetworkInfo ( ) ; if ( ! isAutomaticTimeRequested ( ) || ! netInfo . isConnected ( ) ) return ; < |endfocus| > mWakeLock . acquire ( ) ; try { onPollNetworkTimeUnderWakeLock ( event ) ; } finally { mWakeLock . release ( ) ; } }
private void onPollNetworkTime ( int event ) { // If Automatic time is not set , don't bother . < |startfocus| > if ( ! isAutomaticTimeRequested ( ) ) return ; if ( mConnManager == null ) return ; if ( ! mConnManager . getActiveNetworkInfo ( ) . isConnected ( ) ) return ; < |endfocus| > mWakeLock . acquire ( ) ; try { onPollNetworkTimeUnderWakeLock ( event ) ; } finally { mWakeLock . release ( ) ; }
* * You should have received a copy of the GNU General Public License version * 2 along with this work ; if not , write to the Free Software Foundation , * Inc . , 51 Franklin St , Fifth Floor , Boston , MA 02110 - 1301 USA . * * Please contact Oracle , 500 Oracle Parkway , Redwood Shores , CA 94065 USA * or visit www . oracle . com if you need additional information or have any * questions . */ package javax . security . auth ; < |startfocus| > // Android - changed : This permission system is unavailable on Android . < |endfocus| > /* * * Legacy security code ; do not use . */ public final class AuthPermission extends java . security . BasicPermission { public AuthPermission ( String name ) { super ( "" ) ; } public AuthPermission ( String name , String actions ) { super ( "" , "" ) ; } }
public NetworkTimeUpdateService ( Context context ) { mContext = context ; mTime = NtpTrustedTime . getInstance ( context ) ; mAlarmManager = ( AlarmManager ) mContext . getSystemService ( Context . ALARM_SERVICE ) ; < |startfocus| > mCM = ( ConnectivityManager ) mContext . getSystemService ( Context . CONNECTIVITY_SERVICE ) ; < |endfocus| > Intent pollIntent = new Intent ( ACTION_POLL , null ) ; mPendingPollIntent = PendingIntent . getBroadcast ( mContext , POLL_REQUEST , pollIntent , 0 ) ; mPollingIntervalMs = mContext . getResources ( ) . getInteger ( com . android . internal . R . integer . config_ntpPollingInterval ) ; mPollingIntervalShorterMs = mContext . getResources ( ) . getInteger ( com . android . internal . R . integer . config_ntpPollingIntervalShorter ) ; mTryAgainTimesMax = mContext . getResources ( ) . getInteger ( com . android . internal . R . integer . config_ntpRetry ) ; mTimeErrorThresholdMs = mContext . getResources ( ) . getInteger ( com . android . internal . R . integer . config_ntpThreshold ) ; mWakeLock = ( ( PowerManager ) context . getSystemService ( Context . POWER_SERVICE ) ) . newWakeLock ( PowerManager . PARTIAL_WAKE_LOCK , TAG ) ;
} } } ; /* * Handler to do the network accesses on */ private class MyHandler extends Handler { public MyHandler ( Looper l ) { super ( l ) ; } @Override public void handleMessage ( Message msg ) { switch ( msg . what ) { case EVENT_AUTO_TIME_CHANGED : case EVENT_POLL_NETWORK_TIME : case EVENT_NETWORK_CHANGED : onPollNetworkTime ( msg . what ) ; break ; } } } < |startfocus| > private class TimeServiceNetworkCallback extends ConnectivityManager . NetworkCallback { < |endfocus| > @Override public void onCapabilitiesChanged ( Network network , NetworkCapabilities networkCapabilities ) { if ( networkCapabilities . hasCapability ( NetworkCapabilities . NET_CAPABILITY_VALIDATED ) ) { mNetworkValidated = true ; } else { mNetworkValidated = false ; } } } /* * Observer to watch for changes to the AUTO_TIME setting */ private static class SettingsObserver extends ContentObserver { private int mMsg ; private Handler mHandler ; SettingsObserver ( Handler handler , int msg ) { super ( handler ) ; mHandler = handler ; mMsg = msg ; } void observe ( Context context ) {
} } } ; /* * Handler to do the network accesses on */ private class MyHandler extends Handler { public MyHandler ( Looper l ) { super ( l ) ; } @Override public void handleMessage ( Message msg ) { switch ( msg . what ) { case EVENT_AUTO_TIME_CHANGED : case EVENT_POLL_NETWORK_TIME : case EVENT_NETWORK_CHANGED : onPollNetworkTime ( msg . what ) ; break ; } } } < |startfocus| > private class NetworkCallback extends ConnectivityManager . NetworkCallback { < |endfocus| > @Override public void onCapabilitiesChanged ( Network network , NetworkCapabilities networkCapabilities ) { if ( networkCapabilities . hasCapability ( NetworkCapabilities . NET_CAPABILITY_VALIDATED ) ) { mNetworkValidated = true ; } else { mNetworkValidated = false ; } } } /* * Observer to watch for changes to the AUTO_TIME setting */ private static class SettingsObserver extends ContentObserver { private int mMsg ; private Handler mHandler ; SettingsObserver ( Handler handler , int msg ) { super ( handler ) ; mHandler = handler ; mMsg = msg ; } void observe ( Context context ) {
public void onCapabilitiesChanged ( Network network , NetworkCapabilities networkCapabilities ) { mNetworkValidated = networkCapabilities . hasCapability ( NetworkCapabilities . NET_CAPABILITY_VALIDATED ) ; < |startfocus| > < |endfocus| >
private void onPollNetworkTime ( int event ) { // If Automatic time is not set , don't bother . final NetworkInfo netInfo = mConnManager == null ? null : mConnManager . getActiveNetworkInfo ( ) ; < |startfocus| > if ( ! isAutomaticTimeRequested ( ) || < |endfocus| > netInfo == null || ! netInfo . isConnected ( ) ) return ; mWakeLock . acquire ( ) ; try { onPollNetworkTimeUnderWakeLock ( event ) ; } finally { mWakeLock . release ( ) ; }
return ; case INS_GET_LOCK : /* getLock ( lockId , sendMetadata ) */ resp = sendLockData ( apdu , p1 , p2 ) ; if ( resp != 0 ) { sendResponseCode ( apdu , resp ) ; } return ; case INS_SET_LOCK : /* setlock ( index , val ) { data } */ if ( p1 >= ( byte ) locks . length ) { sendResponseCode ( apdu , ( short ) 0x0100 ) ; return ; } < |startfocus| > if ( metadataLength == ( short ) 0 ) { resp = locks [ p1 ] . set ( p2 ) ; sendResponseCode ( apdu , resp ) ; < |endfocus| > return ; } resp = locks [ p1 ] . setWithMetadata ( p2 , metadata , ( short ) 0 , metadataLength ) ; // "Consume" the metadata . metadataLength = ( short ) 0 ; sendResponseCode ( apdu , resp ) ; return ; case INS_SET_PRODUCTION : /* setProduction ( p1 ) */ if ( globalState . setProduction ( enable ) == true ) { resp = 0x0000 ; } else { resp = 0x0001 ; } sendResponseCode ( apdu , resp ) ; return ; /* carrierLockTest ( ) { testVector } */
import android . widget . TextView ; import java . io . IOException ; import java . net . HttpURLConnection ; import java . net . MalformedURLException ; import java . net . URL ; import java . lang . InterruptedException ; import java . lang . reflect . Field ; import java . lang . reflect . Method ; import java . util . Random ; public class CaptivePortalLoginActivity extends Activity { private static final String TAG = CaptivePortalLoginActivity . class . getSimpleName ( ) ; private static final boolean DBG = true ; < |startfocus| > // Turn this flag on to deactivate auto - closing after successful captive portal login . private static final boolean NO_AUTOCLOSE = false ; < |endfocus| > private static final int SOCKET_TIMEOUT_MS = 10000 ; private enum Result { DISMISSED , UNWANTED , WANTED_AS_IS } ; private URL mUrl ; private String mUserAgent ; private Network mNetwork ; private CaptivePortal mCaptivePortal ; private NetworkCallback mNetworkCallback ; private ConnectivityManager mCm ; private boolean mLaunchBrowser = false ; private MyWebViewClient mWebViewClient ; @Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ) ; mCm = ConnectivityManager . from ( this ) ;
private void testForCaptivePortal ( ) { < |startfocus| > if ( NO_AUTOCLOSE ) { return ; } < |endfocus| > // TODO : reuse NetworkMonitor facilities for consistent captive portal detection . new Thread ( new Runnable ( ) { public void run ( ) { // Give time for captive portal to open . try { Thread . sleep ( 1000 ) ; } catch ( InterruptedException e ) { } HttpURLConnection urlConnection = null ; int httpResponseCode = 500 ; try { urlConnection = ( HttpURLConnection ) mNetwork . openConnection ( mUrl ) ; urlConnection . setInstanceFollowRedirects ( false ) ; urlConnection . setConnectTimeout ( SOCKET_TIMEOUT_MS ) ; urlConnection . setReadTimeout ( SOCKET_TIMEOUT_MS ) ; urlConnection . setUseCaches ( false ) ; if ( mUserAgent != null ) { urlConnection . setRequestProperty ( "User - Agent" , mUserAgent ) ; } // cannot read request header after connection String requestHeader = urlConnection . getRequestProperties ( ) . toString ( ) ; urlConnection . getInputStream ( ) ; httpResponseCode = urlConnection . getResponseCode ( ) ; if ( DBG ) { Log . d ( TAG , "probe at " + mUrl + " returned " + httpResponseCode ) ; } if ( httpResponseCode == 204 ) { // 204 is no content ; indicates that captive portal check was successful . if ( DBG ) { Log . d ( TAG , "successful captive portal check" ) ; } sendMessage ( EVENT_PROVISIONING_SUCCESS , 0 , mNetworkType ) ; } else { if ( DBG ) { Log . d ( TAG , "failed captive portal check" ) ; } sendMessage ( EVENT_PROVISIONING_NOTIFICATION , STATUS_CODE_UNKNOWN , mNetworkType ) ; } } catch ( IOException e ) { if ( DBG ) { Log . d ( TAG , "probe failed with exception " + e ) ; } sendMessage ( EVENT_PROVISIONING_NOTIFICATION , STATUS_CODE_UNKNOWN , mNetworkType ) ; } finally { if ( urlConnection != null ) { urlConnection . disconnect ( ) ; } } } } ) . start ( ) ; }
public void systemRunning ( ) { registerForTelephonyIntents ( ) ; registerForAlarms ( ) ; HandlerThread thread = new HandlerThread ( TAG ) ; thread . start ( ) ; mHandler = new MyHandler ( thread . getLooper ( ) ) ; mNetworkTimeUpdateCallback = new NetworkTimeUpdateCallback ( ) ; mCM . registerDefaultNetworkCallback ( mNetworkTimeUpdateCallback , mHandler ) ; < |startfocus| > // Check the network time on the new thread mHandler . obtainMessage ( EVENT_POLL_NETWORK_TIME ) . sendToTarget ( ) ; < |endfocus| > mSettingsObserver = new SettingsObserver ( mHandler , EVENT_AUTO_TIME_CHANGED ) ; mSettingsObserver . observe ( mContext ) ;
< |startfocus| > public void onCapabilitiesChanged ( Network network , NetworkCapabilities netCap ) { mNetworkValidated = netCap . hasCapability ( < |endfocus| > NetworkCapabilities . NET_CAPABILITY_VALIDATED ) ;
public void onCapabilitiesChanged ( Network network , NetworkCapabilities networkCapabilities ) { mNetworkValidated = networkCapabilities . hasCapability ( NetworkCapabilities . NET_CAPABILITY_VALIDATED ) ;
public void onCapabilitiesChanged ( Network network , NetworkCapabilities networkCapabilities ) { mNetworkValidated = networkCapabilities . hasCapability ( NetworkCapabilities . NET_CAPABILITY_VALIDATED ) ;
// / CHECK - DAG : < < Get2 : b\d + > > ArrayGet loop : < < Loop > > outer_loop : none // / CHECK - DAG : < < Max : i\d + > > InvokeStaticOrDirect [ < < Get1 > > , < < Get2 > > ] intrinsic : MathMaxIntInt loop : < < Loop > > outer_loop : none // / CHECK - DAG : < < Cnv : b\d + > > TypeConversion [ < < Max > > ] loop : < < Loop > > outer_loop : none // / CHECK - DAG : ArraySet [ { { l\d + } } , < < Phi > > , < < Cnv > > ] loop : < < Loop > > outer_loop : none // < |startfocus| > // TODO : narrow type vectorization . < |endfocus| > private static void doitMax ( byte [ ] x , byte [ ] y , byte [ ] z ) { int min = Math . min ( x . length , Math . min ( y . length , z . length ) ) ; for ( int i = 0 ; i < min ; i ++ ) { x [ i ] = ( byte ) Math . max ( y [ i ] , z [ i ] ) ; } } public static void main ( String [ ] args ) { // Initialize cross - values for the interesting values . int total = 256 * 256 ; byte [ ] x = new byte [ total ] ;
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package android . telephony ; import android . content . ComponentName ; import android . content . Context ; import android . content . Intent ; import android . content . ServiceConnection ; import android . content . pm . PackageManager ; import android . content . pm . ResolveInfo ; import android . os . DeadObjectException ; import android . os . IBinder ; import android . os . RemoteException ; import android . telephony . mbms . IMbmsStreamingManagerCallback ; import android . telephony . mbms . IStreamingServiceCallback ; import android . telephony . mbms . MbmsException ; import android . telephony . mbms . StreamingService ; import android . telephony . mbms . StreamingServiceInfo ; import android . telephony . mbms . vendor . IMbmsStreamingService ; import android . util . Log ; import java . util . LinkedList ; import java . util . List ; import java . util . concurrent . CountDownLatch ; import java . util . concurrent . TimeUnit ; import static android . telephony . SubscriptionManager . INVALID_SUBSCRIPTION_ID ; /* * @hide */ public class MbmsStreamingManager { private interface ServiceListener { void onServiceConnected ( ) ; void onServiceDisconnected ( ) ; } private static final String LOG_TAG = "MbmsStreamingManager" ;
* limitations under the License . */ package android . os ; /* * * Mimics the real Android class when running tests on host . This class is needed by the code * generated by Desugar to choose the runtime strategy of try - with - resource based on the android * runtime version . Set it to 17 to force to use the mimic desugaring strategy . */ public class Build { public static class VERSION { public static final int SDK_INT = 17 ; < |startfocus| > public static final String SDK = "17" ; < |endfocus| > } }
* limitations under the License . */ package android . os ; /* * * Mimics the real Android class when running tests on host . This class is needed by the code * generated by Desugar to choose the runtime strategy of try - with - resource based on the android * runtime version . Set it to 17 to force to use the mimic desugaring strategy . */ public class Build { public static class VERSION { public static final int SDK_INT = 17 ; < |startfocus| > public static final String SDK = "17" ; < |endfocus| > } }
import java . util . List ; import java . util . Locale ; import java . util . Objects ; import java . util . Random ; import java . util . concurrent . CountDownLatch ; import java . util . concurrent . Semaphore ; import java . util . concurrent . TimeUnit ; import static java . nio . charset . StandardCharsets . UTF_8 ; /* * * Tests URLConnections for ftp :/ / URLs . */ public class FtpURLConnectionTest extends TestCase { private static final String FILE_PATH = "test / file / for / FtpURLConnectionTest . txt" ; < |startfocus| > private static final String VALID_USER = "user" ; private static final String VALID_PASSWORD = "password" ; < |endfocus| > private static final String SERVER_HOSTNAME = "localhost" ; private static final String USER_HOME_DIR = " / home / user" ; private FakeFtpServer fakeFtpServer ; private UnixFakeFileSystem fileSystem ; @Override public void setUp ( ) throws Exception { super . setUp ( ) ; fakeFtpServer = new FakeFtpServer ( ) ; fakeFtpServer . setServerControlPort ( 0 /* allocate port number automatically */ ) ; fakeFtpServer . addUserAccount ( new UserAccount ( VALID_USER , VALID_PASSWORD , USER_HOME_DIR ) ) ; fileSystem = new UnixFakeFileSystem ( ) ; fakeFtpServer . setFileSystem ( fileSystem ) ;
int total = interesting . length * interesting . length ; short [ ] x = new short [ total ] ; short [ ] y = new short [ total ] ; short [ ] z = new short [ total ] ; int k = 0 ; for ( int i = 0 ; i < interesting . length ; i ++ ) { for ( int j = 0 ; j < interesting . length ; j ++ ) { x [ k ] = 0 ; y [ k ] = interesting [ i ] ; z [ k ] = interesting [ j ] ; k ++ ; } } < |startfocus| > < |endfocus| > // And test . doitMin ( x , y , z ) ; for ( int i = 0 ; i < total ; i ++ ) { short expected = ( short ) Math . min ( y [ i ] , z [ i ] ) ; expectEquals ( expected , x [ i ] ) ; } doitMax ( x , y , z ) ; for ( int i = 0 ; i < total ; i ++ ) { short expected = ( short ) Math . max ( y [ i ] , z [ i ] ) ; expectEquals ( expected , x [ i ] ) ; } System . out . println ( "passed" ) ;
< |startfocus| > private void recordAndEmit ( Category category , String msg ) { < |endfocus| > final String entry = logLine ( category , msg ) ; mLocalLog . log ( entry ) ; if ( ERROR . equals ( category ) ) { Log . e ( mTag , entry ) ; } else { Log . d ( mTag , entry ) ; }
import android . content . Context ; import android . content . ContextWrapper ; import android . content . res . Resources ; import android . support . test . filters . SmallTest ; import android . support . test . runner . AndroidJUnit4 ; import android . telephony . TelephonyManager ; import com . android . internal . util . test . BroadcastInterceptingContext ; import org . junit . Before ; import org . junit . Test ; import org . junit . runner . RunWith ; import org . mockito . Mock ; import org . mockito . MockitoAnnotations ; @RunWith ( AndroidJUnit4 . class ) @SmallTest public class TetheringConfigurationTest { < |startfocus| > private static final String [ ] PROVISIONING_APP_NAME = { "some" , "app" } ; < |endfocus| > @Mock private Context mContext ; @Mock private TelephonyManager mTelephonyManager ; @Mock private Resources mResources ; private Context mMockContext ; private boolean mWithTelephonyManager ; private class MockContext extends BroadcastInterceptingContext { MockContext ( Context base ) { super ( base ) ; } @Override public Resources getResources ( ) { return mResources ; } @Override public Object getSystemService ( String name ) { if ( Context . TELEPHONY_SERVICE . equals ( name ) ) { return mWithTelephonyManager ? mTelephonyManager : null ; } return super . getSystemService ( name ) ; } }
import android . telephony . TelephonyManager ; import com . android . internal . util . test . BroadcastInterceptingContext ; import org . junit . Before ; import org . junit . Test ; import org . junit . runner . RunWith ; import org . mockito . Mock ; import org . mockito . MockitoAnnotations ; @RunWith ( AndroidJUnit4 . class ) @SmallTest public class TetheringConfigurationTest { private static final String [ ] PROVISIONING_APP_NAME = { "some" , "app" } ; @Mock private Context mContext ; @Mock private TelephonyManager mTelephonyManager ; @Mock private Resources mResources ; private Context mMockContext ; < |startfocus| > private boolean mHasTelephonyManager ; < |endfocus| > private class MockContext extends BroadcastInterceptingContext { MockContext ( Context base ) { super ( base ) ; } @Override public Resources getResources ( ) { return mResources ; } @Override public Object getSystemService ( String name ) { if ( Context . TELEPHONY_SERVICE . equals ( name ) ) { return mHasTelephonyManager ? mTelephonyManager : null ; } return super . getSystemService ( name ) ; } } @Before public void setUp ( ) throws Exception { MockitoAnnotations . initMocks ( this ) ;
* is only meant for debugging and is not guaranteed to be stable across * releases and / or devices . * * @hide */ public static native String getDexFileStatus ( String fileName , String instructionSet ) throws FileNotFoundException ; /* * < |startfocus| > * Returns the full file path of the optimized dex file { @code fileName } . The returned string * is the full file name including path of optimized dex file , if it exists . < |endfocus| > * @hide */ public static native String [ ] getDexFileOutputPath ( String fileName , String instructionSet ) throws FileNotFoundException ; /* * * Returns whether the given filter is a valid filter . * * @hide */ public native static boolean isValidCompilerFilter ( String filter ) ; /* * * Returns whether the given filter is based on profiles . * * @hide */ public native static boolean isProfileGuidedCompilerFilter ( String filter ) ; /* * * Returns the version of the compiler filter that is not based on profiles .
* releases and / or devices . * * @hide */ public static native String getDexFileStatus ( String fileName , String instructionSet ) throws FileNotFoundException ; /* * * Returns the full file path of the optimized dex file { @code fileName } . The returned string * is the full file name including path of optimized dex file , if it exists . * @hide */ < |startfocus| > public static native String [ ] getDexFileOutputPaths ( String fileName , String instructionSet ) < |endfocus| > throws FileNotFoundException ; /* * * Returns whether the given filter is a valid filter . * * @hide */ public native static boolean isValidCompilerFilter ( String filter ) ; /* * * Returns whether the given filter is based on profiles . * * @hide */ public native static boolean isProfileGuidedCompilerFilter ( String filter ) ; /* * * Returns the version of the compiler filter that is not based on profiles . * If the input is not a valid filter , or the filter is already not based on
// determine the ABI from either ApplicationInfo or Build String arch = "arm" ; if ( cameraInfo . primaryCpuAbi != null && VMRuntime . is64BitAbi ( cameraInfo . primaryCpuAbi ) ) { arch = arch + "64" ; } else { if ( VMRuntime . is64BitAbi ( Build . SUPPORTED_ABIS [ 0 ] ) ) { arch = arch + "64" ; } } // get the path to the odex or oat file String baseCodePath = cameraInfo . getBaseCodePath ( ) ; String [ ] optimizedCode = null ; try { < |startfocus| > optimizedCode = DexFile . getDexFileOutputPath ( baseCodePath , arch ) ; < |endfocus| > } catch ( IOException ioe ) { } if ( optimizedCode == null ) { return true ; } // not pinning the oat / odex is not a fatal error for ( int i = 0 ; i < optimizedCode . length ; i ++ ) { pf = pinFile ( optimizedCode [ i ] , 0 , 0 , MAX_CAMERA_PIN_SIZE ) ; if ( pf != null ) { mPinnedCameraFiles . add ( pf ) ; if ( DEBUG ) { Slog . i ( TAG , "Pinned " + pf . mFilename ) ; } }
String baseCodePath = cameraInfo . getBaseCodePath ( ) ; String [ ] optimizedCode = null ; try { optimizedCode = DexFile . getDexFileOutputPath ( baseCodePath , arch ) ; } catch ( IOException ioe ) { } if ( optimizedCode == null ) { return true ; } // not pinning the oat / odex is not a fatal error < |startfocus| > for ( String file : optimizedCode ) { pf = pinFile ( file , 0 , 0 , MAX_CAMERA_PIN_SIZE ) ; < |endfocus| > if ( pf != null ) { mPinnedCameraFiles . add ( pf ) ; if ( DEBUG ) { Slog . i ( TAG , "Pinned " + pf . mFilename ) ; } } } return true ;
String baseCodePath = cameraInfo . getBaseCodePath ( ) ; String [ ] optimizedCode = null ; try { optimizedCode = DexFile . getDexFileOutputPath ( baseCodePath , arch ) ; } catch ( IOException ioe ) { } if ( optimizedCode == null ) { return true ; } // not pinning the oat / odex is not a fatal error < |startfocus| > for ( int i = 0 ; i < optimizedCode . length ; i ++ ) { pf = pinFile ( optimizedCode [ i ] , 0 , 0 , MAX_CAMERA_PIN_SIZE ) ; if ( pf != null ) { mPinnedCameraFiles . add ( pf ) ; if ( DEBUG ) { Slog . i ( TAG , "Pinned " + pf . mFilename ) ; } } } < |endfocus| > return true ;
packageIntentFilter . addAction ( Intent . ACTION_PACKAGE_REMOVED ) ; packageIntentFilter . addAction ( Intent . ACTION_PACKAGE_ADDED ) ; packageIntentFilter . addDataScheme ( "package" ) ; context . registerReceiverAsUser ( mReceiver , UserHandle . ALL , packageIntentFilter , null , null ) ; IntentFilter bootIntentFilter = new IntentFilter ( Intent . ACTION_BOOT_COMPLETED ) ; context . registerReceiverAsUser ( mReceiver , UserHandle . ALL , bootIntentFilter , null , null ) ; IntentFilter userRemovedFilter = new IntentFilter ( Intent . ACTION_USER_REMOVED ) ; < |startfocus| > context . registerReceiver ( mReceiver , userRemovedFilter ) ; < |endfocus| > Uri defaultDialerSetting = Settings . Secure . getUriFor ( Settings . Secure . DIALER_DEFAULT_APPLICATION ) ; context . getContentResolver ( ) . registerContentObserver ( defaultDialerSetting , false , mDefaultDialerObserver , UserHandle . USER_ALL ) ;
< |startfocus| > public IPv6TetheringCoordinator ( ArrayList < TetherInterfaceStateMachine > notifyList , SharedLog log ) { mLog = log . forSubComponent ( TAG ) ; < |endfocus| > mNotifyList = notifyList ; mActiveDownstreams = new LinkedList < > ( ) ; mUniqueLocalPrefix = generateUniqueLocalPrefix ( ) ; mNextSubnetId = 0 ;
< |startfocus| > public void e ( String msg ) { recordAndEmit ( Category . ERROR , msg ) ; < |endfocus| >
} public void dump ( FileDescriptor fd , PrintWriter writer , String [ ] args ) { mLocalLog . readOnlyLocalLog ( ) . dump ( fd , writer , args ) ; } public void error ( Exception e ) { recordAndEmit ( Category . ERROR , e . toString ( ) ) ; } public void error ( String msg ) { recordAndEmit ( Category . ERROR , msg ) ; } public void event ( String msg ) { recordAndEmit ( Category . EVENT , msg ) ; } public void log ( String msg ) { record ( Category . NONE , msg ) ; } < |startfocus| > public void logAndEmit ( String msg ) { recordAndEmit ( Category . NONE , msg ) ; } < |endfocus| > public void mark ( String msg ) { record ( Category . MARK , msg ) ; } private void record ( Category category , String msg ) { mLocalLog . log ( logLine ( category , msg ) ) ; } private void recordAndEmit ( Category category , String msg ) { final String entry = logLine ( category , msg ) ; mLocalLog . log ( entry ) ; if ( Category . ERROR . equals ( category ) ) { Log . e ( mTag , entry ) ; } else { Log . d ( mTag , entry ) ; } }
phoneAccountHandle = extras . getParcelable ( TelecomManager . EXTRA_PHONE_ACCOUNT_HANDLE ) ; } boolean isSelfManaged = phoneAccountHandle != null && isSelfManagedConnectionService ( phoneAccountHandle ) ; if ( isSelfManaged ) { mContext . enforceCallingOrSelfPermission ( Manifest . permission . MANAGE_OWN_CALLS , "Self - managed ConnectionServices require MANAGE_OWN_CALLS permission . " ) ; if ( ! callingPackage . equals ( phoneAccountHandle . getComponentName ( ) . getPackageName ( ) ) && ! canCallPhone ( callingPackage , < |startfocus| > "CALL_PHONE permission required to place calls . " ) ) { < |endfocus| > // The caller is not allowed to place calls , so we want to ensure that it // can only place calls through itself . throw new SecurityException ( "Self - managed ConnectionServices can only " + "place calls through their own ConnectionService . " ) ; } } else if ( ! canCallPhone ( callingPackage , "placeCall" ) ) { throw new SecurityException ( "Package " + callingPackage + " is not allowed to place phone calls" ) ; } //
private String logLine ( Category category , String msg ) { final StringJoiner sj = new StringJoiner ( " " ) ; if ( ! isRootLogInstance ( ) ) sj . add ( " [ " + mComponent + " ] " ) ; < |startfocus| > if ( category != Category . NONE ) sj . add ( category . toString ( ) ) ; < |endfocus| > return sj . add ( msg ) . toString ( ) ;
* is used for accessing the key store and trust store for TLS * certificates . * * @param target The base URL for the server to be accessed . * @param conf The configuration for certificates and credentials . * @param mapper The object mapper . * @param loader The resource loader . */ public GatewayClient ( String target , ClientConfig conf , ObjectMapper mapper , ResourceLoader loader ) { super ( target , conf , mapper , loader ) ; } /* * * Ping the peer Acumos . * * @param peerId The ID of the peer Acumos . * @return Information about the peer . */ public MLPPeer ping ( String peerId ) { return handleResponse ( PEER_PFX + FederationClient . PING_URI , new ParameterizedTypeReference < JsonResponse < MLPPeer > > ( ) { } , peerId ) ; } /* * * Ask the peer about its peers . * * @param peerId The ID of the peer Acumos . * @return The list of the peer's peers . */ public List < MLPPeer > getPeers ( String peerId ) {
} /* * * Ask the peer about its peers . * * @param peerId The ID of the peer Acumos . * @return The list of the peer's peers . */ public List < MLPPeer > getPeers ( String peerId ) { return handleResponse ( PEER_PFX + FederationClient . PEERS_URI , new ParameterizedTypeReference < JsonResponse < List < MLPPeer > > > ( ) { } , peerId ) ; } /* * < |startfocus| > * Register with the peer . < |endfocus| > * * @param peerId The ID of the peer Acumos . * @return Information about the peer . */ public MLPPeer register ( String peerId ) { return handleResponse ( PEER_PFX + FederationClient . REGISTER_URI , HttpMethod . POST , new ParameterizedTypeReference < JsonResponse < MLPPeer > > ( ) { } , peerId ) ; } /* * * Ask the peer for a list of catalogs . * * @param peerId The ID of the peer Acumos . * @return The list of catalogs ( enhanced with their sizes ) , the peer is willing to share . */ public List < MLPCatalog > getCatalogs ( String peerId ) {
* * Configuration classes are also Conponents so they are subject to Component scanning . */ @SpringBootApplication @EnableAutoConfiguration ( exclude = { DataSourceAutoConfiguration . class , DataSourceTransactionManagerAutoConfiguration . class , HibernateJpaAutoConfiguration . class } ) @EnableConfigurationProperties @ComponentScan ( basePackages = "org . acumos . federation" , useDefaultFilters = false , includeFilters = @ComponentScan . Filter ( type = FilterType . ASSIGNABLE_TYPE , classes = { org . acumos . federation . gateway . config . GatewayConfiguration . class , org . acumos . federation . gateway . config . AdapterConfiguration . class } ) ) < |startfocus| > public class Application { < |endfocus| > private final static EELFLoggerDelegate logger = EELFLoggerDelegate . getLogger ( Application . class ) ; /* * * We should be able to swap the LocalConfiguration in the case of adapters . */ public static void main ( String [ ] args ) throws Exception { SpringApplicationBuilder gatewayBuilder = new SpringApplicationBuilder ( Application . class ) . bannerMode ( Banner . Mode . OFF ) . web ( false ) ; gatewayBuilder . child ( FederationConfiguration . class ) . bannerMode ( Banner . Mode . OFF ) . web ( true ) . run ( args ) ; gatewayBuilder . child ( LocalConfiguration . class ) . bannerMode ( Banner . Mode . OFF ) . web ( true ) . run ( args ) ; } }
public MLPSolution createSolution ( MLPSolution solution ) { < |startfocus| > Set < MLPTag > tags = solution . getTags ( ) ; solution . setTags ( Collections . emptySet ( ) ) ; solution = clients . getCDSClient ( ) . createSolution ( solution ) ; doTags ( tags , solution . getSolutionId ( ) ) ; return solution ; < |endfocus| >
import com . github . dockerjava . api . DockerClient ; import com . github . dockerjava . core . DefaultDockerClientConfig ; import com . github . dockerjava . core . DockerClientBuilder ; import org . acumos . cds . client . ICommonDataServiceRestClient ; import org . acumos . cds . client . CommonDataServiceRestClientImpl ; import org . acumos . federation . client . config . ClientConfig ; import org . acumos . federation . client . ClientBase ; import org . acumos . federation . client . FederationClient ; /* * * Defines all beans used to access outside services . * * By mocking this bean , all external access can be stubbed out . */ < |startfocus| > public class Clients { < |endfocus| > @Autowired private FederationConfig federation ; @Autowired private ServiceConfig cdmsConfig ; @Autowired private NexusConfig nexusConfig ; @Autowired private DockerConfig dockerConfig ; private ICommonDataServiceRestClient cdsClient ; private NexusClient nexusClient ; private DockerClient dockerClient ; public FederationClient getFederationClient ( String url ) { return new FederationClient ( url , federation ) ; } public synchronized ICommonDataServiceRestClient getCDSClient ( ) { if ( cdsClient == null ) { String url = cdmsConfig . getUrl ( ) ; ClientConfig cc = new ClientConfig ( ) ; cc . setCreds ( cdmsConfig ) ;
public InputStream getArtifactContent ( MLPArtifact artifact ) ; /* * * Set the URI for an artifact . * * @param solutionId The ID of the solution . * @param artifact The artifact to set the URI on . */ public void setArtifactUri ( String solutionId , MLPArtifact artifact ) ; /* * * Put the content of an artifact . * * @param artifact The artifact to put . * @param tag The image tag in the input data . < |startfocus| > * @param is The data to put . < |endfocus| > */ public void putArtifactContent ( MLPArtifact artifact , String tag , InputStream is ) ; /* * * Get the body of a document . * * @param document The document to retrieve . * @return An InputStream for reading the document's content . */ public InputStream getDocumentContent ( MLPDocument document ) ; /* * * Set the URI for an document . * * @param solutionId The ID of the solution . * @param document The document to set the URI on . */ public void setDocumentUri ( String solutionId , MLPDocument document ) ; /* * * Put the content of a document . * * @param document The document to put . * @param tag The image tag in the input data . * @param is The data to put . */ public void putDocumentContent ( MLPDocument document , String tag , InputStream is ) ; /* * * Get the body of a notebook . * * @param notebook The notebook to retrieve . * @return An InputStream for reading the notebook's content . */ public InputStream getNotebookContent ( MLPNotebook notebook ) ; /* * * Set the URI for an notebook . * * @param solutionId The ID of the solution . * @param notebook The notebook to set the URI on . */ public void setNotebookUri ( String solutionId , MLPNotebook notebook ) ; /* * * Put the content of a notebook . * * @param notebook The notebook to put . * @param tag The image tag in the input data . * @param is The data to put . */ public void putNotebookContent ( MLPNotebook notebook , String tag , InputStream is ) ; /* * * Get the body of a pipeline . * * @param pipeline The pipeline to retrieve . * @return An InputStream for reading the pipeline's content . */ public InputStream getPipelineContent ( MLPPipeline pipeline ) ; /* * * Set the URI for an pipeline . * * @param solutionId The ID of the solution . * @param pipeline The pipeline to set the URI on . */ public void setPipelineUri ( String solutionId , MLPPipeline pipeline ) ; /* * * Put the content of a pipeline . * * @param pipeline The pipeline to put . * @param tag The image tag in the input data . * @param is The data to put . */ public void putPipelineContent ( MLPPipeline pipeline , String tag , InputStream is ) ; /* * * Get the body of a pipeline . * * @param pipeline The pipeline to retrieve . * @return An InputStream for reading the pipeline's content . */ public InputStream getPipelineContent ( MLPPipeline pipeline ) ; /* * * Set the URI for an pipeline . * * @param solutionId The ID of the solution . * @param pipeline The pipeline to set the URI on . */ public void setPipelineUri ( String solutionId , MLPPipeline pipeline ) ; /* * * Put the content of a pipeline . * * @param pipeline The pipeline to put . * @param tag The image tag in the input data . * @param is The data to put . */ public void putPipelineContent ( MLPPipeline pipeline , String tag , InputStream is ) ; /* * * Get the body of a pipeline . * * @param pipeline The pipeline to retrieve . * @return An InputStream for reading the pipeline's content . */ public InputStream getPipelineContent ( MLPPipeline pipeline ) ; /* * * Set the URI for an pipeline . * * @param solutionId The ID of the solution . * @param pipeline The pipeline to set the URI on . */ public void setPipelineUri ( String solutionId , MLPPipeline pipeline ) ; /* * * Put the content of a pipeline . * * @param pipeline The pipeline to put . * @param tag The image tag in the input data . * @param is The data to put . */ public void putPipelineContent ( MLPPipeline pipeline , String tag , InputStream is ) ; /* * * Get the body of a pipeline . * * @param pipeline The pipeline to retrieve . * @return An InputStream for reading the pipeline's content . */ public InputStream getPipelineContent ( MLPPipeline pipeline ) ; /* * * Set the URI for an pipeline . * * @param solutionId The ID of the solution . * @param pipeline The pipeline to set the URI on . */ public void setPipelineUri ( String solutionId , MLPPipeline pipeline ) ; /* * * Put the content of a pipeline . * * @param pipeline The pipeline to put . * @param tag The image tag in the input data . * @param is The data to put . */ public void putPipelineContent ( MLPPipeline pipeline , String tag , InputStream is ) ; /* * * Get the body of a pipeline . * * @param pipeline The pipeline to retrieve . * @return An InputStream for reading the pipeline's content . */ public InputStream getPipelineContent ( MLPPipeline pipeline ) ; /* * * Set the URI for an pipeline . * * @param solutionId The ID of the solution . * @param pipeline The pipeline to set the URI on . */ public void setPipelineUri ( String solutionId , MLPPipeline pipeline ) ; /* * * Put the content of a pipeline . * * @param pipeline The pipeline to put . * @param tag The image tag in the input data . * @param is The data to put . */ public void putPipelineContent ( MLPPipeline pipeline , String tag , InputStream is ) ; /* * * Get the body of a pipeline . * * @param pipeline The pipeline to retrieve . * @return An InputStream for reading the pipeline's content . */ public InputStream getPipelineContent ( MLPPipeline pipeline ) ; /* * * Set the URI for an pipeline . * * @param solutionId The ID of the solution . * @param pipeline The pipeline to set the URI on . */ public void setPipelineUri ( String solutionId , MLPPipeline pipeline ) ; /* * * Put the content of a pipeline . * * @param pipeline The pipeline to put . * @param tag The image tag in the input data . * @param is The data to put . */ public void putPipelineContent ( MLPPipeline pipeline , String tag , InputStream is ) ; /* * * Get the body of a pipeline . * * @param pipeline The pipeline to retrieve . * @return An InputStream for reading the pipeline's content . */ public InputStream getPipelineContent ( MLPPipeline pipeline ) ; /* * * Set the URI for an pipeline . * * @param solutionId The ID of the solution . * @param pipeline The pipeline to set the URI on . */ public void setPipelineUri ( String solutionId , MLPPipeline pipeline ) ; /* * * Put the content of a pipeline . * * @param pipeline The pipeline to put . * @param tag The image tag in the input data . * @param is The data to put . */ public void putPipelineContent ( MLPPipeline pipeline , String tag , InputStream is ) ; /* * * Get the body of a pipeline . * * @param pipeline The pipeline to retrieve . * @return An InputStream for reading the pipeline's content . */ public InputStream getPipelineContent ( MLPPipeline pipeline ) ; /* * * Set the URI for an pipeline . * * @param solutionId The ID of the solution . * @param pipeline The pipeline to set the URI on . */ public void setPipelineUri ( String solutionId , MLPPipeline pipeline ) ; /* * * Put the content of a pipeline . * * @param pipeline The pipeline to put . * @param tag The image tag in the input data . * @param is The data to put . */ public void putPipelineContent ( MLPPipeline pipeline , String tag , InputStream is ) ; /* * * Get the body of a pipeline . * * @param pipeline The pipeline to retrieve . * @return An InputStream for reading the pipeline's content . */ public InputStream getPipelineContent ( MLPPipeline pipeline ) ; /* * * Set the URI for an pipeline . * * @param solutionId
*/ public InputStream getDocumentContent ( MLPDocument document ) ; /* * * Set the URI for an document . * * @param solutionId The ID of the solution . * @param document The document to set the URI on . */ public void setDocumentUri ( String solutionId , MLPDocument document ) ; /* * * Put the content of a document . * * @param document The document to put . < |startfocus| > * @param is The data to put . < |endfocus| > */ public void putDocumentContent ( MLPDocument document , InputStream is ) ; }
import org . acumos . cds . domain . MLPSolutionRevision ; import org . acumos . cds . domain . MLPArtifact ; import org . acumos . cds . domain . MLPDocument ; import org . acumos . federation . client . ClientBase ; import org . acumos . federation . client . config . ClientConfig ; import org . acumos . federation . client . FederationClient ; import org . acumos . federation . client . data . Artifact ; import org . acumos . federation . client . data . Document ; import org . acumos . federation . client . data . JsonResponse ; import org . acumos . federation . client . data . SolutionRevision ; /* * * Controller bean for the external ( public ) API . */ @Controller @CrossOrigin public class FederationController { < |startfocus| > private static final Logger log = LoggerFactory . getLogger ( FederationController . class ) ; < |endfocus| > @Autowired private FederationConfig federation ; @Autowired private WebSecurityConfigurerAdapter security ; @Autowired private PeerService peerService ; @Autowired private CatalogService catalogService ; @Autowired private ContentService contentService ; private UriTemplateHandler originBuilder ; private String makeOrigin ( String uri , Object . . . params ) { if ( originBuilder == null ) { originBuilder = new UriTemplateHandler ( ) ; } return originBuilder . expand ( uri , params ) . toString ( ) ; }
import org . acumos . cds . domain . MLPDocument ; import org . acumos . federation . client . ClientBase ; import org . acumos . federation . client . config . ClientConfig ; import org . acumos . federation . client . FederationClient ; import org . acumos . federation . client . data . Artifact ; import org . acumos . federation . client . data . Document ; import org . acumos . federation . client . data . JsonResponse ; import org . acumos . federation . client . data . SolutionRevision ; /* * * Controller bean for the external ( public ) API . */ @Controller @CrossOrigin public class FederationController { < |startfocus| > private static final Logger log = LoggerFactory . getLogger ( FederationController . class ) ; < |endfocus| > @Autowired private FederationConfig federation ; @Autowired private WebSecurityConfigurerAdapter security ; @Autowired private PeerService peerService ; @Autowired private CatalogService catalogService ; @Autowired private ContentService contentService ; private UriTemplateHandler originBuilder ; private String makeOrigin ( String uri , Object . . . params ) { if ( originBuilder == null ) { originBuilder = ClientBase . buildRestTemplate ( "https :/ / " + ( ( Security ) security ) . getSelf ( ) . getSubjectName ( ) + " : " + federation . getServer ( ) . getPort ( ) , new ClientConfig ( ) , null , null ) . getUriTemplateHandler ( ) ; }
public JsonResponse < Void > badRequestError ( HttpServletRequest request , HttpServletResponse response , BadRequestException badRequest ) { < |startfocus| > log . error ( "Request { } failed { } { } { } " , request . getRequestURI ( ) , badRequest . getMessage ( ) , badRequest . getCode ( ) , badRequest ) ; < |endfocus| > JsonResponse < Void > ret = new JsonResponse < > ( ) ; ret . setError ( badRequest . getMessage ( ) ) ; response . setStatus ( badRequest . getCode ( ) ) ; return ret ;
import org . acumos . cds . domain . MLPCatalog ; import org . acumos . cds . domain . MLPSolution ; import org . acumos . cds . domain . MLPPeer ; import org . acumos . cds . domain . MLPPeerSubscription ; import org . acumos . federation . client . FederationClient ; import org . acumos . federation . client . GatewayClient ; import org . acumos . federation . client . data . JsonResponse ; /* * * Controller bean for the internal ( gateway ) API . */ @Controller @CrossOrigin @Secured ( Security . ROLE_INTERNAL ) @RequestMapping ( GatewayClient . PEER_PFX ) public class GatewayController { < |startfocus| > private static final Logger log = LoggerFactory . getLogger ( MethodHandles . lookup ( ) . lookupClass ( ) ) ; < |endfocus| > @Autowired private Clients clients ; @Autowired private PeerService peerService ; @Autowired private PeerGateway peerGateway ; @ApiOperation ( value = "Invoked by local Acumos to get a list of catalogs available from a peer Acumos instance . " , response = MLPCatalog . class , responseContainer = "List" ) @RequestMapping ( value = FederationClient . CATALOGS_URI , method = RequestMethod . GET , produces = MediaType . APPLICATION_JSON_UTF8_VALUE ) @ResponseBody public JsonResponse < List < MLPCatalog > > getCatalogs ( HttpServletResponse response , @PathVariable ( "peerId" ) String peerId ) {
import org . springframework . security . config . http . SessionCreationPolicy ; import org . springframework . security . core . authority . SimpleGrantedAuthority ; import org . springframework . security . core . context . SecurityContextHolder ; import org . springframework . security . core . GrantedAuthority ; import org . springframework . security . core . userdetails . User ; import org . acumos . cds . domain . MLPPeer ; import org . acumos . federation . client . config . TlsConfig ; import org . acumos . federation . client . FederationClient ; /* * * Service bean implementing authentication and peer identification services * on requests to the Federation Gateway . */ @Configuration @EnableWebSecurity < |startfocus| > public class GatewaySecurity extends WebSecurityConfigurerAdapter { < |endfocus| > /* * * The role indicating a peer is allowed to register . */ public static final String ROLE_REGISTER = "ROLE_REGISTRATION" ; /* * * The role indicating a peer is allowed to cancel their registration . */ public static final String ROLE_UNREGISTER = "ROLE_UNREGISTRATION" ; /* * * The role indicating a peer has normal access to the gateway . */ public static final String ROLE_PEER = "ROLE_PEER" ; /* * * The role indicating a peer has trusted access to the gateway . */
if ( alias == null ) { Enumeration < String > aliases = ks . aliases ( ) ; while ( aliases . hasMoreElements ( ) ) { alias = aliases . nextElement ( ) ; if ( ks . entryInstanceOf ( alias , KeyStore . PrivateKeyEntry . class ) ) { break ; } } } myself = peerService . getSelf ( getLdapNameField ( new LdapName ( ( ( X509Certificate ) ks . getCertificate ( alias ) ) . getSubjectX500Principal ( ) . getName ( ) ) , "CN" ) ) ; } } catch ( Exception e ) { myself = new MLPPeer ( ) ; < |startfocus| > myself . setStatusCode ( PSC_UNKNOWN ) ; < |endfocus| > log . error ( "Exception while getting self" , e ) ; }
logger . debug ( "JWTAuthorizationFilter ( ) begin" ) ; this . secretKey = secretKey ; this . userService = new UserService ( cdsClient ) ; logger . debug ( "JWTAuthorizationFilter ( ) end" ) ; } /* * * Method is called internally and should not be accessible directly using class instance . * */ @Override protected void doFilterInternal ( HttpServletRequest request , HttpServletResponse response , FilterChain chain ) throws IOException , ServletException { logger . debug ( "doFilterInternal ( ) begin" ) ; < |startfocus| > String authToken = null ; authToken = request . getHeader ( AUTHORIZATION_HEADER_KEY ) ; logger . debug ( "AUTHORIZATION_HEADER_KEY : " + authToken ) ; if ( authToken == null ) { authToken = request . getHeader ( JWT_TOKEN_HEADER_KEY ) ; logger . debug ( "JWT_TOKEN_HEADER_KEY : " + authToken ) ; } if ( authToken == null ) { authToken = request . getParameter ( JWT_TOKEN_HEADER_KEY ) ; logger . debug ( "JWT_TOKEN_HEADER_KEY : " + authToken ) ; } if ( authToken != null ) {
logger . debug ( "JWT_TOKEN_HEADER_KEY : " + authToken ) ; } if ( authToken != null ) { authToken = authToken . replace ( TOKEN_PASS_KEY , "" ) ; logger . debug ( "TOKEN_PASS_KEY : " + authToken ) ; JWTTokenVO jwtTokenVO = JwtTokenUtil . getUserToken ( authToken , secretKey ) ; if ( jwtTokenVO != null < |startfocus| > && ! ( SecurityContextHolder . getContext ( ) . getAuthentication ( ) instanceof AnonymousAuthenticationToken ) && validateToken ( jwtTokenVO , secretKey ) ) { < |endfocus| > MLPUser mlpUser = userService . findUserByUsername ( jwtTokenVO . getUserName ( ) ) ; // TODO : Need to implement role base authority UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken ( new AuthenticatedUser ( mlpUser ) , authToken , new ArrayList < > ( ) ) ; authentication . setDetails ( new WebAuthenticationDetailsSource ( ) . buildDetails ( httpRequest ) ) ; SecurityContextHolder . getContext ( ) . setAuthentication ( authentication ) ; } } chain . doFilter ( request , response ) ; logger . debug ( "doFilterInternal ( ) End" ) ; } private boolean validateToken ( JWTTokenVO jwtTokenVO , String secretKey ) { logger . debug ( "validateToken ( ) Begin" ) ;
/* * == == == == == == == = LICENSE_START == == == == == == == == == == == == == == == == == == == == == == == == == == == = * Acumos * == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = * Copyright ( C ) 2017 AT & T Intellectual Property & Tech Mahindra . All rights reserved . * == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = * This Acumos software file is distributed by AT & T and Tech Mahindra * under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * This file is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * == == == == == == == = LICENSE_END == == == == == == == == == == == == == == == == == == == == == == == == == == == == = */ package org . acumos . federation . client ; import java . util . List ; import org . acumos . cds . domain . MLPCatalog ; import org . acumos . federation . client . config . ClientConfig ; import org . acumos . federation . client . config . TlsConfig ; import org . acumos . federation . client . data . Catalog ; import org . acumos . federation . client . FederationClient ; import org . acumos . federation . client . GatewayClient ; < |startfocus| > < |endfocus| > public class ClientDemo { private static final String peerApiUrl = "https :/ / public . otheracumos . org : 9084" ; private static final String internalApiUrl = "https :/ / federation - service : 9011" ; private static final String keystore = "keystore . jks" ; private static final String keystorepass = "keystore_pass" ; private static final String firstpeerid = "12345678 - 1234 - 1234 - 1234 - 1234567890ab" ; private static final String secondpeerid = "cafebebe - cafe - bebe - cafe - bebecafebebe" ; public static void main ( String [ ] args ) throws Exception { ClientConfig cconf = new ClientConfig ( ) ;
private static final String keystorepass = "keystore_pass" ; private static final String firstpeerid = "12345678 - 1234 - 1234 - 1234 - 1234567890ab" ; private static final String secondpeerid = "cafebebe - cafe - bebe - cafe - bebecafebebe" ; public static void main ( String [ ] args ) throws Exception { ClientConfig cconf = new ClientConfig ( ) ; cconf . setSsl ( new TlsConfig ( ) ) ; cconf . getSsl ( ) . setKeyStore ( keystore ) ; cconf . getSsl ( ) . setKeyStorePassword ( keystorepass ) ; < |startfocus| > FederationClient fedclient = new FederationClient ( peerApiUrl , cconf ) ; < |endfocus| > System . out . println ( "Listing remote acumos catalogs using public E5 interface" ) ; for ( MLPCatalog mcat : fedclient . getCatalogs ( ) ) { System . out . println ( "Catalog " + mcat . getName ( ) + " has " + ( ( Catalog ) mcat ) . getSize ( ) + " models" ) ; } GatewayClient gwclient = new GatewayClient ( internalApiUrl , cconf ) ; System . out . println ( "Fetching first peer's catalogs from inside Acumos using private interface" ) ; for ( MLPCatalog mcat : gwclient . getCatalogs ( firstpeerid ) ) { System . out . println ( "Catalog " + mcat . getName ( ) + " has " + ( ( Catalog ) mcat ) . getSize ( ) + " models" ) ; }
import org . springframework . beans . factory . annotation . Autowired ; import org . springframework . beans . factory . annotation . Qualifier ; import org . springframework . http . HttpStatus ; import org . springframework . http . ResponseEntity ; import org . springframework . web . bind . annotation . PathVariable ; import org . springframework . web . bind . annotation . RequestBody ; import org . springframework . web . bind . annotation . RequestMapping ; import org . springframework . web . bind . annotation . RequestMethod ; import org . springframework . web . bind . annotation . ResponseBody ; import org . springframework . web . bind . annotation . RestController ; @RestController @RequestMapping ( value = " / " ) public class PipeLineServiceController { < |startfocus| > private static final String PIPELINE_INPROGRESS = "IP" ; < |endfocus| > private static final Logger logger = LoggerFactory . getLogger ( MethodHandles . lookup ( ) . lookupClass ( ) ) ; @Autowired @Qualifier ( "InputValidationServiceImpl" ) private InputValidationService inputValidationService ; @Autowired @Qualifier ( "PipeLineValidationServiceImpl" ) private PipeLineValidationService pipeLineValidationService ; @Autowired @Qualifier ( "PipeLineServiceImpl" ) private PipeLineService pipeLineService ; @Autowired private PipeLineCacheService pipelineCacheService ; /* * * Creates new independent Pipeline for a user . * @param authenticatedUserId
public boolean checkifNifiPodRunning ( String acumosLoginId ) { boolean nifiPodRunning = false ; logger . debug ( "checkifNifiPodRunning ( ) begin" ) ; nifiPodRunning = createNiFi . checkifNifiPodRunning ( acumosLoginId ) ; logger . debug ( "checkifNifiPodRunning ( ) End" ) ; return nifiPodRunning ; } public String createNiFiInstance ( String acumosLoginId ) { logger . debug ( "createNiFiInstance ( ) Begin" ) ; String nifiURL = null ; // Call the Kubernetes API to create a NiFi Instance try { nifiURL = createNiFi . createNiFiInstanceForUser ( acumosLoginId ) ; } catch ( Exception e ) { logger . error ( "Exception Occurred while creating NiFi Instance for user " + acumosLoginId , e ) ; } logger . debug ( "createNiFiInstance ( ) End" ) ; return nifiURL ; } public String createPipeline ( String acumosLoginId , String pipelineName , String pipelineDescription , String pipelineVersion , String pipelineType , String pipelineOwner , String pipelineLicense , String pipelineTags , String pipelineAccessType , String pipelineAccessValue , String pipelineImage , String pipelineImageTag , String pipelineImagePullSecret , String pipelineImagePullSecretName , String pipelineImagePullSecretNamespace , String pipelineImagePullSecretType , String pipelineImagePullSecretData , String pipelineImagePullSecretDataName , String pipelineImagePullSecretDataKey , String pipelineImagePullSecretDataValue , String pipelineImagePullSecretDataType , String pipelineImagePullSecretDataFormat , String pipelineImagePullSecretDataContentType , String pipelineImagePullSecretDataData , String pipelineImagePullSecretDataDataName , String pipelineImagePullSecretDataDataKey , String pipelineImagePullSecretDataDataValue , String pipelineImagePullSecretDataDataType , String pipelineImagePullSecretDataDataFormat , String pipelineImagePullSecretDataDataContentType , String pipelineImagePullSecretDataDataData , String pipelineImagePullSecretDataDataDataName , String pipelineImagePullSecretDataDataDataKey , String pipelineImagePullSecretDataDataDataValue , String pipelineImagePullSecretDataDataDataType , String pipelineImagePullSecretDataDataDataFormat , String pipelineImagePullSecretDataDataDataContentType , String pipelineImagePullSecretDataDataDataData , String pipelineImagePullSecretDataDataDataDataName , String pipelineImagePullSecretDataDataDataDataKey , String pipelineImagePullSecretDataDataDataDataValue , String pipelineImagePullSecretDataDataDataDataType , String pipelineImagePullSecretDataDataDataDataFormat , String pipelineImagePullSecretDataDataDataDataContentType , String pipelineImagePullSecretDataDataDataDataData , String pipelineImagePullSecretDataDataDataDataDataName , String pipelineImagePullSecretDataDataDataDataDataKey , String pipelineImagePullSecretDataDataDataDataDataValue , String pipelineImagePullSecretDataDataDataDataDataType , String pipelineImagePullSecretDataDataDataDataDataFormat , String pipelineImagePullSecretDataDataDataDataDataContentType , String pipelineImagePullSecretDataDataDataDataDataData , String pipelineImagePullSecretDataDataDataDataDataDataName , String pipelineImagePullSecretDataDataDataDataDataDataKey , String pipelineImagePullSecretDataDataDataDataDataDataValue , String pipelineImagePullSecretDataDataDataDataDataDataType , String pipelineImagePullSecretDataDataDataDataDataDataFormat , String pipelineImagePullSecretDataDataDataDataDataDataContentType , String pipelineImagePullSecretDataDataDataDataDataDataData , String pipelineImagePullSecretDataDataDataDataDataDataDataName , String pipelineImagePullSecretDataDataDataDataDataDataDataKey , String pipelineImagePullSecretDataDataDataDataDataDataDataValue , String pipelineImagePullSecretDataDataDataDataDataDataDataType , String pipelineImagePullSecretDataDataDataDataDataDataDataFormat , String pipelineImagePullSecretDataDataDataDataDataDataDataContentType , String pipelineImagePullSecretDataDataDataDataDataDataDataData , String pipelineImagePullSecretDataDataDataDataDataDataDataDataName , String pipelineImagePullSecretDataDataDataDataDataDataDataDataKey , String pipelineImagePullSecretDataDataDataDataDataDataDataDataValue , String pipelineImagePullSecretDataDataDataDataDataDataDataDataType , String pipelineImagePullSecretDataDataDataDataDataDataDataDataFormat , String pipelineImagePullSecretDataDataDataDataDataDataDataDataContentType , String pipelineImagePullSecretDataDataDataDataDataDataDataDataData , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataName , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataKey , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataValue , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataType , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataFormat , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataContentType , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataData , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataName , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataKey , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataValue , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataType , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataFormat , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataContentType , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataData , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataName , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataKey , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataValue , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataType , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataFormat , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataContentType , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataData , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataName , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataKey , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataValue , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataType , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataFormat , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataContentType , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataData , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataDataName , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataDataKey , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataDataValue , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataDataType , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataDataFormat , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataDataContentType , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataDataData , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataDataDataName , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataDataDataKey , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataDataDataValue , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataDataDataType , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataDataDataFormat , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataDataDataContentType , String pipelineImagePullSecretDataDataDataDataDataDataDataDataDataDataDataDataDataDataData , String pipelineImagePullSecretDataDataDataDataDataDataDataDataData
throw new DuplicatePipeLineException ( "Request PipeLine Name : " + pipelineName + " already Exists in Both NiFi Server and NiFi Registry" ) ; } logger . debug ( "NiFi createPipeline ( ) end" ) ; return flowURL ; } public boolean checkifNifiPodRunning ( String acumosLoginId ) { boolean nifiPodRunning = false ; logger . debug ( "checkifNifiPodRunning ( ) begin" ) ; nifiPodRunning = createNiFi . checkifNifiPodRunning ( acumosLoginId ) ; logger . debug ( "checkifNifiPodRunning ( ) End" ) ; return nifiPodRunning ; } < |startfocus| > < |endfocus| > public String createNiFiInstance ( String acumosLoginId ) { logger . debug ( "createNiFiInstance ( ) Begin" ) ; String nifiURL = null ; // Call the Kubernetes API to create a NiFi Instance try { nifiURL = createNiFi . createNiFiInstanceForUser ( acumosLoginId ) ; } catch ( NiFiInstanceCreationException e ) { logger . error ( "Exception occured while creating NiFi Instance for User" , e ) ; throw new NiFiInstanceCreationException ( "Exception occured while creating NiFi Instance for User " ) ; } logger . debug ( "createNiFiInstance ( ) End" ) ; return nifiURL ; }
*/ package org . acumos . workbench . pipelineservice . service ; import java . lang . invoke . MethodHandles ; import org . acumos . workbench . common . vo . Pipeline ; import org . acumos . workbench . pipelineservice . exception . DuplicateRequestException ; import org . acumos . workbench . pipelineservice . util . MLWBRequestCache ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import org . springframework . beans . factory . annotation . Autowired ; import org . springframework . stereotype . Service ; @Service public class PipeLineCacheService { private static final Logger logger = LoggerFactory . getLogger ( MethodHandles . lookup ( ) . lookupClass ( ) ) ; @Autowired private MLWBRequestCache requestCache ; < |startfocus| > < |endfocus| > public void putCreateRequest ( String requestId , Pipeline pipeline ) { logger . debug ( "putCreateRequest ( ) Begin " ) ; Boolean exist = requestCache . checkIfCreateRequestExists ( requestId , pipeline ) ; if ( exist ) { logger . error ( "Duplicate Request Exception ocured . " ) ; throw new DuplicateRequestException ( ) ; } else { requestCache . addCreateRequest ( requestId , pipeline ) ; } logger . debug ( "putCreateRequest ( ) End" ) ; } public void removeCreateRequest ( String requestId , Pipeline pipeline ) { requestCache . removeCreateRequest ( requestId ) ; }
private static final Logger logger = LoggerFactory . getLogger ( MethodHandles . lookup ( ) . lookupClass ( ) ) ; @Autowired private MLWBRequestCache requestCache ; public void putCreateRequest ( String requestId , Pipeline pipeline ) { logger . debug ( "putCreateRequest ( ) Begin " ) ; Boolean exist = requestCache . checkIfCreateRequestExists ( requestId , pipeline ) ; if ( exist ) { logger . error ( "Duplicate Request Exception ocured . " ) ; throw new DuplicateRequestException ( ) ; } else { requestCache . addCreateRequest ( requestId , pipeline ) ; } logger . debug ( "putCreateRequest ( ) End" ) ; } < |startfocus| > < |endfocus| > public void removeCreateRequest ( String requestId , Pipeline pipeline ) { requestCache . removeCreateRequest ( requestId ) ; } public void putUpdateRequest ( String requestId , Pipeline pipeline ) { logger . debug ( "putUpdateRequest ( ) Begin " ) ; Boolean exist = requestCache . checkIfUpdateRequestExists ( requestId , pipeline ) ; if ( exist ) { logger . error ( "Duplicate Request Exception ocured . " ) ; throw new DuplicateRequestException ( ) ; } else { requestCache . addUpdateRequest ( requestId , pipeline ) ; } logger . debug ( "putUpdateRequest ( ) End " ) ; }
public void putCreateRequest ( String requestId , Pipeline pipeline ) { logger . debug ( "putCreateRequest ( ) Begin " ) ; Boolean exist = requestCache . checkIfCreateRequestExists ( requestId , pipeline ) ; if ( exist ) { logger . error ( "Duplicate Request Exception ocured . " ) ; throw new DuplicateRequestException ( ) ; } else { requestCache . addCreateRequest ( requestId , pipeline ) ; } logger . debug ( "putCreateRequest ( ) End" ) ; } public void removeCreateRequest ( String requestId , Pipeline pipeline ) { requestCache . removeCreateRequest ( requestId ) ; } < |startfocus| > /* * * This method is used to put the update request in the cache . * @param requestId * @param pipeline */ < |endfocus| > public void putUpdateRequest ( String requestId , Pipeline pipeline ) { logger . debug ( "putUpdateRequest ( ) Begin " ) ; Boolean exist = requestCache . checkIfUpdateRequestExists ( requestId , pipeline ) ; if ( exist ) { logger . error ( "Duplicate Request Exception ocured . " ) ; throw new DuplicateRequestException ( ) ; } else { requestCache . addUpdateRequest ( requestId , pipeline ) ; } logger . debug ( "putUpdateRequest ( ) End " ) ; } public void removeUpdateRequest ( String requestId , Pipeline pipeline ) { requestCache . removeUpdateRequest ( requestId ) ; }
} public void removeCreateRequest ( String requestId , Pipeline pipeline ) { requestCache . removeCreateRequest ( requestId ) ; } public void putUpdateRequest ( String requestId , Pipeline pipeline ) { logger . debug ( "putUpdateRequest ( ) Begin " ) ; Boolean exist = requestCache . checkIfUpdateRequestExists ( requestId , pipeline ) ; if ( exist ) { logger . error ( "Duplicate Request Exception ocured . " ) ; throw new DuplicateRequestException ( ) ; } else { requestCache . addUpdateRequest ( requestId , pipeline ) ; } logger . debug ( "putUpdateRequest ( ) End " ) ; } < |startfocus| > < |endfocus| > public void removeUpdateRequest ( String requestId , Pipeline pipeline ) { requestCache . removeUpdateRequest ( requestId ) ; } public void putDeleteRequest ( String requestId , String pipelineId ) { logger . debug ( "putDeleteRequest ( ) Begin " ) ; Boolean exist = requestCache . checkIfDeleteRequestExists ( requestId , pipelineId ) ; if ( exist ) { logger . error ( "Duplicate Request Exception ocured . " ) ; throw new DuplicateRequestException ( ) ; } else { requestCache . addDeleteRequest ( requestId , pipelineId ) ; } logger . debug ( "putDeleteRequest ( ) End " ) ; } public void removeDeleteRequest ( String requestId , String pipelineId ) { requestCache . removeDeleteRequest ( requestId , pipelineId ) ; } }
} public void putUpdateRequest ( String requestId , Pipeline pipeline ) { logger . debug ( "putUpdateRequest ( ) Begin " ) ; Boolean exist = requestCache . checkIfUpdateRequestExists ( requestId , pipeline ) ; if ( exist ) { logger . error ( "Duplicate Request Exception ocured . " ) ; throw new DuplicateRequestException ( ) ; } else { requestCache . addUpdateRequest ( requestId , pipeline ) ; } logger . debug ( "putUpdateRequest ( ) End " ) ; } public void removeUpdateRequest ( String requestId , Pipeline pipeline ) { requestCache . removeUpdateRequest ( requestId ) ; } < |startfocus| > < |endfocus| > public void putDeleteRequest ( String requestId , String pipelineId ) { logger . debug ( "putDeleteRequest ( ) Begin " ) ; Boolean exist = requestCache . checkIfDeleteRequestExists ( requestId , pipelineId ) ; if ( exist ) { logger . error ( "Duplicate Request Exception ocured . " ) ; throw new DuplicateRequestException ( ) ; } else { requestCache . addDeleteRequest ( requestId , pipelineId ) ; } logger . debug ( "putDeleteRequest ( ) End " ) ; } public void removeDeleteRequest ( String requestId , String pipelineId ) { requestCache . removeDeleteRequest ( requestId ) ; }
@ApplicationScope @Component public class MLWBRequestCache implements Serializable { private static final long serialVersionUID = - 4688732173089705360L ; private Map < String , Pipeline > createRequests ; // Key is Request Id and value is pipeline input private Map < String , Pipeline > updateRequests ; // Key is Request Id and value is pipeline input private Map < String , String > deleteRequests ; // Key is Request Id and value is pipeline Id private Map < String , String > archiveRequests ; // Key is Request Id and value is pipeline Id < |startfocus| > < |endfocus| > public MLWBRequestCache ( ) { createRequests = new HashMap < String , Pipeline > ( ) ; updateRequests = new HashMap < String , Pipeline > ( ) ; deleteRequests = new HashMap < String , String > ( ) ; archiveRequests = new HashMap < String , String > ( ) ; } public void addCreateRequest ( String key , Pipeline value ) { createRequests . put ( key , value ) ; } public void removeCreateRequest ( String key ) { createRequests . remove ( key ) ; } public Pipeline getCreateRequestByKey ( String key ) { if ( createRequests . containsKey ( key ) ) { return createRequests . get ( key ) ; } } public void addUpdateRequest ( String key , Pipeline value ) { updateRequests . put ( key , value ) ; } public void removeUpdateRequest ( String key ) { updateRequests . remove ( key ) ; } public Pipeline getUpdateRequestByKey ( String key ) { if ( updateRequests . containsKey ( key ) ) { return updateRequests . get ( key ) ; } } public void addDeleteRequest ( String key , String value ) { deleteRequests . put ( key , value ) ; } public void removeDeleteRequest ( String key ) { deleteRequests . remove ( key ) ; } public String getDeleteRequestByKey ( String key ) { if ( deleteRequests . containsKey ( key ) ) { return deleteRequests . get ( key ) ; } } public void addArchiveRequest ( String key , String value ) { archiveRequests . put ( key , value ) ; } public void removeArchiveRequest ( String key ) { archiveRequests . remove ( key ) ; } public String getArchiveRequestByKey ( String key ) { if ( archiveRequests . containsKey ( key ) ) { return archiveRequests . get ( key ) ; } } }
private Map < String , String > deleteRequests ; // Key is Request Id and value is pipeline Id private Map < String , String > archiveRequests ; // Key is Request Id and value is pipeline Id public MLWBRequestCache ( ) { createRequests = new HashMap < String , Pipeline > ( ) ; updateRequests = new HashMap < String , Pipeline > ( ) ; deleteRequests = new HashMap < String , String > ( ) ; archiveRequests = new HashMap < String , String > ( ) ; } < |startfocus| > < |endfocus| > public void addCreateRequest ( String key , Pipeline value ) { createRequests . put ( key , value ) ; } public void removeCreateRequest ( String key ) { createRequests . remove ( key ) ; } public Pipeline getCreateRequestByKey ( String key ) { if ( createRequests . containsKey ( key ) ) { return createRequests . get ( key ) ; } return null ; } /* * * Check if request with given requestId or Pipeline already exists in the cache . * @param key * request Id * @param value * Pipeline * @return boolean */
List < Nodes > nodesList = new ArrayList < Nodes > ( ) ; nodesList . add ( node ) ; cdump . setNodes ( nodesList ) ; String nodeId = "123" ; String userId = "123" ; // try { when ( props . getPackagepath ( ) ) . thenReturn ( "org / acumos / vo / " ) ; when ( props . getClassName ( ) ) . thenReturn ( "DataVO" ) ; Resource resource1 = resourceLoader . getResource ( PROTOBUF_TEMPLATE_NAME ) ; when ( resourceLoader . getResource ( "classpath : Protobuf_Template . txt" ) ) . thenReturn ( resource1 ) ; < |startfocus| > // when ( resourceLoader . getInputStream ( ) ) . thenReturn ( inputStream ) ; // gdmServiceImpl . createDeployGDM ( cdump , nodeId , userId ) ; // } catch ( ServiceException e ) { // e . printStackTrace ( ) ; // } < |endfocus| >
* you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * This file is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * == == == == == == == = LICENSE_END == == == == == == == == == == == == == == == == == == == == == == == == == == == == = */ package org . acumos . designstudio . test ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertNotNull ; import static org . junit . Assert . assertTrue ; import java . lang . invoke . MethodHandles ; import java . util . ArrayList ; import java . util . List ; import java . util . Properties ; import org . acumos . designstudio . ce . util . ConfigurationProperties ; import org . acumos . designstudio . ce . vo . DSSolution ; import org . acumos . designstudio . ce . vo . MatchingModel ; import org . acumos . designstudio . ce . vo . SuccessErrorMessage ; import org . acumos . designstudio . ce . vo . blueprint . BPCollatorMap ; import org . acumos . designstudio . ce . vo . blueprint . BPDataBrokerMap ;
import com . google . common . collect . Lists ; import springfox . documentation . builders . ApiInfoBuilder ; import springfox . documentation . builders . PathSelectors ; import springfox . documentation . builders . RequestHandlerSelectors ; import springfox . documentation . service . ApiInfo ; import springfox . documentation . service . ApiKey ; import springfox . documentation . service . AuthorizationScope ; import springfox . documentation . service . Contact ; import springfox . documentation . service . SecurityReference ; import springfox . documentation . spi . DocumentationType ; import springfox . documentation . spi . service . contexts . SecurityContext ; import springfox . documentation . spring . web . plugins . Docket ; import springfox . documentation . swagger2 . annotations . EnableSwagger2 ; @Configuration @EnableSwagger2 public class SwaggerConfiguration { @Bean public Docket swaggerSpringfoxDocket ( ) { Docket docket = new Docket ( DocumentationType . SWAGGER_2 ) . apiInfo ( apiInfo ( ) ) . forCodeGeneration ( true ) . genericModelSubstitutes ( ResponseEntity . class ) . ignoredParameterTypes ( Pageable . class ) . ignoredParameterTypes ( java . sql . Date . class ) . directModelSubstitute ( java . time . LocalDate . class , java . sql . Date . class ) . directModelSubstitute ( java . time . ZonedDateTime . class , Date . class ) . directModelSubstitute ( java . time . LocalDateTime . class , Date . class ) . securityContexts ( Lists . newArrayList ( securityContext ( ) ) ) . securitySchemes ( Lists . newArrayList ( apiKey ( ) ) ) . useDefaultResponseMessages ( false ) ; docket = docket . select ( ) . apis ( RequestHandlerSelectors . basePackage ( "com . mycompany . myapp . web . rest" ) ) . paths ( PathSelectors . any ( ) ) . build ( ) ; return docket ; } private ApiInfo apiInfo ( ) { return new ApiInfoBuilder ( ) . title ( "Springfox petstore API" ) . description ( "Lorem Ipsum is simply dummy text of the printing and typesetting industry . Lorem Ipsum " + "has been the industry's standard dummy text ever since the 1500s , when an unknown printer " + "took a " + "galley of type and scrambled it to make a type specimen book . It has survived not only five " + "centuries , but also the leap into electronic typesetting , remaining essentially unchanged . " + "It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum " + "passages , and more recently with desktop publishing software like Aldus PageMaker including " + "versions of Lorem Ipsum . " ) . termsOfServiceUrl ( "http :/ / springfox . io" ) . contact ( new Contact ( "springfox" , "http :/ / springfox . io" , "springfox@gmail . com" ) ) . license ( "Apache License Version 2 . 0" ) . licenseUrl ( "https :/ / github . com / springfox / springfox / blob / master / LICENSE" ) . version ( "2 . 0" ) . build ( ) ; } private ApiKey apiKey ( ) { return new ApiKey ( "mykey" , "api_key" , "header" ) ; } private SecurityContext securityContext ( ) { return SecurityContext . builder ( ) . securityReferences ( defaultAuth ( ) ) . forPaths ( PathSelectors . regex ( " / anyPath .* " ) ) . build ( ) ; } List < SecurityReference > defaultAuth ( ) { AuthorizationScope authorizationScope = new AuthorizationScope ( "global" , "accessEverything" ) ; AuthorizationScope [ ] authorizationScopes = new AuthorizationScope [ 1 ] ; authorizationScopes [ 0 ] = authorizationScope ; return Lists . newArrayList ( new SecurityReference ( "mykey" , authorizationScopes ) ) ; } }
} // Secure the endpoints with HTTP Basic authentication @Override protected void configure ( HttpSecurity http ) throws Exception { http . csrf ( ) . disable ( ) . sessionManagement ( ) . sessionCreationPolicy ( SessionCreationPolicy . STATELESS ) . and ( ) . authorizeRequests ( ) . antMatchers ( " / swagger - ui . html" ) . permitAll ( ) . anyRequest ( ) . authenticated ( ) . and ( ) . addFilterBefore ( jwtAuthorizationFilterBean ( ) , UsernamePasswordAuthenticationFilter . class ) ; } @Bean public JWTAuthorizationFilter jwtAuthorizationFilterBean ( ) throws Exception { < |startfocus| > JWTAuthorizationFilter jwtAuthorizationFilter = new JWTAuthorizationFilter ( authenticationManagerBean ( ) , conf . getJwtSecretKey ( ) , cdsClient ) ; < |endfocus| > return jwtAuthorizationFilter ; } }
/* * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * This file is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * == == == == == == == = LICENSE_END == == == == == == == == == == == == == == == == == == == == == == == == == == == == = */ package org . acumos . workbench . modelservice . service ; import org . acumos . workbench . common . vo . Model ; public interface ModelValidationService { /* * < |startfocus| > * To Validate the Input Data * < |endfocus| > * @param authenticatedUserId the authenticated User Id * @param model the model */ public void validateInputData ( String authenticatedUserId , Model model ) ; }
* http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * This file is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * == == == == == == == = LICENSE_END == == == == == == == == == == == == == == == == == == == == == == == == == == == == = */ package org . acumos . workbench . modelservice . service ; import org . acumos . workbench . common . vo . Model ; public interface ModelValidationService { /* * * To Validate the Input for : * 1 . * @param authenticatedUserId * @param model */ public void validateInputData ( String authenticatedUserId , Model model ) ; }
* == == == == == == == = LICENSE_START == == == == == == == == == == == == == == == == == == == == == == == == == == == = * Acumos * == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = < |startfocus| > * Copyright ( C ) 2019 AT & T Intellectual Property & Tech Mahindra . All rights reserved . < |endfocus| > * == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = * This Acumos software file is distributed by AT & T and Tech Mahindra * under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * This file is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * == == == == == == == = LICENSE_END == == == == == == == == == == == == == == == == == == == == == == == == == == == == = */ package org . acumos . designstudio . toscagenerator . test ; import java . io . File ; import java . io . IOException ; import java . lang . invoke . MethodHandles ; import java . time . Instant ; import java . util . ArrayList ; import java . util . List ; import org . acumos . cds . domain . MLPSolutionRevision ; import org . acumos . designstudio . toscagenerator . ToscaGeneratorClient ;
import org . junit . Rule ; import org . junit . Test ; import org . mockito . MockitoAnnotations ; import org . mockito . junit . MockitoJUnit ; import org . mockito . junit . MockitoRule ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; public class ToscaGeneratorClientTest { private static final Logger logger = LoggerFactory . getLogger ( MethodHandles . lookup ( ) . lookupClass ( ) ) ; @Rule public MockitoRule mockitoRule = MockitoJUnit . rule ( ) ; @Before public void setUp ( ) { MockitoAnnotations . initMocks ( this ) ; } < |startfocus| > // @Test ( expected = ServiceException . class ) < |endfocus| > public void ToscaClientTest ( ) { }
mlpRev . setModified ( Instant . now ( ) ) ; mlpRev . setOnboarded ( Instant . now ( ) ) ; mlpRev . setPublisher ( "techmdev" ) ; mlpRev . setRevisionId ( "123" ) ; mlpRev . setSolutionId ( "123" ) ; mlpRev . setUserId ( "123" ) ; mlpRev . setVerifiedLicense ( "Yes" ) ; mlpRev . setVerifiedVulnerability ( "Yes" ) ; mlpRev . setVersion ( "1" ) ; List < MLPSolutionRevision > listMLPSolRev = new ArrayList < > ( ) ; listMLPSolRev . add ( mlpRev ) ; try { < |startfocus| > client . generateTOSCA ( "123" , "123" , "1" , "123" , protoFile , tagFile ) ; } catch ( AcumosException e ) { logger . error ( "AcumosException occured while generating the TOSCA File" ) ; }
* == == == == == == == = LICENSE_START == == == == == == == == == == == == == == == == == == == == == == == == == == == = * Acumos * == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = < |startfocus| > * Copyright ( C ) 2019 AT & T Intellectual Property & Tech Mahindra . All rights reserved . < |endfocus| > * == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = * This Acumos software file is distributed by AT & T and Tech Mahindra * under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * This file is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * == == == == == == == = LICENSE_END == == == == == == == == == == == == == == == == == == == == == == == == == == == == = */ package org . acumos . csvdatabroker . vo ; import static org . junit . Assert . assertTrue ; import org . junit . Test ; public class CSVdatabrokerVOTest { @Test public void csvdatabrokerVOTest ( ) { DataBrokerMap dataBrokerMap = new DataBrokerMap ( ) ; dataBrokerMap . setScript ( "test" ) ;
* == == == == == == == = LICENSE_START == == == == == == == == == == == == == == == == == == == == == == == == == == == = * Acumos * == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = < |startfocus| > * Copyright ( C ) 2019 AT & T Intellectual Property & Tech Mahindra . All rights reserved . < |endfocus| > * == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = * This Acumos software file is distributed by AT & T and Tech Mahindra * under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * This file is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * == == == == == == == = LICENSE_END == == == == == == == == == == == == == == == == == == == == == == == == == == == == = */ package org . acumos . sqldatabroker . vo ; import static org . junit . Assert . assertTrue ; import java . util . ArrayList ; import java . util . List ; import org . acumos . sqldatabroker . exceptionhandler . ServiceException ; import org . junit . Test ; public class DataBrokerMapVOTest { @Test
* == == == == == == == = LICENSE_START == == == == == == == == == == == == == == == == == == == == == == == == == == == = * Acumos * == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = < |startfocus| > * Copyright ( C ) 2019 AT & T Intellectual Property & Tech Mahindra . All rights reserved . < |endfocus| > * == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == = * This Acumos software file is distributed by AT & T and Tech Mahindra * under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * This file is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * == == == == == == == = LICENSE_END == == == == == == == == == == == == == == == == == == == == == == == == == == == == = */ package org . acumos . csvdatabroker . vo ; import static org . junit . Assert . assertTrue ; import org . junit . Test ; public class CSVdatabrokerVOTest { @Test public void csvdatabrokerVOTest ( ) { DataBrokerMap dataBrokerMap = new DataBrokerMap ( ) ; dataBrokerMap . setScript ( "test" ) ;
@RestController @RequestMapping ( value = " / " ) public class ModelServiceController { private static final Logger logger = LoggerFactory . getLogger ( MethodHandles . lookup ( ) . lookupClass ( ) ) ; @Autowired @Qualifier ( "InputValidationServiceImpl" ) private InputValidationService inputValidationService ; @Autowired @Qualifier ( "ModelValidationServiceImpl" ) private ModelValidationService modelValidationService ; @Autowired @Qualifier ( "ModelServiceImpl" ) private ModelService modelService ; < |startfocus| > @ApiOperation ( value = "This API will list out all the Models that belongs to user" ) < |endfocus| > @RequestMapping ( value = " / users / { authenticatedUserId } / models / " , method = RequestMethod . GET ) public ResponseEntity < ? > listModels ( HttpServletRequest request , @ApiParam ( value = "Acumos User login Id" , required = true ) @PathVariable ( "authenticatedUserId" ) String authenticatedUserId ) { logger . debug ( "listModels ( ) Begin" ) ; String authToken = getAuthJWTToken ( request ) ; // 1 . Check the Authenticated User Id is present or not inputValidationService . isValuePresent ( ModelServiceConstants . MODEL_AUTHENTICATED_USER_ID , authenticatedUserId ) ;
import org . acumos . workbench . common . vo . Version ; import org . acumos . workbench . modelservice . exceptionhandling . ModelNotFoundException ; import org . acumos . workbench . modelservice . util . ConfigurationProperties ; import org . acumos . workbench . modelservice . util . ModelServiceProperties ; import org . acumos . workbench . modelservice . util . ModelServiceUtil ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import org . slf4j . MDC ; import org . springframework . beans . factory . annotation . Autowired ; import org . springframework . http . HttpStatus ; import org . springframework . http . ResponseEntity ; import org . springframework . stereotype . Service ; < |startfocus| > import org . springframework . web . client . RestClientResponseException ; < |endfocus| > @Service ( "ModelServiceImpl" ) public class ModelServiceImpl implements ModelService { private static final Logger logger = LoggerFactory . getLogger ( MethodHandles . lookup ( ) . lookupClass ( ) ) ; @Autowired private CommonDataServiceRestClientImpl cdsClient ; @Autowired private ModelServiceProperties props ; @Autowired private ConfigurationProperties confprops ; @Autowired private ProjectServiceRestClientImpl psClient ; @Override public List < Model > getModels ( String authenticatedUserId , String projectId ) { logger . debug ( "getModels ( ) Begin" ) ; List < Model > modelList = new ArrayList < Model > ( ) ; MLPUser mlpUser = getUserDetails ( authenticatedUserId ) ;
Model model = getModelWithErrorStatus ( ex ) ; return new ResponseEntity < Model > ( model , HttpStatus . NOT_FOUND ) ; } /* * * To handle AssociationExistsException and returns appropriate response to UI . * @param ex * the exception thrown by the service method * @param request * the WebRequest * @return ResponseEntitiy < Model > * returns Model with ServiceStatus indicating error */ < |startfocus| > @ExceptionHandler ( AssociationException . class ) public final ResponseEntity < ? > handleAssociationExistsException ( AssociationException ex , WebRequest request ) { < |endfocus| > Model model = getModelWithErrorStatus ( ex ) ; return new ResponseEntity < Model > ( model , HttpStatus . NOT_FOUND ) ; } /* * * To handle AssociationNotFoundException and returns appropriate response to UI . * @param ex * the exception thrown by the service method * @param request * the WebRequest * @return ResponseEntitiy < Model > * returns Model with ServiceStatus indicating error */ @ExceptionHandler ( ProjectModelAssociationNotFoundException . class )
* * @param fieldName * The name of the filed to be shown in the error message . * @param value * The value to be validated * @throws ValueNotFoundException * throws ValueNotFoundException in case value is null or empty . */ public void isValuePresent ( String fieldName , String value ) throws ValueNotFoundException ; /* * < |startfocus| > * To validate the input Json value of Model < |endfocus| > * @param model * the model object with input values * @throws InvalidInputJSONException * throws InvalidInputJSONException in case of error in the input JSON */ public void validateModelInputJson ( Model model ) throws InvalidInputJSONException ; }
* == == == == == == == = LICENSE_END == == == == == == == == == == == == == == == == == == == == == == == == == == == == = */ package org . acumos . workbench . modelservice . util ; public class ModelServiceConstants { public static final String MODEL_AUTHENTICATED_USER_ID = "AuthenticatedUserId" ; public static final String DELETED = "DELETED" ; public static final String MODEL_IS_ACTIVE = "Model is Active" ; public static final String CATALOGNAMES = "CATALOG_NAMES" ; public static final String UNARCHIVE = "UA" ; public static final String ARCHIVE = "A" ; < |startfocus| > public static final String PROJECT_ID = "projectId" ; < |endfocus| > public static final String ASSOCIATION_ID = "ASSOCIATION_ID" ; public static final String MODEL_TYPE_CODE = "MODEL_TYPE_CODE" ; public static final String MODEL_PUBLISH_STATUS = "MODEL_PUBLISH_STATUS" ; }
private List < String > getConnectedPortInputMsgNames ( List < ProtobufServiceOperation > operations ) { List < String > inputMessageNames = null ; for ( ProtobufServiceOperation o : operations ) { < |startfocus| > // TODO : Current logic returns the first operation's input msg name , but need to update the logic to return the connected port input message name < |endfocus| > inputMessageNames = o . getInputMessageNames ( ) ; } return inputMessageNames ;
// 1 . Get the list of SolutionRevision for the solutionId . mlpSolutionRevisionList = getSolutionRevisionsList ( solutionId ) ; // 2 . Match the version with the SolutionRevision and get the // solutionRevisionId . if ( null != mlpSolutionRevisionList && ! mlpSolutionRevisionList . isEmpty ( ) ) { solutionRevisionId = mlpSolutionRevisionList . stream ( ) . filter ( mlp - > mlp . getVersion ( ) . equals ( version ) ) . findFirst ( ) . get ( ) . getRevisionId ( ) ; < |startfocus| > logger . debug ( EELFLoggerDelegator . debugLogger , " SolutionRevisonId for Version : { } " , solutionRevisionId ) ; < |endfocus| > } else { result = String . format ( error , "501" , "Failed to fetch the Solution Revision List" ) ; } } catch ( Exception e ) { logger . error ( EELFLoggerDelegator . errorLogger , "Error : Exception in fetchJsonTOSCA ( ) : Failed to fetch the Solution Revision List" , e ) ; result = String . format ( error , "501" , "Failed to fetch the Solution Revision List for the version { } " , version ) ; } if ( null != solutionRevisionId ) {
// add protobuf file addProtobufFile ( protobufJarEntryName , tempJar ) ; // add DavaVO . class file List < String > dataVOEntryList = addDataVOClasses ( DataVOClassEntryName , tempJar ) ; JarEntry entry = null ; // Open the original jar jar = new JarFile ( jarFile ) ; // Loop through the jar entries and add them to the temp jar , // skipping the entry that was added to the temp jar already . for ( Enumeration entries = jar . entries ( ) ; entries . hasMoreElements ( ) ; ) { // Get the next entry . < |startfocus| > entry = ( JarEntry ) entries . nextElement ( ) ; < |endfocus| > // If the entry has not been added already , add it . if ( ! entry . getName ( ) . equals ( fieldMappingJarEntryName ) && ! dataVOEntryList . contains ( entry . getName ( ) ) ) { // Get an input stream for the entry . InputStream entryStream = jar . getInputStream ( entry ) ; // Read the entry and write it to the temp jar . tempJar . putNextEntry ( entry ) ; while ( ( bytesRead = entryStream . read ( buffer ) ) != - 1 ) {
curPartIdx ++ ; if ( curPartIdx <= endPartIdx ) { boolean suitablePartFound = false ; for ( int i = curPartIdx ; i <= endPartIdx ; i ++ ) { // Prune partition because no element in it can satisfy the occurrence threshold . if ( partitionCursors [ i ] == null || partitionCursors [ i ] . size ( ) < occurrenceThreshold ) { < |startfocus| > continue ; } suitablePartFound = true ; curPartIdx = i ; break ; } // If no partition is availble to explore , we stop here . if ( ! suitablePartFound ) { isFinishedSearch = true ; invListMerger . close ( ) ; finalSearchResult . finalizeWrite ( ) ; return true ; }
isSingleInvertedList = true ; needToReadNewPart = true ; } else { singleInvListCursor = null ; isSingleInvertedList = false ; needToReadNewPart = invListMerger . merge ( partitionCursors [ curPartIdx ] , occurrenceThreshold , numPrefixLists , finalSearchResult ) ; searchResultBuffer = finalSearchResult . getNextFrame ( ) ; searchResultTupleIndex = 0 ; searchResultFta . reset ( searchResultBuffer ) ; < |startfocus| > // Temp : // System . out . println ( "PartitionedTOccurrenceSearcher : : continueSearch ( ) - " + needToReadNewPart // + " tupleCount " + searchResultFta . getTupleCount ( ) ) ; // < |endfocus| > } // Finished processing one partition if ( needToReadNewPart && isFinalPartIdx ) { invListMerger . close ( ) ; finalSearchResult . finalizeWrite ( ) ; isFinishedSearch = true ; // Temp : // System . out . println ( "Final partition " + curPartIdx + " Search done" ) ; return true ; } } else { isFinishedSearch = true ; } return false ; } public void setNumTokensBoundsInSearchKeys ( short numTokensLowerBound , short numTokensUpperBound ) {
needToReadNewPart = true ; } else { singleInvListCursor = null ; isSingleInvertedList = false ; needToReadNewPart = invListMerger . merge ( partitionCursors [ curPartIdx ] , occurrenceThreshold , numPrefixLists , finalSearchResult ) ; searchResultBuffer = finalSearchResult . getNextFrame ( ) ; searchResultTupleIndex = 0 ; searchResultFta . reset ( searchResultBuffer ) ; < |startfocus| > // Temp : // System . out . println ( "PartitionedTOccurrenceSearcher : : continueSearch ( ) - " + needToReadNewPart // + " tupleCount " + searchResultFta . getTupleCount ( ) ) ; // < |endfocus| > } // Finished processing one partition if ( needToReadNewPart && isFinalPartIdx ) { invListMerger . close ( ) ; finalSearchResult . finalizeWrite ( ) ; isFinishedSearch = true ; // Temp : // System . out . println ( "Final partition " + curPartIdx + " Search done" ) ; return true ; } } else { isFinishedSearch = true ; } return false ; } public void setNumTokensBoundsInSearchKeys ( short numTokensLowerBound , short numTokensUpperBound ) {
searchResultTupleIndex = 0 ; searchResultFta . reset ( searchResultBuffer ) ; // Temp : // System . out . println ( "PartitionedTOccurrenceSearcher : : continueSearch ( ) - " + needToReadNewPart // + " tupleCount " + searchResultFta . getTupleCount ( ) ) ; // } // Finished processing one partition if ( needToReadNewPart && isFinalPartIdx ) { invListMerger . close ( ) ; finalSearchResult . finalizeWrite ( ) ; isFinishedSearch = true ; < |startfocus| > // Temp : // System . out . println ( "Final partition " + curPartIdx + " Search done" ) ; < |endfocus| > return true ; } } else { isFinishedSearch = true ; } return false ; } public void setNumTokensBoundsInSearchKeys ( short numTokensLowerBound , short numTokensUpperBound ) { ShortPointable . setShort ( lowerBoundTuple . getFieldData ( 0 ) , lowerBoundTuple . getFieldStart ( 0 ) , numTokensLowerBound ) ; ShortPointable . setShort ( upperBoundTuple . getFieldData ( 0 ) , upperBoundTuple . getFieldStart ( 0 ) , numTokensUpperBound ) ; } public ITupleReference getPrefixSearchKey ( ) { return searchKey ; } public ITupleReference getFullLowSearchKey ( ) { return fullLowSearchKey ; }
* false otherwise . * @throws HyracksDataException */ @Override public boolean continueSearch ( ) throws HyracksDataException { if ( isFinishedSearch ) { return true ; } isFinishedSearch = invListMerger . continueMerge ( ) ; searchResultBuffer = finalSearchResult . getNextFrame ( ) ; searchResultTupleIndex = 0 ; searchResultFta . reset ( searchResultBuffer ) ; < |startfocus| > // Temp : LOGGER . info ( "PartitionedTOccurrenceSearcher : : continueSearch ( ) - " + isFinishedSearch + " tupleCount " + searchResultFta . getTupleCount ( ) ) ; // < |endfocus| > if ( isFinishedSearch ) { invListMerger . close ( ) ; finalSearchResult . finalizeWrite ( ) ; } return isFinishedSearch ; } }
* Otherwise , it performs an insert . * * @param tuple * Tuple to be deleted . * @throws HyracksDataException * If the BufferCache throws while un / pinning or un / latching . * @throws IndexException * If there is no matching tuple in the index . * */ public void upsert ( ITupleReference tuple ) throws HyracksDataException ; /* * * Creates a cursor appropriate for passing into search ( ) . < |startfocus| > * < |endfocus| > * @throws HyracksDataException * */ public IIndexCursor createSearchCursor ( boolean exclusive ) throws HyracksDataException ; /* * * Open the given cursor for an index search using the given predicate as * search condition . * * @param icursor * Cursor over the index entries satisfying searchPred . * @param searchPred * Search condition . * @throws HyracksDataException * If the BufferCache throws while un / pinning or un / latching . * @throws IndexException */ public void search ( IIndexCursor cursor , ISearchPredicate searchPred ) throws HyracksDataException ; }
public boolean append ( byte [ ] bytes , int offset , int length ) { if ( tupleDataEndOffset + length + TUPLE_COUNT_SIZE <= frameSize ) { < |startfocus| > if ( buffer == null ) { LOGGER . info ( "buffer null" ) ; } < |endfocus| > System . arraycopy ( bytes , offset , buffer . array ( ) , tupleDataEndOffset , length ) ; tupleDataEndOffset += length ; return true ; } return false ;
invListTuple = invListCursor . getTuple ( ) ; if ( ! newSearchResult . append ( invListTuple , 1 ) ) { // For a final result , needs to pause when a frame becomes full to let the caller // consume the frame . SearchResult . append ( ) should only return false for this case . return false ; } invListTidx ++ ; if ( invListCursor . hasNext ( ) ) { invListCursor . next ( ) ; } } // append remaining elements from previous result set while ( resultTidx < prevResultFrameTupleCount ) { resultTuple . reset ( prevCurrentBuffer . array ( ) , resultFrameTupleAcc . getTupleStartOffset ( resultTidx ) ) ; count = getCount ( resultTuple ) ; if ( ! newSearchResult . append ( resultTuple , count ) ) { // For a final result , needs to pause when a frame becomes full to let the caller // consume the frame . SearchResult . append ( ) should only return false for this case . return false ; } resultTidx ++ ; checkPrevResultAndFetchNextFrame ( prevSearchResult ) ; } return finishMergingOneList ( isFinalList , prevSearchResult , newSearchResult ) ; }
} private static final Map < Integer , ReplicationRequestType > TYPES = new HashMap < > ( ) ; static { Stream . of ( ReplicationRequestType . values ( ) ) . forEach ( type - > TYPES . put ( type . ordinal ( ) , type ) ) ; } public static ByteBuffer readRequest ( SocketChannel socketChannel , ByteBuffer dataBuffer ) throws IOException { // read request size NetworkingUtil . readBytes ( socketChannel , dataBuffer , Integer . BYTES ) ; final int requestSize = dataBuffer . getInt ( ) ; if ( dataBuffer . capacity ( ) < requestSize ) { ByteBuffer newDataBuffer = ByteBuffer . allocate ( requestSize ) ; dataBuffer = newDataBuffer ; } // read request < |startfocus| > NetworkingUtil . readBytes ( socketChannel , dataBuffer , requestSize ) ; < |endfocus| > return dataBuffer ; } public static ReplicationRequestType getRequestType ( SocketChannel socketChannel , ByteBuffer byteBuffer ) throws IOException { // read replication request type NetworkingUtil . readBytes ( socketChannel , byteBuffer , REPLICATION_REQUEST_TYPE_SIZE ) ; return TYPES . get ( byteBuffer . getInt ( ) ) ; } private static ByteBuffer getGoodbyeBuffer ( ) { ByteBuffer bb = ByteBuffer . allocate ( REPLICATION_REQUEST_TYPE_SIZE ) ; bb . putInt ( ReplicationRequestType . GOODBYE . ordinal ( ) ) ; bb . flip ( ) ; return bb ; }
< |startfocus| > public static int getJobIdFromLogAckMessage ( String msg ) { return Integer . parseInt ( msg . substring ( msg . indexOf ( JOB_REPLICATION_ACK ) + 1 ) ) ; < |endfocus| >
ITupleReference highSearchKey = null ; partSearcher . setNumTokensBoundsInSearchKeys ( numTokensLowerBound , numTokensUpperBound ) ; if ( numTokensLowerBound < 0 ) { ctx . getBtreePred ( ) . setLowKeyComparator ( ctx . getPrefixSearchCmp ( ) ) ; lowSearchKey = partSearcher . getPrefixSearchKey ( ) ; } else { ctx . getBtreePred ( ) . setLowKeyComparator ( ctx . getSearchCmp ( ) ) ; lowSearchKey = partSearcher . getFullLowSearchKey ( ) ; } if ( numTokensUpperBound < 0 ) { < |startfocus| > ctx . getBtreePred ( ) . setHighKeyComparator ( ctx . getPrefixSearchCmp ( ) ) ; < |endfocus| > highSearchKey = partSearcher . getPrefixSearchKey ( ) ; } else { ctx . getBtreePred ( ) . setHighKeyComparator ( ctx . getSearchCmp ( ) ) ; highSearchKey = partSearcher . getFullHighSearchKey ( ) ; } ctx . getBtreePred ( ) . setLowKey ( lowSearchKey , true ) ; ctx . getBtreePred ( ) . setHighKey ( highSearchKey , true ) ; ctx . getBtreeAccessor ( ) . search ( ctx . getBtreeCursor ( ) , ctx . getBtreePred ( ) ) ; boolean tokenExists = false ; try { while ( ctx . getBtreeCursor ( ) . hasNext ( ) ) { ctx . getBtreeCursor ( ) . next ( ) ; ITupleReference btreeTuple = ctx . getBtreeCursor ( ) . getTuple ( ) ;
} protected void createAndOpenFile ( ) throws HyracksDataException { if ( isInMemoryOpMode ) { // In - memory mode should not generate a file . return ; } if ( searchResultWriter == null ) { FileReference file = ctx . getJobletContext ( ) . createManagedWorkspaceFile ( FILE_PREFIX ) ; searchResultWriter = new RunFileWriter ( file , ctx . getIoManager ( ) ) ; searchResultWriter . open ( ) ; isFileOpened = true ; } < |startfocus| > // Temp : // System . out . println ( file + " - InvertedIndexSearchResult : : file create and open - " ) ; < |endfocus| > } // Deallocates the I / O buffer ( one frame ) . This should be the last oepration . protected void deallocateIOBuffer ( ) throws HyracksDataException { if ( ioBufferFrame != null ) { // Temp : // System . out . println ( // "InvertedIndexSearchResult : : deallocateIOBuffer ( ) buffer - " + ObjectUtils . identityToString ( ioBuffer ) ) ; bufferManager . releaseFrame ( ioBuffer ) ; buffers . clear ( ) ; ioBufferFrame = null ; ioBuffer = null ; } } /* *
foundIn = i ; return true ; } } if ( i == 0 && includeMutableComponent ) { // unlatch / unpin btreeCursors [ i ] . reset ( ) ; searchCallback . reconcile ( predicate . getLowKey ( ) ) ; reconciled = true ; // retraverse btreeAccessors [ 0 ] . search ( btreeCursors [ i ] , predicate ) ; if ( btreeCursors [ i ] . hasNext ( ) ) { btreeCursors [ i ] . next ( ) ; if ( ( ( ILSMTreeTupleReference ) btreeCursors [ i ] . getTuple ( ) ) . isAntimatter ( ) ) { searchCallback . cancel ( predicate . getLowKey ( ) ) ; < |startfocus| > btreeCursors [ i ] . close ( ) ; < |endfocus| > return false ; } else { frameTuple = btreeCursors [ i ] . getTuple ( ) ; foundTuple = true ; searchCallback . complete ( predicate . getLowKey ( ) ) ; foundIn = i ; return true ; } } else { searchCallback . cancel ( predicate . getLowKey ( ) ) ; btreeCursors [ i ] . close ( ) ; } } else { frameTuple = btreeCursors [ i ] . getTuple ( ) ; searchCallback . reconcile ( frameTuple ) ; searchCallback . complete ( frameTuple ) ; foundTuple = true ; foundIn = i ; return true ; } } else { frameTuple = btreeCursors [ i ] . getTuple ( ) ; searchCallback . reconcile ( frameTuple ) ; searchCallback . complete ( frameTuple ) ; foundTuple = true ; foundIn = i ;
protected void appendToLogTail ( ILogRecord logRecord ) { syncAppendToLogTail ( logRecord ) ; if ( waitForFlush ( logRecord ) && ! logRecord . isFlushed ( ) ) { synchronized ( logRecord ) { while ( ! logRecord . isFlushed ( ) ) { try { logRecord . wait ( ) ; } catch ( InterruptedException e ) { // NOSONAR ensure txn survive at this stage // ignore interrupt } } < |startfocus| > } < |endfocus| > Thread . currentThread ( ) . interrupt ( ) ; } }
* "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . asterix . common . replication ; import java . util . HashMap ; import java . util . Map ; public class ReplicationStrategyFactory { private static final Map < String , Class < ? extends IReplicationStrategy > > BUILT_IN_REPLICATION_STRATEGY = new HashMap < > ( ) ; static { BUILT_IN_REPLICATION_STRATEGY . put ( "no_replication" , NoReplicationStrategy . class ) ; BUILT_IN_REPLICATION_STRATEGY . put ( "all" , AllDatasetsReplicationStrategy . class ) ; BUILT_IN_REPLICATION_STRATEGY . put ( "metadata" , MetadataOnlyReplicationStrategy . class ) ; } private ReplicationStrategyFactory ( ) { throw new AssertionError ( ) ; } public static IReplicationStrategy create ( String name ) { String strategyName = name . toLowerCase ( ) ; if ( ! BUILT_IN_REPLICATION_STRATEGY . containsKey ( strategyName ) ) { throw new IllegalStateException ( "Couldn't find strategy with name : " + name ) ; } Class < ? extends IReplicationStrategy > clazz = BUILT_IN_REPLICATION_STRATEGY . get ( strategyName ) ; try {
setNumActiveIOOps ( getNumActiveIOOps ( ) + 1 ) ; } public synchronized void undeclareActiveIOOperation ( ) { setNumActiveIOOps ( getNumActiveIOOps ( ) - 1 ) ; // notify threads waiting on this dataset info notifyAll ( ) ; } public synchronized Set < ILSMIndex > getDatasetIndexes ( ) { Set < ILSMIndex > datasetIndexes = new HashSet < > ( ) ; for ( IndexInfo iInfo : getIndexes ( ) . values ( ) ) { if ( iInfo . isOpen ( ) ) { datasetIndexes . add ( iInfo . getIndex ( ) ) ; } } < |startfocus| > return datasetIndexes ; < |endfocus| > } @Override public int compareTo ( DatasetInfo i ) { // sort by ( isOpen , referenceCount , lastAccess ) ascending , where true < false // // Example sort order : // -- -- -- -- -- -- -- -- -- - // ( F , 0 , 70 ) <- - largest // ( F , 0 , 60 ) // ( T , 10 , 80 ) // ( T , 10 , 70 ) // ( T , 9 , 90 ) // ( T , 0 , 100 ) <- - smallest if ( isOpen ( ) && ! i . isOpen ( ) ) { return - 1 ; }
ILSMOperationTracker opTracker = iInfo . getIndex ( ) . getOperationTracker ( ) ; synchronized ( opTracker ) { iInfo . getIndex ( ) . deactivate ( false ) ; } iInfo . setOpen ( false ) ; } } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException { ArrayList < DatasetLifecycle > openDatasets = new ArrayList < > ( datasetLifecycles . values ( ) ) ; for ( DatasetLifecycle dslc : openDatasets ) { closeDataset ( dslc . getDatasetInfo ( ) ) ; } } @Override public synchronized void closeUserDatasets ( ) throws HyracksDataException { < |startfocus| > ArrayList < DatasetLifecycle > openDatasets = new ArrayList < > ( datasetLifecycles . values ( ) ) ; for ( DatasetLifecycle dslc : openDatasets ) { if ( dslc . getDatasetID ( ) >= getFirstAvilableUserDatasetID ( ) ) { closeDataset ( dslc . getDatasetInfo ( ) ) ; } } } @Override public synchronized void stop ( boolean dumpState , OutputStream outputStream ) throws IOException { if ( stopped ) { return ; } if ( dumpState ) { dumpState ( outputStream ) ; } closeAllDatasets ( ) ; datasetLifecycles . clear ( ) ;
protected void cleanupForAbort ( ) { < |startfocus| > for ( Entry < Integer , Pair < PrimaryIndexOperationTracker , IModificationOperationCallback > > e : primaryIndexTrackers . entrySet ( ) ) { < |endfocus| > AtomicInteger pendingOps = partitionPendingOps . get ( e . getKey ( ) ) ; e . getValue ( ) . first . cleanupNumActiveOperationsForAbortedJob ( pendingOps . get ( ) ) ; }
protected void cleanupForAbort ( ) { < |startfocus| > for ( Entry < Integer , Pair < PrimaryIndexOperationTracker , IModificationOperationCallback > > e : primaryIndexTrackers . entrySet ( ) ) { < |endfocus| > AtomicInteger pendingOps = partitionPendingOps . get ( e . getKey ( ) ) ; e . getValue ( ) . first . cleanupNumActiveOperationsForAbortedJob ( pendingOps . get ( ) ) ; }
protected void cleanupForAbort ( ) { < |startfocus| > for ( Entry < Integer , Pair < PrimaryIndexOperationTracker , IModificationOperationCallback > > e : primaryIndexTrackers . entrySet ( ) ) { < |endfocus| > AtomicInteger pendingOps = partitionPendingOps . get ( e . getKey ( ) ) ; e . getValue ( ) . first . cleanupNumActiveOperationsForAbortedJob ( pendingOps . get ( ) ) ; }
protected void cleanupForAbort ( ) { < |startfocus| > for ( Entry < Integer , Pair < PrimaryIndexOperationTracker , IModificationOperationCallback > > e : primaryIndexTrackers . entrySet ( ) ) { < |endfocus| > AtomicInteger pendingOps = partitionPendingOps . get ( e . getKey ( ) ) ; e . getValue ( ) . first . cleanupNumActiveOperationsForAbortedJob ( pendingOps . get ( ) ) ; }
protected void cleanupForAbort ( ) { < |startfocus| > for ( Entry < Integer , Pair < PrimaryIndexOperationTracker , IModificationOperationCallback > > e : primaryIndexTrackers . entrySet ( ) ) { < |endfocus| > AtomicInteger pendingOps = partitionPendingOps . get ( e . getKey ( ) ) ; e . getValue ( ) . first . cleanupNumActiveOperationsForAbortedJob ( pendingOps . get ( ) ) ; }
return primaryKeyVars ; } /* * * Returns the search key expression which feeds a secondary - index search . If we are optimizing a selection query * then this method returns the a ConstantExpression from the first constant value in the optimizable function * expression . * If we are optimizing a join , then this method returns the VariableReferenceExpression that should feed the * secondary index probe . * * @throws AlgebricksException */ < |startfocus| > public static Pair < ILogicalExpression , ILogicalExpression > createSearchKeyExpr ( Index index , < |endfocus| > IOptimizableFuncExpr optFuncExpr , IAType indexedFieldType , OptimizableOperatorSubTree probeSubTree ) throws AlgebricksException { if ( probeSubTree == null ) { // We are optimizing a selection query . Search key is a constant . // Type Checking and type promotion is done here if ( optFuncExpr . getNumConstantExpr ( ) == 0 ) { // We are looking at a selection case , but using two variables // This means that the second variable comes from a nonPure function call // TODO : Right now we miss on type promotion for nonpure functions // TODO : We need to fix this case .
if ( dsInfo . isDurable ( ) ) { synchronized ( logRecord ) { TransactionUtil . formFlushLogRecord ( logRecord , dsInfo . getDatasetID ( ) , null , logManager . getNodeId ( ) , indexes . size ( ) ) ; try { logManager . log ( logRecord ) ; } catch ( ACIDException e ) { throw new HyracksDataException ( "could not write flush log while closing dataset" , e ) ; } try { // notification will come from LogBuffer class ( notifyFlushTerminator ) logRecord . wait ( ) ; } catch ( InterruptedException e ) { < |startfocus| > throw new HyracksDataException ( e ) ; < |endfocus| > } } } for ( ILSMIndex index : indexes ) { // update resource lsn AbstractLSMIOOperationCallback ioOpCallback = ( AbstractLSMIOOperationCallback ) index . getIOOperationCallback ( ) ; ioOpCallback . updateLastLSN ( logRecord . getLSN ( ) ) ; } if ( asyncFlush ) { for ( ILSMIndex index : indexes ) { ILSMIndexAccessor accessor = index . createAccessor ( NoOpIndexAccessParameters . INSTANCE ) ; accessor . scheduleFlush ( index . getIOOperationCallback ( ) ) ; } } else { for ( ILSMIndex index : indexes ) { < |startfocus| > ILSMIndexAccessor accessor = index . createAccessor ( NoOpIndexAccessParameters . INSTANCE ) ; accessor . scheduleFlush ( index . getIOOperationCallback ( ) ) ; < |endfocus| > } }
synchronized ( logRecord ) { TransactionUtil . formFlushLogRecord ( logRecord , dsInfo . getDatasetID ( ) , null , logManager . getNodeId ( ) , indexes . size ( ) ) ; try { logManager . log ( logRecord ) ; } catch ( ACIDException e ) { throw new HyracksDataException ( "could not write flush log while closing dataset" , e ) ; } try { // notification will come from LogBuffer class ( notifyFlushTerminator ) logRecord . wait ( ) ; } catch ( InterruptedException e ) { < |startfocus| > Thread . currentThread ( ) . interrupt ( ) ; < |endfocus| > } } } for ( ILSMIndex index : indexes ) { // update resource lsn AbstractLSMIOOperationCallback ioOpCallback = ( AbstractLSMIOOperationCallback ) index . getIOOperationCallback ( ) ; ioOpCallback . updateLastLSN ( logRecord . getLSN ( ) ) ; } if ( asyncFlush ) { for ( ILSMIndex index : indexes ) { ILSMIndexAccessor accessor = index . createAccessor ( NoOpIndexAccessParameters . INSTANCE ) ; accessor . scheduleFlush ( index . getIOOperationCallback ( ) ) ; } } else { for ( ILSMIndex index : indexes ) { // TODO : This is not efficient since we flush the indexes sequentially .
try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { throw new HyracksDataException ( e ) ; } } } try { flushDatasetOpenIndexes ( dsInfo , false ) ; } catch ( Exception e ) { throw new HyracksDataException ( e ) ; } for ( IndexInfo iInfo : dsInfo . getIndexes ( ) . values ( ) ) { < |startfocus| > if ( iInfo . isOpen ( ) ) { ILSMOperationTracker opTracker = iInfo . getIndex ( ) . getOperationTracker ( ) ; synchronized ( opTracker ) { iInfo . getIndex ( ) . deactivate ( false ) ; } iInfo . setOpen ( false ) ; } < |endfocus| > } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ; for ( DatasetResource dsr : openDatasets ) { closeDataset ( dsr . getDatasetInfo ( ) ) ; } } @Override public synchronized void closeUserDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ; for ( DatasetResource dsr : openDatasets ) { < |startfocus| > if ( dsr . getDatasetInfo ( ) . getDatasetID ( ) >= DatasetIdFactory . FIRST_USER_DATASET_ID ) { closeDataset ( dsr . getDatasetInfo ( ) ) ; } < |endfocus| > } } @Override public synchronized void closeDataset ( int datasetId ) throws HyracksDataException { DatasetResource dsr = datasets . get ( datasetId ) ; if ( dsr == null ) { throw new HyracksDataException ( "Unknown dataset " + datasetId ) ; } closeDataset ( dsr . getDatasetInfo ( ) ) ; } @Override public synchronized void closeDataset ( DatasetInfo dsInfo ) throws HyracksDataException { if ( ! dsInfo . isOpen ( ) ) { return ; } synchronized ( dsInfo ) { while ( dsInfo . getOpenCount ( ) > 0 ) { try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { throw new HyracksDataException ( e ) ; } } } try { flushDatasetOpenIndexes ( dsInfo , false ) ; } catch ( Exception e ) { throw new HyracksDataException ( e ) ; } for ( IndexInfo iInfo : dsInfo . getIndexes ( ) . values ( ) ) { if ( iInfo . isOpen ( ) ) { ILSMOperationTracker opTracker = iInfo . getIndex ( ) . getOperationTracker ( ) ; synchronized ( opTracker ) { iInfo . getIndex ( ) . deactivate ( false ) ; } iInfo . setOpen ( false ) ; } } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ; for ( DatasetResource dsr : openDatasets ) { closeDataset ( dsr . getDatasetInfo ( ) ) ; } } @Override public synchronized void closeUserDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ; for ( DatasetResource dsr : openDatasets ) {
try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { throw new HyracksDataException ( e ) ; } } } try { flushDatasetOpenIndexes ( dsInfo , false ) ; } catch ( Exception e ) { throw new HyracksDataException ( e ) ; } for ( IndexInfo iInfo : dsInfo . getIndexes ( ) . values ( ) ) { < |startfocus| > if ( iInfo . isOpen ( ) ) { ILSMOperationTracker opTracker = iInfo . getIndex ( ) . getOperationTracker ( ) ; synchronized ( opTracker ) { iInfo . getIndex ( ) . deactivate ( false ) ; } iInfo . setOpen ( false ) ; } < |endfocus| > } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ; for ( DatasetResource dsr : openDatasets ) { closeDataset ( dsr . getDatasetInfo ( ) ) ; } } @Override public synchronized void closeUserDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ; for ( DatasetResource dsr : openDatasets ) { Thread . currentThread ( ) . interrupt ( ) ;
// we will force all jobs to spill their cached entities to disk . // This could happen only when we have many jobs with small // number of records and none of them have job commit . freeJobsCachedEntities ( txnId ) ; } jobId2WinnerEntitiesMap . put ( txnId , jobEntityWinners ) ; } else { jobEntityWinners = jobId2WinnerEntitiesMap . get ( txnId ) ; } jobEntityWinners . add ( logRecord ) ; } < |startfocus| > @SuppressWarnings ( { "squid : MethodCyclomaticComplexity" , "squid : S134" } ) < |endfocus| > private synchronized void startRecoveryRedoPhase ( Set < Integer > partitions , ILogReader logReader , long lowWaterMarkLSN , Set < Long > winnerTxnSet ) throws IOException , ACIDException { int redoCount = 0 ; long txnId = 0 ; long resourceId ; long maxDiskLastLsn ; long lsn = - 1 ; ILSMIndex index = null ; LocalResource localResource = null ; DatasetLocalResource localResourceMetadata = null ; boolean foundWinner = false ; JobEntityCommits jobEntityWinners = null ; IAppRuntimeContextProvider appRuntimeContext = txnSubsystem . getAsterixAppRuntimeContextProvider ( ) ; IDatasetLifecycleManager datasetLifecycleManager = appRuntimeContext . getDatasetLifecycleManager ( ) ;
private void doWriteLogRecord ( ByteBuffer buffer ) { buffer . put ( logSource ) ; buffer . put ( logType ) ; buffer . putLong ( txnId ) ; switch ( logType ) { case LogType . ENTITY_COMMIT : < |startfocus| > writeEntityResource ( buffer ) ; < |endfocus| > break ; case LogType . UPDATE : writeEntityResource ( buffer ) ; buffer . putLong ( resourceId ) ; buffer . putInt ( logSize ) ; buffer . putInt ( newValueFieldCount ) ; buffer . put ( newOp ) ; buffer . putInt ( newValueSize ) ; writeTuple ( buffer , newValue , newValueSize ) ; if ( oldValueSize > 0 ) { buffer . putInt ( oldValueSize ) ; buffer . putInt ( oldValueFieldCount ) ; writeTuple ( buffer , oldValue , oldValueSize ) ; } break ; case LogType . FILTER : writeEntityResource ( buffer ) ; buffer . putLong ( resourceId ) ; buffer . putInt ( logSize ) ; buffer . putInt ( newValueFieldCount ) ; buffer . put ( newOp ) ; buffer . putInt ( newValueSize ) ; writeTuple ( buffer , newValue , newValueSize ) ; break ; case LogType . FLUSH : buffer . putInt ( datasetId ) ; break ; case LogType . MARKER : buffer . putInt ( datasetId ) ; buffer . putInt ( resourcePartition ) ; callback . before ( buffer ) ; buffer . putInt ( logSize ) ;
< |startfocus| > private void writeEntityInfo ( ByteBuffer buffer ) { buffer . putInt ( resourcePartition ) ; buffer . putInt ( datasetId ) ; < |endfocus| > buffer . putInt ( PKHashValue ) ; if ( PKValueSize <= 0 ) { throw new IllegalStateException ( "Primary Key Size is less than or equal to 0" ) ; } buffer . putInt ( PKValueSize ) ; writeEntityValue ( buffer ) ;
< |startfocus| > private void writeEntityInfo ( ByteBuffer buffer ) { buffer . putInt ( resourcePartition ) ; buffer . putInt ( datasetId ) ; < |endfocus| > buffer . putInt ( PKHashValue ) ; if ( PKValueSize <= 0 ) { throw new IllegalStateException ( "Primary Key Size is less than or equal to 0" ) ; } buffer . putInt ( PKValueSize ) ; writePKValue ( buffer ) ;
< |startfocus| > private void writeEntityResource ( ByteBuffer buffer ) { < |endfocus| > buffer . putInt ( resourcePartition ) ; buffer . putInt ( datasetId ) ;
txnId = buffer . getLong ( ) ; switch ( logType ) { case LogType . FLUSH : if ( buffer . remaining ( ) < ILogRecord . DS_LEN ) { return RecordReadStatus . TRUNCATED ; } datasetId = buffer . getInt ( ) ; resourceId = 0l ; // fall throuh case LogType . WAIT : computeAndSetLogSize ( ) ; break ; case LogType . JOB_COMMIT : case LogType . ABORT : datasetId = - 1 ; PKHashValue = - 1 ; computeAndSetLogSize ( ) ; break ; case LogType . ENTITY_COMMIT : < |startfocus| > if ( readEntityResource ( buffer ) ) { < |endfocus| > computeAndSetLogSize ( ) ; } else { return RecordReadStatus . TRUNCATED ; } break ; case LogType . UPDATE : if ( readEntityInfo ( buffer ) ) { RecordReadStatus updStatus = readUpdateInfo ( buffer ) ; if ( updStatus != RecordReadStatus . OK ) { return updStatus ; } } else { return RecordReadStatus . TRUNCATED ; } break ; case LogType . FILTER : if ( readEntityNoPKInfo ( buffer ) ) { RecordReadStatus updStatus = readUpdateInfo ( buffer ) ; if ( updStatus != RecordReadStatus . OK ) {
if ( readEntityInfo ( buffer ) ) { computeAndSetLogSize ( ) ; } else { return RecordReadStatus . TRUNCATED ; } break ; case LogType . UPDATE : if ( readEntityInfo ( buffer ) ) { RecordReadStatus updStatus = readUpdateInfo ( buffer ) ; if ( updStatus != RecordReadStatus . OK ) { return updStatus ; } } else { return RecordReadStatus . TRUNCATED ; } break ; case LogType . FILTER : < |startfocus| > if ( readEntityResource ( buffer ) ) { RecordReadStatus updStatus = readUpdateInfo ( buffer ) ; if ( updStatus != RecordReadStatus . OK ) { return updStatus ; } } else { return RecordReadStatus . TRUNCATED ; < |endfocus| > } break ; case LogType . MARKER : if ( buffer . remaining ( ) < DS_LEN + RS_PARTITION_LEN + PRVLSN_LEN + LOGRCD_SZ_LEN ) { return RecordReadStatus . TRUNCATED ; } datasetId = buffer . getInt ( ) ; resourcePartition = buffer . getInt ( ) ; prevMarkerLSN = buffer . getLong ( ) ; logSize = buffer . getInt ( ) ; int lenRemaining = logSize - MARKER_BASE_LOG_SIZE ;
computeAndSetLogSize ( ) ; } else { return RecordReadStatus . TRUNCATED ; } break ; case LogType . UPDATE : if ( readEntityInfo ( buffer ) ) { RecordReadStatus updStatus = readUpdateInfo ( buffer ) ; if ( updStatus != RecordReadStatus . OK ) { return updStatus ; } } else { return RecordReadStatus . TRUNCATED ; } break ; case LogType . FILTER : < |startfocus| > if ( readEntityNoPKInfo ( buffer ) ) { RecordReadStatus updStatus = readUpdateInfo ( buffer ) ; if ( updStatus != RecordReadStatus . OK ) { return updStatus ; } } else { return RecordReadStatus . TRUNCATED ; } break ; case LogType . MARKER : if ( buffer . remaining ( ) < DS_LEN + RS_PARTITION_LEN + PRVLSN_LEN + LOGRCD_SZ_LEN ) { return RecordReadStatus . TRUNCATED ; } datasetId = buffer . getInt ( ) ; resourcePartition = buffer . getInt ( ) ; prevMarkerLSN = buffer . getLong ( ) ; logSize = buffer . getInt ( ) ; int lenRemaining = logSize - MARKER_BASE_LOG_SIZE ; if ( buffer . remaining ( ) < lenRemaining ) {
private boolean readEntityInfo ( ByteBuffer buffer ) { // attempt to read in the resourcePartition , dsid , PK hash and PK length < |startfocus| > if ( buffer . remaining ( ) < ENTITYCOMMIT_UPDATE_HEADER_LEN ) { < |endfocus| > return false ; } resourcePartition = buffer . getInt ( ) ; datasetId = buffer . getInt ( ) ; PKHashValue = buffer . getInt ( ) ; PKValueSize = buffer . getInt ( ) ; // attempt to read in the PK < |startfocus| > if ( buffer . remaining ( ) < PKValueSize ) { return false ; } if ( PKValueSize <= 0 ) { throw new IllegalStateException ( "Primary Key Size is less than or equal to 0" ) ; } < |endfocus| > PKValue = readPKValue ( buffer ) ; return true ;
private boolean readEntityInfo ( ByteBuffer buffer ) { // attempt to read in the resourcePartition , dsid , PK hash and PK length if ( buffer . remaining ( ) < ENTITYCOMMIT_UPDATE_HEADER_LEN ) { return false ; } < |startfocus| > resourcePartition = buffer . getInt ( ) ; datasetId = buffer . getInt ( ) ; PKHashValue = buffer . getInt ( ) ; PKValueSize = buffer . getInt ( ) ; // attempt to read in the PK if ( buffer . remaining ( ) < PKValueSize ) { return false ; } if ( PKValueSize <= 0 ) { throw new IllegalStateException ( "Primary Key Size is less than or equal to 0" ) ; } PKValue = readPKValue ( buffer ) ; return true ; < |endfocus| >
< |startfocus| > private boolean readEntityResource ( ByteBuffer buffer ) { // attempt to read in the resourcePartition , dsid , PK hash and PK length if ( buffer . remaining ( ) < ENTITYCOMMIT_UPDATE_HEADER_LEN ) { < |endfocus| > return false ; } resourcePartition = buffer . getInt ( ) ; datasetId = buffer . getInt ( ) ; return true ;
< |startfocus| > private boolean readEntityNoPKInfo ( ByteBuffer buffer ) { // attempt to read in the resourcePartition , dsid , PK hash and PK length if ( buffer . remaining ( ) < ENTITYCOMMIT_UPDATE_HEADER_LEN ) { < |endfocus| > return false ; } resourcePartition = buffer . getInt ( ) ; datasetId = buffer . getInt ( ) ; return true ;
< |startfocus| > private boolean readEntityNoPKInfo ( ByteBuffer buffer ) { // attempt to read in the resourcePartition , dsid , PK hash and PK length if ( buffer . remaining ( ) < ENTITYCOMMIT_UPDATE_HEADER_LEN ) { < |endfocus| > return false ; } resourcePartition = buffer . getInt ( ) ; datasetId = buffer . getInt ( ) ; entityResourceLength = buffer . getInt ( ) ; return true ;
if ( isDeleteOperation ( tuple , numOfPrimaryKeys ) ) { // Only delete if it is a delete and not upsert abstractModCallback . setOp ( Operation . DELETE ) ; lsmAccessor . forceDelete ( tuple ) ; recordWasDeleted = true ; } else { abstractModCallback . setOp ( Operation . UPSERT ) ; lsmAccessor . forceUpsert ( tuple ) ; recordWasInserted = true ; } if ( isFiltered && prevTuple != null ) { // need to update the filter of the new component with the previous value < |startfocus| > lsmAccessor . updateFilter ( prevTuple , true ) ; < |endfocus| > } writeOutput ( index , recordWasInserted , recordWasDeleted ) ; } catch ( Exception e ) { throw HyracksDataException . create ( e ) ; } } @Override public void start ( ) throws HyracksDataException { lsmAccessor . getCtx ( ) . setOperation ( IndexOperation . UPSERT ) ; } @Override public void finish ( ) throws HyracksDataException { lsmAccessor . getCtx ( ) . setOperation ( IndexOperation . UPSERT ) ; } } ; } // we have the permutation which has [ pk locations , record location , optional : filter - location ] // the index - > we don't need anymore data ? // we have the permutation which has [ pk locations , record location , optional : filter - location ] // the index - > we don't need anymore data ?
* * Unless required by applicable law or agreed to in writing , * software distributed under the License is distributed on an * "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . storage . am . common . ophelpers ; public enum IndexOperation { CREATE , INSERT , DELETE , UPDATE , UPSERT , FILTER_MOD , SEARCH , DISKORDERSCAN , PHYSICALDELETE , NOOP , MERGE , FULL_MERGE , FLUSH , REPLICATE , DISK_COMPONENT_SCAN , DELETE_MEMORY_COMPONENT , DELETE_DISK_COMPONENTS }
ctx . setOperation ( IndexOperation . UPSERT ) ; lsmHarness . forceUpdateMeta ( ctx , key , value ) ; } @Override public ITreeIndexCursor createSearchCursor ( boolean exclusive ) { return cursorFactory . create ( ctx ) ; } @Override public void updateFilter ( ITupleReference tuple ) throws HyracksDataException { ctx . setOperation ( IndexOperation . UPSERT ) ; lsmHarness . updateFilter ( ctx , tuple ) ; } public void updateFilter ( ITupleReference tuple , boolean callback ) throws HyracksDataException { ctx . setOperation ( IndexOperation . UPSERT ) ; lsmHarness . updateFilter ( ctx , tuple , callback ) ; } public void batchOperate ( FrameTupleAccessor accessor , FrameTupleReference tuple , IFrameTupleProcessor processor , IFrameOperationCallback frameOpCallback ) throws HyracksDataException { lsmHarness . batchOperate ( ctx , accessor , tuple , processor , frameOpCallback ) ; } @Override public void scanDiskComponents ( IIndexCursor cursor ) throws HyracksDataException { ctx . setOperation ( IndexOperation . DISK_COMPONENT_SCAN ) ; lsmHarness . scanDiskComponents ( ctx , cursor ) ; } @Override public String toString ( ) { return getClass ( ) . getSimpleName ( ) + ' : ' + lsmHarness . toString ( ) ; } @Override
} @Override public void found ( ITupleReference before , ITupleReference after ) throws HyracksDataException { if ( isFoundNull ) { Assert . assertEquals ( null , before ) ; } else { Assert . assertEquals ( 0 , cmp . compare ( AbstractModificationOperationCallbackTest . this . tuple , before ) ) ; } Assert . assertEquals ( 0 , cmp . compare ( AbstractModificationOperationCallbackTest . this . tuple , after ) ) ; } < |startfocus| > @Override public void after ( ITupleReference tuple ) throws HyracksDataException { Assert . assertEquals ( 0 , cmp . compare ( AbstractModificationOperationCallbackTest . this . tuple , tuple ) ) ; } < |endfocus| > } }
// Do nothing . } @Override public void before ( ITupleReference tuple ) { // Do nothing . } @Override public void found ( ITupleReference before , ITupleReference after ) { // Do nothing . } @Override public void cancel ( ITupleReference tuple ) { // Do nothing . } @Override public void complete ( ITupleReference tuple ) throws HyracksDataException { // Do nothing . } < |startfocus| > @Override public void after ( ITupleReference tuple ) throws HyracksDataException { // Do nothing . } < |endfocus| > }
public void after ( ITupleReference tuple ) { < |startfocus| > < |endfocus| >
IOptimizationContext context , Quadruple < Boolean , Boolean , Boolean , Boolean > indexOnlyPlanInfo ) throws AlgebricksException { // index - only plan possible ? boolean isIndexOnlyPlan = false ; // secondary key field usage after the select ( join ) operators // This boolean is mainly used for R - Tree case since R - Tree index generates an MBR // and we can restore original point or rectangle from this MBR if an index is built on point or rectangle . < |startfocus| > boolean secondaryKeyFieldUsedAfterSelectOrJoinOp = indexOnlyPlanInfo . getSecond ( ) ; // Whether a post verification ( especially for R - Tree case ) is required after the secondary index search // ( e . g . , the shape of the given query is not a point or rectangle . // Then , we may need to apply the select again using the real polygon , not MBR of it to get the true // result , not a super - set of it . ) boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo . getThird ( ) ; // Does the given index can cover all search predicates ? boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo . getFourth ( ) ; < |endfocus| >
// ( e . g . , the shape of the given query is not a point or rectangle . // Then , we may need to apply the select again using the real polygon , not MBR of it to get the true // result , not a super - set of it . ) boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo . getThird ( ) ; // Does the given index can cover all search predicates ? < |startfocus| > indexOnlyPlanInfo . getFourth ( ) ; < |endfocus| > // matched function expressions List < IOptimizableFuncExpr > matchedFuncExprs = analysisCtx . getMatchedFuncExprs ( ) ; // If no - index - only option is given , we stop here to honor that request . boolean noIndexOnlyPlanOption = getNoIndexOnlyOption ( context ) ; if ( noIndexOnlyPlanOption ) { indexOnlyPlanInfo . setFirst ( isIndexOnlyPlan ) ; return ; } // logical variables that select ( join ) operator is using List < LogicalVariable > usedVarsInSelJoinOp = new ArrayList < > ( ) ; List < LogicalVariable > usedVarsInSelJoinOpTemp = new ArrayList < > ( ) ; // live variables that select ( join ) operator can access
|| funcExpr . getFunctionIdentifier ( ) == BuiltinFunctions . FULLTEXT_CONTAINS_WO_OPTION ) { boolean matches = AccessMethodUtils . analyzeFuncExprArgsForOneConstAndVarAndUpdateAnalysisCtx ( funcExpr , analysisCtx , context , typeEnvironment ) ; if ( ! matches ) { matches = AccessMethodUtils . analyzeFuncExprArgsForTwoVarsAndUpdateAnalysisCtx ( funcExpr , analysisCtx ) ; } return matches ; } return analyzeGetItemFuncExpr ( funcExpr , assignsAndUnnests , analysisCtx ) ; } public boolean analyzeGetItemFuncExpr ( AbstractFunctionCallExpression funcExpr , List < AbstractLogicalOperator > assignsAndUnnests , AccessMethodAnalysisContext analysisCtx ) < |startfocus| > throws AlgebricksException { < |endfocus| > if ( funcExpr . getFunctionIdentifier ( ) != BuiltinFunctions . GET_ITEM ) { return false ; } ILogicalExpression arg1 = funcExpr . getArguments ( ) . get ( 0 ) . getValue ( ) ; ILogicalExpression arg2 = funcExpr . getArguments ( ) . get ( 1 ) . getValue ( ) ; // The second arg is the item index to be accessed . It must be a constant . if ( arg2 . getExpressionTag ( ) != LogicalExpressionTag . CONSTANT ) { return false ; } // The first arg must be a variable or a function expr . if ( arg1 . getExpressionTag ( ) == LogicalExpressionTag . FUNCTION_CALL ) { return analyzeGetItemFuncExpr ( ( AbstractFunctionCallExpression ) arg1 , assignsAndUnnests , analysisCtx ) ; } else if ( arg1 . getExpressionTag ( ) == LogicalExpressionTag . VARIABLE ) { return AccessMethodUtils . analyzeVarAndUpdateAnalysisCtx ( arg1 , assignsAndUnnests , analysisCtx ) ; } return false ; }
// ( E . g . There are index - nested - loop - joins in the plan . ) private List < Mutable < ILogicalOperator > > ixJoinOuterAdditionalDataSourceRefs = null ; private List < DataSourceType > ixJoinOuterAdditionalDataSourceTypes = null ; private List < Dataset > ixJoinOuterAdditionalDatasets = null ; private List < ARecordType > ixJoinOuterAdditionalRecordTypes = null ; /* * * Identifies the root of the subtree and initializes the data - source , assign , and unnest information . */ < |startfocus| > public boolean initFromSubTree ( Mutable < ILogicalOperator > subTreeOpRef , IOptimizationContext context ) throws AlgebricksException { < |endfocus| > reset ( ) ; rootRef = subTreeOpRef ; root = subTreeOpRef . getValue ( ) ; boolean passedSource = false ; boolean result = false ; Mutable < ILogicalOperator > searchOpRef = subTreeOpRef ; // Examine the op's children to match the expected patterns . AbstractLogicalOperator subTreeOp = ( AbstractLogicalOperator ) searchOpRef . getValue ( ) ; MetadataProvider metadataProvider = ( MetadataProvider ) context . getMetadataProvider ( ) ; do { // Skips the limit operator . if ( subTreeOp . getOperatorTag ( ) == LogicalOperatorTag . LIMIT ) {
// object creation : should be relatively low btreeCursors = new ITreeIndexCursor [ numBTrees ] ; btreeAccessors = new BTreeAccessor [ numBTrees ] ; bloomFilters = new BloomFilter [ numBTrees ] ; } includeMutableComponent = false ; for ( int i = 0 ; i < numBTrees ; i ++ ) { ILSMComponent component = operationalComponents . get ( i ) ; BTree btree = ( BTree ) component . getIndex ( ) ; if ( component . getType ( ) == LSMComponentType . MEMORY ) { includeMutableComponent = true ; bloomFilters [ i ] = null ; < |startfocus| > } else { < |endfocus| > bloomFilters [ i ] = ( ( LSMBTreeWithBloomFilterDiskComponent ) component ) . getBloomFilter ( ) ; } if ( btreeAccessors [ i ] == null ) { btreeAccessors [ i ] = btree . createAccessor ( NoOpIndexAccessParameters . INSTANCE ) ; btreeCursors [ i ] = btreeAccessors [ i ] . createPointCursor ( false ) ; } else { // re - use btreeAccessors [ i ] . reset ( btree , NoOpOperationCallback . INSTANCE , NoOpOperationCallback . INSTANCE ) ; btreeCursors [ i ] . close ( ) ; } } nextHasBeenCalled = false ; foundTuple = false ; } @Override public void next ( ) throws HyracksDataException { nextHasBeenCalled = true ;
// object creation : should be relatively low btreeCursors = new ITreeIndexCursor [ numBTrees ] ; btreeAccessors = new BTreeAccessor [ numBTrees ] ; bloomFilters = new BloomFilter [ numBTrees ] ; } includeMutableComponent = false ; for ( int i = 0 ; i < numBTrees ; i ++ ) { ILSMComponent component = operationalComponents . get ( i ) ; BTree btree = ( BTree ) component . getIndex ( ) ; if ( component . getType ( ) == LSMComponentType . MEMORY ) { includeMutableComponent = true ; bloomFilters [ i ] = null ; < |startfocus| > } else { < |endfocus| > bloomFilters [ i ] = ( ( LSMBTreeWithBloomFilterDiskComponent ) component ) . getBloomFilter ( ) ; } if ( btreeAccessors [ i ] == null ) { btreeAccessors [ i ] = btree . createAccessor ( NoOpIndexAccessParameters . INSTANCE ) ; btreeCursors [ i ] = btreeAccessors [ i ] . createPointCursor ( false ) ; } else { // re - use btreeAccessors [ i ] . reset ( btree , NoOpOperationCallback . INSTANCE , NoOpOperationCallback . INSTANCE ) ; btreeCursors [ i ] . close ( ) ; } } nextHasBeenCalled = false ; foundTuple = false ; } @Override public void next ( ) throws HyracksDataException { nextHasBeenCalled = true ;
public int compare ( ReferenceEntry tp1 , ReferenceEntry tp2 ) { int [ ] tPointers1 = tp1 . getTPointers ( ) ; int [ ] tPointers2 = tp2 . getTPointers ( ) ; int cmp = NormalizedKeyUtils . compareNormalizeKeys ( tPointers1 , 0 , tPointers2 , 0 , normalizedKeyLength ) ; < |startfocus| > if ( cmp != 0 || isDecisive ) { < |endfocus| > return cmp ; } IFrameTupleAccessor fta1 = tp1 . getAccessor ( ) ; IFrameTupleAccessor fta2 = tp2 . getAccessor ( ) ; byte [ ] b1 = fta1 . getBuffer ( ) . array ( ) ; byte [ ] b2 = fta2 . getBuffer ( ) . array ( ) ; for ( int f = 0 ; f < sortFields . length ; ++ f ) { int c ; try { c = comparators [ f ] . compare ( b1 , tPointers1 [ 2 * f + normalizedKeyLength ] , tPointers1 [ 2 * f + normalizedKeyLength + 1 ] , b2 , tPointers2 [ 2 * f + normalizedKeyLength ] , tPointers2 [ 2 * f + normalizedKeyLength + 1 ] ) ; if ( c != 0 ) { return c ; } } catch ( HyracksDataException e ) {
flushAndWaitForIO ( dsInfo , iInfo ) ; } } } private void closeDataset ( DatasetInfo dsInfo ) throws HyracksDataException { // First wait for any ongoing IO operations synchronized ( dsInfo ) { while ( dsInfo . getNumActiveIOOps ( ) > 0 ) { try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { Thread . currentThread ( ) . interrupt ( ) ; throw new HyracksDataException ( e ) ; } } } try { flushDatasetOpenIndexes ( dsInfo , false ) ; } catch ( Exception e ) { < |startfocus| > throw new HyracksDataException ( e ) ; < |endfocus| > } for ( IndexInfo iInfo : dsInfo . getIndexes ( ) . values ( ) ) { if ( iInfo . isOpen ( ) ) { ILSMOperationTracker opTracker = iInfo . getIndex ( ) . getOperationTracker ( ) ; synchronized ( opTracker ) { iInfo . getIndex ( ) . deactivate ( false ) ; } iInfo . setOpen ( false ) ; } } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException { ArrayList < DatasetResource > openDatasets = new ArrayList < > ( datasets . values ( ) ) ;
if ( op2 . getOperatorTag ( ) == LogicalOperatorTag . DATASOURCESCAN ) { DataSourceScanOperator scan = ( DataSourceScanOperator ) op2 ; int n = scan . getVariables ( ) . size ( ) ; LogicalVariable scanRecordVar = scan . getVariables ( ) . get ( n - 1 ) ; IDataSource < DataSourceId > dataSource = ( IDataSource < DataSourceId > ) scan . getDataSource ( ) ; byte dsType = ( ( DataSource ) dataSource ) . getDatasourceType ( ) ; < |startfocus| > if ( dsType != DataSource . Type . INTERNAL_DATASET && dsType != DataSource . Type . EXTERNAL_DATASET ) { < |endfocus| > return false ; } DataSourceId asid = dataSource . getId ( ) ; MetadataProvider mp = ( MetadataProvider ) context . getMetadataProvider ( ) ; Dataset dataset = mp . findDataset ( asid . getDataverseName ( ) , asid . getDatasourceName ( ) ) ; if ( dataset == null ) { throw new AlgebricksException ( "Dataset " + asid . getDatasourceName ( ) + " not found . " ) ; } if ( dataset . getDatasetType ( ) != DatasetType . INTERNAL ) { setAsFinal ( access , context , finalAnnot ) ; return false ; } String tName = dataset . getItemTypeName ( ) ;
buffer . putInt ( newValueSize ) ; writeTuple ( buffer , newValue , newValueSize ) ; if ( oldValueSize > 0 ) { buffer . putInt ( oldValueSize ) ; buffer . putInt ( oldValueFieldCount ) ; writeTuple ( buffer , oldValue , oldValueSize ) ; } break ; case LogType . FILTER : writeEntityResource ( buffer ) ; buffer . putLong ( resourceId ) ; buffer . putInt ( logSize ) ; buffer . putInt ( newValueFieldCount ) ; buffer . put ( newOp ) ; buffer . putInt ( newValueSize ) ; writeTuple ( buffer , newValue , newValueSize ) ; < |startfocus| > LOGGER . info ( newValueSize ) ; < |endfocus| > break ; case LogType . FLUSH : buffer . putInt ( datasetId ) ; break ; case LogType . MARKER : buffer . putInt ( datasetId ) ; buffer . putInt ( resourcePartition ) ; callback . before ( buffer ) ; buffer . putInt ( logSize ) ; buffer . put ( marker ) ; break ; default : // Do nothing }
* software distributed under the License is distributed on an * "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . storage . am . common . api ; import org . apache . hyracks . api . exceptions . HyracksDataException ; import org . apache . hyracks . dataflow . common . data . accessors . ITupleReference ; import org . apache . hyracks . storage . common . IModificationOperationCallback ; public interface IExtendedModificationOperationCallback extends < |startfocus| > IModificationOperationCallback { < |endfocus| > /* * * Called after the action taken in found , to take action on a tuple that is not part of the index * itself but is part of an ancillary structure that is updated alongside the index . An example would * be a simple statistic on the index that records the minimum and maximum values . * * @param after The tuple to feed to the ancilliary structure * @throws HyracksDataException */ void after ( ITupleReference after ) throws HyracksDataException ; }
public ILSMIndexAccessor createAccessor ( IIndexAccessParameters iap ) { < |startfocus| > return createAccessor ( createOpContext ( ( ( IExtendedModificationOperationCallback ) iap . getModificationCallback ( ) ) , < |endfocus| > iap . getSearchOperationCallback ( ) ) ) ;
public ILSMIndexAccessor createAccessor ( IIndexAccessParameters iap ) { < |startfocus| > return createAccessor ( createOpContext ( ( ( IExtendedModificationOperationCallback ) ( iap . getModificationCallback ( ) ) ) , < |endfocus| > iap . getSearchOperationCallback ( ) ) ) ;
if ( minTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ; minTupleBytes = new byte [ numBytes ] ; opCallback . after ( tuple ) ; logged = true ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; minTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , minTuple ) ; if ( c < 0 ) { < |startfocus| > if ( logged ) { < |endfocus| > opCallback . after ( tuple ) ; logged = true ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( minTupleBytes . length < numBytes ) { minTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } } if ( maxTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ;
if ( minTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ; minTupleBytes = new byte [ numBytes ] ; opCallback . after ( tuple ) ; logged = true ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; minTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , minTuple ) ; if ( c < 0 ) { < |startfocus| > if ( ! logged ) { < |endfocus| > opCallback . after ( tuple ) ; logged = true ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( minTupleBytes . length < numBytes ) { minTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } } if ( maxTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ;
if ( minTupleBytes . length < numBytes ) { minTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } } if ( maxTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ; maxTupleBytes = new byte [ numBytes ] ; < |startfocus| > if ( ! logged ) { < |endfocus| > opCallback . after ( tuple ) ; logged = true ; } tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; maxTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , maxTuple ) ; if ( c > 0 ) { if ( ! logged ) { opCallback . after ( tuple ) ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( maxTupleBytes . length < numBytes ) {
minTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } } if ( maxTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ; maxTupleBytes = new byte [ numBytes ] ; if ( ! logged ) { opCallback . after ( tuple ) ; < |startfocus| > logged = true ; < |endfocus| > } tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; maxTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , maxTuple ) ; if ( c > 0 ) { if ( ! logged ) { opCallback . after ( tuple ) ; logged = true ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( maxTupleBytes . length < numBytes ) { maxTupleBytes = new byte [ numBytes ] ;
int numBytes = tupleWriter . bytesRequired ( tuple ) ; maxTupleBytes = new byte [ numBytes ] ; if ( ! logged ) { opCallback . after ( tuple ) ; logged = true ; } tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; maxTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , maxTuple ) ; if ( c > 0 ) { < |startfocus| > if ( ! logged ) { < |endfocus| > opCallback . after ( tuple ) ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( maxTupleBytes . length < numBytes ) { maxTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } } } @Override public ITupleReference getMinTuple ( ) { return minTuple ; } @Override
return new LSMInvertedIndexAccessor ( getHarness ( ) , createOpContext ( ( IExtendedModificationOperationCallback ) ( iap . getModificationCallback ( ) ) , iap . getSearchOperationCallback ( ) ) ) ; } @Override protected LSMInvertedIndexOpContext createOpContext ( IExtendedModificationOperationCallback modificationCallback , ISearchOperationCallback searchCallback ) throws HyracksDataException { return new LSMInvertedIndexOpContext ( this , memoryComponents , modificationCallback , searchCallback , invertedIndexFieldsForNonBulkLoadOps , filterFieldsForNonBulkLoadOps , getFilterCmpFactories ( ) , tracer ) ; } < |startfocus| > protected LSMInvertedIndexOpContext createRecoveryOpContext ( IExtendedModificationOperationCallback modificationCallback , ISearchOperationCallback searchCallback ) throws HyracksDataException { return new LSMInvertedIndexOpContext ( this , memoryComponents , modificationCallback , searchCallback , invertedIndexFieldsForNonBulkLoadOps , null , null , tracer ) ; } < |endfocus| > @Override public ITypeTraits [ ] getInvListTypeTraits ( ) { return invListTypeTraits ; } @Override public IBinaryComparatorFactory [ ] getInvListCmpFactories ( ) { return invListCmpFactories ; } @Override public ITypeTraits [ ] getTokenTypeTraits ( ) { return tokenTypeTraits ; } @Override public IBinaryComparatorFactory [ ] getTokenCmpFactories ( ) { return tokenCmpFactories ; }
public ILSMIndexAccessor createAccessor ( IIndexAccessParameters iap ) { < |startfocus| > LSMRTreeOpContext opCtx = createOpContext ( ( ( IExtendedModificationOperationCallback ) iap . getModificationCallback ( ) ) , < |endfocus| > iap . getSearchOperationCallback ( ) ) ; return new LSMTreeIndexAccessor ( getHarness ( ) , opCtx , cursorFactory ) ;
public ILSMIndexAccessor createAccessor ( IIndexAccessParameters iap ) { < |startfocus| > LSMRTreeOpContext opCtx = createOpContext ( ( ( IExtendedModificationOperationCallback ) ( iap . getModificationCallback ( ) ) ) , < |endfocus| > iap . getSearchOperationCallback ( ) ) ; return new LSMTreeIndexAccessor ( getHarness ( ) , opCtx , cursorFactory ) ;
public ILSMIndexAccessor createAccessor ( IIndexAccessParameters iap ) { LSMRTreeOpContext opCtx = < |startfocus| > createOpContext ( ( IExtendedModificationOperationCallback ) iap . getModificationCallback ( ) , iap . getSearchOperationCallback ( ) ) ; < |endfocus| > return new LSMTreeIndexAccessor ( getHarness ( ) , opCtx , cursorFactory ) ;
// may lead to a deadlock scenario between the DatasetLifeCycleManager and the PrimaryIndexOperationTracker . flushAndWaitForIO ( dsInfo , iInfo ) ; } } } private void closeDataset ( DatasetInfo dsInfo ) throws HyracksDataException { // First wait for any ongoing IO operations synchronized ( dsInfo ) { while ( dsInfo . getNumActiveIOOps ( ) > 0 ) { try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { throw new HyracksDataException ( e ) ; } } } try { < |startfocus| > flushDatasetOpenIndexes ( dsInfo , false ) ; < |endfocus| > } catch ( Exception e ) { throw new HyracksDataException ( e ) ; } for ( IndexInfo iInfo : dsInfo . getIndexes ( ) . values ( ) ) { if ( iInfo . isOpen ( ) ) { ILSMOperationTracker opTracker = iInfo . getIndex ( ) . getOperationTracker ( ) ; synchronized ( opTracker ) { iInfo . getIndex ( ) . deactivate ( false ) ; } iInfo . setOpen ( false ) ; } } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException { while ( true ) {
// may lead to a deadlock scenario between the DatasetLifeCycleManager and the PrimaryIndexOperationTracker . flushAndWaitForIO ( dsInfo , iInfo ) ; } } } private void closeDataset ( DatasetInfo dsInfo ) throws HyracksDataException { // First wait for any ongoing IO operations synchronized ( dsInfo ) { while ( dsInfo . getNumActiveIOOps ( ) > 0 ) { try { dsInfo . wait ( ) ; } catch ( InterruptedException e ) { Thread . currentThread ( ) . interrupt ( ) ; throw new HyracksDataException ( e ) ; } } } try { < |startfocus| > flushDatasetOpenIndexes ( dsInfo , false ) ; < |endfocus| > } catch ( Exception e ) { throw new HyracksDataException ( e ) ; } for ( IndexInfo iInfo : dsInfo . getIndexes ( ) . values ( ) ) { if ( iInfo . isOpen ( ) ) { ILSMOperationTracker opTracker = iInfo . getIndex ( ) . getOperationTracker ( ) ; synchronized ( opTracker ) { iInfo . getIndex ( ) . deactivate ( false ) ; } iInfo . setOpen ( false ) ; } } removeDatasetFromCache ( dsInfo . getDatasetID ( ) ) ; dsInfo . setOpen ( false ) ; } @Override public synchronized void closeAllDatasets ( ) throws HyracksDataException {
} catch ( HyracksDataException e ) { datasetLifecycleManager . close ( localResource . getPath ( ) ) ; throw e ; } // # . set resourceId and maxDiskLastLSN to the map resourceId2MaxLSNMap . put ( resourceId , maxDiskLastLsn ) ; } else { maxDiskLastLsn = resourceId2MaxLSNMap . get ( resourceId ) ; } < |startfocus| > // lsn @ maxDiskLastLsn is either a flush log or a master replica log if ( lsn >= maxDiskLastLsn ) { redo ( logRecord , datasetLifecycleManager ) ; redoCount ++ ; } < |endfocus| > } break ; case LogType . JOB_COMMIT : case LogType . ENTITY_COMMIT : case LogType . ABORT : case LogType . FLUSH : case LogType . WAIT : case LogType . MARKER : // do nothing break ; default : throw new ACIDException ( "Unsupported LogType : " + logRecord . getLogType ( ) ) ; } logRecord = logReader . next ( ) ; } LOGGER . info ( "Logs REDO phase completed . Redo logs count : " + redoCount ) ; } finally {
int numBytes = tupleWriter . bytesRequired ( tuple ) ; minTupleBytes = new byte [ numBytes ] ; opCallback . after ( tuple ) ; logged = true ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; minTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , minTuple ) ; if ( c < 0 ) { < |startfocus| > if ( ! logged ) { opCallback . after ( tuple ) ; logged = true ; } < |endfocus| > int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( minTupleBytes . length < numBytes ) { minTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } } if ( maxTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ; maxTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; maxTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , maxTuple ) ; if ( c > 0 ) { if ( ! logged ) { opCallback . after ( tuple ) ; logged = true ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( maxTupleBytes . length < numBytes ) { maxTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } } }
minTupleBytes = new byte [ numBytes ] ; tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; minTupleBuf = ByteBuffer . wrap ( minTupleBytes ) ; } else { tupleWriter . writeTuple ( tuple , minTupleBytes , 0 ) ; } ( ( ITreeIndexTupleReference ) minTuple ) . resetByTupleOffset ( minTupleBuf . array ( ) , 0 ) ; } } if ( maxTuple == null ) { int numBytes = tupleWriter . bytesRequired ( tuple ) ; maxTupleBytes = new byte [ numBytes ] ; if ( ! logged ) { opCallback . after ( tuple ) ; < |startfocus| > logged = true ; < |endfocus| > } tupleWriter . writeTuple ( tuple , maxTupleBytes , 0 ) ; maxTupleBuf = ByteBuffer . wrap ( maxTupleBytes ) ; maxTuple = tupleWriter . createTupleReference ( ) ; ( ( ITreeIndexTupleReference ) maxTuple ) . resetByTupleOffset ( maxTupleBuf . array ( ) , 0 ) ; } else { int c = cmp . compare ( tuple , maxTuple ) ; if ( c > 0 ) { if ( ! logged ) { opCallback . after ( tuple ) ; logged = true ; } int numBytes = tupleWriter . bytesRequired ( tuple ) ; if ( maxTupleBytes . length < numBytes ) { maxTupleBytes = new byte [ numBytes ] ;
return pin ( dpid , newPage , null ) ; } @Override public ICachedPage pin ( long dpid , boolean newPage , ILargePageHelper helper ) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging , since // the synchronized block over the fileInfoMap is a hot spot . if ( DEBUG ) { pinSanityCheck ( dpid ) ; } CachedPage cPage = findPage ( dpid , false ) ; if ( ! newPage ) { if ( DEBUG ) { confiscateLock . lock ( ) ; try { for ( CachedPage c : confiscatedPages ) { if ( c . dpid == dpid && c . confiscated . get ( ) ) { < |startfocus| > while ( confiscatedPages . contains ( c ) ) { throw new IllegalStateException ( ) ; } < |endfocus| > } } } finally { confiscateLock . unlock ( ) ; } } // Resolve race of multiple threads trying to read the page from // disk . synchronized ( cPage ) { if ( ! cPage . valid ) { read ( cPage , helper ) ; cPage . valid = true ; } } } else { cPage . valid = true ; }
return pin ( dpid , newPage , null ) ; } @Override public ICachedPage pin ( long dpid , boolean newPage , ILargePageHelper helper ) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging , since // the synchronized block over the fileInfoMap is a hot spot . if ( DEBUG ) { pinSanityCheck ( dpid ) ; } CachedPage cPage = findPage ( dpid , false ) ; if ( ! newPage ) { if ( DEBUG ) { confiscateLock . lock ( ) ; try { for ( CachedPage c : confiscatedPages ) { if ( c . dpid == dpid && c . confiscated . get ( ) ) { < |startfocus| > while ( confiscatedPages . contains ( c ) ) { throw new IllegalStateException ( ) ; } < |endfocus| > } } } finally { confiscateLock . unlock ( ) ; } } // Resolve race of multiple threads trying to read the page from // disk . synchronized ( cPage ) { if ( ! cPage . valid ) { read ( cPage , helper ) ; cPage . valid = true ; } } } else { cPage . valid = true ; }
return pin ( dpid , newPage , null ) ; } @Override public ICachedPage pin ( long dpid , boolean newPage , ILargePageHelper helper ) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging , since // the synchronized block over the fileInfoMap is a hot spot . if ( DEBUG ) { pinSanityCheck ( dpid ) ; } CachedPage cPage = findPage ( dpid , false ) ; if ( ! newPage ) { if ( DEBUG ) { confiscateLock . lock ( ) ; try { for ( CachedPage c : confiscatedPages ) { if ( c . dpid == dpid && c . confiscated . get ( ) ) { < |startfocus| > while ( confiscatedPages . contains ( c ) ) { throw new IllegalStateException ( ) ; } < |endfocus| > } } } finally { confiscateLock . unlock ( ) ; } } // Resolve race of multiple threads trying to read the page from // disk . synchronized ( cPage ) { if ( ! cPage . valid ) { read ( cPage , helper ) ; cPage . valid = true ; } } } else { cPage . valid = true ; }
return null ; } } ) ; } for ( int i = 0 ; i < bufferCacheNumPages ; i ++ ) { synchronized ( readers [ i ] ) { while ( readers [ i ] . getValue ( ) == null ) { readers [ i ] . wait ( ) ; } } } final long start = System . currentTimeMillis ( ) ; while ( System . currentTimeMillis ( ) - start < duration ) { for ( int i = 0 ; i < bufferCacheNumPages ; i ++ ) { readers [ i ] . getValue ( ) . interrupt ( ) ; } < |startfocus| > Thread . sleep ( 25 ) ; < |endfocus| > } try { for ( int i = 0 ; i < bufferCacheNumPages ; i ++ ) { futures [ i ] . get ( ) ; } } finally { bufferCache . deleteFile ( fileId ) ; bufferCache . close ( ) ; } } @Test public void simpleOpenPinCloseTest ( ) throws HyracksException { TestStorageManagerComponentHolder . init ( PAGE_SIZE , NUM_PAGES , MAX_OPEN_FILES ) ; IBufferCache bufferCache = TestStorageManagerComponentHolder . getBufferCache ( ctx . getJobletContext ( ) . getServiceContext ( ) ) ; IIOManager ioManager = TestStorageManagerComponentHolder . getIOManager ( ) ; String fileName = getFileName ( ) ; FileReference file = ioManager . resolve ( fileName ) ; < |startfocus| > Thread . sleep ( 25 ) ; < |endfocus| >
this . btreePred = ( RangePredicate ) searchPred ; btreeAccessor . search ( btreeCursor , btreePred ) ; openInvListRangeSearchCursor ( ) ; } @Override public boolean hasNext ( ) throws HyracksDataException { // No more results possible if ( ! isInvListCursorOpen ) { return false ; } if ( invListRangeSearchCursor . hasNext ( ) ) { return true ; } // The current inverted - list - range - search cursor is exhausted . < |startfocus| > if ( isInvListCursorOpen ) { invListRangeSearchCursor . close ( ) ; isInvListCursorOpen = false ; } < |endfocus| > openInvListRangeSearchCursor ( ) ; return isInvListCursorOpen ; } @Override public void next ( ) throws HyracksDataException { invListRangeSearchCursor . next ( ) ; if ( concatTuple . hasMaxTuples ( ) ) { concatTuple . removeLastTuple ( ) ; } concatTuple . addTuple ( invListRangeSearchCursor . getTuple ( ) ) ; } @Override public void destroy ( ) throws HyracksDataException { if ( isInvListCursorOpen ) { invListRangeSearchCursor . unloadPages ( ) ; invListRangeSearchCursor . destroy ( ) ; isInvListCursorOpen = false ; } btreeCursor . destroy ( ) ; } @Override public void close ( ) throws HyracksDataException { if ( isInvListCursorOpen ) { invListRangeSearchCursor . close ( ) ; isInvListCursorOpen = false ; } btreeCursor . close ( ) ; } @Override
// Calling the pinSanityCheck should be used only for debugging , since // the synchronized block over the fileInfoMap is a hot spot . if ( DEBUG ) { pinSanityCheck ( dpid ) ; } CachedPage cPage = findPage ( dpid , false ) ; if ( ! newPage ) { if ( DEBUG ) { confiscateLock . lock ( ) ; try { for ( CachedPage c : confiscatedPages ) { if ( c . dpid == dpid && c . confiscated . get ( ) ) { < |startfocus| > while ( confiscatedPages . contains ( c ) ) { throw new IllegalStateException ( ) ; } < |endfocus| > } } } finally { confiscateLock . unlock ( ) ; } } // Resolve race of multiple threads trying to read the page from // disk . synchronized ( cPage ) { if ( ! cPage . valid ) { read ( cPage , helper ) ; cPage . valid = true ; } } } else { cPage . valid = true ; } pageReplacementStrategy . notifyCachePageAccess ( cPage ) ; if ( DEBUG ) { pinnedPageOwner . put ( ( CachedPage ) cPage , Thread . currentThread ( ) . getStackTrace ( ) ) ; } cPage . setLargePageHelper ( helper ) ;
// Calling the pinSanityCheck should be used only for debugging , since // the synchronized block over the fileInfoMap is a hot spot . if ( DEBUG ) { pinSanityCheck ( dpid ) ; } CachedPage cPage = findPage ( dpid , false ) ; if ( ! newPage ) { if ( DEBUG ) { confiscateLock . lock ( ) ; try { for ( CachedPage c : confiscatedPages ) { if ( c . dpid == dpid && c . confiscated . get ( ) ) { < |startfocus| > while ( confiscatedPages . contains ( c ) ) { throw new IllegalStateException ( ) ; } < |endfocus| > } } } finally { confiscateLock . unlock ( ) ; } } // Resolve race of multiple threads trying to read the page from // disk . synchronized ( cPage ) { if ( ! cPage . valid ) { read ( cPage , helper ) ; cPage . valid = true ; } } } else { cPage . valid = true ; } pageReplacementStrategy . notifyCachePageAccess ( cPage ) ; if ( DEBUG ) { pinnedPageOwner . put ( ( CachedPage ) cPage , Thread . currentThread ( ) . getStackTrace ( ) ) ; } cPage . setLargePageHelper ( helper ) ;
// Calling the pinSanityCheck should be used only for debugging , since // the synchronized block over the fileInfoMap is a hot spot . if ( DEBUG ) { pinSanityCheck ( dpid ) ; } CachedPage cPage = findPage ( dpid , false ) ; if ( ! newPage ) { if ( DEBUG ) { confiscateLock . lock ( ) ; try { for ( CachedPage c : confiscatedPages ) { if ( c . dpid == dpid && c . confiscated . get ( ) ) { < |startfocus| > while ( confiscatedPages . contains ( c ) ) { throw new IllegalStateException ( ) ; } < |endfocus| > } } } finally { confiscateLock . unlock ( ) ; } } // Resolve race of multiple threads trying to read the page from // disk . synchronized ( cPage ) { if ( ! cPage . valid ) { read ( cPage , helper ) ; cPage . valid = true ; } } } else { cPage . valid = true ; } pageReplacementStrategy . notifyCachePageAccess ( cPage ) ; if ( DEBUG ) { pinnedPageOwner . put ( ( CachedPage ) cPage , Thread . currentThread ( ) . getStackTrace ( ) ) ; } cPage . setLargePageHelper ( helper ) ;
pageReplacementStrategy . notifyCachePageAccess ( cPage ) ; return cPage ; } cPage = cPage . next ; } } finally { bucket . bucketLock . unlock ( ) ; } return cPage ; } @Override public ICachedPage pin ( long dpid , boolean newPage ) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging , since // the synchronized block over the fileInfoMap is a hot spot . if ( DEBUG ) { pinSanityCheck ( dpid ) ; } < |startfocus| > CachedPage cPage = findPage ( dpid ) ; < |endfocus| > if ( ! newPage ) { if ( DEBUG ) { confiscateLock . lock ( ) ; try { for ( CachedPage c : confiscatedPages ) { if ( c . dpid == dpid && c . confiscated . get ( ) ) { throw new IllegalStateException ( ) ; } } } finally { confiscateLock . unlock ( ) ; } } // Resolve race of multiple threads trying to read the page from // disk . synchronized ( cPage ) { if ( ! cPage . valid ) { read ( cPage ) ; cPage . valid = true ; } } } else { < |startfocus| > CachedPage cPage = findPage ( dpid ) ; < |endfocus| > if ( ! newPage ) { if ( DEBUG ) { confiscateLock . lock ( ) ; try { for ( CachedPage c : confiscatedPages ) { if ( c . dpid == dpid && c . confiscated . get ( ) ) { throw new IllegalStateException ( ) ; } } } finally { confiscateLock . unlock ( ) ; } } // Resolve race of multiple threads trying to read the page from // disk . synchronized ( cPage ) { if ( ! cPage . valid ) { read ( cPage ) ; cPage . valid = true ; } } } else {
pageReplacementStrategy . notifyCachePageAccess ( cPage ) ; return cPage ; } cPage = cPage . next ; } } finally { bucket . bucketLock . unlock ( ) ; } return cPage ; } @Override public ICachedPage pin ( long dpid , boolean newPage ) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging , since // the synchronized block over the fileInfoMap is a hot spot . if ( DEBUG ) { pinSanityCheck ( dpid ) ; } < |startfocus| > CachedPage cPage = findPage ( dpid ) ; < |endfocus| > if ( ! newPage ) { if ( DEBUG ) { confiscateLock . lock ( ) ; try { for ( CachedPage c : confiscatedPages ) { if ( c . dpid == dpid && c . confiscated . get ( ) ) { throw new IllegalStateException ( ) ; } } } finally { confiscateLock . unlock ( ) ; } } // Resolve race of multiple threads trying to read the page from // disk . synchronized ( cPage ) { if ( ! cPage . valid ) { read ( cPage ) ; cPage . valid = true ; } } } else {
package org . apache . hyracks . storage . common ; import java . io . File ; import java . text . SimpleDateFormat ; import java . util . ArrayList ; import java . util . Date ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; import java . util . Random ; import java . util . concurrent .* ; import java . util . concurrent . atomic . AtomicInteger ; import org . apache . commons . lang3 . mutable . Mutable ; import org . apache . commons . lang3 . mutable . MutableObject ; import org . apache . hyracks . api . context . IHyracksTaskContext ; import org . apache . hyracks . api . exceptions . HyracksDataException ; import org . apache . hyracks . api . exceptions . HyracksException ; import org . apache . hyracks . api . io . FileReference ; import org . apache . hyracks . api . io . IIOManager ; import org . apache . hyracks . storage . common . buffercache . CachedPage ; import org . apache . hyracks . storage . common . buffercache . IBufferCache ; import org . apache . hyracks . storage . common . buffercache . ICachedPage ; import org . apache . hyracks . storage . common . file . BufferedFileHandle ;
} this . writer = writer ; } @Override public void setInputRecordDescriptor ( int index , RecordDescriptor recordDescriptor ) { // input is not accessed } @Override public void open ( ) throws HyracksDataException { if ( idx == 0 ) { writer . open ( ) ; } } @Override public void nextFrame ( ByteBuffer buffer ) throws HyracksDataException { writer . nextFrame ( buffer ) ; } @Override public void fail ( ) throws HyracksDataException { < |startfocus| > boolean failed = this . failed . getValue ( ) ; this . failed . setValue ( Boolean . TRUE ) ; < |endfocus| > if ( ! failed ) { writer . fail ( ) ; } } @Override public void close ( ) throws HyracksDataException { if ( idx == 0 ) { writer . close ( ) ; } } } }
int n = subplans . size ( ) ; AlgebricksPipeline [ ] result = new AlgebricksPipeline [ n ] ; for ( int i = 0 ; i < n ; i ++ ) { List < AlgebricksPipeline > subplanOps = subplans . get ( i ) ; if ( subplanOps . size ( ) != 1 ) { throw new AlgebricksException ( "Attempting to construct a nested plan with " + subplanOps . size ( ) < |startfocus| > + " operator descriptors . Currently , nested plans can only consist in linear pipelines of Asterix micro operators . " ) ; < |endfocus| > } result [ i ] = subplanOps . get ( 0 ) ; } return result ; } protected List < List < AlgebricksPipeline > > compileSubplansImpl ( IOperatorSchema outerPlanSchema , AbstractOperatorWithNestedPlans npOp , IOperatorSchema opSchema , JobGenContext context ) throws AlgebricksException { List < List < AlgebricksPipeline > > subplans = new ArrayList < > ( npOp . getNestedPlans ( ) . size ( ) ) ; PlanCompiler pc = new PlanCompiler ( context ) ; for ( ILogicalPlan p : npOp . getNestedPlans ( ) ) { subplans . add ( buildPipelineWithProjection ( p , outerPlanSchema , npOp , opSchema , pc ) ) ; } return subplans ; }
context . getTypeEnvironment ( op . getInputs ( ) . get ( 0 ) . getValue ( ) ) , inputSchemas [ 0 ] , context ) ; IMissingWriterFactory [ ] missingWriterFactories = new IMissingWriterFactory [ np . get ( 0 ) . getOutputWidth ( ) ] ; for ( int i = 0 ; i < missingWriterFactories . length ; i ++ ) { missingWriterFactories [ i ] = context . getMissingWriterFactory ( ) ; } RecordDescriptor recDesc = JobGenHelper . mkRecordDescriptor ( context . getTypeEnvironment ( op ) , opSchema , context ) ; < |startfocus| > SubplanRuntimeFactory runtime = new SubplanRuntimeFactory ( np , missingWriterFactories , inputRecordDesc , recDesc , null ) ; < |endfocus| > builder . contributeMicroOperator ( subplan , runtime , recDesc ) ; ILogicalOperator src = op . getInputs ( ) . get ( 0 ) . getValue ( ) ; builder . contributeGraphEdge ( src , 0 , op , 0 ) ; } @Override public boolean expensiveThanMaterialization ( ) { return true ; } }
< |startfocus| > public void setInputRecordDescriptor ( int index , RecordDescriptor recordDescriptor ) { // TODO : Implement this method } < |endfocus| >
return useConnectorPolicyForScheduling ; } public void setUseConnectorPolicyForScheduling ( boolean useConnectorPolicyForScheduling ) { this . useConnectorPolicyForScheduling = useConnectorPolicyForScheduling ; } public void setRequiredClusterCapacity ( IClusterCapacity capacity ) { this . requiredClusterCapacity = capacity ; } public IClusterCapacity getRequiredClusterCapacity ( ) { return requiredClusterCapacity ; } public void setMetaOps ( List < ? extends IOperatorDescriptor > metaOps ) { this . metaOps = metaOps ; } < |startfocus| > public List < ? extends IOperatorDescriptor > getMetaOps ( ) { < |endfocus| > return metaOps ; } private < K , V > void insertIntoIndexedMap ( Map < K , List < V > > map , K key , int index , V value ) { List < V > vList = map . computeIfAbsent ( key , k - > new ArrayList < > ( ) ) ; extend ( vList , index ) ; vList . set ( index , value ) ; } @Override public String toString ( ) { StringBuilder buffer = new StringBuilder ( ) ; opMap . forEach ( ( key , value ) - > { buffer . append ( key . getId ( ) ) . append ( " : " ) . append ( value . toString ( ) ) . append ( "\n" ) ; }
* * Unless required by applicable law or agreed to in writing , * software distributed under the License is distributed on an * "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . ipc . impl ; import org . apache . hyracks . ipc . api . IIPCEventListener ; public class NoOpIPCEventListener implements IIPCEventListener { < |startfocus| > public static final IIPCEventListener INSTANCE = new NoOpIPCEventListener ( ) ; < |endfocus| > private NoOpIPCEventListener ( ) { } }
return new BloomFilterBuilder ( numElements , numHashes , numBitsPerElement ) ; } public class BloomFilterBuilder implements IIndexBulkLoader { private final long [ ] hashes = BloomFilter . createHashArray ( ) ; private final long numElements ; private final int numHashes ; private final long numBits ; private final int numPages ; private final IFIFOPageQueue queue ; private final ICachedPage [ ] pages ; private ICachedPage metaDataPage = null ; < |startfocus| > public BloomFilterBuilder ( long numElements , int numHashes , int numBitsPerElement ) throws HyracksDataException { < |endfocus| > if ( ! isActivated ) { throw HyracksDataException . create ( ErrorCode . CANNOT_CREATE_BLOOM_FILTER_BUILDER_FOR_INACTIVE_FILTER ) ; } queue = bufferCache . createFIFOQueue ( ) ; this . numElements = numElements ; this . numHashes = numHashes ; numBits = this . numElements * numBitsPerElement ; long tmp = ( long ) Math . ceil ( numBits / ( double ) numBitsPerPage ) ; if ( tmp > Integer . MAX_VALUE ) { throw HyracksDataException . create ( ErrorCode . CANNOT_CREATE_BLOOM_FILTER_WITH_NUMBER_OF_PAGES , tmp ) ; } numPages = ( int ) tmp ; pages = new ICachedPage [ numPages ] ;
import org . apache . hyracks . tests . util . NoOpOperatorDescriptor ; import org . junit . Assert ; import org . junit . Test ; public class JobFailureTest extends AbstractMultiNCIntegrationTest { @Test public void failureOnCreatePushRuntime ( ) throws Exception { JobId jobId = null ; for ( int i = 0 ; i < 20 ; i ++ ) { JobSpecification spec = new JobSpecification ( ) ; < |startfocus| > JobId runJobId = runTest ( spec , new ExceptionOnCreatePushRuntimeOperatorDescriptor ( spec , 0 , 1 , new int [ ] { 4 } , true ) ) ; < |endfocus| > if ( i == 0 ) { jobId = runJobId ; // passes . read from job archive waitForCompletion ( jobId , ExceptionOnCreatePushRuntimeOperatorDescriptor . ERROR_MESSAGE ) ; } } // passes . read from job history waitForCompletion ( jobId , ExceptionOnCreatePushRuntimeOperatorDescriptor . ERROR_MESSAGE ) ; for ( int i = 0 ; i < 300 ; i ++ ) { JobSpecification spec = new JobSpecification ( ) ; runTest ( spec , new ExceptionOnCreatePushRuntimeOperatorDescriptor ( spec , 0 , 1 , new int [ ] { 4 } , true ) ) ; } // passes . history has been cleared
* software distributed under the License is distributed on an * "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . asterix . api . http . server ; import java . util . Map ; import java . util . UUID ; import java . util . concurrent . ConcurrentMap ; import java . util . concurrent . TimeUnit ; import java . util . concurrent . TimeoutException ; import java . util . function . Function ; < |startfocus| > import javax . xml . transform . Result ; < |endfocus| > import org . apache . asterix . algebra . base . ILangExtension ; import org . apache . asterix . app . message . CancelQueryRequest ; import org . apache . asterix . app . message . ExecuteStatementRequestMessage ; import org . apache . asterix . app . message . ExecuteStatementResponseMessage ; import org . apache . asterix . app . result . ResultReader ; import org . apache . asterix . common . api . Duration ; import org . apache . asterix . common . api . IApplicationContext ; import org . apache . asterix . common . config . GlobalConfig ; import org . apache . asterix . common . exceptions . ErrorCode ; import org . apache . asterix . common . exceptions . ExceptionUtils ; import org . apache . asterix . common . exceptions . RuntimeDataException ; import org . apache . asterix . common . messaging . api . INCMessageBroker ;
channel . abort ( ) ; } finally { channel . close ( ) ; resultState . readClose ( ) ; // if resultState has been exhausted , delete the result partition if ( resultState . isExhausted ( ) ) { datasetPartitionManager . removePartition ( resultState . getResultSetPartitionId ( ) . getJobId ( ) , resultState . getResultSetPartitionId ( ) . getResultSetId ( ) , resultState . getResultSetPartitionId ( ) . getPartition ( ) ) ; } } } catch ( HyracksDataException e ) { LOGGER . error ( "unexpected failure in partition reader" , e ) ; } < |startfocus| > if ( LOGGER . isInfoEnabled ( ) ) { LOGGER . info ( "result reading successful ( " + resultState . getResultSetPartitionId ( ) + " ) " ) ; } < |endfocus| >
* specific language governing permissions and limitations * under the License . */ package org . apache . asterix . translator ; import java . util . Map ; import org . apache . asterix . translator . IStatementExecutor . Stats ; import org . apache . hyracks . api . dataset . IHyracksDataset ; public interface IRequestParameters { /* * * @return A Hyracks dataset client object that is used to read the results . */ IHyracksDataset getHyracksDataset ( ) ; /* * < |startfocus| > * @return The { @code ResultDelivery } kind required for queries in the list of statements < |endfocus| > */ ResultProperties getResultProperties ( ) ; /* * * @return a reference to write the stats of executed queries */ Stats getStats ( ) ; /* * * @return a reference to write the metadata of executed queries */ IStatementExecutor . ResultMetadata getOutMetadata ( ) ; /* * * @return the client context id for the query */ String getClientContextId ( ) ; /* * * @return Optional request parameters . Otherwise null . */ Map < String , String > getOptionalParameters ( ) ; }
* "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . storage . am . common . api ; import org . apache . hyracks . dataflow . common . data . accessors . ITupleReference ; import org . apache . hyracks . storage . common . IIndexCursor ; public interface ILSMIndexCursor extends IIndexCursor { /* * < |startfocus| > * @return the min tuple of the current component's filter < |endfocus| > */ ITupleReference getFilterMinTuple ( ) ; /* * * * @return the max tuple of the current component's filter */ ITupleReference getFilterMaxTuple ( ) ; }
* * Unless required by applicable law or agreed to in writing , * software distributed under the License is distributed on an * "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . storage . am . common . api ; import org . apache . hyracks . dataflow . common . data . accessors . ITupleReference ; import org . apache . hyracks . storage . common . IIndexCursor ; < |startfocus| > public interface ILSMIndexCursor extends IIndexCursor { < |endfocus| > /* * * @return the min tuple of the current index's filter */ ITupleReference getFilterMinTuple ( ) ; /* * * * @return the max tuple of the current index's filter */ ITupleReference getFilterMaxTuple ( ) ; }
AbstractLogicalOperator op2 = ( AbstractLogicalOperator ) opRef2 . getValue ( ) ; // If it's not an indexed field , it is pushed so that scan can be // rewritten into index search . if ( op2 . getOperatorTag ( ) == LogicalOperatorTag . PROJECT || context . checkAndAddToAlreadyCompared ( access , op2 ) && ! ( op2 . getOperatorTag ( ) == LogicalOperatorTag . SELECT && isAccessToIndexedField ( access , context ) ) ) { return false ; } < |startfocus| > Object annotation = op2 . getAnnotations ( ) . get ( OperatorPropertiesUtil . MOVABLE ) ; < |endfocus| > if ( annotation != null && ! ( ( Boolean ) annotation ) ) { return false ; } if ( tryingToPushThroughSelectionWithSameDataSource ( access , op2 ) ) { return false ; } if ( testAndModifyRedundantOp ( access , op2 ) ) { propagateFieldAccessRec ( opRef2 , context , finalAnnot ) ; return true ; } List < LogicalVariable > usedInAccess = new LinkedList < > ( ) ; VariableUtilities . getUsedVariables ( access , usedInAccess ) ; List < LogicalVariable > produced2 = new LinkedList < > ( ) ; if ( op2 . getOperatorTag ( ) == LogicalOperatorTag . GROUP ) { VariableUtilities . getLiveVariables ( op2 , produced2 ) ;
import org . apache . hyracks . algebricks . common . exceptions . AlgebricksException ; import org . apache . hyracks . algebricks . core . algebra . base . ILogicalExpression ; import org . apache . hyracks . algebricks . core . algebra . base . ILogicalOperator ; import org . apache . hyracks . algebricks . core . algebra . base . LogicalVariable ; import org . apache . hyracks . algebricks . core . algebra . properties . VariablePropagationPolicy ; import org . apache . hyracks . algebricks . core . algebra . visitors . ILogicalExpressionReferenceTransform ; public abstract class AbstractBinaryJoinOperator extends AbstractLogicalOperator { protected final Mutable < ILogicalExpression > condition ; protected JoinKind joinKind ; < |startfocus| > @Override public Map < Integer , Integer > getPhaseToInput ( ) { return phaseToInput ; } protected Map < Integer , Integer > phaseToInput ; < |endfocus| > public enum JoinKind { INNER , LEFT_OUTER } public AbstractBinaryJoinOperator ( JoinKind joinKind , Mutable < ILogicalExpression > condition ) { this . joinKind = joinKind ; this . condition = condition ; this . phaseToInput = new HashMap < > ( ) ; phaseToInput . put ( 0 , 1 ) ; phaseToInput . put ( 1 , 0 ) ; } public AbstractBinaryJoinOperator ( JoinKind joinKind , Mutable < ILogicalExpression > condition , Mutable < ILogicalOperator > input1 , Mutable < ILogicalOperator > input2 ) { this ( joinKind , condition ) ;
import org . apache . hyracks . algebricks . core . algebra . base . ILogicalExpression ; import org . apache . hyracks . algebricks . core . algebra . base . ILogicalOperator ; import org . apache . hyracks . algebricks . core . algebra . base . LogicalVariable ; import org . apache . hyracks . algebricks . core . algebra . properties . VariablePropagationPolicy ; import org . apache . hyracks . algebricks . core . algebra . visitors . ILogicalExpressionReferenceTransform ; public abstract class AbstractBinaryJoinOperator extends AbstractLogicalOperator { protected final Mutable < ILogicalExpression > condition ; protected JoinKind joinKind ; < |startfocus| > public Map < Integer , Integer > getPhaseToInput ( ) { return phaseToInput ; } protected Map < Integer , Integer > phaseToInput ; < |endfocus| > public enum JoinKind { INNER , LEFT_OUTER } public AbstractBinaryJoinOperator ( JoinKind joinKind , Mutable < ILogicalExpression > condition ) { this . joinKind = joinKind ; this . condition = condition ; this . phaseToInput = new HashMap < > ( ) ; phaseToInput . put ( 0 , 1 ) ; phaseToInput . put ( 1 , 0 ) ; } public AbstractBinaryJoinOperator ( JoinKind joinKind , Mutable < ILogicalExpression > condition , Mutable < ILogicalOperator > input1 , Mutable < ILogicalOperator > input2 ) { this ( joinKind , condition ) ; inputs . add ( input1 ) ; inputs . add ( input2 ) ; } public Map < Integer , Integer > getPhaseToInput ( ) { return phaseToInput ; }
if ( connection != null ) { inp . put ( "input" , connection . getLeft ( ) . getLeft ( ) . getOperatorId ( ) . toString ( ) ) ; } } } if ( pleObject . size ( ) > 0 ) { pcObject . set ( "location" , pleObject ) ; } if ( pcObject . size ( ) > 0 ) { op . set ( "partition - constraints" , pcObject ) ; } < |startfocus| > if ( inp . size ( ) > 0 ) { op . set ( "inputs" , inp ) ; } < |endfocus| > } jopArray . add ( op ) ; } ) ; jjob . set ( "operators" , jopArray ) ; ArrayNode jcArray = om . createArrayNode ( ) ; connMap . forEach ( ( key , value ) - > { ObjectNode conn = om . createObjectNode ( ) ; Pair < Pair < IOperatorDescriptor , Integer > , Pair < IOperatorDescriptor , Integer > > connection = connectorOpMap . get ( key ) ; if ( connection != null ) { conn . put ( "in - operator - id" , connection . getLeft ( ) . getLeft ( ) . getOperatorId ( ) . toString ( ) ) ; conn . put ( "in - operator - port" , connection . getLeft ( ) . getRight ( ) . intValue ( ) ) ;
} } return false ; } /* * * Executes the passed interruptible , retrying if the operation fails due to { @link ClosedByInterruptException } . * Once the interruptible completes , the current thread will be re - interrupted , if the original operation was * interrupted . */ public static void doIoUninterruptibly ( ThrowingIOInterruptible interruptible ) throws IOException { boolean interrupted = false ; try { while ( true ) { try { interruptible . run ( ) ; break ; < |startfocus| > } catch ( ClosedByInterruptException e ) { < |endfocus| > LOGGER . error ( "IO operation Interrupted . Retrying . . " , e ) ; interrupted = true ; Thread . interrupted ( ) ; } } } finally { if ( interrupted ) { Thread . currentThread ( ) . interrupt ( ) ; } } } @FunctionalInterface public interface Interruptible { void run ( ) throws InterruptedException ; } @FunctionalInterface public interface ThrowingInterruptible { void run ( ) throws Exception ; // NOSONAR } @FunctionalInterface public interface ThrowingIOInterruptible { void run ( ) throws IOException ; } }
public class Interruptible { private static final Logger LOGGER = LoggerFactory . getLogger ( Interruptible . class ) ; private Interruptible ( ) { } public static void run ( Interruptible interruptible ) { run ( interruptible : : run ) ; } public static void run ( ThrowingInterruptible interruptible ) { run ( ( ) - > { try { interruptible . run ( ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } } ) ; } public static void run ( ThrowingIOInterruptible interruptible ) { run ( ( ) - > { try { interruptible . run ( ) ; } catch ( IOException e ) { throw new UncheckedIOException ( e ) ; } } ) ; } private static void run ( Runnable interruptible ) { boolean interrupted = false ; try { while ( true ) { try { interruptible . run ( ) ; return ; } catch ( InterruptedException e ) { LOGGER . error ( "Interrupted . Retrying . . " , e ) ; interrupted = true ; Thread . interrupted ( ) ; } } } finally { if ( interrupted ) { Thread . currentThread ( ) . interrupt ( ) ; } } } @FunctionalInterface public interface Interruptible { void run ( ) throws InterruptedException ; } @FunctionalInterface public interface ThrowingInterruptible { void run ( ) throws Exception ; // NOSONAR } @FunctionalInterface public interface ThrowingIOInterruptible { < |startfocus| > void run ( ) throws IOException ; < |endfocus| > } }
if ( LOGGER . isLoggable ( Level . INFO ) ) { LOGGER . info ( "Substitute node joining : " + serviceContext . getNodeId ( ) ) ; } updateOnNodeJoin ( ) ; } appContext . initialize ( initialRun ) ; MessagingProperties messagingProperties = ( ( IPropertiesProvider ) appContext ) . getMessagingProperties ( ) ; messageBroker = new NCMessageBroker ( controllerService , messagingProperties ) ; serviceContext . setMessageBroker ( messageBroker ) ; MessagingChannelInterfaceFactory interfaceFactory = new MessagingChannelInterfaceFactory ( ( NCMessageBroker ) messageBroker , messagingProperties ) ; < |startfocus| > serviceContext . setMessagingChannelInterfaceFactory ( interfaceFactory ) ; < |endfocus| > boolean replicationEnabled = ClusterProperties . INSTANCE . isReplicationEnabled ( ) ; boolean autoFailover = ClusterProperties . INSTANCE . isAutoFailoverEnabled ( ) ; if ( initialRun ) { LOGGER . info ( "System is being initialized . ( first run ) " ) ; } else { IRecoveryManager recoveryMgr = appContext . getTransactionSubsystem ( ) . getRecoveryManager ( ) ; systemState = recoveryMgr . getSystemState ( ) ; if ( LOGGER . isLoggable ( Level . INFO ) ) { LOGGER . info ( "System is in a state : " + systemState ) ; } // do not attempt to perform remote recovery if this is a virtual NC if ( autoFailover && ! virtualNC ) {
if ( LOGGER . isLoggable ( Level . INFO ) ) { LOGGER . info ( "Substitute node joining : " + serviceContext . getNodeId ( ) ) ; } updateOnNodeJoin ( ) ; } appContext . initialize ( initialRun ) ; MessagingProperties messagingProperties = ( ( IPropertiesProvider ) appContext ) . getMessagingProperties ( ) ; messageBroker = new NCMessageBroker ( controllerService , messagingProperties ) ; serviceContext . setMessageBroker ( messageBroker ) ; MessagingChannelInterfaceFactory interfaceFactory = new MessagingChannelInterfaceFactory ( ( NCMessageBroker ) messageBroker , messagingProperties ) ; < |startfocus| > serviceContext . setMessagingChannelInterfaceFactory ( interfaceFactory ) ; < |endfocus| > boolean replicationEnabled = ClusterProperties . INSTANCE . isReplicationEnabled ( ) ; boolean autoFailover = ClusterProperties . INSTANCE . isAutoFailoverEnabled ( ) ; if ( initialRun ) { LOGGER . info ( "System is being initialized . ( first run ) " ) ; } else { IRecoveryManager recoveryMgr = appContext . getTransactionSubsystem ( ) . getRecoveryManager ( ) ; systemState = recoveryMgr . getSystemState ( ) ; if ( LOGGER . isLoggable ( Level . INFO ) ) { LOGGER . info ( "System is in a state : " + systemState ) ; } // do not attempt to perform remote recovery if this is a virtual NC if ( autoFailover && ! virtualNC ) {
int n = subplans . size ( ) ; AlgebricksPipeline [ ] result = new AlgebricksPipeline [ n ] ; for ( int i = 0 ; i < n ; i ++ ) { List < AlgebricksPipeline > subplanOps = subplans . get ( i ) ; if ( subplanOps . size ( ) != 1 ) { throw new AlgebricksException ( "Attempting to construct a nested plan with " + subplanOps . size ( ) + " operator descriptors . Currently , nested plans can only consist in linear pipelines of " < |startfocus| > + "micro operators . " ) ; < |endfocus| > } result [ i ] = subplanOps . get ( 0 ) ; } return result ; } protected List < List < AlgebricksPipeline > > compileSubplansImpl ( IOperatorSchema outerPlanSchema , AbstractOperatorWithNestedPlans npOp , IOperatorSchema opSchema , JobGenContext context ) throws AlgebricksException { List < List < AlgebricksPipeline > > subplans = new ArrayList < > ( npOp . getNestedPlans ( ) . size ( ) ) ; PlanCompiler pc = new PlanCompiler ( context ) ; for ( ILogicalPlan p : npOp . getNestedPlans ( ) ) { subplans . add ( buildPipelineWithProjection ( p , outerPlanSchema , npOp , opSchema , pc ) ) ; } return subplans ; }
opSchema . addAllVariables ( topOpInSubplanScm ) ; Map < OperatorDescriptorId , IOperatorDescriptor > opMap = nestedJob . getOperatorMap ( ) ; List < ? extends IOperatorDescriptor > metaOps = nestedJob . getMetaOps ( ) ; if ( opMap . size ( ) != metaOps . size ( ) ) { for ( IOperatorDescriptor opd : opMap . values ( ) ) { if ( ! ( opd instanceof AlgebricksMetaOperatorDescriptor ) ) { throw new AlgebricksException ( < |startfocus| > "Can only generate Hyracks jobs for pipelinable nested plans , not for " + opd < |endfocus| > . getClass ( ) . getName ( ) ) ; } } throw new IllegalStateException ( ) ; } List < AlgebricksPipeline > result = new ArrayList < > ( metaOps . size ( ) ) ; for ( IOperatorDescriptor opd : metaOps ) { AlgebricksMetaOperatorDescriptor amod = ( AlgebricksMetaOperatorDescriptor ) opd ; result . add ( amod . getPipeline ( ) ) ; } return result ; } }
Map < OperatorDescriptorId , IOperatorDescriptor > opMap = nestedJob . getOperatorMap ( ) ; List < ? extends IOperatorDescriptor > metaOps = nestedJob . getMetaOps ( ) ; if ( opMap . size ( ) != metaOps . size ( ) ) { for ( IOperatorDescriptor opd : opMap . values ( ) ) { if ( ! ( opd instanceof AlgebricksMetaOperatorDescriptor ) ) { throw new AlgebricksException ( "Can only generate Hyracks jobs for pipelinable Asterix nested plans , not for " + opd . getClass ( ) . getName ( ) ) ; } } throw new IllegalStateException ( "The number of meta operators does not match the number of operator descriptors . " ) ; } List < AlgebricksPipeline > result = new ArrayList < > ( metaOps . size ( ) ) ; for ( IOperatorDescriptor opd : metaOps ) { AlgebricksMetaOperatorDescriptor amod = ( AlgebricksMetaOperatorDescriptor ) opd ; result . add ( amod . getPipeline ( ) ) ; } return result ; } }
return true ; } @Override public void contributeRuntimeOperator ( IHyracksJobBuilder builder , JobGenContext context , ILogicalOperator op , IOperatorSchema opSchema , IOperatorSchema [ ] inputSchemas , IOperatorSchema outerPlanSchema ) throws AlgebricksException { RecordDescriptor recordDescriptor = JobGenHelper . mkRecordDescriptor ( context . getTypeEnvironment ( op ) , opSchema , context ) ; List < Mutable < ILogicalOperator > > inputs = op . getInputs ( ) ; int nInputs = inputs . size ( ) ; MicroUnionAllRuntimeFactory runtime = new MicroUnionAllRuntimeFactory ( nInputs ) ; builder . contributeMicroOperator ( op , runtime , recordDescriptor ) ; < |startfocus| > for ( int i = 0 ; i < nInputs ; i ++ ) { ILogicalOperator src = inputs . get ( i ) . getValue ( ) ; builder . contributeGraphEdge ( src , 0 , op , i ) ; } < |endfocus| > } }
RecordDescriptor pipelineLastRecordDescriptor = pipeline . getRecordDescriptors ( ) [ pipeline . getRecordDescriptors ( ) . length - 1 ] ; RecordDescriptor outputRecordDescriptor ; IFrameWriter outputWriter ; if ( i == 0 ) { // primary pipeline outputWriter = new TupleOuterProduct ( pipelineLastRecordDescriptor , missingWriters ) ; outputRecordDescriptor = SubplanRuntimeFactory . this . outputRecordDesc ; } else { // secondary pipeline IPushRuntime outputPushRuntime = linkSecondaryPipeline ( pipeline , pipelineAssemblers , i ) ; if ( outputPushRuntime == null ) { < |startfocus| > throw new IllegalStateException ( ) ; < |endfocus| > } outputPushRuntime . setInputRecordDescriptor ( 0 , pipelineLastRecordDescriptor ) ; outputWriter = outputPushRuntime ; outputRecordDescriptor = pipelineLastRecordDescriptor ; } PipelineAssembler pa = new PipelineAssembler ( pipeline , 1 , 1 , inputRecordDesc , outputRecordDescriptor ) ; startOfPipelines [ i ] = ( NestedTupleSourceRuntime ) pa . assemblePipeline ( outputWriter , ctx ) ; pipelineAssemblers [ i ] = pa ; } } IPushRuntime linkSecondaryPipeline ( AlgebricksPipeline pipeline , PipelineAssembler [ ] pipelineAssemblers , int pipelineAssemblersCount ) { IPushRuntimeFactory [ ] outputRuntimeFactories = pipeline . getOutputRuntimeFactories ( ) ; < |startfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ; }
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } < |startfocus| > if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ; }
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; int n2 = n ; if ( n2 > 0xffff ) { n2 > > >= 16 ; log = 16 ; } < |startfocus| > if ( n2 > 0xff ) { n2 > > >= 8 ; log| = 8 ; } < |endfocus| > if ( n2 > 0xf ) { n2 > > >= 4 ; log| = 4 ; } if ( n2 > 0b11 ) { n2 > > >= 2 ; log| = 2 ; } return log + ( n2 > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |startfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |endfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |startfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |endfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |startfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |endfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |startfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |endfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |startfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |endfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |startfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |endfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ; }
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |startfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |endfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } < |startfocus| > if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } < |endfocus| > if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } < |startfocus| > if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } < |endfocus| > if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |startfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |endfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ; }
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } < |startfocus| > if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |endfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } return log + ( n > > > 1 ) ; }
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |startfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |endfocus| > return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |startfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |endfocus| > return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |startfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |endfocus| > return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |startfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |endfocus| > return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |startfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |endfocus| > return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |startfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |endfocus| > return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |startfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |endfocus| > return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } < |startfocus| > if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } < |endfocus| > return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } < |startfocus| > if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } < |endfocus| > return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } < |startfocus| > if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |endfocus| > return log + ( n > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; int m = n ; if ( m > 0xffff ) { m > > >= 16 ; log = 16 ; } if ( m > 0xff ) { m > > >= 8 ; log| = 8 ; } if ( m > 0xf ) { m > > >= 4 ; log| = 4 ; } < |startfocus| > if ( m > 0b11 ) { m > > >= 2 ; log| = 2 ; } < |endfocus| > return log + ( m > > > 1 ) ;
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log | = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log | = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log | = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |startfocus| > int m = n ; return log + ( m > > > 1 ) ; < |endfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
public static int log2Floor ( int n ) { assert n >= 1 ; int log = 0 ; if ( n > 0xffff ) { n > > >= 16 ; log = 16 ; } if ( n > 0xff ) { n > > >= 8 ; log| = 8 ; } if ( n > 0xf ) { n > > >= 4 ; log| = 4 ; } if ( n > 0b11 ) { n > > >= 2 ; log| = 2 ; } < |startfocus| > return log + ( n > > > 1 ) ; < |endfocus| >
public Ini toIni ( boolean includeDefaults ) { Ini ini = new Ini ( ) ; ( includeDefaults ? configurationMap : definedMap ) . forEach ( ( option , value ) - > { if ( value != null ) { ini . add ( option . section ( ) . sectionName ( ) , option . ini ( ) , option . type ( ) . serializeToIni ( value ) ) ; } } ) ; < |startfocus| > getSections ( ) . forEach ( section - > { ini . add ( section . sectionName ( ) ) ; } ) ; < |endfocus| > nodeSpecificMap . forEach ( ( key , nodeValueMap ) - > { String section = Section . NC . sectionName ( ) + " / " + key ; synchronized ( nodeValueMap ) { for ( Map . Entry < IOption , Object > entry : nodeValueMap . entrySet ( ) ) { if ( entry . getValue ( ) != null ) { final IOption option = entry . getKey ( ) ; ini . add ( section , option . ini ( ) , option . type ( ) . serializeToIni ( entry . getValue ( ) ) ) ; } } } } ) ; extensionOptions . forEach ( ( extension , options ) - > { options . forEach ( option - > ini . add ( extension , option . getKey ( ) , option . getValue ( ) ) ) ; } ) ; return ini ;
public void sendApplicationMessageToCC ( byte [ ] data , DeploymentId deploymentId , String nodeId ) throws Exception ; public void registerResultPartitionLocation ( JobId jobId , ResultSetId rsId , boolean orderedResult , boolean emptyResult , int partition , int nPartitions , NetworkAddress networkAddress ) throws Exception ; public void reportResultPartitionWriteCompletion ( JobId jobId , ResultSetId rsId , int partition ) throws Exception ; public void reportResultPartitionFailure ( JobId jobId , ResultSetId rsId , int partition , HyracksDataException cause ) throws Exception ; public void getNodeControllerInfos ( ) throws Exception ; < |startfocus| > public void notifyThreadDump ( String nodeId , String requestId , String threadDumpJSON ) throws Exception ; < |endfocus| > }
public void distributeJob ( JobId jobId , byte [ ] planBytes ) throws Exception ; public void destroyJob ( JobId jobId ) throws Exception ; < |endfocus| > public void dumpState ( String stateDumpId ) throws Exception ; public void shutdown ( boolean terminateNCService ) throws Exception ; public void sendApplicationMessageToNC ( byte [ ] data , DeploymentId deploymentId , String nodeId ) throws Exception ; public void takeThreadDump ( String requestId ) throws Exception ; }
throws HyracksDataException { this . ctx = ctx ; this . treeIndexHelper = indexHelperFactory . create ( ctx . getJobletContext ( ) . getServiceContext ( ) , partition ) ; this . searchCallbackFactory = searchCallbackFactory ; } @Override public void initialize ( ) throws HyracksDataException { treeIndexHelper . open ( ) ; try { try { writer . open ( ) ; FrameTupleAppender appender = new FrameTupleAppender ( new VSizeFrame ( ctx ) ) ; scan ( appender ) ; appender . write ( writer , true ) ; } catch ( Throwable th ) { writer . fail ( ) ; < |startfocus| > throw HyracksDataException . create ( th ) ; } finally { < |endfocus| > writer . close ( ) ; } } catch ( Exception th ) { throw HyracksDataException . create ( th ) ; } } private void scan ( FrameTupleAppender appender ) throws IOException { ITreeIndex treeIndex = ( ITreeIndex ) treeIndexHelper . getIndexInstance ( ) ; LocalResource resource = treeIndexHelper . getResource ( ) ; ISearchOperationCallback searchCallback = searchCallbackFactory . createSearchOperationCallback ( resource . getId ( ) , ctx , null ) ; IIndexAccessParameters iap = new IndexAccessParameters ( NoOpOperationCallback . INSTANCE , searchCallback ) ; ITreeIndexAccessor indexAccessor = ( ITreeIndexAccessor ) treeIndex . createAccessor ( iap ) ; try {
this . searchCallbackFactory = searchCallbackFactory ; } @Override public void initialize ( ) throws HyracksDataException { treeIndexHelper . open ( ) ; try { try { writer . open ( ) ; FrameTupleAppender appender = new FrameTupleAppender ( new VSizeFrame ( ctx ) ) ; scan ( appender ) ; appender . write ( writer , true ) ; } catch ( Throwable th ) { writer . fail ( ) ; throw HyracksDataException . create ( th ) ; } finally { writer . close ( ) ; } < |startfocus| > } catch ( Exception e ) { throw HyracksDataException . create ( e ) ; < |endfocus| > } } private void scan ( FrameTupleAppender appender ) throws IOException { ITreeIndex treeIndex = ( ITreeIndex ) treeIndexHelper . getIndexInstance ( ) ; LocalResource resource = treeIndexHelper . getResource ( ) ; ISearchOperationCallback searchCallback = searchCallbackFactory . createSearchOperationCallback ( resource . getId ( ) , ctx , null ) ; IIndexAccessParameters iap = new IndexAccessParameters ( NoOpOperationCallback . INSTANCE , searchCallback ) ; ITreeIndexAccessor indexAccessor = ( ITreeIndexAccessor ) treeIndex . createAccessor ( iap ) ; try { doScan ( treeIndex , indexAccessor , appender ) ; } finally { indexAccessor . destroy ( ) ; } }
for ( int i = 0 ; i < mergeOp . getMergingComponents ( ) . size ( ) ; ++ i ) { filterTuples . add ( mergeOp . getMergingComponents ( ) . get ( i ) . getLSMComponentFilter ( ) . getMinTuple ( ) ) ; filterTuples . add ( mergeOp . getMergingComponents ( ) . get ( i ) . getLSMComponentFilter ( ) . getMaxTuple ( ) ) ; } getFilterManager ( ) . updateFilter ( mergedComponent . getLSMComponentFilter ( ) , filterTuples ) ; getFilterManager ( ) . writeFilter ( mergedComponent . getLSMComponentFilter ( ) , mergedComponent . getMetadataHolder ( ) ) ; } componentBulkLoader . end ( ) ; return mergedComponent ; } @Override public ILSMIndexAccessor createAccessor ( IIndexAccessParameters iap ) { < |startfocus| > return new LSMRTreeAccessor ( getLsmHarness ( ) , < |endfocus| > createOpContext ( iap . getModificationCallback ( ) , iap . getSearchOperationCallback ( ) ) , buddyBTreeFields ) ; } // This function is modified for R - Trees without antimatter tuples to allow buddy B - Tree to have only primary keys @Override public void modify ( IIndexOperationContext ictx , ITupleReference tuple ) throws HyracksDataException { LSMRTreeOpContext ctx = ( LSMRTreeOpContext ) ictx ; if ( ctx . getOperation ( ) == IndexOperation . PHYSICALDELETE ) { if ( ctx . getOperation ( ) == IndexOperation . PHYSICALDELETE ) {
public void resetNonIndexFieldsTuple ( ITupleReference newValue ) { tupleWithNonIndexFields . reset ( newValue ) ; } @Override public void destroy ( ) throws HyracksDataException { if ( destroyed ) { return ; } destroyed = true ; HyracksDataException failure = null ; try { accessor . destroy ( ) ; } catch ( HyracksDataException e ) { failure = e ; } finally { try { if ( cursor != null ) { cursor . destroy ( ) ; } } catch ( Exception e ) { throw HyracksDataException . suppress ( failure , e ) ; } } } }
public void resetNonIndexFieldsTuple ( ITupleReference newValue ) { tupleWithNonIndexFields . reset ( newValue ) ; } @Override public void destroy ( ) throws HyracksDataException { if ( destroyed ) { return ; } destroyed = true ; HyracksDataException failure = null ; try { accessor . destroy ( ) ; } catch ( HyracksDataException e ) { failure = e ; } finally { try { if ( cursor != null ) { cursor . destroy ( ) ; } } catch ( Exception e ) { throw HyracksDataException . suppress ( failure , e ) ; } < |startfocus| > } < |endfocus| > } }
builder . addField ( diskTuple . getFieldData ( i ) , diskTuple . getFieldStart ( i ) , diskTuple . getFieldLength ( i ) ) ; } } @Override public ITupleReference doGetTuple ( ) { return outputTuple ; } @Override public void doDestroy ( ) throws HyracksDataException { Throwable failure = null ; if ( lsmHarness != null ) { if ( rangeCursors != null ) { for ( int i = 0 ; i < rangeCursors . length ; i ++ ) { try { rangeCursors [ i ] . destroy ( ) ; < |startfocus| > } catch ( Exception th ) { < |endfocus| > failure = ExceptionUtils . suppress ( failure , th ) ; } } rangeCursors = null ; } try { lsmHarness . endScanDiskComponents ( opCtx ) ; } catch ( Exception th ) { failure = ExceptionUtils . suppress ( failure , th ) ; } } foundNext = false ; if ( failure != null ) { throw HyracksDataException . create ( failure ) ; } } @Override protected void setPriorityQueueComparator ( ) { if ( pqCmp == null || cmp != pqCmp . getMultiComparator ( ) ) { pqCmp = new PriorityQueueScanComparator ( cmp ) ; } }
} @Override public void doDestroy ( ) throws HyracksDataException { Throwable failure = null ; if ( lsmHarness != null ) { if ( rangeCursors != null ) { for ( int i = 0 ; i < rangeCursors . length ; i ++ ) { try { rangeCursors [ i ] . destroy ( ) ; } catch ( Throwable th ) { failure = ExceptionUtils . suppress ( failure , th ) ; } } rangeCursors = null ; } try { lsmHarness . endScanDiskComponents ( opCtx ) ; < |startfocus| > } catch ( Exception th ) { < |endfocus| > failure = ExceptionUtils . suppress ( failure , th ) ; } } foundNext = false ; if ( failure != null ) { throw HyracksDataException . create ( failure ) ; } } @Override protected void setPriorityQueueComparator ( ) { if ( pqCmp == null || cmp != pqCmp . getMultiComparator ( ) ) { pqCmp = new PriorityQueueScanComparator ( cmp ) ; } } private class PriorityQueueScanComparator extends PriorityQueueComparator { public PriorityQueueScanComparator ( MultiComparator cmp ) { super ( cmp ) ; } @Override
* software distributed under the License is distributed on an * "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . storage . am . lsm . common . util ; import org . apache . hyracks . storage . am . common . api . IIndexOperationContext ; import org . apache . hyracks . storage . common . IIndexAccessor ; import org . apache . hyracks . storage . common . IIndexCursor ; public class DestroyUtils { < |startfocus| > < |endfocus| > public static < T extends IIndexOperationContext > Throwable destroy ( T [ ] contexts ) { Throwable failure = null ; for ( int i = 0 ; i < contexts . length ; i ++ ) { if ( contexts [ i ] != null ) { try { contexts [ i ] . destroy ( ) ; } catch ( Throwable th ) { if ( failure == null ) { failure = th ; } else { failure . addSuppressed ( th ) ; } } } } return failure ; } public static < T extends IIndexAccessor > Throwable destroy ( T [ ] accessors ) { Throwable failure = null ;
package org . apache . hyracks . storage . am . lsm . common . util ; import org . apache . hyracks . storage . am . common . api . IIndexOperationContext ; import org . apache . hyracks . storage . common . IIndexAccessor ; import org . apache . hyracks . storage . common . IIndexCursor ; public class DestroyUtils { public static < T extends IIndexOperationContext > Throwable destroy ( T [ ] contexts ) { Throwable failure = null ; for ( int i = 0 ; i < contexts . length ; i ++ ) { if ( contexts [ i ] != null ) { try { contexts [ i ] . destroy ( ) ; < |startfocus| > } catch ( Exception th ) { < |endfocus| > if ( failure == null ) { failure = th ; } else { failure . addSuppressed ( th ) ; } } } } return failure ; } public static < T extends IIndexAccessor > Throwable destroy ( T [ ] accessors ) { Throwable failure = null ; for ( int i = 0 ; i < accessors . length ; i ++ ) { if ( accessors [ i ] != null ) { try { accessors [ i ] . destroy ( ) ; } catch ( Exception th ) { if ( failure == null ) { failure = th ;
} catch ( Throwable th ) { if ( failure == null ) { failure = th ; } else { failure . addSuppressed ( th ) ; } } } } return failure ; } public static < T extends IIndexAccessor > Throwable destroy ( T [ ] accessors ) { Throwable failure = null ; for ( int i = 0 ; i < accessors . length ; i ++ ) { if ( accessors [ i ] != null ) { try { accessors [ i ] . destroy ( ) ; < |startfocus| > } catch ( Exception th ) { < |endfocus| > if ( failure == null ) { failure = th ; } else { failure . addSuppressed ( th ) ; } } } } return failure ; } public static < T extends IIndexCursor > Throwable destroy ( T [ ] cursors ) { Throwable failure = null ; for ( int i = 0 ; i < cursors . length ; i ++ ) { if ( cursors [ i ] != null ) { try { cursors [ i ] . destroy ( ) ; } catch ( Throwable th ) { if ( failure == null ) { failure = th ; } else {
} catch ( Throwable th ) { if ( failure == null ) { failure = th ; } else { failure . addSuppressed ( th ) ; } } } } return failure ; } public static < T extends IIndexCursor > Throwable destroy ( T [ ] cursors ) { Throwable failure = null ; for ( int i = 0 ; i < cursors . length ; i ++ ) { if ( cursors [ i ] != null ) { try { cursors [ i ] . destroy ( ) ; < |startfocus| > } catch ( Throwable th ) { < |endfocus| > if ( failure == null ) { failure = th ; } else { failure . addSuppressed ( th ) ; } } } } return failure ; } }
boolean abort = true ; try { try { ISearchPredicate rtreeSearchPred = new SearchPredicate ( null , null ) ; ILSMIndexOperationContext opCtx = ( ( LSMRTreeSortedCursor ) cursor ) . getOpCtx ( ) ; search ( opCtx , cursor , rtreeSearchPred ) ; try { mergedComponent = createDiskComponent ( componentFactory , mergeOp . getTarget ( ) , mergeOp . getBTreeTarget ( ) , mergeOp . getBloomFilterTarget ( ) , true ) ; < |startfocus| > // In case we must keep the deleted - keys BTrees , then they must be merged * before * merging the r - trees so that < |endfocus| > // lsmHarness . endSearch ( ) is called once when the r - trees have been merged . if ( mergeOp . getMergingComponents ( ) . get ( mergeOp . getMergingComponents ( ) . size ( ) - 1 ) != diskComponents . get ( diskComponents . size ( ) - 1 ) ) { // Keep the deleted tuples since the oldest disk component is not included in the merge operation long numElements = 0L ; for ( int i = 0 ; i < mergeOp . getMergingComponents ( ) . size ( ) ; ++ i ) { numElements += ( ( LSMRTreeDiskComponent ) mergeOp . getMergingComponents ( ) . get ( i ) ) . getBloomFilter ( ) . getNumElements ( ) ; }
// In case we must keep the deleted - keys BTrees , then they must be merged * before * merging the r - trees so that // lsmHarness . endSearch ( ) is called once when the r - trees have been merged . if ( mergeOp . getMergingComponents ( ) . get ( mergeOp . getMergingComponents ( ) . size ( ) - 1 ) != diskComponents . get ( diskComponents . size ( ) - 1 ) ) { < |startfocus| > // Keep the deleted tuples since the oldest disk component is not included in the merge operation < |endfocus| > long numElements = 0L ; for ( int i = 0 ; i < mergeOp . getMergingComponents ( ) . size ( ) ; ++ i ) { numElements += ( ( LSMRTreeDiskComponent ) mergeOp . getMergingComponents ( ) . get ( i ) ) . getBloomFilter ( ) . getNumElements ( ) ; } componentBulkLoader = mergedComponent . createBulkLoader ( 1 . 0f , false , numElements , false , false , false ) ; LSMRTreeDeletedKeysBTreeMergeCursor btreeCursor = new LSMRTreeDeletedKeysBTreeMergeCursor ( opCtx ) ; try { search ( opCtx , btreeCursor , rtreeSearchPred ) ; try { while ( btreeCursor . hasNext ( ) ) {
} doOpen ( initialState , searchPred ) ; state = State . OPENED ; if ( STORE_TRACES ) { openCallStack = new Throwable ( ) . getStackTrace ( ) ; } } protected void doOpen ( ICursorInitialState initialState , ISearchPredicate searchPred ) throws HyracksDataException { // Do nothing } @Override public final boolean hasNext ( ) throws HyracksDataException { < |startfocus| > if ( ENFORCE_NEXT_HAS_NEXT && state != State . OPENED ) { throw new IllegalStateException ( "Cannot call hasNext ( ) on a cursor in the state " + state ) ; } < |endfocus| > return doHasNext ( ) ; } protected boolean doHasNext ( ) throws HyracksDataException { return false ; } @Override public final void next ( ) throws HyracksDataException { if ( ENFORCE_NEXT_HAS_NEXT ) { if ( state != State . OPENED ) { throw new IllegalStateException ( "Cannot call next ( ) on a cursor in the state " + state ) ; } } doNext ( ) ; } protected void doNext ( ) throws HyracksDataException { // Do nothing } @Override
if ( state != State . OPENED ) { throw new IllegalStateException ( "Cannot call hasNext ( ) on a cursor in the state " + state ) ; } } return doHasNext ( ) ; } protected boolean doHasNext ( ) throws HyracksDataException { return false ; } @Override public final void next ( ) throws HyracksDataException { < |startfocus| > if ( ENFORCE_NEXT_HAS_NEXT && state != State . OPENED ) { throw new IllegalStateException ( "Cannot call next ( ) on a cursor in the state " + state ) ; } < |endfocus| > doNext ( ) ; } protected void doNext ( ) throws HyracksDataException { // Do nothing } @Override public final void destroy ( ) throws HyracksDataException { if ( ENFORCE_OPEN_CLOSE_DESTROY ) { if ( state == State . DESTROYED ) { LOGGER . log ( Level . WARN , "multiple cursor . destroy ( ) call in " + Arrays . toString ( new Throwable ( ) . getStackTrace ( ) ) ) ; return ; } else if ( state != State . CLOSED ) { if ( STORE_TRACES && openCallStack != null ) {
private ByteBuffer buffer ; private volatile long dpid ; private int multiplier ; private VirtualPage next ; < |startfocus| > private AtomicInteger readCount = new AtomicInteger ( 0 ) ; private AtomicInteger writeCount = new AtomicInteger ( 0 ) ; < |endfocus| > public VirtualPage ( ByteBuffer buffer , int pageSize ) { this . buffer = buffer ; this . pageSize = pageSize ; latch = new ReentrantReadWriteLock ( true ) ; dpid = - 1 ; next = null ;
public void acquireReadLatch ( ) { latch . readLock ( ) . lock ( ) ; < |startfocus| > readCount . incrementAndGet ( ) ; < |endfocus| >
LOGGER . info ( "Disk - Order Scan : " ) ; } ITreeIndexAccessor treeIndexAccessor = ( ITreeIndexAccessor ) indexAccessor ; TreeIndexDiskOrderScanCursor diskOrderCursor = ( TreeIndexDiskOrderScanCursor ) treeIndexAccessor . createDiskOrderScanCursor ( ) ; try { treeIndexAccessor . diskOrderScan ( diskOrderCursor ) ; try { while ( diskOrderCursor . hasNext ( ) ) { diskOrderCursor . next ( ) ; ITupleReference frameTuple = diskOrderCursor . getTuple ( ) ; String rec = TupleUtils . printTuple ( frameTuple , fieldSerdes ) ; < |startfocus| > if ( LOGGER . isInfoEnabled ( ) ) { LOGGER . info ( rec ) ; } < |endfocus| > } } finally { diskOrderCursor . close ( ) ; } } finally { diskOrderCursor . destroy ( ) ; } } catch ( UnsupportedOperationException e ) { // Ignore exception because some indexes , e . g . the LSMRTree , don't // support disk - order scan . if ( LOGGER . isInfoEnabled ( ) ) { LOGGER . info ( "Ignoring disk - order scan since it's not supported . " ) ; } } catch ( ClassCastException e ) { // Ignore exception because IIndexAccessor sometimes isn't // an ITreeIndexAccessor , e . g . , for the LSMRTree . }
Class < ? > c = Class . forName ( className ) ; ncAppEntryPoint = ( INCApplicationEntryPoint ) c . newInstance ( ) ; String [ ] args = ncConfig . appArgs == null ? new String [ 0 ] : ncConfig . appArgs . toArray ( new String [ ncConfig . appArgs . size ( ) ] ) ; ncAppEntryPoint . start ( appCtx , args ) ; } executor = Executors . newCachedThreadPool ( appCtx . getThreadFactory ( ) ) ; } @Override public synchronized void stop ( ) throws Exception { if ( ! shuttedDown ) { LOGGER . log ( Level . INFO , "Stopping NodeControllerService" ) ; executor . shutdownNow ( ) ; if ( ! executor . awaitTermination ( 10 , TimeUnit . SECONDS ) ) { < |startfocus| > LOGGER . log ( Level . SEVERE , "Some jobs failed to exit , continuing with abnormal shutdown" ) ; < |endfocus| > } partitionManager . close ( ) ; datasetPartitionManager . close ( ) ; netManager . stop ( ) ; datasetNetworkManager . stop ( ) ; if ( messagingNetManager != null ) { messagingNetManager . stop ( ) ; } queue . stop ( ) ; if ( ncAppEntryPoint != null ) { ncAppEntryPoint . stop ( ) ; } /* * * Stop heartbeat after NC has stopped to avoid false node failure detection .
CCNCFunctions . NodeRegistrationResult nrrf = ( CCNCFunctions . NodeRegistrationResult ) fn ; setNodeRegistrationResult ( nrrf . getNodeParameters ( ) , nrrf . getException ( ) ) ; return ; case GET_NODE_CONTROLLERS_INFO_RESPONSE : CCNCFunctions . GetNodeControllersInfoResponseFunction gncirf = ( CCNCFunctions . GetNodeControllersInfoResponseFunction ) fn ; setNodeControllersInfo ( gncirf . getNodeControllerInfos ( ) ) ; return ; case DEPLOY_BINARY : CCNCFunctions . DeployBinaryFunction dbf = ( CCNCFunctions . DeployBinaryFunction ) fn ; queue . schedule ( new DeployBinaryWork ( NodeControllerService . this , dbf . getDeploymentId ( ) , dbf . getBinaryURLs ( ) ) ) ; < |startfocus| > return ; < |endfocus| > case UNDEPLOY_BINARY : CCNCFunctions . UnDeployBinaryFunction ndbf = ( CCNCFunctions . UnDeployBinaryFunction ) fn ; queue . schedule ( new UnDeployBinaryWork ( NodeControllerService . this , ndbf . getDeploymentId ( ) ) ) ; return ; case STATE_DUMP_REQUEST : final CCNCFunctions . StateDumpRequestFunction dsrf = ( StateDumpRequestFunction ) fn ; queue . schedule ( new StateDumpWork ( NodeControllerService . this , dsrf . getStateDumpId ( ) ) ) ; return ; case SHUTDOWN_REQUEST : final CCNCFunctions . ShutdownRequestFunction sdrf = ( CCNCFunctions . ShutdownRequestFunction ) fn ; < |startfocus| > return ; < |endfocus| >
*/ package org . apache . hyracks . api . job ; import java . io . DataInput ; import java . io . DataOutput ; import java . io . IOException ; import java . io . Serializable ; import org . apache . hyracks . api . control . CcId ; import org . apache . hyracks . api . exceptions . ErrorCode ; import org . apache . hyracks . api . exceptions . HyracksDataException ; import org . apache . hyracks . api . io . IWritable ; public final class JobId implements IWritable , Serializable , Comparable { < |startfocus| > public static final int CC_BITS = Short . SIZE ; public static final int ID_BITS = Long . SIZE - CC_BITS ; public static final long MAX_ID = ( 1L < < ID_BITS ) - 1 ; < |endfocus| > public static final JobId INVALID = null ; private static final long serialVersionUID = 1L ; private long id ; private transient CcId ccId ; public static JobId create ( DataInput dis ) throws IOException { JobId jobId = new JobId ( ) ; jobId . readFields ( dis ) ; return jobId ; } private JobId ( ) { } public JobId ( long id ) { this . id = id ; } public long getId ( ) {
import java . io . DataOutput ; import java . io . IOException ; import java . io . Serializable ; import org . apache . hyracks . api . control . CcId ; import org . apache . hyracks . api . exceptions . ErrorCode ; import org . apache . hyracks . api . exceptions . HyracksDataException ; import org . apache . hyracks . api . io . IWritable ; public final class JobId implements IWritable , Serializable , Comparable { < |startfocus| > public static final int CC_BITS = Short . SIZE ; public static final int ID_BITS = Long . SIZE - CC_BITS ; public static final long MAX_ID = ( 1L < < ID_BITS ) - 1 ; < |endfocus| > public static final JobId INVALID = null ; private static final long serialVersionUID = 1L ; private long id ; private transient CcId ccId ; public static JobId create ( DataInput dis ) throws IOException { JobId jobId = new JobId ( ) ; jobId . readFields ( dis ) ; return jobId ; } private JobId ( ) { } public JobId ( long id ) { this . id = id ; } public long getId ( ) { return id ; } public CcId getCcId ( ) { return ccId ; } public void setCcId ( CcId ccId ) { this . ccId = ccId ; } @Override public void writeFields ( DataOutput output ) throws IOException { output . writeLong ( id ) ; } @Override public void readFields ( DataInput input ) throws IOException { id = input . readLong ( ) ; } @Override public int compareTo ( JobId o ) { return Long . compare ( id , o . id ) ; } @Override public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( int ) ( id ^ ( id > > > 32 ) ) ; return result ; } @Override public boolean equals ( Object obj ) { if ( this == obj ) return true ; if ( obj == null ) return false ; if ( getClass ( ) != obj . getClass ( ) ) return false ; JobId other = ( JobId ) obj ; if ( id != other . id ) return false ; return true ; } @Override public String toString ( ) { return "JobId [ " + id + " ] " ; } public static JobId create ( CcId ccId , long id ) throws HyracksDataException { if ( id < 0 || id > MAX_ID ) { throw HyracksDataException . create ( ErrorCode . INVALID_JOB_ID , id ) ; } return new JobId ( ccId . getId ( ) < < ID_BITS | id ) ; } }
ncAppEntryPoint . stop ( ) ; /* * Stop heartbeat after NC has stopped to avoid false node failure detection * on CC if an NC takes a long time to stop . */ heartbeatTask . cancel ( ) ; LOGGER . log ( Level . INFO , "Stopped NodeControllerService" ) ; shuttedDown = true ; } } public String getId ( ) { return id ; } public ServerContext getServerContext ( ) { return serverCtx ; } public Map < JobId , Joblet > getJobletMap ( ) { return jobletMap ; } < |startfocus| > public Map < JobId , ActivityClusterGraph > getActivityClusterGraphMap ( ) { return activityClusterGraphMap ; } < |endfocus| > public NetworkManager getNetworkManager ( ) { return netManager ; } public DatasetNetworkManager getDatasetNetworkManager ( ) { return datasetNetworkManager ; } public PartitionManager getPartitionManager ( ) { return partitionManager ; } public IClusterController getClusterController ( ) { return ccs ; } public NodeParameters getNodeParameters ( ) { return nodeParameters ; } public ExecutorService getExecutorService ( ) { return executor ; } public NCConfig getConfiguration ( ) { return config ; } public void setConfiguration ( NCConfig config ) { this . config = config ; } public void setClusterController ( IClusterController ccs ) { this . ccs = ccs ; } public void setNodeParameters ( NodeParameters nodeParameters ) { this . nodeParameters = nodeParameters ; } public void setExecutorService ( ExecutorService executor ) { this . executor = executor ; } public void setNetworkManager ( NetworkManager netManager ) { this . netManager = netManager ; } public void setDatasetNetworkManager ( DatasetNetworkManager datasetNetworkManager ) { this . datasetNetworkManager = datasetNetworkManager ; } public void setPartitionManager ( PartitionManager partitionManager ) { this . partitionManager = partitionManager ; } public void setJobletMap ( Map < JobId , Joblet > jobletMap ) { this . jobletMap = jobletMap ; } public void setActivityClusterGraphMap ( Map < JobId , ActivityClusterGraph > activityClusterGraphMap ) { this . activityClusterGraphMap = activityClusterGraphMap ; } public void setServerContext ( ServerContext serverCtx ) { this . serverCtx = serverCtx ; } public void setId ( String id ) { this . id = id ; } public void setShuttedDown ( boolean shuttedDown ) { this . shuttedDown = shuttedDown ; } public void setHeartbeatTask ( ScheduledFuture < ? > heartbeatTask ) { this . heartbeatTask = heartbeatTask ; } public void setNcAppEntryPoint ( NCAppEntryPoint ncAppEntryPoint ) { this . ncAppEntryPoint = ncAppEntryPoint ; } public void setNodeControllerMetrics ( NodeControllerMetrics nodeControllerMetrics ) { this . nodeControllerMetrics = nodeControllerMetrics ; } public void setNodeControllerRemote ( NodeControllerRemote nodeControllerRemote ) { this . nodeControllerRemote = nodeControllerRemote ; } public void setNodeControllerRemoteInterface ( NodeControllerRemoteInterface nodeControllerRemoteInterface ) { this . nodeControllerRemoteInterface = nodeControllerRemoteInterface ; } public void setNodeControllerService ( NodeControllerService nodeControllerService ) { this . nodeControllerService = nodeControllerService ; } public void setNodeControllerServiceInterface ( NodeControllerServiceInterface nodeControllerServiceInterface ) { this . nodeControllerServiceInterface = nodeControllerServiceInterface ; } public void setNodeControllerServiceSpec ( NodeControllerServiceSpec nodeControllerServiceSpec ) { this . nodeControllerServiceSpec = nodeControllerServiceSpec ; } public void setNodeControllerServiceSpecInterface ( NodeControllerServiceSpecInterface nodeControllerServiceSpecInterface ) { this . nodeControllerServiceSpecInterface = nodeControllerServiceSpecInterface ; } public void setNodeControllerServiceSpecRemote ( NodeControllerServiceSpecRemote nodeControllerServiceSpecRemote ) { this . nodeControllerServiceSpecRemote = nodeControllerServiceSpecRemote ; } public void setNodeControllerServiceSpecRemoteInterface ( NodeControllerServiceSpecRemoteInterface nodeControllerServiceSpecRemoteInterface ) { this . nodeControllerServiceSpecRemoteInterface = nodeControllerServiceSpecRemoteInterface ; } public void setNodeControllerServiceSpecService ( NodeControllerServiceSpecService nodeControllerServiceSpecService ) { this . nodeControllerServiceSpecService = nodeControllerServiceSpecService ; } public void setNodeControllerServiceSpecServiceInterface ( NodeControllerServiceSpecServiceInterface nodeControllerServiceSpecServiceInterface ) { this . nodeControllerServiceSpecServiceInterface = nodeControllerServiceSpecServiceInterface ; } public void setNodeControllerServiceSpecServiceRemote ( NodeControllerServiceSpecServiceRemote nodeControllerServiceSpecServiceRemote ) { this . nodeControllerServiceSpecServiceRemote = nodeControllerServiceSpecServiceRemote ; } public void setNodeControllerServiceSpecServiceRemoteInterface ( NodeControllerServiceSpecServiceRemoteInterface nodeControllerServiceSpecServiceRemoteInterface ) { this . nodeControllerServiceSpecServiceRemoteInterface = nodeControllerServiceSpecServiceRemoteInterface ; } public void setNodeControllerServiceSpecServiceService ( NodeControllerServiceSpecServiceService nodeControllerServiceSpecServiceService ) { this . nodeControllerServiceSpecServiceService = nodeControllerServiceSpecServiceService ; } public void setNodeControllerServiceSpecServiceServiceInterface ( NodeControllerServiceSpecServiceServiceInterface nodeControllerServiceSpecServiceServiceInterface ) { this . nodeControllerServiceSpecServiceServiceInterface = nodeControllerServiceSpecServiceServiceInterface ; } public void setNodeControllerServiceSpecServiceServiceRemote ( NodeControllerServiceSpecServiceServiceRemote nodeControllerServiceSpecServiceServiceRemote ) { this . nodeControllerServiceSpecServiceServiceRemote = nodeControllerServiceSpecServiceServiceRemote ; } public void setNodeControllerServiceSpecServiceServiceRemoteInterface ( NodeControllerServiceSpecServiceServiceRemoteInterface nodeControllerServiceSpecServiceServiceRemoteInterface ) { this . nodeControllerServiceSpecServiceServiceRemoteInterface = nodeControllerServiceSpecServiceServiceRemoteInterface ; } public void setNodeControllerServiceSpecServiceServiceService ( NodeControllerServiceSpecServiceServiceService nodeControllerServiceSpecServiceServiceService ) { this . nodeControllerServiceSpecServiceServiceService = nodeControllerServiceSpecServiceServiceService ; } public void setNodeControllerServiceSpecServiceServiceServiceInterface ( NodeControllerServiceSpecServiceServiceServiceInterface nodeControllerServiceSpecServiceServiceServiceInterface ) { this . nodeControllerServiceSpecServiceServiceServiceInterface = nodeControllerServiceSpecServiceServiceServiceInterface ; } public void setNodeControllerServiceSpecServiceServiceServiceRemote ( NodeControllerServiceSpecServiceServiceServiceRemote nodeControllerServiceSpecServiceServiceServiceRemote ) { this . nodeControllerServiceSpecServiceServiceServiceRemote = nodeControllerServiceSpecServiceServiceServiceRemote ; } public void setNodeControllerServiceSpecServiceServiceServiceRemoteInterface ( NodeControllerServiceSpecServiceServiceServiceRemoteInterface nodeControllerServiceSpecServiceServiceServiceRemoteInterface ) { this . nodeControllerServiceSpecServiceServiceServiceRemoteInterface = nodeControllerServiceSpecServiceServiceServiceRemoteInterface ; } public void setNodeControllerServiceSpecServiceServiceServiceService ( NodeControllerServiceSpecServiceServiceServiceService nodeControllerServiceSpecServiceServiceServiceService ) { this . nodeControllerServiceSpecServiceServiceServiceService = nodeControllerServiceSpecServiceServiceServiceService ; } public void setNodeControllerServiceSpecServiceServiceServiceServiceInterface ( NodeControllerServiceSpecServiceServiceServiceServiceInterface nodeControllerServiceSpecServiceServiceServiceServiceInterface ) { this . nodeControllerServiceSpecServiceServiceServiceServiceInterface = nodeControllerServiceSpecServiceServiceServiceServiceInterface ; } public void setNodeControllerServiceSpecServiceServiceServiceServiceRemote ( NodeControllerServiceSpecServiceServiceServiceServiceRemote nodeControllerServiceSpecServiceServiceServiceServiceRemote ) { this . nodeControllerServiceSpecServiceServiceServiceServiceRemote = nodeControllerServiceSpecServiceServiceServiceServiceRemote ; } public void setNodeControllerServiceSpecServiceServiceServiceServiceRemoteInterface ( NodeControllerServiceSpecServiceServiceServiceServiceRemoteInterface nodeControllerServiceSpecServiceServiceServiceServiceRemoteInterface ) { this . nodeControllerServiceSpecServiceServiceServiceServiceRemoteInterface = nodeControllerServiceSpecServiceServiceServiceServiceRemoteInterface ; } public void setNodeControllerServiceSpecServiceServiceServiceServiceService ( NodeControllerServiceSpecServiceServiceServiceServiceService nodeControllerServiceSpecServiceServiceServiceServiceService ) { this . nodeControllerServiceSpecServiceServiceServiceServiceService = nodeControllerServiceSpecServiceServiceServiceServiceService ; } public void setNodeControllerServiceSpecServiceServiceServiceServiceServiceInterface ( NodeControllerServiceSpecServiceServiceServiceServiceServiceInterface nodeControllerServiceSpecServiceServiceServiceServiceServiceInterface ) { this . nodeControllerServiceSpecServiceServiceServiceServiceServiceInterface = nodeControllerServiceSpecServiceServiceService
currentRecordChannel = new DatasetNetworkInputChannel ( netManager , getSocketAddress ( record ) , jobId , resultSetId , currentRecord , NUM_READ_BUFFERS ) ; currentRecordMonitor = getMonitor ( currentRecord ) ; currentRecordChannel . registerMonitor ( currentRecordMonitor ) ; currentRecordChannel . open ( datasetClientCtx ) ; } private boolean isFirstRead ( ) { return currentRecord == - 1 ; } private boolean isLastRecord ( ) { return knownRecords != null && currentRecord == knownRecords . length - 1 ; } < |startfocus| > private static class DatasetInputChannelMonitor implements IInputChannelMonitor { < |endfocus| > private int availableFrames ; private boolean eos ; private boolean failed ; DatasetInputChannelMonitor ( ) { eos = false ; failed = false ; } @Override public synchronized void notifyFailure ( IInputChannel channel ) { failed = true ; notifyAll ( ) ; } @Override public synchronized void notifyDataAvailability ( IInputChannel channel , int nFrames ) { availableFrames += nFrames ; notifyAll ( ) ; } @Override public synchronized void notifyEndOfStream ( IInputChannel channel ) { eos = true ; notifyAll ( ) ; } synchronized boolean failed ( ) { return failed ; }
private static final boolean [ ] UNIQUE_META_FIELDS = null ; private static final int [ ] KEY_INDEXES = { 0 } ; private static final int [ ] KEY_INDICATORS = { Index . RECORD_INDICATOR } ; private static final List < Integer > KEY_INDICATORS_LIST = Arrays . asList ( new Integer [ ] { Index . RECORD_INDICATOR } ) ; private static final int TOTAL_NUM_OF_RECORDS = 10000 ; private static final int RECORDS_PER_COMPONENT = 1000 ; private static final int DATASET_ID = 101 ; private static final int PARTITION_ID = 0 ; private static final String DATAVERSE_NAME = "TestDV" ; private static final String DATASET_NAME = "TestDS" ; private static final String DATA_TYPE_NAME = "DUMMY" ; private static final String NODE_GROUP_NAME = "DEFAULT" ; private static final Predicate < ILSMComponent > memoryComponentsPredicate = c - > c instanceof ILSMMemoryComponent ; private static final StorageComponentProvider storageManager = new StorageComponentProvider ( ) ; private static TestNodeController nc ; private static TestLsmBtree lsmBtree ; private static NCAppRuntimeContext ncAppCtx ; private static IDatasetLifecycleManager dsLifecycleMgr ; private static Dataset dataset ;
/* * * @return the operation callback */ ILSMIOOperationCallback getCallback ( ) ; /* * * @return the index id */ String getIndexIdentifier ( ) ; /* * * @return the operation type */ LSMIOOperationType getIOOpertionType ( ) ; @Override Boolean call ( ) throws HyracksDataException ; /* * * @return The target of the io operation */ FileReference getTarget ( ) ; /* * * @return the accessor of the operation */ ILSMIndexAccessor getAccessor ( ) ; < |startfocus| > < |endfocus| > LSMComponentFileReferences getComponentFiles ( ) ; }
public LSMBTreeCursorInitialState ( ITreeIndexFrameFactory leafFrameFactory , MultiComparator cmp , MultiComparator bloomFilterCmp , ILSMHarness lsmHarness , ISearchPredicate predicate , ISearchOperationCallback searchCallback , List < ILSMComponent > operationalComponents ) { this . leafFrameFactory = leafFrameFactory ; this . cmp = cmp ; this . bloomFilterCmp = bloomFilterCmp ; this . lsmHarness = lsmHarness ; this . searchCallback = searchCallback ; this . predicate = predicate ; this . operationalComponents = operationalComponents ;
btreeCursors [ i ] = btreeAccessors [ i ] . createPointCursor ( false ) ; } else { // re - use btreeAccessors [ i ] . reset ( btree , NoOpOperationCallback . INSTANCE , NoOpOperationCallback . INSTANCE ) ; btreeCursors [ i ] . reset ( ) ; } } nextHasBeenCalled = false ; foundTuple = false ; } @Override public void next ( ) throws HyracksDataException { nextHasBeenCalled = true ; } @Override < |startfocus| > public void close ( ) throws HyracksDataException { if ( lsmHarness != null ) { try { closeCursors ( ) ; btreeCursors = null ; } finally { lsmHarness . endSearch ( opCtx ) ; < |endfocus| > } } nextHasBeenCalled = false ; foundTuple = false ; } @Override public ITupleReference getTuple ( ) { return frameTuple ; } @Override public ITupleReference getFilterMinTuple ( ) { ILSMComponentFilter filter = getFilter ( ) ; return filter == null ? null : filter . getMinTuple ( ) ; } @Override public ITupleReference getFilterMaxTuple ( ) { ILSMComponentFilter filter = getFilter ( ) ; return filter == null ? null : filter . getMaxTuple ( ) ; }
private final LSMBTreeRangeSearchCursor rangeCursor ; private ITreeIndexCursor currentCursor ; public LSMBTreeSearchCursor ( ILSMIndexOperationContext opCtx ) { pointCursor = new LSMBTreePointSearchCursor ( opCtx ) ; rangeCursor = new LSMBTreeRangeSearchCursor ( opCtx ) ; } @Override public void open ( ICursorInitialState initialState , ISearchPredicate searchPred ) throws HyracksDataException { LSMBTreeCursorInitialState lsmInitialState = ( LSMBTreeCursorInitialState ) initialState ; RangePredicate btreePred = ( RangePredicate ) searchPred ; < |startfocus| > currentCursor = btreePred . isPointPredicate ( lsmInitialState . getOriginalKeyComparator ( ) ) ? pointCursor : rangeCursor ; < |endfocus| > currentCursor . open ( lsmInitialState , searchPred ) ; } @Override public boolean hasNext ( ) throws HyracksDataException { return currentCursor . hasNext ( ) ; } @Override public void next ( ) throws HyracksDataException { currentCursor . next ( ) ; } @Override public void close ( ) throws HyracksDataException { if ( currentCursor != null ) { currentCursor . close ( ) ; } currentCursor = null ; } @Override public void reset ( ) throws HyracksDataException { if ( currentCursor != null ) { currentCursor . reset ( ) ; } currentCursor = null ;
// ( E . g . There are index - nested - loop - joins in the plan . ) private List < Mutable < ILogicalOperator > > ixJoinOuterAdditionalDataSourceRefs = null ; private List < DataSourceType > ixJoinOuterAdditionalDataSourceTypes = null ; private List < Dataset > ixJoinOuterAdditionalDatasets = null ; private List < ARecordType > ixJoinOuterAdditionalRecordTypes = null ; /* * * Identifies the root of the subtree and initializes the data - source , assign , and unnest information . */ < |startfocus| > public boolean initFromSubTree ( Mutable < ILogicalOperator > subTreeOpRef ) throws AlgebricksException { < |endfocus| > reset ( ) ; rootRef = subTreeOpRef ; root = subTreeOpRef . getValue ( ) ; boolean passedSource = false ; boolean result = false ; Mutable < ILogicalOperator > searchOpRef = subTreeOpRef ; // Examine the op's children to match the expected patterns . AbstractLogicalOperator subTreeOp = ( AbstractLogicalOperator ) searchOpRef . getValue ( ) ; do { // Skips select operator . if ( subTreeOp . getOperatorTag ( ) == LogicalOperatorTag . SELECT ) { searchOpRef = subTreeOp . getInputs ( ) . get ( 0 ) ;
} } /* * * Computes and returns the byte array for an integer value . */ public static byte [ ] computeByteArrayForIntValue ( int value ) throws AlgebricksException { ArrayBackedValueStorage castBuffer = new ArrayBackedValueStorage ( ) ; try { AInt32 val = new AInt32 ( value ) ; SerializerDeserializerUtil . serializeTag ( val , castBuffer . getDataOutput ( ) ) ; AInt32SerializerDeserializer . INSTANCE . serialize ( val , castBuffer . getDataOutput ( ) ) ; } catch ( HyracksDataException e ) { < |startfocus| > throw new AlgebricksException ( e ) ; < |endfocus| > } return castBuffer . getByteArray ( ) ; } }
private ITreeIndexAccessor [ ] btreeAccessors ; private RTreeSearchCursor [ ] mutableRTreeCursors ; private ITreeIndexCursor [ ] btreeCursors ; private RangePredicate btreeRangePredicate ; private boolean foundNext ; private ITupleReference frameTuple ; private int [ ] comparatorFields ; private MultiComparator btreeCmp ; private int currentCursor ; private SearchPredicate rtreeSearchPredicate ; private int numMutableComponents ; private boolean open ; protected ISearchOperationCallback searchCallback ; private boolean resultOfsearchCallBackProceed = false ; < |startfocus| > private ArrayTupleBuilder tupleBuilderForProceedResult ; private ArrayTupleReference copyTuple = null ; < |endfocus| > public LSMRTreeWithAntiMatterTuplesSearchCursor ( ILSMIndexOperationContext opCtx ) { this ( opCtx , false ) ; } public LSMRTreeWithAntiMatterTuplesSearchCursor ( ILSMIndexOperationContext opCtx , boolean returnDeletedTuples ) { super ( opCtx , returnDeletedTuples ) ; currentCursor = 0 ; } @Override public void open ( ICursorInitialState initialState , ISearchPredicate searchPred ) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = ( LSMRTreeCursorInitialState ) initialState ; cmp = lsmInitialState . getHilbertCmp ( ) ; btreeCmp = lsmInitialState . getBTreeCmp ( ) ; lsmHarness = lsmInitialState . getLSMHarness ( ) ;
private RTreeSearchCursor [ ] mutableRTreeCursors ; private ITreeIndexCursor [ ] btreeCursors ; private RangePredicate btreeRangePredicate ; private boolean foundNext ; private ITupleReference frameTuple ; private int [ ] comparatorFields ; private MultiComparator btreeCmp ; private int currentCursor ; private SearchPredicate rtreeSearchPredicate ; private int numMutableComponents ; private boolean open ; protected ISearchOperationCallback searchCallback ; private boolean resultOfsearchCallBackProceed = false ; < |startfocus| > private int numberOfFieldFromIndex = 0 ; private ArrayTupleReference copyTuple = null ; < |endfocus| > public LSMRTreeWithAntiMatterTuplesSearchCursor ( ILSMIndexOperationContext opCtx ) { this ( opCtx , false ) ; } public LSMRTreeWithAntiMatterTuplesSearchCursor ( ILSMIndexOperationContext opCtx , boolean returnDeletedTuples ) { super ( opCtx , returnDeletedTuples ) ; currentCursor = 0 ; } @Override public void open ( ICursorInitialState initialState , ISearchPredicate searchPred ) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = ( LSMRTreeCursorInitialState ) initialState ; cmp = lsmInitialState . getHilbertCmp ( ) ; btreeCmp = lsmInitialState . getBTreeCmp ( ) ; lsmHarness = lsmInitialState . getLSMHarness ( ) ;
private RTreeSearchCursor [ ] mutableRTreeCursors ; private ITreeIndexCursor [ ] btreeCursors ; private RangePredicate btreeRangePredicate ; private boolean foundNext ; private ITupleReference frameTuple ; private int [ ] comparatorFields ; private MultiComparator btreeCmp ; private int currentCursor ; private SearchPredicate rtreeSearchPredicate ; private int numMutableComponents ; private boolean open ; protected ISearchOperationCallback searchCallback ; private boolean resultOfsearchCallBackProceed = false ; < |startfocus| > private int numberOfFieldFromIndex = 0 ; private ArrayTupleBuilder tupleBuilderForProceedResult ; < |endfocus| > public LSMRTreeWithAntiMatterTuplesSearchCursor ( ILSMIndexOperationContext opCtx ) { this ( opCtx , false ) ; } public LSMRTreeWithAntiMatterTuplesSearchCursor ( ILSMIndexOperationContext opCtx , boolean returnDeletedTuples ) { super ( opCtx , returnDeletedTuples ) ; currentCursor = 0 ; } @Override public void open ( ICursorInitialState initialState , ISearchPredicate searchPred ) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = ( LSMRTreeCursorInitialState ) initialState ; cmp = lsmInitialState . getHilbertCmp ( ) ; btreeCmp = lsmInitialState . getBTreeCmp ( ) ; lsmHarness = lsmInitialState . getLSMHarness ( ) ;
public interface INcApplicationContext extends IApplicationContext { IIOManager getIoManager ( ) ; Executor getThreadExecutor ( ) ; ITransactionSubsystem getTransactionSubsystem ( ) ; void preStop ( ) throws Exception ; boolean isShuttingdown ( ) ; ILSMIOOperationScheduler getLSMIOScheduler ( ) ; ILSMMergePolicyFactory getMetadataMergePolicyFactory ( ) ; IBufferCache getBufferCache ( ) ; ILocalResourceRepository getLocalResourceRepository ( ) ; IDatasetLifecycleManager getDatasetLifecycleManager ( ) ; IDatasetMemoryManager getDatasetMemoryManager ( ) ; IResourceIdFactory getResourceIdFactory ( ) ; < |startfocus| > ILSMOperationTracker getPrimaryOperationTracker ( int datasetID , int partition ) ; < |endfocus| > void initialize ( boolean initialRun ) throws IOException , ACIDException , AlgebricksException ; void setShuttingdown ( boolean b ) ; void deinitialize ( ) throws HyracksDataException ; double getBloomFilterFalsePositiveRate ( ) ; Object getActiveManager ( ) ; IReplicationManager getReplicationManager ( ) ; IReplicationChannel getReplicationChannel ( ) ; /* * * Exports the metadata node to the metadata RMI port . * * @throws RemoteException */ void exportMetadataNodeStub ( ) throws RemoteException ; /* * * Initializes the metadata node and bootstraps the metadata . * * @param newUniverse * @throws Exception */
idGenerator . refresh ( ) ; if ( dsInfo . isDurable ( ) ) { synchronized ( logRecord ) { TransactionUtil . formFlushLogRecord ( logRecord , dsInfo . getDatasetID ( ) , null ) ; try { logManager . log ( logRecord ) ; } catch ( ACIDException e ) { throw new HyracksDataException ( "could not write flush log while closing dataset" , e ) ; } try { // notification will come from LogBuffer class ( notifyFlushTerminator ) logRecord . wait ( ) ; } catch ( InterruptedException e ) { < |startfocus| > throw new HyracksDataException ( e ) ; < |endfocus| > } } } for ( ILSMIndex index : indexes ) { // update resource lsn AbstractLSMIOOperationCallback ioOpCallback = ( AbstractLSMIOOperationCallback ) index . getIOOperationCallback ( ) ; ioOpCallback . updateLastLSN ( logRecord . getLSN ( ) ) ; } if ( asyncFlush ) { for ( ILSMIndex index : indexes ) { ILSMIndexAccessor accessor = index . createAccessor ( NoOpIndexAccessParameters . INSTANCE ) ; accessor . scheduleFlush ( index . getIOOperationCallback ( ) ) ; } } else { for ( ILSMIndex index : indexes ) { // TODO : This is not efficient since we flush the indexes sequentially .
idGenerator . refresh ( ) ; if ( dsInfo . isDurable ( ) ) { synchronized ( logRecord ) { TransactionUtil . formFlushLogRecord ( logRecord , dsInfo . getDatasetID ( ) , null ) ; try { logManager . log ( logRecord ) ; } catch ( ACIDException e ) { throw new HyracksDataException ( "could not write flush log while closing dataset" , e ) ; } try { // notification will come from LogBuffer class ( notifyFlushTerminator ) logRecord . wait ( ) ; } catch ( InterruptedException e ) { < |startfocus| > Thread . currentThread ( ) . interrupt ( ) ; < |endfocus| > } } } for ( ILSMIndex index : indexes ) { // update resource lsn AbstractLSMIOOperationCallback ioOpCallback = ( AbstractLSMIOOperationCallback ) index . getIOOperationCallback ( ) ; ioOpCallback . updateLastLSN ( logRecord . getLSN ( ) ) ; } if ( asyncFlush ) { for ( ILSMIndex index : indexes ) { ILSMIndexAccessor accessor = index . createAccessor ( NoOpIndexAccessParameters . INSTANCE ) ; accessor . scheduleFlush ( index . getIOOperationCallback ( ) ) ; } } else { for ( ILSMIndex index : indexes ) { // TODO : This is not efficient since we flush the indexes sequentially .
this . setMemoryAllocated ( false ) ; } @Override public void touch ( ) { super . touch ( ) ; setLastAccess ( System . currentTimeMillis ( ) ) ; } @Override public void untouch ( ) { super . untouch ( ) ; setLastAccess ( System . currentTimeMillis ( ) ) ; } public synchronized void declareActiveIOOperation ( ) { numActiveIOOps ++ ; } public synchronized void undeclareActiveIOOperation ( ) { numActiveIOOps -- ; // notify threads waiting on this dataset info notifyAll ( ) ; } < |startfocus| > public synchronized Set < ILSMIndex > getDatasetPartitionOpenIndexes ( int partition ) { < |endfocus| > Set < ILSMIndex > indexSet = new HashSet < > ( ) ; Set < IndexInfo > partitionIndexInfos = this . partitionIndexes . get ( partition ) ; if ( partitionIndexInfos != null ) { for ( IndexInfo iInfo : partitionIndexInfos ) { if ( iInfo . isOpen ( ) ) { indexSet . add ( iInfo . getIndex ( ) ) ; } } } return indexSet ; } @Override public int compareTo ( DatasetInfo i ) { // sort by ( isOpen , referenceCount , lastAccess ) ascending , where true < false // // Example sort order : // -- -- -- -- -- -- -- -- -- -
public String toString ( ) { < |startfocus| > return "JID : [ " + getCcId ( ) + " ] " + getIdOnly ( ) ; < |endfocus| >
import java . util . Map ; import java . util . Set ; import org . apache . hyracks . api . application . ICCServiceContext ; import org . apache . hyracks . api . application . IClusterLifecycleListener ; import org . apache . hyracks . api . config . IApplicationConfig ; import org . apache . hyracks . api . config . IOption ; import org . apache . hyracks . api . context . ICCContext ; import org . apache . hyracks . api . exceptions . HyracksException ; import org . apache . hyracks . api . job . IJobLifecycleListener ; import org . apache . hyracks . api . job . JobId ; import org . apache . hyracks . api . job . JobSpecification ; import org . apache . hyracks . api . job . JobStatus ; < |startfocus| > import org . apache . hyracks . api . messages . IMessageBroker ; < |endfocus| > import org . apache . hyracks . api . service . IControllerService ; import org . apache . hyracks . control . cc . ClusterControllerService ; import org . apache . hyracks . control . common . application . ServiceContext ; import org . apache . hyracks . control . common . context . ServerContext ; import org . apache . hyracks . control . common . utils . HyracksThreadFactory ; import org . apache . hyracks . control . common . work . IResultCallback ; public class CCServiceContext extends ServiceContext implements ICCServiceContext { private final ICCContext ccContext ; protected final Set < String > initPendingNodeIds ; protected final Set < String > deinitPendingNodeIds ; protected IResultCallback < Object > initializationCallback ; protected IResultCallback < Object > deinitializationCallback ;
indexOnlyPlanInfo . setFirst ( false ) ; return ; } // index - only plan possible ? boolean isIndexOnlyPlan = false ; // secondary key field usage after the select ( join ) operators // This boolean is mainly used for R - Tree case since R - Tree index generates an MBR // and we can restore original point or rectangle from this MBR if an index is built on point or rectangle . < |startfocus| > boolean secondaryKeyFieldUsedAfterSelectOrJoinOp = indexOnlyPlanInfo . getSecond ( ) ; // Whether a post verification ( especially for R - Tree case ) is required after the secondary index search // ( e . g . , the shape of the given query is not a point or rectangle . // Then , we may need to apply the select again using the real polygon , not MBR of it to get the true // result , not a super - set of it . ) boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo . getThird ( ) ; // Does the given index can cover all search predicates ? boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo . getFourth ( ) ; // matched function expressions
// ( e . g . , the shape of the given query is not a point or rectangle . // Then , we may need to apply the select again using the real polygon , not MBR of it to get the true // result , not a super - set of it . ) boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo . getThird ( ) ; // Does the given index can cover all search predicates ? < |startfocus| > boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo . getFourth ( ) ; < |endfocus| > // matched function expressions List < IOptimizableFuncExpr > matchedFuncExprs = analysisCtx . getMatchedFuncExprs ( ) ; // logical variables that select ( join ) operator is using List < LogicalVariable > usedVarsInSelJoinOp = new ArrayList < > ( ) ; List < LogicalVariable > usedVarsInSelJoinOpTemp = new ArrayList < > ( ) ; // live variables that select ( join ) operator can access List < LogicalVariable > liveVarsAfterSelJoinOp = new ArrayList < > ( ) ; // PK , record variable List < LogicalVariable > dataScanPKRecordVars ; List < LogicalVariable > dataScanPKVars = new ArrayList < > ( ) ; List < LogicalVariable > dataScanRecordVars = new ArrayList < > ( ) ; // Does the given index can cover all search predicates ? < |startfocus| > boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo . getFourth ( ) ; < |endfocus| >
public IScalarEvaluatorFactory createEvaluatorFactory ( final IScalarEvaluatorFactory [ ] args ) { return new IScalarEvaluatorFactory ( ) { private static final long serialVersionUID = 1L ; @Override @SuppressWarnings ( "unchecked" ) public IScalarEvaluator createScalarEvaluator ( final IHyracksTaskContext ctx ) throws HyracksDataException { return new IScalarEvaluator ( ) { < |startfocus| > private final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage ( ) ; private final DataOutput out = resultStorage . getDataOutput ( ) ; private final IPointable argPtr0 = new VoidPointable ( ) ; private final IScalarEvaluator eval0 = args [ 0 ] . createScalarEvaluator ( ctx ) ; private final AMutableInt32 intRes = new AMutableInt32 ( 0 ) ; < |endfocus| > @Override public void evaluate ( IFrameTupleReference tuple , IPointable result ) throws HyracksDataException { resultStorage . reset ( ) ; eval0 . evaluate ( tuple , argPtr0 ) ; try { byte [ ] bytes0 = argPtr0 . getByteArray ( ) ; int offset0 = argPtr0 . getStartOffset ( ) ; int len0 = argPtr0 . getLength ( ) ; ATypeTag tag = EnumDeserializer . ATYPETAGDESERIALIZER . deserialize ( bytes0 [ offset0 ] ) ; if ( tag != ATypeTag . GEOMETRY ) {
public IScalarEvaluatorFactory createEvaluatorFactory ( final IScalarEvaluatorFactory [ ] args ) { return new IScalarEvaluatorFactory ( ) { private static final long serialVersionUID = 1L ; @Override public IScalarEvaluator createScalarEvaluator ( IHyracksTaskContext ctx ) throws HyracksDataException { return new IScalarEvaluator ( ) { < |startfocus| > private ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage ( ) ; private DataOutput out = resultStorage . getDataOutput ( ) ; private IPointable inputArg = new VoidPointable ( ) ; private IScalarEvaluator eval = args [ 0 ] . createScalarEvaluator ( ctx ) ; < |endfocus| > @Override public void evaluate ( IFrameTupleReference tuple , IPointable result ) throws HyracksDataException { eval . evaluate ( tuple , inputArg ) ; byte [ ] data = inputArg . getByteArray ( ) ; int offset = inputArg . getStartOffset ( ) ; int len = inputArg . getLength ( ) ; if ( data [ offset ] != ATypeTag . SERIALIZED_BINARY_TYPE_TAG ) { throw new TypeMismatchException ( BuiltinFunctions . ST_GEOM_FROM_WKB , 0 , data [ offset ] , ATypeTag . SERIALIZED_BINARY_TYPE_TAG ) ; } try { out . writeByte ( ATypeTag . SERIALIZED_GEOMETRY_TYPE_TAG ) ; out . write ( data , offset + 1 , len - 1 ) ; result . set ( resultStorage ) ; } catch ( IOException e ) { throw HyracksDataException . create ( e ) ; } } } ; } } ; }
public IScalarEvaluatorFactory createEvaluatorFactory ( final IScalarEvaluatorFactory [ ] args ) { return new IScalarEvaluatorFactory ( ) { private static final long serialVersionUID = 1L ; @Override public IScalarEvaluator createScalarEvaluator ( IHyracksTaskContext ctx ) throws HyracksDataException { < |startfocus| > return new IScalarEvaluator ( ) { private ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage ( ) ; private DataOutput out = resultStorage . getDataOutput ( ) ; private IPointable inputArg = new VoidPointable ( ) ; private IScalarEvaluator eval = args [ 0 ] . createScalarEvaluator ( ctx ) ; < |endfocus| > @Override @SuppressWarnings ( "unchecked" ) public void evaluate ( IFrameTupleReference tuple , IPointable result ) throws HyracksDataException { eval . evaluate ( tuple , inputArg ) ; byte [ ] bytes = inputArg . getByteArray ( ) ; int offset = inputArg . getStartOffset ( ) ; int len = inputArg . getLength ( ) ; AOrderedListType type = new AOrderedListType ( BuiltinType . AGEOMETRY , null ) ; byte typeTag = inputArg . getByteArray ( ) [ inputArg . getStartOffset ( ) ] ; ISerializerDeserializer serde ; if ( typeTag == ATypeTag . SERIALIZED_ORDEREDLIST_TYPE_TAG ) { serde = new AOrderedListSerializerDeserializer ( type ) ; } else { throw new TypeMismatchException ( sourceLoc , getIdentifier ( ) , 0 , typeTag , ATypeTag . SERIALIZED_ORDEREDLIST_TYPE_TAG ) ; } try { OrderedListBuilder listBuilder = new OrderedListBuilder ( ) ; listBuilder . reset ( type ) ; for ( int i = 0 ; i < len ; i ++ ) { listBuilder . addItem ( bytes [ i + offset + 1 ] ) ; } listBuilder . write ( out , true ) ; result . set ( resultStorage ) ; } catch ( IOException e1 ) { throw new HyracksDataException ( e1 ) ; } } } ; } } ; }
public int hashCode ( ) { < |startfocus| > return Objects . hash ( first , second , third , fourth ) ; < |endfocus| >
public boolean equals ( Object o ) { if ( ! ( o instanceof Quadruple < ? , ? , ? , ? > ) ) { return false ; } < |startfocus| > Quadruple < ? , ? , ? , ? > quadRuple = ( Quadruple < ? , ? , ? , ? > ) o ; return Objects . equals ( first , quadRuple . first ) && Objects . equals ( second , quadRuple . second ) && Objects . equals ( third , quadRuple . third ) && Objects . equals ( fourth , quadRuple . fourth ) ; < |endfocus| >
public boolean hasNext ( ) { < |startfocus| > return currentElementIx < numElements ; < |endfocus| >
* KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . storage . common ; import java . util . Arrays ; import org . apache . hyracks . api . exceptions . HyracksDataException ; import org . apache . hyracks . dataflow . common . data . accessors . ITupleReference ; import org . apache . logging . log4j . Level ; import org . apache . logging . log4j . LogManager ; import org . apache . logging . log4j . Logger ; < |startfocus| > public class EnforcedIndexCursor implements IIndexCursor { < |endfocus| > enum State { CLOSED , OPENED , DESTROYED } private static final boolean STORE_TRACES = false ; private static final boolean ENFORCE_NEXT_HAS_NEXT = true ; private static final boolean ENFORCE_OPEN_CLOSE_DESTROY = true ; private static final Logger LOGGER = LogManager . getLogger ( ) ; private State state = State . CLOSED ; private StackTraceElement [ ] openCallStack ; private StackTraceElement [ ] destroyCallStack ; @Override public final void open ( ICursorInitialState initialState , ISearchPredicate searchPred ) throws HyracksDataException { if ( ENFORCE_OPEN_CLOSE_DESTROY && state != State . CLOSED ) {
private static final long serialVersionUID = 1L ; private static final int METADATA_DATASET_ID = MetadataPrimaryIndexes . PROPERTIES_METADATA . getDatasetId ( ) ; // shared between core and extension private IDatasetLifecycleManager datasetLifecycleManager ; private ITransactionSubsystem transactionSubsystem ; private int metadataStoragePartition ; // core only private transient MetadataTupleTranslatorProvider tupleTranslatorProvider ; // extension only private Map < ExtensionMetadataDatasetId , ExtensionMetadataDataset < ? > > extensionDatasets ; public static final MetadataNode INSTANCE = new MetadataNode ( ) ; private MetadataNode ( ) { super ( ) ; } < |startfocus| > public void initialize ( IAppRuntimeContext runtimeContext , < |endfocus| > MetadataTupleTranslatorProvider tupleTranslatorProvider , List < IMetadataExtension > metadataExtensions ) { this . tupleTranslatorProvider = tupleTranslatorProvider ; this . transactionSubsystem = runtimeContext . getTransactionSubsystem ( ) ; this . datasetLifecycleManager = runtimeContext . getDatasetLifecycleManager ( ) ; this . metadataStoragePartition = ( ( IPropertiesProvider ) runtimeContext ) . getMetadataProperties ( ) . getMetadataPartition ( ) . getPartitionId ( ) ; if ( metadataExtensions != null ) { extensionDatasets = new HashMap < > ( ) ; for ( IMetadataExtension metadataExtension : metadataExtensions ) { for ( ExtensionMetadataDataset < ? > extensionIndex : metadataExtension . getExtensionIndexes ( ) ) { < |startfocus| > extensionIndex . setTxnIdFactory ( transactionSubsystem . getTxnIdFactory ( ) ) ; < |endfocus| > extensionDatasets . put ( extensionIndex . getDatasetId ( ) , extensionIndex ) ; } } } }
import java . util . concurrent . atomic . AtomicLong ; import java . util . function . Supplier ; import org . apache . asterix . common . transactions . ILongBlockFactory ; import org . apache . asterix . common . transactions . ITxnIdFactory ; import org . apache . asterix . common . transactions . TxnId ; import org . apache . hyracks . algebricks . common . exceptions . AlgebricksException ; import org . apache . logging . log4j . LogManager ; import org . apache . logging . log4j . Logger ; /* * * Represents a factory to generate unique transaction IDs . */ < |startfocus| > /* package */ class CcTxnIdFactory implements ITxnIdFactory { private static int txnBlockSize = 10 ; < |endfocus| > private static final Logger LOGGER = LogManager . getLogger ( ) ; private final Supplier < ILongBlockFactory > blockFactorySupplier ; private volatile Block block = new Block ( 0 , 0 ) ; public CcTxnIdFactory ( Supplier < ILongBlockFactory > blockFactorySupplier ) { this . blockFactorySupplier = blockFactorySupplier ; } @Override public TxnId create ( ) throws AlgebricksException { while ( true ) { try { return new TxnId ( block . nextId ( ) ) ; } catch ( BlockExhaustedException ex ) { // retry
private static int TXN_BLOCK_SIZE = 10 ; private static final Logger LOGGER = LogManager . getLogger ( ) ; private final Supplier < ILongBlockFactory > blockFactorySupplier ; private volatile Block block = new Block ( 0 , 0 ) ; public CcTxnIdFactory ( Supplier < ILongBlockFactory > blockFactorySupplier ) { this . blockFactorySupplier = blockFactorySupplier ; } @Override public TxnId create ( ) throws AlgebricksException { while ( true ) { try { return new TxnId ( block . nextId ( ) ) ; } catch ( BlockExhaustedException ex ) { < |startfocus| > // retry < |endfocus| > block = new Block ( blockFactorySupplier . get ( ) . getBlock ( TXN_BLOCK_SIZE ) , TXN_BLOCK_SIZE ) ; } } } @Override public void ensureMinimumId ( long id ) throws AlgebricksException { blockFactorySupplier . get ( ) . ensureMinimum ( id ) ; } static class Block { private static final BlockExhaustedException BLOCK_EXHAUSTED_EXCEPTION = new BlockExhaustedException ( ) ; private final AtomicLong id ; private final long start ; private final long endExclusive ; private Block ( long start , long blockSize ) { this . id = new AtomicLong ( start ) ; this . start = start ; this . endExclusive = start + blockSize ; } long nextId ( ) throws BlockExhaustedException { long nextId = id . getAndIncrement ( ) ; if ( nextId >= endExclusive ) { throw BLOCK_EXHAUSTED_EXCEPTION ; } return nextId ; } } }
} @Override public ActiveManager getActiveManager ( ) { return activeManager ; } @Override public ReplicationProperties getReplicationProperties ( ) { return replicationProperties ; } @Override public IReplicationChannel getReplicationChannel ( ) { return replicationChannel ; } @Override public IReplicationManager getReplicationManager ( ) { return replicationManager ; } @Override public ILibraryManager getLibraryManager ( ) { return libraryManager ; } @Override public void initializeMetadata ( boolean newUniverse ) throws Exception { < |startfocus| > LOGGER . info ( "Bootstrapping metadata" ) ; < |endfocus| > MetadataNode . INSTANCE . initialize ( this , ncExtensionManager . getMetadataTupleTranslatorProvider ( ) , ncExtensionManager . getMetadataExtensions ( ) ) ; // noinspection unchecked ConcurrentHashMap < CcId , IAsterixStateProxy > proxyMap = ( ( ConcurrentHashMap < CcId , IAsterixStateProxy > ) getServiceContext ( ) . getDistributedState ( ) ) ; if ( proxyMap == null ) { throw new IllegalStateException ( "Metadata node cannot access distributed state" ) ; } // This is a special case , we just give the metadataNode directly . // This way we can delay the registration of the metadataNode until // it is completely initialized .
return replicationManager ; } @Override public ILibraryManager getLibraryManager ( ) { return libraryManager ; } @Override public void initializeMetadata ( boolean newUniverse ) throws Exception { Collection < IAsterixStateProxy > proxies ; LOGGER . info ( "Bootstrapping metadata" ) ; MetadataNode . INSTANCE . initialize ( this , ncExtensionManager . getMetadataTupleTranslatorProvider ( ) , ncExtensionManager . getMetadataExtensions ( ) ) ; < |startfocus| > // noinspection unchecked ConcurrentHashMap < CcId , IAsterixStateProxy > proxyMap = ( ConcurrentHashMap < CcId , IAsterixStateProxy > ) getServiceContext ( ) . getDistributedState ( ) ; if ( proxyMap == null ) { < |endfocus| > throw new IllegalStateException ( "Metadata node cannot access distributed state" ) ; } // This is a special case , we just give the metadataNode directly . // This way we can delay the registration of the metadataNode until // it is completely initialized . MetadataManager . initialize ( proxyMap . values ( ) , MetadataNode . INSTANCE ) ; MetadataBootstrap . startUniverse ( getServiceContext ( ) , newUniverse ) ; MetadataBootstrap . startDDLRecovery ( ) ; ncExtensionManager . initializeMetadata ( getServiceContext ( ) ) ; LOGGER . info ( "Metadata node bound" ) ; } @Override public synchronized void exportMetadataNodeStub ( ) throws RemoteException {
} } catch ( InterruptedException e ) { Thread . currentThread ( ) . interrupt ( ) ; throw HyracksDataException . create ( e ) ; } catch ( RemoteException e ) { throw new RuntimeDataException ( ErrorCode . REMOTE_EXCEPTION_WHEN_CALLING_METADATA_NODE , e ) ; } super . init ( ) ; } } private static class NCMetadataManagerImpl extends MetadataManager { public NCMetadataManagerImpl ( Collection < IAsterixStateProxy > proxies , IMetadataNode metadataNode ) { super ( proxies , metadataNode ) ; } @Override < |startfocus| > public MetadataTransactionContext beginTransaction ( ) throws RemoteException , ACIDException { < |endfocus| > TxnId txnId = new TxnId ( metadataNode . reserveTxnIdBlock ( 1 ) ) ; metadataNode . beginTransaction ( txnId ) ; return new MetadataTransactionContext ( txnId ) ; } } }
import java . util . concurrent . atomic . AtomicLong ; import java . util . function . Supplier ; import org . apache . asterix . common . transactions . ILongBlockFactory ; import org . apache . asterix . common . transactions . ITxnIdFactory ; import org . apache . asterix . common . transactions . TxnId ; import org . apache . hyracks . algebricks . common . exceptions . AlgebricksException ; import org . apache . logging . log4j . LogManager ; import org . apache . logging . log4j . Logger ; /* * * Represents a factory to generate unique transaction IDs . */ < |startfocus| > /* package */ class CcTxnIdFactory implements ITxnIdFactory { private static int TXN_BLOCK_SIZE = 10 ; < |endfocus| > private static final Logger LOGGER = LogManager . getLogger ( ) ; private final Supplier < ILongBlockFactory > blockFactorySupplier ; private volatile Block block = new Block ( 0 , 0 ) ; public CcTxnIdFactory ( Supplier < ILongBlockFactory > blockFactorySupplier ) { this . blockFactorySupplier = blockFactorySupplier ; } @Override public TxnId create ( ) throws AlgebricksException { while ( true ) { try { return new TxnId ( block . nextId ( ) ) ; } catch ( BlockExhaustedException ex ) { // retry
} @Override public synchronized void stop ( ) throws Exception { if ( ! shuttedDown ) { LOGGER . log ( Level . INFO , "Stopping NodeControllerService" ) ; executor . shutdownNow ( ) ; if ( ! executor . awaitTermination ( 10 , TimeUnit . SECONDS ) ) { LOGGER . log ( Level . SEVERE , "Some jobs failed to exit , continuing with abnormal shutdown" ) ; } partitionManager . close ( ) ; datasetPartitionManager . close ( ) ; netManager . stop ( ) ; datasetNetworkManager . stop ( ) ; < |startfocus| > if ( messagingNetManager != null ) { messagingNetManager . stop ( ) ; < |endfocus| > } workQueue . stop ( ) ; ncAppEntryPoint . stop ( ) ; /* * Stop heartbeat after NC has stopped to avoid false node failure detection * on CC if an NC takes a long time to stop . */ heartbeatTask . cancel ( ) ; LOGGER . log ( Level . INFO , "Stopped NodeControllerService" ) ; shuttedDown = true ; } } public String getId ( ) { return id ; } public ServerContext getServerContext ( ) { return serverCtx ; } public Map < JobId , Joblet > getJobletMap ( ) { return jobletMap ; } public void setJobletMap ( Map < JobId , Joblet > jobletMap ) { this . jobletMap = jobletMap ; }
} @Override public synchronized void stop ( ) throws Exception { if ( ! shuttedDown ) { LOGGER . log ( Level . INFO , "Stopping NodeControllerService" ) ; executor . shutdownNow ( ) ; if ( ! executor . awaitTermination ( 10 , TimeUnit . SECONDS ) ) { LOGGER . log ( Level . SEVERE , "Some jobs failed to exit , continuing with abnormal shutdown" ) ; } partitionManager . close ( ) ; datasetPartitionManager . close ( ) ; netManager . stop ( ) ; datasetNetworkManager . stop ( ) ; if ( messagingNetManager != null ) { messagingNetManager . stop ( ) ; } < |startfocus| > workQueue . stop ( ) ; ncAppEntryPoint . stop ( ) ; /* < |endfocus| > * Stop heartbeat after NC has stopped to avoid false node failure detection * on CC if an NC takes a long time to stop . */ heartbeatTask . cancel ( ) ; LOGGER . log ( Level . INFO , "Stopped NodeControllerService" ) ; shuttedDown = true ; } } public String getId ( ) { return id ; } public ServerContext getServerContext ( ) { return serverCtx ; } public Map < JobId , Joblet > getJobletMap ( ) { return jobletMap ; } public Map < JobId , Joblet > getJobletMap ( ) { return jobletMap ; }
// Scan diskInvertedIndexes ignoring the memoryInvertedIndex . // Create an inverted index instance . ILSMDiskComponent component = createDiskComponent ( componentFactory , mergeOp . getTarget ( ) , mergeOp . getDeletedKeysBTreeTarget ( ) , mergeOp . getBloomFilterTarget ( ) , true ) ; ILSMDiskComponentBulkLoader componentBulkLoader ; < |startfocus| > // In case we must keep the deleted - keys BTrees , then they must be merged * before * merging the inverted indexes so that // lsmHarness . endSearch ( ) is called once when the inverted indexes have been merged . < |endfocus| > if ( mergeOp . getMergingComponents ( ) . get ( mergeOp . getMergingComponents ( ) . size ( ) - 1 ) != diskComponents . get ( diskComponents . size ( ) - 1 ) ) { // Keep the deleted tuples since the oldest disk component is not included in the merge operation LSMInvertedIndexDeletedKeysBTreeMergeCursor btreeCursor = new LSMInvertedIndexDeletedKeysBTreeMergeCursor ( opCtx ) ; try { long numElements = 0L ; for ( int i = 0 ; i < mergeOp . getMergingComponents ( ) . size ( ) ; ++ i ) { numElements += ( ( LSMInvertedIndexDiskComponent ) mergeOp . getMergingComponents ( ) . get ( i ) ) . getDeletedKeysBTree ( ) . getCount ( ) ; }
private boolean isOpen ; < |startfocus| > private final Map < Long , List < StackTraceElement [ ] > > callers = new HashMap < > ( ) ; < |endfocus| > public Info ( ) { referenceCount = 0 ; isOpen = false ;
public void untouch ( ) { long tid = Thread . currentThread ( ) . getId ( ) ; List < StackTraceElement [ ] > caller = callers . get ( tid ) ; if ( caller == null || caller . isEmpty ( ) ) { throw new IllegalStateException ( "Untouch of an untouched resource by thread : " + tid ) ; } caller . remove ( caller . size ( ) - 1 ) ; < |startfocus| > -- referenceCount ; < |endfocus| >
public void touch ( ) { long tid = Thread . currentThread ( ) . getId ( ) ; if ( callers . containsKey ( tid ) ) { LOGGER . log ( Level . WARN , "\"Double touch of a resource by thread : " + tid + " . Previous call was from : " + Arrays . toString ( callers . get ( tid ) ) + " . This call is from : " + Arrays . toString ( new Throwable ( ) . getStackTrace ( ) ) ) ; throw new IllegalStateException ( "Double touch of a resource by thread : " + tid ) ; } < |startfocus| > callers . put ( tid , new Throwable ( ) . getStackTrace ( ) ) ; < |endfocus| > ++ referenceCount ;
* KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . api . dataflow ; import org . apache . hyracks . api . exceptions . HyracksDataException ; public interface IDestroyable { /* * * Destroy the object and releases any system resources associated * with it . If the object is already destroyed then invoking this * method has no effect . < |startfocus| > * All other calls after this method is invoked must throw exceptions < |endfocus| > * * @throws HyracksDataException */ void destroy ( ) throws HyracksDataException ; }
dest . add ( context . newVar ( ) ) ; } } /* * * Gets the primary key variables from the unnest - map or left - outer - unnest - map operator * that does a secondary index lookup . * The order : SK , PK , [ Optional : the result of a TryLock on PK ] */ public static List < LogicalVariable > getKeyVarsFromSecondaryUnnestMap ( Dataset dataset , ARecordType recordType , < |startfocus| > ARecordType metaRecordType , ILogicalOperator unnestMapOp , Index index , int keyType , boolean outputPrimaryKeysOnlyFromSIdxSearch ) throws AlgebricksException { < |endfocus| > int numPrimaryKeys ; int numSecondaryKeys = KeyFieldTypeUtil . getNumSecondaryKeys ( index , recordType , metaRecordType ) ; if ( dataset . getDatasetType ( ) == DatasetType . EXTERNAL ) { numPrimaryKeys = IndexingConstants . getRIDSize ( ( ( ExternalDatasetDetails ) dataset . getDatasetDetails ( ) ) . getProperties ( ) ) ; } else { numPrimaryKeys = dataset . getPrimaryKeys ( ) . size ( ) ; } List < LogicalVariable > keyVars = new ArrayList < > ( ) ; List < LogicalVariable > sourceVars = ( ( AbstractUnnestMapOperator ) unnestMapOp ) . getVariables ( ) ; // Assumption : the primary keys are located after the secondary key .
numPrimaryKeys = IndexingConstants . getRIDSize ( ( ( ExternalDatasetDetails ) dataset . getDatasetDetails ( ) ) . getProperties ( ) ) ; } else { numPrimaryKeys = dataset . getPrimaryKeys ( ) . size ( ) ; } List < LogicalVariable > keyVars = new ArrayList < > ( ) ; List < LogicalVariable > sourceVars = ( ( AbstractUnnestMapOperator ) unnestMapOp ) . getVariables ( ) ; // Assumption : the primary keys are located after the secondary key . int start ; int stop ; < |startfocus| > // If a secondary - index search didn't generate SKs if ( outputPrimaryKeysOnlyFromSIdxSearch ) { < |endfocus| > numSecondaryKeys = 0 ; } // Fetches keys : type 0 - PK , type 1 - SK , type 2 - the result of instantTryLock ( ) on PK switch ( keyType ) { case 0 : // Fetches primary keys - the second position start = numSecondaryKeys ; stop = numSecondaryKeys + numPrimaryKeys ; break ; case 1 : // Fetches secondary keys - the first position start = 0 ; stop = numSecondaryKeys ; break ; case 2 : // Fetches conditional splitter - the last position start = numSecondaryKeys + numPrimaryKeys ; stop = numSecondaryKeys + numPrimaryKeys + 1 ; break ; default : throw new IllegalStateException ( ) ; }
switch ( keyType ) { case 0 : // Fetches primary keys - the second position start = numSecondaryKeys ; stop = numSecondaryKeys + numPrimaryKeys ; break ; case 1 : // Fetches secondary keys - the first position start = 0 ; stop = numSecondaryKeys ; break ; case 2 : // Fetches conditional splitter - the last position start = numSecondaryKeys + numPrimaryKeys ; < |startfocus| > stop = start + 1 ; < |endfocus| > break ; default : return Collections . emptyList ( ) ; } for ( int i = start ; i < stop ; i ++ ) { keyVars . add ( sourceVars . get ( i ) ) ; } return keyVars ; } public static List < LogicalVariable > getPrimaryKeyVarsFromSecondaryUnnestMap ( Dataset dataset , ILogicalOperator unnestMapOp ) { int numPrimaryKeys ; if ( dataset . getDatasetType ( ) == DatasetType . EXTERNAL ) { numPrimaryKeys = IndexingConstants . getRIDSize ( ( ( ExternalDatasetDetails ) dataset . getDatasetDetails ( ) ) . getProperties ( ) ) ; } else { numPrimaryKeys = dataset . getPrimaryKeys ( ) . size ( ) ; } List < LogicalVariable > primaryKeyVars = new ArrayList < > ( ) ;
// If the constant type and target type does not match , we may need to do a type conversion . if ( constantValueTag != indexedFieldTypeTag && constantValue != null ) { // To check whether the constant is REAL values , and target field is an INT type field . // In this case , we need to change the search parameter . Refer to the caller section for the detail . realTypeConvertedToIntegerType = isRealTypeConvertedToIntegerType ( constantValueTag , indexedFieldTypeTag ) ; < |startfocus| > if ( realTypeConvertedToIntegerType && ! index . isEnforced ( ) && ! index . isOverridingKeyFieldTypes ( ) ) { < |endfocus| > // For the index on a closed - type field , // if a DOUBLE or FLOAT constant is converted to an INT type value , // we need to check a corner case where two real values are located // between an INT value . For example , the following query , // // for $emp in dataset empDataset // where $emp . age > double ( "2 . 3" ) and $emp . age < double ( "3 . 3" ) // return $emp . id ; //
mathFunctionTypeForNumericTypeCasting ) ; break ; case EQ : // equality case - both CEIL and FLOOR need to be applied . replacedConstantValue = getReplacedConstantValue ( constantValue . getObject ( ) , constantValueTag , indexedFieldTypeTag , index . isEnforced ( ) , TypeCastingMathFunctionType . FLOOR ) ; replacedConstantValueForEQCase = getReplacedConstantValue ( constantValue . getObject ( ) , constantValueTag , indexedFieldTypeTag , index . isEnforced ( ) , TypeCastingMathFunctionType . CEIL ) ; break ; default : break ; } < |startfocus| > } // Type conversion only case : ( e . g . , INT - > BIGINT ) if ( mathFunctionTypeForNumericTypeCasting == TypeCastingMathFunctionType . NONE ) { < |endfocus| > replacedConstantValue = getReplacedConstantValue ( constantValue . getObject ( ) , constantValueTag , indexedFieldTypeTag , index . isEnforced ( ) , TypeCastingMathFunctionType . NONE ) ; } } // No type - casting at all if ( replacedConstantValue == null ) { return new Triple < > ( constantAtRuntimeExpression , null , false ) ; } // A type - casting happened , but not EQ case if ( replacedConstantValueForEQCase == null ) { < |startfocus| > throw new IllegalStateException ( "NEQ is not expected here . " ) ; < |endfocus| > }
replacedConstantValueForEQCase = getReplacedConstantValue ( constantValue . getObject ( ) , constantValueTag , indexedFieldTypeTag , index . isEnforced ( ) , TypeCastingMathFunctionType . CEIL ) ; break ; default : break ; } } // Type conversion only case : ( e . g . , INT - > BIGINT ) if ( mathFunctionTypeForNumericTypeCasting == TypeCastingMathFunctionType . NONE ) { replacedConstantValue = getReplacedConstantValue ( constantValue . getObject ( ) , constantValueTag , indexedFieldTypeTag , index . isEnforced ( ) , TypeCastingMathFunctionType . NONE ) ; } < |startfocus| > < |endfocus| > } // No type - casting at all if ( replacedConstantValue == null ) { return new Triple < > ( constantAtRuntimeExpression , null , false ) ; } // A type - casting happened , but not EQ case if ( replacedConstantValueForEQCase == null ) { return new Triple < > ( new ConstantExpression ( replacedConstantValue ) , null , realTypeConvertedToIntegerType ) ; } // A type - casting happened and it's an EQ case . return new Triple < > ( new ConstantExpression ( replacedConstantValue ) , new ConstantExpression ( replacedConstantValueForEQCase ) , realTypeConvertedToIntegerType ) ; }
private final String nodeId ; private final List < INCLifecycleTask > tasks ; public RegistrationTasksResponseMessage ( String nodeId , List < INCLifecycleTask > tasks ) { this . nodeId = nodeId ; this . tasks = tasks ; } @Override public void handle ( INcApplicationContext appCtx ) throws HyracksDataException , InterruptedException { INCMessageBroker broker = ( INCMessageBroker ) appCtx . getServiceContext ( ) . getMessageBroker ( ) ; IControllerService cs = appCtx . getServiceContext ( ) . getControllerService ( ) ; < |startfocus| > cs . getExecutor ( ) . submit ( ( ) - > { boolean success = true ; try { Throwable exception = null ; try { for ( INCLifecycleTask task : tasks ) { if ( LOGGER . isInfoEnabled ( ) ) { LOGGER . log ( Level . INFO , "Starting startup task : " + task ) ; } task . perform ( getCcId ( ) , cs ) ; if ( LOGGER . isInfoEnabled ( ) ) { LOGGER . log ( Level . INFO , "Completed startup task : " + task ) ; } } } catch ( Throwable e ) { // NOSONAR all startup failures should be reported to CC LOGGER . log ( Level . ERROR , "Failed during startup task" , e ) ;
class CachingTxnIdFactory implements ITxnIdFactory { private static final Logger LOGGER = LogManager . getLogger ( ) ; private final INcApplicationContext appCtx ; private volatile Block block = new Block ( 0 , 0 ) ; public CachingTxnIdFactory ( INcApplicationContext appCtx ) { this . appCtx = appCtx ; } @Override public TxnId create ( ) throws AlgebricksException { while ( true ) { try { return new TxnId ( block . nextId ( ) ) ; } catch ( BlockExhaustedException ex ) { // retry LOGGER . info ( "block exhausted ; obtaining new block from supplier" ) ; < |startfocus| > TxnIdBlockRequestMessage . Block newBlock ; < |endfocus| > try { newBlock = TxnIdBlockRequestMessage . send ( appCtx ) ; } catch ( HyracksDataException e ) { LOGGER . error ( "Error while obtaining new block from supplier" , e ) ; throw new AlgebricksException ( e ) ; } block = new Block ( newBlock . getStartingId ( ) , newBlock . getBlockSize ( ) ) ; } } } @Override public void ensureMinimumId ( long id ) throws AlgebricksException { throw new UnsupportedOperationException ( ) ; } @Override public long getIdBlock ( int blockSize ) { throw new UnsupportedOperationException ( ) ; } @Override
( ( ClusterControllerService ) appCtx . getServiceContext ( ) . getControllerService ( ) ) . getJobIdFactory ( ) . setMaxJobId ( maxJobId ) ; } public static void send ( CcId ccId , NodeControllerService ncs ) throws HyracksDataException { INcApplicationContext appContext = ( INcApplicationContext ) ncs . getApplicationContext ( ) ; long maxResourceId = Math . max ( appContext . getLocalResourceRepository ( ) . maxId ( ) , MetadataIndexImmutableProperties . FIRST_AVAILABLE_USER_DATASET_ID ) ; < |startfocus| > long maxTxnId = appContext . getMaxTxnId ( ) ; < |endfocus| > long maxJobId = ncs . getMaxJobId ( ccId ) ; ReportLocalCountersMessage countersMessage = new ReportLocalCountersMessage ( ncs . getId ( ) , maxResourceId , maxTxnId , maxJobId ) ; try { ( ( INCMessageBroker ) ncs . getContext ( ) . getMessageBroker ( ) ) . sendMessageToCC ( ccId , countersMessage ) ; } catch ( Exception e ) { LOGGER . log ( Level . ERROR , "Unable to report local counters" , e ) ; throw HyracksDataException . create ( e ) ; } } @Override public String toString ( ) { return ReportLocalCountersMessage . class . getSimpleName ( ) ; } }
public static Throwable close ( ITupleForwarder tupleForwarder , Throwable root ) { if ( tupleForwarder != null ) { try { tupleForwarder . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be re - thrown try { LOGGER . log ( Level . WARN , "Failure closing a closeable resource" , th ) ; < |startfocus| > } catch ( Exception loggingFailure ) { // Do nothing < |endfocus| > } root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
public static Throwable close ( ITupleForwarder tupleForwarder , Throwable root ) { if ( tupleForwarder != null ) { try { tupleForwarder . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be re - thrown try { LOGGER . log ( Level . WARN , "Failure closing a closeable resource" , th ) ; < |startfocus| > } catch ( Throwable loggingFailure ) { // Do nothing } < |endfocus| > root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
* * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , * software distributed under the License is distributed on an * "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . api . dataflow ; import org . apache . hyracks . api . exceptions . HyracksDataException ; < |startfocus| > < |endfocus| > @FunctionalInterface public interface IDestroyable { /* * * Destroy the object and releases any system resources associated * with it . If the object is already destroyed then invoking this * method has no effect . * All other calls after this method is invoked is undefined * * @throws HyracksDataException */ void destroy ( ) throws HyracksDataException ; }
* KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . hyracks . api . dataflow ; import org . apache . hyracks . api . exceptions . HyracksDataException ; public interface IDestroyable { /* * * Destroy the object and releases any system resources associated * with it . If the object is already destroyed then invoking this * method has no effect . < |startfocus| > * All other calls after this method is invoked is undefined < |endfocus| > * * @throws HyracksDataException */ void destroy ( ) throws HyracksDataException ; }
public static Throwable destroy ( IDestroyable destroyable , Throwable root ) { if ( destroyable != null ) { try { destroyable . destroy ( ) ; } catch ( Throwable th ) { // NOSONAR . Had to be done to satisfy contracts try { LOGGER . log ( Level . WARN , "Failure destroying a destroyable resource" , th ) ; < |startfocus| > } catch ( Exception loggingFailure ) { < |endfocus| > // Do nothing } root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
public static Throwable destroy ( IDestroyable destroyable , Throwable root ) { if ( destroyable != null ) { try { destroyable . destroy ( ) ; } catch ( Throwable th ) { // NOSONAR . Had to be done to satisfy contracts try { LOGGER . log ( Level . WARN , "Failure destroying a destroyable resource" , th ) ; < |startfocus| > } catch ( Throwable loggingFailure ) { < |endfocus| > // Do nothing } root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
public static Throwable destroy ( IDestroyable destroyable , Throwable root ) { if ( destroyable != null ) { try { destroyable . destroy ( ) ; } catch ( Throwable th ) { // NOSONAR . Had to be done to satisfy contracts try { LOGGER . log ( Level . WARN , "Failure destroying a destroyable resource" , th ) ; } catch ( Throwable loggingFailure ) { // Do nothing } < |startfocus| > Throwable suppressed = ExceptionUtils . suppress ( root , th ) ; < |endfocus| > } } return root ;
public static Throwable close ( List < IIndexDataflowHelper > indexHelpers , Throwable root ) { for ( int i = 0 ; i < indexHelpers . size ( ) ; i ++ ) { < |startfocus| > Throwable t = close ( indexHelpers , root ) ; < |endfocus| > } return root ;
reusablePred . setHighKeyComparator ( predicate . getHighKeyComparator ( ) ) ; includeMutableComponent = false ; int numBTrees = operationalComponents . size ( ) ; if ( rangeCursors == null ) { // object creation : should be relatively low rangeCursors = new IIndexCursor [ numBTrees ] ; btreeAccessors = new BTreeAccessor [ numBTrees ] ; } else if ( rangeCursors . length != numBTrees ) { // should destroy first Throwable failure = ExceptionUtils . suppress ( DestroyUtils . destroy ( btreeAccessors ) , DestroyUtils . destroy ( rangeCursors ) ) ; < |startfocus| > if ( failure != null ) { throw HyracksDataException . create ( failure ) ; } < |endfocus| > rangeCursors = new IIndexCursor [ numBTrees ] ; btreeAccessors = new BTreeAccessor [ numBTrees ] ; } for ( int i = 0 ; i < numBTrees ; i ++ ) { ILSMComponent component = operationalComponents . get ( i ) ; BTree btree ; if ( component . getType ( ) == LSMComponentType . MEMORY ) { includeMutableComponent = true ; } btree = ( BTree ) component . getIndex ( ) ; if ( btreeAccessors [ i ] == null ) { btreeAccessors [ i ] = btree . createAccessor ( NoOpIndexAccessParameters . INSTANCE ) ; rangeCursors [ i ] = btreeAccessors [ i ] . createSearchCursor ( false ) ; } }
try { indexHelper . close ( ) ; } catch ( Throwable th ) { if ( closeException == null ) { closeException = new HyracksDataException ( th ) ; } else { closeException . addSuppressed ( th ) ; } } } try { // will definitely be called regardless of exceptions writer . close ( ) ; } catch ( Throwable th ) { if ( closeException == null ) { closeException = new HyracksDataException ( th ) ; } else { closeException . addSuppressed ( th ) ; } } if ( closeException != null ) { < |startfocus| > throw closeException ; < |endfocus| > } } @Override public void doFail ( ) throws HyracksDataException { writer . fail ( ) ; } }
indexHelper . close ( ) ; } catch ( Throwable th ) { if ( closeException == null ) { closeException = new HyracksDataException ( th ) ; } else { closeException . addSuppressed ( th ) ; } } } try { // will definitely be called regardless of exceptions writer . close ( ) ; } catch ( Throwable th ) { if ( closeException == null ) { closeException = new HyracksDataException ( th ) ; } else { closeException . addSuppressed ( th ) ; } } if ( closeException != null ) { < |startfocus| > throw closeException ; < |endfocus| > } } @Override public void doFail ( ) throws HyracksDataException { writer . fail ( ) ; } }
} } try { indexHelper . close ( ) ; } catch ( Throwable th ) { if ( closeException == null ) { closeException = new HyracksDataException ( th ) ; } else { closeException . addSuppressed ( th ) ; } } } try { // will definitely be called regardless of exceptions writer . close ( ) ; } catch ( Throwable th ) { if ( closeException == null ) { closeException = new HyracksDataException ( th ) ; } else { closeException . addSuppressed ( th ) ; } } if ( closeException != null ) { < |startfocus| > throw closeException ; < |endfocus| > } } @Override public void doFail ( ) throws HyracksDataException { writer . fail ( ) ; } }
. getLongValue ( ) ) ; file . setLastModefiedTime ( new Date ( ( ( ADateTime ) externalFileRecord . getValueByPos ( FilesIndexDescription . EXTERNAL_FILE_MOD_DATE_FIELD_INDEX ) ) . getChrononTime ( ) ) ) ; } public void close ( ) throws HyracksDataException { Throwable failure = ResourceReleaseUtils . close ( fileIndexSearchCursor , null ) ; failure = DestroyUtils . destroy ( fileIndexSearchCursor , failure ) ; failure = DestroyUtils . destroy ( fileIndexAccessor , failure ) ; failure = ResourceReleaseUtils . close ( indexDataflowHelper , failure ) ; < |startfocus| > HyracksDataException . throwIfNotNull ( failure ) ; < |endfocus| > } }
public static Throwable close ( ITupleForwarder tupleForwarder , Throwable root ) { if ( tupleForwarder != null ) { try { tupleForwarder . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be re - thrown try { LOGGER . log ( Level . WARN , "Failure closing a closeable resource" , th ) ; < |startfocus| > } catch ( Throwable loggingFailure ) { // Do nothing < |endfocus| > } root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
public static Throwable destroy ( IDestroyable destroyable , Throwable root ) { if ( destroyable != null ) { try { destroyable . destroy ( ) ; } catch ( Throwable th ) { // NOSONAR . Had to be done to satisfy contracts try { LOGGER . log ( Level . WARN , "Failure destroying a destroyable resource" , th ) ; < |startfocus| > } catch ( Throwable loggingFailure ) { < |endfocus| > // Do nothing } root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
try { rangeCursors [ i ] . destroy ( ) ; } catch ( Throwable th ) { // NOSONAR . Must destroy all cursors failure = ExceptionUtils . suppress ( failure , th ) ; } } rangeCursors = null ; } try { lsmHarness . endScanDiskComponents ( opCtx ) ; } catch ( Throwable th ) { // NOSONAR . Don't lose the root cause failure = ExceptionUtils . suppress ( failure , th ) ; } } foundNext = false ; < |startfocus| > ExceptionUtils . throwIfNotNull ( failure ) ; < |endfocus| > } @Override protected void setPriorityQueueComparator ( ) { if ( pqCmp == null || cmp != pqCmp . getMultiComparator ( ) ) { pqCmp = new PriorityQueueScanComparator ( cmp ) ; } } private class PriorityQueueScanComparator extends PriorityQueueComparator { public PriorityQueueScanComparator ( MultiComparator cmp ) { super ( cmp ) ; } @Override public int compare ( PriorityQueueElement elementA , PriorityQueueElement elementB ) { int result ; try { result = cmp . compare ( elementA . getTuple ( ) , elementB . getTuple ( ) ) ; if ( result != 0 ) { return result ; }
*/ package org . apache . asterix . test . base ; import org . apache . logging . log4j . LogManager ; import org . apache . logging . log4j . Logger ; import org . junit . rules . TestWatcher ; import org . junit . runner . Description ; /* * Traces method entry / exit to System . out ( or supplied PrintStream ) . To use , add the following to your test class : * * @Rule * public TestRule watcher = new TestMethodTracer ( ) ; * * @Rule < |startfocus| > * public TestRule watcher = new TestMethodTracer ( System . err ) ; < |endfocus| > */ public class TestMethodTracer extends TestWatcher { private static final Logger LOGGER = LogManager . getLogger ( ) ; @Override protected void starting ( Description description ) { LOGGER . info ( "### { } START" , description . getMethodName ( ) ) ; } @Override protected void failed ( Throwable e , Description description ) { LOGGER . info ( "### { } FAILED ( { } ) " , description . getMethodName ( ) , e . getClass ( ) . getName ( ) ) ; } @Override protected void succeeded ( Description description ) { LOGGER . info ( "### { } SUCCEEDED" , description . getMethodName ( ) ) ; } }
public static Throwable destroy ( IDestroyable destroyable , Throwable root ) { if ( destroyable != null ) { try { destroyable . destroy ( ) ; } catch ( Throwable th ) { // NOSONAR . Had to be done to satisfy contracts try { LOGGER . log ( Level . WARN , "Failure destroying a destroyable resource" , th ) ; } catch ( Exception ignore ) { // Do nothing } < |startfocus| > root = ExceptionUtils . suppress ( root , th ) ; < |endfocus| > } } return root ;
public static Throwable destroy ( IDestroyable destroyable , Throwable root ) { if ( destroyable != null ) { try { destroyable . destroy ( ) ; } catch ( Throwable th ) { // NOSONAR . Had to be done to satisfy contracts try { LOGGER . log ( Level . WARN , "Failure destroying a destroyable resource" , th ) ; } catch ( Throwable ignore ) { // Do nothing } root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
public static Throwable destroy ( IDestroyable destroyable , Throwable root ) { if ( destroyable != null ) { try { destroyable . destroy ( ) ; } catch ( Throwable th ) { // NOSONAR . Had to be done to satisfy contracts try { LOGGER . log ( Level . WARN , "Failure destroying a destroyable resource" , th ) ; } catch ( Throwable ignore ) { // Do nothing } < |startfocus| > Throwable suppressed = ExceptionUtils . suppress ( root , th ) ; < |endfocus| > } } return root ;
} public LSMBTreePointSearchCursor getInsertSearchCursor ( ) { return insertSearchCursor ; } public BTreeRangeSearchCursor getMemCursor ( ) { return memCursor ; } public LSMBTreeCursorInitialState getSearchInitialState ( ) { return searchInitialState ; } public MultiComparator getCmp ( ) { return cmp ; } @Override public void destroy ( ) throws HyracksDataException { if ( destroyed ) { return ; } destroyed = true ; Throwable failure = DestroyUtils . destroy ( null , mutableBTreeAccessors ) ; failure = DestroyUtils . destroy ( failure , mutableBTreeOpCtxs ) ; < |startfocus| > failure = DestroyUtils . destroy ( insertSearchCursor , failure ) ; failure = DestroyUtils . destroy ( memCursor , failure ) ; < |endfocus| > if ( failure != null ) { throw HyracksDataException . create ( failure ) ; } } }
public BTreeRangeSearchCursor getMemCursor ( ) { return memCursor ; } public LSMBTreeCursorInitialState getSearchInitialState ( ) { return searchInitialState ; } public MultiComparator getCmp ( ) { return cmp ; } @Override public void destroy ( ) throws HyracksDataException { if ( destroyed ) { return ; } destroyed = true ; Throwable failure = DestroyUtils . destroy ( null , mutableBTreeAccessors ) ; failure = DestroyUtils . destroy ( failure , mutableBTreeOpCtxs ) ; < |startfocus| > failure = DestroyUtils . destroy ( failure , insertSearchCursor ) ; failure = DestroyUtils . destroy ( failure , memCursor ) ; < |endfocus| > if ( failure != null ) { throw HyracksDataException . create ( failure ) ; } } }
return memCursor ; } public LSMBTreeCursorInitialState getSearchInitialState ( ) { return searchInitialState ; } public MultiComparator getCmp ( ) { return cmp ; } @Override public void destroy ( ) throws HyracksDataException { if ( destroyed ) { return ; } destroyed = true ; Throwable failure = DestroyUtils . destroy ( null , mutableBTreeAccessors ) ; failure = DestroyUtils . destroy ( failure , mutableBTreeOpCtxs ) ; < |startfocus| > failure = DestroyUtils . destroy ( insertSearchCursor , memCursor , failure ) ; < |endfocus| > if ( failure != null ) { throw HyracksDataException . create ( failure ) ; } } }
} Function f = new Function ( dataverse , getExternalFunctionFullName ( libraryName , function . getName ( ) . trim ( ) ) , args . size ( ) , args , function . getReturnType ( ) . trim ( ) , function . getDefinition ( ) . trim ( ) , library . getLanguage ( ) . trim ( ) , function . getFunctionType ( ) . trim ( ) , null ) ; MetadataManager . INSTANCE . addFunction ( mdTxnCtx , f ) ; if ( LOGGER . isInfoEnabled ( ) ) { < |startfocus| > LOGGER . info ( "Installed function : " + getExternalFunctionFullName ( libraryName , function . getName ( ) . trim ( ) ) ) ; < |endfocus| > } } } if ( LOGGER . isInfoEnabled ( ) ) { LOGGER . info ( "Installed functions in library : " + libraryName ) ; } // Add adapters if ( library . getLibraryAdapters ( ) != null ) { for ( LibraryAdapter adapter : library . getLibraryAdapters ( ) . getLibraryAdapter ( ) ) { String adapterFactoryClass = adapter . getFactoryClass ( ) . trim ( ) ; String adapterName = getExternalFunctionFullName ( libraryName , adapter . getName ( ) . trim ( ) ) ; AdapterIdentifier aid = new AdapterIdentifier ( dataverse , adapterName ) ; DatasourceAdapter dsa = new DatasourceAdapter ( aid , adapterFactoryClass ) ; MetadataManager . INSTANCE . addAdapter ( mdTxnCtx , dsa ) ; if ( LOGGER . isInfoEnabled ( ) ) { LOGGER . info ( "Installed adapter : " + adapterName ) ; } } } if ( LOGGER . isInfoEnabled ( ) ) { LOGGER . info ( "Installed adapters in library : " + libraryName ) ; } } catch ( Exception e ) { throw new AlgebricksException ( e ) ; } }
* specific language governing permissions and limitations * under the License . */ package org . apache . asterix . external . api ; import org . apache . asterix . external . library . java . JTypeTag ; import org . apache . hyracks . api . exceptions . HyracksDataException ; public interface IFunctionHelper { public IJObject getArgument ( int index ) ; public IJObject getResultObject ( ) ; public void setResult ( IJObject result ) throws HyracksDataException ; public boolean isValidResult ( ) ; public IJObject getObject ( JTypeTag jtypeTag ) throws HyracksDataException ; public void reset ( ) ; < |startfocus| > public String getParameter ( ) ; < |endfocus| > }
import org . apache . hyracks . data . std . api . IDataOutputProvider ; import org . apache . hyracks . data . std . api . IValueReference ; public class JavaFunctionHelper implements IFunctionHelper { private final IExternalFunctionInfo finfo ; private final IDataOutputProvider outputProvider ; private final IJObject [ ] arguments ; private IJObject resultHolder ; private final IObjectPool < IJObject , IAType > objectPool = new ListObjectPool < > ( JTypeObjectFactory . INSTANCE ) ; private final JObjectPointableVisitor pointableVisitor ; private final PointableAllocator pointableAllocator ; private final Map < Integer , TypeInfo > poolTypeInfo ; < |startfocus| > private final String [ ] parameters ; < |endfocus| > private boolean isValidResult = false ; public JavaFunctionHelper ( IExternalFunctionInfo finfo , IDataOutputProvider outputProvider , String [ ] parameters ) throws HyracksDataException { this . finfo = finfo ; this . outputProvider = outputProvider ; this . pointableVisitor = new JObjectPointableVisitor ( ) ; this . pointableAllocator = new PointableAllocator ( ) ; this . arguments = new IJObject [ finfo . getArgumentList ( ) . size ( ) ] ; int index = 0 ; for ( IAType param : finfo . getArgumentList ( ) ) { this . arguments [ index ++ ] = objectPool . allocate ( param ) ; } this . resultHolder = objectPool . allocate ( finfo . getReturnType ( ) ) ;
try { while ( true ) { pageCleanerPolicy . notifyCleanCycleStart ( this ) ; int curPage = 0 ; while ( true ) { synchronized ( cachedPages ) { if ( curPage >= cachedPages . size ( ) ) { break ; } CachedPage cPage = ( CachedPage ) cachedPages . get ( curPage ) ; if ( cPage != null ) { cleanPage ( cPage , false ) ; } } curPage ++ ; } if ( shutdownStart ) { break ; } pageCleanerPolicy . notifyCleanCycleFinish ( this ) ; } < |startfocus| > } catch ( Exception e ) { e . printStackTrace ( ) ; } finally { shutdownComplete = true ; notifyAll ( ) ; < |endfocus| > } } } @Override public void close ( ) { closed = true ; fifoWriter . destroyQueue ( ) ; synchronized ( cleanerThread ) { cleanerThread . shutdownStart = true ; cleanerThread . notifyAll ( ) ; while ( ! cleanerThread . shutdownComplete ) { try { cleanerThread . wait ( ) ; } catch ( InterruptedException e ) { e . printStackTrace ( ) ; } } } synchronized ( fileInfoMap ) { try {
synchronized ( cachedPages ) { if ( curPage >= cachedPages . size ( ) ) { break ; } CachedPage cPage = ( CachedPage ) cachedPages . get ( curPage ) ; if ( cPage != null ) { cleanPage ( cPage , false ) ; } } curPage ++ ; } if ( shutdownStart ) { break ; } pageCleanerPolicy . notifyCleanCycleFinish ( this ) ; } } catch ( Exception e ) { e . printStackTrace ( ) ; } finally { shutdownComplete = true ; notifyAll ( ) ; < |startfocus| > } < |endfocus| > } } @Override public void close ( ) { closed = true ; fifoWriter . destroyQueue ( ) ; synchronized ( cleanerThread ) { cleanerThread . shutdownStart = true ; cleanerThread . notifyAll ( ) ; while ( ! cleanerThread . shutdownComplete ) { try { cleanerThread . wait ( ) ; } catch ( InterruptedException e ) { e . printStackTrace ( ) ; } } } synchronized ( fileInfoMap ) { try { for ( Map . Entry < Integer , BufferedFileHandle > entry : fileInfoMap . entrySet ( ) ) { < |startfocus| >
public void close ( ) { closed = true ; fifoWriter . destroyQueue ( ) ; < |startfocus| > synchronized ( cleanerThread ) { cleanerThread . shutdownStart = true ; cleanerThread . notifyAll ( ) ; while ( ! cleanerThread . shutdownComplete ) { try { cleanerThread . wait ( ) ; } catch ( InterruptedException e ) { e . printStackTrace ( ) ; < |endfocus| > } } } synchronized ( fileInfoMap ) { try { for ( Map . Entry < Integer , BufferedFileHandle > entry : fileInfoMap . entrySet ( ) ) { boolean fileHasBeenDeleted = entry . getValue ( ) . fileHasBeenDeleted ( ) ; sweepAndFlush ( entry . getKey ( ) , ! fileHasBeenDeleted ) ; if ( ! fileHasBeenDeleted ) { ioManager . close ( entry . getValue ( ) . getFileHandle ( ) ) ; } } } catch ( HyracksDataException e ) { e . printStackTrace ( ) ; } fileInfoMap . clear ( ) ; }
CachedPage cPage = bucket . cachedPage ; bucket . cachedPage = bucket . cachedPage . next ; cPage . next = null ; } } } finally { bucket . bucketLock . unlock ( ) ; } } } private boolean invalidateIfFileIdMatch ( int fileId , CachedPage cPage , boolean flushDirtyPages ) throws HyracksDataException { if ( BufferedFileHandle . getFileId ( cPage . dpid ) == fileId ) { < |startfocus| > int pinCount = - 1 ; < |endfocus| > if ( cPage . dirty . get ( ) ) { if ( flushDirtyPages ) { write ( cPage ) ; } cPage . dirty . set ( false ) ; pinCount = cPage . pinCount . decrementAndGet ( ) ; } else { pinCount = cPage . pinCount . get ( ) ; } if ( pinCount > 0 ) { throw new IllegalStateException ( "Page " + BufferedFileHandle . getFileId ( cPage . dpid ) + " : " + BufferedFileHandle . getPageId ( cPage . dpid ) + " is pinned and file is being closed . Pincount is : " + pinCount + " Page is confiscated : " + cPage . confiscated ) ; } cPage . invalidate ( ) ; return true ; }
isFinishedSearch = true ; invListMerger . close ( ) ; finalSearchResult . finalizeWrite ( ) ; return true ; } return false ; } // Finished one partition for the both cases #1 and #2 . So , moves to the next partition . curPartIdx ++ ; if ( curPartIdx <= endPartIdx ) { boolean suitablePartFound = false ; for ( int i = curPartIdx ; i <= endPartIdx ; i ++ ) { // Prune partition because no element in it can satisfy the occurrence threshold . < |startfocus| > if ( partitionCursors [ i ] == null || partitionCursors [ i ] . size ( ) < occurrenceThreshold ) { < |endfocus| > continue ; } suitablePartFound = true ; curPartIdx = i ; break ; } // If no partition is availble to explore , we stop here . if ( ! suitablePartFound ) { isFinishedSearch = true ; invListMerger . close ( ) ; finalSearchResult . finalizeWrite ( ) ; return true ; } // Merge inverted lists of current partition . numPrefixLists = searchModifier . getNumPrefixLists ( occurrenceThreshold , partitionCursors [ curPartIdx ] . size ( ) ) ; invListMerger . reset ( ) ; finalSearchResult . resetBuffer ( ) ;
this . argTypes = argTypes ; this . failOnArgTypeMismatch = failOnArgTypeMismatch ; } @Override public IScalarEvaluator createScalarEvaluator ( final IHyracksTaskContext ctx ) throws HyracksDataException { final IScalarEvaluator [ ] argEvals = new IScalarEvaluator [ args . length ] ; final IPointable [ ] argPtrs = new IPointable [ args . length ] ; for ( int i = 0 ; i < args . length ; i ++ ) { argEvals [ i ] = args [ i ] . createScalarEvaluator ( ctx ) ; argPtrs [ i ] = new VoidPointable ( ) ; } return new IScalarEvaluator ( ) { < |startfocus| > final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage ( ) ; final DataOutput resultOutput = resultStorage . getDataOutput ( ) ; < |endfocus| > final ARecordVisitablePointable openRecordPointable = new ARecordVisitablePointable ( DefaultOpenFieldType . NESTED_OPEN_RECORD_TYPE ) ; final ARecordVisitablePointable [ ] argVisitablePointables ; final BitSet castRequired ; final ACastVisitor castVisitor ; final Triple < IVisitablePointable , IAType , Boolean > castVisitorArg ; final RecordBuilder outRecordBuilder = new RecordBuilder ( ) ; final BinaryEntry keyEntry = new BinaryEntry ( ) ; final BinaryEntry valEntry = new BinaryEntry ( ) ; final BinaryHashMap fieldMap = new BinaryHashMap ( ctx . getJobletContext ( ) . getServiceContext ( ) . getIoManager ( ) ) ;
final BitSet castRequired ; final ACastVisitor castVisitor ; final Triple < IVisitablePointable , IAType , Boolean > castVisitorArg ; final RecordBuilder outRecordBuilder = new RecordBuilder ( ) ; final BinaryEntry keyEntry = new BinaryEntry ( ) ; final BinaryEntry valEntry = new BinaryEntry ( ) ; final BinaryHashMap fieldMap = new BinaryHashMap ( TABLE_SIZE , TABLE_FRAME_SIZE , outRecordBuilder . getFieldNameHashFunction ( ) , outRecordBuilder . getFieldNameHashFunction ( ) , outRecordBuilder . getFieldNameComparator ( ) ) ; < |startfocus| > outRecordBuilder . reset ( openRecordPointable . getInputRecordType ( ) ) ; valEntry . set ( new byte [ 0 ] , 0 , 0 ) ; < |endfocus| > int argCount = argEvals . length ; ARecordVisitablePointable [ ] vp = new ARecordVisitablePointable [ argCount ] ; BitSet cr = new BitSet ( ) ; ACastVisitor cv = null ; Triple < IVisitablePointable , IAType , Boolean > ca = null ; for ( int i = 0 ; i < argCount ; i ++ ) { ARecordType argType = argTypes [ i ] ; if ( argType != null ) { vp [ i ] = new ARecordVisitablePointable ( argType ) ; if ( hasDerivedType ( argType . getFieldTypes ( ) ) ) {
import org . apache . hyracks . algebricks . core . algebra . operators . logical . visitors . VariableUtilities ; import org . apache . hyracks . algebricks . core . algebra . plan . ALogicalPlanImpl ; import org . apache . hyracks . algebricks . core . algebra . util . OperatorPropertiesUtil ; import org . apache . hyracks . api . exceptions . HyracksDataException ; import org . apache . hyracks . storage . am . lsm . invertedindex . tokenizers . DelimitedUTF8StringBinaryTokenizer ; /* * * Static helper functions for rewriting plans using indexes . */ public class AccessMethodUtils { // Output variable type from a secondary unnest - map < |startfocus| > enum SecondaryUnnestMapOutputVarType { < |endfocus| > PRIMARY_KEY , SECONDARY_KEY , CONDITIONAL_SPLIT_VAR } public static void appendPrimaryIndexTypes ( Dataset dataset , IAType itemType , IAType metaItemType , List < Object > target ) throws AlgebricksException { ARecordType recordType = ( ARecordType ) itemType ; ARecordType metaRecordType = ( ARecordType ) metaItemType ; target . addAll ( KeyFieldTypeUtil . getPartitoningKeyTypes ( dataset , recordType , metaRecordType ) ) ; // Adds data record type . target . add ( itemType ) ; // Adds meta record type if any . if ( dataset . hasMetaPart ( ) ) { target . add ( metaItemType ) ; } }
switch ( keyVarType ) { case PRIMARY_KEY : // Fetches primary keys - the second position start = numSecondaryKeys ; stop = numSecondaryKeys + numPrimaryKeys ; break ; case SECONDARY_KEY : // Fetches secondary keys - the first position start = 0 ; stop = numSecondaryKeys ; break ; case CONDITIONAL_SPLIT_VAR : // Sanity check - the given unnest map should generate this variable . if ( ! abstractUnnestMapOp . getGenerateCallBackProceedResultVar ( ) ) { < |startfocus| > throw CompilationException . create ( ErrorCode . CANNOT_GET_CONDITIONAL_SPLIT_KEY_VARIABLE ) ; < |endfocus| > } // Fetches conditional splitter - the last position start = numSecondaryKeys + numPrimaryKeys ; stop = start + 1 ; break ; default : return Collections . emptyList ( ) ; } for ( int i = start ; i < stop ; i ++ ) { keyVars . add ( sourceVars . get ( i ) ) ; } return keyVars ; } public static List < LogicalVariable > getPrimaryKeyVarsFromPrimaryUnnestMap ( Dataset dataset , ILogicalOperator unnestMapOp ) { int numPrimaryKeys = dataset . getPrimaryKeys ( ) . size ( ) ;
case UPDATE : case WRITE : case WRITE_RESULT : case INDEX_INSERT_DELETE_UPSERT : case INSERT_DELETE_UPSERT : case INTERSECT : return getOperatorRequiredMemory ( operator , frameSize ) ; case LEFT_OUTER_UNNEST_MAP : case UNNEST_MAP : // Since an inverted - index search requires certain amount of memory , needs to calculate // the memory size differently if the given index - search is an inverted - index search . long unnestMapMemorySize = frameSize ; if ( isInvertedIndexSearch ( ( AbstractUnnestMapOperator ) operator ) ) { < |startfocus| > unnestMapMemorySize = textSearchMemorySize + frameSize ; < |endfocus| > } return getOperatorRequiredMemory ( operator , unnestMapMemorySize ) ; case EXCHANGE : return getExchangeRequiredMemory ( ( ExchangeOperator ) operator ) ; case GROUP : return getOperatorRequiredMemory ( operator , groupByMemorySize ) ; case ORDER : return getOperatorRequiredMemory ( operator , sortMemorySize ) ; case INNERJOIN : case LEFTOUTERJOIN : return getOperatorRequiredMemory ( operator , joinMemorySize ) ; default : throw new IllegalStateException ( "Unrecognized operator : " + operator . getOperatorTag ( ) ) ; }
public static Throwable destroy ( Throwable root , IDestroyable . . . destroyables ) { for ( IDestroyable destroyable : destroyables ) { if ( destroyable != null ) { try { destroyable . destroy ( ) ; } catch ( Throwable th ) { // NOSONAR . Had to be done to satisfy contracts try { LOGGER . log ( Level . WARN , "Failure destroying a destroyable resource" , th ) ; } catch ( Throwable loggingFailure ) { // NOSONAR // Do nothing } < |startfocus| > Throwable suppressed = ExceptionUtils . suppress ( root , th ) ; < |endfocus| > } } } return root ;
public static Throwable close ( IFrameWriter writer , Throwable root ) { if ( writer != null ) { try { writer . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be re - thrown try { LOGGER . log ( Level . WARN , "Failure closing a closeable resource" , th ) ; } catch ( Throwable loggingFailure ) { // NOSONAR // Do nothing } < |startfocus| > Throwable suppressed = ExceptionUtils . suppress ( root , th ) ; < |endfocus| > } } return root ;
*/ String [ ] getPaths ( ) ; /* * * @return the context associated with this IServlet */ ConcurrentMap < String , Object > ctx ( ) ; /* * * handle the IServletRequest writing the response in the passed IServletResponse * * @param request * @param response */ void handle ( IServletRequest request , IServletResponse response ) ; /* * * @return the handler for channel close events */ < |startfocus| > default IChannelCloseHandler getChannelCloseHandler ( ) { return null ; < |endfocus| > } }
Collection < Task > tasks = joblet . getTaskMap ( ) . values ( ) ; for ( Task task : tasks ) { task . abort ( ) ; allTasks . add ( task ) ; } final JobId jobId = joblet . getJobId ( ) ; if ( dpm != null ) { dpm . abortReader ( jobId ) ; dpm . sweep ( jobId ) ; } ncs . getWorkQueue ( ) . schedule ( new CleanupJobletWork ( ncs , jobId , JobStatus . FAILURE ) ) ; } ) ; < |startfocus| > for ( int i = 0 ; i < allTasks . size ( ) ; i ++ ) { allTasks . get ( i ) . awaitCompletion ( ) ; } < |endfocus| > } }
import java . io . DataOutput ; import java . io . IOException ; import java . util . LinkedHashMap ; import java . util . Map ; public final class JRecord implements IJObject { private ARecordType recordType ; private IJObject [ ] fields ; private Map < String , IJObject > openFields ; RecordBuilder recordBuilder = new RecordBuilder ( ) ; ArrayBackedValueStorage fieldName = new ArrayBackedValueStorage ( ) ; ArrayBackedValueStorage fieldValue = new ArrayBackedValueStorage ( ) ; AMutableString nameString = new AMutableString ( "" ) ; < |startfocus| > private static final AStringSerializerDeserializer aStringSerDer = AStringSerializerDeserializer . INSTANCE ; < |endfocus| > public JRecord ( ARecordType recordType , IJObject [ ] fields ) { this . recordType = recordType ; this . fields = fields ; this . openFields = new LinkedHashMap < > ( ) ; } public JRecord ( ARecordType recordType , IJObject [ ] fields , LinkedHashMap < String , IJObject > openFields ) { this ( recordType , fields ) ; this . openFields = openFields ; } public void addField ( String fieldName , IJObject fieldValue ) throws HyracksDataException { int pos = getFieldPosByName ( fieldName ) ; if ( pos >= 0 ) {
< |startfocus| > public JRecord ( ARecordType recordType , IJObject [ ] fields , Map < String , IJObject > openFields ) { < |endfocus| > this ( recordType , fields ) ; this . openFields = openFields ;
return new ARecord ( mergedRecordType , mergedFields ) ; } @Override public void reset ( ) throws HyracksDataException { if ( openFields != null && ! openFields . isEmpty ( ) ) { openFields . clear ( ) ; } if ( fields != null ) { for ( IJObject field : fields ) { if ( field != null ) { field . reset ( ) ; } } } } < |startfocus| > public void reset ( IJObject [ ] fields , Map < String , IJObject > openFields ) throws HyracksDataException { < |endfocus| > this . reset ( ) ; this . fields = fields ; this . openFields = openFields ; } }
* * Unless required by applicable law or agreed to in writing , * software distributed under the License is distributed on an * "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . asterix . external . library . java . base . builtin ; import org . apache . asterix . om . types . BuiltinType ; import org . apache . asterix . om . types . IAType ; public abstract class JBuiltinType implements IJType { < |startfocus| > public static JBuiltinType JBooleanType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) {
* software distributed under the License is distributed on an * "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . asterix . external . library . java . base . builtin ; import org . apache . asterix . om . types . BuiltinType ; import org . apache . asterix . om . types . IAType ; public abstract class JBuiltinType implements IJType { < |startfocus| > public static final JBuiltinType JBooleanType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ;
* software distributed under the License is distributed on an * "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . asterix . external . library . java . base . builtin ; import org . apache . asterix . om . types . BuiltinType ; import org . apache . asterix . om . types . IAType ; public abstract class JBuiltinType implements IJType { < |startfocus| > private static final JBuiltinType JBooleanType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ;
* software distributed under the License is distributed on an * "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . asterix . external . library . java . base . builtin ; import org . apache . asterix . om . types . BuiltinType ; import org . apache . asterix . om . types . IAType ; public abstract class JBuiltinType implements IJType { < |startfocus| > public static JBuiltinType jBooleanType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ;
import org . apache . asterix . om . types . BuiltinType ; import org . apache . asterix . om . types . IAType ; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; < |startfocus| > public static final JBuiltinType JCircleType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) {
import org . apache . asterix . om . types . BuiltinType ; import org . apache . asterix . om . types . IAType ; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; < |startfocus| > public static final JBuiltinType JCircleType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) {
import org . apache . asterix . om . types . BuiltinType ; import org . apache . asterix . om . types . IAType ; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; < |startfocus| > public static JBuiltinType jCircleType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) {
public static JBuiltinType JBooleanType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; < |startfocus| > public static final JBuiltinType JDateType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ;
public static JBuiltinType JBooleanType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; < |startfocus| > private static final JBuiltinType JDateType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ;
public static JBuiltinType JBooleanType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; < |startfocus| > public static JBuiltinType jDateType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ;
} } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; < |startfocus| > public static final JBuiltinType JDateTimeType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ;
} } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; < |startfocus| > public static final JBuiltinType JDateTimeType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ;
} } ; public static JBuiltinType JByteType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; < |startfocus| > public static JBuiltinType jDateTimeType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ;
} } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; < |startfocus| > public static final JBuiltinType JDoubleType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ;
} } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; < |startfocus| > public static final JBuiltinType JDoubleType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ;
} } ; public static JBuiltinType JCircleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; < |startfocus| > public static JBuiltinType jDoubleType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ;
} } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; < |startfocus| > public static final JBuiltinType JDurationType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ;
} } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; < |startfocus| > public static final JBuiltinType JDurationType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ;
} } ; public static JBuiltinType JDateType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; < |startfocus| > public static JBuiltinType jDurationType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ;
} } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; < |startfocus| > public static final JBuiltinType JFloatType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ;
} } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; < |startfocus| > private static final JBuiltinType JFloatType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ;
} } ; public static JBuiltinType JDateTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; < |startfocus| > public static JBuiltinType jFloatType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ;
} } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; < |startfocus| > public static final JBuiltinType JIntType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ;
} } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; < |startfocus| > public static final JBuiltinType JIntType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ;
} } ; public static JBuiltinType JDoubleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADOUBLE ; } } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; < |startfocus| > public static JBuiltinType jIntType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ;
} } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; < |startfocus| > public static final JBuiltinType JIntervalType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ;
} } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; < |startfocus| > private static final JBuiltinType JIntervalType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ;
} } ; public static JBuiltinType JDurationType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; < |startfocus| > public static JBuiltinType jIntervalType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ;
} } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; < |startfocus| > public static final JBuiltinType JLineType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ;
} } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; < |startfocus| > private static final JBuiltinType JLineType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ;
} } ; public static JBuiltinType JFloatType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AFLOAT ; } } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; < |startfocus| > public static JBuiltinType jLineType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ;
} } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; < |startfocus| > public static final JBuiltinType JLongType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ;
} } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; < |startfocus| > public static final JBuiltinType JLongType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ;
} } ; public static JBuiltinType JIntType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT32 ; } } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; < |startfocus| > public static JBuiltinType jLongType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ;
} } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; < |startfocus| > public static final JBuiltinType JMissingType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ;
} } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; < |startfocus| > private static final JBuiltinType JMissingType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ;
} } ; public static JBuiltinType JIntervalType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; < |startfocus| > public static JBuiltinType jMissingType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ;
} } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; < |startfocus| > public static final JBuiltinType JNullType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ;
} } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; < |startfocus| > public static final JBuiltinType JNullType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ;
} } ; public static JBuiltinType JLineType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; < |startfocus| > public static JBuiltinType jNullType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ;
} } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; < |startfocus| > public static final JBuiltinType JPointType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ;
} } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; < |startfocus| > public static final JBuiltinType JPointType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ;
} } ; public static JBuiltinType JLongType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT64 ; } } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; < |startfocus| > public static JBuiltinType jPointType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ;
} } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; < |startfocus| > public static final JBuiltinType JPoint3DType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ;
} } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; < |startfocus| > public static final JBuiltinType JPoint3DType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ;
} } ; public static JBuiltinType JMissingType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AMISSING ; } } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; < |startfocus| > public static JBuiltinType jPoint3DType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ;
} } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; < |startfocus| > public static final JBuiltinType JPolygonType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ;
} } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; < |startfocus| > private static final JBuiltinType JPolygonType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ;
} } ; public static JBuiltinType JNullType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ANULL ; } } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; < |startfocus| > public static JBuiltinType jPolygonType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ;
} } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; < |startfocus| > public static final JBuiltinType JRectangleType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; public static JBuiltinType JTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
} } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; < |startfocus| > private static final JBuiltinType JRectangleType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; public static JBuiltinType JTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
} } ; public static JBuiltinType JPointType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT ; } } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; < |startfocus| > public static JBuiltinType jRectangleType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; public static JBuiltinType JTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
} } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; < |startfocus| > public static final JBuiltinType JShortType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; public static JBuiltinType JTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
} } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; < |startfocus| > public static final JBuiltinType JShortType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; public static JBuiltinType JTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
} } ; public static JBuiltinType JPoint3DType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; < |startfocus| > public static JBuiltinType jShortType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; public static JBuiltinType JTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
} } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; < |startfocus| > public static final JBuiltinType JStringType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; public static JBuiltinType JTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
} } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; < |startfocus| > public static final JBuiltinType JStringType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; public static JBuiltinType JTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
} } ; public static JBuiltinType JPolygonType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . APOLYGON ; } } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; < |startfocus| > public static JBuiltinType jStringType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; public static JBuiltinType JTimeType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
} } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; < |startfocus| > public static final JBuiltinType JTimeType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
} } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; < |startfocus| > private static final JBuiltinType JTimeType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
} } ; public static JBuiltinType JRectangleType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ARECTANGLE ; } } ; public static JBuiltinType JShortType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . AINT8 ; } } ; public static JBuiltinType JStringType = new JBuiltinType ( ) { @Override public IAType getIAType ( ) { return BuiltinType . ASTRING ; } } ; < |startfocus| > public static JBuiltinType JTimeType = new JBuiltinType ( ) { < |endfocus| > @Override public IAType getIAType ( ) { return BuiltinType . ATIME ; } } ; }
( ( AMutableCircle ) value ) . setValue ( ( APoint ) center . getIAObject ( ) , radius ) ; } @Override public IAType getIAType ( ) { return BuiltinType . ACIRCLE ; } @Override public void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException { if ( writeTypeTag ) { try { dataOutput . writeByte ( ATypeTag . CIRCLE . serialize ( ) ) ; } catch ( IOException e ) { throw new HyracksDataException ( e ) ; } } < |startfocus| > ACircleSerializerDeserializer . INSTANCE . serialize ( ( ( AMutableCircle ) value ) , dataOutput ) ; < |endfocus| > } @Override public void reset ( ) { ( ( AMutableCircle ) value ) . setValue ( null , 0 ) ; } }
public JDate ( int chrononTimeInDays ) { super ( new AMutableDate ( chrononTimeInDays ) ) ; } public void setValue ( int chrononTimeInDays ) { ( ( AMutableDate ) value ) . setValue ( chrononTimeInDays ) ; } @Override public void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException { if ( writeTypeTag ) { try { dataOutput . writeByte ( ATypeTag . DATE . serialize ( ) ) ; } catch ( IOException e ) { throw new HyracksDataException ( e ) ; } } < |startfocus| > ADateSerializerDeserializer . INSTANCE . serialize ( ( AMutableDate ) value , dataOutput ) ; < |endfocus| > } @Override public void reset ( ) { ( ( AMutableDate ) value ) . setValue ( 0 ) ; } @Override public IAType getIAType ( ) { return BuiltinType . ADATE ; } }
public JDateTime ( long chrononTime ) { super ( new AMutableDateTime ( chrononTime ) ) ; } public void setValue ( long chrononTime ) { ( ( AMutableDateTime ) value ) . setValue ( chrononTime ) ; } @Override public void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException { if ( writeTypeTag ) { try { dataOutput . writeByte ( ATypeTag . DATETIME . serialize ( ) ) ; } catch ( IOException e ) { throw new HyracksDataException ( e ) ; } } < |startfocus| > ADateTimeSerializerDeserializer . INSTANCE . serialize ( ( AMutableDateTime ) value , dataOutput ) ; < |endfocus| > } @Override public void reset ( ) { ( ( AMutableDateTime ) value ) . setValue ( 0 ) ; } @Override public IAType getIAType ( ) { return BuiltinType . ADATETIME ; } }
super ( new AMutableDuration ( months , milliseconds ) ) ; } public void setValue ( int months , long milliseconds ) { ( ( AMutableDuration ) value ) . setValue ( months , milliseconds ) ; } @Override public void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException { if ( writeTypeTag ) { try { dataOutput . writeByte ( ATypeTag . DURATION . serialize ( ) ) ; } catch ( IOException e ) { throw new HyracksDataException ( e ) ; } } < |startfocus| > ADurationSerializerDeserializer . INSTANCE . serialize ( ( AMutableDuration ) value , dataOutput ) ; < |endfocus| > } @Override public void reset ( ) { ( ( AMutableDuration ) value ) . setValue ( 0 , 0 ) ; } @Override public IAType getIAType ( ) { return BuiltinType . ADURATION ; } }
} public long getIntervalEnd ( ) { return ( ( AMutableInterval ) value ) . getIntervalEnd ( ) ; } public short getIntervalType ( ) { return ( ( AMutableInterval ) value ) . getIntervalType ( ) ; } @Override public void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException { if ( writeTypeTag ) { try { dataOutput . writeByte ( ATypeTag . INTERVAL . serialize ( ) ) ; } catch ( IOException e ) { throw new HyracksDataException ( e ) ; } } < |startfocus| > AIntervalSerializerDeserializer . INSTANCE . serialize ( ( AMutableInterval ) value , dataOutput ) ; < |endfocus| > } @Override public void reset ( ) throws HyracksDataException { ( ( AMutableInterval ) value ) . setValue ( 0L , 0L , ( byte ) 0 ) ; } @Override public IAType getIAType ( ) { return BuiltinType . AINTERVAL ; } }
} public void setValue ( APoint p1 , APoint p2 ) { ( ( AMutableLine ) value ) . setValue ( p1 , p2 ) ; } @Override public void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException { if ( writeTypeTag ) { try { dataOutput . writeByte ( ATypeTag . LINE . serialize ( ) ) ; } catch ( IOException e ) { throw new HyracksDataException ( e ) ; } } < |startfocus| > ALineSerializerDeserializer . INSTANCE . serialize ( ( AMutableLine ) value , dataOutput ) ; < |endfocus| > } @Override public void reset ( ) { ( ( AMutableLine ) value ) . setValue ( null , null ) ; } @Override public IAType getIAType ( ) { return BuiltinType . ALINE ; } }
< |startfocus| > public void reset ( ) { // TODO : implement this method } < |endfocus| >
public double getYValue ( ) { return ( ( AMutablePoint3D ) value ) . getY ( ) ; } public double getZValue ( ) { return ( ( AMutablePoint3D ) value ) . getZ ( ) ; } @Override public void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException { if ( writeTypeTag ) { try { dataOutput . writeByte ( ATypeTag . POINT3D . serialize ( ) ) ; } catch ( IOException e ) { throw new HyracksDataException ( e ) ; } } < |startfocus| > APoint3DSerializerDeserializer . INSTANCE . serialize ( ( AMutablePoint3D ) value , dataOutput ) ; < |endfocus| > } @Override public void reset ( ) { ( ( AMutablePoint3D ) value ) . setValue ( 0 , 0 , 0 ) ; } @Override public IAType getIAType ( ) { return BuiltinType . APOINT3D ; } }
builder . appendString ( String . valueOf ( i ) ) ; break ; } case BIGINT : { long l = AInt64SerializerDeserializer . getLong ( serString , startOffset ) ; builder . appendString ( String . valueOf ( l ) ) ; break ; } case DOUBLE : { double d = ADoubleSerializerDeserializer . getDouble ( serString , startOffset ) ; if ( Double . isNaN ( d ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( d == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; } else if ( d == Double . NEGATIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } else { builder . appendString ( String . valueOf ( d ) ) ; } break ; } case FLOAT : { float f = AFloatSerializerDeserializer . getFloat ( serString , startOffset ) ; if ( Float . isNaN ( f ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( f == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; } else if ( f == Double . NEGATIVE_INFINITY ) {
break ; } case BIGINT : { long l = AInt64SerializerDeserializer . getLong ( serString , startOffset ) ; builder . appendString ( String . valueOf ( l ) ) ; break ; } case DOUBLE : { double d = ADoubleSerializerDeserializer . getDouble ( serString , startOffset ) ; if ( Double . isNaN ( d ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( d == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; < |startfocus| > } else if ( d == Double . NEGATIVE_INFINITY ) { < |endfocus| > builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } else { builder . appendString ( String . valueOf ( d ) ) ; } break ; } case FLOAT : { float f = AFloatSerializerDeserializer . getFloat ( serString , startOffset ) ; if ( Float . isNaN ( f ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( f == Float . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; } else if ( f == Float . NEGATIVE_INFINITY ) {
} else if ( d == Double . NEGATIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } else { builder . appendString ( String . valueOf ( d ) ) ; } break ; } case FLOAT : { float f = AFloatSerializerDeserializer . getFloat ( serString , startOffset ) ; if ( Float . isNaN ( f ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( f == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; < |startfocus| > } else if ( f == Double . NEGATIVE_INFINITY ) { < |endfocus| > builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } else { builder . appendString ( String . valueOf ( f ) ) ; } break ; } case BOOLEAN : { boolean b = ABooleanSerializerDeserializer . getBoolean ( serString , startOffset ) ; builder . appendString ( String . valueOf ( b ) ) ; break ; } // NotYetImplemented case CIRCLE : case DATE : case DATETIME : case LINE : case TIME : case DURATION : case YEARMONTHDURATION : case DAYTIMEDURATION : case INTERVAL : case ARRAY : case POINT :
builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } else { builder . appendString ( String . valueOf ( d ) ) ; } break ; } case FLOAT : { float f = AFloatSerializerDeserializer . getFloat ( serString , startOffset ) ; if ( Float . isNaN ( f ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( f == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; < |startfocus| > } else if ( f == Double . NEGATIVE_INFINITY ) { < |endfocus| > builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } else { builder . appendString ( String . valueOf ( f ) ) ; } break ; } case BOOLEAN : { boolean b = ABooleanSerializerDeserializer . getBoolean ( serString , startOffset ) ; builder . appendString ( String . valueOf ( b ) ) ; break ; } // NotYetImplemented case CIRCLE : case DATE : case DATETIME : case LINE : case TIME : case DURATION : case YEARMONTHDURATION : case DAYTIMEDURATION : case INTERVAL : case ARRAY : case POINT : case POINT3D : case RECTANGLE : case POLYGON : case STRING :
builder . appendString ( String . valueOf ( i ) ) ; break ; } case BIGINT : { long l = AInt64SerializerDeserializer . getLong ( serString , startOffset ) ; builder . appendString ( String . valueOf ( l ) ) ; break ; } case DOUBLE : { double d = ADoubleSerializerDeserializer . getDouble ( serString , startOffset ) ; if ( Double . isNaN ( d ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( d == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; < |startfocus| > } else if ( d == Double . NEGATIVE_INFINITY ) { < |endfocus| > builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } else { builder . appendString ( String . valueOf ( d ) ) ; } break ; } case FLOAT : { float f = AFloatSerializerDeserializer . getFloat ( serString , startOffset ) ; if ( Float . isNaN ( f ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( f == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; } else if ( f == Double . NEGATIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } else { builder . appendString ( String . valueOf ( f ) ) ; } break ; } case BOOLEAN : { boolean b = ABooleanSerializerDeserializer . getBoolean ( serString , startOffset ) ; builder . appendString ( String . valueOf ( b ) ) ; break ; } case DATETIME : { long chrononTimeInMs = ADateTimeSerializerDeserializer . getChronon ( serString , startOffset ) ; builder . appendString ( ATypeHierarchy . convertDatetimeToString ( chrononTimeInMs ) ) ; break ; } case DATE : { int chrononTimeInDay = ADateSerializerDeserializer . getChronon ( serString , startOffset ) ; builder . appendString ( ATypeHierarchy . convertDateToString ( chrononTimeInDay ) ) ; break ; } case TIME : { int chrononTimeInMs = ATimeSerializerDeserializer . getChronon ( serString , startOffset ) ; builder . appendString ( ATypeHierarchy . convertTimeToString ( chrononTimeInMs ) ) ; break ; } case DURATION : { long chrononDuration = ADurationSerializerDeserializer . getChrononDuration ( serString , startOffset ) ; builder . appendString ( ATypeHierarchy . convertDurationToString ( chrononDuration ) ) ; break ; } case YEARMONTHDURATION : { int months = AYearMonthDurationSerializerDeserializer . getYearMonth ( serString , startOffset ) ; builder . appendString ( ATypeHierarchy . convertYearMonthDurationToString ( months ) ) ; break ; } case DAYTIMEDURATION : { long millis = ADayTimeDurationSerializerDeserializer . getDayTime ( serString , startOffset ) ; builder . appendString ( ATypeHierarchy . convertDayTimeDurationToString ( millis ) ) ; break ; } case POINT : { builder . appendString ( APointSerializerDeserializer . getString ( serString , startOffset ) ) ; break ; } case POINT3D : { builder . appendString ( APoint3DSerializerDeserializer . getString ( serString , startOffset ) ) ; break ; } case CIRCLE : { builder . appendString ( ACircleSerializerDeserializer . getString ( serString , startOffset ) ) ; break ; } case RECTANGLE : { builder . appendString ( ARectangleSerializerDeserializer . getString ( serString , startOffset ) ) ; break ; } case LINE : { builder . appendString ( ALineSerializerDeserializer . getString ( serString , startOffset ) ) ; break ; } case POLYGON : { builder . appendString ( APolygonSerializerDeserializer . getString ( serString , startOffset ) ) ; break ; } case SYSTEM_NULL : { builder . appendString ( ANullSerializerDeserializer . NULL_STRING ) ; break ; } default : { throw new NotImplementedException ( "Cannot convert " + serString . getItemType ( ) + " to string . " ) ; } } }
} else if ( d == Double . NEGATIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } else { builder . appendString ( String . valueOf ( d ) ) ; } break ; } case FLOAT : { float f = AFloatSerializerDeserializer . getFloat ( serString , startOffset ) ; if ( Float . isNaN ( f ) ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NAN ) ; } else if ( f == Double . POSITIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . POSITIVE_INF ) ; } else if ( f == Double . NEGATIVE_INFINITY ) { builder . appendUtf8StringPointable ( AbstractDoubleConstructorEvaluator . NEGATIVE_INF ) ; } else { builder . appendString ( String . valueOf ( f ) ) ; } break ; } case BOOLEAN : { boolean b = ABooleanSerializerDeserializer . getBoolean ( serString , startOffset ) ; builder . appendString ( String . valueOf ( b ) ) ; break ; } // NotYetImplemented case CIRCLE : case DATE : case DATETIME : case LINE : case TIME : case DURATION : case YEARMONTHDURATION : case DAYTIMEDURATION : case INTERVAL : case ARRAY : case POINT :
completeOperation ( index , opType , searchCallback , modificationCallback ) ; } } @Override public synchronized void completeOperation ( ILSMIndex index , LSMOperationType opType , ISearchOperationCallback searchCallback , IModificationOperationCallback modificationCallback ) throws HyracksDataException { if ( opType == LSMOperationType . MODIFICATION || opType == LSMOperationType . FORCE_MODIFICATION ) { decrementNumActiveOperations ( modificationCallback ) ; < |startfocus| > flushIfNeeded ( ) ; < |endfocus| > } else if ( opType == LSMOperationType . FLUSH || opType == LSMOperationType . MERGE || opType == LSMOperationType . REPLICATE ) { dsInfo . undeclareActiveIOOperation ( ) ; } } public synchronized void flushIfNeeded ( ) throws HyracksDataException { if ( numActiveOperations . get ( ) == 0 ) { flushIfRequested ( ) ; } } public void flushIfRequested ( ) throws HyracksDataException { // If we need a flush , and this is the last completing operation , then schedule the flush ,
public static Throwable close ( AutoCloseable closable , Throwable root ) { if ( closable != null ) { try { closable . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be re - thrown try { LOGGER . log ( Level . WARN , "Failure closing a closeable resource" , th ) ; < |startfocus| > } catch ( Exception loggingFailure ) { // Do nothing < |endfocus| > } root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
public static Throwable close ( AutoCloseable closable , Throwable root ) { if ( closable != null ) { try { closable . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be re - thrown try { LOGGER . log ( Level . WARN , "Failure closing a closeable resource" , th ) ; < |startfocus| > } catch ( Throwable loggingFailure ) { // Do nothing < |endfocus| > } root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
public static Throwable close ( AutoCloseable closable , Throwable root ) { if ( closable != null ) { try { closable . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be re - thrown try { LOGGER . log ( Level . WARN , "Failure closing a closeable resource" , th ) ; } catch ( Throwable loggingFailure ) { // Do nothing } < |startfocus| > Throwable root2 = ExceptionUtils . suppress ( root , th ) ; < |endfocus| > } } return root ;
} public void write ( IFileHandle fHandle , long offset , ByteBuffer data ) throws HyracksDataException { if ( state != State . INITIAL ) { throw new IllegalStateException ( "Can't request a read operation through a " + state + " request" ) ; } state = State . WRITE_REQUESTED ; this . fHandle = fHandle ; this . offset = offset ; this . data = data ; queue ( ) ; } private void queue ( ) throws HyracksDataException { try { submittedRequests . put ( this ) ; < |startfocus| > } catch ( InterruptedException e ) { < |endfocus| > throw HyracksDataException . create ( e ) ; } } @Override public void await ( ) throws InterruptedException { synchronized ( this ) { while ( state != State . OPERATION_FAILED && state != State . OPERATION_SUCCEEDED ) { wait ( ) ; } } } synchronized void handle ( ) { try { if ( state == State . READ_REQUESTED ) { read = ioManager . doSyncRead ( fHandle , offset , data ) ; } else if ( state == State . WRITE_REQUESTED ) { if ( data != null ) { // single buffer
read = ioManager . doSyncRead ( fHandle , offset , data ) ; } else if ( state == State . WRITE_REQUESTED ) { if ( data != null ) { // single buffer write = ioManager . doSyncWrite ( fHandle , offset , data ) ; } else { // multiple buffers writes = ioManager . doSyncWrite ( fHandle , offset , dataArray ) ; } } else { throw new IllegalStateException ( "IO Request with state = " + state ) ; } state = State . OPERATION_SUCCEEDED ; < |startfocus| > } catch ( Exception th ) { < |endfocus| > state = State . OPERATION_FAILED ; failure = HyracksDataException . create ( th ) ; } notifyAll ( ) ; } public State getState ( ) { return state ; } void recycle ( ) { reset ( ) ; freeRequests . offer ( this ) ; } public int getRead ( ) { return read ; } public int getWrite ( ) { return write ; } public long getWrites ( ) { return writes ; } @Override public void run ( ) throws InterruptedException { await ( ) ; } public HyracksDataException getFailure ( ) { return failure ;
public void run ( ) { Thread . currentThread ( ) . setName ( getClass ( ) . getSimpleName ( ) + " - " + num ) ; < |startfocus| > while ( true ) { < |endfocus| > IoRequest next ; try { next = queue . take ( ) ; } catch ( InterruptedException e ) { LOGGER . log ( Level . WARN , "Ignoring interrupt . IO threads should never be interrupted . " ) ; continue ; } if ( next == POISON_PILL ) { LOGGER . log ( Level . INFO , "Exiting" ) ; InvokeUtil . doUninterruptibly ( ( ) - > queue . put ( POISON_PILL ) ) ; if ( Thread . interrupted ( ) ) { LOGGER . log ( Level . ERROR , "Ignoring interrupt . IO threads should never be interrupted . " ) ; } continue ; } next . handle ( ) ; }
public void run ( ) { Thread . currentThread ( ) . setName ( getClass ( ) . getSimpleName ( ) + " - " + num ) ; while ( true ) { IoRequest next ; try { next = queue . take ( ) ; < |startfocus| > } catch ( InterruptedException e ) { < |endfocus| > LOGGER . log ( Level . WARN , "Ignoring interrupt . IO threads should never be interrupted . " ) ; continue ; } if ( next == POISON_PILL ) { LOGGER . log ( Level . INFO , "Exiting" ) ; InvokeUtil . doUninterruptibly ( ( ) - > queue . put ( POISON_PILL ) ) ; if ( Thread . interrupted ( ) ) { LOGGER . log ( Level . ERROR , "Ignoring interrupt . IO threads should never be interrupted . " ) ; } break ; } next . handle ( ) ; } }
public static Throwable close ( AutoCloseable closable , Throwable root ) { if ( closable != null ) { try { closable . close ( ) ; < |startfocus| > } catch ( Throwable th ) { // NOSONAR Will be re - thrown < |endfocus| > try { LOGGER . log ( Level . WARN , "Failure closing a closeable resource" , th ) ; } catch ( Throwable loggingFailure ) { // Do nothing } root = ExceptionUtils . suppressed ( root , th ) ; } } return root ;
public static Throwable close ( AutoCloseable closable , Throwable root ) { if ( closable != null ) { try { closable . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be re - thrown try { LOGGER . log ( Level . WARN , "Failure closing a closeable resource" , th ) ; < |startfocus| > } catch ( Throwable loggingFailure ) { // Do nothing < |endfocus| > } root = ExceptionUtils . suppress ( root , th ) ; } } return root ;
executor . execute ( req ) ; return req ; } @Override public void close ( IFileHandle fHandle ) throws HyracksDataException { try { ( ( FileHandle ) fHandle ) . close ( ) ; } catch ( IOException e ) { throw new HyracksDataException ( e ) ; } } public synchronized FileReference createWorkspaceFile ( String prefix ) throws HyracksDataException { IODeviceHandle dev = workAreaIODevices . get ( workAreaDeviceIndex ) ; workAreaDeviceIndex = ( workAreaDeviceIndex + 1 ) % workAreaIODevices . size ( ) ; String waPath = dev . getWorkAreaPath ( ) ; File waf ; try { < |startfocus| > waf = File . createTempFile ( prefix , WORKSPACE_FILE_SUFFIX , new File ( dev . getPath ( ) , waPath ) ) ; < |endfocus| > } catch ( IOException e ) { throw new HyracksDataException ( e ) ; } return dev . createFileReference ( waPath + File . separator + waf . getName ( ) ) ; } private abstract class AsyncRequest implements IIOFuture , Runnable { protected final FileHandle fHandle ; protected final long offset ; protected final ByteBuffer data ; private boolean complete ; private HyracksDataException exception ; private int result ; private
public void run ( ) { Thread . currentThread ( ) . setName ( getClass ( ) . getSimpleName ( ) + " - " + num ) ; while ( true ) { IoRequest next ; try { next = queue . take ( ) ; < |startfocus| > } catch ( InterruptedException e ) { < |endfocus| > LOGGER . log ( Level . WARN , "Ignoring interrupt . IO threads should never be interrupted . " ) ; continue ; } if ( next == POISON_PILL ) { LOGGER . log ( Level . INFO , "Exiting" ) ; InvokeUtil . doUninterruptibly ( ( ) - > queue . put ( POISON_PILL ) ) ; if ( Thread . interrupted ( ) ) { LOGGER . log ( Level . ERROR , "Ignoring interrupt . IO threads should never be interrupted . " ) ; } break ; } next . handle ( ) ; } }
boolean finishConnect = false ; try { finishConnect = channel . finishConnect ( ) ; } catch ( IOException e ) { key . cancel ( ) ; synchronized ( connectionListener ) { connectionListener . connectionFailure ( ( InetSocketAddress ) key . attachment ( ) , e ) ; } } if ( finishConnect ) { createConnection ( key , channel ) ; } } } } } catch ( Exception e ) { LOGGER . error ( ( ) - > new ParameterizedMessage ( "Error in TCPEndpoint { } " , localAddress ) , e ) ; } }
TestHelper . deleteExistingInstanceFiles ( ) ; String configPath = System . getProperty ( "user . dir" ) + File . separator + "src" + File . separator + "test" + File . separator + "resources" + File . separator + "cc . conf" ; nc = new TestNodeController ( configPath , false ) ; nc . init ( ) ; ncAppCtx = nc . getAppRuntimeContext ( ) ; dsLifecycleMgr = ncAppCtx . getDatasetLifecycleManager ( ) ; } @AfterClass public static void tearDown ( ) throws Exception { nc . deInit ( ) ; TestHelper . deleteExistingInstanceFiles ( ) ; } @Before public void createIndex ( ) throws Exception { PrimaryIndexInfo primaryIndexInfo = StorageTestUtils . createPrimaryIndex ( nc , PARTITION ) ; IndexDataflowHelperFactory iHelperFactory = new IndexDataflowHelperFactory ( nc . getStorageManager ( ) , primaryIndexInfo . getFileSplitProvider ( ) ) ; JobId jobId = nc . newJobId ( ) ; ctx = nc . createTestContext ( jobId , PARTITION , false ) ; indexDataflowHelper = iHelperFactory . create ( ctx . getJobletContext ( ) . getServiceContext ( ) , PARTITION ) ; indexDataflowHelper . open ( ) ; lsmBtree = ( TestLsmBtree ) indexDataflowHelper . getIndexInstance ( ) ;
< |startfocus| > public void testRollbackWhileNoOp ( ) { < |endfocus| > try { // allow all operations StorageTestUtils . allowAllOps ( lsmBtree ) ; // ensure no disk component and memory component is empty Assert . assertEquals ( 0 , lsmBtree . getDiskComponents ( ) . size ( ) ) ; Assert . assertFalse ( lsmBtree . isMemoryComponentsAllocated ( ) ) ; MutableArrayValueReference key = new MutableArrayValueReference ( "FlushMetadataOnlyTestKey" . getBytes ( ) ) ; MutableArrayValueReference value = new MutableArrayValueReference ( "FlushMetadataOnlyTestValue" . getBytes ( ) ) ; indexDataflowHelper . open ( ) ; ILSMIndexAccessor accessor = lsmBtree . createAccessor ( NoOpIndexAccessParameters . INSTANCE ) ; accessor . updateMeta ( key , value ) ; Assert . assertTrue ( lsmBtree . isMemoryComponentsAllocated ( ) ) ; Assert . assertTrue ( lsmBtree . getCurrentMemoryComponent ( ) . isModified ( ) ) ; indexDataflowHelper . close ( ) ; // flush synchronously StorageTestUtils . flush ( dsLifecycleMgr , lsmBtree , false ) ; // assert one disk component Assert . assertEquals ( 1 , lsmBtree . getDiskComponents ( ) . size ( ) ) ; VoidPointable pointable = VoidPointable . FACTORY . createPointable ( ) ; ComponentUtils . get ( lsmBtree , key , pointable ) ; Assert . assertTrue ( DataUtils . equals ( pointable , value ) ) ; // ensure that we can search this component
< |startfocus| > public static boolean equalsValue ( IValueReference first , IValueReference second ) { < |endfocus| > if ( first . getLength ( ) != second . getLength ( ) ) { return false ; } return equalsInRange ( first . getByteArray ( ) , first . getStartOffset ( ) , second . getByteArray ( ) , second . getStartOffset ( ) , first . getLength ( ) ) ;
private static TestLsmBtree lsmBtree ; private static NCAppRuntimeContext ncAppCtx ; private static IDatasetLifecycleManager dsLifecycleMgr ; private static IHyracksTaskContext ctx ; private static IIndexDataflowHelper indexDataflowHelper ; private static final int PARTITION = 0 ; @BeforeClass public static void setUp ( ) throws Exception { TestHelper . deleteExistingInstanceFiles ( ) ; < |startfocus| > String configPath = FilePath . joinPath ( System . getProperty ( "user . dir" ) , "src" , "test" , "resources" , "cc . conf" ) ; < |endfocus| > nc = new TestNodeController ( configPath , false ) ; nc . init ( ) ; ncAppCtx = nc . getAppRuntimeContext ( ) ; dsLifecycleMgr = ncAppCtx . getDatasetLifecycleManager ( ) ; } @AfterClass public static void tearDown ( ) throws Exception { System . out . println ( "TearDown" ) ; nc . deInit ( ) ; TestHelper . deleteExistingInstanceFiles ( ) ; } @Before public void createIndex ( ) throws Exception { PrimaryIndexInfo primaryIndexInfo = StorageTestUtils . createPrimaryIndex ( nc , PARTITION ) ; IndexDataflowHelperFactory iHelperFactory =
ncSection = ccini . add ( sectionName ) ; } if ( ncConfig . getString ( NCConfig . Option . CLUSTER_ADDRESS ) == null ) { ncSection . put ( NCConfig . Option . CLUSTER_ADDRESS . ini ( ) , ccs . getCCConfig ( ) . getClusterPublicAddress ( ) ) ; ncSection . put ( NCConfig . Option . CLUSTER_PORT . ini ( ) , String . valueOf ( ccs . getCCConfig ( ) . getClusterPublicPort ( ) ) ) ; } // if not already configured , set GC max pause time millis to not exceed 1 / 2 the total max heartbeat miss period . . . String ncJvmArgs = ncConfig . getString ( NCConfig . Option . JVM_ARGS ) ; < |startfocus| > if ( ncJvmArgs == null || ! ncJvmArgs . contains ( " - XX : MaxGCPauseMillis" ) ) { String gcMaxPauseArg = " - XX : MaxGCPauseMillis = " + getGcMaxPauseMillis ( ) ; < |endfocus| > ncSection . put ( NCConfig . Option . JVM_ARGS . ini ( ) , ncJvmArgs == null ? gcMaxPauseArg : ncJvmArgs + " " + gcMaxPauseArg ) ; } // Finally insert * this * NC's name into localnc section - this is a fixed // entry point so that NCs can determine where all their config is .
ncSection . put ( NCConfig . Option . CLUSTER_PORT . ini ( ) , String . valueOf ( ccs . getCCConfig ( ) . getClusterPublicPort ( ) ) ) ; } // if not already configured , set GC max pause time millis to not exceed 1 / 2 the total max heartbeat miss period . . . String ncJvmArgs = ncConfig . getString ( NCConfig . Option . JVM_ARGS ) ; < |startfocus| > if ( ncJvmArgs == null || ! ncJvmArgs . contains ( Review : ) ) { String gcMaxPauseArg = " - XX : MaxGCPauseMillis = " + getGcMaxPauseMillis ( ) ; < |endfocus| > ncSection . put ( NCConfig . Option . JVM_ARGS . ini ( ) , ncJvmArgs == null ? gcMaxPauseArg : ncJvmArgs + " " + gcMaxPauseArg ) ; } // Finally insert * this * NC's name into localnc section - this is a fixed // entry point so that NCs can determine where all their config is . ccini . put ( Section . LOCALNC . sectionName ( ) , NCConfig . Option . NODE_ID . ini ( ) , ncId ) ; ccini . store ( iniString ) ; if ( LOGGER . isDebugEnabled ( ) ) { LOGGER . debug ( "Returning Ini file : \n" + iniString . toString ( ) ) ; } return iniString . toString ( ) ;
public List < String > getFunctionParameters ( String dataverseName , String fullFunctionName ) { < |startfocus| > return externalFunctionParameters . getOrDefault ( dataverseName + " . " + fullFunctionName , Collections . emptyList ( ) ) ; < |endfocus| >
String functionReturnType = function . getReturnType ( ) . trim ( ) ; String functionDefinition = function . getDefinition ( ) . trim ( ) ; String functionLanguage = library . getLanguage ( ) . trim ( ) ; String functionType = function . getFunctionType ( ) . trim ( ) ; List < String > args = new ArrayList < > ( ) ; for ( String arg : fargs ) { args . add ( arg ) ; } < |startfocus| > FunctionSignature signature = new FunctionSignature ( dataverse , functionFullName , args . size ( ) ) ; < |endfocus| > Function f = new Function ( signature , args , functionReturnType , functionDefinition , functionLanguage , functionType , null ) ; MetadataManager . INSTANCE . addFunction ( mdTxnCtx , f ) ; if ( LOGGER . isInfoEnabled ( ) ) { LOGGER . info ( "Installed function : " + functionFullName ) ; } } } if ( LOGGER . isInfoEnabled ( ) ) { LOGGER . info ( "Installed functions in library : " + libraryName ) ; } // Add adapters if ( library . getLibraryAdapters ( ) != null ) { for ( LibraryAdapter adapter : library . getLibraryAdapters ( ) . getLibraryAdapter ( ) ) {
configManager . set ( nodeId , NCConfig . Option . NCSERVICE_PORT , NCConfig . NCSERVICE_PORT_DISABLED ) ; final INCApplication ncApplication = createNCApplication ( ) ; ConfigManager ncConfigManager ; if ( confFile == null ) { ncConfigManager = new ConfigManager ( ) ; } else { ncConfigManager = new ConfigManager ( new String [ ] { " - config - file" , confFile } ) ; } ncApplication . registerConfig ( ncConfigManager ) ; < |startfocus| > opts . forEach ( opt - > ncConfigManager . set ( nodeId , opt . getLeft ( ) , opt . getRight ( ) ) ) ; < |endfocus| > nodeControllers . add ( new NodeControllerService ( fixupIODevices ( createNCConfig ( nodeId , ncConfigManager ) ) , ncApplication ) ) ; } opts . stream ( ) . forEach ( opt - > configManager . set ( opt . getLeft ( ) , opt . getRight ( ) ) ) ; cc . start ( ) ; // Starts ncs . nodeNames = ccConfig . getConfigManager ( ) . getNodeNames ( ) ; List < Thread > startupThreads = new ArrayList < > ( ) ; for ( NodeControllerService nc : nodeControllers ) { Thread ncStartThread = new Thread ( "IntegrationUtil - " + nc . getId ( ) ) { @Override public void run ( ) { try { nc . start ( ) ;
throws Exception { flushPartition ( dslLifecycleMgr , lsmBtree , DATASET , async ) ; } public static void flushPartition ( IDatasetLifecycleManager dslLifecycleMgr , TestLsmBtree lsmBtree , Dataset dataset , boolean async ) throws Exception { waitForOperations ( lsmBtree ) ; PrimaryIndexOperationTracker opTracker = ( PrimaryIndexOperationTracker ) lsmBtree . getOperationTracker ( ) ; opTracker . setFlushOnExit ( true ) ; opTracker . flushIfNeeded ( ) ; long maxWaitTime = 60000L ; // 1min // wait for log record is flushed , i . e . , the flush is scheduled < |startfocus| > long before = System . currentTimeMillis ( ) ; < |endfocus| > while ( opTracker . isFlushLogCreated ( ) ) { Thread . sleep ( 5 ) ; // NOSONAR : Test code with a timeout if ( System . currentTimeMillis ( ) - before > maxWaitTime ) { throw new IllegalStateException ( ( System . currentTimeMillis ( ) - before ) + "ms passed without scheduling the flush operation" ) ; } } if ( ! async ) { DatasetInfo dsInfo = dslLifecycleMgr . getDatasetInfo ( dataset . getDatasetId ( ) ) ; dsInfo . waitForIO ( ) ; } }
throws Exception { flushPartition ( dslLifecycleMgr , lsmBtree , DATASET , async ) ; } public static void flushPartition ( IDatasetLifecycleManager dslLifecycleMgr , TestLsmBtree lsmBtree , Dataset dataset , boolean async ) throws Exception { waitForOperations ( lsmBtree ) ; PrimaryIndexOperationTracker opTracker = ( PrimaryIndexOperationTracker ) lsmBtree . getOperationTracker ( ) ; opTracker . setFlushOnExit ( true ) ; opTracker . flushIfNeeded ( ) ; long maxWaitTime = 60000L ; // 1min // wait for log record is flushed , i . e . , the flush is scheduled < |startfocus| > long before = System . nanoTime ( ) ; < |endfocus| > while ( opTracker . isFlushLogCreated ( ) ) { Thread . sleep ( 5 ) ; // NOSONAR : Test code with a timeout if ( System . nanoTime ( ) - before > maxWaitTime ) { throw new IllegalStateException ( ( System . nanoTime ( ) - before ) + "ms passed without scheduling the flush operation" ) ; } } if ( ! async ) { DatasetInfo dsInfo = dslLifecycleMgr . getDatasetInfo ( dataset . getDatasetId ( ) ) ; dsInfo . waitForIO ( ) ; } }
* harness callback simply . */ public class StubIOOperationCallback implements ILSMIOOperationCallback { private ILSMIndexOperationContext opCtx = null ; @Override public void beforeOperation ( ILSMIndexOperationContext opCtx ) throws HyracksDataException { // Not interested in this } @Override public void afterOperation ( ILSMIndexOperationContext opCtx ) throws HyracksDataException { this . opCtx = opCtx ; } @Override < |startfocus| > public void afterFinalize ( ILSMIndexOperationContext opCtx ) throws HyracksDataException { < |endfocus| > } public List < ILSMDiskComponent > getLastOldComponents ( ) { return opCtx . getComponentsToBeMerged ( ) ; } public ILSMDiskComponent getLastNewComponent ( ) { return opCtx . getNewComponent ( ) ; } @Override public void recycled ( ILSMMemoryComponent component , boolean componentSwitched ) { // Not interested in this } @Override public void allocated ( ILSMMemoryComponent component ) { // Not interested in this } }
* harness callback simply . */ public class StubIOOperationCallback implements ILSMIOOperationCallback { private ILSMIndexOperationContext opCtx = null ; @Override public void beforeOperation ( ILSMIndexOperationContext opCtx ) throws HyracksDataException { // Not interested in this } @Override public void afterOperation ( ILSMIndexOperationContext opCtx ) throws HyracksDataException { this . opCtx = opCtx ; } @Override < |startfocus| > public void afterFinalize ( ILSMIndexOperationContext opCtx ) throws HyracksDataException { // Redundant info from after < |endfocus| > } public List < ILSMDiskComponent > getLastOldComponents ( ) { return opCtx . getComponentsToBeMerged ( ) ; } public ILSMDiskComponent getLastNewComponent ( ) { return opCtx . getNewComponent ( ) ; } @Override public void recycled ( ILSMMemoryComponent component , boolean componentSwitched ) { // Not interested in this } @Override public void allocated ( ILSMMemoryComponent component ) { // Not interested in this } }
protected LSMRTreeOpContext createOpContext ( IIndexAccessParameters iap ) { return new LSMRTreeOpContext ( this , memoryComponents , rtreeLeafFrameFactory , rtreeInteriorFrameFactory , < |startfocus| > btreeLeafFrameFactory , ( IExtendedModificationOperationCallback ) iap . getModificationCallback ( ) , < |endfocus| > iap . getSearchOperationCallback ( ) , getTreeFields ( ) , getFilterFields ( ) , getHarness ( ) , comparatorFields , linearizerArray , getFilterCmpFactories ( ) , tracer ) ;
* * Unless required by applicable law or agreed to in writing , * software distributed under the License is distributed on an * "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . asterix . external . api ; import java . io . DataOutput ; import org . apache . asterix . om . base . IAObject ; import org . apache . asterix . om . types . ATypeTag ; import org . apache . asterix . om . types . IAType ; import org . apache . hyracks . api . exceptions . HyracksDataException ; public interface IJObject { IAType getIAType ( ) ; IAObject getIAObject ( ) ; void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException ; void reset ( ) throws HyracksDataException ; }
super ( ) ; this . listType = new AOrderedListType ( listItemType , null ) ; } @Override public IAType getIAType ( ) { return listType ; } @Override public IAObject getIAObject ( ) { AMutableOrderedList v = new AMutableOrderedList ( listType ) ; for ( IJObject jObj : jObjects ) { v . add ( jObj . getIAObject ( ) ) ; } return v ; } @Override public void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException { < |startfocus| > IAsterixListBuilder listBuilder = new OrderedListBuilder ( ) ; < |endfocus| > listBuilder . reset ( listType ) ; ArrayBackedValueStorage fieldValue = new ArrayBackedValueStorage ( ) ; for ( IJObject jObject : jObjects ) { fieldValue . reset ( ) ; jObject . serialize ( fieldValue . getDataOutput ( ) , true ) ; listBuilder . addItem ( fieldValue ) ; } listBuilder . write ( dataOutput , writeTypeTag ) ; } @Override public void reset ( ) { jObjects . clear ( ) ; } }
* specific language governing permissions and limitations * under the License . */ package org . apache . asterix . external . library . java . base ; import org . apache . asterix . dataflow . data . nontagged . serde . ABooleanSerializerDeserializer ; import org . apache . asterix . om . base . ABoolean ; import org . apache . asterix . om . base . IAObject ; import org . apache . asterix . om . types . ATypeTag ; import org . apache . asterix . om . types . BuiltinType ; import org . apache . asterix . om . types . IAType ; import org . apache . hyracks . api . exceptions . HyracksDataException ; import java . io . DataOutput ; public final class JBoolean extends JObject { < |startfocus| > private boolean booleanValue ; < |endfocus| > public JBoolean ( boolean booleanValue ) { this . booleanValue = booleanValue ; } public void setValue ( boolean booleanValue ) { this . booleanValue = booleanValue ; } public boolean getValue ( ) { return booleanValue ; } @Override public IAType getIAType ( ) { return BuiltinType . ABOOLEAN ; } @Override public IAObject getIAObject ( ) { return booleanValue ? ABoolean . TRUE : ABoolean . FALSE ; } @Override public void serialize ( DataOutput dataOutput , boolean writeTypeTag ) throws HyracksDataException { serializeTypeTag ( writeTypeTag , dataOutput , ATypeTag . BOOLEAN ) ;
public ARectangle getValue ( ) { < |startfocus| > return ( AMutableRectangle ) value ; < |endfocus| >
< |startfocus| > public ITupleReference getSearchKey ( ) { return MetadataNode . createTuple ( signature . getNamespace ( ) , signature . getName ( ) , Integer . toString ( signature . getArity ( ) ) ) ; < |endfocus| >
adapterRuntimeManager = new AdapterRuntimeManager ( ctx , feedId , adapter , writer , partition ) ; ActiveRuntimeId runtimeId = new ActiveRuntimeId ( feedId , FeedRuntimeType . INTAKE . toString ( ) , partition ) ; ingestionRuntime = new IngestionRuntime ( feedId , runtimeId , adapterRuntimeManager , ctx ) ; feedManager . registerRuntime ( ingestionRuntime ) ; < |startfocus| > writer . open ( ) ; < |endfocus| > TaskUtils . putInSharedMap ( HyracksConstants . KEY_MESSAGE , new VSizeFrame ( ctx ) , ctx ) ; adapterRuntimeManager . start ( ) ; synchronized ( adapterRuntimeManager ) { while ( ! adapterRuntimeManager . isDone ( ) ) { adapterRuntimeManager . wait ( ) ; } } if ( adapterRuntimeManager . isFailed ( ) ) { throw new HyracksDataException ( "Unable to ingest data" ) ; } } catch ( Exception ie ) { /* * An Interrupted Exception is thrown if the Intake job cannot progress further due to failure of another node involved in the Hyracks job . * As the Intake job involves only the intake operator , the exception is indicative of a failure at the sibling intake operator location . * The surviving intake partitions must continue to live and receive data from the external source . */
public static void exit ( int status ) { if ( exitThread . isAlive ( ) ) { LOGGER . warn ( "ignoring duplicate request to exit with status " + status + " ; already exiting with status " + exitThread . status + " . . . " ) ; return ; } < |startfocus| > exitThread . setStatus ( status ) ; exitThread . start ( ) ; < |endfocus| >
import org . apache . logging . log4j . Level ; import org . apache . logging . log4j . LogManager ; import org . apache . logging . log4j . Logger ; /* * * Shutdown hook that invokes { @link NodeControllerService#stop ( ) stop } method . * This shutdown hook must have a failsafe mechanism to halt the process in case the shutdown * operation is hanging for any reason */ public class NCShutdownHook extends Thread { < |startfocus| > public static final int FAILED_TO_STARTUP_EXIT_CODE = 2 ; public static final int FAILED_TO_RECOVER_EXIT_CODE = 3 ; < |endfocus| > private static final Logger LOGGER = LogManager . getLogger ( ) ; private final NodeControllerService nodeControllerService ; NCShutdownHook ( NodeControllerService nodeControllerService ) { super ( "ShutdownHook - " + nodeControllerService . getId ( ) ) ; this . nodeControllerService = nodeControllerService ; } @Override public void run ( ) { try { try { LOGGER . info ( "Shutdown hook called" ) ; } catch ( Throwable th ) { // NOSONAR } LOGGER . log ( Level . INFO , ( ) - > "Thread dump at shutdown : " + ThreadDumpUtil . takeDumpString ( ) ) ; nodeControllerService . stop ( ) ; } catch ( Throwable th ) { // NOSONAR LOGGER . error ( "Error while shutting down the NC" , th ) ; } } }
protected void cleanup ( ) { for ( Entry < Integer , Pair < PrimaryIndexOperationTracker , IModificationOperationCallback > > e : primaryIndexTrackers . entrySet ( ) ) { int pendingOps = partitionPendingOps . get ( e . getKey ( ) ) . intValue ( ) ; for ( int i = 0 ; i < pendingOps ; i ++ ) { try { e . getValue ( ) . first . completeOperation ( null , LSMOperationType . MODIFICATION , null , e . getValue ( ) . second ) ; } catch ( HyracksDataException ex ) { throw new ACIDException ( ex ) ; } } }
if ( interrupted ) { Thread . currentThread ( ) . interrupt ( ) ; } } } /* * * Runs the supplied { @code action } until { @code stopCondition } is met or timeout . */ public static void runWithTimeout ( ThrowingAction action , BooleanSupplier stopCondition , long timeout , TimeUnit unit ) throws Exception { long remainingTime = unit . toNanos ( timeout ) ; final long startTime = System . nanoTime ( ) ; while ( ! stopCondition . getAsBoolean ( ) ) { if ( remainingTime <= 0 ) { < |startfocus| > throw new TimeoutException ( "Timed out after " + timeout + " " + unit ) ; < |endfocus| > } action . run ( ) ; remainingTime -= System . nanoTime ( ) - startTime ; } } }
throws HyracksDataException { // start + 1 and len - 1 due to type tag ignore ( only interested in String value ) return comparator . compare ( a . getByteArray ( ) , a . getStartOffset ( ) + 1 , a . getLength ( ) - 1 , b . getByteArray ( ) , b . getStartOffset ( ) + 1 , b . getLength ( ) - 1 ) ; } public static boolean isEqual ( IValueReference a , IValueReference b , IBinaryComparator comparator ) throws HyracksDataException { < |startfocus| > return compareStringBinValues ( a , b , comparator ) == 0 ; < |endfocus| > } public static boolean byteArrayEqual ( IValueReference valueRef1 , IValueReference valueRef2 ) { return byteArrayEqual ( valueRef1 , valueRef2 , 3 ) ; } public static boolean byteArrayEqual ( IValueReference valueRef1 , IValueReference valueRef2 , int dataOffset ) { if ( valueRef1 == null || valueRef2 == null ) { return false ; } if ( valueRef1 == valueRef2 ) { return true ; } int length1 = valueRef1 . getLength ( ) ; int length2 = valueRef2 . getLength ( ) ; if ( length1 != length2 ) { return false ; }
utf8Writer = new UTF8StringWriter ( ) ; } public static IBinaryComparator createStringBinaryComparator ( ) { return PointableBinaryComparatorFactory . of ( UTF8StringPointable . FACTORY ) . createBinaryComparator ( ) ; } public static int compareStringBinValues ( IValueReference a , IValueReference b , IBinaryComparator comparator ) throws HyracksDataException { // start + 1 and len - 1 due to type tag ignore ( only interested in String value ) < |startfocus| > return comparator . compare ( a . getByteArray ( ) , a . getStartOffset ( ) + 1 , a . getLength ( ) - 1 , b . getByteArray ( ) , < |endfocus| > b . getStartOffset ( ) + 1 , b . getLength ( ) - 1 ) ; } public static boolean isEqual ( IValueReference a , IValueReference b , IBinaryComparator comparator ) throws HyracksDataException { return ( compareStringBinValues ( a , b , comparator ) == 0 ) ; } public static boolean byteArrayEqual ( IValueReference valueRef1 , IValueReference valueRef2 ) { return byteArrayEqual ( valueRef1 , valueRef2 , 3 ) ; } public static boolean byteArrayEqual ( IValueReference valueRef1 , IValueReference valueRef2 , int dataOffset ) { if ( valueRef1 == null || valueRef2 == null ) {
} IndexCursorUtils . open ( btreeAccessors , btreeCursors , btreeRangePredicate ) ; try { for ( int i = 0 ; i < numberOfTrees ; i ++ ) { if ( btreeCursors [ i ] . hasNext ( ) ) { btreeCursors [ i ] . next ( ) ; } else { depletedBtreeCursors [ i ] = true ; } } } catch ( Throwable th ) { // NOSONAR Must catch all failures to close before throwing for ( int i = 0 ; i < numberOfTrees ; i ++ ) { < |startfocus| > Throwable th2 = IndexCursorUtils . close ( btreeCursors [ i ] , th ) ; < |endfocus| > } throw HyracksDataException . create ( th ) ; } } }
public static Throwable close ( IIndexCursor cursor , Throwable root ) { if ( cursor != null ) { try { cursor . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be suppressed try { LOGGER . log ( Level . WARN , "Failure closing a cursor" , th ) ; } catch ( Throwable loggingFailure ) { // NOSONAR : Ignore catching Throwable // NOSONAR ignore logging failure } < |startfocus| > Throwable suppressed = ExceptionUtils . suppress ( root , th ) ; < |endfocus| > } } return root ;
throws HyracksDataException { int opened = 0 ; try { for ( int i = 0 ; i < cursors . length ; i ++ ) { if ( accessors . get ( i ) != null ) { accessors . get ( i ) . search ( cursors [ i ] , pred ) ; } opened ++ ; } } catch ( Throwable th ) { // NOSONAR : Much catch all failures for ( int j = 0 ; j < opened ; j ++ ) { < |startfocus| > Throwable th2 = IndexCursorUtils . close ( cursors [ j ] , th ) ; < |endfocus| > } throw HyracksDataException . create ( th ) ; } } public static void open ( IIndexAccessor [ ] accessors , IIndexCursor [ ] cursors , ISearchPredicate pred ) throws HyracksDataException { int opened = 0 ; try { for ( int i = 0 ; i < accessors . length ; i ++ ) { if ( accessors [ i ] != null ) { accessors [ i ] . search ( cursors [ i ] , pred ) ; } opened ++ ; } } catch ( Throwable th ) { // NOSONAR : Much catch all failures for ( int j = 0 ; j < opened ; j ++ ) { th = IndexCursorUtils . close ( cursors [ j ] , th ) ;
throws HyracksDataException { int opened = 0 ; try { for ( int i = 0 ; i < accessors . length ; i ++ ) { if ( accessors [ i ] != null ) { accessors [ i ] . search ( cursors [ i ] , pred ) ; } opened ++ ; } } catch ( Throwable th ) { // NOSONAR : Much catch all failures for ( int j = 0 ; j < opened ; j ++ ) { < |startfocus| > Throwable t = IndexCursorUtils . close ( cursors [ j ] , th ) ; < |endfocus| > } throw HyracksDataException . create ( th ) ; } } public static Throwable close ( IIndexCursor [ ] cursors , Throwable th ) { for ( int j = 0 ; j < cursors . length ; j ++ ) { th = IndexCursorUtils . close ( cursors [ j ] , th ) ; } return th ; } }
public static Throwable close ( IIndexCursor [ ] cursors , Throwable th ) { for ( int j = 0 ; j < cursors . length ; j ++ ) { < |startfocus| > Throwable th2 = IndexCursorUtils . close ( cursors [ j ] , th ) ; < |endfocus| > } return th ;
ILSMOperationTracker getOperationTracker ( ) ; ILSMIOOperationScheduler getIOScheduler ( ) ; ILSMIOOperationCallback getIOOperationCallback ( ) ; /* * * components with lower indexes are newer than components with higher index */ List < ILSMDiskComponent > getDiskComponents ( ) ; boolean isPrimaryIndex ( ) ; void modify ( IIndexOperationContext ictx , ITupleReference tuple ) throws HyracksDataException ; /* * * If this method returns successfully , then the cursor has been opened , and need to be closed * Otherwise , it has not been opened < |startfocus| > * < |endfocus| > * @param ictx * @param cursor * @param pred * @throws HyracksDataException */ void search ( ILSMIndexOperationContext ictx , IIndexCursor cursor , ISearchPredicate pred ) throws HyracksDataException ; public void scanDiskComponents ( ILSMIndexOperationContext ctx , IIndexCursor cursor ) throws HyracksDataException ; void scheduleFlush ( ILSMIndexOperationContext ctx , ILSMIOOperationCallback callback ) throws HyracksDataException ; ILSMDiskComponent flush ( ILSMIOOperation operation ) throws HyracksDataException ; void scheduleMerge ( ILSMIndexOperationContext ctx , ILSMIOOperationCallback callback ) throws HyracksDataException ; ILSMDiskComponent merge ( ILSMIOOperation operation ) throws HyracksDataException ;
public static Throwable close ( IIndexCursor cursor , Throwable root ) { if ( cursor != null ) { try { cursor . close ( ) ; } catch ( Throwable th ) { // NOSONAR Will be suppressed try { LOGGER . log ( Level . WARN , "Failure closing a cursor" , th ) ; } catch ( Throwable loggingFailure ) { // NOSONAR : Ignore catching Throwable // NOSONAR ignore logging failure } < |startfocus| > root = ExceptionUtils . suppress ( root , th ) ; // NOSONAR < |endfocus| > } } return root ;
IOperatorNodePushable operatorNodePushable = operatorNodePushables . get ( activityIdInputIndex . getLeft ( ) ) ; return operatorNodePushable . getInputFrameWriter ( activityIdInputIndex . getRight ( ) ) ; } @Override public String getDisplayName ( ) { return "Super Activity " + parent . getActivityMap ( ) . values ( ) . toString ( ) ; } @FunctionalInterface interface OperatorNodePushableAction { void run ( IOperatorNodePushable op ) throws HyracksDataException ; } @SuppressWarnings ( "unchecked" ) private void runInParallel ( OperatorNodePushableAction action ) throws HyracksDataException { < |startfocus| > Future < Void > [ ] tasks = new Future [ operatorNodePushablesBFSOrder . size ( ) ] ; Throwable [ ] failures = new Throwable [ operatorNodePushablesBFSOrder . size ( ) ] ; < |endfocus| > final Semaphore startSemaphore = new Semaphore ( 1 - operatorNodePushablesBFSOrder . size ( ) ) ; final Semaphore completeSemaphore = new Semaphore ( 1 - operatorNodePushablesBFSOrder . size ( ) ) ; int completed = 0 ; Throwable root = null ; try { for ( int i = 0 ; i < operatorNodePushablesBFSOrder . size ( ) ; i ++ ) { final int current = i ; tasks [ i ] = ctx . getExecutorService ( ) . submit ( ( ) - > { startSemaphore . release ( ) ; try { < |startfocus| >
} @FunctionalInterface interface OperatorNodePushableAction { void run ( IOperatorNodePushable op ) throws HyracksDataException ; } @SuppressWarnings ( "unchecked" ) private void runInParallel ( OperatorNodePushableAction action ) throws HyracksDataException { Future < Void > [ ] tasks = new Future [ operatorNodePushablesBFSOrder . size ( ) ] ; Throwable [ ] failures = new Throwable [ operatorNodePushablesBFSOrder . size ( ) ] ; final Semaphore startSemaphore = new Semaphore ( 1 - operatorNodePushablesBFSOrder . size ( ) ) ; final Semaphore completeSemaphore = new Semaphore ( 1 - operatorNodePushablesBFSOrder . size ( ) ) ; < |startfocus| > int completed = 0 ; < |endfocus| > Throwable root = null ; try { for ( int i = 0 ; i < operatorNodePushablesBFSOrder . size ( ) ; i ++ ) { final int current = i ; tasks [ i ] = ctx . getExecutorService ( ) . submit ( ( ) - > { startSemaphore . release ( ) ; try { action . run ( operatorNodePushablesBFSOrder . get ( current ) ) ; } catch ( Throwable th ) { // NOSONAR : Must catch all causes of failure failures [ current ] = th ; throw th ; } finally { completeSemaphore . release ( ) ; } return null ; } ) ; } < |startfocus| >
final Semaphore completeSemaphore = new Semaphore ( 1 - operatorNodePushablesBFSOrder . size ( ) ) ; int completed = 0 ; Throwable root = null ; try { for ( int i = 0 ; i < operatorNodePushablesBFSOrder . size ( ) ; i ++ ) { final int current = i ; tasks [ i ] = ctx . getExecutorService ( ) . submit ( ( ) - > { startSemaphore . release ( ) ; try { action . run ( operatorNodePushablesBFSOrder . get ( current ) ) ; } catch ( Throwable th ) { // NOSONAR : Must catch all causes of failure < |startfocus| > failures [ current ] = th ; < |endfocus| > throw th ; } finally { completeSemaphore . release ( ) ; } return null ; } ) ; } for ( Future < Void > task : tasks ) { task . get ( ) ; completed ++ ; } } catch ( ExecutionException e ) { root = e . getCause ( ) ; completed ++ ; } catch ( Throwable e ) { // NOSONAR : Must catch all causes of failure root = e ; } if ( root != null ) { cancelTasks ( tasks , startSemaphore , completeSemaphore ) ; }
*/ Checkpoint getLatest ( ) throws ACIDException ; /* * * Performs a sharp checkpoint . * * @throws HyracksDataException */ void doSharpCheckpoint ( ) throws HyracksDataException ; /* * * Attempts to perform a soft checkpoint at the specified { @code checkpointTargetLSN } . * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint . * @throws HyracksDataException */ long tryCheckpoint ( long checkpointTargetLSN ) throws HyracksDataException ; void unlockLSN ( long lsn ) ; void lockLSN ( long lsn ) ; }
/* * * Performs a sharp checkpoint . * * @throws HyracksDataException */ void doSharpCheckpoint ( ) throws HyracksDataException ; /* * * Attempts to perform a soft checkpoint at the specified { @code checkpointTargetLSN } . * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint . * @throws HyracksDataException */ long tryCheckpoint ( long checkpointTargetLSN ) throws HyracksDataException ; void unlockLSN ( long lsn ) ; < |startfocus| > void lockLSN ( long lsn ) ; < |endfocus| > }
DataflowUtils . addTupleToFrame ( tupleAppender , tuple , insertOp ) ; lowWaterMarkLSN = recoveryManager . getMinFirstLSN ( ) ; currentLowWaterMarkLogFileId = logManager . getLogFileId ( lowWaterMarkLSN ) ; } } /* * At this point , the low - water mark is not in the initialLowWaterMarkFileId , so * a checkpoint should delete it . We will also start a second < |startfocus| > * job to ensure that the checkpointing coexists peacefully * with other concurrent readers of the log that request < |endfocus| > * deletions to be witheld */ JobId jobId2 = nc . newJobId ( ) ; IHyracksTaskContext ctx2 = nc . createTestContext ( jobId2 , 0 , false ) ; nc . getTransactionManager ( ) . beginTransaction ( nc . getTxnJobId ( ctx2 ) , new TransactionOptions ( ITransactionManager . AtomicityLevel . ENTITY_LEVEL ) ) ; // Prepare insert operation LSMInsertDeleteOperatorNodePushable insertOp2 = nc . getInsertPipeline ( ctx2 , dataset , KEY_TYPES , RECORD_TYPE , META_TYPE , null , KEY_INDEXES , KEY_INDICATOR_LIST , storageManager , null ) . getLeft ( ) ; insertOp2 . open ( ) ; VSizeFrame frame2 = new VSizeFrame ( ctx2 ) ;
RECORD_TYPE , META_TYPE , null , KEY_INDEXES , KEY_INDICATOR_LIST , storageManager , null ) . getLeft ( ) ; insertOp2 . open ( ) ; VSizeFrame frame2 = new VSizeFrame ( ctx2 ) ; FrameTupleAppender tupleAppender2 = new FrameTupleAppender ( frame2 ) ; for ( int i = 0 ; i < 4 ; i ++ ) { long lastCkpoint = recoveryManager . getMinFirstLSN ( ) ; long lastFileId = logManager . getLogFileId ( lastCkpoint ) ; < |startfocus| > LOGGER . info ( "ckpoint : " + lastCkpoint ) ; < |endfocus| > checkpointManager . tryCheckpoint ( lowWaterMarkLSN ) ; // Validate initialLowWaterMarkFileId was deleted for ( Long fileId : logManager . getLogFileIds ( ) ) { Assert . assertNotEquals ( initialLowWaterMarkFileId , fileId . longValue ( ) ) ; } while ( currentLowWaterMarkLogFileId == lastFileId ) { ITupleReference tuple = tupleGenerator . next ( ) ; DataflowUtils . addTupleToFrame ( tupleAppender2 , tuple , insertOp2 ) ; lowWaterMarkLSN = recoveryManager . getMinFirstLSN ( ) ; currentLowWaterMarkLogFileId = logManager . getLogFileId ( lowWaterMarkLSN ) ; } }
/* * * Performs a sharp checkpoint . * * @throws HyracksDataException */ void doSharpCheckpoint ( ) throws HyracksDataException ; /* * * Attempts to perform a soft checkpoint at the specified { @code checkpointTargetLSN } . * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint . * @throws HyracksDataException */ long tryCheckpoint ( long checkpointTargetLSN ) throws HyracksDataException ; void unlockLSN ( long lsn ) ; void lockLSN ( long lsn ) ; }
private void touchLogFile ( long fileId ) { synchronized ( txnLogFileId2ReaderCount ) { if ( txnLogFileId2ReaderCount . containsKey ( fileId ) ) { txnLogFileId2ReaderCount . put ( fileId , txnLogFileId2ReaderCount . get ( fileId ) + 1 ) ; } else { txnLogFileId2ReaderCount . put ( fileId , 1 ) ; } < |startfocus| > } < |endfocus| > }
public void run ( ) { < |startfocus| > while ( true ) { < |endfocus| > try { logRecord = flushLogsQ . take ( ) ; appendToLogTail ( logRecord ) ; } catch ( ACIDException e ) { e . printStackTrace ( ) ; } catch ( InterruptedException e ) { // ignore } } }
if ( ! checkpointDir . exists ( ) ) { if ( LOGGER . isInfoEnabled ( ) ) { LOGGER . log ( Level . INFO , "Checkpoint directory " + checkpointDirPath + " didn't exist . Creating one" ) ; } checkpointDir . mkdirs ( ) ; } lsnThreshold = checkpointProperties . getLsnThreshold ( ) ; pollFrequency = checkpointProperties . getPollFrequency ( ) ; // We must keep at least the latest checkpoint historyToKeep = checkpointProperties . getHistoryToKeep ( ) == 0 ? 1 : checkpointProperties . getHistoryToKeep ( ) ; < |startfocus| > lockedLSNs = new ConcurrentSkipListMap < > ( ) ; < |endfocus| >
if ( checkpointSucceeded ) { ILogManager logManager = txnSubsystem . getLogManager ( ) ; synchronized ( logManager ) { for ( Long l : lockedLSNs . keySet ( ) ) { if ( minFirstLSN > l ) { return minFirstLSN ; } } logManager . deleteOldLogFiles ( minFirstLSN ) ; LOGGER . info ( String . format ( "soft checkpoint succeeded at LSN ( % s ) " , minFirstLSN ) ) ; } } return minFirstLSN ; } @Override public void lockLSN ( long lsn ) { < |startfocus| > synchronized ( this ) { < |endfocus| > if ( ! lockedLSNs . containsKey ( lsn ) ) { lockedLSNs . put ( lsn , 1 ) ; } else { lockedLSNs . replace ( lsn , lockedLSNs . get ( lsn ) + 1 ) ; } } } @Override public void unlockLSN ( long lsn ) { synchronized ( this ) { if ( ! lockedLSNs . containsKey ( lsn ) ) { return ; } else { if ( lockedLSNs . get ( lsn ) == 1 ) { lockedLSNs . remove ( lsn ) ; } else { lockedLSNs . replace ( lsn , lockedLSNs . get ( lsn ) - 1 ) ; } } } } }
} } return minFirstLSN ; } @Override public void lockLSN ( long lsn ) { synchronized ( txnSubsystem . getLogManager ( ) ) { if ( ! lockedLSNs . containsKey ( lsn ) ) { lockedLSNs . put ( lsn , 1 ) ; } else { lockedLSNs . replace ( lsn , lockedLSNs . get ( lsn ) + 1 ) ; } } } @Override public void unlockLSN ( long lsn ) { synchronized ( txnSubsystem . getLogManager ( ) ) { if ( ! lockedLSNs . containsKey ( lsn ) ) { < |startfocus| > throw new IllegalStateException ( "LSN " + lsn + " is not locked" ) ; < |endfocus| > } else { if ( lockedLSNs . get ( lsn ) == 1 ) { lockedLSNs . remove ( lsn ) ; } else { lockedLSNs . replace ( lsn , lockedLSNs . get ( lsn ) - 1 ) ; } } } } }
final IVisitablePointable vp1 = pa . allocateRecordValue ( inRecType1 ) ; final IPointable argPtr0 = new VoidPointable ( ) ; final IPointable argPtr1 = new VoidPointable ( ) ; final IScalarEvaluator eval0 = args [ 0 ] . createScalarEvaluator ( ctx ) ; final IScalarEvaluator eval1 = args [ 1 ] . createScalarEvaluator ( ctx ) ; final List < RecordBuilder > rbStack = new ArrayList < > ( ) ; final ArrayBackedValueStorage tabvs = new ArrayBackedValueStorage ( ) ; < |startfocus| > final IBinaryComparator stringBinaryComparator = PointableHelper . createStringBinaryComparator ( ) ; < |endfocus| > return new IScalarEvaluator ( ) { private final RuntimeRecordTypeInfo runtimeRecordTypeInfo = new RuntimeRecordTypeInfo ( ) ; private final DeepEqualAssessor deepEqualAssesor = new DeepEqualAssessor ( ) ; private ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage ( ) ; private DataOutput out = resultStorage . getDataOutput ( ) ; @Override public void evaluate ( IFrameTupleReference tuple , IPointable result ) throws HyracksDataException { resultStorage . reset ( ) ; eval0 . evaluate ( tuple , argPtr0 ) ; eval1 . evaluate ( tuple , argPtr1 ) ; vp0 . set ( argPtr0 ) ; vp1 . set ( argPtr1 ) ;
public IScalarEvaluator createScalarEvaluator ( final IHyracksTaskContext ctx ) throws HyracksDataException { final PointableAllocator pa = new PointableAllocator ( ) ; final IVisitablePointable vp0 = pa . allocateRecordValue ( inputRecType ) ; final IVisitablePointable vp1 = pa . allocateListValue ( inputListType ) ; final IPointable inputArg0 = new VoidPointable ( ) ; final IPointable inputArg1 = new VoidPointable ( ) ; final IScalarEvaluator eval0 = inputRecordEvalFactory . createScalarEvaluator ( ctx ) ; final IScalarEvaluator eval1 = removeFieldPathsFactory . createScalarEvaluator ( ctx ) ; < |startfocus| > final IBinaryComparator stringBinaryComparator = PointableHelper . createStringBinaryComparator ( ) ; < |endfocus| > return new IScalarEvaluator ( ) { private final RuntimeRecordTypeInfo runtimeRecordTypeInfo = new RuntimeRecordTypeInfo ( ) ; private final List < RecordBuilder > rbStack = new ArrayList < > ( ) ; private final ArrayBackedValueStorage tabvs = new ArrayBackedValueStorage ( ) ; private final Deque < IVisitablePointable > recordPath = new ArrayDeque < > ( ) ; private ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage ( ) ; private DataOutput out = resultStorage . getDataOutput ( ) ; @Override public void evaluate ( IFrameTupleReference tuple , IPointable result ) throws HyracksDataException { resultStorage . reset ( ) ;
} IndexCursorUtils . open ( btreeAccessors , btreeCursors , btreeRangePredicate ) ; try { for ( int i = 0 ; i < numberOfTrees ; i ++ ) { if ( btreeCursors [ i ] . hasNext ( ) ) { btreeCursors [ i ] . next ( ) ; } else { depletedBtreeCursors [ i ] = true ; } } } catch ( Throwable th ) { // NOSONAR Must catch all failures to close before throwing for ( int i = 0 ; i < numberOfTrees ; i ++ ) { < |startfocus| > th = IndexCursorUtils . close ( btreeCursors [ i ] , th ) ; < |endfocus| > } throw HyracksDataException . create ( th ) ; } } }
throws HyracksDataException { int opened = 0 ; try { for ( int i = 0 ; i < cursors . length ; i ++ ) { if ( accessors . get ( i ) != null ) { accessors . get ( i ) . search ( cursors [ i ] , pred ) ; } opened ++ ; } } catch ( Throwable th ) { // NOSONAR : Much catch all failures for ( int j = 0 ; j < opened ; j ++ ) { < |startfocus| > th = IndexCursorUtils . close ( cursors [ j ] , th ) ; < |endfocus| > } throw HyracksDataException . create ( th ) ; } } public static void open ( IIndexAccessor [ ] accessors , IIndexCursor [ ] cursors , ISearchPredicate pred ) throws HyracksDataException { int opened = 0 ; try { for ( int i = 0 ; i < accessors . length ; i ++ ) { if ( accessors [ i ] != null ) { accessors [ i ] . search ( cursors [ i ] , pred ) ; } opened ++ ; } } catch ( Throwable th ) { // NOSONAR : Much catch all failures for ( int j = 0 ; j < opened ; j ++ ) { th = IndexCursorUtils . close ( cursors [ j ] , th ) ; } throw HyracksDataException . create ( th ) ; } }
throws HyracksDataException { int opened = 0 ; try { for ( int i = 0 ; i < accessors . length ; i ++ ) { if ( accessors [ i ] != null ) { accessors [ i ] . search ( cursors [ i ] , pred ) ; } opened ++ ; } } catch ( Throwable th ) { // NOSONAR : Much catch all failures for ( int j = 0 ; j < opened ; j ++ ) { < |startfocus| > th = IndexCursorUtils . close ( cursors [ j ] , th ) ; < |endfocus| > } throw HyracksDataException . create ( th ) ; } } public static Throwable close ( IIndexCursor [ ] cursors , Throwable th ) { for ( int j = 0 ; j < cursors . length ; j ++ ) { th = IndexCursorUtils . close ( cursors [ j ] , th ) ; } return th ; } }
initializationTasks . add ( ctx . getExecutorService ( ) . submit ( new Callable < Void > ( ) { @Override public Void call ( ) throws Exception { opAction . runAction ( op , opIndex ) ; return null ; } } ) ) ; } // Waits until all parallel actions to finish . for ( Future < Void > initializationTask : initializationTasks ) { initializationTask . get ( ) ; } } catch ( Throwable th ) { for ( Future < Void > initializationTask : initializationTasks ) { initializationTask . cancel ( true ) ; } < |startfocus| > throw new HyracksDataException ( th ) ; < |endfocus| > } } }
public LogRecord next ( ) { if ( buffer . position ( ) == endOffset ) { return null ; } RecordReadStatus status = logRecord . readLogRecord ( buffer ) ; // underflow is not expected because we are at the very tail of the current log buffer if ( status != RecordReadStatus . OK ) { < |startfocus| > throw new IllegalStateException ( "Unexpected log read status : " + status + " . Read log : " + logRecord . getLogRecordForDisplay ( ) ) ; < |endfocus| > } return logRecord ;
IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem . getApplicationContext ( ) . getDatasetLifecycleManager ( ) ; datasetLifecycleManager . scheduleAsyncFlushForLaggingDatasets ( checkpointTargetLSN ) ; } capture ( minFirstLSN , false ) ; if ( checkpointSucceeded ) { txnSubsystem . getLogManager ( ) . deleteOldLogFiles ( minFirstLSN ) ; LOGGER . info ( String . format ( "soft checkpoint succeeded at LSN ( % s ) " , minFirstLSN ) ) ; } return minFirstLSN ; } private synchronized long getMinSecuredLSN ( ) { < |startfocus| > return ! securedLSNs . values ( ) . isEmpty ( ) ? Collections . min ( securedLSNs . values ( ) ) : - 1 ; < |endfocus| > } @Override public synchronized void secure ( TxnId id ) throws HyracksDataException { securedLSNs . put ( id , txnSubsystem . getRecoveryManager ( ) . getMinFirstLSN ( ) ) ; } @Override public synchronized void completed ( TxnId id ) { securedLSNs . remove ( id ) ; } }
Checkpoint getLatest ( ) throws ACIDException ; /* * * Performs a sharp checkpoint . * * @throws HyracksDataException */ void doSharpCheckpoint ( ) throws HyracksDataException ; /* * * Attempts to perform a soft checkpoint at the specified { @code checkpointTargetLSN } . * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint . * @throws HyracksDataException */ long tryCheckpoint ( long checkpointTargetLSN ) throws HyracksDataException ; void secure ( TxnId id ) throws HyracksDataException ; /* * * Notifies this { @link ICheckpointManager } that the transaction identified by { @code id } completed . * * @param id */ void completed ( TxnId id ) ; }
*/ public abstract class AbstractCheckpointManager implements ICheckpointManager { private static final Logger LOGGER = LogManager . getLogger ( ) ; private static final String CHECKPOINT_FILENAME_PREFIX = "checkpoint_" ; public static final long SHARP_CHECKPOINT_LSN = - 1 ; private static final FilenameFilter filter = ( File dir , String name ) - > name . startsWith ( CHECKPOINT_FILENAME_PREFIX ) ; private final File checkpointDir ; private final int historyToKeep ; private final int lsnThreshold ; private final int pollFrequency ; protected final ITransactionSubsystem txnSubsystem ; private CheckpointThread checkpointer ; public AbstractCheckpointManager ( ITransactionSubsystem txnSubsystem , CheckpointProperties checkpointProperties ) { this . txnSubsystem = txnSubsystem ; String checkpointDirPath = checkpointProperties . getCheckpointDirPath ( ) ; if ( LOGGER . isInfoEnabled ( ) ) { LOGGER . log ( Level . INFO , "Checkpoint directory = " + checkpointDirPath ) ; } if ( ! checkpointDirPath . endsWith ( File . separator ) ) { checkpointDirPath += File . separator ; } checkpointDir = new File ( checkpointDirPath ) ; // Create the checkpoint directory if missing if ( ! checkpointDir . exists ( ) ) {
final long minFirstLSN = txnSubsystem . getRecoveryManager ( ) . getMinFirstLSN ( ) ; boolean checkpointSucceeded = minFirstLSN >= checkpointTargetLSN ; if ( ! checkpointSucceeded ) { // Flush datasets with indexes behind target checkpoint LSN IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem . getApplicationContext ( ) . getDatasetLifecycleManager ( ) ; datasetLifecycleManager . scheduleAsyncFlushForLaggingDatasets ( checkpointTargetLSN ) ; } capture ( minFirstLSN , false ) ; if ( checkpointSucceeded ) { < |startfocus| > long minSecuredLSN = Long . MAX_VALUE ; for ( Long l : securedLSNs . values ( ) ) { if ( minFirstLSN >= l ) { minSecuredLSN = Math . min ( minSecuredLSN , l ) ; } } if ( minSecuredLSN == Long . MAX_VALUE ) { return minFirstLSN ; } < |endfocus| > txnSubsystem . getLogManager ( ) . deleteOldLogFiles ( minFirstLSN ) ; LOGGER . info ( String . format ( "soft checkpoint succeeded at LSN ( % s ) " , minFirstLSN ) ) ; } return minFirstLSN ; } @Override public synchronized void secure ( TxnId id ) throws HyracksDataException { securedLSNs . put ( id , txnSubsystem . getRecoveryManager ( ) . getMinFirstLSN ( ) ) ; } @Override public synchronized void completed ( TxnId id ) throws IllegalStateException { if ( securedLSNs . containsKey ( id ) ) { securedLSNs . remove ( id ) ; } else { throw new IllegalStateException (
} } @Override public void abortTransaction ( TxnId txnId ) throws ACIDException { final ITransactionContext txnCtx = getTransactionContext ( txnId ) ; try { if ( txnCtx . isWriteTxn ( ) ) { LogRecord logRecord = new LogRecord ( ) ; TransactionUtil . formJobTerminateLogRecord ( txnCtx , logRecord , false ) ; txnSubsystem . getLogManager ( ) . log ( logRecord ) ; txnSubsystem . getCheckpointManager ( ) . secure ( txnId ) ; txnSubsystem . getRecoveryManager ( ) . rollbackTransaction ( txnCtx ) ; txnCtx . setTxnState ( ITransactionManager . ABORTED ) ; } < |startfocus| > } catch ( ACIDException | HyracksDataException e ) { < |endfocus| > String msg = "Could not complete rollback ! System is in an inconsistent state" ; if ( LOGGER . isErrorEnabled ( ) ) { LOGGER . log ( Level . ERROR , msg , e ) ; } throw new ACIDException ( msg , e ) ; } finally { txnCtx . complete ( ) ; txnSubsystem . getLockManager ( ) . releaseLocks ( txnCtx ) ; txnCtxRepository . remove ( txnCtx . getTxnId ( ) ) ; txnSubsystem . getCheckpointManager ( ) . completed ( txnId ) ; } } @Override public long getMaxTxnId ( ) { return maxTxnId . get ( ) ; } @Override public void start ( ) { < |startfocus| > } < |endfocus| >
*/ public abstract class AbstractCheckpointManager implements ICheckpointManager { private static final Logger LOGGER = LogManager . getLogger ( ) ; private static final String CHECKPOINT_FILENAME_PREFIX = "checkpoint_" ; public static final long SHARP_CHECKPOINT_LSN = - 1 ; private static final FilenameFilter filter = ( File dir , String name ) - > name . startsWith ( CHECKPOINT_FILENAME_PREFIX ) ; private final File checkpointDir ; private final int historyToKeep ; private final int lsnThreshold ; private final int pollFrequency ; < |startfocus| > private Map < TxnId , Long > securedLSNs ; < |endfocus| > protected final ITransactionSubsystem txnSubsystem ; private CheckpointThread checkpointer ; public AbstractCheckpointManager ( ITransactionSubsystem txnSubsystem , CheckpointProperties checkpointProperties ) { this . txnSubsystem = txnSubsystem ; String checkpointDirPath = checkpointProperties . getCheckpointDirPath ( ) ; if ( LOGGER . isInfoEnabled ( ) ) { LOGGER . log ( Level . INFO , "Checkpoint directory = " + checkpointDirPath ) ; } if ( ! checkpointDirPath . endsWith ( File . separator ) ) { checkpointDirPath += File . separator ; } checkpointDir = new File ( checkpointDirPath ) ; // Create the checkpoint directory if missing if ( ! checkpointDir . exists ( ) ) {
for ( DatasetResourceReference indexRef : partitionResources ) { long remoteIndexMaxLSN = idxCheckpointMgrProvider . get ( indexRef ) . getLowWatermark ( ) ; minRemoteLSN = Math . min ( minRemoteLSN , remoteIndexMaxLSN ) ; } } return minRemoteLSN ; } @Override public synchronized void replayReplicaPartitionLogs ( Set < Integer > partitions , boolean flush ) throws HyracksDataException { // replay logs > minLSN that belong to these partitions final TxnId randomDummyTxnId = new TxnId ( ThreadLocalRandom . current ( ) . nextInt ( Integer . MIN_VALUE , - 1 ) ) ; try { < |startfocus| > checkpointManager . secure ( recoveryTxnId ) ; < |endfocus| > long minLSN = getPartitionsMinLSN ( partitions ) ; long readableSmallestLSN = logMgr . getReadableSmallestLSN ( ) ; if ( minLSN < readableSmallestLSN ) { minLSN = readableSmallestLSN ; } replayPartitionsLogs ( partitions , logMgr . getLogReader ( true ) , minLSN ) ; if ( flush ) { appCtx . getDatasetLifecycleManager ( ) . flushAllDatasets ( ) ; } } catch ( IOException | ACIDException e ) { throw HyracksDataException . create ( e ) ; } finally { checkpointManager . completed ( randomDummyTxnId ) ; } } @Override
void doSharpCheckpoint ( ) throws HyracksDataException ; /* * * Attempts to perform a soft checkpoint at the specified { @code checkpointTargetLSN } . * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint . * @throws HyracksDataException */ long tryCheckpoint ( long checkpointTargetLSN ) throws HyracksDataException ; /* * * Secures the current low - water mark until the transaction identified by { @code id } completes . * * @param id * @throws HyracksDataException */ < |startfocus| > void secure ( TxnId id ) throws HyracksDataException ; < |endfocus| > /* * * Notifies this { @link ICheckpointManager } that the transaction identified by { @code id } completed . * * @param id */ void completed ( TxnId id ) ; }
* @throws HyracksDataException */ long tryCheckpoint ( long checkpointTargetLSN ) throws HyracksDataException ; /* * * Secures the current low - water mark until the transaction identified by { @code id } completes . * * @param id * @throws HyracksDataException */ void secure ( TxnId id ) throws HyracksDataException ; /* * * Notifies this { @link ICheckpointManager } that the transaction identified by { @code id } completed . * * @param id */ void completed ( TxnId id ) ; }
* KIND , either express or implied . See the License for the * specific language governing permissions and limitations * under the License . */ package org . apache . asterix . transaction . management . service . recovery ; import java . io . BufferedWriter ; import java . io . File ; import java . io . FilenameFilter ; import java . io . IOException ; import java . io . OutputStream ; import java . nio . channels . ClosedByInterruptException ; import java . nio . file . Files ; import java . nio . file . Path ; import java . nio . file . Paths ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . Collections ; < |startfocus| > import java . util . HashMap ; < |endfocus| > import java . util . List ; import java . util . Map ; import org . apache . asterix . common . exceptions . ACIDException ; import org . apache . asterix . common . transactions . Checkpoint ; import org . apache . asterix . common . transactions . CheckpointProperties ; import org . apache . asterix . common . transactions . ICheckpointManager ; import org . apache . asterix . common . transactions . ILogManager ; import org . apache . asterix . common . transactions . ITransactionManager ; import org . apache . asterix . common . transactions . ITransactionSubsystem ; import org . apache . asterix . common . transactions . TxnId ; import org . apache . asterix . common . utils . StorageConstants ; import org . apache . hyracks . api . exceptions . HyracksDataException ;
* log files that end with LSN < { @code checkpointTargetLSN } are deleted . */ @Override public synchronized long tryCheckpoint ( long checkpointTargetLSN ) throws HyracksDataException { LOGGER . info ( "Attemping soft checkpoint . . . " ) ; final long minFirstLSN = txnSubsystem . getRecoveryManager ( ) . getMinFirstLSN ( ) ; final long minSecuredLSN = getMinSecuredLSN ( ) ; < |startfocus| > if ( minSecuredLSN != - 1 && minFirstLSN >= getMinSecuredLSN ( ) ) { return minFirstLSN ; < |endfocus| > } boolean checkpointSucceeded = minFirstLSN >= checkpointTargetLSN ; if ( ! checkpointSucceeded ) { // Flush datasets with indexes behind target checkpoint LSN IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem . getApplicationContext ( ) . getDatasetLifecycleManager ( ) ; datasetLifecycleManager . scheduleAsyncFlushForLaggingDatasets ( checkpointTargetLSN ) ; } capture ( minFirstLSN , false ) ; if ( checkpointSucceeded ) { txnSubsystem . getLogManager ( ) . deleteOldLogFiles ( minFirstLSN ) ; LOGGER . info ( String . format ( "soft checkpoint succeeded at LSN ( % s ) " , minFirstLSN ) ) ; } return minFirstLSN ; } private synchronized long getMinSecuredLSN ( ) {
IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem . getApplicationContext ( ) . getDatasetLifecycleManager ( ) ; datasetLifecycleManager . scheduleAsyncFlushForLaggingDatasets ( checkpointTargetLSN ) ; } capture ( minFirstLSN , false ) ; if ( checkpointSucceeded ) { txnSubsystem . getLogManager ( ) . deleteOldLogFiles ( minFirstLSN ) ; LOGGER . info ( String . format ( "soft checkpoint succeeded at LSN ( % s ) " , minFirstLSN ) ) ; } return minFirstLSN ; } private synchronized long getMinSecuredLSN ( ) { < |startfocus| > return securedLSNs . isEmpty ( ) ? Long . MAX_VALUE : Collections . min ( securedLSNs . values ( ) ) ; < |endfocus| > } @Override public synchronized void secure ( TxnId id ) throws HyracksDataException { securedLSNs . put ( id , txnSubsystem . getRecoveryManager ( ) . getMinFirstLSN ( ) ) ; } @Override public synchronized void completed ( TxnId id ) { securedLSNs . remove ( id ) ; } }
public void run ( ) { Thread ct = Thread . currentThread ( ) ; < |startfocus| > String threadName = ct . getName ( ) ; < |endfocus| > // Calls synchronized addPendingThread ( . . ) to make sure that in the abort ( ) method , // the thread is not escaped from interruption . if ( ! addPendingThread ( ct ) ) { exceptions . add ( new InterruptedException ( "Task " + getTaskAttemptId ( ) + " was aborted ! " ) ) ; ExceptionUtils . setNodeIds ( exceptions , ncs . getId ( ) ) ; ncs . getWorkQueue ( ) . schedule ( new NotifyTaskFailureWork ( ncs , this , exceptions ) ) ; return ; } try { ct . setName ( displayName + " : " + taskAttemptId + " : " + 0 ) ; try { operator . initialize ( ) ; if ( collectors . length > 0 ) { final Semaphore sem = new Semaphore ( collectors . length - 1 ) ; for ( int i = 1 ; i < collectors . length ; ++ i ) { final IPartitionCollector collector = collectors [ i ] ; final IFrameWriter writer = operator . getInputFrameWriter ( i ) ; sem . acquire ( ) ; final int cIdx = i ; executorService . execute ( new Runnable ( ) { @Override public void run ( ) { try { writer . open ( ) ; collector . open ( ) ; } catch ( Exception e ) { exceptions . add ( e ) ; } finally { sem . release ( ) ; } } } ) ; } } } catch ( Exception e ) { exceptions . add ( e ) ; } if ( exceptions . isEmpty ( ) ) { try { operator . open ( ) ; } catch ( Exception e ) { exceptions . add ( e ) ; } } if ( exceptions . isEmpty ( ) ) { try { operator . nextFrame ( collectors [ 0 ] . getNextFrame ( ctx ) ) ; } catch ( Exception e ) { exceptions . add ( e ) ; } } } finally { ct . setName ( threadName ) ; } if ( ! exceptions . isEmpty ( ) ) { ExceptionUtils . setNodeIds ( exceptions , ncs . getId ( ) ) ; ncs . getWorkQueue ( ) . schedule ( new NotifyTaskFailureWork ( ncs , this , exceptions ) ) ; } }
int tzCount = tzIds . length ; TIMEZONE_IDS = new byte [ tzCount ] [ ] ; TIMEZONE_OFFSETS = new int [ tzCount ] ; for ( int i = 0 ; i < tzCount ; i ++ ) { TIMEZONE_IDS [ i ] = encode ( tzIds [ i ] ) ; } Arrays . sort ( TIMEZONE_IDS , byteArrayComparator ) ; for ( int i = 0 ; i < tzCount ; i ++ ) { < |startfocus| > String tzId ; try { tzId = new String ( TIMEZONE_IDS [ i ] , ENCODING ) ; } catch ( UnsupportedEncodingException e ) { throw new IllegalStateException ( ENCODING , e ) ; } TIMEZONE_OFFSETS [ i ] = TimeZone . getTimeZone ( tzId ) . getRawOffset ( ) ; < |endfocus| > } } private static final DateTimeFormatUtils INSTANCE = new DateTimeFormatUtils ( ) ; public static DateTimeFormatUtils getInstance ( ) { return INSTANCE ; } private DateTimeFormatUtils ( ) { } private int parseFormatField ( byte [ ] format , int formatStart , int formatLength , int formatPointer , char formatChar , int maxAllowedFormatCharCopied ) { int formatCharCopies = 0 ; formatPointer ++ ; formatCharCopies ++ ; }
&& data [ dataStart + timezoneEndField ] <= 'Z' ) || data [ dataStart + timezoneEndField ] == ' / ' || data [ dataStart + timezoneEndField ] == '_' ) ) { timezoneEndField ++ ; } int searchIdx = binaryTimezoneIDSearch ( data , dataStart + dataStringPointer , timezoneEndField - dataStringPointer ) ; if ( searchIdx >= 0 ) { timezone = TIMEZONE_OFFSETS [ searchIdx ] ; } else { if ( raiseParseDataError ) { < |startfocus| > throw new AsterixTemporalTypeParseException ( "Unexpected timezone string : " + decode ( data , dataStart + dataStringPointer , dataStart + timezoneEndField ) ) ; < |endfocus| > } else { return false ; } } dataStringPointer = timezoneEndField ; } timezoneExists = true ; break ; case AMPM : if ( dataStringPointer + 1 < dataLength ) { if ( hour > 12 || hour <= 0 ) { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( "Hour " + hour + " cannot be a time for AM / PM . " ) ; } else { return false ; } } if ( data [ dataStart + dataStringPointer ] == 'A' ) { if ( hour == 12 ) { hour = 0 ; } } else if ( data [ dataStart + dataStringPointer ] == 'P' ) { if ( hour != 12 ) { hour += 12 ; } } else { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( "Unexpected AM / PM string : " + decode ( data , dataStart + dataStringPointer , dataStart + dataStringPointer + 1 ) ) ; } else { return false ; } } dataStringPointer ++ ; } break ; case HOUR_OF_DAY : if ( dataStringPointer + 1 < dataLength ) { if ( data [ dataStart + dataStringPointer ] == '2' && data [ dataStart + dataStringPointer + 1 ] == '4' ) { hour = 0 ; dataStringPointer += 2 ; } else { if ( data [ dataStart + dataStringPointer ] < '0' || data [ dataStart + dataStringPointer ] > '9' || data [ dataStart + dataStringPointer + 1 ] < '0' || data [ dataStart + dataStringPointer + 1 ] > '9' ) { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( "Unexpected hour string : " + decode ( data , dataStart + dataStringPointer , dataStart + dataStringPointer + 2 ) ) ; } else { return false ; } } hour = ( data [ dataStart + dataStringPointer ] - '0' ) * 10 + ( data [ dataStart + dataStringPointer + 1 ] - '0' ) ; dataStringPointer += 2 ; } } break ; case MINUTE : if ( dataStringPointer + 1 < dataLength ) { if ( data [ dataStart + dataStringPointer ] < '0' || data [ dataStart + dataStringPointer ] > '9' || data [ dataStart + dataStringPointer + 1 ] < '0' || data [ dataStart + dataStringPointer + 1 ] > '9' ) { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( "Unexpected minute string : " + decode ( data , dataStart + dataStringPointer , dataStart + dataStringPointer + 2 ) ) ; } else { return false ; } } minute = ( data [ dataStart + dataStringPointer ] - '0' ) * 10 + ( data [ dataStart + dataStringPointer + 1 ] - '0' ) ; dataStringPointer += 2 ; } break ; case SECOND : if ( dataStringPointer + 1 < dataLength ) { if ( data [ dataStart + dataStringPointer ] < '0' || data [ dataStart + dataStringPointer ] > '9' || data [ dataStart + dataStringPointer + 1 ] < '0' || data [ dataStart + dataStringPointer + 1 ] > '9' ) { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( "Unexpected second string : " + decode ( data , dataStart + dataStringPointer , dataStart + dataStringPointer + 2 ) ) ; } else { return false ; } } second = ( data [ dataStart + dataStringPointer ] - '0' ) * 10 + ( data [ dataStart + dataStringPointer + 1 ] - '0' ) ; dataStringPointer += 2 ; } break ; case MILLISECOND : if ( dataStringPointer + 2 < dataLength ) { if ( data [ dataStart + dataStringPointer ] < '0' || data [ dataStart + dataStringPointer ] > '9' || data [ dataStart + dataStringPointer + 1 ] < '0' || data [ dataStart + dataStringPointer + 1 ] > '9' || data [ dataStart + dataStringPointer + 2 ] < '0' || data [ dataStart + dataStringPointer + 2 ] > '9' ) { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( "Unexpected millisecond string : " + decode ( data , dataStart + dataStringPointer , dataStart + dataStringPointer + 3 ) ) ; } else { return false ; } } millisecond = ( data [ dataStart + dataStringPointer ] - '0' ) * 100 + ( data [ dataStart + dataStringPointer + 1 ] - '0' ) * 10 + ( data [ dataStart + dataStringPointer + 2 ] - '0' ) ; dataStringPointer += 3 ; } break ; } } }
} else { return false ; } } if ( byteArrayEqualToString ( data , dataStart + dataStringPointer , 2 , AM_BYTEARRAY ) ) { // do nothing } else if ( byteArrayEqualToString ( data , dataStart + dataStringPointer , 2 , PM_BYTEARRAY ) ) { hour += 12 ; if ( hour == 24 ) { hour = 0 ; } } else { if ( raiseParseDataError ) { < |startfocus| > throw new AsterixTemporalTypeParseException ( "Unexpected string for AM / PM marker " + decode ( data , dataStart + dataStringPointer , dataStart + dataStringPointer + 2 ) ) ; < |endfocus| > } else { return false ; } } dataStringPointer += 2 ; } else { if ( raiseParseDataError ) { throw new AsterixTemporalTypeParseException ( "Cannot find valid AM / PM marker . " ) ; } else { return false ; } } break ; case SKIPPER : // just skip all continuous character and numbers
public long getWrites ( ) { try { List < String > rows = getInfo ( ) ; long writes = extractRow ( rows , 5 ) ; long cancelledWrites = extractRow ( rows , 6 ) ; < |startfocus| > return writes - cancelledWrites ; < |endfocus| > } catch ( Exception e ) { LOGGER . log ( failureCount ++ > 0 ? Level . DEBUG : Level . WARN , "Failure getting writes" , e ) ; return IOCounterDefault . IO_COUNTER_UNAVAILABLE ; }
"Input stream given to OnDiskInvertedIndex bulk load is not sorted . " ) ; } } // Remember last tuple by creating a copy . // TODO : This portion can be optimized by only copying the token when it changes , and using the last appended inverted - list element as a reference . lastTupleBuilder . reset ( ) ; for ( int i = 0 ; i < tuple . getFieldCount ( ) ; i ++ ) { lastTupleBuilder . addField ( tuple . getFieldData ( i ) , tuple . getFieldStart ( i ) , tuple . getFieldLength ( i ) ) ; < |startfocus| > } < |endfocus| > } @Override public void end ( ) throws HyracksDataException { // The last tuple builder is empty if add ( ) was never called . if ( lastTupleBuilder . getSize ( ) != 0 ) { createAndInsertBTreeTuple ( ) ; } btreeBulkloader . end ( ) ; if ( currentPage != null ) { queue . put ( currentPage ) ; } invListsMaxPageId = currentPageId ; bufferCache . finishQueue ( ) ; } @Override public void abort ( ) throws HyracksDataException { if ( btreeBulkloader != null ) { btreeBulkloader . abort ( ) ; } } } @Override
lastTupleBuilder . reset ( ) ; for ( int i = 0 ; i < tuple . getFieldCount ( ) ; i ++ ) { lastTupleBuilder . addField ( tuple . getFieldData ( i ) , tuple . getFieldStart ( i ) , tuple . getFieldLength ( i ) ) ; } } @Override public void end ( ) throws HyracksDataException { // The last tuple builder is empty if add ( ) was never called . if ( lastTupleBuilder . getSize ( ) != 0 ) { createAndInsertBTreeTuple ( ) ; < |startfocus| > } < |endfocus| > btreeBulkloader . end ( ) ; if ( currentPage != null ) { queue . put ( currentPage ) ; } invListsMaxPageId = currentPageId ; bufferCache . finishQueue ( ) ; } @Override public void abort ( ) throws HyracksDataException { if ( btreeBulkloader != null ) { btreeBulkloader . abort ( ) ; } } } @Override public IBufferCache getBufferCache ( ) { return bufferCache ; } public int getInvListsFileId ( ) { return fileId ; } public int getInvListsMaxPageId ( ) { return invListsMaxPageId ; } @Override public IBinaryComparatorFactory [ ] getInvListCmpFactories ( ) {
} public class OnDiskInvertedIndexAccessor implements IInvertedIndexAccessor { private final OnDiskInvertedIndex index ; private final IInvertedIndexSearcher searcher ; private final IIndexOperationContext opCtx = new OnDiskInvertedIndexOpContext ( btree ) ; public OnDiskInvertedIndexAccessor ( OnDiskInvertedIndex index ) throws HyracksDataException { this . index = index ; this . searcher = new TOccurrenceSearcher ( ctx , index ) ; } // Let subclasses initialize . protected OnDiskInvertedIndexAccessor ( OnDiskInvertedIndex index , IInvertedIndexSearcher searcher ) { this . index = index ; this . searcher = searcher ; } @Override < |startfocus| > public IIndexCursor createSearchCursor ( boolean exclusive ) { return new OnDiskInvertedIndexSearchCursor ( searcher , index . getInvListTypeTraits ( ) . length ) ; < |endfocus| > } @Override public void search ( IIndexCursor cursor , ISearchPredicate searchPred ) throws HyracksDataException { searcher . search ( ( OnDiskInvertedIndexSearchCursor ) cursor , ( InvertedIndexSearchPredicate ) searchPred , opCtx ) ; } @Override public IInvertedListCursor createInvertedListCursor ( ) { return index . createInvertedListCursor ( ) ; } @Override public void openInvertedListCursor ( IInvertedListCursor listCursor , ITupleReference searchKey ) throws HyracksDataException {
public void setKeyTuple ( ITupleReference key ) { < |startfocus| > newToken = this . keyTuple == null ; < |endfocus| > this . keyTuple = key ;
for ( int i = 0 ; i < end ; i ++ ) { if ( bloomFilters [ i ] != null && ! bloomFilters [ i ] . contains ( keysOnlyTuple , hashes ) ) { continue ; } deletedKeysBTreeAccessors . get ( i ) . search ( deletedKeysBTreeCursors [ i ] , keySearchPred ) ; try { if ( deletedKeysBTreeCursors [ i ] . hasNext ( ) ) { return true ; } } finally { deletedKeysBTreeCursors [ i ] . close ( ) ; } } return false ; } @Override public void doClose ( ) throws HyracksDataException { < |startfocus| > < < < < < < < HEAD < |endfocus| > try { super . doClose ( ) ; } finally { if ( deletedKeysBTreeCursors != null ) { for ( int i = 0 ; i < deletedKeysBTreeCursors . length ; i ++ ) { deletedKeysBTreeCursors [ i ] . close ( ) ; } } } == == == = if ( deletedKeysBTreeCursors != null ) { for ( int i = 0 ; i < deletedKeysBTreeCursors . length ; i ++ ) { deletedKeysBTreeCursors [ i ] . close ( ) ; } } super . doClose ( ) ; > > > > > > > initial commit } @Override public void doDestroy ( ) throws HyracksDataException { < |startfocus| > < < < < < < < HEAD < |endfocus| > try { super . doDestroy ( ) ; } finally { if ( deletedKeysBTreeCursors != null ) { for ( int i = 0 ; i < deletedKeysBTreeCursors . length ; i ++ ) { deletedKeysBTreeCursors [ i ] . close ( ) ; } } } == == == = if ( deletedKeysBTreeCursors != null ) { for ( int i = 0 ; i < deletedKeysBTreeCursors . length ; i ++ ) { deletedKeysBTreeCursors [ i ] . close ( ) ; } } super . doDestroy ( ) ; > > > > > > > initial commit }
IIndex invIndex = testCtx . getIndex ( ) ; if ( LOGGER . isInfoEnabled ( ) ) { LOGGER . info ( "Validating index : " + invIndex ) ; } // Validate index and compare against expected index . invIndex . validate ( ) ; if ( invIndexType == InvertedIndexType . INMEMORY || invIndexType == InvertedIndexType . ONDISK ) { // This comparison method exercises different features of these types of inverted indexes . LSMInvertedIndexTestUtils . compareActualAndExpectedIndexes ( testCtx ) ; } < |startfocus| > // LSMInvertedIndexTestUtils . compareActualAndExpectedIndexesRangeSearch ( testCtx ) ; < |endfocus| > if ( invIndexType == InvertedIndexType . LSM || invIndexType == InvertedIndexType . PARTITIONED_LSM ) { LSMInvertedIndex lsmIndex = ( LSMInvertedIndex ) invIndex ; if ( ! lsmIndex . isMemoryComponentsAllocated ( ) || lsmIndex . isCurrentMutableComponentEmpty ( ) ) { LSMInvertedIndexTestUtils . compareActualAndExpectedIndexesMergeSearch ( testCtx ) ; } } } /* * * Runs a workload of queries using different search modifiers , and verifies the correctness of the results . */ protected void runTinySearchWorkload ( LSMInvertedIndexTestContext testCtx , TupleGenerator tupleGen ) throws IOException { for ( IInvertedIndexSearchModifier searchModifier : TEST_SEARCH_MODIFIERS ) { < |startfocus| > // LSMInvertedIndexTestUtils . compareActualAndExpectedIndexesRangeSearch ( testCtx ) ; < |endfocus| >
* @throws AlgebricksException */ public boolean isSubFieldNullable ( List < String > subFieldName ) throws AlgebricksException { IAType subRecordType = getFieldType ( subFieldName . get ( 0 ) ) ; boolean nullable = false ; for ( int i = 1 ; i < subFieldName . size ( ) ; i ++ ) { if ( subRecordType == null ) { // open field is nullable return true ; } if ( subRecordType . getTypeTag ( ) . equals ( ATypeTag . UNION ) ) { if ( NonTaggedFormatUtil . isOptional ( subRecordType ) ) { < |startfocus| > return true ; < |endfocus| > } subRecordType = ( ( AUnionType ) subRecordType ) . getActualType ( ) ; if ( subRecordType . getTypeTag ( ) != ATypeTag . OBJECT ) { throw new AsterixException ( "Field accessor is not defined for values of type " + subRecordType . getTypeTag ( ) ) ; } } subRecordType = ( ( ARecordType ) subRecordType ) . getFieldType ( subFieldName . get ( i ) ) ; } return nullable || subRecordType == null || NonTaggedFormatUtil . isOptional ( subRecordType ) ; } /* *
boolean changed = changeRec ( expr , arg ) ; if ( ! checkArgs ( expr ) || ! expr . isFunctional ( ) ) { return new Pair < > ( changed , expr ) ; } // Skip Constant Folding for the record - related functions . if ( FUNC_ID_SET_THAT_SHOULD_NOT_BE_APPLIED . contains ( expr . getFunctionIdentifier ( ) ) ) { return new Pair < > ( false , null ) ; } try { < |startfocus| > // Current List SerDe assumes a strongly typed list , so we do not constant fold the list constructors if they are not strongly typed < |endfocus| > if ( expr . getFunctionIdentifier ( ) . equals ( BuiltinFunctions . UNORDERED_LIST_CONSTRUCTOR ) || expr . getFunctionIdentifier ( ) . equals ( BuiltinFunctions . ORDERED_LIST_CONSTRUCTOR ) ) { AbstractCollectionType listType = ( AbstractCollectionType ) TypeCastUtils . getRequiredType ( expr ) ; if ( listType != null && ( listType . getItemType ( ) . getTypeTag ( ) == ATypeTag . ANY || listType . getItemType ( ) instanceof AbstractCollectionType ) ) { // case1 : listType == null , could be a nested list inside a list < ANY > // case2 : itemType = ANY // case3 : itemType = a nested list } } }
IScalarEvaluator eval = fact . createScalarEvaluator ( null ) ; eval . evaluate ( null , p ) ; Object t = _emptyTypeEnv . getType ( expr ) ; @SuppressWarnings ( "rawtypes" ) ISerializerDeserializer serde = jobGenCtx . getSerializerDeserializerProvider ( ) . getSerializerDeserializer ( t ) ; bbis . setByteBuffer ( ByteBuffer . wrap ( p . getByteArray ( ) , p . getStartOffset ( ) , p . getLength ( ) ) , 0 ) ; IAObject o = ( IAObject ) serde . deserialize ( dis ) ; return new Pair < > ( true , new ConstantExpression ( new AsterixConstantValue ( o ) ) ) ; < |startfocus| > } catch ( HyracksDataException | AlgebricksException e ) { < |endfocus| > return new Pair < > ( false , null ) ; } } @Override public Pair < Boolean , ILogicalExpression > visitAggregateFunctionCallExpression ( AggregateFunctionCallExpression expr , Void arg ) throws AlgebricksException { boolean changed = changeRec ( expr , arg ) ; return new Pair < > ( changed , expr ) ; } @Override public Pair < Boolean , ILogicalExpression > visitStatefulFunctionCallExpression ( StatefulFunctionCallExpression expr , Void arg ) throws AlgebricksException { boolean changed = changeRec ( expr , arg ) ; return new Pair < > ( changed , expr ) ; } @Override
empty - tuple - source -- |UNPARTITIONED| assign [ $$29 ] <- [ TRUE ] -- |UNPARTITIONED| assign [ $$26 ] <- [ TRUE ] -- |UNPARTITIONED| data - scan [ ] <- [ $$20 , $$21 , $$2 ] <- tpch : LineItems -- |UNPARTITIONED| empty - tuple - source -- |UNPARTITIONED| */ public class InlineSubplanInputForNestedTupleSourceRule implements IAlgebraicRewriteRule { @Override public boolean rewritePre ( Mutable < ILogicalOperator > opRef , IOptimizationContext context ) throws AlgebricksException { if ( context . checkIfInDontApplySet ( this , opRef . getValue ( ) ) ) { return false ; } Pair < Boolean , LinkedHashMap < LogicalVariable , LogicalVariable > > result = rewriteSubplanOperator ( opRef , context ) ; return result . first ; } private Pair < Boolean , LinkedHashMap < LogicalVariable , LogicalVariable > > rewriteSubplanOperator ( Mutable < ILogicalOperator > opRef , IOptimizationContext context ) throws AlgebricksException { AbstractLogicalOperator op = ( AbstractLogicalOperator ) opRef . getValue ( ) ; // Recursively traverses input operators as if the current operator before rewriting the current operator . Pair < Boolean , LinkedHashMap < LogicalVariable , LogicalVariable > > changedAndVarMap = traverseNonSubplanOperator ( op , context ) ;
translator . addVariableToMetaScope ( new VarIdentifier ( "$$RIGHT_" + i ) , rightInputVarCopy ) ; for ( int j = 0 ; j < rightInputPKs . size ( ) ; j ++ ) { rightInputVarCopy = copyVisitor . varCopy ( rightInputPKs . get ( j ) ) ; translator . addVariableToMetaScope ( new VarIdentifier ( "$$RIGHTPK_" + i + "_" + j ) , rightInputVarCopy ) ; } copyVisitor . updatePrimaryKeys ( context ) ; copyVisitor . reset ( ) ; } < |startfocus| > counter . set ( context . getVarCounter ( ) ) ; < |endfocus| > AQLPlusParser parser = new AQLPlusParser ( new StringReader ( aqlPlus ) ) ; parser . initScope ( ) ; parser . setVarCounter ( counter ) ; List < Clause > clauses ; try { clauses = parser . Clauses ( ) ; } catch ( ParseException e ) { throw new AlgebricksException ( e ) ; } // Step 4 . The essential substitution with translator . ILogicalPlan plan ; try { plan = translator . translate ( clauses ) ; } catch ( AsterixException e ) { throw new AlgebricksException ( e ) ; } context . setVarCounter ( counter . get ( ) ) ;
} while ( triggerCount == previousTriggerCount ) ; return triggerCount ; } /* * * Test time - based invalidation in CatalogdTableInvalidator . */ @Test public void testCatalogdTableInvalidator ( ) throws CatalogException , InterruptedException { Reference < Boolean > tblWasRemoved = new Reference < > ( ) ; Reference < Boolean > dbWasAdded = new Reference < > ( ) ; String dbName = "functional" ; String tblName = "alltypes" ; < |startfocus| > catalog_ . invalidateTable ( new TTableName ( dbName , tblName ) , tblWasRemoved , dbWasAdded ) ; < |endfocus| > MockTicker ticker = new MockTicker ( ) ; CatalogdTableInvalidator . TIME_SOURCE = ticker ; catalog_ . setCatalogdTableInvalidator ( new CatalogdTableInvalidator ( catalog_ , /* unusedTableTtlSec =* / 2 , /* invalidateTablesOnMemoryPressure =* / false , /* oldGenFullThreshold =* / 0 . 6 , /* gcInvalidationFraction =* / 0 . 1 ) ) ; Assert . assertFalse ( catalog_ . getDb ( dbName ) . getTable ( tblName ) . isLoaded ( ) ) ; Table table = catalog_ . getOrLoadTable ( dbName , tblName ) ; Assert . assertTrue ( table . isLoaded ( ) ) ; Assert . assertEquals ( ticker . now_ , table . getLastUsedTime ( ) ) ; long previousTriggerCount = catalog_ . getCatalogdTableInvalidator ( ) . triggerCount_ . get ( ) ;
profile_ = new TRuntimeProfileNode ( "Frontend" , /* num_children =* / 0 , /* counters =* / new ArrayList < > ( ) , /* metadata =* /- 1L , // TODO ( todd ) what is this used for ? why is it required ? /* indent =* / false , /* info_strings =* / new HashMap < > ( ) , /* info_strings_display_order */ new ArrayList < > ( ) , /* child_counters_map =* / ImmutableMap . of ( ROOT_COUNTER_NAME , new HashSet < > ( ) ) ) ; } /* * < |startfocus| > * Create a new profile , setting it as the current thread - local profile for the < |endfocus| > * length of the current scope . This is meant to be used in a try - with - resources * statement . */ public static Scope createNewWithScope ( ) { return new Scope ( new FrontendProfile ( ) ) ; } /* * * Get the profile attached to the current thread , throw IllegalStateException if there * is none . */ @Nonnull public static FrontendProfile getCurrent ( ) { FrontendProfile prof = THREAD_LOCAL . get ( ) ; Preconditions . checkState ( prof != null , "no profile in scope" ) ; return prof ; } /* *
private boolean shouldEvictFromFullHeapAfterGc ( ) { if ( ! invalidateTableOnMemoryPressure_ ) return false ; long gcCount = oldGenGcBean_ . getCollectionCount ( ) ; if ( gcCount > lastObservedGcCount_ ) { lastObservedGcCount_ = gcCount ; GcInfo lastGcInfo = oldGenGcBean_ . getLastGcInfo ( ) ; if ( lastGcInfo == null ) { < |startfocus| > LOG . warn ( "Table invalidation due to memory pressure was skipped . " ) ; < |endfocus| > return false ; } MemoryUsage tenuredGenUsage = lastGcInfo . getMemoryUsageAfterGc ( ) . get ( oldGcGenName_ ) ; return tenuredGenUsage . getMax ( ) * oldGenFullThreshold_ < tenuredGenUsage . getUsed ( ) ; } return false ;
long gcCount = oldGenGcBean_ . getCollectionCount ( ) ; if ( gcCount > lastObservedGcCount_ ) { lastObservedGcCount_ = gcCount ; GcInfo lastGcInfo = oldGenGcBean_ . getLastGcInfo ( ) ; if ( lastGcInfo == null ) { LOG . warn ( "gcBean . getLastGcInfo ( ) returns null . Will continue without " + "invalidating tables based on memory pressure this time . " ) ; return false ; } MemoryUsage tenuredGenUsage = lastGcInfo . getMemoryUsageAfterGc ( ) . get ( oldGcGenName_ ) ; return tenuredGenUsage . getMax ( ) * oldGenFullThreshold_ < tenuredGenUsage . getUsed ( ) ; } return false ;
if ( removedDb == null ) { // Nothing was removed from the catalogd's cache . resp . result . setVersion ( catalog_ . getCatalogVersion ( ) ) ; return ; } // Make sure the cache directives , if any , of the underlying tables are removed for ( String tableName : removedDb . getAllTableNames ( ) ) { uncacheTable ( removedDb . getTable ( tableName ) ) ; } removedObject = removedDb . toTCatalogObject ( ) ; } < |startfocus| > updateDatabasePrivileges ( db . getName ( ) , /* tableName */ null , params . server_name , < |endfocus| > db . getMetaStoreDb ( ) . getOwnerName ( ) , db . getMetaStoreDb ( ) . getOwnerType ( ) , /* newOwner */ null , /* newOwnerType */ null , resp ) ; Preconditions . checkNotNull ( removedObject ) ; resp . result . setVersion ( removedObject . getCatalog_version ( ) ) ; resp . result . addToRemoved_catalog_objects ( removedObject ) ; addSummary ( resp , "Database has been dropped . " ) ; } /* * * Drops all the Kudu tables of database 'db' from the Kudu storage engine . Retrieves * the Kudu table name of each table in 'db' from HMS . Throws an ImpalaException if * there is an error . */ private void dropKuduTables ( TDropDbParams params , TDdlExecResponse resp ) throws ImpalaException {
table = catalog_ . removeTable ( params . getTable_name ( ) . db_name , params . getTable_name ( ) . table_name ) ; if ( table == null ) { // Nothing was removed from the catalogd's cache . resp . result . setVersion ( catalog_ . getCatalogVersion ( ) ) ; return ; } resp . result . setVersion ( table . getCatalogVersion ( ) ) ; uncacheTable ( table ) ; } if ( table . getMetaStoreTable ( ) != null ) { < |startfocus| > updateDatabasePrivileges ( table . getDb ( ) . getName ( ) , table . getName ( ) , params . server_name , table . getMetaStoreTable ( ) . getOwner ( ) , table . getMetaStoreTable ( ) . getOwnerType ( ) , /* newOwner */ null , /* newOwnerType */ null , resp ) ; < |endfocus| > } removedObject . setType ( TCatalogObjectType . TABLE ) ; removedObject . setTable ( new TTable ( ) ) ; removedObject . getTable ( ) . setTbl_name ( tableName . getTbl ( ) ) ; removedObject . getTable ( ) . setDb_name ( tableName . getDb ( ) ) ; removedObject . setCatalog_version ( resp . result . getVersion ( ) ) ; resp . result . addToRemoved_catalog_objects ( removedObject ) ; } /* * * Removes a function from the catalog cache . Also removes all associated privileges . * * @param params * @param resp * @throws ImpalaException */ private void removeFunction ( RemoveFunctionParams params , RemoveFunctionResult resp ) throws ImpalaException { Function desc = Function . fromThrift ( params . fn ) ; if ( desc == null ) { throw new ImpalaRuntimeException ( String . format ( "Unknown function : % s . % s ( ) " , params . fn . name . db_name , params . fn . name . function_name ) ) ; } catalog_ . removeFunction ( desc ) ; resp . setVersion ( catalog_ . getCatalogVersion ( ) ) ; TCatalogObject removedObject = new TCatalogObject ( ) ; removedObject . setType ( TCatalogObjectType . FUNCTION ) ; removedObject . setFn ( new org . apache . impala . thrift . TFunction ( ) ) ; removedObject . getFn ( ) . setSignature ( desc . signatureString ( ) ) ; removedObject . setCatalog_version ( resp . getVersion ( ) ) ; resp . addToRemoved_catalog_objects ( removedObject ) ; } /* *
// list of the revoked privileges that contain the grant option . The rolePrivileges // parameter will contain a list of new privileges without the grant option that are // granted . If this is simply a revoke of a privilege without grant options , the // api will still return revoked privileges , but the rolePrivileges will be empty // since there will be no newly granted privileges . rolePrivileges = Lists . newArrayList ( ) ; < |startfocus| > removedGrantOptPrivileges = catalog_ . getSentryProxy ( ) . revokeRolePrivileges ( requestingUser , roleName , privileges , grantRevokePrivParams . isHas_grant_opt ( ) , rolePrivileges ) ; < |endfocus| > addSummary ( resp , "Privilege ( s ) have been revoked . " ) ; } Preconditions . checkNotNull ( rolePrivileges ) ; List < TCatalogObject > updatedPrivs = Lists . newArrayList ( ) ; for ( PrincipalPrivilege rolePriv : rolePrivileges ) { updatedPrivs . add ( rolePriv . toTCatalogObject ( ) ) ; } List < TCatalogObject > removedPrivs = Lists . newArrayList ( ) ; for ( PrincipalPrivilege rolePriv : removedGrantOptPrivileges ) { removedPrivs . add ( rolePriv . toTCatalogObject ( ) ) ; }
} resp . result . setVersion ( role . getCatalogVersion ( ) ) ; } /* * * Grants or revokes one or more privileges to / from a Sentry role on behalf of the * requestingUser . */ private void grantRevokeRolePrivilege ( User requestingUser , TGrantRevokePrivParams grantRevokePrivParams , TDdlExecResponse resp ) throws ImpalaException { Preconditions . checkNotNull ( requestingUser ) ; verifySentryServiceEnabled ( ) ; String roleName = grantRevokePrivParams . getRole_name ( ) ; List < TPrivilege > privileges = grantRevokePrivParams . getPrivileges ( ) ; < |startfocus| > List < PrincipalPrivilege > rolePrivileges = null ; < |endfocus| > List < PrincipalPrivilege > removedGrantOptPrivileges = Lists . newArrayList ( ) ; if ( grantRevokePrivParams . isIs_grant ( ) ) { rolePrivileges = catalog_ . getSentryProxy ( ) . grantRolePrivileges ( requestingUser , roleName , privileges ) ; addSummary ( resp , "Privilege ( s ) have been granted . " ) ; } else { // If this is a revoke of a privilege that contains the grant option , the privileges // with the grant option will be revoked and new privileges without the grant option // will be added .
} if ( ! updatedPrivs . isEmpty ( ) || ! removedPrivs . isEmpty ( ) ) { // If this is a REVOKE statement with hasGrantOpt , only the GRANT OPTION is removed // from the privileges . Otherwise the privileges are removed from the catalog . if ( grantRevokePrivParams . isIs_grant ( ) ) { resp . result . setUpdated_catalog_objects ( updatedPrivs ) ; resp . result . setVersion ( updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; < |startfocus| > } else if ( privileges . get ( 0 ) . isHas_grant_opt ( ) ) { < |endfocus| > resp . result . setUpdated_catalog_objects ( updatedPrivs ) ; resp . result . setRemoved_catalog_objects ( removedPrivs ) ; resp . result . setVersion ( updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) > removedPrivs . get ( removedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ? updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) : removedPrivs . get ( removedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; } else { resp . result . setRemoved_catalog_objects ( removedPrivs ) ; resp . result . setVersion ( removedPrivs . get ( removedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; } } return resp ; }
private static final String ERROR_MSG_BAD_COLUMN_VALUE = "Raw value '" + ROW_BAD_COLUMN_VALUE + "' couldn't be parsed to type Type : int8 for column 'byteFld'" ; private static final String POLICY_REJECT = "REJECT" ; private static final String POLICY_WARN = "WARN" ; private static final String POLICY_IGNORE = "IGNORE" ; @Rule < |startfocus| > public ExpectedException thrown = ExpectedException . none ( ) ; < |endfocus| > @Test public void testMissingColumnThrowsExceptionDefaultConfig ( ) throws Exception { Context additionalContext = new Context ( ) ; additionalContext . put ( PATTERN_PROP , TEST_REGEXP_MISSING_COLUMN ) ; testThrowsException ( additionalContext , ERROR_MSG_MISSING_COLUMN , ROW_MISSING_COLUMN ) ; } @Test public void testMissingColumnThrowsExceptionDeprecated ( ) throws Exception { Context additionalContext = new Context ( ) ; additionalContext . put ( PATTERN_PROP , TEST_REGEXP_MISSING_COLUMN ) ; additionalContext . put ( SKIP_MISSING_COLUMN_PROP , String . valueOf ( false ) ) ; testThrowsException ( additionalContext , ERROR_MSG_MISSING_COLUMN , ROW_MISSING_COLUMN ) ; } @Test public void testMissingColumnThrowsException ( ) throws Exception { Context additionalContext = new Context ( ) ;
* The phases of aggregate computation are as follows . Also see AggregateInfo . * - Only a non - distinct class : * - Example : SELECT max ( a ) FROM . . . * - 1 - phase aggregation * - One distinct class , and optionally a non - distinct class : * - Example : SELECT count ( distinct a ) [ , max ( b ) ] FROM . . . * - coalesced into a single AggregateInfo to preserve the pre - IMPALA - 110 behavior < |startfocus| > * - 2 - phase aggregation , 1st phase groups by GROUP BY ples DISTINCT exprs , 2nd phase < |endfocus| > * groups by GROUP BY * - the non - distinct class is carried along the two phases , aggregated in 1st phase and * merged in 2nd phase * - Multiple distinct classes , and optionally a non - distinct class * - Example : SELECT count ( distinct a ) , count ( distinct b ) [ , max ( c ) ] FROM . . . * - 2 - phase aggregation followed by a transposition aggregation * - aggregation nodes update and maintain the state of all aggregation classes at once < |startfocus| > * - The phases of aggregate computation are as follows . Also see AggregateInfo . * - Only a non - distinct class : * - Example : SELECT max ( a ) FROM . . . * - 1 - phase aggregation * - One distinct class , and optionally a non - distinct class : * - Example : SELECT count ( distinct a ) [ , max ( b ) ] FROM . . . * - coalesced into a single AggregateInfo to preserve the pre - IMPALA - 110 behavior * - 2 - phase aggregation , 1st phase groups by GROUP BY ples DISTINCT exprs , 2nd phase * groups by GROUP BY * - the non - distinct class is carried along the two phases , aggregated in 1st phase and * merged in 2nd phase * - Multiple distinct classes , and optionally a non - distinct class * - Example : SELECT count ( distinct a ) , count ( distinct b ) [ , max ( c ) ] FROM . . . * - 2 - phase aggregation followed by a transposition aggregation * - aggregation nodes update and maintain the state of all aggregation classes at once < |endfocus| >
/* * * The number of times the daemon thread wakes up and scans the tables for invalidation . < |startfocus| > * It's useful for tests to ensure that a scanning occurred and to proceed . < |endfocus| > */ @VisibleForTesting AtomicLong scanCount_ = new AtomicLong ( ) ; private GarbageCollectorMXBean oldGenGcBean_ ; /* * * The name of the old gen memory pool . */ private String oldGcGenName_ ; /* * * The value of oldGenGcBean_ . getCollectionCount ( ) when the last memory - based * invalidation was executed . */ private long lastObservedGcCount_ ; private boolean stopped_ = false ; /* * * Last time an time - based invalidation is executed in nanoseconds . */ private long lastInvalidationTime_ ;
private boolean shouldEvictFromFullHeapAfterGc ( ) { if ( ! invalidateTableOnMemoryPressure_ ) return false ; long gcCount = oldGenGcBean_ . getCollectionCount ( ) ; if ( gcCount > lastObservedGcCount_ ) { lastObservedGcCount_ = gcCount ; GcInfo lastGcInfo = oldGenGcBean_ . getLastGcInfo ( ) ; if ( lastGcInfo == null ) { < |startfocus| > LOG . warn ( "gcBean . getLastGcInfo ( ) returned null . Will continue without " + "invalidating tables based on memory pressure this time . " ) ; < |endfocus| > return false ; } MemoryUsage tenuredGenUsage = lastGcInfo . getMemoryUsageAfterGc ( ) . get ( oldGcGenName_ ) ; return tenuredGenUsage . getMax ( ) * oldGenFullThreshold_ < tenuredGenUsage . getUsed ( ) ; } return false ;
* If a user with the same name already exists it will be overwritten . */ public User addUser ( String userName ) { Principal user = addPrincipal ( userName , Sets . < String > newHashSet ( ) , TPrincipalType . USER ) ; Preconditions . checkState ( user instanceof User ) ; return ( User ) user ; } /* * * Add a user to the catalog if it doesn't exist . This is necessary so privileges < |startfocus| > * can be added for a user . For example : owner privileges . < |endfocus| > */ public org . apache . impala . catalog . User addUserIfNotExists ( String owner ) { versionLock_ . writeLock ( ) . lock ( ) ; try { org . apache . impala . catalog . User user = getAuthPolicy ( ) . getUser ( owner ) ; if ( user == null ) { user = addUser ( owner ) ; } return user ; } finally { versionLock_ . writeLock ( ) . unlock ( ) ; } } private Principal addPrincipal ( String principalName , Set < String > grantGroups , TPrincipalType type ) { versionLock_ . writeLock ( ) . lock ( ) ; try { Principal principal = Principal . newInstance ( principalName , type , grantGroups ) ;
PrincipalPrivilege privilege = owner . getPrivilege ( filter . getPrivilege_name ( ) ) ; if ( privilege != null ) { PrincipalPrivilege removedPrivilege = catalog_ . getAuthPolicy ( ) . removePrivilege ( privilege ) ; removedPrivilege . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; response . result . addToRemoved_catalog_objects ( removedPrivilege . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } } } catch ( CatalogException e ) { < |startfocus| > LOG . error ( "Error modifying privilege : " , e ) ; < |endfocus| > } } /* * * This is a helper method to take care of catalog related updates when removing * a privilege . */ private void addPrivilegeToCatalog ( String ownerString , PrincipalType ownerType , TPrivilege filter , TDdlExecResponse response ) { try { Principal owner ; PrincipalPrivilege cPrivilege ; if ( ownerType == PrincipalType . USER ) { owner = catalog_ . addUserIfNotExists ( ownerString ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; filter . setPrincipal_type ( TPrincipalType . USER ) ; cPrivilege = new PrincipalPrivilege ( filter ) ; } else { owner = catalog_ . addRoleIfNotExists ( ownerString ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; filter . setPrincipal_type ( TPrincipalType . ROLE ) ; cPrivilege = new PrincipalPrivilege ( filter ) ; } cPrivilege . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; catalog_ . getAuthPolicy ( ) . addPrivilege ( cPrivilege ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( cPrivilege . toTCatalogObject ( ) ) ; } catch ( CatalogException e ) { < |startfocus| > LOG . error ( "Error modifying privilege : " , e ) ; < |endfocus| > } } /* * * This is a helper method to take care of catalog related updates when removing * a privilege . */ private void removePrivilegeFromCatalog ( String ownerString , PrincipalType ownerType , TPrivilege filter , TDdlExecResponse response ) { try { Principal owner ; if ( ownerType == PrincipalType . USER ) { owner = catalog_ . getUser ( ownerString ) ; } else { owner = catalog_ . getRole ( ownerString ) ; } PrincipalPrivilege privilege = owner . getPrivilege ( filter . getPrivilege_name ( ) ) ; if ( privilege != null ) { PrincipalPrivilege removedPrivilege = catalog_ . getAuthPolicy ( ) . removePrivilege ( privilege ) ; removedPrivilege . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; response . result . addToRemoved_catalog_objects ( removedPrivilege . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } } catch ( CatalogException e ) { < |startfocus| > LOG . error ( "Error modifying privilege : " , e ) ; < |endfocus| > } } /* * * This is a helper method to take care of catalog related updates when removing * a privilege . */ private void addPrivilegeToCatalog ( String ownerString , PrincipalType ownerType , TPrivilege filter , TDdlExecResponse response ) { try { Principal owner ; PrincipalPrivilege cPrivilege ; if ( ownerType == PrincipalType . USER ) { owner = catalog_ . addUserIfNotExists ( ownerString ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; filter . setPrincipal_type ( TPrincipalType . USER ) ; cPrivilege = new PrincipalPrivilege ( filter ) ; } else { owner = catalog_ . addRoleIfNotExists ( ownerString ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; filter . setPrincipal_type ( TPrincipalType . ROLE ) ; cPrivilege = new PrincipalPrivilege ( filter ) ; } cPrivilege . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; catalog_ . getAuthPolicy ( ) . addPrivilege ( cPrivilege ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( cPrivilege . toTCatalogObject ( ) ) ; } catch ( CatalogException e ) { < |startfocus| > LOG . error ( "Error modifying privilege : " , e ) ; < |endfocus| > } } /* * * This is a helper method to take care of catalog related updates when removing * a privilege . */ private void removePrivilegeFromCatalog ( String ownerString , PrincipalType ownerType , TPrivilege filter , TDdlExecResponse response ) { try { Principal owner ; if ( ownerType == PrincipalType . USER ) { owner = catalog_ . getUser ( ownerString ) ; } else { owner = catalog_ . getRole ( ownerString ) ; } PrincipalPrivilege privilege = owner . getPrivilege ( filter . getPrivilege_name ( ) ) ; if ( privilege != null ) { PrincipalPrivilege removedPrivilege = catalog_ . getAuthPolicy ( ) . removePrivilege ( privilege ) ; removedPrivilege . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; response . result . addToRemoved_catalog_objects ( removedPrivilege . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } } catch ( CatalogException e ) { < |startfocus| > LOG . error ( "Error modifying privilege : " , e ) ; < |endfocus| > } } /* * * This is a helper method to take care of catalog related updates when removing * a privilege . */ private void addPrivilegeToCatalog ( String ownerString , PrincipalType ownerType , TPrivilege filter , TDdlExecResponse response ) { try { Principal owner ; PrincipalPrivilege cPrivilege ; if ( ownerType == PrincipalType . USER ) { owner = catalog_ . addUserIfNotExists ( ownerString ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; filter . setPrincipal_type ( TPrincipalType . USER ) ;
} else { owner = catalog_ . getAuthPolicy ( ) . getRole ( ownerString ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; filter . setPrincipal_type ( TPrincipalType . ROLE ) ; cPrivilege = catalog_ . addRolePrivilege ( ownerString , filter ) ; } owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; response . result . addToUpdated_catalog_objects ( cPrivilege . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } catch ( CatalogException e ) { < |startfocus| > LOG . error ( "Error modifying privilege : " , e ) ; < |endfocus| > } } /* * * Create a new HMS Partition . */ private static Partition createHmsPartition ( List < TPartitionKeyValue > partitionSpec , org . apache . hadoop . hive . metastore . api . Table msTbl , TableName tableName , String location ) { List < String > values = Lists . newArrayList ( ) ; // Need to add in the values in the same order they are defined in the table . for ( FieldSchema fs : msTbl . getPartitionKeys ( ) ) { for ( TPartitionKeyValue kv : partitionSpec ) { < |startfocus| >
Map < String , Set < TSentryPrivilege > > allUsersPrivileges = sentryPolicyService_ . listAllUsersPrivileges ( processUser_ ) ; for ( Map . Entry < String , Set < TSentryPrivilege > > userPrivilegesEntry : allUsersPrivileges . entrySet ( ) ) { String userName = userPrivilegesEntry . getKey ( ) ; // This user exists and should not be removed so remove it from the // usersToRemove set . usersToRemove . remove ( userName ) ; < |startfocus| > org . apache . impala . catalog . User user = catalog_ . addUserIfNotExists ( userName ) ; if ( resetVersions_ ) { < |endfocus| > user . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; } refreshPrivilegesInCatalog ( user , allUsersPrivileges ) ; } return usersToRemove ; } /* * * Updates the privileges for a given principal in the catalog since the last Sentry * sync update . */ private void refreshPrivilegesInCatalog ( Principal principal , Map < String , Set < TSentryPrivilege > > allPrincipalPrivileges ) throws CatalogException { // Assume all privileges should be removed . Privileges that still exist are // deleted from this set and we are left with the set of privileges that need // to be removed .
TableName tableName = table . getTableName ( ) ; PrivilegeRequestBuilder builder = new PrivilegeRequestBuilder ( ) . onTable ( tableName . getDb ( ) , tableName . getTbl ( ) ) . allOf ( priv ) ; if ( requireGrantOption ) { builder . grantOption ( ) ; } registerPrivReq ( builder . toRequest ( ) ) ; } /* * * Returns the server name if authorization is enabled . Returns null when authorization * is not enabled . */ public String getServerName ( ) { < |startfocus| > return getAuthzConfig ( ) . isEnabled ( ) ? getAuthzConfig ( ) . getServerName ( ) : null ; < |endfocus| > } }
String serverName , String oldOwner , PrincipalType oldOwnerType , String newOwner , PrincipalType newOwnerType , TDdlExecResponse resp ) { if ( catalog_ . getSentryProxy ( ) == null || ! catalog_ . getSentryProxy ( ) . isObjectOwnershipEnabled ( ) ) return ; Preconditions . checkNotNull ( serverName ) ; TPrivilege filter ; if ( tableName == null ) { filter = createDatabaseOwnerPrivilegeFilter ( databaseName , serverName ) ; } else { filter = createTableOwnerPrivilegeFilter ( databaseName , tableName , serverName ) ; } < |startfocus| > if ( oldOwner != null && ! oldOwner . isEmpty ( ) ) { < |endfocus| > removePrivilegeFromCatalog ( oldOwner , oldOwnerType , filter , resp ) ; } if ( newOwner != null && ! newOwner . isEmpty ( ) ) { addPrivilegeToCatalog ( newOwner , newOwnerType , filter , resp ) ; } } private void createFunction ( TCreateFunctionParams params , TDdlExecResponse resp ) throws ImpalaException { Function fn = Function . fromThrift ( params . getFn ( ) ) ; if ( LOG . isTraceEnabled ( ) ) { LOG . trace ( String . format ( "Adding % s : % s" , fn . getClass ( ) . getSimpleName ( ) , fn . signatureString ( ) ) ) ; }
PrincipalType newOwnerType , TDdlExecResponse resp ) { if ( catalog_ . getSentryProxy ( ) == null || ! catalog_ . getSentryProxy ( ) . isObjectOwnershipEnabled ( ) ) return ; Preconditions . checkNotNull ( serverName ) ; TPrivilege filter ; if ( tableName == null ) { filter = createDatabaseOwnerPrivilegeFilter ( databaseName , serverName ) ; } else { filter = createTableOwnerPrivilegeFilter ( databaseName , tableName , serverName ) ; } < |startfocus| > if ( oldOwner != null && oldOwner . length ( ) > 0 ) { < |endfocus| > removePrivilegeFromCatalog ( oldOwner , oldOwnerType , filter , resp ) ; } if ( newOwner != null && newOwner . length ( ) > 0 ) { addPrivilegeToCatalog ( newOwner , newOwnerType , filter , resp ) ; } } private void createFunction ( TCreateFunctionParams params , TDdlExecResponse resp ) throws ImpalaException { Function fn = Function . fromThrift ( params . getFn ( ) ) ; if ( LOG . isTraceEnabled ( ) ) { LOG . trace ( String . format ( "Adding % s : % s" , fn . getClass ( ) . getSimpleName ( ) , fn . signatureString ( ) ) ) ; } boolean isPersistentJavaFn = fn . getBinaryType ( ) == TFunctionBinaryType . JAVA ;
TPrivilege filter , TDdlExecResponse response ) { try { Principal owner = catalog_ . getAuthPolicy ( ) . getPrincipal ( ownerString , ownerType == PrincipalType . ROLE ? TPrincipalType . ROLE : TPrincipalType . USER ) ; if ( owner != null ) { PrincipalPrivilege privilege = owner . getPrivilege ( filter . getPrivilege_name ( ) ) ; if ( privilege != null ) { PrincipalPrivilege removedPrivilege = catalog_ . getAuthPolicy ( ) . removePrivilege ( privilege ) ; removedPrivilege . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; < |startfocus| > removedPrivilege . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; < |endfocus| > response . result . addToRemoved_catalog_objects ( removedPrivilege . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } } } catch ( CatalogException e ) { LOG . error ( "Error removing privilege : " , e ) ; } } /* * * This is a helper method to take care of catalog related updates when removing * a privilege . */ private void addPrivilegeToCatalog ( String ownerString , PrincipalType ownerType , TPrivilege filter , TDdlExecResponse response ) { try { Principal owner ; PrincipalPrivilege cPrivilege ;
PrincipalPrivilege privilege = owner . getPrivilege ( filter . getPrivilege_name ( ) ) ; if ( privilege != null ) { PrincipalPrivilege removedPrivilege = catalog_ . getAuthPolicy ( ) . removePrivilege ( privilege ) ; removedPrivilege . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; response . result . addToRemoved_catalog_objects ( removedPrivilege . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } } } catch ( CatalogException e ) { < |startfocus| > LOG . error ( "Error removing privilege : " , e ) ; < |endfocus| > } } /* * * This is a helper method to take care of catalog related updates when removing * a privilege . */ private void addPrivilegeToCatalog ( String ownerString , PrincipalType ownerType , TPrivilege filter , TDdlExecResponse response ) { try { Principal owner ; PrincipalPrivilege cPrivilege ; Reference < Boolean > existingUser = new Reference < > ( ) ; if ( ownerType == PrincipalType . USER ) { owner = catalog_ . addUserIfNotExists ( ownerString , existingUser ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; if ( existingUser . getRef ( ) ) { response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } } else { owner = catalog_ . addRoleIfNotExists ( ownerString , existingUser ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; if ( existingUser . getRef ( ) ) { response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } } cPrivilege = new PrincipalPrivilege ( filter ) ; cPrivilege . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; owner . addToPrivileges ( cPrivilege ) ; owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; response . result . addToCreated_catalog_objects ( cPrivilege . toTCatalogObject ( ) ) ; } catch ( CatalogException e ) { < |startfocus| > LOG . error ( "Error adding privilege : " , e ) ; < |endfocus| > } } /* * * This is a helper method to take care of catalog related updates when removing * a privilege . */ private void removePrivilegeFromCatalog ( String ownerString , PrincipalType ownerType , TPrivilege filter , TDdlExecResponse response ) { try { Principal owner ; if ( ownerType == PrincipalType . USER ) { owner = catalog_ . getAuthPolicy ( ) . getUser ( ownerString ) ; } else { owner = catalog_ . getAuthPolicy ( ) . getRole ( ownerString ) ; }
} } } catch ( CatalogException e ) { LOG . error ( "Error removing privilege : " , e ) ; } } /* * * This is a helper method to take care of catalog related updates when removing * a privilege . */ private void addPrivilegeToCatalog ( String ownerString , PrincipalType ownerType , TPrivilege filter , TDdlExecResponse response ) { try { Principal owner ; PrincipalPrivilege cPrivilege ; < |startfocus| > boolean existingUser = false ; < |endfocus| > if ( ownerType == PrincipalType . USER ) { owner = catalog_ . addUserIfNotExists ( ownerString , existingUser ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; filter . setPrincipal_type ( TPrincipalType . USER ) ; cPrivilege = catalog_ . addUserPrivilege ( ownerString , filter ) ; } else { owner = catalog_ . getAuthPolicy ( ) . getRole ( ownerString ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; filter . setPrincipal_type ( TPrincipalType . ROLE ) ; cPrivilege = catalog_ . addRolePrivilege ( ownerString , filter ) ; } if ( ! existingUser ) { owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; }
* a privilege . */ private void addPrivilegeToCatalog ( String ownerString , PrincipalType ownerType , TPrivilege filter , TDdlExecResponse response ) { try { Principal owner ; PrincipalPrivilege cPrivilege ; Reference < Boolean > existingUser = new Reference < > ( ) ; if ( ownerType == PrincipalType . USER ) { owner = catalog_ . addUserIfNotExists ( ownerString , existingUser ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; filter . setPrincipal_type ( TPrincipalType . USER ) ; < |startfocus| > cPrivilege = catalog_ . addUserPrivilege ( ownerString , filter ) ; < |endfocus| > } else { owner = catalog_ . getAuthPolicy ( ) . getRole ( ownerString ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; filter . setPrincipal_type ( TPrincipalType . ROLE ) ; cPrivilege = catalog_ . addRolePrivilege ( ownerString , filter ) ; } if ( ! existingUser . getRef ( ) ) { owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; } response . result . addToUpdated_catalog_objects ( cPrivilege . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } catch ( CatalogException e ) { LOG . error ( "Error adding privilege : " , e ) ; } }
if ( ownerType == PrincipalType . USER ) { owner = catalog_ . addUserIfNotExists ( ownerString , existingUser ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; filter . setPrincipal_type ( TPrincipalType . USER ) ; cPrivilege = catalog_ . addUserPrivilege ( ownerString , filter ) ; } else { owner = catalog_ . getAuthPolicy ( ) . getRole ( ownerString ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; filter . setPrincipal_type ( TPrincipalType . ROLE ) ; cPrivilege = catalog_ . addRolePrivilege ( ownerString , filter ) ; < |startfocus| > } if ( ! existingUser . getRef ( ) ) { < |endfocus| > synchronized ( owner ) { owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; } } response . result . addToUpdated_catalog_objects ( cPrivilege . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } catch ( CatalogException e ) { LOG . error ( "Error adding privilege : " , e ) ; } } /* * * Create a new HMS Partition . */ private static Partition createHmsPartition ( List < TPartitionKeyValue > partitionSpec , org . apache . hadoop . hive . metastore . api . Table msTbl , TableName tableName , String location ) {
} /* * * Grants or revokes one or more privileges to / from a Sentry role on behalf of the * requestingUser . */ private void grantRevokeRolePrivilege ( User requestingUser , TGrantRevokePrivParams grantRevokePrivParams , TDdlExecResponse resp ) throws ImpalaException { Preconditions . checkNotNull ( requestingUser ) ; verifySentryServiceEnabled ( ) ; String roleName = grantRevokePrivParams . getRole_name ( ) ; List < TPrivilege > privileges = grantRevokePrivParams . getPrivileges ( ) ; List < PrincipalPrivilege > addedRolePrivileges = null ; < |startfocus| > List < PrincipalPrivilege > removedGrantOptPrivileges = new ArrayList < > ( ) ; < |endfocus| > if ( grantRevokePrivParams . isIs_grant ( ) ) { addedRolePrivileges = catalog_ . getSentryProxy ( ) . grantRolePrivileges ( requestingUser , roleName , privileges ) ; addSummary ( resp , "Privilege ( s ) have been granted . " ) ; } else { // If this is a revoke of a privilege that contains the grant option , the privileges // with the grant option will be revoked and new privileges without the grant option // will be added . The privilege in the catalog cannot simply be updated since the
// list of the revoked privileges that contain the grant option . The // addedRolePrivileges parameter will contain a list of new privileges without the // grant option that are granted . If this is simply a revoke of a privilege without // grant options , the api will still return revoked privileges , but the // addedRolePrivileges will be empty since there will be no newly granted // privileges . < |startfocus| > addedRolePrivileges = new ArrayList < > ( ) ; < |endfocus| > removedGrantOptPrivileges = catalog_ . getSentryProxy ( ) . revokeRolePrivileges ( requestingUser , roleName , privileges , grantRevokePrivParams . isHas_grant_opt ( ) , addedRolePrivileges ) ; addSummary ( resp , "Privilege ( s ) have been revoked . " ) ; } Preconditions . checkNotNull ( addedRolePrivileges ) ; List < TCatalogObject > updatedPrivs = Lists . newArrayList ( ) ; for ( PrincipalPrivilege rolePriv : addedRolePrivileges ) { updatedPrivs . add ( rolePriv . toTCatalogObject ( ) ) ; } List < TCatalogObject > removedPrivs = Lists . newArrayList ( ) ; for ( PrincipalPrivilege rolePriv : removedGrantOptPrivileges ) { removedPrivs . add ( rolePriv . toTCatalogObject ( ) ) ; }
// grant options , the api will still return revoked privileges , but the // addedRolePrivileges will be empty since there will be no newly granted // privileges . addedRolePrivileges = Lists . newArrayList ( ) ; removedGrantOptPrivileges = catalog_ . getSentryProxy ( ) . revokeRolePrivileges ( requestingUser , roleName , privileges , grantRevokePrivParams . isHas_grant_opt ( ) , addedRolePrivileges ) ; addSummary ( resp , "Privilege ( s ) have been revoked . " ) ; } Preconditions . checkNotNull ( addedRolePrivileges ) ; < |startfocus| > List < TCatalogObject > updatedPrivs = new ArrayList < > ( addedRolePrivileges . size ( ) ) ; < |endfocus| > for ( PrincipalPrivilege rolePriv : addedRolePrivileges ) { updatedPrivs . add ( rolePriv . toTCatalogObject ( ) ) ; } List < TCatalogObject > removedPrivs = Lists . newArrayList ( ) ; for ( PrincipalPrivilege rolePriv : removedGrantOptPrivileges ) { removedPrivs . add ( rolePriv . toTCatalogObject ( ) ) ; } if ( ! updatedPrivs . isEmpty ( ) || ! removedPrivs . isEmpty ( ) ) { // If this is a REVOKE statement with hasGrantOpt , only the GRANT OPTION is removed // from the privileges . Otherwise the privileges are removed from the catalog .
// privileges . addedRolePrivileges = Lists . newArrayList ( ) ; removedGrantOptPrivileges = catalog_ . getSentryProxy ( ) . revokeRolePrivileges ( requestingUser , roleName , privileges , grantRevokePrivParams . isHas_grant_opt ( ) , addedRolePrivileges ) ; addSummary ( resp , "Privilege ( s ) have been revoked . " ) ; } Preconditions . checkNotNull ( addedRolePrivileges ) ; List < TCatalogObject > updatedPrivs = Lists . newArrayList ( ) ; for ( PrincipalPrivilege rolePriv : addedRolePrivileges ) { updatedPrivs . add ( rolePriv . toTCatalogObject ( ) ) ; } < |startfocus| > List < TCatalogObject > removedPrivs = Lists . newArrayList ( ) ; < |endfocus| > for ( PrincipalPrivilege rolePriv : removedGrantOptPrivileges ) { removedPrivs . add ( rolePriv . toTCatalogObject ( ) ) ; } if ( ! updatedPrivs . isEmpty ( ) || ! removedPrivs . isEmpty ( ) ) { // If this is a REVOKE statement with hasGrantOpt , only the GRANT OPTION is removed // from the privileges . Otherwise the privileges are removed from the catalog . if ( grantRevokePrivParams . isIs_grant ( ) ) { resp . result . setUpdated_catalog_objects ( updatedPrivs ) ; resp . result . setVersion ( catalog_ . getCatalogVersion ( ) ) ; } else { resp . result . setRemoved_catalog_objects ( removedPrivs ) ; resp . result . setUpdated_catalog_objects ( updatedPrivs ) ; resp . result . setVersion ( catalog_ . getCatalogVersion ( ) ) ; } } } }
} if ( ! updatedPrivs . isEmpty ( ) || ! removedPrivs . isEmpty ( ) ) { // If this is a REVOKE statement with hasGrantOpt , only the GRANT OPTION is removed // from the privileges . Otherwise the privileges are removed from the catalog . if ( grantRevokePrivParams . isIs_grant ( ) ) { resp . result . setUpdated_catalog_objects ( updatedPrivs ) ; resp . result . setVersion ( updatedPrivs . get ( updatedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; < |startfocus| > } else if ( privileges . get ( 0 ) . isHas_grant_opt ( ) ) { < |endfocus| > resp . result . setUpdated_catalog_objects ( updatedPrivs ) ; resp . result . setRemoved_catalog_objects ( removedPrivs ) ; resp . result . setVersion ( getLastItemVersion ( updatedPrivs ) > getLastItemVersion ( removedPrivs ) ? getLastItemVersion ( updatedPrivs ) : getLastItemVersion ( removedPrivs ) ) ; } else { resp . result . setRemoved_catalog_objects ( removedPrivs ) ; resp . result . setVersion ( removedPrivs . get ( removedPrivs . size ( ) - 1 ) . getCatalog_version ( ) ) ; } } } /* * * Returns the version from the last item in the list . This assumes that the items in the list are sorted by version . * * @param items * @return */ private long getLastItemVersion ( List < ? extends CatalogObject > items ) { if ( items . isEmpty ( ) ) { return Catalog . INITIAL_CATALOG_VERSION ; } return items . get ( items . size ( ) - 1 ) . getCatalog_version ( ) ; } }
} /* * * Throws a CatalogException if the Sentry Service is not enabled . */ private void verifySentryServiceEnabled ( ) throws CatalogException { if ( catalog_ . getSentryProxy ( ) == null ) { throw new CatalogException ( "Sentry Service is not enabled on the " + "CatalogServer . " ) ; } } /* * * Checks if with grant is enabled for object ownership in Sentry . */ private boolean isObjectOwnershipGrantEnabled ( ) { < |startfocus| > return catalog_ . getSentryProxy ( ) != null ? catalog_ . getSentryProxy ( ) . isObjectOwnershipGrantEnabled ( ) : false ; < |endfocus| > } /* * * Alters partitions in batches of size 'MAX_PARTITION_UPDATES_PER_RPC' . This * reduces the time spent in a single update and helps avoid metastore client * timeouts . */ private void bulkAlterPartitions ( String dbName , String tableName , List < HdfsPartition > modifiedParts ) throws ImpalaException { List < org . apache . hadoop . hive . metastore . api . Partition > hmsPartitions = Lists . newArrayList ( ) ; for ( HdfsPartition p : modifiedParts ) {
*/ private void verifySentryServiceEnabled ( ) throws CatalogException { if ( catalog_ . getSentryProxy ( ) == null ) { throw new CatalogException ( "Sentry Service is not enabled on the " + "CatalogServer . " ) ; } } /* * * Checks if with grant is enabled for object ownership in Sentry . */ private boolean isObjectOwnershipGrantEnabled ( ) { < |startfocus| > if ( catalog_ . getSentryProxy ( ) == null ) return false ; return catalog_ . getSentryProxy ( ) . isObjectOwnershipGrantEnabled ( ) ; < |endfocus| > } /* * * Alters partitions in batches of size 'MAX_PARTITION_UPDATES_PER_RPC' . This * reduces the time spent in a single update and helps avoid metastore client * timeouts . */ private void bulkAlterPartitions ( String dbName , String tableName , List < HdfsPartition > modifiedParts ) throws ImpalaException { List < org . apache . hadoop . hive . metastore . api . Partition > hmsPartitions = Lists . newArrayList ( ) ; for ( HdfsPartition p : modifiedParts ) { org . apache . hadoop . hive . metastore . api . Partition msPart = p . toHmsPartition ( ) ; < |startfocus| > if ( catalog_ . getSentryProxy ( ) != null ) { msPart . setParameters ( p . getParameters ( ) ) ; } < |endfocus| > hmsPartitions . add ( msPart ) ; }
originalOwnerName = msDb . getOwnerName ( ) ; originalOwnerType = msDb . getOwnerType ( ) ; msDb . setOwnerName ( params . owner_name ) ; msDb . setOwnerType ( PrincipalType . valueOf ( params . owner_type . name ( ) ) ) ; try { applyAlterDatabase ( db ) ; } catch ( ImpalaRuntimeException e ) { msDb . setOwnerName ( originalOwnerName ) ; msDb . setOwnerType ( originalOwnerType ) ; throw e ; } } addDbToCatalogUpdate ( db , response . result ) ; < |startfocus| > updateOwnerPrivileges ( db . getName ( ) , /* tableName */ null , params . server_name , originalOwnerName , originalOwnerType , db . getMetaStoreDb ( ) . getOwnerName ( ) , db . getMetaStoreDb ( ) . getOwnerType ( ) , response ) ; < |endfocus| > addSummary ( response , "Updated database . " ) ; } private void addDbToCatalogUpdate ( Db db , TCatalogUpdateResult result ) { Preconditions . checkNotNull ( db ) ; // Updating the new catalog version and setting it to the DB catalog version while // holding the catalog version lock for an atomic operation . Most DB operations are // short - lived . It is unnecessary to have a fine - grained DB lock . }
} throw new InternalException ( String . format ( "Error making ' % s' RPC to " + "Sentry Service : " , type == TPrincipalType . ROLE ? "listAllRolesPrivileges" : "listAllUsersPrivileges" ) , e ) ; } finally { client . close ( ) ; } } /* * * Returns the configuration value for the specified key . Will return an empty string * if no value is set . */ public String getConfigValue ( String key ) throws ImpalaException { < |startfocus| > try ( SentryServiceClient client = new SentryServiceClient ( ) ) { < |endfocus| > return client . get ( ) . getConfigValue ( key , "" ) ; } catch ( SentryUserException e ) { throw new InternalException ( "Error making 'getConfigValue' RPC to Sentry Service : " , e ) ; } } /* * * Utility function that converts a TSentryPrivilege to an Impala TPrivilege object . */ public static TPrivilege sentryPrivilegeToTPrivilege ( TSentryPrivilege sentryPriv , Principal principal ) { TPrivilege privilege = new TPrivilege ( ) ; privilege . setServer_name ( sentryPriv . getServerName ( ) ) ;
public SentryProxy ( SentryConfig sentryConfig , CatalogServiceCatalog catalog , String kerberosPrincipal ) throws ImpalaException { Preconditions . checkNotNull ( catalog ) ; Preconditions . checkNotNull ( sentryConfig ) ; catalog_ = catalog ; if ( Strings . isNullOrEmpty ( kerberosPrincipal ) ) { processUser_ = new User ( System . getProperty ( "user . name" ) ) ; } else { processUser_ = new User ( kerberosPrincipal ) ; } sentryPolicyService_ = new SentryPolicyService ( sentryConfig ) ; // For some tests , we create a config but may not have a config file . < |startfocus| > if ( sentryConfig . getConfigFile ( ) != null && sentryConfig . getConfigFile ( ) . length ( ) > 0 ) { < |endfocus| > objectOwnershipConfigValue_ = sentryPolicyService_ . getConfigValue ( ServiceConstants . ServerConfig . SENTRY_DB_POLICY_STORE_OWNER_AS_PRIVILEGE ) ; } else { objectOwnershipConfigValue_ = SentryOwnerPrivilegeType . NONE . toString ( ) ; } policyReader_ . scheduleAtFixedRate ( new PolicyReader ( false ) , 0 , BackendConfig . INSTANCE . getSentryCatalogPollingFrequency ( ) , TimeUnit . SECONDS ) ; } /* * * Refreshes the authorization policy metadata by querying the Sentry Policy Service . * * @param isInitialLoad - true if this is the initial load of the policy metadata . */ private void refreshAuthorizationPolicy ( boolean isInitialLoad ) { try { LOG . info ( "Refreshing authorization policy metadata . " ) ; // Get the latest policy metadata from the Sentry Policy Service .
Preconditions . checkNotNull ( catalog ) ; Preconditions . checkNotNull ( sentryConfig ) ; catalog_ = catalog ; if ( Strings . isNullOrEmpty ( kerberosPrincipal ) ) { processUser_ = new User ( System . getProperty ( "user . name" ) ) ; } else { processUser_ = new User ( kerberosPrincipal ) ; } sentryPolicyService_ = new SentryPolicyService ( sentryConfig ) ; // For some tests , we create a config but may not have a config file . < |startfocus| > if ( sentryConfig . getConfigFile ( ) != null && ! sentryConfig . getConfigFile ( ) . isEmpty ( ) ) { < |endfocus| > objectOwnershipConfigValue_ = sentryPolicyService_ . getConfigValue ( ServiceConstants . ServerConfig . SENTRY_DB_POLICY_STORE_OWNER_AS_PRIVILEGE ) ; } else { objectOwnershipConfigValue_ = SentryOwnerPrivilegeType . NONE . toString ( ) ; } policyReader_ . scheduleAtFixedRate ( new PolicyReader ( false ) , 0 , BackendConfig . INSTANCE . getSentryCatalogPollingFrequency ( ) , TimeUnit . SECONDS ) ; } /* * * Refreshes the authorization policy metadata by querying the Sentry Policy Service . * There is currently no way to get a snapshot of the policy from the Sentry Service ,
// software distributed under the License is distributed on an // "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND , either express or implied . See the License for the // specific language governing permissions and limitations // under the License . package org . apache . kudu . util ; import javax . annotation . concurrent . NotThreadSafe ; import java . nio . charset . StandardCharsets ; import com . sangupta . murmur . Murmur2 ; import org . apache . yetus . audience . InterfaceAudience ; import org . apache . yetus . audience . InterfaceStability ; @InterfaceAudience . Public @InterfaceStability . Unstable @NotThreadSafe public class BloomFilter { < |startfocus| > private int nBits ; private byte [ ] bitmap ; private int nHashes ; private byte [ ] byteBuffer ; private HashFunction hashFunction ; < |endfocus| > private BloomFilter ( int nBits , byte [ ] bitmap , int nHashes , HashFunction hashFunction ) { this . nBits = nBits ; this . bitmap = bitmap ; this . nHashes = nHashes ; this . hashFunction = hashFunction ; byteBuffer = new byte [ 8 ] ; } public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate ) { return BySizeAndFPRate ( nBytes , fpRate , HashFunctions . MURMUR2 ) ; }
// "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND , either express or implied . See the License for the // specific language governing permissions and limitations // under the License . package org . apache . kudu . util ; import javax . annotation . concurrent . NotThreadSafe ; import java . nio . charset . StandardCharsets ; import com . sangupta . murmur . Murmur2 ; import org . apache . yetus . audience . InterfaceAudience ; import org . apache . yetus . audience . InterfaceStability ; @InterfaceAudience . Public @InterfaceStability . Unstable @NotThreadSafe public class BloomFilter { < |startfocus| > private int nBits ; private byte [ ] bitmap ; private int nHashes ; private byte [ ] byteBuffer ; private HashFunction hashFunction ; < |endfocus| > private BloomFilter ( int nBits , byte [ ] bitmap , int nHashes , HashFunction hashFunction ) { this . nBits = nBits ; this . bitmap = bitmap ; this . nHashes = nHashes ; this . hashFunction = hashFunction ; byteBuffer = new byte [ 8 ] ; } public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate ) { return BySizeAndFPRate ( nBytes , fpRate , HashFunctions . MURMUR2 ) ; } public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate , HashFunction hashFunction ) { int nBits = ( int ) Math . ceil ( nBytes * 8 . 0 / - Math . log ( fpRate ) ) ; int nHashes = ( int ) Math . ceil ( Math . log ( 2 . 0 ) * nBits / nBytes ) ; return new BloomFilter ( nBits , new byte [ nBytes ] , nHashes , hashFunction ) ; } public static BloomFilter BySizeAndNumHashes ( int nBytes , int nHashes ) { return BySizeAndNumHashes ( nBytes , nHashes , HashFunctions . MURMUR2 ) ; } public static BloomFilter BySizeAndNumHashes ( int nBytes , int nHashes , HashFunction hashFunction ) { int nBits = nBytes * 8 ; return new BloomFilter ( nBits , new byte [ nBytes ] , nHashes , hashFunction ) ; } public static BloomFilter BySizeAndNumEntries ( int nBytes , int nEntries ) { return BySizeAndNumEntries ( nBytes , nEntries , HashFunctions . MURMUR2 ) ; } public static BloomFilter BySizeAndNumEntries ( int nBytes , int nEntries , HashFunction hashFunction ) { int nBits = ( int ) Math . ceil ( nEntries * Math . log ( 2 . 0 ) * nBytes / nEntries ) ; int nHashes = ( int ) Math . ceil ( Math . log ( 2 . 0 ) * nBits / nEntries ) ; return new BloomFilter ( nBits , new byte [ nBytes ] , nHashes , hashFunction ) ; } public void add ( byte [ ] key ) { int hash1 = hashFunction . hash ( key , 0 , key . length , 0 ) ; int hash2 = hashFunction . hash ( key , 0 , key . length , hash1 ) ; for ( int i = 0 ; i < nHashes ; i ++ ) { int combinedHash = hash1 + ( i * hash2 ) ; if ( combinedHash < 0 ) { combinedHash = ~combinedHash ; } int pos = combinedHash % nBits ; int bytePos = pos / 8 ; int bitPos = pos % 8 ; bitmap [ bytePos ] | = 1 < < bitPos ; } } public boolean mightContain ( byte [ ] key ) { int hash1 = hashFunction . hash ( key , 0 , key . length , 0 ) ; int hash2 = hashFunction . hash ( key , 0 , key . length , hash1 ) ; for ( int i = 0 ; i < nHashes ; i ++ ) { int combinedHash = hash1 + ( i * hash2 ) ; if ( combinedHash < 0 ) { combinedHash = ~combinedHash ; } int pos = combinedHash % nBits ; int bytePos = pos / 8 ; int bitPos = pos % 8 ; if ( ( bitmap [ bytePos ] & ( 1 < < bitPos ) ) == 0 ) { return false ; } } return true ; } public int getNumBits ( ) { return nBits ; } public int getNumHashes ( ) { return nHashes ; } public byte [ ] getBitmap ( ) { return bitmap ; } public HashFunction getHashFunction ( ) { return hashFunction ; } public interface HashFunction { int hash ( byte [ ] data , int offset , int length , int seed ) ; } public static class Murmur2 implements HashFunction { private static final Murmur2 INSTANCE = new Murmur2 ( ) ; private Murmur2 ( ) { } public static Murmur2 getInstance ( ) { return INSTANCE ; } @Override public int hash ( byte [ ] data , int offset , int length , int seed ) { return Murmur2 . hash32 ( data , offset , length , seed ) ; } } }
public static BloomFilter ByCountAndFPRate ( int expectedCount , double fpRate , HashFunction hashFunction ) { int nBytes = optimalNumOfBytes ( expectedCount , fpRate ) ; int nBits = nBytes * 8 ; < |startfocus| > byte [ ] bitmap = new byte [ nBytes ] ; int nHashes = computeOptimalHashCount ( nBits , optimalExpectedCount ( nBytes , fpRate ) ) ; return new BloomFilter ( nBits , bitmap , nHashes , hashFunction ) ; < |endfocus| >
public void put ( boolean data ) { < |startfocus| > byteBuffer [ 0 ] = data ? 1 : 0 ; updateBitmap ( byteBuffer , 1 ) ; < |endfocus| >
< |startfocus| > private void updateBitmap ( byte [ ] byteBuffer , int length ) { < |endfocus| > long h = Murmur2 . hash64 ( byteBuffer , length , 0 ) ; long h1 = ( 0xFFFFFFFFL & h ) ; long h2 = ( h > > > 32 ) ; long tmp = h1 ; for ( int i = 0 ; i < nHashes ; i ++ ) { long bitPos = pickBit ( tmp , nBits ) ; bitmapSet ( bitmap , bitPos ) ; tmp = tmp + h2 ; }
private void updateBitmap ( byte [ ] byteBuffer , int length ) { long h = Murmur2 . hash64 ( byteBuffer , length , 0 ) ; long h1 = ( 0xFFFFFFFFL & h ) ; long h2 = ( h > > > 32 ) ; long tmp = h1 ; for ( int i = 0 ; i < nHashes ; i ++ ) { < |startfocus| > long bitPos = pickBit ( tmp , nBits ) ; bitmapSet ( bitmap , bitPos ) ; tmp += h2 ; < |endfocus| > }
} } } private void updateBitmap ( byte [ ] byteBuffer , int length ) { long h = Murmur2 . hash64 ( byteBuffer , length , 0 ) ; long h1 = ( 0xFFFFFFFFL & h ) ; long h2 = ( h > > > 32 ) ; long tmp = h1 ; for ( int i = 0 ; i < nHashes ; i ++ ) { long bitPos = pickBit ( tmp , nBits ) ; bitmapSet ( bitmap , bitPos ) ; tmp = tmp + h2 ; } } < |startfocus| > @InterfaceAudience . LimitedPrivate ( "Test" ) < |endfocus| > public boolean mayContain ( byte [ ] data ) { return checkIfContains ( data ) ; } @InterfaceAudience . LimitedPrivate ( "Test" ) public boolean mayContain ( boolean data ) { byte [ ] byteBuffer = new byte [ 1 ] ; if ( data ) { byteBuffer [ 0 ] = 1 ; } else { byteBuffer [ 0 ] = 0 ; } return checkIfContains ( byteBuffer ) ; } @InterfaceAudience . LimitedPrivate ( "Test" ) public boolean mayContain ( byte data ) { byte [ ] byteBuffer = new byte [ 1 ] ; byteBuffer [ 0 ] = data ; return checkIfContains ( byteBuffer ) ;
private boolean checkIfContains ( byte [ ] bytes ) { long h = Murmur2 . hash64 ( bytes , bytes . length , 0 ) ; long h1 = ( 0xFFFFFFFFL & h ) ; long h2 = ( h > > > 32 ) ; long tmp = h1 ; int remHashes = nHashes ; while ( remHashes != 0 ) { < |startfocus| > long bitPos = pickBit ( tmp , nBits ) ; if ( ! bitmapTest ( bitmap , bitPos ) ) { < |endfocus| > return false ; } tmp = tmp + h2 ; remHashes -- ; } return true ;
private boolean checkIfContains ( byte [ ] bytes ) { long h = Murmur2 . hash64 ( bytes , bytes . length , 0 ) ; long h1 = ( 0xFFFFFFFFL & h ) ; long h2 = ( h > > > 32 ) ; long tmp = h1 ; int remHashes = nHashes ; while ( remHashes != 0 ) { long bitpos = pickBit ( tmp , nBits ) ; if ( ! bitmapTest ( bitmap , bitpos ) ) { return false ; } < |startfocus| > tmp += h2 ; < |endfocus| > remHashes -- ; } return true ;
long h = Murmur2 . hash64 ( bytes , bytes . length , 0 ) ; long h1 = ( 0xFFFFFFFFL & h ) ; long h2 = ( h > > > 32 ) ; long tmp = h1 ; int remHashes = nHashes ; while ( remHashes != 0 ) { long bitpos = pickBit ( tmp , nBits ) ; if ( ! bitmapTest ( bitmap , bitpos ) ) { return false ; } tmp = tmp + h2 ; remHashes -- ; } return true ; } < |startfocus| > private static double kNaturalLog2 = 0 . 69314 ; < |endfocus| > private static int optimalNumOfBytes ( int expectedCount , double fpRate ) { if ( fpRate == 0 ) { fpRate = Double . MIN_VALUE ; } return ( int ) ( - expectedCount * Math . log ( fpRate ) / ( Math . log ( 2 ) * Math . log ( 2 ) * 8 ) ) ; } private static int optimalExpectedCount ( int nBytes , double fpRate ) { int nBits = nBytes * 8 ; return ( int ) ( Math . ceil ( nBits * kNaturalLog2 * kNaturalLog2 / Math . log ( fpRate ) ) ) ; }
< |startfocus| > private static int computeOptimalHashCount ( int nBits , int elems ) { int nHashes = ( int ) ( nBits * kNaturalLog2 / elems ) ; < |endfocus| > if ( nHashes < 1 ) nHashes = 1 ; return nHashes ;
// software distributed under the License is distributed on an // "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND , either express or implied . See the License for the // specific language governing permissions and limitations // under the License . package org . apache . kudu . client ; import static org . junit . Assert . assertTrue ; import java . util . Random ; import org . apache . kudu . util . BloomFilter ; import org . junit . Test ; public class TestBloomFilter { private int nBytes = 32 * 1024 ; < |startfocus| > private int kRandomSeed = 0xdeadbeef ; < |endfocus| > private int nKeys = 2000 ; private double fpRate = 0 . 01 ; @Test public void testIntGenBFBySizeAndFPRate ( ) { final BloomFilter bf = BloomFilter . BySizeAndFPRate ( nBytes , fpRate ) ; // Put integers into bloomfilter by random Random rand = new Random ( kRandomSeed ) ; for ( int i = 0 ; i < nKeys ; i ++ ) { bf . put ( rand . nextInt ( ) ) ; } // Reset the rand and check existence of the keys . rand = new Random ( kRandomSeed ) ;
< |startfocus| > public void testFloat ( ) { < |endfocus| > final BloomFilter bf = BloomFilter . BySizeAndFPRate ( nBytes , fpRate ) ; // Put floats into bloomfilter by random Random rand = new Random ( kRandomSeed ) ; for ( int i = 0 ; i < nKeys ; i ++ ) { bf . put ( rand . nextFloat ( ) ) ; } // Reset the rand and check existence of the keys . rand = new Random ( kRandomSeed ) ; for ( int i = 0 ; i < nKeys ; i ++ ) { assertTrue ( bf . mayContain ( rand . nextFloat ( ) ) ) ; }
import java . util . List ; import org . apache . impala . authorization . PrivilegeRequestBuilder ; import org . apache . impala . common . AnalysisException ; import org . apache . impala . common . InternalException ; import org . apache . impala . common . Pair ; import org . apache . impala . thrift . TAdminRequest ; import org . apache . impala . thrift . TAdminRequestType ; import org . apache . impala . thrift . TNetworkAddress ; import org . apache . impala . thrift . TShutdownParams ; import com . google . common . base . Joiner ; import com . google . common . base . Preconditions ; import com . google . common . collect . Lists ; /* * < |startfocus| > * Represents an administrative function call , e . g . " : shutdown ( ) " . < |endfocus| > * * This "admin statement" framework provides a way to expand the set of supported admin * statements without modifying the SQL grammar . For now , the only supported function is * shutdown ( ) , so the logic in here is not generic . */ public class AdminFnStmt extends StatementBase { // Name of the function . Validated during analysis . private final String fnName_ ; // Arguments to the function . Always non - null . private final List < Expr > params_ ; // Parameters for the shutdown ( ) command . private final TShutdownParams shutdownParams_ ;
* not used since it accesses multiple catalog entities in order to compute a snapshot * of catalog metadata . * * Operations that CREATE / DROP catalog objects such as tables and databases employ the * following locking protocol : * 1 . Acquire the metastoreDdlLock_ * 2 . Update the Hive Metastore * 3 . Increment and get a new catalog version * 4 . Update the catalog * 5 . Make Sentry cache changes if ownership is enabled . < |startfocus| > * 5 . Release the metastoreDdlLock_ < |endfocus| > * * It is imperative that other operations that need to hold both the catalog lock and * table locks at the same time follow the same locking protocol and acquire these * locks in that particular order . Also , operations that modify table metadata * ( e . g . alter table statements ) should not acquire the metastoreDdlLock_ . * * TODO : Refactor the CatalogOpExecutor and CatalogServiceCatalog classes and consolidate * the locking protocol into a single class . * * TODO : Improve catalog's consistency guarantees by using a hierarchical locking scheme . * * TODO : Improve catalog's consistency guarantees by using a hierarchical locking scheme .
filter . setPrincipal_type ( TPrincipalType . USER ) ; cPrivilege = catalog_ . addUserPrivilege ( ownerString , filter ) ; if ( existingUser . getRef ( ) ) { owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; } } else if ( ownerType == PrincipalType . ROLE ) { owner = catalog_ . getAuthPolicy ( ) . getRole ( ownerString ) ; filter . setPrincipal_id ( owner . getId ( ) ) ; filter . setPrincipal_type ( TPrincipalType . ROLE ) ; cPrivilege = catalog_ . addRolePrivilege ( ownerString , filter ) ; < |startfocus| > owner . setCatalogVersion ( catalog_ . incrementAndGetCatalogVersion ( ) ) ; < |endfocus| > } else { throw new CatalogException ( "Unexpected PrincipalType : " + ownerType . name ( ) ) ; } response . result . addToUpdated_catalog_objects ( cPrivilege . toTCatalogObject ( ) ) ; response . result . addToUpdated_catalog_objects ( owner . toTCatalogObject ( ) ) ; } catch ( CatalogException e ) { LOG . error ( "Error adding privilege : " , e ) ; } } /* * * Create a new HMS Partition . */ private static Partition createHmsPartition ( List < TPartitionKeyValue > partitionSpec , org . apache . hadoop . hive . metastore . api . Table msTbl , TableName tableName , String location ) { < |startfocus| >
// "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND , either express or implied . See the License for the // specific language governing permissions and limitations // under the License . package org . apache . kudu . util ; import javax . annotation . concurrent . NotThreadSafe ; import java . nio . charset . StandardCharsets ; import java . util . BitSet ; import com . sangupta . murmur . Murmur2 ; import org . apache . yetus . audience . InterfaceAudience ; import org . apache . yetus . audience . InterfaceStability ; /* * < |startfocus| > * A space - efficient filter which offers an approximate containment check . < |endfocus| > * * < p > It can be used to filter all the records which are wanted , but doesn't guarantee to filter out * all the records which are < i > not </ i > wanted . * * < p > Please check this < a * href = "https :/ / en . wikipedia . org / wiki / Bloom_filter" > wiki </ a > for more details . * * < p > The { @code BloomFilter } here is a scanning filter and used to shrink the amount of records
* < p > The { @code BloomFilter } here is a scanning filter and used to shrink the amount of records * returned from TServer . It provides different types of { @code put } methods . When you { @code put } a * record into { @code BloomFilter } , it means you are expecting TServer to return records have * the same value in a scan . * * < p > Here is an example for use : * < pre > * { @code * BloomFilter bf = BloomFilter . BySizeAndFPRate ( nBytes , fpRate ) ; * bf . put ( 1 ) ; * bf . put ( 3 ) ; * bf . put ( 4 ) ; * bf . put ( 5 ) ; * bf . put ( 6 ) ; * bf . put ( 7 ) ; * bf . put ( 8 ) ; * bf . put ( 9 ) ; * bf . put ( 10 ) ; * bf . put ( 11 ) ; * bf . put ( 12 ) ; * bf . put ( 13 ) ; * bf . put ( 14 ) ; * bf . put ( 15 ) ; * bf . put ( 16 ) ; * bf . put ( 17 ) ; * bf . put ( 18 ) ; * bf . put ( 19 ) ; * bf . put ( 20 ) ; * bf . put ( 21 ) ; * bf . put ( 22 ) ; * bf . put ( 23 ) ; * bf . put ( 24 ) ; * bf . put ( 25 ) ; * bf . put ( 26 ) ; * bf . put ( 27 ) ; * bf . put ( 28 ) ; * bf . put ( 29 ) ; * bf . put ( 30 ) ; * bf . put ( 31 ) ; * bf . put ( 32 ) ; * bf . put ( 33 ) ; * bf . put ( 34 ) ; * bf . put ( 35 ) ; * bf . put ( 36 ) ; * bf . put ( 37 ) ; * bf . put ( 38 ) ; * bf . put ( 39 ) ; * bf . put ( 40 ) ; * bf . put ( 41 ) ; * bf . put ( 42 ) ; * bf . put ( 43 ) ; * bf . put ( 44 ) ; * bf . put ( 45 ) ; * bf . put ( 46 ) ; * bf . put ( 47 ) ; * bf . put ( 48 ) ; * bf . put ( 49 ) ; * bf . put ( 50 ) ; * bf . put ( 51 ) ; * bf . put ( 52 ) ; * bf . put ( 53 ) ; * bf . put ( 54 ) ; * bf . put ( 55 ) ; * bf . put ( 56 ) ; * bf . put ( 57 ) ; * bf . put ( 58 ) ; * bf . put ( 59 ) ; * bf . put ( 60 ) ; * bf . put ( 61 ) ; * bf . put ( 62 ) ; * bf . put ( 63 ) ; * bf . put ( 64 ) ; * bf . put ( 65 ) ; * bf . put ( 66 ) ; * bf . put ( 67 ) ; * bf . put ( 68 ) ; * bf . put ( 69 ) ; * bf . put ( 70 ) ; * bf . put ( 71 ) ; * bf . put ( 72 ) ; * bf . put ( 73 ) ; * bf . put ( 74 ) ; * bf . put ( 75 ) ; * bf . put ( 76 ) ; * bf . put ( 77 ) ; * bf . put ( 78 ) ; * bf . put ( 79 ) ; * bf . put ( 80 ) ; * bf . put ( 81 ) ; * bf . put ( 82 ) ; * bf . put ( 83 ) ; * bf . put ( 84 ) ; * bf . put ( 85 ) ; * bf . put ( 86 ) ; * bf . put ( 87 ) ; * bf . put ( 88 ) ; * bf . put ( 89 ) ; * bf . put ( 90 ) ; * bf . put ( 91 ) ; * bf . put ( 92 ) ; * bf . put ( 93 ) ; * bf . put ( 94 ) ; * bf . put ( 95 ) ; * bf . put ( 96 ) ; * bf . put ( 97 ) ; * bf . put ( 98 ) ; * bf . put ( 99 ) ; * bf . put ( 100 ) ; * bf . put ( 101 ) ; * bf . put ( 102 ) ; * bf . put ( 103 ) ; * bf . put ( 104 ) ; * bf . put ( 105 ) ; * bf . put ( 106 ) ; * bf . put ( 107 ) ; * bf . put ( 108 ) ; * bf . put ( 109 ) ; * bf . put ( 110 ) ; * bf . put ( 111 ) ; * bf . put ( 112 ) ; * bf . put ( 113 ) ; * bf . put ( 114 ) ; * bf . put ( 115 ) ; * bf . put ( 116 ) ; * bf . put ( 117 ) ; * bf . put ( 118 ) ; * bf . put ( 119 ) ; * bf . put ( 120 ) ; * bf . put ( 121 ) ; * bf . put ( 122 ) ; * bf . put ( 123 ) ; * bf . put ( 124 ) ; * bf . put ( 125 ) ; * bf . put ( 126 ) ; * bf . put ( 127 ) ; * bf . put ( 128 ) ; * bf . put ( 129 ) ; * bf . put ( 130 ) ; * bf . put ( 131 ) ; * bf . put ( 132 ) ; * bf . put ( 133 ) ; * bf . put ( 134 ) ; * bf . put ( 135 ) ; * bf . put ( 136 ) ; * bf . put ( 137 ) ; * bf . put ( 138 ) ; * bf . put ( 139 ) ; * bf . put ( 140 ) ; * bf . put ( 141 ) ; * bf . put ( 142 ) ; * bf . put ( 143 ) ; * bf . put ( 144 ) ; * bf . put ( 145 ) ; * bf . put ( 146 ) ; * bf . put ( 147 ) ; * bf . put ( 148 ) ; * bf . put ( 149 ) ; * bf . put ( 150 ) ; * bf . put ( 151 ) ; * bf . put ( 152 ) ; * bf . put ( 153 ) ; * bf . put ( 154 ) ; * bf . put ( 155 ) ; * bf . put ( 156 ) ; * bf . put ( 157 ) ; * bf . put ( 158 ) ; * bf . put ( 159 ) ; * bf . put ( 160 ) ; * bf . put ( 161 ) ; * bf . put ( 162 ) ; * bf . put ( 163 ) ; * bf . put ( 164 ) ; * bf . put ( 165 ) ; * bf . put ( 166 ) ; * bf . put ( 167 ) ; * bf . put ( 168 ) ; * bf . put ( 169 ) ; * bf . put ( 170 ) ; * bf . put ( 171 ) ; * bf . put ( 172 ) ; * bf . put ( 173 ) ; * bf . put ( 174 ) ; * bf . put ( 175 ) ; * bf . put ( 176 ) ; * bf . put ( 177 ) ; * bf . put ( 178 ) ; * bf . put ( 179 ) ; * bf . put ( 180 ) ; * bf . put ( 181 ) ; * bf . put ( 182 ) ; * bf . put ( 183 ) ; * bf . put ( 184 ) ; * bf . put ( 185 ) ; * bf . put ( 186 ) ; * bf . put ( 187 ) ; * bf . put ( 188 ) ; * bf . put ( 189 ) ; * bf . put ( 190 ) ; * bf . put ( 191 ) ; * bf . put ( 192 ) ; * bf . put ( 193 ) ; * bf . put ( 194 ) ; * bf . put ( 195 ) ; * bf . put ( 196 ) ; * bf . put ( 197 ) ; * bf . put ( 198 ) ; * bf . put ( 199 ) ; * bf . put ( 200 ) ; * bf . put ( 201 ) ; * bf . put ( 202 ) ; * bf . put ( 203 ) ; * bf . put ( 204 ) ; * bf . put ( 205 ) ; * bf . put ( 206 ) ; * bf . put ( 207 ) ; * bf . put ( 208 ) ; * bf . put ( 209 ) ; * bf . put
* </ pre > */ @InterfaceAudience . Public @InterfaceStability . Unstable @NotThreadSafe public class BloomFilter { private final int nBits ; private final BitSet bitSet ; private final int nHashes ; private final byte [ ] byteBuffer ; private final HashFunction hashFunction ; private BloomFilter ( BitSet bitSet , int nHashes , HashFunction hashFunction ) { < |startfocus| > Preconditions . checkArgument ( bitSet . size ( ) < 8 , "Number of bits in bitset should be at least 8 , but found " + bitSet . length ( ) ) ; < |endfocus| > this . nBits = bitSet . size ( ) ; this . bitSet = bitSet ; this . nHashes = nHashes ; this . hashFunction = hashFunction ; byteBuffer = new byte [ 8 ] ; } /* * * Generate bloom filter , Murmur2 is used for hashing by default . * @param nBytes size of Bloom filter * @param fpRate false positive rate */ public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate ) { return BySizeAndFPRate ( nBytes , fpRate , HashFunctions . MURMUR2 ) ; }
* </ pre > */ @InterfaceAudience . Public @InterfaceStability . Unstable @NotThreadSafe public class BloomFilter { private final BitSet bitSet ; private final int nHashes ; private final byte [ ] byteBuffer ; private final HashFunction hashFunction ; private BloomFilter ( BitSet bitSet , int nHashes , HashFunction hashFunction ) { < |startfocus| > if ( bitSet . size ( ) < 8 ) { throw new IllegalArgumentException ( "Number of bits in bitset should be at least 8 , but found " + bitSet . length ( ) ) ; } < |endfocus| > this . bitSet = bitSet ; this . nHashes = nHashes ; this . hashFunction = hashFunction ; byteBuffer = new byte [ 8 ] ; } /* * * Generate bloom filter , Murmur2 is used for hashing by default . * @param nBytes size of Bloom filter * @param fpRate false positive rate */ public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate ) { return BySizeAndFPRate ( nBytes , fpRate , HashFunctions . MURMUR2 ) ; }
if ( bitSet . size ( ) < 8 ) { throw new IllegalArgumentException ( "Number of bits in bitset should be at least 8 , but found " + bitSet . length ( ) ) ; } this . nBits = bitSet . size ( ) ; this . bitSet = bitSet ; this . nHashes = nHashes ; this . hashFunction = hashFunction ; byteBuffer = new byte [ 8 ] ; } /* * < |startfocus| > * Generate bloom filter , Murmur2 is used for hashing by default . * @param nBytes size of Bloom filter in bytes * @param fpRate false positive rate < |endfocus| > */ public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate ) { return BySizeAndFPRate ( nBytes , fpRate , HashFunctions . MURMUR2 ) ; } public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate , HashFunction hashFunction ) { int nBits = nBytes * 8 ; int nHashes = computeOptimalHashCount ( nBits , optimalExpectedCount ( nBytes , fpRate ) ) ; return new BloomFilter ( new BitSet ( nBits ) , nHashes , hashFunction ) ; } /* *
} public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate , HashFunction hashFunction ) { int nBits = nBytes * 8 ; int nHashes = computeOptimalHashCount ( nBits , optimalExpectedCount ( nBytes , fpRate ) ) ; return new BloomFilter ( new BitSet ( nBits ) , nHashes , hashFunction ) ; } /* * < |startfocus| > * Generate bloom filter , Murmur2 is used for hashing by default . * @param expectedCount The expected number of elements , targeted by this bloom filter . < |endfocus| > * It is used to size the bloom filter . * @param fpRate false positive rate */ public static BloomFilter ByCountAndFPRate ( int expectedCount , double fpRate ) { return ByCountAndFPRate ( expectedCount , fpRate , HashFunctions . MURMUR2 ) ; } public static BloomFilter ByCountAndFPRate ( int expectedCount , double fpRate , HashFunction hashFunction ) { int nBytes = optimalNumOfBytes ( expectedCount , fpRate ) ; int nBits = nBytes * 8 ; int nHashes = computeOptimalHashCount ( nBits , expectedCount ) ; return new BloomFilter ( new BitSet ( nBits ) , nHashes , hashFunction ) ; }
* @param fpRate false positive rate */ public static BloomFilter ByCountAndFPRate ( int expectedCount , double fpRate ) { return ByCountAndFPRate ( expectedCount , fpRate , HashFunctions . MURMUR2 ) ; } public static BloomFilter ByCountAndFPRate ( int expectedCount , double fpRate , HashFunction hashFunction ) { int nBytes = optimalNumOfBytes ( expectedCount , fpRate ) ; int nBits = nBytes * 8 ; int nHashes = computeOptimalHashCount ( nBits , expectedCount ) ; return new BloomFilter ( new BitSet ( nBits ) , nHashes , hashFunction ) ; } < |startfocus| > < |endfocus| > public void put ( byte [ ] data ) { updateBitset ( data , data . length ) ; } public void put ( boolean data ) { byteBuffer [ 0 ] = ( byte ) ( data ? 1 : 0 ) ; updateBitset ( byteBuffer , 1 ) ; } public void put ( byte data ) { byteBuffer [ 0 ] = data ; updateBitset ( byteBuffer , 1 ) ; } public void put ( short data ) { byteBuffer [ 0 ] = ( byte ) ( data > > > 0 ) ; byteBuffer [ 1 ] = ( byte ) ( data > > > 8 ) ; updateBitset ( byteBuffer , 2 ) ; } public void put ( char data ) { byteBuffer [ 0 ] = ( byte ) ( data > > > 0 ) ; byteBuffer [ 1 ] = ( byte ) ( data > > > 8 ) ; updateBitset ( byteBuffer , 2 ) ; }
public void put ( byte data ) { put ( new byte [ ] { data } ) ; } public void put ( short data ) { put ( ByteBuffer . allocate ( 2 ) . putShort ( data ) . array ( ) ) ; } public void put ( int data ) { put ( ByteBuffer . allocate ( 4 ) . putInt ( data ) . array ( ) ) ; } public void put ( long data ) { put ( ByteBuffer . allocate ( 8 ) . putLong ( data ) . array ( ) ) ; } public void put ( float data ) { put ( Float . floatToIntBits ( data ) ) ; } public void put ( double data ) { put ( Double . doubleToLongBits ( data ) ) ; } public void put ( String data ) { put ( data . getBytes ( StandardCharsets . UTF_8 ) ) ; } public byte [ ] getBitSet ( ) { return bitSet . toByteArray ( ) ; } public int getNHashes ( ) { return nHashes ; } < |startfocus| > < |endfocus| > public String getHashFunctionName ( ) { return hashFunction . toString ( ) ; } // Mark it `private` and user can only use the `HashFunction` specified in the // enumeration below . Thus user cannot send TServer a self defined `HashFunction` , // which might not be identified by TServer . private interface HashFunction { long hash ( byte [ ] data , int length , long seed ) ; } public enum HashFunctions implements HashFunction { // Currently only Murmur2 is provided as an option for hashing . // We can consider to provide some other options like Murmur3 , CityHash in the future .
// Currently only Murmur2 is provided as an option for hashing . // We can consider to provide some other options like Murmur3 , CityHash in the future . MURMUR2 ( ) { @Override public long hash ( byte [ ] data , int length , long seed ) { return Murmur2 . hash ( data , length , seed ) ; } @Override public String toString ( ) { return "Murmur2" ; } } } private void updateBitset ( byte [ ] byteBuffer , int length ) { < |startfocus| > Preconditions . checkArgument ( byteBuffer . length >= length ) ; < |endfocus| > long h = Murmur2 . hash64 ( byteBuffer , length , 0 ) ; long h1 = ( 0xFFFFFFFFL & h ) ; long h2 = ( h > > > 32 ) ; long tmp = h1 ; for ( int i = 0 ; i < nHashes ; i ++ ) { long bitPos = tmp % nBits ; bitSet . set ( ( int ) bitPos ) ; tmp += h2 ; } } @InterfaceAudience . LimitedPrivate ( "Test" ) public boolean mayContain ( byte [ ] data ) { return checkIfContains ( data ) ; }
TPrivilegeLevel . values ( ) ) ) . error ( accessError ( true , "functional . alltypes" ) , onDatabase ( "functional" , TPrivilegeLevel . values ( ) ) ) . error ( accessError ( true , "functional . alltypes" ) , onTable ( "functional" , "alltypes" , TPrivilegeLevel . values ( ) ) ) . error ( accessError ( true , "functional . alltypes" ) ) . error ( accessError ( true , "functional . alltypes" ) , onServer ( true , allExcept ( TPrivilegeLevel . ALL , TPrivilegeLevel . OWNER ) ) ) < |startfocus| > . error ( accessError ( true , "functional . alltypes" ) , onDatabase ( true , "functional" , allExcept ( TPrivilegeLevel . ALL , TPrivilegeLevel . OWNER ) ) ) < |endfocus| > . error ( accessError ( true , "functional . alltypes" ) , onTable ( true , "functional" , "alltypes" , allExcept ( TPrivilegeLevel . ALL , TPrivilegeLevel . OWNER ) ) ) ; } } finally { authzCatalog_ . removeRole ( "foo_owner" ) ; } // Alter table rename . authorize ( "alter table functional . alltypes rename to functional_parquet . new_table" ) . ok ( onServer ( TPrivilegeLevel . ALL ) ) . ok ( onServer ( TPrivilegeLevel . OWNER ) ) . ok ( onDatabase ( "functional" , TPrivilegeLevel . ALL ) , onDatabase ( "functional_parquet" , TPrivilegeLevel . CREATE ) ) . ok ( onDatabase ( "functional" , TPrivilegeLevel . OWNER ) , onDatabase ( "functional_parquet" , TPrivilegeLevel . CREATE ) )
< |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |endfocus| > < |startfocus| > < |
// Copyright ( c ) 2012 Cloudera , Inc . All rights reserved . package com . cloudera . impala . service ; import java . util . List ; import org . apache . hadoop . hive . metastore . api . PrincipalType ; import org . apache . hadoop . hive . metastore . api . PrivilegeGrantInfo ; import org . apache . hadoop . hive . metastore . api . Role ; import org . apache . hadoop . hive . metastore . api . RolePrincipalGrant ; import org . apache . hadoop . hive . metastore . api . ThriftHiveMetastore . Iface ; import org . apache . hadoop . hive . metastore . api . ThriftHiveMetastore . Processor . Grant_Role ; import org . apache . hadoop . hive . metastore . api . ThriftHiveMetastore . Processor . Revoke_Role ; import org . apache . thrift . TException ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import com . cloudera . impala . catalog . CatalogException ; import com . cloudera . impala . catalog . CatalogServiceCatalog ; import com . cloudera . impala . catalog . Db ; import com . cloudera . impala . catalog . Principal ; import com . cloudera . impala . catalog . PrincipalPrivilege ; import com . cloudera . impala . catalog . RolePrivilege ; import com . cloudera . impala . thrift . TDdlExecResponse ; import com . cloudera . impala . thrift . TPrivilege ; import com . cloudera . impala . thrift . TPrivilegeLevel ; import com . cloudera . impala . thrift . TPrivilegeScope ; import com . cloudera . impala . thrift . TPrivilegeState ; import com . cloudera . impala . thrift . TPrivilegeType ; import com . cloudera . impala . thrift . TPrincipalType ; import com . cloudera . impala . util . TAccessLevelUtil ; import com . cloudera . impala . util . TResultRowBuilder ; import com . google . common . base . Preconditions ; import com . google . common . collect . Lists ; /* * * Class used to grant / revoke roles to / from users and groups . */ public class RoleDDL { private final static Logger LOG = LoggerFactory . getLogger ( RoleDDL . class ) ; // Hive Metastore Client for interacting with the underlying metastore . private final Iface client_ ; // Catalog service for updating the authorization policy . private final CatalogServiceCatalog catalog_ ; public RoleDDL ( Iface client , CatalogServiceCatalog catalog ) { Preconditions . checkNotNull ( client ) ; Preconditions . checkNotNull ( catalog ) ; client_ = client ; catalog_ = catalog ; } /* * * Grants a role to a group / user . */ public TDdlExecResponse grantRole ( String roleName , String groupName , String grantor , PrincipalType grantorType , boolean grantOption ) throws ImpalaException { TDdlExecResponse response = new TDdlExecResponse ( ) ; try { client_ . grant_role ( new Grant_Role ( roleName , groupName , grantor , PrincipalType . valueOf ( grantorType . name ( ) ) , grantOption ) ) ; } catch ( TException e ) { throw new ImpalaException ( e . getMessage ( ) , e ) ; } return response ; } /* * * Revokes a role from a group / user . */ public TDdlExecResponse revokeRole ( String roleName , String groupName , String grantor , PrincipalType grantorType , boolean grantOption ) throws ImpalaException { TDdlExecResponse response = new TDdlExecResponse ( ) ; try { client_ . revoke_role ( new Revoke_Role ( roleName , groupName , grantor , PrincipalType . valueOf ( grantorType . name ( ) ) , grantOption ) ) ; } catch ( TException e ) { throw new ImpalaException ( e . getMessage ( ) , e ) ; } return response ; } }
* } * </ pre > */ @InterfaceAudience . Public @InterfaceStability . Unstable @NotThreadSafe public class BloomFilter { private final int nBits ; private final BitSet bitSet ; private final int nHashes ; private final byte [ ] byteBuffer ; private final HashFunction hashFunction ; private static final double DEFAULT_FP_RATE = 0 . 01 ; private BloomFilter ( BitSet bitSet , int nHashes , HashFunction hashFunction ) { < |startfocus| > Preconditions . checkArgument ( bitSet . size ( ) >= 8 , "Number of bits in " + < |endfocus| > "bitset should be at least 8 , but found % s . " , bitSet . size ( ) ) ; this . nBits = bitSet . size ( ) ; this . bitSet = bitSet ; this . nHashes = nHashes ; this . hashFunction = hashFunction ; byteBuffer = new byte [ 8 ] ; } /* * * Generate bloom filter , default hashing is { @code Murmur2 } and false positive rate is 0 . 01 . * @param nBytes size of bloom filter in bytes */ public static BloomFilter BySize ( int nBytes ) { return BySizeAndFPRate ( nBytes , DEFAULT_FP_RATE ) ; }
"bitset should be at least 8 , but found % s . " , bitSet . size ( ) ) ; this . nBits = bitSet . size ( ) ; this . bitSet = bitSet ; this . nHashes = nHashes ; this . hashFunction = hashFunction ; byteBuffer = new byte [ 8 ] ; } /* * * Generate bloom filter , default hashing is { @code Murmur2 } and false positive rate is 0 . 01 . * @param nBytes size of bloom filter in bytes */ < |startfocus| > public static BloomFilter bySize ( int nBytes ) { return bySizeAndFPRate ( nBytes , DEFAULT_FP_RATE ) ; < |endfocus| > } /* * * Generate bloom filter , default hashing is { @code Murmur2 } . * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been { @code put } into the { @code BloomFilter } . */ public static BloomFilter bySizeAndFPRate ( int nBytes , double fpRate ) { return bySizeAndFPRate ( nBytes , fpRate , HashFunctions . MURMUR2 ) ; } /* *
* @param nBytes size of bloom filter in bytes */ public static BloomFilter BySize ( int nBytes ) { return BySizeAndFPRate ( nBytes , DEFAULT_FP_RATE ) ; } /* * * Generate bloom filter , default hashing is { @code Murmur2 } . * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been { @code put } into the { @code BloomFilter } . */ public static BloomFilter BySizeAndFPRate ( int nBytes , double fpRate ) { return BySizeAndFPRate ( nBytes , fpRate , HashFunctions . MURMUR2 ) ; } /* * * Generate bloom filter . * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been { @code put } into the { @code BloomFilter } . * @param hashFunction hashing used when updating or checking containment , user should pick * the hashing function from { @code HashFunctions }
TPrivilegeLevel . values ( ) ) ) . error ( accessError ( true , "functional . alltypes" ) , onDatabase ( "functional" , TPrivilegeLevel . values ( ) ) ) . error ( accessError ( true , "functional . alltypes" ) , onTable ( "functional" , "alltypes" , TPrivilegeLevel . values ( ) ) ) . error ( accessError ( true , "functional . alltypes" ) ) . error ( accessError ( true , "functional . alltypes" ) , onServer ( true , allExcept ( TPrivilegeLevel . ALL , TPrivilegeLevel . OWNER ) ) ) < |startfocus| > . error ( accessError ( true , "functional . alltypes" ) , onDatabase ( true , "functional" , allExcept ( TPrivilegeLevel . ALL , TPrivilegeLevel . OWNER ) ) ) < |endfocus| > . error ( accessError ( true , "functional . alltypes" ) , onTable ( true , "functional" , "alltypes" , allExcept ( TPrivilegeLevel . ALL , TPrivilegeLevel . OWNER ) ) ) ; } } finally { authzCatalog_ . removeRole ( "foo_owner" ) ; } boolean exceptionThrown = false ; try { parseAndAnalyze ( "alter table functional . alltypes set owner role foo_owner" , analysisContext_ , frontend_ ) ; } catch ( AnalysisException e ) { exceptionThrown = true ; assertEquals ( "Role 'foo_owner' does not exist . " , e . getLocalizedMessage ( ) ) ; }
private final long MISSING_TBL_LOAD_WAIT_TIMEOUT_MS = 2 * 60 * 1000 ; // Max time to wait for a catalog update notification . private final long MAX_CATALOG_UPDATE_WAIT_TIME_MS = 2 * 1000 ; // TODO : Make the reload interval configurable . private static final int AUTHORIZATION_POLICY_RELOAD_INTERVAL_SECS = 5 * 60 ; private ImpaladCatalog impaladCatalog_ ; private final AuthorizationConfig authzConfig_ ; private final AtomicReference < AuthorizationChecker > authzChecker_ ; private final ScheduledExecutorService policyReader_ = Executors . newScheduledThreadPool ( 1 ) ; < |startfocus| > private final String defaultKuduMasterHosts_ ; < |endfocus| > public Frontend ( AuthorizationConfig authorizationConfig , String defaultKuduMasterHosts ) { this ( authorizationConfig , new ImpaladCatalog ( defaultKuduMasterHosts ) ) ; } /* * * C'tor used by tests to pass in a custom ImpaladCatalog . */ public Frontend ( AuthorizationConfig authorizationConfig , ImpaladCatalog catalog ) { authzConfig_ = authorizationConfig ; impaladCatalog_ = catalog ; defaultKuduMasterHosts_ = catalog . getDefaultKuduMasterHosts ( ) ; authzChecker_ = new AtomicReference < AuthorizationChecker > ( new AuthorizationChecker ( authzConfig_ , impaladCatalog_ . getAuthPolicy ( ) ) ) ; private final long MISSING_TBL_LOAD_WAIT_TIMEOUT_MS = 2 * 60 * 1000 ; // Max time to wait for a catalog update notification . private final long MAX_CATALOG_UPDATE_WAIT_TIME_MS = 2 * 1000 ; // TODO : Make the reload interval configurable . private static final int AUTHORIZATION_POLICY_RELOAD_INTERVAL_SECS = 5 * 60 ; private ImpaladCatalog impaladCatalog_ ; private final AuthorizationConfig authzConfig_ ; private final AtomicReference < AuthorizationChecker > authzChecker_ ; private final ScheduledExecutorService policyReader_ = Executors . newScheduledThreadPool ( 1 ) ; < |startfocus| > private final String defaultKuduMasterHosts_ ; < |endfocus| > public Frontend ( AuthorizationConfig authorizationConfig , String defaultKuduMasterHosts ) { this ( authorizationConfig , new ImpaladCatalog ( defaultKuduMasterHosts ) ) ; } /* * * C'tor used by tests to pass in a custom ImpaladCatalog . */ public Frontend ( AuthorizationConfig authorizationConfig , ImpaladCatalog catalog ) { authzConfig_ = authorizationConfig ; impaladCatalog_ = catalog ; defaultKuduMasterHosts_ = catalog . getDefaultKuduMasterHosts ( ) ; authzChecker_ = new AtomicReference < AuthorizationChecker > ( new AuthorizationChecker ( authzConfig_ , impaladCatalog_ . getAuthPolicy ( ) ) ) ;
public String getHostname ( ) { < |startfocus| > return hostPort . getHostString ( ) ; < |endfocus| >
/* * * Kills the TS listening on the provided port . Doesn't do anything if the TS was already killed . * @param port port on which the tablet server is listening on * @throws InterruptedException */ public void killTabletServerOnPort ( int port ) throws InterruptedException { Process ts = tserverProcesses . remove ( port ) ; if ( ts == null ) { // The TS is already dead , good . return ; } < |startfocus| > LOG . info ( "Killing server at port " + port ) ; destroyAndWaitForProcess ( ts ) ; < |endfocus| > } /* * * Kills all tablet servers . * @throws InterruptedException */ public void killTabletServers ( ) throws InterruptedException { for ( Process tserver : tserverProcesses . values ( ) ) { destroyAndWaitForProcess ( tserver ) ; } tserverProcesses . clear ( ) ; } /* * * Restarts any tablet servers which were previously killed . */ public void restartDeadTabletServers ( ) throws Exception { for ( int port : tserverPorts ) { if ( tserverProcesses . containsKey ( port ) ) continue ; restartDeadTabletServerOnPort ( port ) ; } }
private static String findBinaryDir ( ) { // First check the system property , which is our standard override . String kuduHomeProp = System . getProperty ( KUDU_BIN_DIR_PROP ) ; if ( kuduHomeProp != null ) { < |startfocus| > LOG . info ( "Using Kudu binary directory specified by system property ' { } ' : { } " , KUDU_BIN_DIR_PROP , kuduHomeProp ) ; < |endfocus| > return kuduHomeProp ; } // Next , check the environment variable . String kuduHomeVar = System . getenv ( KUDU_HOME_VAR ) ; if ( kuduHomeVar != null ) { LOG . info ( "Using Kudu home directory specified by environment variable ' { } ' : { } " , KUDU_HOME_VAR , kuduHomeVar ) ; String kuduBinDir = new File ( kuduHomeVar , "bin" ) . getPath ( ) ; return kuduBinDir ; } // Last , use the kudu that is available on the path . try { Runtime runtime = Runtime . getRuntime ( ) ; Process process = runtime . exec ( "which kudu" ) ; int errorCode = process . waitFor ( ) ; if ( errorCode == 0 ) { < |startfocus| > BufferedReader reader = new BufferedReader ( new InputStreamReader ( process . getInputStream ( ) ) ) ; String kuduBinDir = reader . readLine ( ) ; LOG . info ( "Using Kudu binary directory specified by 'which kudu' : { } " , kuduBinDir ) ; < |endfocus| > return kuduBinDir ; } } catch ( IOException e ) { LOG . warn ( "Failed to execute 'which kudu'" , e ) ; } catch ( InterruptedException e ) { LOG . warn ( "Interrupted while executing 'which kudu'" , e ) ; } return null ; }
String kuduHomeProp = System . getProperty ( KUDU_BIN_DIR_PROP ) ; if ( kuduHomeProp != null ) { LOG . info ( "Using Kudu binary directory specified by system property ' { } ' : { } " , KUDU_BIN_DIR_PROP , kuduHomeProp ) ; return kuduHomeProp ; } // Next , check the environment variable . String kuduHomeVar = System . getenv ( KUDU_HOME_VAR ) ; if ( kuduHomeVar != null ) { < |startfocus| > LOG . info ( "Using Kudu home directory specified by environment variable ' { } ' : { } " , KUDU_HOME_VAR , kuduHomeVar ) ; < |endfocus| > String kuduBinDir = new File ( kuduHomeVar , "bin" ) . getPath ( ) ; return kuduBinDir ; } // Last , use the kudu that is available on the path . try { Runtime runtime = Runtime . getRuntime ( ) ; Process process = runtime . exec ( "which kudu" ) ; int errorCode = process . waitFor ( ) ; if ( errorCode == 0 ) { try ( final Reader reader = new InputStreamReader ( process . getInputStream ( ) , UTF_8 ) ) { String kuduBinary = CharStreams . toString ( reader ) ;
return kuduHomeProp ; } // Next , check the environment variable . String kuduHomeVar = System . getenv ( KUDU_HOME_VAR ) ; if ( kuduHomeVar != null ) { LOG . info ( "Using Kudu home directory specified by environment variable ' { } ' : { } " , KUDU_HOME_VAR , kuduHomeVar ) ; String kuduBinDir = new File ( kuduHomeVar , "bin" ) . getPath ( ) ; return kuduBinDir ; } < |startfocus| > // Last , use the kudu that is available on the path as a proxy for the bin dir . < |endfocus| > try { Runtime runtime = Runtime . getRuntime ( ) ; Process process = runtime . exec ( "which kudu" ) ; int errorCode = process . waitFor ( ) ; if ( errorCode == 0 ) { try ( final Reader reader = new InputStreamReader ( process . getInputStream ( ) , UTF_8 ) ) { String kuduBinary = CharStreams . toString ( reader ) ; String kuduBinDir = new File ( kuduBinary ) . getParent ( ) ; LOG . info ( "Using Kudu binary directory found on path with 'which kudu' : { } " , kuduBinDir ) ; return kuduBinDir ; } } } catch ( IOException | InterruptedException ex ) {
String kuduBinDir = new File ( kuduHomeVar , "bin" ) . getPath ( ) ; return kuduBinDir ; } // Last , use the kudu that is available on the path . try { Runtime runtime = Runtime . getRuntime ( ) ; Process process = runtime . exec ( "which kudu" ) ; int errorCode = process . waitFor ( ) ; if ( errorCode == 0 ) { < |startfocus| > try ( final Reader reader = new InputStreamReader ( process . getInputStream ( ) , UTF_8 ) ) { < |endfocus| > String kuduBinary = CharStreams . toString ( reader ) ; String kuduBinDir = new File ( kuduBinary ) . getParent ( ) ; LOG . info ( "Using Kudu binary directory found on path with 'which kudu' : { } " , kuduBinDir ) ; return kuduBinDir ; } } } catch ( IOException | InterruptedException ex ) { throw new RuntimeException ( "Error while locating kudu binary" , ex ) ; } throw new RuntimeException ( "Could not locate the kudu binary directory . " + "Set the system variable " + KUDU_BIN_DIR_PROP + " , environment variable " + KUDU_HOME_VAR + " or add the kudu binary directory to the path . " ) ; } }
public class AlterViewStmt extends CreateOrAlterViewStmtBase { public AlterViewStmt ( TableName tableName , List < ColumnDef > columnDefs , QueryStmt viewDefStmt ) { super ( false , tableName , columnDefs , null , viewDefStmt ) ; } @Override public void analyze ( Analyzer analyzer ) throws AnalysisException { // Enforce Hive column labels for view compatibility . analyzer . setUseHiveColLabels ( true ) ; viewDefStmt_ . analyze ( analyzer ) ; Preconditions . checkState ( tableName_ != null && ! tableName_ . isEmpty ( ) ) ; dbName_ = analyzer . getTargetDbName ( tableName_ ) ; < |startfocus| > owner_ = analyzer . getUser ( ) . getShortName ( ) ; < |endfocus| > // Set the servername here if authorization is enabled because analyzer_ is not // available in the toThrift ( ) method . serverName_ = analyzer . getServerName ( ) ; FeTable table = analyzer . getTable ( tableName_ , Privilege . ALTER ) ; Preconditions . checkNotNull ( table ) ; if ( ! ( table instanceof FeView ) ) {
try { miniCluster . waitFor ( ) ; } catch ( InterruptedException e ) { LOG . warn ( "Minicluster process did not exit , destroying" ) ; miniCluster . destroy ( ) ; } } } /* * * Returns a master server identified by an address . * * @param address unique address identifying the server * @return the DaemonInfo of the server * @throws RuntimeException if the server is not found */ < |startfocus| > private DaemonInfo getMasterServer ( HostAndPort hostAndPort ) throws RuntimeException { DaemonInfo d = masterServers . get ( hostAndPort ) ; < |endfocus| > if ( d == null ) { throw new RuntimeException ( String . format ( "Master server % s not found" , hostAndPort ) ) ; } return d ; } /* * * Returns a tablet server identified by an address . * * @param address unique address identifying the server * @return the DaemonInfo of the server * @throws RuntimeException if the server is not found */ private DaemonInfo getTabletServer ( HostAndPort hostAndPort ) throws RuntimeException { DaemonInfo d = tabletServers . get ( hostAndPort ) ;
import static org . junit . Assert . assertArrayEquals ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; import java . net . InetAddress ; import java . net . InetSocketAddress ; import java . util . Arrays ; import java . util . List ; import org . apache . kudu . client . HostAndPort ; import org . junit . Test ; /* * * Test for { @link NetUtil } . */ public class TestNetUtil { /* * < |startfocus| > * Tests parsing strings into { @link InetSocketAddress } objects with and without specifying < |endfocus| > * the port in the string . */ @Test public void testParseString ( ) { String aStringWithPort = "1 . 2 . 3 . 4 : 1234" ; HostAndPort hostAndPortForAStringWithPort = NetUtil . parseString ( aStringWithPort , 0 ) ; assertEquals ( hostAndPortForAStringWithPort . getHost ( ) , "1 . 2 . 3 . 4" ) ; assertEquals ( hostAndPortForAStringWithPort . getPort ( ) , 1234 ) ; String aStringWithoutPort = "1 . 2 . 3 . 4" ; HostAndPort hostAndPortForAStringWithoutPort = NetUtil . parseString ( aStringWithoutPort , 12345 ) ;
private static String findBinaryDir ( ) { // If kuduBinDir system property is set , use that . < |startfocus| > String kuduBinProp = System . getProperty ( KUDU_BIN_DIR_PROP ) ; if ( kuduBinProp != null ) { < |endfocus| > LOG . info ( "Using Kudu binary directory specified by system property ' { } ' : { } " , KUDU_BIN_DIR_PROP , kuduBinProp ) ; return kuduBinProp ; } // If the `kudu` binary is found on the PATH using `which kudu` , use its parent directory . try { Runtime runtime = Runtime . getRuntime ( ) ; Process process = runtime . exec ( "which kudu" ) ; int errorCode = process . waitFor ( ) ; if ( errorCode == 0 ) { try ( Reader reader = new InputStreamReader ( process . getInputStream ( ) , UTF_8 ) ) { String kuduBinary = CharStreams . toString ( reader ) ; String kuduBinDir = new File ( kuduBinary ) . getParent ( ) ; LOG . info ( "Using Kudu binary directory found on path with 'which kudu' : { } " , kuduBinDir ) ; return kuduBinDir ; } } } catch ( IOException | InterruptedException ex ) {
private PrivilegedExecutor privilegedExecutor ; public KuduSink ( ) { this ( null ) ; } @InterfaceAudience . LimitedPrivate ( "Test" ) @InterfaceAudience . Private public KuduSink ( KuduClient kuduClient ) { this . client = kuduClient ; } @Override public synchronized void start ( ) { Preconditions . checkState ( table == null && session == null , "Please call stop before calling start on an old instance . " ) ; // Client is not null only inside tests . if ( client == null ) { < |startfocus| > // Creating client with FlumeAuthenticator . < |endfocus| > client = privilegedExecutor . execute ( new PrivilegedAction < KuduClient > ( ) { @Override public KuduClient run ( ) { return new KuduClient . KuduClientBuilder ( masterAddresses ) . build ( ) ; } } ) ; } session = client . newSession ( ) ; session . setFlushMode ( SessionConfiguration . FlushMode . MANUAL_FLUSH ) ; session . setTimeoutMillis ( timeoutMillis ) ; session . setIgnoreAllDuplicateRows ( ignoreDuplicateRows ) ; session . setMutationBufferSpace ( batchSize ) ; try { table = client . openTable ( tableName ) ; } catch ( Exception ex ) { sinkCounter . incrementConnectionFailedCount ( ) ;
TABLE_NAME ) ; batchSize = context . getInteger ( BATCH_SIZE , DEFAULT_BATCH_SIZE ) ; timeoutMillis = context . getLong ( TIMEOUT_MILLIS , DEFAULT_TIMEOUT_MILLIS ) ; ignoreDuplicateRows = context . getBoolean ( IGNORE_DUPLICATE_ROWS , DEFAULT_IGNORE_DUPLICATE_ROWS ) ; String operationProducerType = context . getString ( PRODUCER ) ; String kerberosPrincipal = context . getString ( KERBEROS_PRINCIPAL ) ; String kerberosKeytab = context . getString ( KERBEROS_KEYTAB ) ; String proxyUser = context . getString ( PROXY_USER ) ; privilegedExecutor = FlumeAuthenticationUtil . getAuthenticator ( < |startfocus| > kerberosPrincipal , kerberosKeytab ) . proxyAs ( proxyUser ) ; < |endfocus| > // Check for operations producer , if null set default operations producer type . if ( operationProducerType == null || operationProducerType . isEmpty ( ) ) { operationProducerType = DEFAULT_KUDU_OPERATION_PRODUCER ; logger . warn ( "No Kudu operations producer provided , using default" ) ; } Context producerContext = new Context ( ) ; producerContext . putAll ( context . getSubProperties ( KuduSinkConfigurationConstants . PRODUCER_PREFIX ) ) ; try { Class < ? extends KuduOperationsProducer > clazz = ( Class < ? extends KuduOperationsProducer > ) Class . forName ( operationProducerType ) ; operationsProducer = clazz . getDeclaredConstructor ( ) . newInstance ( ) ;
. nullable ( true ) . build ( ) ) ; columns . add ( new ColumnSchema . ColumnSchemaBuilder ( "stringField" , Type . STRING ) . build ( ) ) ; columns . add ( new ColumnSchema . ColumnSchemaBuilder ( "decimalField" , Type . DECIMAL ) . typeAttributes ( DecimalUtil . typeAttributes ( 9 , 1 ) ) . build ( ) ) ; CreateTableOptions createOptions = new CreateTableOptions ( ) . setRangePartitionColumns ( ImmutableList . of ( "key" ) ) . setNumReplicas ( 1 ) ; return createTable ( tableName , new Schema ( columns ) , createOptions ) ; } private List < Event > generateEvents ( int eventCount , SchemaLocation schemaLocation ) throws Exception { List < Event > events = new ArrayList < > ( ) ; for ( int i = 0 ; i < eventCount ; i ++ ) { AvroKuduOperationsProducerTestRecord record = new AvroKuduOperationsProducerTestRecord ( ) ; record . setKey ( 10 * i ) ; record . setLongField ( 2L * i ) ; record . setDoubleField ( 2 . 71828 * i ) ; record . setNullableField ( i % 2 == 0 ? null : "taco" ) ; record . setStringField ( String . format ( "hello % d" , i ) ) ; record . setDecimalField ( BigDecimal . valueOf ( i , 1 ) ) ;
return sink ; } static KuduSink createSecureSink ( String tableName , String masterAddresses , String clusterRoot ) { Context context = new Context ( ) ; context . put ( KERBEROS_KEYTAB , clusterRoot + " / krb5kdc / test - user . keytab" ) ; context . put ( KERBEROS_PRINCIPAL , "test - user@KRBTEST . COM" ) ; return createSink ( tableName , null , context , masterAddresses ) ; } static void processEventsCreatingSink ( KuduClient syncClient , Context context , String tableName , List < Event > events ) throws EventDeliveryException { KuduSink sink = createSink ( syncClient , tableName , context ) ; sink . start ( ) ; processEvents ( sink , events ) ; } static void processEvents ( KuduSink sink , List < Event > events ) throws EventDeliveryException { Channel channel = sink . getChannel ( ) ; Transaction tx = channel . getTransaction ( ) ; tx . begin ( ) ; for ( Event e : events ) { channel . put ( e ) ; } tx . commit ( ) ; tx . close ( ) ; Status status = sink . process ( ) ; if ( events . isEmpty ( ) ) { assertSame ( "incorrect status for empty channel" , status , Status . BACKOFF ) ; } else {
import org . slf4j . LoggerFactory ; import org . apache . kudu . ColumnSchema ; import org . apache . kudu . Schema ; import org . apache . kudu . Type ; import org . apache . kudu . client . BaseKuduTest ; import org . apache . kudu . client . CreateTableOptions ; import org . apache . kudu . client . KuduTable ; import org . apache . kudu . client . MiniKuduCluster . MiniKuduClusterBuilder ; public class SecureKuduSinkTest extends BaseKuduTest { private static final Logger LOG = LoggerFactory . getLogger ( SecureKuduSinkTest . class ) ; < |startfocus| > private static final int TICKET_LIFETIME_SEC = 10 ; private static final int RENEWABLE_LIFETIME_SEC = 30 ; < |endfocus| > @Before public void clearTicketCacheProperty ( ) { // Let Flume authenticate System . clearProperty ( KUDU_TICKETCACHE_PROPERTY ) ; } @Override protected MiniKuduClusterBuilder getMiniClusterBuilder ( ) { return super . getMiniClusterBuilder ( ) . kdcTicketLifetime ( TICKET_LIFETIME_SEC + "s" ) . kdcRenewLifetime ( RENEWABLE_LIFETIME_SEC + "s" ) . enableKerberos ( ) ; } @Test public void testEventsWithShortTickets ( ) throws Exception { LOG . info ( "Creating new table . . . " ) ; ArrayList < ColumnSchema > columns = new ArrayList < > ( 1 ) ;
public PartitionRefImpl ( TPartialPartitionInfo p ) { < |startfocus| > this . info_ = p ; < |endfocus| > }
public PartitionRefImpl ( TPartialPartitionInfo p ) { < |startfocus| > this . info_ = p ; < |endfocus| > }
private void computeScanRangeLocations ( List < TScanRangeLocations > locations ) throws InternalException { < |startfocus| > // TODO : Can we factor out the per - host scan range calculation into a helper ? I know it's short but the logic isn't trivial and I think we expect it to be identical between the scan node implementations ( unless something changes in future ) . < |endfocus| > for ( TScanRangeLocations location : locations ) { for ( TScanRangeLocation scanRangeLocation : location . getLocations ( ) ) { if ( scanRangeLocation . getServer ( ) . isSetHostname ( ) ) { String hostname = scanRangeLocation . getServer ( ) . getHostname ( ) ; if ( ! scanRangeLocationMap_ . containsKey ( hostname ) ) { scanRangeLocationMap_ . put ( hostname , new ArrayList < TScanRangeLocation > ( ) ) ; } scanRangeLocationMap_ . get ( hostname ) . add ( scanRangeLocation ) ; } } } }
if ( ! ( expr instanceof BinaryPredicate ) ) return false ; BinaryPredicate predicate = ( BinaryPredicate ) expr ; // TODO KUDU - 931 look into handling implicit / explicit casts on the SlotRef . predicate = normalizeSlotRefComparison ( predicate , analyzer ) ; if ( predicate == null ) return false ; < |startfocus| > ComparisonOp op = getKuduOperator ( predicate . getOp ( ) ) ; < |endfocus| > if ( op == null ) return false ; SlotRef ref = ( SlotRef ) predicate . getChild ( 0 ) ; LiteralExpr literal = ( LiteralExpr ) predicate . getChild ( 1 ) ; // Cannot push prediates with null literal values ( KUDU - 1595 ) . if ( literal instanceof NullLiteral ) return false ; String colName = ref . getDesc ( ) . getColumn ( ) . getName ( ) ; ColumnSchema column = table . getSchema ( ) . getColumn ( colName ) ; KuduPredicate kuduPredicate = null ; switch ( literal . getType ( ) . getPrimitiveType ( ) ) { case BOOLEAN : { kuduPredicate = KuduPredicate . newComparisonPredicate ( column , op , ( ( BoolLiteral ) literal ) . getValue ( ) ) ; break ; } case TINYINT : case SMALLINT : case INT : { kuduPredicate = KuduPredicate . newComparisonPredicate ( column , op , ( ( IntLiteral ) literal ) . getValue ( ) ) ; break ; } case BIGINT : { kuduPredicate = KuduPredicate . newComparisonPredicate ( column , op , ( ( BigIntLiteral ) literal ) . getValue ( ) ) ; break ; } case FLOAT : { kuduPredicate = KuduPredicate . newComparisonPredicate ( column , op , ( ( FloatLiteral ) literal ) . getValue ( ) ) ; break ; } case DOUBLE : { kuduPredicate = KuduPredicate . newComparisonPredicate ( column , op , ( ( DoubleLiteral ) literal ) . getValue ( ) ) ; break ; } case STRING : { kuduPredicate = KuduPredicate . newComparisonPredicate ( column , op , ( ( StringLiteral ) literal ) . getValue ( ) ) ; break ; } case TIMESTAMP : { kuduPredicate = KuduPredicate . newComparisonPredicate ( column , op , ( ( TimestampLiteral ) literal ) . getValue ( ) ) ; break ; } default : return false ; } if ( kuduPredicate == null ) return false ; if ( kuduPredicate . isAlwaysTrue ( ) ) return false ; if ( kuduPredicate . isAlwaysFalse ( ) ) { // KuduPredicate . isAlwaysFalse ( ) returns true if the predicate is always false // for all values of the column . This means that the predicate is always false // for all rows in the table . In this case , we can simply return an empty // result set . analyzer . markConstant ( true ) ; return true ; } kuduScanNode . addPredicate ( kuduPredicate ) ; return true ; }
// Compute the per - instance number of concurrent partitions , taking the number // of nodes and the data partition of the fragment executing this sink into account . long numConcurrentPartitionsPerInstance = fragment_ . getPerInstanceNdv ( queryOptions . getMt_dop ( ) , partitionKeyExprs_ ) ; if ( numConcurrentPartitionsPerInstance == - 1 ) { numConcurrentPartitionsPerInstance = DEFAULT_NUM_PARTITIONS ; } < |startfocus| > // If the insert is clustered , it produces a single partition at a time . if ( inputIsClustered_ ) { numConcurrentPartitionsPerInstance = 1 ; } < |endfocus| > FeFsTable table = ( FeFsTable ) targetTable_ ; // TODO : Estimate the memory requirements more accurately by partition type . Set < HdfsFileFormat > formats = table . getFileFormats ( ) ; long perPartitionMemReq = getPerPartitionMemReq ( formats ) ; long perInstanceMemEstimate ; // The estimate is based purely on the per - partition mem req if the input cardinality_ // or the avg row size is unknown . if ( inputNode . getCardinality ( ) == - 1 || inputNode . getAvgRowSize ( ) == - 1 ) { perInstanceMemEstimate = numConcurrentPartitionsPerInstance * perPartitionMemReq ;
FunctionCallExpr mergeAggInputFn ) { super ( ) ; fnName_ = fnName ; params_ = params ; mergeAggInputFn_ = mergeAggInputFn == null ? null : ( FunctionCallExpr ) mergeAggInputFn . clone ( ) ; if ( params . exprs ( ) != null ) children_ = Lists . newArrayList ( params_ . exprs ( ) ) ; } /* * * Returns an Expr that evaluates the function call < fnName > ( < params > ) . The returned * Expr is not necessarily a FunctionCallExpr ( example : DECODE ( ) ) */ < |startfocus| > public static Expr createExpr ( FunctionName fnName , FunctionParams params ) { < |endfocus| > FunctionCallExpr functionCallExpr = new FunctionCallExpr ( fnName , params ) ; if ( fnName . getFnNamePath ( ) . size ( ) == 1 && fnName . getFnNamePath ( ) . get ( 0 ) . equalsIgnoreCase ( "decode" ) || fnName . getFnNamePath ( ) . size ( ) == 2 && fnName . getFnNamePath ( ) . get ( 0 ) . equalsIgnoreCase ( Catalog . BUILTINS_DB ) && fnName . getFnNamePath ( ) . get ( 1 ) . equalsIgnoreCase ( "decode" ) ) { return new CaseExpr ( functionCallExpr ) ; } return functionCallExpr ; }
public static FunctionCallExpr createMergeAggCall ( FunctionCallExpr agg , List < Expr > params ) { Preconditions . checkState ( agg . isAnalyzed ( ) ) ; Preconditions . checkState ( agg . isAggregateFunction ( ) ) ; FunctionCallExpr result = new FunctionCallExpr ( < |startfocus| > agg . fnName_ , new FunctionParams ( false , params ) , agg ) ; < |endfocus| > // Inherit the function object from 'agg' . result . fn_ = agg . fn_ ; result . type_ = agg . type_ ; // Set an explicit label based on the input agg . if ( agg . isMergeAggFn ( ) ) { result . label_ = agg . label_ ; } else { // fn ( input ) becomes fn : merge ( input ) . result . label_ = agg . toSql ( ) . replaceFirst ( agg . fnName_ . toString ( ) , agg . fnName_ . toString ( ) + " : merge" ) ; } Preconditions . checkState ( ! result . type_ . isWildcardDecimal ( ) ) ; return result ;
public static FunctionCallExpr createMergeAggCall ( FunctionCallExpr agg , List < Expr > params ) { Preconditions . checkState ( agg . isAnalyzed ( ) ) ; Preconditions . checkState ( agg . isAggregateFunction ( ) ) ; FunctionCallExpr result = new FunctionCallExpr ( < |startfocus| > agg . fnName_ , new FunctionParams ( false , params ) , agg ) ; < |endfocus| > // Inherit the function object from 'agg' . result . fn_ = agg . fn_ ; result . type_ = agg . type_ ; // Set an explicit label based on the input agg . if ( agg . isMergeAggFn ( ) ) { result . label_ = agg . label_ ; } else { // fn ( input ) becomes fn : merge ( input ) . result . label_ = agg . toSql ( ) . replaceFirst ( agg . fnName_ . toString ( ) , agg . fnName_ . toString ( ) + " : merge" ) ; } Preconditions . checkState ( ! result . type_ . isWildcardDecimal ( ) ) ; return result ;
// For CTAS the overall TExecRequest statement type is DDL , but the // query_exec_request should be DML result . stmt_type = analysisResult . isCreateTableAsSelectStmt ( ) ? TStmtType . DDL : TStmtType . DML ; result . query_exec_request . stmt_type = TStmtType . DML ; // create finalization params of insert stmt InsertStmt insertStmt = analysisResult . getInsertStmt ( ) ; if ( insertStmt . getTargetTable ( ) instanceof HdfsTable ) { TFinalizeParams finalizeParams = new TFinalizeParams ( ) ; finalizeParams . setIs_overwrite ( insertStmt . isOverwrite ( ) ) ; finalizeParams . setTable_name ( insertStmt . getTargetTableName ( ) . getTbl ( ) ) ; < |startfocus| > finalizeParams . setTable_id ( insertStmt . getTargetTable ( ) . getId ( ) ) ; < |endfocus| > String db = insertStmt . getTargetTableName ( ) . getDb ( ) ; finalizeParams . setTable_db ( db == null ? queryCtx . session . database : db ) ; HdfsTable hdfsTable = ( HdfsTable ) insertStmt . getTargetTable ( ) ; finalizeParams . setHdfs_base_dir ( hdfsTable . getHdfsBaseDir ( ) ) ; finalizeParams . setStaging_dir ( hdfsTable . getHdfsBaseDir ( ) + " / _impala_insert_staging" ) ; queryExecRequest . setFinalize_params ( finalizeParams ) ; }
import org . slf4j . LoggerFactory ; import com . google . common . base . Objects ; import com . google . common . base . Preconditions ; import com . google . common . collect . Lists ; /* * * Encapsulates all the information needed to compute a list of aggregate functions with * compatible grouping including their distributed execution . * * Each SELECT block containing aggregates will have a single MultiAggregateInfo which * will contain one AggregateInfo per unique list of DISTINCT expressions . If there is < |startfocus| > * only a single DISTINCT class , a single AggregateInfo will be created which will * represent that class and any non - DISTINCT aggregates . If there is more than one * DISTINCT class , the non - DISTINCT aggregates will be grouped together in their own < |endfocus| > * AggregateInfo . * * Execution is modeled as a tree of AggregateInfo objects which express the local and * merging aggregate computations . The tree structure looks as follows : * - for non - distinct aggregation : * - aggInfo : contains the original aggregation functions and grouping exprs * - aggInfo . mergeAggInfo : contains the merging aggregation functions ( grouping
private long warnThresholdMs_ ; private static final long WARN_THRESHOLD_MS = 10000 ; // log INFO if we detect a pause longer than this threshold . private long infoThresholdMs_ ; private static final long INFO_THRESHOLD_MS = 1000 ; // Daemon thread running the pause monitor loop . private Thread monitorThread_ ; private volatile boolean shouldRun = true ; < |startfocus| > // Singleton isntance of this pause monitor . < |endfocus| > public static JvmPauseMonitor INSTANCE = new JvmPauseMonitor ( ) ; // Initializes the pause monitor . No - op if called multiple times . public static void initPauseMonitor ( ) { if ( INSTANCE . isStarted ( ) ) return ; INSTANCE . init ( ) ; } private JvmPauseMonitor ( ) { this ( INFO_THRESHOLD_MS , WARN_THRESHOLD_MS ) ; } private JvmPauseMonitor ( long infoThresholdMs , long warnThresholdMs ) { this . infoThresholdMs_ = infoThresholdMs ; this . warnThresholdMs_ = warnThresholdMs ; } protected void init ( ) { monitorThread_ = new Thread ( new Monitor ( ) , "JVM pause monitor" ) ; monitorThread_ . setDaemon ( true ) ; monitorThread_ . start ( ) ; }
switch ( catalogObject . getType ( ) ) { case DATABASE : return "DATABASE : " + catalogObject . getDb ( ) . getDb_name ( ) . toLowerCase ( ) ; case TABLE : case VIEW : TTable tbl = catalogObject . getTable ( ) ; return "TABLE : " + tbl . getDb_name ( ) . toLowerCase ( ) + " . " + tbl . getTbl_name ( ) . toLowerCase ( ) ; case FUNCTION : return "FUNCTION : " + catalogObject . getFn ( ) . getName ( ) + " ( " + catalogObject . getFn ( ) . getSignature ( ) + " ) " ; < |startfocus| > case ROLE : return "ROLE : " + catalogObject . getRole ( ) . getRole_name ( ) . toLowerCase ( ) ; < |endfocus| > case PRIVILEGE : return "PRIVILEGE : " + catalogObject . getPrivilege ( ) . getPrivilege_name ( ) . toLowerCase ( ) + " . " + Integer . toString ( catalogObject . getPrivilege ( ) . getPrincipal_id ( ) ) ; case HDFS_CACHE_POOL : return "HDFS_CACHE_POOL : " + catalogObject . getCache_pool ( ) . getPool_name ( ) . toLowerCase ( ) ; case DATA_SOURCE : return "DATA_SOURCE : " + catalogObject . getData_source ( ) . getName ( ) . toLowerCase ( ) ; default :
public void testBasicsWithStats ( ) { // Return all rows . Cardinality is row count ; < |startfocus| > runTest ( "SELECT id FROM functional . alltypes ; " , 7300 ) ; < |endfocus| > // Return all rows . Cardinality is row count , // should not be influenced by limited NDV of selected // column . runTest ( "SELECT bool_col FROM functional . alltypes ; " , 7300 ) ; // Result cardinality reduced by limited NDV . // Boolean column has cardinality 3 ( true , false , null ) . // Since we have metadata , and know the column is non - null , // NDV is 2 . We select one of them . runTest ( "SELECT id FROM functional . alltypes WHERE bool_col = TRUE ; " , 7300 / 2 ) ; // Result cardinality reduced by NDV . // NDV should be 10 ( from metadata ) . runTest ( "SELECT id FROM functional . alltypes WHERE int_col = 1 ; " , 7300 / 10 ) ; // Assume classic 0 . 1 selectivity for other operators // IMPALA - 7560 says this should be revised . runTest ( "SELECT id FROM functional . alltypes WHERE int_col != 1" , 730 ) ; // Return all rows . Cardinality is row count . runTest ( "SELECT id FROM functional . alltypes ; " , 7300 ) ; // Return all rows . Cardinality is row count , // should not be influenced by limited NDV of selected // column . runTest ( "SELECT bool_col FROM functional . alltypes ; " , 7300 ) ; // Result cardinality reduced by limited NDV . // Boolean column has cardinality 3 ( true , false , null ) . // Since we have metadata , and know the column is non - null , // NDV is 2 . We select one of them . runTest ( "SELECT id FROM functional . alltypes WHERE bool_col = TRUE ; " , 7300 / 2 ) ; // Result cardinality reduced by NDV . // NDV should be 10 ( from metadata ) . runTest ( "SELECT id FROM functional . alltypes WHERE int_col = 1 ; " , 7300 / 10 ) ; // Assume classic 0 . 1 selectivity for other operators // IMPALA - 7560 says this should be revised . runTest ( "SELECT id FROM functional . alltypes WHERE int_col != 1" , 730 ) ;
< |startfocus| > protected void expectCardinality ( String query , long expected ) { < |endfocus| > List < PlanFragment > plan = getPlan ( query ) ; PlanNode planRoot = plan . get ( 0 ) . getPlanRoot ( ) ; assertEquals ( expected , planRoot . getCardinality ( ) ) ;
protected void runTest ( String query , long expected ) { List < PlanFragment > plan = getPlan ( query ) ; PlanNode planRoot = plan . get ( 0 ) . getPlanRoot ( ) ; < |startfocus| > assertEquals ( query , expected , planRoot . getCardinality ( ) ) ; < |endfocus| >
private List < PlanFragment > getPlan ( String query ) { // Set up the query context . Note that we need to deep copy it before planning each // time since planning modifies it . TQueryCtx queryCtx = TestUtils . createQueryContext ( "default" , System . getProperty ( "user . name" ) ) ; queryCtx . client_request . setStmt ( query ) ; TQueryOptions queryOptions = queryCtx . client_request . getQuery_options ( ) ; queryOptions . setNum_nodes ( 1 ) ; PlanCtx planCtx = new PlanCtx ( queryCtx ) ; < |startfocus| > planCtx . setCapturePlan ( true ) ; < |endfocus| > // Discard the actual execution plan . Return the cached // internal form instead . try { frontend_ . createExecRequest ( planCtx ) ; } catch ( ImpalaException e ) { fail ( e . getMessage ( ) ) ; } List < PlanFragment > plan = planCtx . getPlan ( ) ; if ( DEBUG_MODE ) { System . out . println ( plan . get ( 0 ) . getExplainString ( queryOptions , TExplainLevel . EXTENDED ) ) ; } return plan ;
// Set up the query context . Note that we need to deep copy it before planning each // time since planning modifies it . TQueryCtx queryCtx = TestUtils . createQueryContext ( "default" , System . getProperty ( "user . name" ) ) ; queryCtx . client_request . setStmt ( query ) ; TQueryOptions queryOptions = queryCtx . client_request . getQuery_options ( ) ; queryOptions . setNum_nodes ( 1 ) ; PlanCtx planCtx = new PlanCtx ( queryCtx ) ; planCtx . capturePlan ( ) ; // Discard the actual execution plan . Return the cached // internal form instead . try { frontend_ . createExecRequest ( planCtx ) ; } catch ( ImpalaException e ) { fail ( e . getMessage ( ) ) ; } List < PlanFragment > plan = planCtx . getPlan ( ) ; if ( DEBUG_MODE ) { System . out . println ( plan . get ( 0 ) . getExplainString ( queryOptions , TExplainLevel . EXTENDED ) ) ; } return plan ;
queryOptions . setNum_nodes ( 1 ) ; PlanCtx planCtx = new PlanCtx ( queryCtx ) ; planCtx . capturePlan ( ) ; // Discard the actual execution plan . Return the cached // internal form instead . try { frontend_ . createExecRequest ( planCtx ) ; } catch ( ImpalaException e ) { fail ( e . getMessage ( ) ) ; } List < PlanFragment > plan = planCtx . getPlan ( ) ; if ( DEBUG_MODE ) { < |startfocus| > System . out . println ( plan . get ( 0 ) . getExplainString ( queryOptions , TExplainLevel . EXTENDED ) ) ; < |endfocus| > } return plan ;
// e . g . map . We could report a better error if we stored the original // HMS string . throw new AnalysisException ( "Unsupported type in '" + toSql ( ) + "' . " ) ; } < |startfocus| > computeNdv ( ) ; FeTable rootTable = resolvedPath . getRootTable ( ) ; < |endfocus| > if ( rootTable != null && rootTable . getNumRows ( ) > 0 ) { // The NDV cannot exceed the #rows in the table . numDistinctValues_ = Math . min ( numDistinctValues_ , rootTable . getNumRows ( ) ) ; } } @Override protected float computeEvalCost ( ) { return SLOT_REF_COST ; } @Override protected boolean isConstantImpl ( ) { return false ; } public SlotDescriptor getDesc ( ) { Preconditions . checkState ( isAnalyzed ( ) ) ; Preconditions . checkNotNull ( desc_ ) ; return desc_ ; } public SlotId getSlotId ( ) { Preconditions . checkState ( isAnalyzed ( ) ) ; Preconditions . checkNotNull ( desc_ ) ; return desc_ . getId ( ) ; } public Path getResolvedPath ( ) { Preconditions . checkState ( isAnalyzed ( ) ) ; return desc_ . getPath ( ) ; } @Override public String toSql ( ) { return toSql ( false ) ; } public String toSql ( boolean ifExists ) { if ( ! isAnalyzed ( ) ) { return " < slot " + id_ . toString ( ) + " > " ; } StringBuilder output = new StringBuilder ( ) ; output . append ( desc_ . getParent ( ) . getAliasAsName ( ) ) ; output . append ( " . " ) ; output . append ( desc_ . getLabel ( ) ) ; if ( ifExists ) { output . append ( " IF EXISTS" ) ; } return output . toString ( ) ; } @Override public String debugString ( ) { return Objects . toStringHelper ( this ) . add ( "id" , id_ ) . addValue ( super . debugString ( ) ) . toString ( ) ; } @Override public void getMaterializedIds ( Analyzer analyzer , List < SlotId > ids ) { Preconditions . checkState ( isAnalyzed ( ) ) ; ids . add ( desc_ . getId ( ) ) ; } @Override public Expr clone ( ) { return new SlotRef ( this ) ; } @Override public boolean localEquals ( Expr that ) { if ( ! ( that instanceof SlotRef ) ) return false ; SlotRef other = ( SlotRef ) that ; return desc_ . equals ( other . desc_ ) ; } @Override public boolean equals ( Object obj ) { if ( ! super . equals ( obj ) ) return false ; SlotRef other = ( SlotRef ) obj ; return desc_ . equals ( other . desc_ ) ; } @Override public int hashCode ( ) { if ( hashCode_ == 0 ) { hashCode_ = Objects . hashCode ( super . hashCode ( ) , desc_ ) ; } return hashCode_ ; } @Override public String toString ( ) { return Objects . toStringHelper ( this ) . add ( "desc" , desc_ ) . toString ( ) ; } }
for ( String groupName : groupNames ) { roles . addAll ( fe . getCatalog ( ) . getAuthPolicy ( ) . getGrantedRoles ( groupName ) ) ; } for ( Role role : roles ) { Principal rolePrincipal = getRole ( role . getName ( ) ) ; if ( rolePrincipal != null ) { createShowUserPrivilegesResultRows ( result , rolePrincipal . getPrivileges ( ) , filter , rolePrincipal . getName ( ) , TPrincipalType . ROLE ) ; } } return result ; } /* * < |startfocus| > * This method add the rows to the output for the SHOW GRANT USER statement for user < |endfocus| > * and associated roles . */ private void createShowUserPrivilegesResultRows ( TResultSet result , List < PrincipalPrivilege > privileges , TPrivilege filter , String name , TPrincipalType type ) { for ( PrincipalPrivilege p : privileges ) { TPrivilege privilege = p . toThrift ( ) ; if ( filter != null && isPrivilegeFiltered ( filter , privilege ) ) continue ; TResultRowBuilder rowBuilder = new TResultRowBuilder ( ) ; rowBuilder . add ( Strings . nullToEmpty ( type . name ( ) . toUpperCase ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( name ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getPrivilege_name ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getPrivilege_scope ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getCreate_time_ms ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getGrant_option ( ) ) ) ; result . addToRows ( rowBuilder . get ( ) ) ; } } /* * * This method add the rows to the output for the SHOW GRANT USER statement for user * and associated roles . */ private void createShowUserPrivilegesResultRows ( TResultSet result , List < PrincipalPrivilege > privileges , TPrivilege filter , String name , TPrincipalType type ) { for ( PrincipalPrivilege p : privileges ) { TPrivilege privilege = p . toThrift ( ) ; if ( filter != null && isPrivilegeFiltered ( filter , privilege ) ) continue ; TResultRowBuilder rowBuilder = new TResultRowBuilder ( ) ; rowBuilder . add ( Strings . nullToEmpty ( type . name ( ) . toUpperCase ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( name ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getPrivilege_name ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getPrivilege_scope ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getCreate_time_ms ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getGrant_option ( ) ) ) ; result . addToRows ( rowBuilder . get ( ) ) ; } } /* * * This method add the rows to the output for the SHOW GRANT USER statement for user * and associated roles . */ private void createShowUserPrivilegesResultRows ( TResultSet result , List < PrincipalPrivilege > privileges , TPrivilege filter , String name , TPrincipalType type ) { for ( PrincipalPrivilege p : privileges ) { TPrivilege privilege = p . toThrift ( ) ; if ( filter != null && isPrivilegeFiltered ( filter , privilege ) ) continue ; TResultRowBuilder rowBuilder = new TResultRowBuilder ( ) ; rowBuilder . add ( Strings . nullToEmpty ( type . name ( ) . toUpperCase ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( name ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getPrivilege_name ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getPrivilege_scope ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getCreate_time_ms ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getGrant_option ( ) ) ) ; result . addToRows ( rowBuilder . get ( ) ) ; } } /* * * This method add the rows to the output for the SHOW GRANT USER statement for user * and associated roles . */ private void createShowUserPrivilegesResultRows ( TResultSet result , List < PrincipalPrivilege > privileges , TPrivilege filter , String name , TPrincipalType type ) { for ( PrincipalPrivilege p : privileges ) { TPrivilege privilege = p . toThrift ( ) ; if ( filter != null && isPrivilegeFiltered ( filter , privilege ) ) continue ; TResultRowBuilder rowBuilder = new TResultRowBuilder ( ) ; rowBuilder . add ( Strings . nullToEmpty ( type . name ( ) . toUpperCase ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( name ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getPrivilege_name ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getPrivilege_scope ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getCreate_time_ms ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( privilege . getGrant_option ( ) ) ) ; result . addToRows ( rowBuilder . get ( ) ) ; } }
* Allows for filtering based on a specific privilege spec or showing all privileges * granted to the role . Used by the SHOW GRANT ROLE statement . */ public synchronized TResultSet getRolePrivileges ( String principalName , TPrivilege filter ) { TResultSet result = new TResultSet ( ) ; result . setSchema ( new TResultSetMetadata ( ) ) ; addColumnOutputColumns ( result . getSchema ( ) ) ; result . setRows ( Lists . < TResultRow > newArrayList ( ) ) ; < |startfocus| > Role role = getRole ( principalName ) ; < |endfocus| > if ( role != null ) { for ( PrincipalPrivilege p : role . getPrivileges ( ) ) { TPrivilege privilege = p . toThrift ( ) ; if ( filter != null && isPrivilegeFiltered ( filter , privilege ) ) continue ; TResultRowBuilder rowBuilder = new TResultRowBuilder ( ) ; result . addToRows ( addShowPrincipalOutputResults ( privilege , rowBuilder ) . get ( ) ) ; } } return result ; } /* * * Check if the filter matches the privilege . */ private boolean isPrivilegeFiltered ( TPrivilege filter , TPrivilege privilege ) { filter . setPrivilege_level ( privilege . getPrivilege_level ( ) ) ; String privName = PrincipalPrivilege . buildPrivilegeName ( filter ) ;
Type . STRING . toThrift ( ) ) ) ; addColumnOutputColumns ( result . getSchema ( ) ) ; result . setRows ( Lists . < TResultRow > newArrayList ( ) ) ; // A user should be considered to not exist if they do not have any groups . Set < String > groupNames = fe . getAuthzChecker ( ) . getUserGroups ( new org . apache . impala . authorization . User ( principalName ) ) ; if ( groupNames . isEmpty ( ) ) { throw new AnalysisException ( String . format ( "User ' % s' does not exist . " , principalName ) ) ; } < |startfocus| > User user = getUser ( principalName ) ; < |endfocus| > if ( user != null ) { for ( PrincipalPrivilege p : user . getPrivileges ( ) ) { TPrivilege privilege = p . toThrift ( ) ; if ( filter != null ) { if ( isPrivilegeFiltered ( filter , privilege ) ) continue ; } TResultRowBuilder rowBuilder = new TResultRowBuilder ( ) ; rowBuilder . add ( Strings . nullToEmpty ( TPrincipalType . USER . name ( ) . toUpperCase ( ) ) ) ; rowBuilder . add ( Strings . nullToEmpty ( principalName ) ) ; result . addToRows ( addShowPrincipalOutputResults ( privilege , rowBuilder ) . get ( ) ) ; } }
import org . apache . sentry . provider . common . GroupMappingService ; import java . util . Map ; import java . util . Set ; /* * * This class is used for testing complex privileges where we don't create * users and groups on the system . * * The current structure is : * user_1group - > group_1 * user_2group - > group_2a , group_2b * user1_shared - > group_3 * user2_shared - > group_3 */ public class CustomClusterGroupMapper implements GroupMappingService { < |startfocus| > < |endfocus| > private final Map < String , Set < String > > groupsMap_ = Maps . newHashMap ( ) ; public CustomClusterGroupMapper ( ) { // Need to make sure we can resolve the dev user . String devUser = System . getProperty ( "user . name" ) ; groupsMap_ . put ( devUser , Sets . newHashSet ( devUser ) ) ; groupsMap_ . put ( "user_1group" , Sets . newHashSet ( "group_1" ) ) ; groupsMap_ . put ( "user_2group" , Sets . newHashSet ( "group_2a" , "group_2b" ) ) ; groupsMap_ . put ( "user1_shared" , Sets . newHashSet ( "group_3" ) ) ; groupsMap_ . put ( "user2_shared" , Sets . newHashSet ( "group_3" ) ) ; }
public CustomClusterResourceAuthorizationProvider ( String resource , PolicyEngine policy , < |startfocus| > Model model ) { < |endfocus| > super ( policy , new CustomClusterGroupMapper ( ) , model ) ;
public CustomClusterResourceAuthorizationProvider ( Configuration conf , String resource , < |startfocus| > PolicyEngine policy , Model model ) { < |endfocus| > super ( policy , new CustomClusterGroupMapper ( ) , model ) ;
import org . apache . impala . catalog . Type ; import org . apache . impala . common . AnalysisException ; import org . apache . impala . thrift . TExprNode ; import org . apache . impala . thrift . TExprNodeType ; import org . apache . impala . thrift . TSlotRef ; import com . google . common . base . Joiner ; import com . google . common . base . Objects ; import com . google . common . base . Preconditions ; public class SlotRef extends Expr { // Magic number to use to decide whether to adjust the // reported NDV value to account for possible null values . < |startfocus| > // Above this number , the adjustment does not make sense . // Making this value any higher causes TPC - H plan tests to < |endfocus| > // fail because that has several two - value , non - nullable // fields that are marked as nullable . private static final int NULL_ADJUST_THRESHOLD = 1 ; private final List < String > rawPath_ ; private final String label_ ; // printed in toSql ( ) // Results of analysis . private SlotDescriptor desc_ ; public SlotRef ( ArrayList < String > rawPath ) { super ( ) ; rawPath_ = rawPath ; label_ = ToSqlUtils . getPathSql ( rawPath_ ) ; }
import static org . junit . Assert . fail ; import java . util . List ; import org . apache . impala . common . ImpalaException ; import org . apache . impala . service . Frontend . PlanCtx ; import org . apache . impala . testutil . TestUtils ; import org . apache . impala . thrift . TExplainLevel ; import org . apache . impala . thrift . TQueryCtx ; import org . apache . impala . thrift . TQueryOptions ; import org . junit . Test ; /* * * Test the inference of tuple cardinality from NDV and * selectivity . */ public class CardinalityTest extends PlannerTestBase { < |startfocus| > private static final boolean DEBUG_MODE = false ; < |endfocus| > /* * * Test the happy path : table with stats , no all - null cols . */ @Test public void testBasicsWithStats ( ) { // Return all rows . Cardinality is row count ; verifyCardinality ( "SELECT id FROM functional . alltypes" , 7300 ) ; // Return all rows . Cardinality is row count , // should not be influenced by limited NDV of selected // column . verifyCardinality ( "SELECT bool_col FROM functional . alltypes" , 7300 ) ; // Result cardinality reduced by limited NDV . // Boolean column has cardinality 3 ( true , false , null ) .
queryOptions . setNum_nodes ( 1 ) ; PlanCtx planCtx = new PlanCtx ( queryCtx ) ; planCtx . requestPlanCapture ( ) ; // Discard the actual execution plan . Return the cached // internal form instead . try { frontend_ . createExecRequest ( planCtx ) ; } catch ( ImpalaException e ) { fail ( e . getMessage ( ) ) ; } < |startfocus| > List < PlanFragment > plan = planCtx . getPlan ( ) ; if ( DEBUG_MODE ) { LOG . info ( plan . get ( 0 ) . getExplainString ( queryOptions , TExplainLevel . EXTENDED ) ) ; } return plan ; < |endfocus| >
public void testJoinWithoutStats ( ) { // NDV multiplied out on group by < |startfocus| > expectCardinality ( "SELECT d FROM functional . alltypes , functional . nullrows" , 7300 * 26 ) ; < |endfocus| > // With that as the basis , add a GROUP BY String baseStmt = "SELECT COUNT ( * ) " + "FROM functional . alltypes , functional . nullrows " + "GROUP BY " ; // Unique values , one group per row expectCardinality ( baseStmt + "id" , 7300 ) ; // NDV ( a ) = 26 expectCardinality ( baseStmt + "a" , 26 ) ; // b has NDV = 1 , but adjust for nulls expectCardinality ( baseStmt + "b" , 2 ) ; // f has NDV = 6 expectCardinality ( baseStmt + "f" , 6 ) ; // c is all nulls expectCardinality ( baseStmt + "c" , 1 ) ; // NDV ( a ) = 26 * ndv ( c ) = 1 expectCardinality ( baseStmt + "a , c" , 26 ) ; // NDV ( a ) = 26 * ndv ( f ) = 156 // Planner does not know that a determines f expectCardinality ( baseStmt + "a , f" , 156 ) ;
public void testJoins ( ) { // Cartesian product String joinClause = " FROM functional . alltypes t1 , functional . alltypes t2 " ; expectCardinality ( "SELECT t1 . id" + joinClause , 7300 * 7300 ) ; // Cartesian product , reduced by NDV of group key < |startfocus| > expectCardinality ( "SELECT COUNT ( * ) " + joinClause + "GROUP BY t1 . id" , 7300 ) ; expectCardinality ( "SELECT COUNT ( * ) " + joinClause + "GROUP BY t1 . id , t1 . int_col" , 7300 * 10 ) ; < |endfocus| >
import org . apache . hadoop . util . GenericOptionsParser ; import org . apache . kudu . test . KuduRule ; import org . junit . After ; import org . junit . Rule ; import org . junit . Test ; import org . apache . kudu . mapreduce . CommandLineParser ; import org . apache . kudu . mapreduce . HadoopTestingUtility ; public class ITExportCsv { private static final String TABLE_NAME = ITExportCsv . class . getName ( ) + " - " + System . currentTimeMillis ( ) ; private static final HadoopTestingUtility HADOOP_UTIL = new HadoopTestingUtility ( ) ; < |startfocus| > @Rule public KuduRule kudu = new KuduRule ( ) ; < |endfocus| > @After public void tearDown ( ) throws Exception { HADOOP_UTIL . cleanup ( ) ; } @Test public void test ( ) throws Exception { Configuration conf = new Configuration ( ) ; String testHome = HADOOP_UTIL . setupAndGetTestDir ( ITExportCsv . class . getName ( ) , conf ) . getAbsolutePath ( ) ; // create a table with on empty tablet and 3 tablets of 3 rows each . createFourTabletsTableWithNineRows ( kudu . getAsyncClient ( ) , TABLE_NAME , DEFAULT_SLEEP ) ; String [ ] args = new String [ ] { " -- kuduMaster" , kudu . getMasterAddressesAsString ( ) , " -- tableName" , TABLE_NAME , " -- outputPath" , testHome , " -- columns" , "key , int_val , string_val" , " -- numMappers" , "1" } ;
// KIND , either express or implied . See the License for the // specific language governing permissions and limitations // under the License . package org . apache . kudu . client ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertNotNull ; import static org . junit . Assert . assertNotSame ; import static org . junit . Assert . assertTrue ; import com . stumbleupon . async . Deferred ; import org . junit . Test ; import org . apache . kudu . util . NetUtil ; public class TestConnectionCache { < |startfocus| > < |endfocus| > @Test ( timeout = 50000 ) public void test ( ) throws Exception { MiniKuduCluster cluster = null ; try { cluster = new MiniKuduCluster . MiniKuduClusterBuilder ( ) . numMasterServers ( 3 ) . build ( ) ; final AsyncKuduClient client = new AsyncKuduClient . AsyncKuduClientBuilder ( cluster . getMasterAddressesAsString ( ) ) . build ( ) ; // Below we ping the masters directly using RpcProxy , so if they aren't ready to process // RPCs we'll get an error . Here by listing the tables we make sure this won't happen since // the masters are ready to process RPCs . client . getTablesList ( ) . join ( ) ;
private MiniKuduClusterBuilder clusterBuilder ; private MiniKuduCluster miniCluster ; // We create both versions of the asyncClient for ease of use . public AsyncKuduClient asyncClient ; public KuduClient client ; public KuduRule ( final MiniKuduClusterBuilder clusterBuilder ) { this . clusterBuilder = clusterBuilder ; } public KuduRule ( ) { this . clusterBuilder = getBaseClusterBuilder ( ) ; } /* * * Returns the base MiniKuduClusterBuilder used when creating a < |startfocus| > * KuduRule with the default constructor . This is useful < |endfocus| > * if you want to add to the default cluster setup . * * @return */ public static MiniKuduClusterBuilder getBaseClusterBuilder ( ) { return new MiniKuduClusterBuilder ( ) . numMasterServers ( NUM_MASTER_SERVERS ) . numTabletServers ( NUM_TABLET_SERVERS ) ; } @Override public Statement apply ( Statement base , Description description ) { // Set any master server flags defined in the method level annotation . MasterServerConfig masterServerConfig = description . getAnnotation ( MasterServerConfig . class ) ; if ( masterServerConfig != null ) { for ( String flag : masterServerConfig . flags ( ) ) {
// Set any master server flags defined in the method level annotation . MasterServerConfig masterServerConfig = description . getAnnotation ( MasterServerConfig . class ) ; if ( masterServerConfig != null ) { for ( String flag : masterServerConfig . flags ( ) ) { clusterBuilder . addMasterServerFlag ( flag ) ; } } // Set any tablet server flags defined in the method level annotation . TabletServerConfig tabletServerConfig = description . getAnnotation ( TabletServerConfig . class ) ; if ( tabletServerConfig != null ) { for ( String flag : tabletServerConfig . flags ( ) ) { clusterBuilder . addTabletServerFlag ( flag ) ; } } // Generate the ExternalResource Statement . Statement statement = super . apply ( base , description ) ; // Wrap in the RetryRule to rerun flaky tests . // We use this with Gradle because it doesn't support // Surefire / Failsafe rerunFailingTestsCount like Maven does . return new RetryRule ( ) . apply ( statement , description ) ;
// Set any tablet server flags defined in the method level annotation . TabletServerConfig tabletServerConfig = description . getAnnotation ( TabletServerConfig . class ) ; if ( tabletServerConfig != null ) { for ( String flag : tabletServerConfig . flags ( ) ) { clusterBuilder . addTabletServerFlag ( flag ) ; } } // Generate the ExternalResource Statement . Statement statement = super . apply ( base , description ) ; // Wrap in the RetryRule to rerun flaky tests . < |startfocus| > // Maven's surefire / failsafe execution frameworks both support // rerunning failed tests , but Gradle doesn't , and so it was a lot // easier to implement retrying as a JUnit rule to be applied // universally than it was to hack up Gradle to support the // equivalent logic . < |endfocus| > return new RetryRule ( ) . apply ( statement , description ) ;
// Wrap in the RetryRule to rerun flaky tests . // We use this with Gradle because it doesn't support // Surefire / Failsafe rerunFailingTestsCount like Maven does . return new RetryRule ( ) . apply ( statement , description ) ; } @Override public void before ( ) throws Exception { FakeDNS . getInstance ( ) . install ( ) ; LOG . info ( "Creating a new MiniKuduCluster . . . " ) ; miniCluster = clusterBuilder . build ( ) ; LOG . info ( "Creating a new Kudu client . . . " ) ; < |startfocus| > asyncClient = new AsyncKuduClient . AsyncKuduClientBuilder ( miniCluster . getMasterAddressesAsString ( ) ) < |endfocus| > . defaultAdminOperationTimeoutMs ( DEFAULT_SLEEP ) . build ( ) ; client = asyncClient . syncClient ( ) ; } @Override public void after ( ) { try { if ( asyncClient != null ) { client . shutdown ( ) ; // No need to explicitly shutdown the async client , // shutting down the sync client effectively does that . } } catch ( KuduException e ) { LOG . warn ( "Error while shutting down the test client" ) ; } finally { if ( miniCluster != null ) { miniCluster . shutdown ( ) ; } } }
public void after ( ) { try { < |startfocus| > if ( client != null ) { < |endfocus| > client . shutdown ( ) ; // No need to explicitly shutdown the async client , // shutting down the sync client effectively does that . } } catch ( KuduException e ) { LOG . warn ( "Error while shutting down the test client" ) ; } finally { if ( miniCluster != null ) { miniCluster . shutdown ( ) ; } }
< |startfocus| > public KuduTable createTable ( String tableName , Schema schema , CreateTableOptions builder ) throws KuduException { LOG . info ( "Creating table : { } " , tableName ) ; return asyncClient . syncClient ( ) . createTable ( tableName , schema , builder ) ; } < |endfocus| > /* * * Helper method to open a table . It sets the default sleep time when joining on the Deferred . * @param name Name of the table * @return A KuduTable * @throws Exception MasterErrorException if the table doesn't exist */ public KuduTable openTable ( String name ) throws Exception {
// shutting down the sync client effectively does that . } } catch ( KuduException e ) { LOG . warn ( "Error while shutting down the test client" ) ; } finally { if ( miniCluster != null ) { miniCluster . shutdown ( ) ; } } } public KuduClient getClient ( ) { return client ; } public AsyncKuduClient getAsyncClient ( ) { return asyncClient ; } < |startfocus| > public KuduTable createTable ( String tableName , Schema schema , CreateTableOptions builder ) throws KuduException { LOG . info ( "Creating table : { } " , tableName ) ; return asyncClient . syncClient ( ) . createTable ( tableName , schema , builder ) ; } < |endfocus| > /* * * Helper method to open a table . It sets the default sleep time when joining on the Deferred . * @param name Name of the table * @return A KuduTable * @throws Exception MasterErrorException if the table doesn't exist */ public KuduTable openTable ( String name ) throws Exception { Deferred < KuduTable > d = asyncClient . openTable ( name ) ; return d . join ( DEFAULT_SLEEP ) ; }
* into the Kerberos credential cache . * @param username the username to kinit as */ public void kinit ( String username ) throws IOException { miniCluster . kinit ( username ) ; } /* * * Resets the clients so that their state is completely fresh , including meta * cache , connections , open tables , sessions and scanners , and propagated timestamp . */ public void resetClients ( ) throws IOException { client . shutdown ( ) ; < |startfocus| > asyncClient = new AsyncKuduClient . AsyncKuduClientBuilder ( miniCluster . getMasterAddressesAsString ( ) ) < |endfocus| > . defaultAdminOperationTimeoutMs ( DEFAULT_SLEEP ) . build ( ) ; client = asyncClient . syncClient ( ) ; } /* * * An annotation that can be added to each test method to * define additional master server flags to be used when * creating the test cluster . * * ex : @MasterServerConfig ( flags = { "key1 = valA" , "key2 = valB" } ) */ @Retention ( RetentionPolicy . RUNTIME ) @Target ( { ElementType . METHOD } ) public @interface MasterServerConfig { String [ ] flags ( ) ; } /* * * An annotation that can be added to each test method to * define additional tserver flags to be used when * creating the test cluster . * * ex : @TserverConfig ( flags = { "key1 = valA" , "key2 = valB" } ) */ @Retention ( RetentionPolicy . RUNTIME ) @Target ( { ElementType . METHOD } ) public @interface TserverConfig { String [ ] flags ( ) ; } /* * * An annotation that can be added to each test method to * define additional master server flags to be used when * creating the test cluster . * * ex : @MasterServerConfig ( flags = { "key1 = valA" , "key2 = valB" } ) */ @Retention ( RetentionPolicy . RUNTIME ) @Target ( { ElementType . METHOD } ) public @interface MasterServerConfig { String [ ] flags ( ) ; } /* * * An annotation that can be added to each test method to * define additional tserver flags to be used when * creating the test cluster . * * ex : @TserverConfig ( flags = { "key1 = valA" , "key2 = valB" } ) */ @Retention ( RetentionPolicy . RUNTIME ) @Target ( { ElementType . METHOD } ) public @interface TserverConfig { String [ ] flags ( ) ; } /* * * An annotation that can be added to each test method to * define additional master server flags to be used when * creating the test cluster . * * ex : @MasterServerConfig ( flags = { "key1 = valA" , "key2 = valB" } ) */ @Retention ( RetentionPolicy . RUNTIME ) @Target ( { ElementType . METHOD } ) public @interface MasterServerConfig { String [ ] flags ( ) ; } /* * * An annotation that can be added to each test method to * define additional tserver flags to be used when * creating the test cluster . * * ex : @TserverConfig ( flags = { "key1 = valA" , "key2 = valB" } ) */ @Retention ( RetentionPolicy . RUNTIME ) @Target ( { ElementType . METHOD } ) public @interface TserverConfig { String [ ] flags ( ) ; } /* *
public void analyzePlanHints ( Analyzer analyzer ) { for ( PlanHint hint : planHints_ ) { if ( hint . is ( "straight_join" ) ) { < |startfocus| > analyzer . setIsStraightJoin ( ) ; < |endfocus| > } else { analyzer . addWarning ( "PLAN hint not recognized : " + hint ) ; } }
public void analyzePlanHints ( Analyzer analyzer ) { for ( PlanHint hint : planHints_ ) { if ( ! hint . is ( "straight_join" ) ) { analyzer . addWarning ( "PLAN hint not recognized : " + hint ) ; < |startfocus| > } else { analyzer . setIsStraightJoin ( ) ; < |endfocus| > } }
// be moved from this location , the user needs to have all permission . sourceDataPath_ . analyze ( analyzer , Privilege . ALL ) ; // Catch all exceptions thrown by accessing files , and rethrow as AnalysisExceptions . try { Path source = sourceDataPath_ . getPath ( ) ; FileSystem fs = source . getFileSystem ( FileSystemUtil . getConfiguration ( ) ) ; if ( ! ( fs instanceof DistributedFileSystem ) && ! ( fs instanceof S3AFileSystem ) && < |startfocus| > ! ( fs instanceof AzureBlobFileSystem ) && ! ( fs instanceof SecureAzureBlobFileSystem ) && < |endfocus| > ! ( fs instanceof AdlFileSystem ) ) { throw new AnalysisException ( String . format ( "INPATH location ' % s' " + "must point to an HDFS , S3A , ADL or ABFS filesystem . " , sourceDataPath_ ) ) ; } if ( ! fs . exists ( source ) ) { throw new AnalysisException ( String . format ( "INPATH location ' % s' does not exist . " , sourceDataPath_ ) ) ; } // If the source file is a directory , we must be able to read from and write to it .
public static byte [ ] deflateCompress ( byte [ ] input ) { if ( input == null ) return null ; ByteArrayOutputStream bos = new ByteArrayOutputStream ( input . length ) ; < |startfocus| > // TODO : Benchmark other compression levels . < |endfocus| > DeflaterOutputStream stream = new DeflaterOutputStream ( bos , new Deflater ( Deflater . BEST_SPEED ) ) ; try { stream . write ( input ) ; stream . close ( ) ; } catch ( IOException e ) { LOG . error ( "Error compressing input bytes . " , e ) ; return null ; } return bos . toByteArray ( ) ;
// so it's necessary to use the HMS APIs directly . HiveMetastoreConfig hmsConfig = client . getHiveMetastoreConfig ( ) ; HiveConf hiveConf = new HiveConf ( ) ; hiveConf . setVar ( HiveConf . ConfVars . METASTOREURIS , hmsConfig . getHiveMetastoreUris ( ) ) ; hiveConf . setBoolVar ( HiveConf . ConfVars . METASTORE_USE_THRIFT_SASL , hmsConfig . getHiveMetastoreSaslEnabled ( ) ) ; // Check that the owner of the table in the HMS matches . < |startfocus| > IMetaStoreClient hmsClient = new HiveMetaStoreClient ( hiveConf , null , false ) ; < |endfocus| > assertEquals ( owner , hmsClient . getTable ( "default" , "testOverrideTableOwner" ) . getOwner ( ) ) ; // Altering the table should not result in a change of ownership . client . alterTable ( tableName , new AlterTableOptions ( ) . renameTable ( "default . testOverrideTableOwner_renamed" ) ) ; assertEquals ( owner , hmsClient . getTable ( "default" , "testOverrideTableOwner_renamed" ) . getOwner ( ) ) ; } }
public void setQueryOptions ( TQueryOptions queryOptions ) { queryOptions_ = queryOptions ; } /* * * Returns the query options set on this query . */ public TQueryOptions getQueryOptions ( ) { return queryOptions_ ; } /* * * Returns the query options set on this query as a list of * KuduPredicate . */ public List < KuduPredicate > getKuduPredicates ( ) { return kuduPredicates_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken . */ public List < KuduScanToken > getKuduScanTokens ( ) { return kuduScanTokens_ ; } /* * * Returns the query options set on this query as a list of * KuduScanToken
return authzChecker_ . get ( ) . hasAccess ( user , request ) ; } /* * * Returns all data sources that match the pattern . If pattern is null , * matches all data sources . */ public List < DataSource > getDataSrcs ( String pattern ) { return impaladCatalog_ . getDataSources ( PatternMatcher . createHivePatternMatcher ( pattern ) ) ; } /* * * Generate result set and schema for a SHOW COLUMN STATS command . */ public TResultSet getColumnStats ( String dbName , String tableName ) throws ImpalaException { < |startfocus| > Table table = impaladCatalog_ . getTable ( dbName , tableName ) ; < |endfocus| > TResultSet result = new TResultSet ( ) ; TResultSetMetadata resultSchema = new TResultSetMetadata ( ) ; result . setSchema ( resultSchema ) ; resultSchema . addToColumns ( new TColumn ( "Column" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Type" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "#Distinct Values" , Type . BIGINT . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "#Nulls" , Type . BIGINT . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Max Size" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Avg Size" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "#Trues" , Type . BIGINT . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "#Falses" , Type . BIGINT . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Max Value" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Min Value" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "#Unsupported" , Type . BIGINT . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "NDV" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "BitVector" , Type . STRING . toThrift ( ) ) ) ; for ( ColumnStats stats : table . getColumnStats ( ) ) { TResultRowBuilder rowBuilder = new TResultRowBuilder ( ) ; rowBuilder . add ( stats . getColName ( ) ) . add ( stats . getColType ( ) ) . add ( stats . getNumDistinctValues ( ) ) . add ( stats . getNumNulls ( ) ) . add ( stats . getMaxSize ( ) ) . add ( stats . getAvgSize ( ) ) . add ( stats . getNumTrues ( ) ) . add ( stats . getNumFalses ( ) ) . add ( stats . getMaxValue ( ) ) . add ( stats . getMinValue ( ) ) . add ( stats . getNumUnsupportedValues ( ) ) . add ( stats . getNdvEstimate ( ) ) . add ( stats . getBitVectors ( ) ) ; result . addToRows ( rowBuilder . get ( ) ) ; } return result ; } /* * * Generate result set and schema for a SHOW RANGE PARTITIONS command . */ public TResultSet getRangePartitions ( String dbName , String tableName , List < TPartitionKeyValue > partitionSet ) throws ImpalaException { Table table = impaladCatalog_ . getTable ( dbName , tableName ) ; TResultSet result = new TResultSet ( ) ; TResultSetMetadata resultSchema = new TResultSetMetadata ( ) ; result . setSchema ( resultSchema ) ; resultSchema . addToColumns ( new TColumn ( "Partition" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "#Rows" , Type . BIGINT . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Size" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Bytes Cached" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Cache Replication" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Format" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Incremental stats" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Location" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Partition Parameters" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Serde Parameters" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "File Format" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Row Format" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Compressed" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Num Buckets" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Bucket Columns" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Sort Columns" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Parameters" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Database" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Table" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Partition Id" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Create Time" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Last Access Time" , Type . STRING . toThrift ( ) ) ) ; resultSchema . addToColumns ( new TColumn ( "Storage Desc Params" , Type . STRING . toThrift ( ) ) ) ; for ( HdfsPartition partition : table . getPartitions ( ) ) { if ( partition . getPartitionValues ( ) . containsAll ( partitionSet ) ) { TResultRowBuilder rowBuilder = new TResultRowBuilder ( ) ; rowBuilder . add ( partition . getPartitionName ( ) ) . add ( partition . getNumRows ( ) ) . add ( partition . getSize ( ) ) . add ( partition . getBytesCached ( ) ) . add ( partition . getCacheReplication ( ) ) . add ( partition . getInputFormatDescriptor ( ) . getFileFormat ( ) . toString ( ) ) . add ( partition . hasIncrementalStats ( ) ) . add ( partition . getLocation ( ) ) . add ( partition . getParameters ( ) ) . add ( partition . getSerdeParameters ( ) ) . add ( partition . getInputFormatDescriptor ( ) . getFileFormat ( ) . toString ( ) ) . add ( partition . getInputFormatDescriptor ( ) . getRowFormat ( ) . toString ( ) ) . add ( partition . getInputFormatDescriptor ( ) . getInputFormat ( ) . toString ( ) ) . add ( partition . getNumBuckets ( ) ) . add ( partition . getBucketColumns ( ) . toString ( ) ) . add ( partition . getSortColumns ( ) . toString ( ) ) . add ( partition . getParameters ( ) ) . add ( partition . getDbName ( ) ) . add ( partition . getTableName ( ) ) . add ( partition . getId ( ) ) . add ( partition . getCreateTime ( ) ) . add ( partition . getLastAccessTime ( ) ) . add ( partition
} else { root . setLimit ( stmt . getLimit ( ) ) ; root . computeStats ( analyzer ) ; } return root ; } /* * * If there are unassigned conjuncts that are bound by tupleIds or if there are slot * equivalences for tupleIds that have not yet been enforced , returns a SelectNode on * top of root that evaluates those conjuncts ; otherwise returns root unchanged . * TODO : change this to assign the unassigned conjuncts to root itself , if that is * semantically correct */ private PlanNode addUnassignedConjuncts ( < |startfocus| > Analyzer analyzer , List < TupleId > tupleIds , PlanNode root ) throws ImpalaException { < |endfocus| > // No point in adding SelectNode on top of an EmptyNode . if ( root instanceof EmptySetNode ) return root ; Preconditions . checkNotNull ( root ) ; // Gather unassigned conjuncts and generate predicates to enfore // slot equivalences for each tuple id . List < Expr > conjuncts = analyzer . getUnassignedConjuncts ( root ) ; for ( TupleId tid : tupleIds ) { analyzer . createEquivConjuncts ( tid , conjuncts ) ; } if ( conjuncts . isEmpty ( ) ) return root ;
// KIND , either express or implied . See the License for the // specific language governing permissions and limitations // under the License . package org . apache . impala . analysis ; import org . apache . impala . common . AnalysisException ; public interface ParseNode { /* * * Perform semantic analysis of node and all of its children . * Throws exception if any semantic errors were found . */ void analyze ( Analyzer analyzer ) throws AnalysisException ; /* * * Returns the SQL string corresponding to this node . */ < |startfocus| > String toSql ( ) ; < |endfocus| > /* * * Returns the SQL string corresponding to this node . * @param options controls what sql is returned * @see ToSqlOptions */ String toSql ( ToSqlOptions options ) ; }
< |startfocus| > < |endfocus| > /* * * Create plan tree for the entire sort group , including all contained window groups . * Marks the SortNode as requiring its input to be partitioned if partitionExprs * is not null ( partitionExprs represent the data partition of the entire partition * group of which this sort group is a part ) . */ private PlanNode createSortGroupPlan ( PlanNode root , SortGroup sortGroup , List < Expr > partitionExprs ) throws ImpalaException { List < Expr > partitionByExprs = sortGroup . partitionByExprs ; List < OrderByElement > orderByElements = sortGroup . orderByElements ;
public void computeResourceProfile ( TQueryOptions queryOptions ) { Preconditions . checkState ( hasValidStats ( ) ) ; if ( type_ == TSortType . TOPN ) { < |startfocus| > long perInstanceMemEstimate = ( long ) Math . ceil ( ( cardinality_ + offset_ ) * avgRowSize_ ) ; resourceProfile_ = new ResourceProfile ( perInstanceMemEstimate , 0 ) ; return ; < |endfocus| > } // For an external sort , set the memory cost to be what is required for a 2 - phase // sort . If the input to be sorted would take up N blocks in memory , then the // memory required for a 2 - phase sort is sqrt ( N ) blocks . A single run would be of // size sqrt ( N ) blocks , and we could merge sqrt ( N ) such runs with sqrt ( N ) blocks // of memory . double fullInputSize = getChild ( 0 ) . cardinality_ * avgRowSize_ ; boolean hasVarLenSlots = false ; for ( SlotDescriptor slotDesc : info_ . getSortTupleDescriptor ( ) . getSlots ( ) ) { if ( slotDesc . isMaterialized ( ) && ! slotDesc . getType ( ) . isFixedLengthType ( ) ) { hasVarLenSlots = true ; break ;
* true AND 'expr' - > 'expr' * false AND 'expr' - > false * true OR 'expr' - > true * false OR 'expr' - > 'expr' * * Unlike other rules here such as IF , we cannot in general simplify CompoundPredicates * with a NullLiteral child ( unless the other child is a BoolLiteral ) , eg . null and * 'expr' is false if 'expr' is false but null if 'expr' is true . * * NOT is covered by FoldConstantRule . */ private Expr simplifyCompoundPredicate ( CompoundPredicate expr ) { < |startfocus| > Expr leftChild = expr . getChild ( 0 ) ; if ( ! ( leftChild instanceof BoolLiteral ) ) return expr ; < |endfocus| > if ( expr . getOp ( ) == CompoundPredicate . Operator . AND ) { if ( ( ( BoolLiteral ) leftChild ) . getValue ( ) ) { // TRUE AND 'expr' , so return 'expr' . return expr . getChild ( 1 ) ; } else { // FALSE AND 'expr' , so return FALSE . return leftChild ; } else { if ( ( ( BoolLiteral ) leftChild ) . getValue ( ) ) { // TRUE OR 'expr' , so return TRUE . return leftChild ; } else { // FALSE OR 'expr' , so return 'expr' . return expr . getChild ( 1 ) ; } } }
private boolean isBroadcastExchange ( ) { // If the output of the sink is not partitioned but the target fragment is // partitioned , then the data exchange is broadcast . Preconditions . checkState ( ! children_ . isEmpty ( ) ) ; DataSink sink = getChild ( 0 ) . getFragment ( ) . getSink ( ) ; if ( sink == null ) return false ; Preconditions . checkState ( sink instanceof DataStreamSink ) ; DataStreamSink streamSink = ( DataStreamSink ) sink ; < |startfocus| > return ! streamSink . getOutputPartition ( ) . isPartitioned ( ) && fragment_ . isPartitioned ( ) ; < |endfocus| >
byte [ ] partitionStats , boolean hasIncrementalStats ) { table_ = Preconditions . checkNotNull ( table ) ; spec_ = Preconditions . checkNotNull ( spec ) ; msPartition_ = Preconditions . checkNotNull ( msPartition ) ; < |startfocus| > fileDescriptors_ = fileDescriptors ; partitionStats_ = partitionStats ; hasIncrementalStats_ = hasIncrementalStats ; // Columns should have been removed in the cache . Preconditions . checkArgument ( msPartition_ . getSd ( ) . getCols ( ) == null ) ; < |endfocus| >
* nullif ( expr1 , expr2 ) * nvl ( a , ifNull ) * * Since every function is rewritten to a CASE * statement , the planner runs the rule to simplify CASE * after this rule . Where that other rule can perform simplifications , * those simplifications are omitted here . However , the CASE * case rules are limited ( See IMPALA - 7750 ) , so several optimizations * appear here that can be removed once IMPALA - 7750 is fixed . */ < |startfocus| > public class RewriteConditionalFnsRule implements ExprRewriteRule { < |endfocus| > public static RewriteConditionalFnsRule INSTANCE = new RewriteConditionalFnsRule ( ) ; private RewriteConditionalFnsRule ( ) { } @Override public Expr apply ( Expr expr , Analyzer analyzer ) throws AnalysisException { if ( ! expr . isAnalyzed ( ) ) return expr ; // Rewrite conditional functions to use CASE . The result becomes // the original expression since there is no implementation for the // rewritten function . All rewritten functions use CASE , so we'll // then want to allow CASE to do any simplification ( reverting to // the original case expression if we don't pass the aggregate
Lists . newArrayList ( new CaseWhenClause ( // WHEN cond THEN thenExpr expr . getChild ( 0 ) , expr . getChild ( 1 ) ) ) , expr . getChild ( 2 ) ) ; // ELSE elseExpr END } /* * * Rewrites IFNULL ( a , x ) , which is an alias * for ISNULL ( a , x ) and NVL ( a , x ) . * * IFNULL ( NULL , x ) -- > x * IFNULL ( a , x ) -- > a , if a is a non - null literal < |startfocus| > * IFNULL ( a , x ) -- > < |endfocus| > * CASE WHEN a IS NULL THEN x ELSE a END */ private Expr rewriteIfNullFn ( FunctionCallExpr expr ) { Preconditions . checkState ( expr . getChildren ( ) . size ( ) == 2 ) ; Expr child0 = expr . getChild ( 0 ) ; return new CaseExpr ( null , // CASE Lists . newArrayList ( new CaseWhenClause ( // WHEN a IS NULL new IsNullPredicate ( child0 , false ) , expr . getChild ( 1 ) ) ) , // THEN x child0 . clone ( ) ) ; // ELSE a END } /* *
} /* * * Test some basic simplifications that are assumed in the * subsequent tests . These uncovered subtle errors and are here * to prevent regressions . */ @Test public void sanityTest ( ) throws ImpalaException { verifySelectRewrite ( "null + 1" , "NULL" ) ; verifySelectRewrite ( "null is null" , "TRUE" ) ; verifySelectRewrite ( "id + ( 2 + 3 ) " , "id + 5" ) ; verifySelectRewrite ( "1 + 2 + id" , "3 + id" ) ; < |startfocus| > // TODO : IMPALA - 7766 : Simplify arithmetic expressions < |endfocus| > // verifySelectRewrite ( "id + 1 + 2" , "id + 3" ) ; // TODO : IMPALA - 7769 : Simplify arithmetic expressions // verifySelectRewrite ( "cast ( null as INT ) IS NULL" , "TRUE" ) ; // verifySelectRewrite ( " ( null + 1 ) is null" , "TRUE" ) ; // verifySelectRewrite ( " ( 1 + 1 ) is null" , "FALSE" ) ; // verifySelectRewrite ( "CASE WHEN null + 1 THEN 10 ELSE 20 END" , "20" ) ; } @Test public void testIf ( ) throws ImpalaException { // Simplifications provided by CASE rewriting
// TODO : IMPALA - 7766 // verifySelectRewrite ( "id + 1 + 2" , "id + 3" ) ; // TODO : IMPALA - 7769 // verifySelectRewrite ( "cast ( null as INT ) IS NULL" , "TRUE" ) ; // verifySelectRewrite ( " ( null + 1 ) is null" , "TRUE" ) ; // verifySelectRewrite ( " ( 1 + 1 ) is null" , "FALSE" ) ; // verifySelectRewrite ( "CASE WHEN null + 1 THEN 10 ELSE 20 END" , "20" ) ; } @Test public void testIf ( ) throws ImpalaException { < |startfocus| > < |endfocus| > // Simplifications provided by CASE rewriting verifySelectRewrite ( "if ( true , id , id + 1 ) " , "id" ) ; verifySelectRewrite ( "if ( false , id , id + 1 ) " , "id + 1" ) ; verifySelectRewrite ( "if ( null , id , id + 1 ) " , "id + 1" ) ; // Nothing to simplify verifySelectRewrite ( "if ( id = 0 , true , false ) " , "CASE WHEN id = 0 THEN TRUE ELSE FALSE END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , 0 , sum ( id ) ) " , "CASE WHEN TRUE THEN 0 ELSE sum ( id ) END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) , 0 ) " , "CASE WHEN TRUE THEN sum ( id ) ELSE 0 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) , sum ( id ) ) " , "CASE WHEN TRUE THEN sum ( id ) ELSE sum ( id ) END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) , sum ( id ) + 1 ) " , "CASE WHEN TRUE THEN sum ( id ) ELSE sum ( id ) + 1 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 1 , sum ( id ) ) " , "CASE WHEN TRUE THEN sum ( id ) + 1 ELSE sum ( id ) END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 1 , sum ( id ) + 1 ) " , "CASE WHEN TRUE THEN sum ( id ) + 1 ELSE sum ( id ) + 1 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 1 , sum ( id ) + 2 ) " , "CASE WHEN TRUE THEN sum ( id ) + 1 ELSE sum ( id ) + 2 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 2 , sum ( id ) + 1 ) " , "CASE WHEN TRUE THEN sum ( id ) + 2 ELSE sum ( id ) + 1 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 2 , sum ( id ) + 2 ) " , "CASE WHEN TRUE THEN sum ( id ) + 2 ELSE sum ( id ) + 2 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 2 , sum ( id ) + 3 ) " , "CASE WHEN TRUE THEN sum ( id ) + 2 ELSE sum ( id ) + 3 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 3 , sum ( id ) + 2 ) " , "CASE WHEN TRUE THEN sum ( id ) + 3 ELSE sum ( id ) + 2 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 3 , sum ( id ) + 3 ) " , "CASE WHEN TRUE THEN sum ( id ) + 3 ELSE sum ( id ) + 3 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 3 , sum ( id ) + 4 ) " , "CASE WHEN TRUE THEN sum ( id ) + 3 ELSE sum ( id ) + 4 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 4 , sum ( id ) + 3 ) " , "CASE WHEN TRUE THEN sum ( id ) + 4 ELSE sum ( id ) + 3 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 4 , sum ( id ) + 4 ) " , "CASE WHEN TRUE THEN sum ( id ) + 4 ELSE sum ( id ) + 4 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 4 , sum ( id ) + 5 ) " , "CASE WHEN TRUE THEN sum ( id ) + 4 ELSE sum ( id ) + 5 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 5 , sum ( id ) + 4 ) " , "CASE WHEN TRUE THEN sum ( id ) + 5 ELSE sum ( id ) + 4 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 5 , sum ( id ) + 5 ) " , "CASE WHEN TRUE THEN sum ( id ) + 5 ELSE sum ( id ) + 5 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 5 , sum ( id ) + 6 ) " , "CASE WHEN TRUE THEN sum ( id ) + 5 ELSE sum ( id ) + 6 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 6 , sum ( id ) + 5 ) " , "CASE WHEN TRUE THEN sum ( id ) + 6 ELSE sum ( id ) + 5 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 6 , sum ( id ) + 6 ) " , "CASE WHEN TRUE THEN sum ( id ) + 6 ELSE sum ( id ) + 6 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 6 , sum ( id ) + 7 ) " , "CASE WHEN TRUE THEN sum ( id ) + 6 ELSE sum ( id ) + 7 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 7 , sum ( id ) + 6 ) " , "CASE WHEN TRUE THEN sum ( id ) + 7 ELSE sum ( id ) + 6 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 7 , sum ( id ) + 7 ) " , "CASE WHEN TRUE THEN sum ( id ) + 7 ELSE sum ( id ) + 7 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 7 , sum ( id ) + 8 ) " , "CASE WHEN TRUE THEN sum ( id ) + 7 ELSE sum ( id ) + 8 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 8 , sum ( id ) + 7 ) " , "CASE WHEN TRUE THEN sum ( id ) + 8 ELSE sum ( id ) + 7 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 8 , sum ( id ) + 8 ) " , "CASE WHEN TRUE THEN sum ( id ) + 8 ELSE sum ( id ) + 8 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 8 , sum ( id ) + 9 ) " , "CASE WHEN TRUE THEN sum ( id ) + 8 ELSE sum ( id ) + 9 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 9 , sum ( id ) + 8 ) " , "CASE WHEN TRUE THEN sum ( id ) + 9 ELSE sum ( id ) + 8 END" ) ; // Don't simplify if drops last aggregate verifySelectRewrite ( "if ( true , sum ( id ) + 9 , sum ( id ) + 9 ) " , "CASE WHEN TRUE THEN sum ( id ) + 9 ELSE sum ( id ) +
SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ; AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getSelectList ( ) . getItems ( ) . get ( 0 ) . getExpr ( ) ; Expr rewrittenExpr = verifyExprEquivalence ( origExpr , expectedExprStr , rules , stmt . getAnalyzer ( ) ) ; return rewrittenExpr ; } public Expr RewritesOkWhereExpr ( String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { < |startfocus| > return RewritesOkWhereExpr ( "functional . alltypessmall" , exprStr , rule , expectedExprStr ) ; < |endfocus| > } public Expr RewritesOkWhereExpr ( String tableName , String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOkWhereExpr ( tableName , exprStr , Lists . newArrayList ( rule ) , expectedExprStr ) ; } public Expr RewritesOkWhereExpr ( String tableName , String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { String stmtStr = "select count ( 1 ) from " + tableName + " where " + exprStr ; // Analyze without rewrites since that's what we want to test here . SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ; AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getWhereClause ( ) . get ( 0 ) ; Expr rewrittenExpr = verifyExprEquivalence ( origExpr , expectedExprStr , rules , stmt . getAnalyzer ( ) ) ; return rewrittenExpr ; } public Expr RewritesOkHavingExpr ( String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOkHavingExpr ( "functional . alltypessmall" , exprStr , rule , expectedExprStr ) ; } public Expr RewritesOkHavingExpr ( String tableName , String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOkHavingExpr ( tableName , exprStr , Lists . newArrayList ( rule ) , expectedExprStr ) ; } public Expr RewritesOkHavingExpr ( String tableName , String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { String stmtStr = "select count ( 1 ) from " + tableName + " having " + exprStr ; // Analyze without rewrites since that's what we want to test here . SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ; AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getHavingClause ( ) . get ( 0 ) ; Expr rewrittenExpr = verifyExprEquivalence ( origExpr , expectedExprStr , rules , stmt . getAnalyzer ( ) ) ; return rewrittenExpr ; } public Expr RewritesOkOnClause ( String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOkOnClause ( "functional . alltypessmall" , exprStr , rule , expectedExprStr ) ; } public Expr RewritesOkOnClause ( String tableName , String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOkOnClause ( tableName , exprStr , Lists . newArrayList ( rule ) , expectedExprStr ) ; } public Expr RewritesOkOnClause ( String tableName , String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { String stmtStr = "select count ( 1 ) from " + tableName + " join " + tableName + " t2 on " + exprStr ; // Analyze without rewrites since that's what we want to test here . SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ; AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getJoinClause ( ) . getOnClause ( ) ; Expr rewrittenExpr = verifyExprEquivalence ( origExpr , expectedExprStr , rules , stmt . getAnalyzer ( ) ) ; return rewrittenExpr ; } public Expr RewritesOkSelectList ( String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOkSelectList ( "functional . alltypessmall" , exprStr , rule , expectedExprStr ) ; } public Expr RewritesOkSelectList ( String tableName , String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOkSelectList ( tableName , exprStr , Lists . newArrayList ( rule ) , expectedExprStr ) ; } public Expr RewritesOkSelectList ( String tableName , String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { String stmtStr = "select " + exprStr + " from " + tableName ; // Analyze without rewrites since that's what we want to test here . SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ; AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getSelectList ( ) . getItems ( ) . get ( 0 ) . getExpr ( ) ; Expr rewrittenExpr = verifyExprEquivalence ( origExpr , expectedExprStr , rules , stmt . getAnalyzer ( ) ) ; return rewrittenExpr ; } public Expr RewritesOkWhereExpr ( String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { < |startfocus| > return RewritesOkWhereExpr ( "functional . alltypessmall" , exprStr , rule , expectedExprStr ) ; < |endfocus| > } public Expr RewritesOkWhereExpr ( String tableName , String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOkWhereExpr ( tableName , exprStr , Lists . newArrayList ( rule ) , expectedExprStr ) ; } public Expr RewritesOkWhereExpr ( String tableName , String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { String stmtStr = "select count ( 1 ) from " + tableName + " where " + exprStr ; // Analyze without rewrites since that's what we want to test here . SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ;
this . wrapped = wrapped ; } public Expr apply ( Expr expr , Analyzer analyzer ) throws AnalysisException { Expr ret = wrapped . apply ( expr , analyzer ) ; if ( expr != ret ) rewrites ++ ; return ret ; } } public Expr RewritesOk ( String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOk ( "functional . alltypessmall" , exprStr , rule , expectedExprStr ) ; } < |startfocus| > public Expr RewritesOk ( String tableName , String exprStr , ExprRewriteRule rule , String expectedExprStr ) < |endfocus| > throws ImpalaException { return RewritesOk ( tableName , exprStr , Lists . newArrayList ( rule ) , expectedExprStr ) ; } public Expr RewritesOk ( String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { return RewritesOk ( "functional . alltypessmall" , exprStr , rules , expectedExprStr ) ; } public Expr RewritesOk ( String tableName , String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { String stmtStr = "select " + exprStr + " from " + tableName ;
return ret ; } } public Expr RewritesOk ( String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOk ( "functional . alltypessmall" , exprStr , rule , expectedExprStr ) ; } public Expr RewritesOk ( String tableName , String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOk ( tableName , exprStr , Lists . newArrayList ( rule ) , expectedExprStr ) ; } < |startfocus| > public Expr RewritesOk ( String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) < |endfocus| > throws ImpalaException { return RewritesOk ( "functional . alltypessmall" , exprStr , rules , expectedExprStr ) ; } public Expr RewritesOk ( String tableName , String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { String stmtStr = "select " + exprStr + " from " + tableName ; // Analyze without rewrites since that's what we want to test here . SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ; AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getSelectList ( ) . getItems ( ) . get ( 0 ) . getExpr ( ) ; Expr expr = origExpr . clone ( ) ;
String stmtStr = "select " + exprStr + " from " + tableName ; // Analyze without rewrites since that's what we want to test here . SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ; AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getSelectList ( ) . getItems ( ) . get ( 0 ) . getExpr ( ) ; Expr rewrittenExpr = verifyExprEquivalence ( origExpr , expectedExprStr , rules , stmt . getAnalyzer ( ) ) ; return rewrittenExpr ; } < |startfocus| > public Expr RewritesOkWhereExpr ( String exprStr , ExprRewriteRule rule , String expectedExprStr ) < |endfocus| > throws ImpalaException { return RewritesOkWhereExpr ( "functional . alltypessmall" , exprStr , rule , expectedExprStr ) ; } public Expr RewritesOkWhereExpr ( String tableName , String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOkWhereExpr ( tableName , exprStr , Lists . newArrayList ( rule ) , expectedExprStr ) ; } public Expr RewritesOkWhereExpr ( String tableName , String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException {
AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getSelectList ( ) . getItems ( ) . get ( 0 ) . getExpr ( ) ; Expr rewrittenExpr = verifyExprEquivalence ( origExpr , expectedExprStr , rules , stmt . getAnalyzer ( ) ) ; return rewrittenExpr ; } public Expr RewritesOkWhereExpr ( String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOkWhereExpr ( "functional . alltypessmall" , exprStr , rule , expectedExprStr ) ; } < |startfocus| > public Expr RewritesOkWhereExpr ( String tableName , String exprStr , ExprRewriteRule rule , String expectedExprStr ) < |endfocus| > throws ImpalaException { return RewritesOkWhereExpr ( tableName , exprStr , Lists . newArrayList ( rule ) , expectedExprStr ) ; } public Expr RewritesOkWhereExpr ( String tableName , String exprStr , List < ExprRewriteRule > rules , String expectedExprStr ) throws ImpalaException { String stmtStr = "select count ( 1 ) from " + tableName + " where " + exprStr ; // Analyze without rewrites since that's what we want to test here . SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ; AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getWhereClause ( ) ; Expr rewrittenExpr = verifyExprEquivalence ( origExpr , expectedExprStr , rules , stmt . getAnalyzer ( ) ) ; return rewrittenExpr ; }
return rewrittenExpr ; } public Expr RewritesOkWhereExpr ( String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOkWhereExpr ( "functional . alltypessmall" , exprStr , rule , expectedExprStr ) ; } public Expr RewritesOkWhereExpr ( String tableName , String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOkWhereExpr ( tableName , exprStr , Lists . newArrayList ( rule ) , expectedExprStr ) ; } < |startfocus| > public Expr RewritesOkWhereExpr ( String tableName , String exprStr , List < ExprRewriteRule > rules , < |endfocus| > String expectedExprStr ) throws ImpalaException { String stmtStr = "select count ( 1 ) from " + tableName + " where " + exprStr ; // Analyze without rewrites since that's what we want to test here . SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ; AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getWhereClause ( ) ; Expr rewrittenExpr = verifyExprEquivalence ( origExpr , expectedExprStr , rules , stmt . getAnalyzer ( ) ) ; return rewrittenExpr ; } private Expr verifyExprEquivalence ( Expr origExpr , String expectedExprStr , List < ExprRewriteRule > rules , Analyzer analyzer ) throws ImpalaException { Expr rewrittenExpr = origExpr . rewrite ( rules , analyzer ) ; Assert . assertEquals ( expectedExprStr , rewrittenExpr . toSql ( ) ) ; return rewrittenExpr ; } public Expr RewritesOkWhereExpr ( String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOkWhereExpr ( "functional . alltypessmall" , exprStr , rule , expectedExprStr ) ; } public Expr RewritesOkWhereExpr ( String tableName , String exprStr , ExprRewriteRule rule , String expectedExprStr ) throws ImpalaException { return RewritesOkWhereExpr ( tableName , exprStr , Lists . newArrayList ( rule ) , expectedExprStr ) ; } < |startfocus| > public Expr RewritesOkWhereExpr ( String tableName , String exprStr , List < ExprRewriteRule > rules , < |endfocus| > String expectedExprStr ) throws ImpalaException { String stmtStr = "select count ( 1 ) from " + tableName + " where " + exprStr ; // Analyze without rewrites since that's what we want to test here . SelectStmt stmt = ( SelectStmt ) ParsesOk ( stmtStr ) ; AnalyzesOkNoRewrite ( stmt ) ; Expr origExpr = stmt . getWhereClause ( ) ; Expr rewrittenExpr = verifyExprEquivalence ( origExpr , expectedExprStr , rules , stmt . getAnalyzer ( ) ) ; return rewrittenExpr ; } private Expr verifyExprEquivalence ( Expr origExpr , String expectedExprStr ,
// specific language governing permissions and limitations // under the License . package org . apache . impala . analysis ; import org . apache . impala . common . AnalysisException ; public interface ParseNode { /* * * Perform semantic analysis of node and all of its children . * Throws exception if any semantic errors were found . */ void analyze ( Analyzer analyzer ) throws AnalysisException ; /* * * Returns the SQL string corresponding to this node and its descendants . < |startfocus| > * @param options controls the form of the SQL that is returned . * @see ToSqlOptions < |endfocus| > */ String toSql ( ToSqlOptions options ) ; /* * * Returns the SQL string corresponding to this node and its descendants . * This should return the same result as calling toSql ( ToSqlOptions . DEFAULT ) . */ String toSql ( ) ; }
// specific language governing permissions and limitations // under the License . package org . apache . impala . analysis ; import org . apache . impala . common . AnalysisException ; public interface ParseNode { /* * * Perform semantic analysis of node and all of its children . * Throws exception if any semantic errors were found . */ void analyze ( Analyzer analyzer ) throws AnalysisException ; /* * * Returns the SQL string corresponding to this node and its descendants . * @param options controls the form of the sql that is returned . * @see ToSqlOptions */ String toSql ( ToSqlOptions options ) ; /* * * Returns the SQL string corresponding to this node and its descendants . * This should return the same result as calling toSql ( ToSqlOptions . DEFAULT ) . */ String toSql ( ) ; }
* Throws exception if any semantic errors were found . */ void analyze ( Analyzer analyzer ) throws AnalysisException ; /* * * Returns the SQL string corresponding to this node and its descendants . * @param options controls the form of the sql that is returned . * @see ToSqlOptions */ String toSql ( ToSqlOptions options ) ; /* * * Returns the SQL string corresponding to this node and its descendants . < |startfocus| > * This should return the same result as calling toSql ( ToSqlOptions . DEFAULT ) . < |endfocus| > */ String toSql ( ) ; }
// Unless required by applicable law or agreed to in writing , // software distributed under the License is distributed on an // "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND , either express or implied . See the License for the // specific language governing permissions and limitations // under the License . package org . apache . impala . analysis ; /* * * Options to configure how Sql should be outputted by toSql ( ) and related calls . */ public enum ToSqlOptions { /* * < |startfocus| > * The default , normal way of displaying Sql < |endfocus| > */ DEFAULT ( false , false ) , /* * * Show rewritten query if it exists */ REWRITTEN ( true , false ) , /* * * Show Implicit Casts */ // To see implicit casts we must also show rewrites as otherwise we see original sql . // This does have the consequence that the sql with implict casts may not pssibly fail // to parse if resubmitted as , for example , rewritten semi - joins are not legal Sql . SHOW_IMPLICIT_CASTS ( true , true ) ; private boolean rewritten_ ; private boolean showImplicitCasts_ ;
public static String wrapString ( String s , int wrapLength ) { < |startfocus| > StringBuilder ret = new StringBuilder ( s . length ( ) + 32 ) ; < |endfocus| > String [ ] split = s . split ( "\n" ) ; for ( int i = 0 ; i < split . length ; i ++ ) { String line = split [ i ] ; String wrappedLine = WordUtils . wrap ( line , wrapLength , null , true ) ; // we keep any exiting newlines in text - these should be commented hints ret . append ( wrappedLine ) ; if ( i < split . length - 1 ) ret . append ( "\n" ) ; } return ret . toString ( ) ; }
public static String wrapString ( String s , int wrapLength ) { StringBuilder ret = new StringBuilder ( s . length ( ) + 32 ) ; String [ ] split = s . split ( "\n" ) ; for ( int i = 0 ; i < split . length ; i ++ ) { String line = split [ i ] ; String wrappedLine = WordUtils . wrap ( line , wrapLength , null , true ) ; < |startfocus| > // we keep any existing newlines in text - these should be commented hints < |endfocus| > ret . append ( wrappedLine ) ; if ( i < split . length - 1 ) ret . append ( "\n" ) ; } return ret . toString ( ) ;
checkNumericLiteralCasts ( ctx , "double_col" , "1" , "TINYINT" ) ; checkNumericLiteralCasts ( ctx , "double_col" , "1 . 0" , "DECIMAL ( 2 , 1 ) " ) ; checkNumericLiteralCasts ( ctx , "double_col" , "100000 . 001" , "DECIMAL ( 9 , 3 ) " ) ; } /* * * Generate an insert query into a column and check that the toSql ( ) with implicit casts * looks as expected * @param columnName the name of a column in functional . alltypesnopart * @param data the literal value to insert * @param castColumn the type to which the literal is expected to be cast */ private void checkNumericLiteralCasts ( AnalysisContext ctx , String columnName , String data , String castColumn ) { String query = "insert into table functional . alltypesnopart ( " + columnName + " ) " + "values ( " + data + " ) " ; String expectedToSql = "INSERT INTO TABLE " + "functional . alltypesnopart ( " + columnName + " ) " + "SELECT CAST ( " + data + " AS " + castColumn + " ) "
private void assertToSqlWithImplicitCasts ( AnalysisContext ctx , String query , String expectedToSqlWithImplicitCasts ) { StatementBase stmt = ( StatementBase ) AnalyzesOk ( query , ctx ) ; < |startfocus| > // AnalyzesOk ( stmt . toSql ( true ) , ctx ) ; < |endfocus| > String actual = stmt . toSql ( SHOW_IMPLICIT_CASTS ) ; Assert . assertEquals ( "Bad sql with implicit casts from original query : \n" + query , expectedToSqlWithImplicitCasts , actual ) ;
ignoreExplainHeader ) ; } catch ( CatalogException e ) { errorLog . append ( String . format ( "Failed to plan query\n % s\n % s" , testCase . getQuery ( ) , e . getMessage ( ) ) ) ; } actualOutput . append ( " == == \n" ) ; } if ( GENERATE_OUTPUT_FILE ) { try { < |startfocus| > File outDirFile = new File ( outDir_ ) ; outDirFile . mkdirs ( ) ; FileWriter fw = new FileWriter ( outDir_ + testFile + " . test" ) ; < |endfocus| > fw . write ( actualOutput . toString ( ) ) ; fw . close ( ) ; } catch ( IOException e ) { errorLog . append ( "Unable to create output file : " + e . getMessage ( ) ) ; } } if ( errorLog . length ( ) != 0 ) { fail ( errorLog . toString ( ) ) ; }
assertEquals ( "8 . 42PB" , PrintUtils . printBytesRoundedToMb ( ( long ) ( 1024L * 1024L * 1024L * 1024L * 1024L * 8 . 42 ) ) ) ; // Negative values always get bytes as unit . // TODO : fix this behaviour if needed . assertEquals ( " - 10B" , PrintUtils . printBytesRoundedToMb ( - 10L ) ) ; assertEquals ( " - 123456789B" , PrintUtils . printBytesRoundedToMb ( - 123456789L ) ) ; } /* * < |startfocus| > * wrap length for testWrapText ( ) - less than 80 to make test layout nicer < |endfocus| > */ private static final int WRAP_LENGTH = 60 ; /* * * Test for PrintUtils . wrapString ( ) . * */ @Test public void testWrapText ( ) { // Simple query wrapping . assertWrap ( "Analyzed query : SELECT * FROM functional_kudu . alltypestiny WHERE CAST ( bigint_col" + " AS DOUBLE ) < CAST ( 10 AS DOUBLE ) " , "Analyzed query : SELECT * FROM functional_kudu . alltypestiny\n" + "WHERE CAST ( bigint_col AS DOUBLE ) < CAST ( 10 AS DOUBLE ) . " ) ;
// Negative values always get bytes as unit . // TODO : fix this behaviour if needed . assertEquals ( " - 10B" , PrintUtils . printBytesRoundedToMb ( - 10L ) ) ; assertEquals ( " - 123456789B" , PrintUtils . printBytesRoundedToMb ( - 123456789L ) ) ; } /* * * wrap length for testWrapText ( ) - less than 80 to make test layout nicer */ private static final int WRAP_LENGTH = 60 ; /* * * Test for PrintUtils . wrapString ( ) . < |startfocus| > */ < |endfocus| > @Test public void testWrapText ( ) { // Simple query wrapping . assertWrap ( "Analyzed query : SELECT * FROM functional_kudu . alltypestiny WHERE CAST ( bigint_col" + " AS DOUBLE ) < CAST ( 10 AS DOUBLE ) " , "Analyzed query : SELECT * FROM functional_kudu . alltypestiny\n" + "WHERE CAST ( bigint_col AS DOUBLE ) < CAST ( 10 AS DOUBLE ) " ) ; // Simple query with a hint retains newlines surrounding hint . assertWrap ( "SELECT \n" + " -- + straight_join\n" + " * FROM tpch_parquet . orders INNER JOIN \n"
assertWrap ( "insert into foo values ( ' " + " " + " ' ) " , "insert into foo values ( ' \n" + "' ) " ) ; // test that long words are broken up for clarity assertWrap ( "select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" , "select\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxx" ) ; } /* * < |startfocus| > * Check that code that has been wrapped is correctly formatted * @param input input to wrap < |endfocus| > * @param expected what it should be */ private void assertWrap ( String input , String expected ) { String actual = PrintUtils . wrapString ( input , WRAP_LENGTH ) ; assertEquals ( expected , actual ) ; assertNoBlankLines ( actual ) ; assertNoTerminatingNewline ( actual ) ; assertNoLongLines ( actual ) ; } /* * * Assert that all lines of wrapped output are 80 chars or less . */ private void assertNoLongLines ( String s ) { for ( String line : s . split ( "\n" ) ) {
+ " " + " ' ) " , "insert into foo values ( ' \n" + "' ) " ) ; // test that long words are broken up for clarity assertWrap ( "select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" , "select\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxx" ) ; } /* * < |startfocus| > * Check that code that has been wrapped is correctly formatted * @param input input to wrap < |endfocus| > * @param expected what it should be */ private void assertWrap ( String input , String expected ) { String actual = PrintUtils . wrapString ( input , WRAP_LENGTH ) ; assertEquals ( expected , actual ) ; assertNoBlankLines ( actual ) ; assertNoTerminatingNewline ( actual ) ; assertNoLongLines ( actual ) ; } /* * * Assert that all lines of wrapped output are 80 chars or less . */ private void assertNoLongLines ( String s ) { for ( String line : s . split ( "\n" ) ) {
import java . util . List ; import org . apache . impala . analysis . Analyzer ; import org . apache . impala . analysis . CaseExpr ; import org . apache . impala . analysis . CaseWhenClause ; import org . apache . impala . analysis . Expr ; import org . apache . impala . analysis . FunctionCallExpr ; import org . apache . impala . analysis . IsNullPredicate ; import org . apache . impala . analysis . NullLiteral ; import org . apache . impala . common . AnalysisException ; import com . google . common . base . Preconditions ; import com . google . common . collect . Lists ; /* * * Rewrites conditional functions to use a CASE statement . * The conditional functions vanish from the plan after this < |startfocus| > * rewrite : there is no back - end implementation for these functions . < |endfocus| > * * coalesce ( v1 , v2 , . . . ) * if ( condition , ifTrue , ifFalseOrNull ) * ifnull ( a , ifNull ) * isnull ( a , ifNull ) * nullif ( expr1 , expr2 ) * nvl ( a , ifNull ) * * Since every function is rewritten to a CASE * statement , the planner runs the rule to simplify CASE * after this rule . Where that other rule can perform simplifications , * those simplifications are omitted here . However , the CASE
switch ( expr . getFnName ( ) . getFunction ( ) ) { case "if" : return rewriteIfFn ( expr ) ; case "coalesce" : return rewriteCoalesceFn ( expr ) ; case "isnull" : case "nvl" : case "ifnull" : return rewriteIfNullFn ( expr ) ; default : return expr ; } } /* * * Rewrites IF ( cond , thenExpr , elseExpr ) -- > * CASE WHEN cond THEN thenExpr ELSE elseExpr END . * < |startfocus| > * Relies on CASE simplification to perform the * following simplifications : < |endfocus| > * * IF ( TRUE , thenExpr , elseExpr ) -- > thenExpr * IF ( FALSE|NULL , thenExpr , elseExpr ) -- > elseExpr * */ private Expr rewriteIfFn ( FunctionCallExpr expr ) { Preconditions . checkState ( expr . getChildren ( ) . size ( ) == 3 ) ; return new CaseExpr ( null , // CASE Lists . newArrayList ( new CaseWhenClause ( // WHEN cond THEN thenExpr expr . getChild ( 0 ) , expr . getChild ( 1 ) ) ) , expr . getChild ( 2 ) ) ; // ELSE elseExpr END } /* * * Rewrites COALESCE ( expr1 , expr2 , . . . ) -- > * CASE WHEN expr1 IS NOT NULL THEN expr1 * WHEN expr2 IS NOT NULL THEN expr2 * . . . * ELSE NULL END . * < |startfocus| > * Relies on CASE simplification to perform the * following simplifications : < |endfocus| > * * COALESCE ( expr1 , NULL , . . . ) -- > COALESCE ( expr1 , . . . ) * COALESCE ( NULL , expr2 , . . . ) -- > COALESCE ( expr2 , . . . ) * COALESCE ( NULL , NULL , . . . ) -- > COALESCE ( NULL , . . . ) * COALESCE ( NULL , NULL ) -- > NULL * COALESCE ( expr1 ) -- > expr1 * */ private Expr rewriteCoalesceFn ( FunctionCallExpr expr ) { Preconditions . checkState ( expr . getChildren ( ) . size ( ) >= 1 ) ; List < CaseWhenClause > whenClauses = Lists . newArrayList ( ) ; for ( int i = 0 ; i < expr . getChildren ( ) . size ( ) ; ++ i ) { Expr child = expr . getChild ( i ) ; whenClauses . add ( new CaseWhenClause ( // WHEN child IS NOT NULL new IsNullPredicate ( child , false ) , child ) ) ; } return new CaseExpr ( null , whenClauses , new NullLiteral ( ) ) ; } /* * * Rewrites ISNULL ( expr ) -- > COALESCE ( expr , NULL ) . * < |startfocus| > * Relies on COALESCE simplification to perform the * following simplifications : < |endfocus| > * * ISNULL ( expr ) -- > expr * ISNULL ( NULL ) -- > NULL * */ private Expr rewriteIfNullFn ( FunctionCallExpr expr ) { Preconditions . checkState ( expr . getChildren ( ) . size ( ) == 1 ) ; return new FunctionCallExpr ( "coalesce" , Lists . newArrayList ( expr . getChild ( 0 ) , new NullLiteral ( ) ) ) ; } }
* include at least one of them , even if that means adding terms * A special case occurs if the resulting rules remove all * aggregate functions . If so , the rewrite must be done again to include * at least one aggregate , even if that aggregate won't ever be evaluated . * See IMPALA - 5125 . * * The simplifications are done here because they benefit from knowledge * of the semantics of COALESCE ( ) , and are difficult to do once encoded * as a CASE statement . < |startfocus| > */ < |endfocus| > private Expr rewriteCoalesceFn ( FunctionCallExpr expr ) { CoalesceRewriteState state = expr . contains ( Expr . isAggregatePredicate ( ) ) ? CoalesceRewriteState . AWAIT_AGGREGATE : CoalesceRewriteState . STOP_AT_LITERAL ; List < Expr > revised = new ArrayList < > ( ) ; top : for ( Expr childExpr : expr . getChildren ( ) ) { // Skip nulls . if ( childExpr . isNullLiteral ( ) ) continue ; // Stop after either first literal ( no aggregates ) // or first literal after an aggregate ( if has aggregates ) . switch ( state ) {
// Negative values always get bytes as unit . // TODO : fix this behaviour if needed . assertEquals ( " - 10B" , PrintUtils . printBytesRoundedToMb ( - 10L ) ) ; assertEquals ( " - 123456789B" , PrintUtils . printBytesRoundedToMb ( - 123456789L ) ) ; } /* * * Wrap length for testWrapText ( ) - less than 80 to make test layout nicer . */ private static final int WRAP_LENGTH = 60 ; /* * * Test for PrintUtils . wrapString ( ) . < |startfocus| > ** / < |endfocus| > @Test public void testWrapText ( ) { // Simple query wrapping . assertWrap ( "Analyzed query : SELECT * FROM functional_kudu . alltypestiny WHERE CAST ( bigint_col" + " AS DOUBLE ) < CAST ( 10 AS DOUBLE ) " , "Analyzed query : SELECT * FROM functional_kudu . alltypestiny\n" + "WHERE CAST ( bigint_col AS DOUBLE ) < CAST ( 10 AS DOUBLE ) " ) ; // Simple query with a hint retains newlines surrounding hint . assertWrap ( "SELECT \n" + " -- + straight_join\n" + " * FROM tpch_parquet . orders INNER JOIN \n"
if ( ! expr . getType ( ) . isSupported ( ) || expr . getType ( ) . isInvalid ( ) ) { < |startfocus| > throw new AnalysisException ( "Unsupported type '" + expr . getType ( ) . toSql ( ) + "' in '" + expr . toSql ( ) + "' . " ) ; < |endfocus| > } } if ( TreeNode . contains ( resultExprs_ , AnalyticExpr . class ) ) { if ( fromClause_ . isEmpty ( ) ) { throw new AnalysisException ( "Analytic expressions require FROM clause . " ) ; } // do this here , not after analyzeAggregation ( ) , otherwise the AnalyticExprs // will get substituted away if ( selectList_ . isDistinct ( ) ) { throw new AnalysisException ( "cannot combine SELECT DISTINCT with analytic functions" ) ; } } if ( whereClause_ != null ) { whereClause_ . analyze ( analyzer ) ; if ( whereClause_ . contains ( Expr . isAggregatePredicate ( ) ) ) {
public static ExprRewriteRule INSTANCE = new FoldConstantsRule ( ) ; @Override public Expr apply ( Expr expr , Analyzer analyzer ) throws AnalysisException { // Avoid calling Expr . isConstant ( ) because that would lead to repeated traversals // of the Expr tree . Assumes the bottom - up application of this rule . Constant // children should have been folded at this point . < |startfocus| > for ( Expr child : expr . getChildren ( ) ) if ( ! child . isLiteral ( ) ) return expr ; if ( expr . isLiteral ( ) || ! expr . isConstant ( ) ) return expr ; < |endfocus| > // Do not constant fold cast ( null as dataType ) because we cannot preserve the // cast - to - types and that can lead to query failures , e . g . , CTAS if ( expr instanceof CastExpr ) { CastExpr castExpr = ( CastExpr ) expr ; if ( castExpr . getChild ( 0 ) instanceof NullLiteral ) { return expr ; } } // Analyze constant exprs , if necessary . Note that the 'expr' may become non - constant // after analysis ( e . g . , aggregate functions ) . if ( ! expr . isAnalyzed ( ) ) {
public static String getPartitionKeyValueString ( LiteralExpr literalValue , String nullPartitionKeyValue ) { Preconditions . checkNotNull ( literalValue ) ; < |startfocus| > if ( Expr . IS_NULL_LITERAL . apply ( literalValue ) || literalValue . getStringValue ( ) . isEmpty ( ) ) { < |endfocus| > return nullPartitionKeyValue ; } return literalValue . getStringValue ( ) ; }
public void testUpdateCatalog ( ) { withAllPrincipalTypes ( ctx - > { String principalName = String . format ( " % s_update" , PRINCIPAL_NAME_PREFIX ) ; addCatalogPrincipalPrivileges ( ctx . type_ , ctx . catalog_ , principalName , "functional" ) ; < |startfocus| > addSentryPrincipalPrivileges ( ctx . type_ , ctx . sentryService_ , principalName , "functional" , "functional_kudu" ) ; < |endfocus| > SentryProxy . refreshSentryAuthorization ( ctx . catalog_ , ctx . sentryService_ , USER , false ) ; checkCatalogPrincipalPrivileges ( ctx . type_ , ctx . catalog_ , principalName , "server = server1 - > db = functional - > grantoption = false" , "server = server1 - > db = functional_kudu - > grantoption = false" ) ; } ) ; }
switch ( catalogObject . getType ( ) ) { case DATABASE : return "DATABASE : " + catalogObject . getDb ( ) . getDb_name ( ) . toLowerCase ( ) ; case TABLE : case VIEW : TTable tbl = catalogObject . getTable ( ) ; return "TABLE : " + tbl . getDb_name ( ) . toLowerCase ( ) + " . " + tbl . getTbl_name ( ) . toLowerCase ( ) ; case FUNCTION : return "FUNCTION : " + catalogObject . getFn ( ) . getName ( ) + " ( " + catalogObject . getFn ( ) . getSignature ( ) + " ) " ; < |startfocus| > case ROLE : String principalName = catalogObject . getPrincipal ( ) . getPrincipal_name ( ) ; if ( catalogObject . getPrincipal ( ) . getPrincipal_type ( ) == TPrincipalType . ROLE ) { principalName = principalName . toLowerCase ( ) ; } return "ROLE : " + principalName ; < |endfocus| > case PRIVILEGE : return "PRIVILEGE : " + catalogObject . getPrivilege ( ) . getPrivilege_name ( ) . toLowerCase ( ) + " . " + Integer . toString ( catalogObject . getPrivilege ( ) . getRole_id ( ) ) ; case HDFS_CACHE_POOL : return "HDFS_CACHE_POOL : " + catalogObject . getCache_pool ( ) . getPool_name ( ) . toLowerCase ( ) ; case DATA_SOURCE : return "DATA_SOURCE : " + catalogObject . getData_source ( ) . getName ( ) . toLowerCase ( ) ; default :
return "TABLE : " + tbl . getDb_name ( ) . toLowerCase ( ) + " . " + tbl . getTbl_name ( ) . toLowerCase ( ) ; case FUNCTION : return "FUNCTION : " + catalogObject . getFn ( ) . getName ( ) + " ( " + catalogObject . getFn ( ) . getSignature ( ) + " ) " ; case ROLE : return "ROLE : " + catalogObject . getRole ( ) . getRole_name ( ) . toLowerCase ( ) ; case PRIVILEGE : return "PRIVILEGE : " + < |startfocus| > catalogObject . getPrivilege ( ) . getPrivilege_name ( ) . toLowerCase ( ) + " . " + Integer . toString ( catalogObject . getPrivilege ( ) . getRole_id ( ) ) ; < |endfocus| > case HDFS_CACHE_POOL : return "HDFS_CACHE_POOL : " + catalogObject . getCache_pool ( ) . getPool_name ( ) . toLowerCase ( ) ; case DATA_SOURCE : return "DATA_SOURCE : " + catalogObject . getData_source ( ) . getName ( ) . toLowerCase ( ) ; default : throw new IllegalStateException ( "Unsupported catalog object type : " + catalogObject . getType ( ) ) ; }
for ( SlotDescriptor d : slotsBySize . get ( slotSize ) ) { Preconditions . checkState ( d . isMaterialized ( ) ) ; d . setByteSize ( slotSize ) ; d . setByteOffset ( slotOffset ) ; d . setSlotIdx ( slotIdx ++ ) ; slotOffset += slotSize ; // assign null indicator if ( d . getIsNullable ( ) ) { d . setNullIndicatorByte ( nullIndicatorByte ) ; d . setNullIndicatorBit ( nullIndicatorBit ) ; nullIndicatorBit = ( nullIndicatorBit + 1 ) % 8 ; if ( nullIndicatorBit == 0 ) ++ nullIndicatorByte ; < |startfocus| > } else { // non - nullable slots will have 0 for the byte offset and - 1 for the bit mask < |endfocus| > d . setNullIndicatorBit ( - 1 ) ; d . setNullIndicatorByte ( 0 ) ; } } Preconditions . checkState ( slotOffset == totalSlotSize ) ; byteSize_ = totalSlotSize + numNullBytes_ ;
// specific language governing permissions and limitations // under the License . package org . apache . impala . analysis ; import org . apache . impala . common . AnalysisException ; public interface ParseNode { /* * * Perform semantic analysis of node and all of its children . * Throws exception if any semantic errors were found . */ void analyze ( Analyzer analyzer ) throws AnalysisException ; /* * * Returns the SQL string corresponding to this node and its descendants . */ < |startfocus| > String toSql ( ToSqlOptions options ) ; < |endfocus| > }
public List < NodeType > getChildren ( ) { return children_ ; } /* * * Return list of all nodes of the tree rooted at 'this' , obtained * through pre - order traversal . * * Warning : this method is unsafe : it returns a list of nodes * of the requested type , but does not verify that the actual * nodes are indeed of that type . */ < |startfocus| > @SuppressWarnings ( "unchecked" ) public < C extends TreeNode < NodeType > > List < C > getNodesPreOrder ( ) { List < TreeNode < NodeType > > result = new ArrayList < > ( ) ; < |endfocus| > getNodesPreOrderAux ( result ) ; return ( List < C > ) result ; } protected void getNodesPreOrderAux ( List < TreeNode < NodeType > > result ) { result . add ( this ) ; for ( NodeType child : children_ ) child . getNodesPreOrderAux ( result ) ; } /* * * Return list of all nodes of the tree rooted at 'this' , obtained * through post - order traversal . * * Warning : this method is unsafe : it returns a list of nodes
} for ( NodeType child : children_ ) child . collect ( predicate , matches ) ; } /* * * Add all nodes in the tree that are of class 'cl' to the list 'matches' . * This node is checked first , followed by its children in order . If the node * itself is of class 'cl' , the children are skipped . */ @SuppressWarnings ( "unchecked" ) public < C extends TreeNode < NodeType > , D extends C > void collect ( < |startfocus| > Class < C > cl , Collection < D > matches ) { < |endfocus| > if ( cl . equals ( getClass ( ) ) ) { matches . add ( ( D ) this ) ; return ; } for ( NodeType child : children_ ) child . collect ( cl , matches ) ; } /* * * Add all nodes in the tree that satisfy 'predicate' to the list 'matches' * This node is checked first , followed by its children in order . All nodes * that match in the subtree are added . */ @SuppressWarnings ( "unchecked" ) public < C extends TreeNode < NodeType > , D extends C > void collectAll (
public static < C extends TreeNode < C > , D extends C > void collect ( Collection < C > nodeList , Predicate < ? super C > predicate , Collection < D > matches ) { for ( C node : nodeList ) node . collect ( predicate , matches ) ; } /* * * For each expression in 'nodeList' , collect all subexpressions of class 'cl' * into 'matches' */ public static < C extends TreeNode < C > , D extends C > void collect ( < |startfocus| > Collection < C > nodeList , Class < C > cl , Collection < D > matches ) { < |endfocus| > for ( C node : nodeList ) node . collect ( cl , matches ) ; } /* * * Return true if this node or any of its children satisfy 'predicate' . */ @SuppressWarnings ( "unchecked" ) public < C extends TreeNode < NodeType > > boolean contains ( Predicate < ? super C > predicate ) { if ( predicate . apply ( ( C ) this ) ) return true ; for ( NodeType child : children_ ) if ( child . contains ( predicate ) ) return true ; return false ; } /* *
< |startfocus| > public < C extends TreeNode < NodeType > > boolean contains ( Class < C > cl ) { < |endfocus| > if ( cl . equals ( getClass ( ) ) ) return true ; for ( NodeType child : children_ ) if ( child . contains ( cl ) ) return true ; return false ;
public static < C extends TreeNode < C > > boolean contains ( < |startfocus| > List < C > nodeList , Class < C > cl ) { < |endfocus| > for ( C node : nodeList ) if ( node . contains ( cl ) ) return true ; return false ;
} return new ArrayType ( convertParquetType ( innerGroup . getType ( 0 ) ) ) ; } /* * * Converts a "logical" Parquet type to an Impala column type . * A Parquet type is considered logical when it has an annotation . The annotation is * stored as a "OriginalType" . The Parquet documentation refers to these as logical * types , so we use that terminology here . */ private static Type convertLogicalParquetType ( < |startfocus| > org . apache . parquet . schema . Type parquetType ) throws AnalysisException { < |endfocus| > LogicalTypeAnnotation logicalType = parquetType . getLogicalTypeAnnotation ( ) ; if ( logicalType instanceof ListLogicalTypeAnnotation ) { return convertArray ( parquetType . asGroupType ( ) ) ; } if ( logicalType instanceof MapLogicalTypeAnnotation || logicalType instanceof MapKeyValueTypeAnnotation ) { // MAP_KEY_VALUE annotation should not be used any more . However , according to the // Parquet spec , some existing data incorrectly uses MAP_KEY_VALUE in place of MAP . // For backward - compatibility , a group annotated with MAP_KEY_VALUE that is not < |startfocus| > } < |endfocus| >
* Construct a thrift representation of the sink . */ protected final TDataSink toThrift ( ) { TDataSink tsink = new TDataSink ( getSinkType ( ) ) ; tsink . setLabel ( fragment_ . getId ( ) + " : " + getLabel ( ) ) ; TExecStats estimatedStats = new TExecStats ( ) ; estimatedStats . setMemory_used ( resourceProfile_ . getMemEstimateBytes ( ) ) ; tsink . setEstimated_stats ( estimatedStats ) ; toThriftInternal ( tsink ) ; return tsink ; } /* * * Add subclass - specific information to the sink . */ < |startfocus| > abstract protected void toThriftInternal ( TDataSink tsink ) ; < |endfocus| > /* * * Get the sink type of the subclass . */ abstract protected TDataSinkType getSinkType ( ) ; public void setFragment ( PlanFragment fragment ) { fragment_ = fragment ; } public PlanFragment getFragment ( ) { return fragment_ ; } public ResourceProfile getResourceProfile ( ) { return resourceProfile_ ; } /* * * Compute the resource profile for an instance of this DataSink . */ public abstract void computeResourceProfile ( TQueryOptions queryOptions ) ; }
public void testScalarFunctionSql ( ) { { // Can't generate SQL for an unresolved function List < Type > args = new ArrayList < > ( ) ; < |startfocus| > Function fn = Function . createFunction ( "mydb" , "fn1" , args , Type . INT , false , TFunctionBinaryType . JAVA ) ; < |endfocus| > try { ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; } catch ( UnsupportedOperationException e ) { // Expected } } { // Java function , leave off location and symbol List < Type > args = new ArrayList < > ( ) ; Function fn = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . INT , false ) ; fn . setBinaryType ( TFunctionBinaryType . JAVA ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1\n" ; assertEquals ( expected , sql ) ; } { // Java function , with location and symbol List < Type > args = new ArrayList < > ( ) ; Function fn = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . INT , false ) ; fn . setBinaryType ( TFunctionBinaryType . JAVA ) ; fn . setLocation ( " / path / to / my / lib . jar" ) ; fn . setSymbolName ( "myclass" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1\n" + "LOCATION ' / path / to / my / lib . jar'\n" + "SYMBOL = 'myclass'\n" ; assertEquals ( expected , sql ) ; } { // Hive function , with location and symbol List < Type > args = new ArrayList < > ( ) ; Function fn = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . INT , false ) ; fn . setBinaryType ( TFunctionBinaryType . HIVE ) ; fn . setLocation ( " / path / to / my / lib . jar" ) ; fn . setSymbolName ( "myclass" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1\n" + "LOCATION ' / path / to / my / lib . jar'\n" + "SYMBOL = 'myclass'\n" + "PREPARE_FN = 'hiveUdfPrepare'\n" + "CLOSE_FN = 'hiveUdfClose'\n" ; assertEquals ( expected , sql ) ; } }
Function fn = Function . createFunction ( "mydb" , "fn1" , args , Type . INT , false , TFunctionBinaryType . JAVA ) ; try { ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; } catch ( UnsupportedOperationException e ) { // Expected } } { // Java function , leave off location and symbol List < Type > args = new ArrayList < > ( ) ; < |startfocus| > Function fn = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . INT , false ) ; < |endfocus| > fn . setBinaryType ( TFunctionBinaryType . JAVA ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1\n" ; assertEquals ( expected , sql ) ; } { // Java function , with location and symbol List < Type > args = new ArrayList < > ( ) ; ScalarFunction fn = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . INT , false ) ; fn . setBinaryType ( TFunctionBinaryType . JAVA ) ; fn . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . jar" ) ) ; fn . setSymbolName ( "myfunc" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1\n" + "LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . jar'\n" + "SYMBOL = 'myfunc'\n" ; assertEquals ( expected , sql ) ; } { // Hive function , with location and symbol List < Type > args = new ArrayList < > ( ) ; ScalarFunction fn = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . INT , false ) ; fn . setBinaryType ( TFunctionBinaryType . HIVE ) ; fn . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . jar" ) ) ; fn . setSymbolName ( "myfunc" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1\n" + "LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . jar'\n" + "SYMBOL = 'myfunc'\n" + "PREPARE_FN = 'hdfs :/ / foo : 123 / fns / prepare_myfunc . sh'\n" + "CLOSE_FN = 'hdfs :/ / foo : 123 / fns / close_myfunc . sh'\n" ; assertEquals ( expected , sql ) ; } }
fn . setBinaryType ( TFunctionBinaryType . JAVA ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1\n" ; assertEquals ( expected , sql ) ; } { // Java function , with location and symbol List < Type > args = new ArrayList < > ( ) ; < |startfocus| > ScalarFunction fn = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . INT , false ) ; < |endfocus| > fn . setBinaryType ( TFunctionBinaryType . JAVA ) ; fn . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . jar" ) ) ; fn . setSymbolName ( "MyClass" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . jar'\n" + " SYMBOL = 'MyClass'\n" ; assertEquals ( expected , sql ) ; } { // Java function , with location and symbol List < Type > args = Lists . newArrayList ( Type . VARCHAR , Type . BOOLEAN ) ; ScalarFunction fn = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . INT , false ) ;
String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . jar'\n" + " SYMBOL = 'MyClass'\n" ; assertEquals ( expected , sql ) ; } { // Java function , with location and symbol List < Type > args = Lists . newArrayList ( Type . VARCHAR , Type . BOOLEAN ) ; < |startfocus| > ScalarFunction fn = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . INT , false ) ; < |endfocus| > fn . setBinaryType ( TFunctionBinaryType . JAVA ) ; fn . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . jar" ) ) ; fn . setSymbolName ( "MyClass" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . jar'\n" + " SYMBOL = 'MyClass'\n" ; assertEquals ( expected , sql ) ; } { // C ++ function , with location and symbol List < Type > args = Lists . newArrayList ( Type . VARCHAR , Type . BOOLEAN ) ; ScalarFunction fn = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . INT , false ) ; fn . setBinaryType ( TFunctionBinaryType . NATIVE ) ; fn . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . so" ) ) ; fn . setSymbolName ( "MyClass" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . so'\n" + " SYMBOL = 'MyClass'\n" ; assertEquals ( expected , sql ) ; } { // C ++ function , with location and symbol
String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . jar'\n" + " SYMBOL = 'MyClass'\n" ; assertEquals ( expected , sql ) ; } { // C ++ function , with location and symbol List < Type > args = new ArrayList < > ( ) ; < |startfocus| > ScalarFunction fn = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . INT , false ) ; < |endfocus| > fn . setBinaryType ( TFunctionBinaryType . NATIVE ) ; fn . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . so" ) ) ; fn . setSymbolName ( "myClass" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1 ( ) \n" + " RETURNS INT\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . so'\n" + " SYMBOL = 'myClass'\n" ; assertEquals ( expected , sql ) ; } { // C ++ function , with location and symbol
String expected = "CREATE FUNCTION mydb . fn1 ( ) \n" + " RETURNS INT\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . so'\n" + " SYMBOL = 'myClass'\n" ; assertEquals ( expected , sql ) ; } { // C ++ function , with location and symbol List < Type > args = Lists . newArrayList ( Type . VARCHAR , Type . BOOLEAN ) ; < |startfocus| > ScalarFunction fn = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . INT , false ) ; < |endfocus| > fn . setBinaryType ( TFunctionBinaryType . NATIVE ) ; fn . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . so" ) ) ; fn . setSymbolName ( "myClass" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1 ( VARCHAR ( * ) , BOOLEAN ) \n" + " RETURNS INT\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . so'\n" + " SYMBOL = 'myClass'\n" ; assertEquals ( expected , sql ) ; } { // C ++ function , with location and symbol List < Type > args = Lists . newArrayList ( Type . VARCHAR , Type . BOOLEAN ) ; < |startfocus| > ScalarFunction fn = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . INT , false ) ; < |endfocus| > fn . setBinaryType ( TFunctionBinaryType . NATIVE ) ; fn . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . so" ) ) ; fn . setSymbolName ( "myClass" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE FUNCTION mydb . fn1 ( VARCHAR ( * ) , BOOLEAN ) \n" + " RETURNS INT\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . so'\n" + " SYMBOL = 'myClass'\n" ; assertEquals ( expected , sql ) ; }
public void testAggFnSql ( ) { { // C ++ aggregate function , with minimum state List < Type > args = Lists . newArrayList ( Type . INT , Type . BOOLEAN ) ; < |startfocus| > AggregateFunction fn = new AggregateFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . BIGINT , false ) ; < |endfocus| > fn . setBinaryType ( TFunctionBinaryType . NATIVE ) ; fn . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . so" ) ) ; fn . setUpdateFnSymbol ( "Update" ) ; fn . setInitFnSymbol ( "Init" ) ; fn . setMergeFnSymbol ( "Merge" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE AGGREGATE FUNCTION mydb . fn1 ( INT , BOOLEAN ) \n" + " RETURNS BIGINT\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . so'\n" + " UPDATE_FN = 'Update'\n" + " INIT_FN = 'Init'\n" + " MERGE_FN = 'Merge'\n" ; assertEquals ( expected , sql ) ; } { // C ++ aggregate function , with full state List < Type > args = Lists . newArrayList ( Type . INT , Type . BOOLEAN ) ; AggregateFunction fn = new AggregateFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . BIGINT , false ) ; fn . setBinaryType ( TFunctionBinaryType . NATIVE ) ; fn . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . so" ) ) ; fn . setUpdateFnSymbol ( "Update" ) ; fn . setInitFnSymbol ( "Init" ) ; fn . setMergeFnSymbol ( "Merge" ) ; fn . setPrepareFnSymbol ( "Prepare" ) ; fn . setCloseFnSymbol ( "Close" ) ; fn . setSerializeFnSymbol ( "Serialize" ) ; fn . setFinalizeFnSymbol ( "Finalize" ) ; fn . setIntermediateType ( Type . STRING ) ; fn . setOutputType ( Type . STRING ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE AGGREGATE FUNCTION mydb . fn1 ( INT , BOOLEAN ) \n" + " RETURNS BIGINT\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . so'\n" + " UPDATE_FN = 'Update'\n" + " INIT_FN = 'Init'\n" + " MERGE_FN = 'Merge'\n" + " PREPARE_FN = 'Prepare'\n" + " CLOSE_FN = 'Close'\n" + " SERIALIZE_FN = 'Serialize'\n" + " FINALIZE_FN = 'Finalize'\n" + " INTERMEDIATE TYPE STRING\n" + " OUTPUT TYPE STRING\n" ; assertEquals ( expected , sql ) ; } }
" RETURNS BIGINT\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . so'\n" + " UPDATE_FN = 'Update'\n" + " INIT_FN = 'Init'\n" + " MERGE_FN = 'Merge'\n" ; assertEquals ( expected , sql ) ; } { // C ++ aggregate function , with full state List < Type > args = Lists . newArrayList ( Type . INT , Type . BOOLEAN ) ; < |startfocus| > AggregateFunction fn = new AggregateFunction ( new FunctionName ( "mydb" , "fn1" ) , args , Type . BIGINT , false ) ; < |endfocus| > fn . setBinaryType ( TFunctionBinaryType . NATIVE ) ; fn . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . so" ) ) ; fn . setUpdateFnSymbol ( "Update" ) ; fn . setInitFnSymbol ( "Init" ) ; fn . setMergeFnSymbol ( "Merge" ) ; fn . setFinalizeFnSymbol ( "Finalize" ) ; fn . setSerializeFnSymbol ( "Serialize" ) ; fn . setIntermediateType ( Type . INT ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn ) ) ; String expected = "CREATE AGGREGATE FUNCTION mydb . fn1 ( INT , BOOLEAN ) \n" + " RETURNS BIGINT\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . so'\n" + " UPDATE_FN = 'Update'\n" + " INIT_FN = 'Init'\n" + " MERGE_FN = 'Merge'\n" + " FINALIZE_FN = 'Finalize'\n" + " SERIALIZE_FN = 'Serialize'\n" + " INTERMEDIATE = 'INT'\n" ; assertEquals ( expected , sql ) ; } }
public void testCreateFunctionSql ( ) { { // Two functions , one C ++ , one Java < |startfocus| > ScalarFunction fn1 = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , new ArrayList < > ( ) , Type . INT , false ) ; < |endfocus| > fn1 . setBinaryType ( TFunctionBinaryType . JAVA ) ; fn1 . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . jar" ) ) ; fn1 . setSymbolName ( "MyClass" ) ; List < Type > args = Lists . newArrayList ( Type . VARCHAR , Type . BOOLEAN ) ; ScalarFunction fn2 = new ScalarFunction ( new FunctionName ( "mydb" , "fn2" ) , args , Type . INT , false ) ; fn2 . setBinaryType ( TFunctionBinaryType . NATIVE ) ; fn2 . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . so" ) ) ; fn2 . setSymbolName ( "myClass" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn1 , fn2 ) ) ; String expected = "CREATE FUNCTION mydb . fn1\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . jar'\n" + " SYMBOL = 'MyClass' ; \n" + "CREATE FUNCTION mydb . fn2\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . so'\n" + " SYMBOL = 'myClass'\n" + " RETURNS INT\n" + " LOCAL\n" + " WITH SYMBOL = 'myClass'\n" + " ARGUMENTS ( VARCHAR ( MAX ) , BOOLEAN ) ; " ; Assert . assertEquals ( expected , sql ) ; } }
ScalarFunction fn1 = new ScalarFunction ( new FunctionName ( "mydb" , "fn1" ) , new ArrayList < > ( ) , Type . INT , false ) ; fn1 . setBinaryType ( TFunctionBinaryType . JAVA ) ; fn1 . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . jar" ) ) ; fn1 . setSymbolName ( "MyClass" ) ; List < Type > args = Lists . newArrayList ( Type . VARCHAR , Type . BOOLEAN ) ; < |startfocus| > ScalarFunction fn2 = new ScalarFunction ( new FunctionName ( "mydb" , "fn2" ) , args , Type . INT , false ) ; < |endfocus| > fn2 . setBinaryType ( TFunctionBinaryType . NATIVE ) ; fn2 . setLocation ( new HdfsUri ( "hdfs :/ / foo : 123 / fns / myfunc . so" ) ) ; fn2 . setSymbolName ( "myClass" ) ; String sql = ToSqlUtils . getCreateFunctionSql ( Lists . newArrayList ( fn1 , fn2 ) ) ; String expected = "CREATE FUNCTION mydb . fn1\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . jar'\n" + " SYMBOL = 'MyClass' ; \n" + "CREATE FUNCTION mydb . fn2 ( VARCHAR ( * ) , BOOLEAN ) \n" + " RETURNS INT\n" + " LOCATION 'hdfs :/ / foo : 123 / fns / myfunc . so'\n" + " SYMBOL = 'myClass' ; " ;
public RetryRule ( ) { this ( Integer . getInteger ( "rerunFailingTestsCount" , 0 ) ) ;
< |startfocus| > RetryRule ( int retryCount ) { < |endfocus| > this . retryCount = retryCount ;
return new RetryStatement ( base , description , retryCount ) ; } private static class RetryStatement extends Statement { private final Statement base ; private final Description description ; private final int retryCount ; RetryStatement ( Statement base , Description description , int retryCount ) { this . base = base ; this . description = description ; this . retryCount = retryCount ; } @Override public void evaluate ( ) throws Throwable { Throwable lastException ; int attempt = 0 ; do { < |startfocus| > attempt ++ ; < |endfocus| > try { base . evaluate ( ) ; return ; } catch ( Throwable t ) { // To retry , we catch the exception from evaluate ( ) , log an error , and loop . // We retain and rethrow the last failure if all attempts fail . lastException = t ; LOG . error ( " { } : failed attempt { } " , description . getDisplayName ( ) , attempt , t ) ; } } while ( attempt <= retryCount ) ; LOG . error ( " { } : giving up after { } attempts" , description . getDisplayName ( ) , attempt ) ; throw lastException ; } } }
public void testRetry ( ) { if ( failures < MAX_FAILURES ) { failures ++ ; < |startfocus| > assertFalse ( String . format ( " % d failures" , failures ) , true ) ; < |endfocus| > } // Fall through and pass the test on the final retry .
* limitations under the License . */ package com . couchbase . client . core . env ; public enum NetworkResolution { /* * * Pick whatever the server returns in the config , this is the * old and backwards compatible mode ( server default ) . */ DEFAULT , /* * * Based on heuristics discovers if internal or * external resolution will be used . * * This is the default setting ( not to be confused with * the default mode ) ! */ < |startfocus| > BLANK , < |endfocus| > /* * * Pins it to external resolution . */ EXTERNAL }
OpenBucketRequest request ; if ( ClusterDependentTest . minClusterVersion ( ) [ 0 ] >= 5 ) { request = new OpenBucketRequest ( TestProperties . bucket ( ) , TestProperties . adminUser ( ) , TestProperties . adminPassword ( ) ) ; } else { request = new OpenBucketRequest ( TestProperties . bucket ( ) , TestProperties . username ( ) , TestProperties . password ( ) ) ; } core . send ( request ) . toBlocking ( ) . single ( ) ; BackpressureException exception = RingBufferMonitor . instance ( ) . createException ( ) ; < |startfocus| > assertEquals ( 0 , exception . diagostics ( ) . totalCount ( ) ) ; < |endfocus| > core . send ( new CloseBucketRequest ( TestProperties . bucket ( ) ) ) . toBlocking ( ) . single ( ) ; } }
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . couchbase . client . core ; import com . couchbase . client . core . tracing . RingBufferDiagnostics ; /* * * Identifies the need to back off on the supplier side when using a service , because the consumer is overloaded . * * @author Michael Nitschinger * @since 1 . 0 */ < |startfocus| > public class BackpressureException extends CouchbaseException { < |endfocus| > public BackpressureException ( ) { } public BackpressureException ( RingBufferDiagnostics diagnostics ) { this . diagnostics = diagnostics ; } /* * * Returns a { @link RingBufferDiagnostics } which , if non - null , gives a granular breakdown of the contents of the * ringbuffer at the time of this exception */ public RingBufferDiagnostics getRingBufferDiagnostics ( ) { return diagnostics ; } @Override public String toString ( ) { if ( diagnostics != null ) { return super . toString ( ) + " " + diagnostics . toString ( ) ; } else { return super . toString ( ) ; } } private RingBufferDiagnostics diagnostics ; }
< |startfocus| > public RingBufferDiagnostics diagnostics ( ) { < |endfocus| > return diagnostics ;
requestDisruptor . start ( ) ; requestRingBuffer = requestDisruptor . getRingBuffer ( ) ; } @Override @SuppressWarnings ( "unchecked" ) public < R extends CouchbaseResponse > Observable < R > send ( CouchbaseRequest request ) { if ( request instanceof InternalRequest ) { handleInternalRequest ( request ) ; return ( Observable < R > ) request . observable ( ) . observeOn ( environment . scheduler ( ) ) ; } else if ( request instanceof ClusterRequest ) { handleClusterRequest ( request ) ; return ( Observable < R > ) request . observable ( ) . observeOn ( environment . scheduler ( ) ) ; } else { < |startfocus| > RingBufferMonitor monitor = RingBufferMonitor . getInstance ( ) ; monitor . addRequest ( request ) ; < |endfocus| > if ( coreSendHook == null ) { boolean published = requestRingBuffer . tryPublishEvent ( REQUEST_TRANSLATOR , request ) ; if ( ! published ) { request . observable ( ) . onError ( monitor . createException ( ) ) ; } return ( Observable < R > ) request . observable ( ) ; } else { Subject < CouchbaseResponse , CouchbaseResponse > response = request . observable ( ) ; Tuple2 < CouchbaseRequest , Observable < CouchbaseResponse > > hook = coreSendHook . beforeSend ( request , response ) ; boolean published = requestRingBuffer . tryPublishEvent ( REQUEST_TRANSLATOR , hook . value1 ( ) ) ; if ( ! published ) {
< |startfocus| > public static RingBufferMonitor getInstance ( ) { if ( instance == null ) { synchronized ( RingBufferMonitor . class ) { if ( instance == null ) { instance = new RingBufferMonitor ( ) ; } } } return instance ; < |endfocus| >
private AtomicInteger getOrAddCount ( CouchbaseRequest request ) { // instanceof is used instead of a more generic Map - based solution purely to provide lock - free performance < |startfocus| > if ( request instanceof AbstractKeyValueRequest ) { return countKeyValue ; } else if ( request instanceof GenericQueryRequest ) { < |endfocus| > return countQuery ; } else if ( request instanceof ClusterRequest ) { return countCluster ; } else if ( request instanceof ConfigRequest ) { return countConfig ; } else if ( request instanceof InternalRequest ) { return countInternal ; } else if ( request instanceof BinaryRequest ) { return countBinary ; } else if ( request instanceof SearchRequest ) { return countSearch ; } else if ( request instanceof ViewRequest ) { return countView ; } else if ( request instanceof AnalyticsRequest ) { return countAnalytics ; } else { return countOther ; }
*/ private EncryptionConfig encryptionConfig ; /* * * Encryption prefix */ public static final String ENCRYPTION_PREFIX = "__encrypt_" ; /* * * Private constructor to create the object . * * The internal map is initialized with the default capacity . */ private JsonObject ( ) { content = new HashMap < String , Object > ( ) ; < |startfocus| > encryptionPathInfo = new HashMap < String , EncryptionInfo > ( ) ; < |endfocus| > } /* * * Private constructor to create the object with a custom initial capacity . */ private JsonObject ( int initialCapacity ) { content = new HashMap < String , Object > ( initialCapacity ) ; encryptionPathInfo = new HashMap < String , EncryptionInfo > ( ) ; } /* * * Creates a empty { @link JsonObject } . * * @return a empty { @link JsonObject } . */ public static JsonObject empty ( ) { return new JsonObject ( ) ; } /* * * Creates a empty { @link JsonObject } . * * @return a empty { @link JsonObject } . */
sb . append ( " , viewTimeout = " ) . append ( this . viewTimeout ) ; sb . append ( " , searchTimeout = " ) . append ( this . searchTimeout ) ; sb . append ( " , analyticsTimeout = " ) . append ( this . analyticsTimeout ) ; sb . append ( " , kvTimeout = " ) . append ( this . kvTimeout ) ; sb . append ( " , connectTimeout = " ) . append ( this . connectTimeout ) ; sb . append ( " , dnsSrvEnabled = " ) . append ( this . dnsSrvEnabled ) ; if ( this . cryptoManager ( ) != null ) { < |startfocus| > sb . append ( " , cryptoManager = " ) . append ( this . cryptoManager . toString ( ) ) ; < |endfocus| > } return sb ;
* allow to store such objects which can be represented by JSON . * * @author Michael Nitschinger * @author Simon Basl * @since 2 . 0 */ public class JsonObject extends JsonValue implements Serializable { private static final long serialVersionUID = 8817717605659870262L ; /* * * The backing { @link Map } for the object . */ private final Map < String , Object > content ; /* * * Encryption meta information for the Json values */ < |startfocus| > private volatile Map < String , String > encryptionPathInfo ; < |endfocus| > /* * * Configuration for decryption , set using the environment */ private EncryptionConfig encryptionConfig ; /* * * Encryption prefix */ public static final String ENCRYPTION_PREFIX = "__encrypt_" ; /* * * Private constructor to create the object . * * The internal map is initialized with the default capacity . */ private JsonObject ( ) { content = new HashMap < String , Object > ( ) ; encryptionPathInfo = new HashMap < String , String > ( ) ; } /* *
/* * * Decrypt value if the name starts with "__encrypt_" */ private Object decrypt ( JsonObject object , String providerName ) throws Exception { Object decrypted ; String key = object . getString ( "kid" ) ; String alg = object . getString ( "alg" ) ; CryptoProvider provider = this . cryptoManager . getProvider ( providerName ) ; if ( ! provider . checkAlgorithmNameMatch ( alg ) ) { < |startfocus| > throw new CryptoProviderDecryptFailedException ( "The decryption of the field failed for the alias : " + providerName + " ( Crypto provider algorithm name mismatch ) " ) ; < |endfocus| > } if ( ! key . contentEquals ( provider . getKeyStoreProvider ( ) . publicKeyName ( ) ) ) { < |startfocus| > throw new CryptoProviderMissingPublicKeyException ( "The decryption of the field failed for the alias : " + providerName + " ( Public key mismatch ) " ) ; < |endfocus| > } byte [ ] encryptedBytes ; String encryptedValueWithConfig ; if ( object . containsKey ( "iv" ) ) { encryptedValueWithConfig = object . getString ( "kid" ) + object . getString ( "alg" ) + object . getString ( "iv" ) + object . getString ( "ciphertext" ) ;
+ object . getString ( "ciphertext" ) ; encryptedBytes = Base64 . decode ( object . getString ( "ciphertext" ) ) ; } if ( object . containsKey ( "sig" ) ) { byte [ ] signature = Base64 . decode ( object . getString ( "sig" ) ) ; if ( ! provider . verifySignature ( encryptedValueWithConfig . getBytes ( ) , signature ) ) { < |startfocus| > throw new CryptoProviderSigningFailedException ( "The decryption of the field failed for the alias : " + providerName + " ( Signature check for data integrity failed ) " ) ; < |endfocus| > } } byte [ ] decryptedBytes = provider . decrypt ( encryptedBytes ) ; String decryptedString = new String ( decryptedBytes , Charset . forName ( "UTF - 8" ) ) ; decrypted = JacksonTransformers . MAPPER . readValue ( decryptedString , Object . class ) ; if ( decrypted instanceof Map ) { decrypted = JsonObject . from ( ( Map < String , ? > ) decrypted ) ; } else if ( decrypted instanceof List ) { decrypted = JsonArray . from ( ( List < ? > ) decrypted ) ; } return decrypted ; } /* * * Retrieves the ( potential null ) content and not casting its type . * * @param name the key of the field .
public String toString ( ) { return "DefaultPortInfo { " + "ports = " + ports + " , sslPorts = " + sslPorts + " , hostname = '" + hostname + '\'' + ' } ' ;
public Credentials ( String username , String password ) { < |startfocus| > this . username = username ; this . password = password ; < |endfocus| >
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . couchbase . client . dcp ; import java . net . InetSocketAddress ; public interface CredentialsProvider { /* * * Get the username / password pair to use for authentication / authorization * * @param address * @return credentials */ Credentials get ( InetSocketAddress address ) throws RuntimeException ; }
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . couchbase . client . dcp ; import java . net . InetSocketAddress ; public class StaticCredentialsProvider implements CredentialsProvider { private final Credentials credentials ; public StaticCredentialsProvider ( String username , String password ) { credentials = new Credentials ( username , password ) ; } @Override public Credentials get ( InetSocketAddress address ) throws RuntimeException { return credentials ; } }
*/ private SaslClient saslClient ; /* * * Stores the selected SASL mechanism in the process . */ private String selectedMechanism ; /* * * Creates a new auth handler . * * @param address user / bucket name . * @param environment password of the user / bucket . */ < |startfocus| > AuthHandler ( final InetSocketAddress address , final ClientEnvironment environment , final Credentials credentials ) { this . username = credentials . getUsername ( ) ; this . password = credentials . getPassword ( ) ; < |endfocus| > } /* * * Once the channel is active , start the SASL auth negotiation . */ @Override public void channelActive ( final ChannelHandlerContext ctx ) throws Exception { ByteBuf request = ctx . alloc ( ) . buffer ( ) ; SaslListMechsRequest . init ( request ) ; ctx . writeAndFlush ( request ) ; } /* * * Every time we recieve a message as part of the negotiation process , handle * it according to the req / res process . */ @Override protected void channelRead0 ( final ChannelHandlerContext ctx , final ByteBuf msg ) throws Exception {
private String clientContextId ; private Map < String , Object > rawParams ; private boolean pretty ; /* * * We are exposing this as a boolean , but internally the server * wants it as int . To be forwards compatible */ private int priority ; private AnalyticsParams ( ) { pretty = false ; priority = 0 ;
public AnalyticsParams priority ( boolean priority ) { < |startfocus| > return priority ( priority ? - 1 : 0 ) ; < |endfocus| >
public String toString ( ) { return "AnalyticsParams { " + "serverSideTimeout = '" + serverSideTimeout + '\'' + " , clientContextId = '" + clientContextId + '\'' + " , rawParams = " + rawParams + " , pretty = " + pretty + < |startfocus| > " , priority = " + ( priority > 0 ? "true" : "false" ) + < |endfocus| > ' } ' ;
} public static void setOpaque ( int opaque , ByteBuf buffer ) { buffer . setInt ( OPAQUE_OFFSET , opaque ) ; } public static int getOpaque ( ByteBuf buffer ) { return buffer . getInt ( OPAQUE_OFFSET ) ; } public static long getCas ( ByteBuf buffer ) { return buffer . getLong ( CAS_OFFSET ) ; } private static String formatOpcode ( byte opcode ) { < |startfocus| > String name = OPCODE_NAMES [ 0xff & opcode ] ; return String . format ( "0x % 02x ( % s ) " , opcode , name == null ? " ? " : name ) ; < |endfocus| > } private static String formatMagic ( byte magic ) { String name = magic == MAGIC_REQ ? "REQUEST" : ( magic == MAGIC_RES ) ? "RESPONSE" : " ? " ; return String . format ( "0x % 02x ( % s ) " , magic , name ) ; } }
} DcpControl control = environment . dcpControl ( ) ; Credentials credentials = environment . credentialsProvider ( ) . get ( ( InetSocketAddress ) ch . remoteAddress ( ) ) ; pipeline . addLast ( new AuthHandler ( credentials . getUsername ( ) , credentials . getPassword ( ) ) ) . addLast ( new DcpConnectHandler ( environment . connectionNameGenerator ( ) , environment . bucket ( ) , control ) ) . addLast ( new DcpControlHandler ( control ) ) ; if ( control . noopEnabled ( ) ) { pipeline . addLast ( new IdleStateHandler ( 2 * control . noopIntervalSeconds ( ) , 0 , 0 ) ) ; } < |startfocus| > // pipeline . addLast ( new DcpLoggingHandler ( LogLevel . DEBUG ) ) ; < |endfocus| > DcpMessageHandler messageHandler = new DcpMessageHandler ( ch , environment , controlHandler ) ; pipeline . addLast ( messageHandler ) ; if ( environment . persistencePollingEnabled ( ) ) { pipeline . addLast ( new PersistencePollingHandler ( environment , configProvider , messageHandler ) ) ; } } }
public void shouldSerializeEjectionMethod ( ) { BucketSettings settings = DefaultBucketSettings . builder ( ) . ejectionMethod ( EjectionMethod . FULL ) . build ( ) ; DefaultAsyncClusterManager clusterManager = new DefaultAsyncClusterManager ( "login" , "password" , null , null , null ) ; String payload = clusterManager . getConfigureBucketPayload ( settings , false ) ; < |startfocus| > System . err . println ( payload ) ; < |endfocus| > assertTrue ( payload . contains ( "evictionPolicy = fullEviction" ) ) ; }
* distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . couchbase . client . java . error ; import com . couchbase . client . core . CouchbaseException ; /* * * An exception denoting that the search engine couldn't parse an FTS request . * * @author Simon Basl * @since 2 . 3 */ < |startfocus| > public class FtsServerOverloadException extends CouchbaseException { < |endfocus| > public FtsServerOverloadException ( String payload ) { super ( "Search server is overloaded . Details : " + payload ) ; } }
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . couchbase . client . java . error ; import com . couchbase . client . core . CouchbaseException ; /* * * An exception denoting that the search engine couldn't parse an FTS request . * * @author Simon Basl * @since 2 . 3 */ < |startfocus| > public class FtsServerOverloadException extends TemporaryFailureException { < |endfocus| > public FtsServerOverloadException ( String payload ) { super ( "Search server is overloaded . Details : " + payload ) ; } }
return applyTimeout ( core . < SearchQueryResponse > send ( request ) , request , environment , timeout , timeUnit ) ; } } ) . flatMap ( new Func1 < SearchQueryResponse , Observable < SearchQueryResponse > > ( ) { @Override public Observable < SearchQueryResponse > call ( final SearchQueryResponse r ) { if ( shouldRetry ( r . statusCode ( ) ) ) { return Observable . error ( new RetryableException ( r ) ) ; } return Observable . just ( r ) ; } } ) . retryWhen ( RetryBuilder . anyOf ( RetryableException . class ) . max ( 10 ) < |startfocus| > . delay ( Delay . exponential ( TimeUnit . MILLISECONDS , 500 , 2 ) ) < |endfocus| > . doOnRetry ( new Action4 < Integer , Throwable , Long , TimeUnit > ( ) { @Override public void call ( Integer attempt , Throwable error , Long delay , TimeUnit delayUnit ) { LOGGER . debug ( "Retrying { } because of { } ( attempt { } , delay { } { } ) " , query . export ( ) , error . getMessage ( ) , attempt , delay , delayUnit ) ; } } ) . build ( ) ) . map ( new Func1 < SearchQueryResponse , AsyncSearchQueryResult > ( ) { @Override public AsyncSearchQueryResult call ( final SearchQueryResponse response ) {
public N1qlWriter ( N1qlMode mode , boolean createDocuments ) { < |startfocus| > this . mode = mode ; < |endfocus| > this . createDocuments = createDocuments ;
* size is respected . * * @param spans the span list to work off of . * @param span the span to store . */ private void updateSpans ( final List < ThresholdLogSpan > spans , final ThresholdLogSpan span ) { spans . add ( span ) ; // We always need to keep the list properly sorted so that the highest // spans by duration are at the top Collections . sort ( spans , Collections . < ThresholdLogSpan > reverseOrder ( ) ) ; while ( spans . size ( ) > sampleSize ) { // Remove the element with the lowest duration , so we only keep // the highest ones consistently < |startfocus| > spans . remove ( spans . size ( ) - 1 ) ; < |endfocus| > } hasThresholdWritten = true ; } } /* * * This method is intended to be overridden in test implementations * to assert against the output . */ void logOverThreshold ( final List < Map < String , Object > > toLog ) { try { String result = pretty ? prettyWriter ( ) . writeValueAsString ( toLog ) : writer ( ) . writeValueAsString ( toLog ) ;
} @Override public void flush ( ChannelHandlerContext ctx ) throws Exception { ctx . flush ( ) ; } @Override public void exceptionCaught ( ChannelHandlerContext ctx , Throwable cause ) throws Exception { if ( originalPromise != null ) { originalPromise . setFailure ( cause ) ; } ctx . fireExceptionCaught ( cause ) ; } @Override public void userEventTriggered ( ChannelHandlerContext ctx , Object evt ) throws Exception { if ( evt instanceof HandshakeDeadlineEvent ) { < |startfocus| > originalPromise ( ) . tryFailure ( new ConnectTimeoutException ( "Handshake did not complete before deadline . " ) ) ; < |endfocus| > ctx . close ( ) ; return ; } ctx . fireUserEventTriggered ( evt ) ; } @Override public void channelInactive ( ChannelHandlerContext ctx ) throws Exception { originalPromise ( ) . tryFailure ( new ConnectException ( "Channel became inactive before handshake completed . " ) ) ; ctx . fireChannelInactive ( ) ; } }
} @Override protected Tuple2 < ByteBuf , Integer > doEncode ( final JsonDocument document ) throws Exception { addEncryption ( document . content ( ) ) ; return Tuple . create ( jsonObjectToByteBuf ( document . content ( ) ) , TranscoderUtils . JSON_COMPAT_FLAGS ) ; } @Override protected JsonDocument doDecode ( String id , ByteBuf content , long cas , int expiry , int flags , ResponseStatus status ) throws Exception { if ( ! TranscoderUtils . hasJsonFlags ( flags ) ) { throw new TranscodingException ( "Flags ( 0x" + Integer . toHexString ( flags ) + " ) indicate non - JSON document for " + "id " + id + " , could not decode . " ) ; } < |startfocus| > JsonObject jsonObject = byteBufToJsonObject ( content ) ; jsonObject . setEncryptionConfig ( encryptionConfig ) ; return newDocument ( id , expiry , jsonObject , cas ) ; < |endfocus| > } @Override public JsonDocument newDocument ( String id , int expiry , JsonObject content , long cas ) { JsonDocument document = JsonDocument . create ( id , expiry , content , cas ) ; document . content ( ) . setEncryptionConfig ( this . encryptionConfig ) ; return document ; } @Override
public JsonDocument newDocument ( String id , int expiry , JsonObject content , long cas ) { JsonDocument document = JsonDocument . create ( id , expiry , content , cas ) ; < |startfocus| > document . content ( ) . setEncryptionConfig ( this . encryptionConfig ) ; < |endfocus| > return document ; }
JsonDocument doc = JsonDocument . create ( id , data ) ; Observable < JsonDocument > result ; switch ( opts . ingestMethod ) { case INSERT : result = bucket . async ( ) . insert ( doc ) ; break ; case UPSERT : result = bucket . async ( ) . upsert ( doc ) ; break ; case REPLACE : result = bucket . async ( ) . replace ( doc ) ; break ; default : return Observable . error ( new UnsupportedOperationException ( "Unsupported ingest method" ) ) ; } < |startfocus| > result = result . timeout ( kvTimeout , TimeUnit . MILLISECONDS ) ; < |endfocus| > if ( opts . retryBuilder != null ) { result = result . retryWhen ( opts . retryBuilder . build ( ) ) ; } if ( opts . ignoreIngestError ) { result = result . onErrorResumeNext ( Observable . < JsonDocument > empty ( ) ) ; } return result ;
public class Test { public static void main ( String [ ] args ) { System . out . println ( "Hello World ! " ) ; } }
* distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package com . couchbase . client . java . query . dsl . path ; /* * * . * * @author Michael Nitschinger */ public enum SelectType { DEFAULT ( "" ) , ALL ( "ALL" ) , DISTINCT ( "DISTINCT" ) , RAW ( "RAW" ) , < |startfocus| > DISTINCT_RAW ( "DISTINCT RAW" ) ; < |endfocus| > private final String value ; SelectType ( String value ) { this . value = value ; } public String value ( ) { return value ; } }
public void shouldNotAllowReplaceAndUUID ( ) { AnalyticsIngester . ingest ( null , null , < |startfocus| > AnalyticsIngester . IngestOptions . ingestOptions ( ) . ingestMethod ( AnalyticsIngester . IngestMethod . REPLACE ) . uuid ( UUID . randomUUID ( ) ) < |endfocus| > ) ;
package com . couchbase . client . java ; import java . util . Iterator ; import com . couchbase . client . java . analytics . AnalyticsDeferredResultHandle ; import com . couchbase . client . java . analytics . AnalyticsParams ; import com . couchbase . client . java . analytics . AnalyticsQuery ; import com . couchbase . client . java . analytics . AnalyticsQueryResult ; import com . couchbase . client . java . analytics . AnalyticsQueryRow ; /* * * Stand alone test for now as it is experimental */ public class AnalyticsDeferredQueryTest { public static void main ( String . . . args ) throws Exception { < |startfocus| > System . setProperty ( "com . couchbase . analyticsEnabled" , "true" ) ; < |endfocus| > Cluster cluster = CouchbaseCluster . create ( ) ; cluster . authenticate ( "Administrator" , "password" ) ; Bucket bucket = cluster . openBucket ( "default" ) ; AnalyticsQueryResult result = bucket . query ( AnalyticsQuery . simple ( "SELECT 1 = 1 ; " , AnalyticsParams . build ( ) . deferred ( true ) ) ) ; byte [ ] serialized = bucket . exportAnalyticsDeferredResultHandle ( result . handle ( ) ) ; AnalyticsDeferredResultHandle handle = bucket . importAnalyticsDeferredResultHandle ( serialized ) ; while ( ! handle . status ( ) . equalsIgnoreCase ( "success" ) ) { Thread . sleep ( 100 ) ; handle . status ( ) ; } Iterator < AnalyticsQueryRow > it = handle . rows ( ) ;
import com . couchbase . client . core . annotations . InterfaceAudience ; import com . couchbase . client . core . annotations . InterfaceStability ; /* * * An async handle to fetch the status and results of a deferred * Analytics Query * * @author Subhashni Balakrishnan * @since 2 . 7 . 2 */ @InterfaceStability . Experimental @InterfaceAudience . Public public interface AnalyticsDeferredResultHandle { /* * * Get the status uri * * @return uri */ @InterfaceAudience . Private String getStatusHandleUri ( ) ; /* * * Get the result uri if available < |startfocus| > * < |endfocus| > * @return uri */ @InterfaceAudience . Private String getResultHandleUri ( ) ; /* * * @return the list of all { @link AnalyticsQueryRow } , the results of the query , if successful . */ List < AnalyticsQueryRow > allRows ( ) ; /* * * @return an iterator over the list of all { @link AnalyticsQueryRow } , the results of the query , if successful . */ Iterator < AnalyticsQueryRow > rows ( ) ; /* *
"status = '" + status + '\'' + " , finalSuccess = " + finalSuccess + " , parseSuccess = " + parseSuccess + " , allRows = " + allRows + " , signature = " + signature + " , info = " + info + " , errors = " + errors + " , requestId = '" + requestId + '\'' + " , clientContextId = '" + clientContextId + '\'' + < |startfocus| > " , handle = '" + handle + '\'' + < |endfocus| > ' } ' ;
public String getResultHandleUri ( ) { if ( this . resultHandle . length ( ) == 0 ) { < |startfocus| > throw new IllegalStateException ( "There is no result handle available , retry status until success" ) ; < |endfocus| > } return this . resultHandle ;
< |startfocus| > public KeysPath useNestedLoop ( ) { < |endfocus| > element ( new NestedLoopJoinHintElement ( ) ) ; return new DefaultKeysPath ( this ) ;
public String export ( ) { < |startfocus| > StringBuilder sb = new StringBuilder ( ) ; sb . append ( "USE HASH ( " ) ; sb . append ( this . side . getValue ( ) ) ; sb . append ( " ) " ) ; return sb . toString ( ) ; < |endfocus| >
public String export ( ) { < |startfocus| > return "USE HASH ( " + this . side + " ) " ; < |endfocus| >
* See the License for the specific language governing permissions and * limitations under the License . */ package com . couchbase . client . java . query . dsl . path ; import com . couchbase . client . core . annotations . InterfaceAudience ; import com . couchbase . client . core . annotations . InterfaceStability ; /* * * Hash side for hash based join * * @author Subhashni Balakrishnan */ @InterfaceStability . Experimental @InterfaceAudience . Public public enum HashSide { /* * The PROBE side will use that table to find matches and perform the join */ PROBE ( "PROBE" ) , < |startfocus| > /* * The BUILD side of the join will be used to create an in - memory hash table */ < |endfocus| > BUILD ( "BUILD" ) ; private final String value ; HashSide ( String value ) { this . value = value ; } public String getValue ( ) { return this . value ; } }
/* * * Hash side for hash based join * * @author Subhashni Balakrishnan */ @InterfaceStability . Experimental @InterfaceAudience . Public public enum HashSide { /* The PROBE side will use that table to find matches and perform the join */ PROBE ( "PROBE" ) , /* The BUILD side of the join will be used to create an in - memory hash table */ BUILD ( "BUILD" ) ; private final String value ; HashSide ( String value ) { this . value = value ; } < |startfocus| > public String toString ( ) { < |endfocus| > return this . value ; } }
* updated or deleted from the repository . * * @return type of ref . */ @NonNull Storage getStorage ( ) ; /* * * Indicator of the relative order between updates of an specific reference * name . * < p > * A number that increases when a reference is updated . Implementations * define its meaning ( e . g . version counter or timestamp ) . When the * implementation doesn't support versioning , it throws an * { @link UnsupportedOperationException } . * < |startfocus| > * @return the update index of this reference . < |endfocus| > */ default long getUpdateIndex ( ) { throw new UnsupportedOperationException ( ) ; } }
* @return type of ref . */ @NonNull Storage getStorage ( ) ; /* * * Indicator of the relative order between updates of an specific reference * name . * < p > * A number that increases when a reference is updated . Implementations * define its meaning ( e . g . version counter or timestamp ) . When the * implementation doesn't support versioning , it throws an * { @link UnsupportedOperationException } . * * @return the update index of this reference . */ < |startfocus| > default long getUpdateIndex ( ) { < |endfocus| > throw new UnsupportedOperationException ( ) ; } }
public void testUpdateIndexNotImplemented ( ) throws IOException { Ref exactRef = refdir . exactRef ( HEAD ) ; assertNotNull ( exactRef ) ; exactRef . getVersion ( ) ; // Not implemented on FS } @Test public void testUpdateIndexNotImplemented2 ( ) throws Exception { RevCommit C = repo . commit ( ) . parent ( B ) . create ( ) ; repo . update ( "master" , C ) ; List < Ref > refs = refdir . getRefs ( ) ; for ( Ref ref : refs ) { try { ref . getVersion ( ) ; < |startfocus| > fail ( "FS doesn't implement update index" ) ; < |endfocus| > } catch ( UnsupportedOperationException e ) { // ok } } } @Test public void testGetRefs_EmptyDatabase ( ) throws IOException { Map < String , Ref > all ; all = refdir . getRefs ( RefDatabase . ALL ) ; assertTrue ( "no references" , all . isEmpty ( ) ) ; all = refdir . getRefs ( R_HEADS ) ; assertTrue ( "no references" , all . isEmpty ( ) ) ; all = refdir . getRefs ( R_TAGS ) ; assertTrue ( "no references" , all . isEmpty ( ) ) ; } @Test public void testGetRefs_HeadOnOneBranch ( ) throws IOException { Ref head = refdir . exactRef ( HEAD ) ; assertNotNull ( head ) ; assertEquals ( R_HEADS + MASTER , head . getName ( ) ) ; assertEquals ( MASTER , head . getTarget ( ) . getName ( ) ) ; assertEquals ( A , head . getTarget ( ) . getObjectId ( ) ) ; Map < String , Ref > all ; all = refdir . getRefs ( RefDatabase . ALL ) ; assertEquals ( 2 , all . size ( ) ) ; assertEquals ( head , all . get ( HEAD ) ) ; assertEquals ( head . getTarget ( ) , all . get ( MASTER ) ) ; all = refdir . getRefs ( R_HEADS ) ; assertEquals ( 1 , all . size ( ) ) ; assertEquals ( head . getTarget ( ) , all . get ( MASTER ) ) ; all = refdir . getRefs ( R_TAGS ) ; assertTrue ( "no references" , all . isEmpty ( ) ) ; } @Test public void testGetRefs_HeadOnTwoBranches ( ) throws IOException { Ref head = refdir . exactRef ( HEAD ) ; assertNotNull ( head ) ; assertEquals ( R_HEADS + MASTER , head . getName ( ) ) ; assertEquals ( MASTER , head . getTarget ( ) . getName ( ) ) ; assertEquals ( A , head . getTarget ( ) . getObjectId ( ) ) ; Ref master = refdir . exactRef ( MASTER ) ; assertNotNull ( master ) ; assertEquals ( A , master . getObjectId ( ) ) ; Ref branch = refdir . exactRef ( BRANCH ) ; assertNotNull ( branch ) ; assertEquals ( B , branch . getObjectId ( ) ) ; Map < String , Ref > all ; all = refdir . getRefs ( RefDatabase . ALL ) ; assertEquals ( 3 , all . size ( ) ) ; assertEquals ( head , all . get ( HEAD ) ) ; assertEquals ( master , all . get ( MASTER ) ) ; assertEquals ( branch , all . get ( BRANCH ) ) ; all = refdir . getRefs ( R_HEADS ) ; assertEquals ( 2 , all . size ( ) ) ; assertEquals ( master , all . get ( MASTER ) ) ; assertEquals ( branch , all . get ( BRANCH ) ) ; all = refdir . getRefs ( R_TAGS ) ; assertTrue ( "no references" , all . isEmpty ( ) ) ; } @Test public void testGetRefs_HeadOnTwoBranches_OneDeleted ( ) throws IOException { Ref head = refdir . exactRef ( HEAD ) ; assertNotNull ( head ) ; assertEquals ( R_HEADS + MASTER , head . getName ( ) ) ; assertEquals ( MASTER , head . getTarget ( ) . getName ( ) ) ; assertEquals ( A , head . getTarget ( ) . getObjectId ( ) ) ; Ref master = refdir . exactRef ( MASTER ) ; assertNotNull ( master ) ; assertEquals ( A , master . getObjectId ( ) ) ; Ref branch = refdir . exactRef ( BRANCH ) ; assertNotNull ( branch ) ; assertEquals ( B , branch . getObjectId ( ) ) ; refdir . delete ( branch ) ; Map < String , Ref > all ; all = refdir . getRefs ( RefDatabase . ALL ) ; assertEquals ( 2 , all . size ( ) ) ; assertEquals ( head , all . get ( HEAD ) ) ; assertEquals ( master , all . get ( MASTER ) ) ; all = refdir . getRefs ( R_HEADS ) ; assertEquals ( 1 , all . size ( ) ) ; assertEquals ( master , all . get ( MASTER ) ) ; all = refdir . getRefs ( R_TAGS ) ; assertTrue ( "no references" , all . isEmpty ( ) ) ; } @Test public void testGetRefs_HeadOnTwoBranches_OneDeleted_OneRenamed ( ) throws IOException { Ref head = refdir . exactRef ( HEAD ) ; assertNotNull ( head ) ; assertEquals ( R_HEADS + MASTER , head . getName ( ) ) ; assertEquals ( MASTER , head . getTarget ( ) . getName ( ) ) ; assertEquals ( A , head . getTarget ( ) . getObjectId ( ) ) ; Ref master = refdir . exactRef ( MASTER ) ; assertNotNull ( master ) ; assertEquals ( A , master . getObjectId ( ) ) ; Ref branch = refdir . exactRef ( BRANCH ) ; assertNotNull ( branch ) ; assertEquals ( B , branch . getObjectId ( ) ) ; refdir . delete ( branch ) ; refdir . rename ( master , "newbranch" ) ; Map < String , Ref > all ; all = refdir . getRefs ( RefDatabase . ALL ) ; assertEquals ( 2 , all . size ( ) ) ; assertEquals ( head , all . get ( HEAD ) ) ; assertEquals ( master , all . get ( NEWBRANCH ) ) ; all = refdir . getRefs ( R_HEADS ) ; assertEquals ( 1 , all . size ( ) ) ; assertEquals ( master , all . get ( NEWBRANCH ) ) ; all = refdir . getRefs ( R_TAGS ) ; assertTrue ( "no references" , all . isEmpty ( ) ) ; } @Test public void testGetRefs_HeadOnTwoBranches_OneDeleted_OneRenamed_OneRenamedBack ( ) throws IOException { Ref head = refdir . exactRef ( HEAD ) ; assertNotNull ( head ) ; assertEquals ( R_HEADS + MASTER , head . getName ( ) ) ; assertEquals ( MASTER , head . getTarget ( ) . getName ( ) ) ; assertEquals ( A , head . getTarget ( ) . getObjectId ( ) ) ; Ref master = refdir . exactRef ( MASTER ) ; assertNotNull ( master ) ; assertEquals ( A , master . getObjectId ( ) ) ; Ref branch = refdir . exactRef ( BRANCH ) ; assertNotNull ( branch ) ; assertEquals ( B , branch . getObjectId ( ) ) ; refdir . delete ( branch ) ; refdir . rename ( master , "newbranch" ) ; refdir . rename ( master , MASTER ) ; Map < String , Ref > all ; all = refdir . getRefs ( RefDatabase . ALL ) ; assertEquals ( 3 , all . size ( ) ) ; assertEquals ( head , all . get ( HEAD ) ) ; assertEquals ( master , all . get ( MASTER ) ) ; assertEquals ( branch , all . get ( NEWBRANCH ) ) ; all = refdir . getRefs ( R_HEADS ) ; assertEquals ( 2 , all . size ( ) ) ; assertEquals ( master , all . get ( MASTER ) ) ; assertEquals ( branch , all . get ( NEWBRANCH ) ) ; all = refdir . getRefs ( R_TAGS ) ; assertTrue ( "no references" , all . isEmpty ( ) ) ; } @Test public void testGetRefs_HeadOnTwoBranches_OneDeleted_OneRenamed_OneRenamedBack_OneDeleted ( ) throws IOException { Ref head = refdir . exactRef ( HEAD ) ; assertNotNull ( head ) ; assertEquals ( R_HEADS + MASTER , head . getName ( ) ) ; assertEquals ( MASTER , head . get
private TmfFilterHelper ( ) { // nothing to do } /* * * Build an event filter from the regex string in parameter * * @param regexes * The filter regex * @param trace * The trace this filter applies to * @return An event filter */ public static @Nullable ITmfFilter buildFilterFromRegex ( Collection < String > regexes , ITmfTrace trace ) { FilterCu compile = FilterCu . compile ( IFilterStrings . mergeFilters ( regexes ) ) ; < |startfocus| > if ( compile == null ) { < |endfocus| > return null ; } return compile . getEventFilter ( trace ) ; } /* * * Get the regex that corresponds to this filter . The regex should be in the * filter language described in the * { @link org . eclipse . tracecompass . tmf . filter . parser } plugin . And as it may * be used to filter anything , so it may not be the direct string * representing of the original filter . For instance , a ITmfFilter specific * for events will do a smart conversion , so that the parameters of the * filter are the same as the ones in the original filter . * * @param filter * The filter to convert * @return The regex that corresponds to this filter */ public static String getRegexFromFilter ( ITmfFilter filter ) { if ( filter instanceof ITmfFilterWithRegex ) { return ( ( ITmfFilterWithRegex ) filter ) . getRegex ( ) ; } return filter . toString ( ) ; }
* instantiator of the Ref must override this method ( e . g . with the * { @link VersionedRef } decorator ) if it can provide a version value . * * @return the version of this reference . * @throws UnsupportedOperationException * if the creator of the instance ( e . g . { @link RefDatabase } ) * doesn't support versioning and doesn't override this method * @since 5 . 2 */ < |startfocus| > default long getVersion ( ) { < |endfocus| > throw new UnsupportedOperationException ( ) ; }
* ADVISED OF THE POSSIBILITY OF SUCH DAMAGE . */ package org . eclipse . jgit . lib ; /* * * Decorate a reference adding the update index ( version ) property . * * Undecorated Refs throw { @link UnsupportedOperationException } on * { @link #getVersion ( ) } , while decorated instances return the expect value . * < |startfocus| > * The client is responsible to call { @link #getVersion ( ) } only on refs * obtained from { @link RefDatabase } implementations that support versioning * ( e . g . reftables ) < |endfocus| > * * @since 5 . 2 */ public class VersionedRef implements Ref { private Ref ref ; private long updateIndex ; /* * * @param ref * the Reference * @param updateIndex * its update index */ public VersionedRef ( Ref ref , long updateIndex ) { this . ref = ref ; this . updateIndex = updateIndex ; } @Override public String getName ( ) { return ref . getName ( ) ; } @Override public boolean isSymbolic ( ) { return ref . isSymbolic ( ) ; } @Override
} } ; } else { factory = new UMLPropertyEditorFactory ( reference ) ; } EClass type = reference . getEReferenceType ( ) ; factory . setContainerLabelProvider ( new UMLFilteredLabelProvider ( ) ) ; factory . setReferenceLabelProvider ( new EMFLabelProvider ( ) ) ; ITreeContentProvider contentProvider = new UMLContainerContentProvider ( source , reference ) ; ResourceSet rs = source == null ? null : source . eResource ( ) == null ? null : source . eResource ( ) . getResourceSet ( ) ; < |startfocus| > EMFGraphicalContentProvider provider = ProviderHelper . encapsulateProvider ( contentProvider , rs , HistoryUtil . getHistoryID ( source , feature , "container" ) ) ; < |endfocus| > factory . setContainerContentProvider ( provider ) ; factory . setReferenceContentProvider ( new FeatureContentProvider ( type ) ) ; return factory ;
* https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Camille Letavernier ( CEA LIST ) camille . letavernier@cea . fr - Initial API and implementation * Christian W . Damus - bug 485220 * ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . papyrus . uml . tools . databinding ; import org . eclipse . core . databinding . observable . IObservable ; import org . eclipse . emf . edit . domain . EditingDomain ; /* * < |startfocus| > * @deprecated Use the { @link org . eclipse . papyrus . infra . services . edit . ui . databinding . AggregatedPapyrusObservableValue } API , instead . < |endfocus| > * * @since 1 . 2 . 0 */ @Deprecated public class AggregatedPapyrusObservableValue extends org . eclipse . papyrus . infra . services . edit . ui . databinding . AggregatedPapyrusObservableValue { public AggregatedPapyrusObservableValue ( EditingDomain domain , IObservable . . . observableValues ) { super ( domain , observableValues ) ; } }
* which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Camille Letavernier ( CEA LIST ) camille . letavernier@cea . fr - Initial API and implementation * Christian W . Damus - bug 485220 * ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . papyrus . uml . tools . databinding ; /* * < |startfocus| > * @deprecated Use the { @link org . eclipse . papyrus . infra . tools . databinding . CommandBasedObservable } API , instead . < |endfocus| > * * This class Will be removed in Papyrus 5 . 0 , see bug 540829 */ @Deprecated public interface CommandBasedObservable extends org . eclipse . papyrus . infra . tools . databinding . CommandBasedObservable { // Nothing additional }
* which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Camille Letavernier ( CEA LIST ) camille . letavernier@cea . fr - Initial API and implementation * Christian W . Damus - bug 485220 * ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . papyrus . uml . tools . databinding ; /* * < |startfocus| > * @deprecated Use the { @link org . eclipse . papyrus . infra . tools . databinding . CommandBasedObservableValue } API , instead . < |endfocus| > * * This class Will be removed in Papyrus 5 . 0 , see bug 540829 */ @Deprecated public interface CommandBasedObservableValue extends CommandBasedObservable , org . eclipse . papyrus . infra . tools . databinding . CommandBasedObservableValue { // Nothing additional }
import org . eclipse . gmf . runtime . emf . type . core . requests . SetRequest ; import org . eclipse . papyrus . infra . emf . gmf . command . GMFtoEMFCommandWrapper ; import org . eclipse . papyrus . infra . services . edit . service . ElementEditServiceUtils ; import org . eclipse . papyrus . infra . services . edit . service . IElementEditService ; import org . eclipse . papyrus . infra . ui . emf . databinding . EMFObservableList ; /* * * An ObservableList used to edit collections of EObjects through * Papyrus commands * * @author Camille Letavernier < |startfocus| > * @deprecated Use the { @link org . eclipse . papyrus . infra . gmfdiag . common . databinding . GMFObservableList } API , instead < |endfocus| > * * This class Will be removed in Papyrus 5 . 0 , see bug 540829 */ @Deprecated @SuppressWarnings ( "unchecked" ) public class PapyrusObservableList extends EMFObservableList { /* * * * Constructor . * * @param wrappedList * The list to be edited when #commit ( ) is called * @param domain * The editing domain on which the commands will be executed * @param source * The EObject from which the list will be retrieved * @param feature
import org . eclipse . papyrus . infra . services . edit . service . ElementEditServiceUtils ; import org . eclipse . papyrus . infra . services . edit . service . IElementEditService ; import org . eclipse . papyrus . infra . tools . databinding . AggregatedObservable ; import org . eclipse . papyrus . infra . tools . databinding . ReferenceCountedObservable ; import org . eclipse . papyrus . infra . ui . emf . databinding . EMFObservableValue ; import org . eclipse . papyrus . uml . tools . Activator ; /* * * An ObservableValue used to edit EObject properties through * Papyrus commands * * @author Camille Letavernier < |startfocus| > * @deprecated Use the { @link org . eclipse . papyrus . infra . gmfdiag . common . databinding . GMFObservableValue } API , instead < |endfocus| > * * This class Will be removed in Papyrus 5 . 0 , see bug 540829 */ @Deprecated public class PapyrusObservableValue extends EMFObservableValue implements AggregatedObservable , CommandBasedObservableValue , ReferenceCountedObservable { private final ReferenceCountedObservable . Support refCount = new ReferenceCountedObservable . Support ( this ) ; /* * * * Constructor . * * @param eObject * The EObject to edit * @param eStructuralFeature * The structural feature to edit * @param domain * The editing domain on which the commands will be executed * @param commandFactory * The factory used to create the commands * @param commandParameter * The parameter to pass to the command factory */ public PapyrusObservableValue ( EObject eObject , EStructuralFeature eStructuralFeature , EditingDomain domain , CommandFactory commandFactory , Object commandParameter ) { super ( eObject , eStructuralFeature , domain ) ; this . commandFactory = commandFactory ; this . commandParameter = commandParameter ; }
* * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Camille Letavernier ( CEA LIST ) camille . letavernier@cea . fr - Initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . papyrus . uml . tools . providers ; import org . eclipse . jface . viewers . ILabelProvider ; import org . eclipse . papyrus . infra . ui . emf . providers . EMFLabelProvider ; import org . eclipse . papyrus . uml . tools . utils . ProfileUtil ; import org . eclipse . uml2 . uml . Package ; import org . eclipse . uml2 . uml . Profile ; // TODO : To be refactored . Merge this class with UMLLabelProvider < |startfocus| > // should be removed in Papyrus 5 . 0 ( see bug 540821 ) < |endfocus| > @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage ; public static final String TAG_PROFILE_CHANGED = " ( has changed , consider re - applying profile ) " ; public static final String UNKNOWN_PROFILE = " < Unknown > " ; public ProfileLabelProvider ( Package umlPackage ) { this . umlPackage = umlPackage ; } @Override public String getText ( Object source ) { if ( source instanceof Profile ) { Profile profile = ( Profile ) source ; String name = profile . getQualifiedName ( ) ;
* * Contributors : * Camille Letavernier ( CEA LIST ) camille . letavernier@cea . fr - Initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . papyrus . uml . tools . providers ; import org . eclipse . jface . viewers . ILabelProvider ; import org . eclipse . papyrus . infra . ui . emf . providers . EMFLabelProvider ; import org . eclipse . papyrus . uml . tools . utils . ProfileUtil ; import org . eclipse . uml2 . uml . Package ; import org . eclipse . uml2 . uml . Profile ; // TODO : To be refactored . Merge this class with UMLLabelProvider < |startfocus| > // should be removed in Papyrus 5 . 0 ( see bug 540821 ) < |endfocus| > @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage ; public static final String TAG_PROFILE_CHANGED = " ( has changed , consider re - applying profile ) " ; public static final String UNKNOWN_PROFILE = " < Unknown > " ; public ProfileLabelProvider ( Package umlPackage ) { this . umlPackage = umlPackage ; } @Override public String getText ( Object source ) { if ( source instanceof Profile ) { Profile profile = ( Profile ) source ; String name = profile . getQualifiedName ( ) ; if ( name == null ) {
import org . eclipse . jface . viewers . ILabelProvider ; import org . eclipse . papyrus . infra . ui . emf . providers . EMFLabelProvider ; import org . eclipse . papyrus . uml . tools . utils . ProfileUtil ; import org . eclipse . uml2 . uml . Package ; import org . eclipse . uml2 . uml . Profile ; // TODO : To be refactored . Merge this class with UMLLabelProvider // should be removed in Papyrus 5 . 0 ( see bug 540821 ) @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage ; < |startfocus| > public static final String TAG_PROFILE_CHANGED = " ( has changed , consider re - applying profile ) " ; < |endfocus| > public static final String UNKNOWN_PROFILE = " < Unknown > " ; public ProfileLabelProvider ( Package umlPackage ) { this . umlPackage = umlPackage ; } @Override public String getText ( Object source ) { if ( source instanceof Profile ) { Profile profile = ( Profile ) source ; String name = profile . getQualifiedName ( ) ; if ( name == null ) { name = UNKNOWN_PROFILE ; } if ( ProfileUtil . isDirty ( umlPackage , profile ) ) { name += TAG_PROFILE_CHANGED ; } return name ; } return super . getText ( source ) ;
long [ ] stack = new long [ 1 ] ; stack [ 0 ] = 0 ; return new Pair < > ( element , getCallSite ( element , stack , event . getTimestamp ( ) . getValue ( ) ) ) ; } long [ ] stack = new long [ userCs . size ( ) + kernelCs . size ( ) ] ; int i = 0 ; for ( Object call : userCs ) { stack [ i ] = ( long ) call ; i ++ ; } for ( Object call : kernelCs ) { < |startfocus| > stack [ i ] = ( long ) call ; < |endfocus| > i ++ ; } return new Pair < > ( element , getCallSite ( element , stack , event . getTimestamp ( ) . getValue ( ) ) ) ; } /* * * @param event */ private ICallStackElement getElement ( ITmfEvent event ) { // Find a root elements with the same PID Collection < ICallStackElement > rootElements = getRootElements ( ) ; String name = event . getName ( ) ; Optional < ICallStackElement > events = rootElements . stream ( ) . filter ( e - > e . getName ( ) . equals ( String . valueOf ( name ) ) ) . findFirst ( ) ; < |startfocus| >
} long [ ] stack = new long [ userCs . size ( ) + kernelCs . size ( ) ] ; int i = 0 ; for ( Object call : userCs ) { stack [ i ] = ( long ) call ; i ++ ; } for ( Object call : kernelCs ) { stack [ i ] = ( long ) call ; i ++ ; } return new Pair < > ( element , getCallSite ( element , stack , event . getTimestamp ( ) . getValue ( ) ) ) ; } < |startfocus| > /* * * @param event */ < |endfocus| > private ICallStackElement getElement ( ITmfEvent event ) { // Find a root elements with the same PID Collection < ICallStackElement > rootElements = getRootElements ( ) ; String name = event . getName ( ) ; Optional < ICallStackElement > events = rootElements . stream ( ) . filter ( e - > e . getName ( ) . equals ( String . valueOf ( name ) ) ) . findFirst ( ) ; Integer threadId = TmfTraceUtils . resolveIntEventAspectOfClassForEvent ( event . getTrace ( ) , LinuxTidAspect . class , event ) ; int tid = ( threadId == null ) ? - 1 : threadId ;
* The event containing the cpu * * @return the CPU number ( null for not set ) */ public static @Nullable Integer getCpu ( ITmfEvent event ) { Integer cpuObj = TmfTraceUtils . resolveIntEventAspectOfClassForEvent ( event . getTrace ( ) , TmfCpuAspect . class , event ) ; if ( cpuObj == null ) { /* We couldn't find any CPU information , ignore this event */ return null ; } return cpuObj ; } @Override public Map < String , Collection < Object > > getCallStack ( ITmfEvent event ) { < |startfocus| > < |endfocus| > Map < String , Collection < Object > > map = new HashMap < > ( ) ; ITmfEventField content = event . getContent ( ) ; ITmfEventField field = content . getField ( KERNEL_CALLSTACK_FIELD ) ; if ( field != null ) { map . put ( KERNEL_STACK_NAME , getCallstack ( field ) ) ; } field = content . getField ( USER_CALLSTACK_FIELD ) ; if ( field != null ) { map . put ( USER_STACK_NAME , getCallstack ( field ) ) ; } return map ; } private static Collection < Object > getCallstack ( ITmfEventField field ) { Object value = field . getValue ( ) ; if ( value instanceof long [ ] ) { return Arrays . asList ( ( long [ ] ) value ) ; } if ( value instanceof int [ ] ) { return Arrays . asList ( ( int [ ] ) value ) ; } if ( value instanceof short [ ] ) { return Arrays . asList ( ( short [ ] ) value ) ; } if ( value instanceof byte [ ] ) { return Arrays . asList ( ( byte [ ] ) value ) ; } if ( value instanceof char [ ] ) { return Arrays . asList ( ( char [ ] ) value ) ; } if ( value instanceof boolean [ ] ) { return Arrays . asList ( ( boolean [ ] ) value ) ; } if ( value instanceof float [ ] ) { return Arrays . asList ( ( float [ ] ) value ) ; } if ( value instanceof double [ ] ) { return Arrays . asList ( ( double [ ] ) value ) ; } if ( value instanceof Object [ ] ) { return Arrays . asList ( ( Object [ ] ) value ) ; } return Collections . emptyList ( ) ; } }
} long [ ] stack = new long [ userCs . size ( ) + kernelCs . size ( ) ] ; int i = 0 ; for ( Object call : userCs ) { stack [ i ] = ( long ) call ; i ++ ; } for ( Object call : kernelCs ) { stack [ i ] = ( long ) call ; i ++ ; } return new Pair < > ( element , getCallSite ( element , stack , event . getTimestamp ( ) . getValue ( ) ) ) ; } < |startfocus| > /* * * @param event */ < |endfocus| > private ICallStackElement getElement ( ITmfEvent event ) { // Find a root elements with the same PID Collection < ICallStackElement > rootElements = getRootElements ( ) ; String name = event . getName ( ) ; Optional < ICallStackElement > events = rootElements . stream ( ) . filter ( e - > e . getName ( ) . equals ( String . valueOf ( name ) ) ) . findFirst ( ) ; Integer threadId = TmfTraceUtils . resolveIntEventAspectOfClassForEvent ( event . getTrace ( ) , LinuxTidAspect . class , event ) ; int tid = ( threadId == null ) ? - 1 : threadId ;
if ( userCs == null ) { userCs = Collections . emptyList ( ) ; } if ( kernelCs . size ( ) + userCs . size ( ) == 0 ) { long [ ] stack = new long [ 1 ] ; stack [ 0 ] = 0 ; return new Pair < > ( element , getCallSite ( element , stack , event . getTimestamp ( ) . getValue ( ) ) ) ; } long [ ] stack = new long [ userCs . size ( ) + kernelCs . size ( ) ] ; int i = 0 ; for ( Object call : userCs ) { < |startfocus| > stack [ i ] = ( long ) call ; < |endfocus| > i ++ ; } for ( Object call : kernelCs ) { stack [ i ] = ( long ) call ; i ++ ; } return new Pair < > ( element , getCallSite ( element , stack , event . getTimestamp ( ) . getValue ( ) ) ) ; } private ICallStackElement getElement ( ITmfEvent event ) { // Find a root elements with the same PID Collection < ICallStackElement > rootElements = getRootElements ( ) ; String name = event . getName ( ) ; Optional < ICallStackElement > events = rootElements . stream ( ) . filter ( e - > e . getName ( ) . equals ( name ) ) . findFirst ( ) ; if ( events . isPresent ( ) ) { return events . get ( ) ; } ICallStackElement element = new CallStackElement ( name , null , event . getTimestamp ( ) . getValue ( ) ) ; addRootElement ( element ) ; return element ; } private ICallStackElement getCallSite ( ICallStackElement element , long [ ] stack , long timestamp ) { ICallStackElement current = element ; for ( int i = stack . length - 1 ; i >= 0 ; i -- ) { ICallStackElement child = new CallStackElement ( String . valueOf ( stack [ i ] ) , current , timestamp ) ; current . addChild ( child ) ; current = child ; } return current ; } @Override public void handleEvent ( ITmfEvent event ) { if ( ! ( event instanceof CallStackEvent ) ) { return ; } CallStackEvent callStackEvent = ( CallStackEvent ) event ; ICallStackElement element = getElement ( event ) ; List < Object > kernelCs = callStackEvent . getKernelCallStack ( ) ; List < Object > userCs = callStackEvent . getUserCallStack ( ) ;
// sufficient . // @formatter : off Optional < Resource > representationResource = Optional . ofNullable ( resource ) . map ( rsr - > rsr . getResourceSet ( ) ) . filter ( resourceSet - > ! loadOnDemand || resourceSet . getURIConverter ( ) . exists ( repResourceURI , new HashMap < > ( ) ) ) // @formatter : on . map ( resourceSet - > { Resource res = null ; try { res = resourceSet . getResource ( repResourceURI , loadOnDemand ) ; // CHECKSTYLE : OFF < |startfocus| > } catch ( RuntimeException e ) { < |endfocus| > // CHECKSTYLE : ON // an exception may occur if the segment part is malformed or if the resource does not // exists in case the representation is in its own resource . } return res ; } ) ; String repId = uri . get ( ) . fragment ( ) ; if ( representationResource . isPresent ( ) && repId != null ) { // We look for the representation with the repId ( retrieved from // the uri fragment ) within the representation resource . return representationResource . get ( ) . getContents ( ) . stream ( ) . filter ( DRepresentation . class : : isInstance ) . map ( DRepresentation . class : : cast )
/* ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * Copyright ( c ) 2017 , 2018 THALES GLOBAL SERVICES . * All rights reserved . This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1 . 0 * which accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html * * Contributors : * Thales - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . sirius . business . internal . representation ; import java . util . HashMap ; import java . util . Optional ; import org . eclipse . emf . common . util . URI ; import org . eclipse . emf . ecore . resource . Resource ; import org . eclipse . emf . ecore . util . ECrossReferenceAdapter ; import org . eclipse . sirius . business . api . resource . ResourceDescriptor ; import org . eclipse . sirius . viewpoint . DRepresentation ; import org . eclipse . sirius . viewpoint . DRepresentationDescriptor ; /* * * This class is intended to manage the link between the { @link DRepresentationDescriptor } and its * { @link DRepresentation } through the { @link DRepresentationDescriptor#repPath } attribute . * * @author fbarbin * */ public class DRepresentationDescriptorToDRepresentationLinkManager {
} @Test public void testMirrorAcceptAllNonConflictingAction ( ) { // mirrored - > same behavior as not mirrored action testMirrorAllNonConflictingAction ( MergeMode . ACCEPT , DifferenceState . MERGED ) ; } @Test public void testMirrorRejectAllNonConflictingAction ( ) { // mirrored - > same behavior as not mirrored action testMirrorAllNonConflictingAction ( MergeMode . REJECT , DifferenceState . DISCARDED ) ; } private IEMFCompareConfiguration createConfiguration ( boolean leftEditable , boolean rightEditable ) { CompareConfiguration cc = new CompareConfiguration ( ) ; < |startfocus| > cc . setProperty ( EMFCompareConfiguration . MIRRORED , Boolean . TRUE ) ; // $NON - NLS - 1$ < |endfocus| > cc . setLeftEditable ( leftEditable ) ; cc . setRightEditable ( rightEditable ) ; EMFCompareConfiguration emfCC = new EMFCompareConfiguration ( cc ) ; emfCC . setEditingDomain ( editingDomain ) ; return emfCC ; } class MockMergeAction extends MergeAction { public MockMergeAction ( IEMFCompareConfiguration compareConfiguration , Registry mergerRegistry , MergeMode mode , INavigatable navigatable ) { super ( compareConfiguration , mergerRegistry , mode , navigatable ) ; } @Override public boolean updateSelection ( IStructuredSelection selection ) { return super . updateSelection ( selection ) ; } @Override protected void clearCache ( ) { super . clearCache ( ) ; } @Override
public boolean isMirrored ( ) { < |startfocus| > Object property = getProperty ( MIRRORED ) ; < |endfocus| > return property instanceof Boolean && ( ( Boolean ) property ) . booleanValue ( ) ;
public void propertyChange ( PropertyChangeEvent event ) { < |startfocus| > if ( "MIRRORED" . equals ( event . getProperty ( ) ) ) { // $NON - NLS - 1$ < |endfocus| > Object newValue = event . getNewValue ( ) ; mirroredPropertyChanged ( Boolean . TRUE . equals ( newValue ) ) ; } }
private String getCurrentValueFromViewer ( MergeViewerSide side ) { < |startfocus| > boolean isLeft = MergeViewerSide . LEFT == side ; if ( getCompareConfiguration . isMirrored ( ) ) { isLeft = MergeViewerSide . RIGHT == side ; } < |endfocus| > final GetContentRunnable runnable = new GetContentRunnable ( isLeft ) ; Display . getDefault ( ) . syncExec ( runnable ) ; return ( String ) runnable . getResult ( ) ;
} @Test public void testMirrorAcceptAllNonConflictingAction ( ) { // mirrored - > same behavior as not mirrored action testMirrorAllNonConflictingAction ( MergeMode . ACCEPT , DifferenceState . MERGED ) ; } @Test public void testMirrorRejectAllNonConflictingAction ( ) { // mirrored - > same behavior as not mirrored action testMirrorAllNonConflictingAction ( MergeMode . REJECT , DifferenceState . DISCARDED ) ; } private IEMFCompareConfiguration createConfiguration ( boolean leftEditable , boolean rightEditable ) { CompareConfiguration cc = new CompareConfiguration ( ) ; < |startfocus| > cc . setProperty ( EMFCompareConfiguration . MIRRORED , Boolean . TRUE ) ; // $NON - NLS - 1$ < |endfocus| > cc . setLeftEditable ( leftEditable ) ; cc . setRightEditable ( rightEditable ) ; EMFCompareConfiguration emfCC = new EMFCompareConfiguration ( cc ) ; emfCC . setEditingDomain ( editingDomain ) ; return emfCC ; } class MockMergeAction extends MergeAction { public MockMergeAction ( IEMFCompareConfiguration compareConfiguration , Registry mergerRegistry , MergeMode mode , INavigatable navigatable ) { super ( compareConfiguration , mergerRegistry , mode , navigatable ) ; } @Override public boolean updateSelection ( IStructuredSelection selection ) { return super . updateSelection ( selection ) ; } @Override protected void clearCache ( ) { super . clearCache ( ) ; } @Override
try { int length = string . length ( ) ; if ( length == 0 ) return ; boolean mode = true ; switch ( data . textAntialias ) { case SWT . DEFAULT : /* Printer is off by default */ if ( ! handle . isDrawingToScreen ( ) ) mode = false ; break ; case SWT . OFF : mode = false ; break ; case SWT . ON : mode = true ; break ; } handle . saveGraphicsState ( ) ; handle . setShouldAntialias ( mode ) ; < |startfocus| > if ( length == 1 && ( flags & SWT . DRAW_TRANSPARENT ) != 0 ) { < |endfocus| > doFastDrawText ( string , x , y ) ; } else { doDrawText ( string , x , y , flags ) ; } handle . restoreGraphicsState ( ) ; } finally { uncheckGC ( pool ) ; }
} } @Override public void close ( ) { try { ch . close ( ) ; } catch ( IOException e ) { // Ignore read close failures . } } private static final class LazyReadableChannel implements ReadableChannel { private final DfsReader ctx ; private final DfsReftable file ; private ReadableChannel ch ; LazyReadableChannel ( DfsReftable file , DfsReader ctx ) { this . file = file ; this . ctx = ctx ; } < |startfocus| > private ReadableChannel getChannel ( ) throws IOException { < |endfocus| > if ( ch == null ) { ch = ctx . db . openFile ( file . desc , file . ext ) ; } return ch ; } @Override public int blockSize ( ) { try { return getChannel ( ) . blockSize ( ) ; } catch ( IOException e ) { return - 1 ; } } @Override public long position ( ) throws IOException { return getChannel ( ) . position ( ) ; } @Override public void position ( long newPosition ) throws IOException { getChannel ( ) . position ( newPosition ) ; } @Override public void setReadAheadBytes ( int bufferSize ) throws IOException {
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * * Copyright ( c ) 2016 Frank Becker and others . * * This program and the accompanying materials are made available under the * terms of the Eclipse Public License v . 2 . 0 which is available at < |startfocus| > * https :/ / www . eclipse . org / legal / epl - 2 . 0 < |endfocus| > * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Frank Becker - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . mylyn . bugzilla . rest . core . tests ; import java . util . List ; import org . eclipse . mylyn . commons . sdk . util . CommonTestUtil ; import org . eclipse . mylyn . commons . sdk . util . ManagedSuite ; import org . eclipse . mylyn . commons . sdk . util . ManagedSuite . SuiteClassProvider ; import org . eclipse . mylyn . commons . sdk . util . ManagedSuite . TestConfigurationProperty ; import org . eclipse . mylyn . commons . sdk . util . TestConfiguration ; import org . junit . runner . RunWith ; import org . junit . runners . Suite ; @RunWith ( ManagedSuite . class ) @Suite . SuiteClasses ( { RepositoryKeyTest . class , BugzillaRestFlagMapperTest . class , BugzillaRestConnectorNoFixtureTest . class } ) @TestConfigurationProperty ( ) public class AllBugzillaRestCoreTests { static { if ( CommonTestUtil . fixProxyConfiguration ( ) ) {
assertTrue ( new File ( d , "logs / refs / heads" ) . isDirectory ( ) ) ; assertFalse ( new File ( d , "logs / HEAD" ) . exists ( ) ) ; assertEquals ( 0 , new File ( d , "logs / refs / heads" ) . list ( ) . length ) ; assertEquals ( "ref : refs / heads / master\n" , read ( new File ( d , HEAD ) ) ) ; } @Test ( expected = UnsupportedOperationException . class ) public void testVersioningNotImplemented_exactRef ( ) throws IOException { assertFalse ( refdir . hasVersioning ( ) ) ; < |startfocus| > Ref exactRef = refdir . exactRef ( HEAD ) ; assertNotNull ( exactRef ) ; exactRef . getUpdateIndex ( ) ; // Not implemented on FS < |endfocus| > } @Test public void testVersioningNotImplemented_getRefs ( ) throws Exception { assertFalse ( refdir . hasVersioning ( ) ) ; RevCommit C = repo . commit ( ) . parent ( B ) . create ( ) ; repo . update ( "master" , C ) ; List < Ref > refs = refdir . getRefs ( ) ; for ( Ref ref : refs ) { try { ref . getUpdateIndex ( ) ; fail ( "FS doesn't implement ref versioning" ) ; } catch ( UnsupportedOperationException e ) { // ok } } } @Test public void testVersioningNotImplemented_getRefs_optional ( ) throws Exception { assertFalse ( refdir . hasVersioning ( ) ) ; RevCommit C = repo . commit ( ) . parent ( B ) . create ( ) ; repo . update ( "master" , C ) ; List < Ref > refs = refdir . getRefs ( ) ; for ( Ref ref : refs ) { < |startfocus| > Optional < Ref > refOptional = refdir . getRef ( ref . getName ( ) ) ; assertTrue ( refOptional . isPresent ( ) ) ; Ref ref2 = refOptional . get ( ) ; assertEquals ( ref . getName ( ) , ref2 . getName ( ) ) ; assertEquals ( ref . getObjectId ( ) , ref2 . getObjectId ( ) ) ; assertEquals ( ref . getStorage ( ) , ref2 . getStorage ( ) ) ; assertEquals ( ref . getTarget ( ) , ref2 . getTarget ( ) ) ; assertEquals ( ref . getUpdateIndex ( ) , ref2 . getUpdateIndex ( ) ) ; < |endfocus| > } } @Test
public void testVersioningNotImplemented_exactRef ( ) throws IOException { assertFalse ( refdir . hasVersioning ( ) ) ; Ref exactRef = refdir . exactRef ( HEAD ) ; assertNotNull ( exactRef ) ; exactRef . getUpdateIndex ( ) ; // Not implemented on FS } @Test public void testVersioningNotImplemented_getRefs ( ) throws Exception { assertFalse ( refdir . hasVersioning ( ) ) ; RevCommit C = repo . commit ( ) . parent ( B ) . create ( ) ; repo . update ( "master" , C ) ; List < Ref > refs = refdir . getRefs ( ) ; < |startfocus| > for ( Ref ref : refs ) { < |endfocus| > try { ref . getUpdateIndex ( ) ; fail ( "FS doesn't implement ref versioning" ) ; } catch ( UnsupportedOperationException e ) { // ok } } } @Test public void testGetRefs_EmptyDatabase ( ) throws IOException { Map < String , Ref > all ; all = refdir . getRefs ( RefDatabase . ALL ) ; assertTrue ( "no references" , all . isEmpty ( ) ) ; all = refdir . getRefs ( R_HEADS ) ; assertTrue ( "no references" , all . isEmpty ( ) ) ; all = refdir . getRefs ( R_TAGS ) ; assertTrue ( "no references" , all . isEmpty ( ) ) ; }
return ref ; } Ref dst = ref . getTarget ( ) ; if ( MAX_SYMBOLIC_REF_DEPTH <= depth ) { return null ; // claim it doesn't exist } dst = exactRef ( dst . getName ( ) ) ; if ( dst == null ) { return ref ; } dst = resolve ( dst , depth + 1 ) ; if ( dst == null ) { return null ; // claim it doesn't exist } < |startfocus| > return new VersionedRef ( new SymbolicRef ( ref . getName ( ) , dst ) , ref . getUpdateIndex ( ) ) ; < |endfocus| > } /* * { @inheritDoc } */ @Override public abstract void close ( ) throws IOException ; } < |startfocus| > /* * * Resolve the given reference to a versioned reference . * * @param ref * the reference to resolve . * @return the versioned reference , or null if the reference does not exist . */ private Ref resolve ( Ref ref , int depth ) { if ( ref instanceof VersionedRef ) { return ref ; } Ref dst = ref . getTarget ( ) ; if ( MAX_SYMBOLIC_REF_DEPTH <= depth ) { return null ; // claim it doesn't exist } dst = exactRef ( dst . getName ( ) ) ; if ( dst == null ) { return ref ; } dst = resolve ( dst , depth + 1 ) ; if ( dst == null ) { return null ; // claim it doesn't exist } return new VersionedRef ( new SymbolicRef ( ref . getName ( ) , dst ) , ref . getUpdateIndex ( ) ) ; } /* * { @inheritDoc } */ @Override public abstract void close ( ) throws IOException ; } < |endfocus| >
} /* * * Get namespace used by bootstrap layer . * * @return namespace used by bootstrap layer , e . g . { @code refs / txn / } . Always * ends in { @code ' / ' } . */ @Nullable public String getTxnNamespace ( ) { return txnNamespace ; } /* * { @inheritDoc } */ @Override public void create ( ) throws IOException { bootstrap . create ( ) ; } /* * { @inheritDoc } */ @Override < |startfocus| > public boolean hasVersioning ( ) { return false ; } /* * { @inheritDoc } */ @Override < |endfocus| > public boolean performsAtomicTransactions ( ) { return true ; } /* * { @inheritDoc } */ @Override public void refresh ( ) { bootstrap . refresh ( ) ; } /* * { @inheritDoc } */ @Override public void close ( ) { refs = null ; bootstrap . close ( ) ; } /* * { @inheritDoc } */ @Override public Ref getRef ( String name ) throws IOException { String [ ] needle = new String [ SEARCH_PATH . length ] ; < |startfocus| >
* LOSS OF USE , DATA , OR PROFITS ; OR BUSINESS INTERRUPTION ) HOWEVER * CAUSED AND ON ANY THEORY OF LIABILITY , WHETHER IN CONTRACT , * STRICT LIABILITY , OR TORT ( INCLUDING NEGLIGENCE OR OTHERWISE ) * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE , EVEN IF * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE . */ package org . eclipse . jgit . lib ; import org . eclipse . jgit . annotations . NonNull ; import org . eclipse . jgit . annotations . Nullable ; < |startfocus| > import org . eclipse . jgit . lib . internal . VersionedRef ; < |endfocus| > /* * * Pairing of a name and the { @link org . eclipse . jgit . lib . ObjectId } it currently * has . * < p > * A ref in Git is ( more or less ) a variable that holds a single object * identifier . The object identifier can be any valid Git object ( blob , tree , * commit , annotated tag , . . . ) . * < p > * The ref name has the attributes of the ref that was asked for as well as the * ref it was resolved to for symbolic refs plus the object id it points to and
/* * * Indicator of the relative order between updates of a specific reference * name . * < p > * A number that increases when a reference is updated . Implementations * define its value ( e . g . version counter or timestamp ) . * < p > * By default this throws an { @link UnsupportedOperationException } . The < |startfocus| > * instantiator of the Ref must override this method ( e . g . by using the * { @link VersionedRef } decorator ) if it can provide a version value . < |endfocus| > * * @return the version of this reference . * @throws UnsupportedOperationException * if the creator of the instance ( e . g . { @link RefDatabase } ) * doesn't support versioning and doesn't override this method * @since 5 . 3 */ default long getUpdateIndex ( ) { throw new UnsupportedOperationException ( ) ; } }
/* * * Initialize a new reference database at this location . * * @throws java . io . IOException * the database could not be created . */ public abstract void create ( ) throws IOException ; /* * * Close any resources held by this database . */ public abstract void close ( ) ; /* * * With versioning , each reference has a version number that increases on * update . * < |startfocus| > * @return true when the implementation assigns sequencer numbers to < |endfocus| > * references . * @since 5 . 3 */ public abstract boolean hasVersioning ( ) ; /* * * Determine if a proposed reference name overlaps with an existing one . * < p > * Reference names use ' / ' as a component separator , and may be stored in a * hierarchical storage such as a directory on the local filesystem . * < p > * If the reference "refs / heads / foo" exists then "refs / heads / foo / bar" must
/* * * Initialize a new reference database at this location . * * @throws java . io . IOException * the database could not be created . */ public abstract void create ( ) throws IOException ; /* * * Close any resources held by this database . */ public abstract void close ( ) ; /* * * With versioning , each reference has a version number that increases on * update . * < |startfocus| > * @return true whether the implementation assigns version numbers to < |endfocus| > * references . * @since 5 . 3 */ public abstract boolean hasVersioning ( ) ; /* * * Determine if a proposed reference name overlaps with an existing one . * < p > * Reference names use ' / ' as a component separator , and may be stored in a * hierarchical storage such as a directory on the local filesystem . * < p > * If the reference "refs / heads / foo" exists then "refs / heads / foo / bar" must
return false ; } else if ( ! block . next ( ) ) { long pos = block . endPosition ( ) ; if ( pos >= scanEnd ) { return false ; } block = readBlock ( pos , scanEnd ) ; continue ; } block . parseKey ( ) ; if ( match != null && ! block . match ( match , prefix ) ) { block . skipValue ( ) ; return false ; } < |startfocus| > ref = block . readRef ( minUpdateIndex + block . readUpdateIndexDelta ( ) ) ; < |endfocus| > if ( ! includeDeletes && wasDeleted ( ) ) { continue ; } return true ; } } @Override public Ref getRef ( ) { return ref ; } @Override public void close ( ) { // Do nothing . } } private class LogCursorImpl extends LogCursor { private final long scanEnd ; private final byte [ ] match ; private String refName ; private long updateIndex ; private ReflogEntry entry ; BlockReader block ; LogCursorImpl ( long scanEnd , byte [ ] match ) { this . scanEnd = scanEnd ; this . match = match ;
} else if ( ! block . next ( ) ) { long pos ; if ( blockPos != null ) { if ( listIdx >= blockPos . size ( ) ) { return false ; } pos = blockPos . get ( listIdx ++ ) ; } else { pos = block . endPosition ( ) ; } if ( pos >= scanEnd ) { return false ; } block = readBlock ( pos , scanEnd ) ; continue ; } block . parseKey ( ) ; < |startfocus| > long updateIndex = minUpdateIndex + block . readUpdateIndexDelta ( ) ; ref = block . readRef ( updateIndex ) ; < |endfocus| > ObjectId id = ref . getObjectId ( ) ; if ( id != null && match . equals ( id ) && ( includeDeletes || ! wasDeleted ( ) ) ) { return true ; } } } @Override public Ref getRef ( ) { return ref ; } @Override public void close ( ) { // Do nothing . } } }
* name . A number that increases when a reference is updated . * * In case of symbolic references , the update index refers to the update of * the symbolic reference iself ( e . g . if HEAD points to master , the HEAD * update index will only increase when HEAD changes , regarless how many * times master is updated ) . * < |startfocus| > * The update index and its meaning are usually provided by the * { @code RefDatabase } that instantiates the ref . By default this method * throws an { @link UnsupportedOperationException } . Implementors must * overrride it to return a useful value . < |endfocus| > * * @return the update index ( i . e . version ) of this reference . * @throws UnsupportedOperationException * if the creator of the instance ( e . g . { @link RefDatabase } ) * doesn't support versioning and doesn't override this method * @since 5 . 3 */ default long getUpdateIndex ( ) { throw new UnsupportedOperationException ( ) ; } }
protected Object createElementViewerInput ( ) { List < TracePackageTraceElement > traceElements = new ArrayList < > ( ) ; for ( TmfTraceElement tmfTraceElement : fSelectedTraces ) { TracePackageTraceElement traceElement = new TracePackageTraceElement ( null , tmfTraceElement ) ; // Trace files < |startfocus| > List < TracePackageElement > children = new ArrayList < > ( ) ; < |endfocus| > TracePackageFilesElement filesElement = new TracePackageFilesElement ( traceElement , tmfTraceElement . getResource ( ) ) ; filesElement . setChecked ( true ) ; children . add ( filesElement ) ; // Supplementary files try { String supplementaryFolder = tmfTraceElement . getResource ( ) . getPersistentProperty ( TmfCommonConstants . TRACE_SUPPLEMENTARY_FOLDER ) ; IResource [ ] supplementaryResources = tmfTraceElement . getSupplementaryResources ( ) ; TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement ( traceElement ) ; children . add ( suppFilesElement ) ; if ( supplementaryResources . length > 0 ) { IFolder propertiesFolder = ( ( IFolder ) supplementaryResources [ 0 ] . getParent ( ) ) . getFolder ( TmfCommonConstants . TRACE_PROPERTIES_FOLDER ) ; for ( IResource res : propertiesFolder . members ( ) ) {
filesElement . setChecked ( true ) ; children . add ( filesElement ) ; // Supplementary files try { String supplementaryFolder = tmfTraceElement . getResource ( ) . getPersistentProperty ( TmfCommonConstants . TRACE_SUPPLEMENTARY_FOLDER ) ; IResource [ ] supplementaryResources = tmfTraceElement . getSupplementaryResources ( ) ; List < TracePackageElement > suppFilesChildren = new ArrayList < > ( ) ; TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement ( traceElement ) ; children . add ( suppFilesElement ) ; if ( supplementaryResources . length > 0 ) { IFolder propertiesFolder = ( ( IFolder ) supplementaryResources [ 0 ] . getParent ( ) ) . getFolder ( TmfCommonConstants . TRACE_PROPERTIES_FOLDER ) ; for ( IResource res : propertiesFolder . members ( ) ) { < |startfocus| > String name = supplementaryFolder == null ? res . getName ( ) : res . getLocation ( ) . makeRelativeTo ( new Path ( supplementaryFolder ) ) . toString ( ) ; suppFilesChildren . add ( new TracePackageSupplFileElement ( res , name , suppFilesElement ) ) ; } } for ( IResource res : supplementaryResources ) { String name = supplementaryFolder == null ? res . getName ( ) : res . getLocation ( ) . makeRelativeTo ( new Path ( supplementaryFolder ) ) . toString ( ) ; < |endfocus| >
// Supplementary files try { String supplementaryFolder = tmfTraceElement . getResource ( ) . getPersistentProperty ( TmfCommonConstants . TRACE_SUPPLEMENTARY_FOLDER ) ; IResource [ ] supplementaryResources = tmfTraceElement . getSupplementaryResources ( ) ; List < TracePackageElement > suppFilesChildren = new ArrayList < > ( ) ; TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement ( traceElement ) ; children . add ( suppFilesElement ) ; if ( supplementaryResources . length > 0 ) { IFolder propertiesFolder = ( ( IFolder ) supplementaryResources [ 0 ] . getParent ( ) ) . getFolder ( TmfCommonConstants . TRACE_PROPERTIES_FOLDER ) ; for ( IResource res : propertiesFolder . members ( ) ) { String name = supplementaryFolder == null ? res . getName ( ) : res . getLocation ( ) . makeRelativeTo ( new Path ( supplementaryFolder ) ) . toString ( ) ; suppFilesChildren . add ( new TracePackageSupplFileElement ( res , name , suppFilesElement ) ) ; } } for ( IResource res : supplementaryResources ) { String name = supplementaryFolder == null ? res . getName ( ) : res . getLocation ( ) . makeRelativeTo ( new Path ( supplementaryFolder ) ) . toString ( ) ; suppFilesChildren . add ( new TracePackageSupplFileElement ( res , name , suppFilesElement ) ) ; }
try { String supplementaryFolder = tmfTraceElement . getResource ( ) . getPersistentProperty ( TmfCommonConstants . TRACE_SUPPLEMENTARY_FOLDER ) ; IResource [ ] supplementaryResources = tmfTraceElement . getSupplementaryResources ( ) ; List < TracePackageElement > suppFilesChildren = new ArrayList < > ( ) ; TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement ( traceElement ) ; children . add ( suppFilesElement ) ; if ( supplementaryResources . length > 0 ) { IFolder propertiesFolder = ( ( IFolder ) supplementaryResources [ 0 ] . getParent ( ) ) . getFolder ( TmfCommonConstants . TRACE_PROPERTIES_FOLDER ) ; if ( propertiesFolder . exists ( ) ) { for ( IResource res : propertiesFolder . members ( ) ) { < |startfocus| > String name = supplementaryFolder == null ? res . getName ( ) : res . getLocation ( ) . makeRelativeTo ( new Path ( supplementaryFolder ) ) . toString ( ) ; suppFilesChildren . add ( new TracePackageSupplFileElement ( res , name , suppFilesElement ) ) ; < |endfocus| > } } } for ( IResource res : supplementaryResources ) { String name = supplementaryFolder == null ? res . getName ( ) : res . getLocation ( ) . makeRelativeTo ( new Path ( supplementaryFolder ) ) . toString ( ) ; suppFilesChildren . add ( new TracePackageSupplFileElement ( res , name , suppFilesElement ) ) ; } } catch ( CoreException e ) {
TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement ( traceElement ) ; children . add ( suppFilesElement ) ; if ( supplementaryResources . length > 0 ) { IFolder propertiesFolder = ( ( IFolder ) supplementaryResources [ 0 ] . getParent ( ) ) . getFolder ( TmfCommonConstants . TRACE_PROPERTIES_FOLDER ) ; for ( IResource res : propertiesFolder . members ( ) ) { String name = supplementaryFolder == null ? res . getName ( ) : res . getLocation ( ) . makeRelativeTo ( new Path ( supplementaryFolder ) ) . toString ( ) ; suppFilesChildren . add ( new TracePackageSupplFileElement ( res , name , suppFilesElement ) ) ; < |startfocus| > } < |endfocus| > } for ( IResource res : supplementaryResources ) { String name = supplementaryFolder == null ? res . getName ( ) : res . getLocation ( ) . makeRelativeTo ( new Path ( supplementaryFolder ) ) . toString ( ) ; suppFilesChildren . add ( new TracePackageSupplFileElement ( res , name , suppFilesElement ) ) ; } } catch ( CoreException e ) { // Should not happen Activator . getDefault ( ) . logError ( "Error finding supplementary files" , e ) ; // $NON - NLS - 1$ } // Bookmarks IFile bookmarksFile = tmfTraceElement . getBookmarksFile ( ) ;
import java . io . ByteArrayOutputStream ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Arrays ; import java . util . Collection ; import java . util . Collections ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; import org . eclipse . jgit . internal . storage . io . BlockSource ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . ObjectIdRef ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . RefComparator ; import org . eclipse . jgit . lib . SymbolicRef ; import org . junit . Test ; public class MergedReftableTest { < |startfocus| > < |endfocus| > @Test public void noTables ( ) throws IOException { MergedReftable mr = merge ( new byte [ 0 ] [ ] ) ; try ( RefCursor rc = mr . allRefs ( ) ) { assertFalse ( rc . next ( ) ) ; } try ( RefCursor rc = mr . seekRef ( HEAD ) ) { assertFalse ( rc . next ( ) ) ; } try ( RefCursor rc = mr . seekRefsWithPrefix ( R_HEADS ) ) { assertFalse ( rc . next ( ) ) ; } } @Test public void oneEmptyTable ( ) throws IOException { MergedReftable mr = merge ( write ( ) ) ;
/* * * Initialize a new reference database at this location . * * @throws java . io . IOException * the database could not be created . */ public abstract void create ( ) throws IOException ; /* * * Close any resources held by this database . */ public abstract void close ( ) ; /* * * With versioning , each reference has a version number that increases on * update . < |startfocus| > * * @return true if the implementation assigns update indices to * references . < |endfocus| > * @since 5 . 3 */ public abstract boolean hasVersioning ( ) ; /* * * Determine if a proposed reference name overlaps with an existing one . * < p > * Reference names use ' / ' as a component separator , and may be stored in a * hierarchical storage such as a directory on the local filesystem . * < p > * If the reference "refs / heads / foo" exists then "refs / heads / foo / bar" must
* * @throws java . io . IOException * the database could not be created . */ public abstract void create ( ) throws IOException ; /* * * Close any resources held by this database . */ public abstract void close ( ) ; /* * * With versioning , each reference has a version number that increases on * update . * * @return true whether the implementation assigns update indices to * references . * @since 5 . 3 */ < |startfocus| > public boolean hasVersioning ( ) { return false ; } < |endfocus| > /* * * Determine if a proposed reference name overlaps with an existing one . * < p > * Reference names use ' / ' as a component separator , and may be stored in a * hierarchical storage such as a directory on the local filesystem . * < p > * If the reference "refs / heads / foo" exists then "refs / heads / foo / bar" must * not exist , as a reference cannot have a value and also be a container for * other references at the same time .
* * With symbolic references , the update index refers to updates of the * symbolic reference itself . For example , if HEAD points to * refs / heads / master , then the update index for exactRef ( "HEAD" ) will only * increase when HEAD changes to point to another ref , regardless of how * many times refs / heads / master is updated . * * Should not be used unless the { @code RefDatabase } that instantiated the < |startfocus| > * ref supports versioning ( see { @link RefDatabase#hasVersioning ( ) } < |endfocus| > * * @return the update index ( i . e . version ) of this reference . * @throws UnsupportedOperationException * if the creator of the instance ( e . g . { @link RefDatabase } ) * doesn't support versioning and doesn't override this method * @since 5 . 3 */ default long getUpdateIndex ( ) { throw new UnsupportedOperationException ( ) ; } }
*/ boolean isPeeled ( ) ; /* * * How was this ref obtained ? * < p > * The current storage model of a Ref may influence how the ref must be * updated or deleted from the repository . * * @return type of ref . */ @NonNull Storage getStorage ( ) ; /* * * Indicator of the relative order between updates of a specific reference * name . A number that increases when a reference is updated . < |startfocus| > * < |endfocus| > * With symbolic references , the update index refers to updates of the * symbolic reference itself . For example , if HEAD points to * refs / heads / master , then the update index for exactRef ( "HEAD" ) will only * increase when HEAD changes to point to another ref , regardless of how * many times refs / heads / master is updated . * * Should not be used unless the { @code RefDatabase } that instantiated the * ref supports versioning ( see { @link RefDatabase#hasVersioning ( ) } ) * < p >
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * < |startfocus| > * Copyright ( c ) 2009 , 2018 THALES GLOBAL SERVICES and others . < |endfocus| > * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Obeo - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . sirius . ui . tools . internal . actions . export ; import java . util . Collection ; import java . util . Iterator ; import java . util . LinkedHashSet ; import java . util . Set ; import java . util . stream . Collectors ; import org . eclipse . emf . ecore . EObject ; import org . eclipse . sirius . business . api . dialect . DialectManager ; import org . eclipse . sirius . business . api . query . DRepresentationDescriptorQuery ; import org . eclipse . sirius . business . api . session . Session ; import org . eclipse . sirius . ui . business . api . dialect . DialectUIManager ; import org . eclipse . sirius . ui . business . api . dialect . ExportFormat ; import org . eclipse . sirius . ui . business . api . dialect . ExportFormat . ExportDocumentFormat ; import org . eclipse . sirius . viewpoint . DRepresentationDescriptor ; import org . eclipse . sirius . viewpoint . provider . Messages ;
public void run ( ) { Collection < DRepresentationDescriptor > repDescriptorsToExport = getRepresentationToExport ( ) . stream ( ) . filter ( Objects : : nonNull ) . collect ( Collectors . toList ( ) ) ; < |startfocus| > // keep only the representations < |endfocus| > repDescriptorsToExport = repDescriptorsToExport . stream ( ) . filter ( repDesc - > repDesc . getRepresentation ( ) != null ) . collect ( Collectors . toList ( ) ) ; if ( ! repDescriptorsToExport . isEmpty ( ) ) { DRepresentationDescriptor firstDRepDescriptorToExport = repDescriptorsToExport . iterator ( ) . next ( ) ; // Make sure the representation is loaded firstDRepDescriptorToExport . getRepresentation ( ) ; Session session = getSession ( firstDRepDescriptorToExport ) ; if ( session != null ) { IPath exportPath = getExportPath ( firstDRepDescriptorToExport , session ) ; if ( exportPath != null ) { exportRepresentation ( exportPath , repDescriptorsToExport , session ) ; } } } else { MessageDialog . openInformation ( Display . getCurrent ( ) . getActiveShell ( ) , Messages . ExportRepresentationsAction_noRepresentationsDialog_title , Messages . ExportRepresentationsAction_noRepresentationsDialog_message ) ; }
* * @param name * the name of the reference . May be a short name which must be * searched for using the standard { @link #SEARCH_PATH } . * @return the reference ( if it exists ) ; else { @code null } . * @throws IOException * the reference space cannot be accessed . * @deprecated Use { @link #findRef ( String ) } instead . */ @Deprecated @Nullable < |startfocus| > public Ref getRef ( String name ) throws IOException { return findRef ( name ) ; } < |endfocus| > /* * * Read a single reference . * < p > * Aside from taking advantage of { @link #SEARCH_PATH } , this method may be * able to more quickly resolve a single reference name than obtaining the * complete namespace by { @code getRefs ( ALL ) . get ( name ) } . * < p > * To read a specific reference without using @ { link #SEARCH_PATH } , see * { @link #exactRef ( String ) } . * * @param name * the name of the reference . May be a short name which must be
public static FirstCommand fromLine ( String line ) { int nul = line . indexOf ( '\0' ) ; if ( nul < 0 ) { return new FirstCommand ( line , emptySet ( ) ) ; } Set < String > opts = asList ( line . substring ( nul + 1 ) . split ( " " ) ) // $NON - NLS - 1$ . stream ( ) . collect ( toSet ( ) ) ; < |startfocus| > return new FirstCommand ( line . substring ( 0 , nul ) , Collections . unmodifiableSet ( opts ) ) ; < |endfocus| >
protected IResource getResource ( IPath path ) { if ( path != null ) { IWorkspaceRoot root = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) ; IFile file = root . getFileForLocation ( path ) ; if ( file != null ) { return file ; } if ( ! "jar" . equalsIgnoreCase ( path . getFileExtension ( ) ) ) { // $NON - NLS - 1$ IContainer container = root . getContainerForLocation ( path ) ; if ( container != null ) { return container ; } } < |startfocus| > if ( path . getDevice ( ) == null ) { // search relative to the workspace if no device present return root . findMember ( path ) ; } < |endfocus| > } return null ;
protected IResource getResource ( IPath path ) { if ( path != null ) { IWorkspaceRoot root = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) ; if ( path . getDevice ( ) == null ) { // search relative to the workspace if no device present return root . findMember ( path ) ; } IFile file = root . getFileForLocation ( path ) ; if ( file != null ) { return file ; } < |startfocus| > if ( ! "jar" . equalsIgnoreCase ( path . getFileExtension ( ) ) ) { // $NON - NLS - 1$ < |endfocus| > IContainer container = root . getContainerForLocation ( path ) ; if ( container != null ) { return container ; } } else { return null ; } } return null ;
IWorkspaceRoot root = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) ; // look for files or folders with the given path IFile file = root . getFileForLocation ( path ) ; if ( file != null ) { return file ; } if ( getType ( ) != ARCHIVE ) { IContainer container = root . getContainerForLocation ( path ) ; if ( container != null ) { return container ; } } if ( path . getDevice ( ) == null ) { // search relative to the workspace if no device present return root . findMember ( path ) ; } return null ;
} } static int read ( ReadableChannel rc , ByteBuffer buf ) throws IOException { int n ; do { n = rc . read ( buf ) ; } while ( 0 < n && buf . hasRemaining ( ) ) ; return buf . position ( ) ; } static long elapsedMicros ( long start ) { return ( System . nanoTime ( ) - start ) / 1000L ; } /* * * A supplier of readable channel that opens the channel lazily . */ < |startfocus| > private static class LazyChannel implements AutoCloseable , DfsBlockCache . ReadableChannelSupplier { final DfsReader ctx ; ReadableChannel rc = null ; < |endfocus| > LazyChannel ( DfsReader ctx ) { this . ctx = ctx ; } @Override public ReadableChannel get ( ) throws IOException { if ( rc == null ) { synchronized ( this ) { if ( rc == null ) { rc = ctx . db . openFile ( desc , ext ) ; } } } return rc ; } @Override public void close ( ) throws IOException { if ( rc != null ) { rc . close ( ) ; } } } }
import org . eclipse . osgi . util . NLS ; final public class ChecksumVerifier extends MessageDigestProcessingStep { private String expectedChecksum ; final private String algorithmName ; final private String algorithmId ; // public to access from tests public ChecksumVerifier ( String digestAlgorithm , String algorithmId ) { this . algorithmName = digestAlgorithm ; this . algorithmId = algorithmId ; basicInitialize ( null ) ; } @Override public final void initialize ( IProvisioningAgent agent , IProcessingStepDescriptor descriptor , IArtifactDescriptor context ) { super . initialize ( agent , descriptor , context ) ; < |startfocus| > basicInitialize ( descriptor ) ; < |endfocus| > String data = descriptor . getData ( ) ; if ( IArtifactDescriptor . DOWNLOAD_CHECKSUM . concat ( " . " ) . concat ( algorithmId ) . equals ( data ) ) // $NON - NLS - 1$ expectedChecksum = ChecksumHelper . getChecksums ( context , IArtifactDescriptor . DOWNLOAD_CHECKSUM ) . get ( algorithmId ) ; else if ( IArtifactDescriptor . ARTIFACT_CHECKSUM . concat ( " . " ) . concat ( algorithmId ) . equals ( data ) ) // $NON - NLS - 1$ expectedChecksum = ChecksumHelper . getChecksums ( context , IArtifactDescriptor . ARTIFACT_CHECKSUM ) . get ( algorithmId ) ; else expectedChecksum = data ; if ( ofNullable ( expectedChecksum ) . orElse ( "" ) . isEmpty ( ) ) { // $NON - NLS - 1$ return ; } } @Override public IStatus initializeFrom ( Map < String , String > parameters ) { IStatus status = super . initializeFrom ( parameters ) ; if ( status . getSeverity ( ) != IStatus . OK ) return status ;
private static String selectionToString ( Table table ) { < |startfocus| > StringBuilder builder = new StringBuilder ( ) ; < |endfocus| > for ( TableItem tableItem : table . getSelection ( ) ) { if ( builder . length ( ) > 0 ) { builder . append ( System . lineSeparator ( ) ) ; } for ( int column = 0 ; column < table . getColumnCount ( ) ; column ++ ) { if ( column > 0 ) { builder . append ( '\t' ) ; } builder . append ( tableItem . getText ( column ) ) ; } } return builder . toString ( ) ;
sessionId . toAPI ( ) , userId . toAPI ( ) ) ; authorizationService . checkProjectAdminAccess ( sessionId . toAPI ( ) , null , ESProjectAdminPrivileges . DeleteOrgUnit ) ; ACUser userToDelete = null ; for ( final Iterator < ACUser > iter = getUsers ( ) . iterator ( ) ; iter . hasNext ( ) ; ) { final ACUser user = iter . next ( ) ; /* check if we were created by the deleted user */ if ( user . getCreatedBy ( ) != null && user . getCreatedBy ( ) . equals ( userId . getId ( ) ) ) { user . setCreatedBy ( null ) ; } /* check if we are the deleted user */ if ( user . getId ( ) . equals ( userId ) ) { userToDelete = user ; } } for ( final ACGroup group : getGroups ( ) ) { if ( group . getCreatedBy ( ) != null && group . getCreatedBy ( ) . equals ( userId . getId ( ) ) ) { group . setCreatedBy ( null ) ; } } /* perform deletion */ if ( userToDelete != null ) { final List < ACGroup > groups = getGroups ( sessionId , userId ) ;
if ( user . getCreatedBy ( ) != null && user . getCreatedBy ( ) . equals ( userId . getId ( ) ) ) { user . setCreatedBy ( null ) ; save ( ) ; } /* check if we are the deleted user */ if ( user . getId ( ) . equals ( userId ) ) { userToDelete = user ; } } for ( final ACGroup group : getGroups ( ) ) { if ( group . getCreatedBy ( ) != null && group . getCreatedBy ( ) . equals ( userId . getId ( ) ) ) { group . setCreatedBy ( null ) ; < |startfocus| > save ( ) ; < |endfocus| > } } /* perform deletion */ if ( userToDelete != null ) { final List < ACGroup > groups = getGroups ( sessionId , userId ) ; for ( final ACGroup acGroup : groups ) { removeMember ( sessionId , acGroup . getId ( ) , userId ) ; } getAccessControl ( ) . getOrgUnitProviderService ( ) . removeUser ( userToDelete . toAPI ( ) ) ; // TODO : move ecore delete into ServerSpace#deleteUser implementation EcoreUtil . delete ( userToDelete ) ; save ( ) ; } } /* * * { @inheritDoc } */
/* act */ adminBroker2 . deleteUser ( createdUser1 . getId ( ) ) ; /* assert */ assertEquals ( initialSize - 1 , adminBroker . getUsers ( ) . size ( ) ) ; assertNull ( findUser ( USER_NAME_2 ) . getCreatedBy ( ) ) ; } private ACUser findUser ( String name ) throws ESException { ACUser result = null ; for ( final ACUser user : adminBroker . getUsers ( ) ) { if ( user . getName ( ) . equals ( name ) ) { < |startfocus| > result = user ; break ; < |endfocus| > } } return result ; } private ACGroup findGroup ( String name ) throws ESException { ACGroup result = null ; for ( final ACGroup group : adminBroker . getGroups ( ) ) { if ( group . getName ( ) . equals ( name ) ) { result = group ; } } return result ; } @Test ( expected = AccessControlException . class ) public void testLoginOfCreatedUserWithNoPasswordSet ( ) throws ESException { adminBroker . createUser ( USER_NAME ) ; ACUser user = null ; for ( final ACUser u : adminBroker . getUsers ( ) ) { if ( u . getName ( ) . equals ( USER_NAME ) ) { user = u ; } }
throw new StorageException ( StorageException . NOSAVE , e ) ; } } private void checkForNulls ( Object . . . objects ) throws InvalidInputException { for ( final Object obj : objects ) { if ( obj == null ) { throw new InvalidInputException ( ) ; } } } private < T extends ACOrgUnit < ? > > List < T > removeInvisibleOrgUnits ( List < T > orgUnits , ESSessionId sessionId ) throws AccessControlException { /* < |startfocus| > * regular users can't see any orgunits , while server admins can see all of them . Only server admins have < |endfocus| > * reduced visibility . */ final ESOrgUnitId adminId = getAccessControl ( ) . getSessions ( ) . resolveToOrgUnitId ( sessionId ) ; final Optional < ACOrgUnit < ? > > orgUnit = ACHelper . getOrgUnit ( getAccessControl ( ) . getOrgUnitProviderService ( ) , adminId ) ; if ( ! orgUnit . isPresent ( ) ) { return orgUnits ; } final List < Role > allRolesOfAdmin = ACHelper . getAllRoles ( getAccessControl ( ) . getOrgUnitResolverServive ( ) , orgUnit . get ( ) ) ; if ( Iterables . any ( allRolesOfAdmin , new HasRolePredicate ( ServerAdmin . class ) ) ) { return orgUnits ; }
package org . eclipse . emf . emfstore . server . accesscontrol . test ; import static org . eclipse . emf . emfstore . client . test . common . util . ProjectUtil . share ; import static org . junit . Assert . assertEquals ; import static org . junit . Assert . assertTrue ; import static org . junit . Assert . fail ; import java . util . Arrays ; import java . util . LinkedHashSet ; import java . util . List ; import java . util . Set ; import org . eclipse . emf . emfstore . client . ESUsersession ; import org . eclipse . emf . emfstore . client . test . common . dsl . Roles ; import org . eclipse . emf . emfstore . client . test . common . util . ServerUtil ; import org . eclipse . emf . emfstore . internal . server . model . accesscontrol . ACGroup ; import org . eclipse . emf . emfstore . internal . server . model . accesscontrol . ACOrgUnit ; import org . eclipse . emf . emfstore . internal . server . model . accesscontrol . ACUser ; import org . eclipse . emf . emfstore . internal . server . model . accesscontrol . roles . RolesPackage ; import org . eclipse . emf . emfstore . server . exceptions . ESException ; import org . eclipse . emf . emfstore . server . model . ESProject ; import org . eclipse . emf . emfstore . server . model . accesscontrol . ACOrgUnitId ; import org . eclipse . emf . emfstore . server . model . accesscontrol . roles . Role ; import org . eclipse . emf . emfstore . server . model . accesscontrol . roles . RoleAssignment ; import org . eclipse . emf . emfstore . server . model . accesscontrol . roles . RoleId ; import org . eclipse . emf . emfstore . server . model . accesscontrol . roles . RolePackage ; import org . eclipse . emf . emfstore . server . model . accesscontrol . roles . ServerAdmin ; import org . eclipse . emf . emfstore . server . model . accesscontrol . roles . Writer ; import org . eclipse . emf . emfstore . server . model . url . ModelElementUrlFragment ; import org . eclipse . emf . emfstore . server . model . url . ModelElementUrlFragment . ModelElementUrlFragmentFactory ; import org . eclipse . emf . emfstore . server . model . url . ProjectUrlFragment ; import org . eclipse . emf . emfstore . server . model . url . ServerUrl ; import org . eclipse . emf . emfstore . server . model . url . UrlFactory ; import org . junit . After ; import org . junit . Before ; import org . junit . Test ; public class RoleAssignmentTest extends AbstractRolesTest { 	private ESProject project ; 	private ACOrgUnitId userId ; 	private ACOrgUnitId groupId ; 	private ACOrgUnitId projectId ; 	private ACOrgUnitId serverAdminId ; 	private ACOrgUnitId writerId ; 	@Before 	public void before ( ) throws ESException { 		project = createProject ( "project" ) ; 		userId = createUser ( "user" ) . getId ( ) ; 		groupId = createGroup ( "group" ) . getId ( ) ; 		projectId = project . getACUser ( ) . getId ( ) ; 		serverAdminId = getServerAdmin ( ) . getId ( ) ; 		writerId = getWriter ( ) . getId ( ) ; 	 } 	@After 	public void after ( ) throws ESException { 		deleteProject ( project ) ; 		deleteUser ( userId ) ; 		deleteGroup ( groupId ) ; 	 } 	@Test 	public void testRoleAssignment ( ) throws ESException { 		final RoleAssignment roleAssignment = getRoleAssignment ( userId , projectId , Roles . WRITER ) ; 		assertEquals ( userId , roleAssignment . getOrgUnitId ( ) ) ; 		assertEquals ( projectId , roleAssignment . getProjectId ( ) ) ; 		assertEquals ( Roles . WRITER , roleAssignment . getRole ( ) ) ; 	 } 	@Test 	public void testRoleAssignmentWithGroup ( ) throws ESException { 		final RoleAssignment roleAssignment = getRoleAssignment ( groupId , projectId , Roles . WRITER ) ; 		assertEquals ( groupId , roleAssignment . getOrgUnitId ( ) ) ; 		assertEquals ( projectId , roleAssignment . getProjectId ( ) ) ; 		assertEquals ( Roles . WRITER , roleAssignment . getRole ( ) ) ; 	 } 	@Test 	public void testRoleAssignmentWithProject ( ) throws ESException { 		final RoleAssignment roleAssignment = getRoleAssignment ( projectId , projectId , Roles . WRITER ) ; 		assertEquals ( projectId , roleAssignment . getOrgUnitId ( ) ) ; 		assertEquals ( projectId , roleAssignment . getProjectId ( ) ) ; 		assertEquals ( Roles . WRITER , roleAssignment . getRole ( ) ) ; 	 } 	@Test 	public void testRoleAssignmentWithServerAdmin ( ) throws ESException { 		final RoleAssignment roleAssignment = getRoleAssignment ( serverAdminId , projectId , Roles . WRITER ) ; 		assertEquals ( serverAdminId , roleAssignment . getOrgUnitId ( ) ) ; 		assertEquals ( projectId , roleAssignment . getProjectId ( ) ) ; 		assertEquals ( Roles . WRITER , roleAssignment . getRole ( ) ) ; 	 } 	@Test 	public void testRoleAssignmentWithWriter ( ) throws ESException { 		final RoleAssignment roleAssignment = getRoleAssignment ( writerId , projectId , Roles . WRITER ) ; 		assertEquals ( writerId , roleAssignment . getOrgUnitId ( ) ) ; 		assertEquals ( projectId , roleAssignment . getProjectId ( ) ) ; 		assertEquals ( Roles . WRITER , roleAssignment . getRole ( ) ) ; 	 } }
getAdminBroker ( ) . addMember ( group , otherGroup ) ; getAdminBroker ( ) . addMember ( otherGroup , newUser ) ; ProjectUtil . share ( getUsersession ( ) , getLocalProject ( ) ) ; final ProjectSpace clonedProjectSpace = cloneProjectSpace ( getProjectSpace ( ) ) ; ProjectUtil . share ( getSuperUsersession ( ) , clonedProjectSpace . toAPI ( ) ) ; < |startfocus| > getAdminBroker ( ) . changeRole ( getProjectSpace ( ) . getProjectId ( ) , group , Roles . writer ( ) ) ; getAdminBroker ( ) . changeRole ( getProjectSpace ( ) . getProjectId ( ) , otherGroup , Roles . writer ( ) ) ; final int oldSize = getAdminBroker ( ) . getGroups ( ) . size ( ) ; < |endfocus| > getAdminBroker ( ) . deleteGroup ( group ) ; assertEquals ( oldSize - 1 , getAdminBroker ( ) . getGroups ( ) . size ( ) ) ; } /* * * @throws ESException */ @Test public void deleteUser ( ) throws ESException { makeUserPA ( ) ; final ACOrgUnitId newUser = ServerUtil . createUser ( getSuperUsersession ( ) , getNewUsername ( ) ) ; final ACOrgUnitId group = ServerUtil . createGroup ( getSuperUsersession ( ) , getNewGroupName ( ) ) ; final ACOrgUnitId otherGroup = ServerUtil . createGroup ( getSuperUsersession ( ) , getNewOtherGroupName ( ) ) ; getAdminBroker ( ) . addMember ( group , otherGroup ) ; getAdminBroker ( ) . addMember ( otherGroup , newUser ) ; ProjectUtil . share ( getUsersession ( ) , getLocalProject ( ) ) ; final ProjectSpace clonedProjectSpace = cloneProjectSpace ( getProjectSpace ( ) ) ; ProjectUtil . share ( getSuperUsersession ( ) , clonedProjectSpace . toAPI ( ) ) ; < |startfocus| > getAdminBroker ( ) . changeRole ( getProjectSpace ( ) . getProjectId ( ) , group , Roles . writer ( ) ) ; getAdminBroker ( ) . changeRole ( getProjectSpace ( ) . getProjectId ( ) , otherGroup , Roles . writer ( ) ) ; final int oldSize = getAdminBroker ( ) . getGroups ( ) . size ( ) ; < |endfocus| > getAdminBroker ( ) . deleteGroup ( group ) ; assertEquals ( oldSize - 1 , getAdminBroker ( ) . getGroups ( ) . size ( ) ) ; } /* * * @throws ESException */ @Test public void deleteUser ( ) throws ESException { makeUserPA ( ) ; final ACOrgUnitId newUser = ServerUtil . createUser ( getSuperUsersession ( ) , getNewUsername ( ) ) ; final ACOrgUnitId group = ServerUtil . createGroup ( getSuperUsersession ( ) , getNewGroupName ( ) ) ; final ACOrgUnitId otherGroup = ServerUtil . createGroup ( getSuperUsersession ( ) , getNewOtherGroupName ( ) ) ;
import org . junit . runners . Parameterized . Parameters ; import org . mockito . ArgumentCaptor ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; @RunWith ( ParameterizedPlatformTestRunner . class ) public class JmsMomImplementorTest { private static final Logger LOG = LoggerFactory . getLogger ( JmsMomImplementorTest . class ) ; @ClassRule public static final ArtemisJmsBrokerTestRule ARTEMIS_RULE = new ArtemisJmsBrokerTestRule ( ) ; private IBean < ? extends JmsTestMom > m_momBean ; private IBean < ? extends IJmsMessageHandler > m_messageHandlerBean ; private List < IDisposable > m_disposables ; private String m_testJobExecutionHint ; @Rule public TestName m_testName = new TestName ( ) ; public long m_t0 ; private static final AtomicInteger MOM_COUNTER = new AtomicInteger ( 0 ) ; @Parameters public static List < IScoutTestParameter > getParameters ( ) { List < IScoutTestParameter > parametersList = new LinkedList < IScoutTestParameter > ( ) ; // We do not need jmx for unit testing . Also we must disable watchTopicAdvisories else some concurrent issues with broker recreation will happen
try { Jobs . getJobManager ( ) . awaitDone ( testJobsFilter , 10 , TimeUnit . SECONDS ) ; LOG . info ( "All jobs have finished after { } ms" , StringUtility . formatNanos ( System . nanoTime ( ) - t0 ) ) ; } catch ( TimedOutError e ) { LOG . warn ( "Some cancelled jobs are still running after { } ms ! Please check their implementation . " , StringUtility . formatNanos ( System . nanoTime ( ) - t0 ) ) ; } } < |startfocus| > uninstallTestMessagehandler ( ) ; < |endfocus| > uninstallTestMom ( ) ; // ensure activeMQ is stopped BrokerService brokerService = BrokerRegistry . getInstance ( ) . findFirst ( ) ; if ( brokerService != null ) { brokerService . stop ( ) ; brokerService . waitUntilStopped ( ) ; } LOG . info ( "Finished test in { } ms" , StringUtility . formatNanos ( System . nanoTime ( ) - m_t0 ) ) ; LOG . info ( " </ { } > " , m_testName . getMethodName ( ) ) ; } @Test @NonParameterized public void testInstanceScoped ( ) { JmsMomImplementor mom1 = BEANS . get ( JmsMomImplementor . class ) ;
} } ) ) ; // Initiate 'request - reply' communication final String request = "hello world" ; String testee = MOM . request ( JmsTestMom . class , queue , request ) ; // Verify final String expectedReply = "HELLO WORLD" ; assertEquals ( expectedReply , testee ) ; IMarshaller marshaller = BEANS . get ( CONFIG . getPropertyValue ( DefaultMarshallerProperty . class ) ) ; verifyRequestReplyMessageLogger ( queue , marshaller , request , expectedReply ) ; } < |startfocus| > private static < DTO > void verifyRequestReplyMessageLogger ( IDestination < DTO > expectedDestination , IMarshaller marshaller , DTO expectedRequest , DTO expectedReply ) { < |endfocus| > verify ( BEANS . get ( IJmsMessageHandler . class ) , times ( 2 ) ) . handleOutgoing ( any ( ) , any ( ) , any ( ) ) ; verifyMessageLoggerHandleOutgoingCalled ( expectedDestination , marshaller , expectedRequest ) ; verifyMessageLoggerHandleOutgoingCalled ( null , marshaller , expectedReply ) ; // "reply" message is sent only with JMS destination ( but without a Scout MOM destination ) verify ( BEANS . get ( IJmsMessageHandler . class ) , times ( 2 ) ) . handleIncoming ( eq ( expectedDestination ) , any ( ) , any ( ) ) ; verifyMessageLoggerHandleIncomingCalled ( expectedDestination , marshaller , expectedRequest , expectedReply ) ; } < |startfocus| > private static < DTO > void verifyMessageLoggerHandleOutgoingCalled ( IDestination < DTO > expectedDestination , IMarshaller marshaller , DTO expectedDto ) { < |endfocus| > ArgumentCaptor < IDestination < DTO > > destinationCaptor = ArgumentCaptor . forClass ( IDestination . class ) ; ArgumentCaptor < DTO > dtoCaptor = ArgumentCaptor . forClass ( expectedDto . getClass ( ) ) ; verify ( BEANS . get ( IJmsMessageHandler . class ) ) . handleOutgoing ( destinationCaptor . capture ( ) , dtoCaptor . capture ( ) , any ( ) ) ; assertEquals ( expectedDestination , destinationCaptor . getValue ( ) ) ; assertEquals ( expectedDto , dtoCaptor . getValue ( ) ) ; } < |startfocus| > private static < DTO > void verifyMessageLoggerHandleIncomingCalled ( IDestination < DTO > expectedDestination , IMarshaller marshaller , DTO expectedRequest , DTO expectedReply ) { < |endfocus| > ArgumentCaptor < IDestination < DTO > > destinationCaptor = ArgumentCaptor . forClass ( IDestination . class ) ; ArgumentCaptor < DTO > dtoCaptor = ArgumentCaptor . forClass ( expectedRequest . getClass ( ) ) ; verify ( BEANS . get ( IJmsMessageHandler . class ) , times ( 2 ) ) . handleIncoming ( destinationCaptor . capture ( ) , dtoCaptor . capture ( ) , any ( ) ) ; assertEquals ( expectedDestination , destinationCaptor . getAllValues ( ) . get ( 0 ) ) ; assertEquals ( expectedRequest , dtoCaptor . getAllValues ( ) . get ( 0 ) ) ; assertEquals ( expectedReply , dtoCaptor . getAllValues ( ) . get ( 1 ) ) ; }
* @param properties * the MOM environment properties provided to the JMS implementor * @see org . eclipse . scout . rt . mom . api . IMomImplementor . init ( Map < Object , Object > ) */ void init ( Map < Object , Object > properties ) ; /* * * Handles JMS messages consumed by a { @link javax . jms . MessageConsumer } . * < p > * This method is called directly after a JMS message has been received . * < p > < |startfocus| > * The message has not yet been processed ( unmarshalled ) by the MOM framework . < |endfocus| > */ void handleIncoming ( IDestination < ? > destination , Message message , IMarshaller marshaller ) ; /* * * Handles JMS messages being sent by a { @link javax . jms . MessageProducer } . * < p > * This method is called directly before a JMS message is "sent" by the < i > MessageProducer </ i > . "Sent" means that the * < i > send </ i > method of the message producer is called . Therefore it is not guaranteed that the time , at which this
* < p > * This method is called directly before a JMS message is "sent" by the < i > MessageProducer </ i > . "Sent" means that the * < i > send </ i > method of the message producer is called . Therefore it is not guaranteed that the time , at which this * method is called , is the < i > sent time </ i > of the JMS message ( e . g . in a transactional context ) . * < p > < |startfocus| > * The message has already been processed ( marshalled ) by the MOM framework . < |endfocus| > * * @param destination * the MOM destination this message is being sent to . < b > Attention : </ b > This might be < code > null </ code > in * case of a 'request - reply' communication , where the reply message is only sent back through the JMS * destination defined by { @link Message#getJMSReplyTo ( ) } ( and not through a MOM destination ) */ void handleOutgoing ( IDestination < ? > destination , Message message , IMarshaller marshaller ) ; }
* @return the writer's { @link IMarshaller } used to transform the transfer object . < |endfocus| > */ public IMarshaller getMarshaller ( ) { return m_marshaller ; } /* * * Writes the given transfer object , and uses the writer's { @link IMarshaller } to transform the object into its * transport type . * * @see JmsMessageReader#readTransferObject ( ) */ public JmsMessageWriter writeTransferObject ( final Object transferObject ) throws JMSException { final Object transportObject = m_marshaller . marshall ( transferObject , m_marshallerContext ) ; m_marshallerContext . put ( CTX_PROP_NULL_OBJECT , Boolean . valueOf ( transferObject == null ) . toString ( ) ) ;
* Writes the given { @link Map } as message properties . * * @see JmsMessageReader#readContext ( String ) */ protected JmsMessageWriter writeContext ( final String property , final Map < String , String > context ) throws JMSException { if ( context . isEmpty ( ) ) { return this ; } final String json = ( String ) BEANS . get ( JsonMarshaller . class ) . marshall ( context , new HashMap < > ( ) ) ; writeProperty ( property , json ) ; return this ; } /* * * Finish writing and get the message . * < p > * If the message is a { @link javax . jms . BytesMessage } , its message body is put in read - only mode and repositions the * stream of bytes to the beginning . * * @return the JMS message in read - only mode * @see BytesMessage#reset ( ) */ public Message build ( ) throws JMSException { writeContext ( JMS_PROP_MARSHALLER_CONTEXT , m_marshallerContext ) ; if ( m_message instanceof BytesMessage ) { ( ( BytesMessage ) m_message ) . reset ( ) ; } return m_message ; } /* *
} /* * * @return the identifier to name the { @link Connection } . */ protected String computeClientId ( final Map < Object , Object > properties ) { final String clientId = ObjectUtility . toString ( properties . get ( JMS_CLIENT_ID ) ) ; if ( clientId != null ) { return clientId ; } final String nodeId = BEANS . get ( NodeIdentifier . class ) . get ( ) ; return StringUtility . join ( " " , m_symbolicName , StringUtility . box ( " ( " , nodeId , " ) " ) ) ; } < |startfocus| > < |endfocus| > public IJmsMessageHandler getMessageHandler ( ) { return m_messageHandler ; } /* * * Exception Handler used in MOM . */ public static class MomExceptionHandler extends ExceptionHandler { } }
public class BundleWriterTest extends SampleDataRepositoryTestCase { @Rule public ExpectedException thrown = ExpectedException . none ( ) ; @Test public void testEmptyBundleFails ( ) throws Exception { Repository newRepo = createBareRepository ( ) ; thrown . expect ( TransportException . class ) ; fetchFromBundle ( newRepo , new byte [ 0 ] ) ; } @Test public void testNonBundleFails ( ) throws Exception { Repository newRepo = createBareRepository ( ) ; thrown . expect ( TransportException . class ) ; < |startfocus| > fetchFromBundle ( newRepo , "Not a bundle file" . getBytes ( UTF_8 ) ) ; < |endfocus| > } @Test public void testGarbageBundleFails ( ) throws Exception { Repository newRepo = createBareRepository ( ) ; thrown . expect ( TransportException . class ) ; fetchFromBundle ( newRepo , ( TransportBundle . V2_BUNDLE_SIGNATURE + '\n' + "Garbage" ) . getBytes ( UTF_8 ) ) ; } @Test public void testWriteSingleRef ( ) throws Exception { // Create a tiny bundle , ( well one of ) the first commits only final byte [ ] bundle = makeBundle ( "refs / heads / firstcommit" ,
* key is not specified ) * @param credentialsProvider * provider to use when querying for signing key credentials ( eg . * passphrase ) * @throws CanceledException * when signing was canceled ( eg . , user aborted when entering * passphrase ) */ public abstract void sign ( @NonNull CommitBuilder commit , String gpgSigningKey , @NonNull PersonIdent committer , CredentialsProvider credentialsProvider ) throws CanceledException ; /* * * Indicates is a signing key is available for the specified committer * and / or signing key . * * @param gpgSigningKey * the signing key ( passed as is to the GPG signing tool ) * @param committer * the signing identity ( to help with key lookup in case signing * key is not specified ) * @param credentialsProvider * provider to use when querying for signing key credentials ( eg . * passphrase ) * @return < code > true </ code > if a signing key is available , * < code > false </ code > otherwise * @throws CanceledException
protected void doSetValue ( Object value ) { // value = dataType instance < |startfocus| > super . doSetValue ( value ) ; // TODO : type rel de value ? compatibilit des types ? < |endfocus| >
* * @author dlecan */ public class RevealElementsAction extends AbstractRevealElementsAction < Object > { /* * * Constructor . */ public RevealElementsAction ( ) { super ( Messages . RevealOutlineElementsAction_label ) ; } /* * * Constructor . * * @param text the label */ public RevealElementsAction ( final String text ) { super ( text ) ; } /* * < |startfocus| > * Tests whether the given { @link IDiagramElementEditPart } is hidden . < |endfocus| > * * @param selectedElement * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( IDiagramElementEditPart selectedElement ) { boolean result = true ; DDiagramElement diagramElement = selectedElement . resolveDiagramElement ( ) ; if ( diagramElement == null ) { result = false ; } else { result = ! diagramElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( List < IDiagramElementEditPart > selectedElements ) { boolean result = true ; for ( IDiagramElementEditPart selectedElement : selectedElements ) { result = result && isActive ( selectedElement ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( List < DDiagramElement > selectedElements ) { boolean result = true ; for ( DDiagramElement selectedElement : selectedElements ) { result = result && ! selectedElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( List < DDiagramElement > selectedElements , DDiagram diagram ) { boolean result = true ; for ( DDiagramElement selectedElement : selectedElements ) { result = result && ! selectedElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( List < DDiagramElement > selectedElements , DDiagram diagram , boolean considerHiddenLayer ) { boolean result = true ; for ( DDiagramElement selectedElement : selectedElements ) { result = result && ! selectedElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( List < DDiagramElement > selectedElements , DDiagram diagram , boolean considerHiddenLayer , boolean considerCollapsedLayer ) { boolean result = true ; for ( DDiagramElement selectedElement : selectedElements ) { result = result && ! selectedElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( List < DDiagramElement > selectedElements , DDiagram diagram , boolean considerHiddenLayer , boolean considerCollapsedLayer , boolean considerHiddenElements ) { boolean result = true ; for ( DDiagramElement selectedElement : selectedElements ) { result = result && ! selectedElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( List < DDiagramElement > selectedElements , DDiagram diagram , boolean considerHiddenLayer , boolean considerCollapsedLayer , boolean considerHiddenElements , boolean considerCollapsedElements ) { boolean result = true ; for ( DDiagramElement selectedElement : selectedElements ) { result = result && ! selectedElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( List < DDiagramElement > selectedElements , DDiagram diagram , boolean considerHiddenLayer , boolean considerCollapsedLayer , boolean considerHiddenElements , boolean considerCollapsedElements , boolean considerHiddenBorderedNodes ) { boolean result = true ; for ( DDiagramElement selectedElement : selectedElements ) { result = result && ! selectedElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( List < DDiagramElement > selectedElements , DDiagram diagram , boolean considerHiddenLayer , boolean considerCollapsedLayer , boolean considerHiddenElements , boolean considerCollapsedElements , boolean considerHiddenBorderedNodes , boolean considerCollapsedBorderedNodes ) { boolean result = true ; for ( DDiagramElement selectedElement : selectedElements ) { result = result && ! selectedElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( List < DDiagramElement > selectedElements , DDiagram diagram , boolean considerHiddenLayer , boolean considerCollapsedLayer , boolean considerHiddenElements , boolean considerCollapsedElements , boolean considerHiddenBorderedNodes , boolean considerCollapsedBorderedNodes , boolean considerHiddenContainers ) { boolean result = true ; for ( DDiagramElement selectedElement : selectedElements ) { result = result && ! selectedElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( List < DDiagramElement > selectedElements , DDiagram diagram , boolean considerHiddenLayer , boolean considerCollapsedLayer , boolean considerHiddenElements , boolean considerCollapsedElements , boolean considerHiddenBorderedNodes , boolean considerCollapsedBorderedNodes , boolean considerHiddenContainers , boolean considerCollapsedContainers ) { boolean result = true ; for ( DDiagramElement selectedElement : selectedElements ) { result = result && ! selectedElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( List < DDiagramElement > selectedElements , DDiagram diagram , boolean considerHiddenLayer , boolean considerCollapsedLayer , boolean considerHiddenElements , boolean considerCollapsedElements , boolean considerHiddenBorderedNodes , boolean considerCollapsedBorderedNodes , boolean considerHiddenContainers , boolean considerCollapsedContainers , boolean considerHiddenNodes ) { boolean result = true ; for ( DDiagramElement selectedElement : selectedElements ) { result = result && ! selectedElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( List < DDiagramElement > selectedElements , DDiagram diagram , boolean considerHiddenLayer , boolean considerCollapsedLayer , boolean considerHiddenElements , boolean considerCollapsedElements , boolean considerHiddenBorderedNodes , boolean considerCollapsedBorderedNodes , boolean considerHiddenContainers , boolean considerCollapsedContainers , boolean considerHiddenNodes , boolean considerCollapsedNodes ) { boolean result = true ; for ( DDiagramElement selectedElement : selectedE
/* * * Constructor . */ public RevealElementsAction ( ) { super ( Messages . RevealOutlineElementsAction_label ) ; } /* * * Constructor . * * @param text the label */ public RevealElementsAction ( final String text ) { super ( text ) ; } /* * * Tests whether the given { @link IDiagramElementEditPart } is hidden . * * @param selectedElement * The current selection < |startfocus| > * @return true if all selected element is hidden hidden . < |endfocus| > */ public static boolean isActive ( IDiagramElementEditPart selectedElement ) { boolean result = true ; DDiagramElement diagramElement = selectedElement . resolveDiagramElement ( ) ; if ( diagramElement == null ) { result = false ; } else { result = ! diagramElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( List < IGraphicalEditPart > selectedElements ) { boolean result = true ; for ( IGraphicalEditPart selectedElement : selectedElements ) { if ( ! ( selectedElement instanceof IDiagramElementEditPart ) ) { result = false ; break ; } else { result = isActive ( ( IDiagramElementEditPart ) selectedElement ) ; if ( ! result ) { break ; } } } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( IStructuredSelection selection ) { boolean result = true ; for ( Object selectedElement : selection . toList ( ) ) { if ( ! ( selectedElement instanceof IDiagramElementEditPart ) ) { result = false ; break ; } else { result = isActive ( ( IDiagramElementEditPart ) selectedElement ) ; if ( ! result ) { break ; } } } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else if ( selection instanceof ITextSelection ) { result = false ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , IEditorPart editor ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else if ( selection instanceof ITextSelection ) { result = false ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , IEditorPart editor , IWorkbenchPart workbenchPart ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else if ( selection instanceof ITextSelection ) { result = false ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , IEditorPart editor , IWorkbenchPart workbenchPart , IWorkbenchPage page ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else if ( selection instanceof ITextSelection ) { result = false ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , IEditorPart editor , IWorkbenchPart workbenchPart , IWorkbenchPage page , IWorkbenchWindow window ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else if ( selection instanceof ITextSelection ) { result = false ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , IEditorPart editor , IWorkbenchPart workbenchPart , IWorkbenchPage page , IWorkbenchWindow window , IWorkbench workbench ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else if ( selection instanceof ITextSelection ) { result = false ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , IEditorPart editor , IWorkbenchPart workbenchPart , IWorkbenchPage page , IWorkbenchWindow window , IWorkbench workbench , IAdaptable adaptable ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else if ( selection instanceof ITextSelection ) { result = false ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , IEditorPart editor , IWorkbenchPart workbenchPart , IWorkbenchPage page , IWorkbenchWindow window , IWorkbench workbench , IAdaptable adaptable , IAction action ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else if ( selection instanceof ITextSelection ) { result = false ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , IEditorPart editor , IWorkbenchPart workbenchPart , IWorkbenchPage page , IWorkbenchWindow window , IWorkbench workbench , IAdaptable adaptable , IAction action , IHandlerService handlerService ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else if ( selection instanceof ITextSelection ) { result = false ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , IEditorPart editor , IWorkbenchPart workbenchPart , IWorkbenchPage page , IWorkbenchWindow window , IWorkbench workbench , IAdaptable adaptable , IAction action , IHandlerService handlerService , ICommandService commandService ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive
/* * * Constructor . */ public RevealElementsAction ( ) { super ( Messages . RevealOutlineElementsAction_label ) ; } /* * * Constructor . * * @param text the label */ public RevealElementsAction ( final String text ) { super ( text ) ; } /* * * Tests whether the given { @link IDiagramElementEditPart } is hidden . * * @param selectedElement * The current selection < |startfocus| > * @return true if all selected element is hidden hidden . < |endfocus| > */ public static boolean isActive ( IDiagramElementEditPart selectedElement ) { boolean result = true ; DDiagramElement diagramElement = selectedElement . resolveDiagramElement ( ) ; if ( diagramElement == null ) { result = false ; } else { result = ! diagramElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( List < IGraphicalEditPart > selectedElements ) { boolean result = true ; for ( IGraphicalEditPart editPart : selectedElements ) { if ( editPart instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) editPart ) ; } else { result = false ; } } return result ; } /* * * { @inheritDoc } */ @Override public void run ( ) { final List < IGraphicalEditPart > selectedElements = getSelectedElements ( ) ; if ( selectedElements . size ( ) > 0 ) { final TransactionalEditingDomain domain = selectedElements . get ( 0 ) . getEditingDomain ( ) ; final Command cmd = new RevealElementsCommand ( domain , selectedElements ) ; domain . getCommandStack ( ) . execute ( cmd ) ; } } /* * * { @inheritDoc } */ @Override public boolean isEnabled ( ) { return isActive ( getSelectedElements ( ) ) ; } /* * * { @inheritDoc } */ @Override public boolean isHandled ( ) { return true ; } /* * * { @inheritDoc } */ @Override public void dispose ( ) { // Nothing to do } /* * * { @inheritDoc } */ @Override public void selectionChanged ( final IAction action , final ISelection selection ) { // Nothing to do } /* * * { @inheritDoc } */ @Override public void init ( final IWorkbenchPart part ) { // Nothing to do } }
/* * * Constructor . */ public RevealElementsAction ( ) { super ( Messages . RevealOutlineElementsAction_label ) ; } /* * * Constructor . * * @param text the label */ public RevealElementsAction ( final String text ) { super ( text ) ; } /* * * Tests whether the given { @link IDiagramElementEditPart } is hidden . * * @param selectedElement * The current selection < |startfocus| > * @return true if all selected element is hidden hidden . < |endfocus| > */ public static boolean isActive ( IDiagramElementEditPart selectedElement ) { boolean result = true ; DDiagramElement diagramElement = selectedElement . resolveDiagramElement ( ) ; if ( diagramElement == null ) { result = false ; } else { result = ! diagramElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( List < IGraphicalEditPart > selectedElements ) { boolean result = true ; for ( IGraphicalEditPart selectedElement : selectedElements ) { if ( ! ( selectedElement instanceof IDiagramElementEditPart ) ) { result = false ; break ; } else { result = isActive ( ( IDiagramElementEditPart ) selectedElement ) ; if ( ! result ) { break ; } } } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( IStructuredSelection selection ) { boolean result = true ; for ( Object selectedElement : selection . toList ( ) ) { if ( ! ( selectedElement instanceof IDiagramElementEditPart ) ) { result = false ; break ; } else { result = isActive ( ( IDiagramElementEditPart ) selectedElement ) ; if ( ! result ) { break ; } } } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , List < IGraphicalEditPart > selectedElements ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else { result = isActive ( selectedElements ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , IGraphicalEditPart selectedElement ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else { result = isActive ( selectedElement ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , IDiagramElementEditPart selectedElement ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else { result = isActive ( selectedElement ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , List < IGraphicalEditPart > selectedElements , IGraphicalEditPart selectedElement ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else { result = isActive ( selectedElements , selectedElement ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , List < IGraphicalEditPart > selectedElements , IDiagramElementEditPart selectedElement ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else { result = isActive ( selectedElements , selectedElement ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , IGraphicalEditPart selectedElement , IDiagramElementEditPart selectedElement2 ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else { result = isActive ( selectedElement , selectedElement2 ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , List < IGraphicalEditPart > selectedElements , IGraphicalEditPart selectedElement , IDiagramElementEditPart selectedElement2 ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else { result = isActive ( selectedElements , selectedElement , selectedElement2 ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , List < IGraphicalEditPart > selectedElements , IDiagramElementEditPart selectedElement , IGraphicalEditPart selectedElement2 ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else { result = isActive ( selectedElements , selectedElement , selectedElement2 ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , IGraphicalEditPart selectedElement , List < IGraphicalEditPart > selectedElements , IDiagramElementEditPart selectedElement2 ) { boolean result = true ; if ( selection instanceof IStructuredSelection ) { result = isActive ( ( IStructuredSelection ) selection ) ; } else { result = isActive ( selectedElement , selectedElements , selectedElement2 ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( ISelection selection , IDiagramElementEditPart selectedElement , List < IGraphicalEditPart > selectedElements , IGraphicalEditPart selectedElement2 ) { boolean result = true ; if (
* * @param selectedElement * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( IDiagramElementEditPart selectedElement ) { boolean result = true ; DDiagramElement diagramElement = selectedElement . resolveDiagramElement ( ) ; if ( diagramElement == null ) { result = false ; } else { result = ! diagramElement . isVisible ( ) ; } return result ; } /* * < |startfocus| > * Tests whether the given selection is an hidden diagram graphical element . < |endfocus| > * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( IStructuredSelection selectedElements ) { boolean result = true ; final Iterator < ? > iterator = selectedElements . iterator ( ) ; if ( ! iterator . hasNext ( ) ) { result = false ; } while ( iterator . hasNext ( ) ) { final Object next = iterator . next ( ) ; if ( next instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) next ) ; } else { result = false ; } } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElement * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( IDiagramElementEditPart selectedElement ) { boolean result = true ; DDiagramElement diagramElement = selectedElement . resolveDiagramElement ( ) ; if ( diagramElement == null ) { result = false ; } else { result = ! diagramElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( IStructuredSelection selectedElements ) { boolean result = true ; final Iterator < ? > iterator = selectedElements . iterator ( ) ; if ( ! iterator . hasNext ( ) ) { result = false ; } while ( iterator . hasNext ( ) ) { final Object next = iterator . next ( ) ; if ( next instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) next ) ; } else { result = false ; } } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElement * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( IDiagramElementEditPart selectedElement ) { boolean result = true ; DDiagramElement diagramElement = selectedElement . resolveDiagramElement ( ) ; if ( diagramElement == null ) { result = false ; } else { result = ! diagramElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( IStructuredSelection selectedElements ) { boolean result = true ; final Iterator < ? > iterator = selectedElements . iterator ( ) ; if ( ! iterator . hasNext ( ) ) { result = false ; } while ( iterator . hasNext ( ) ) { final Object next = iterator . next ( ) ; if ( next instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) next ) ; } else { result = false ; } } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElement * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( IDiagramElementEditPart selectedElement ) { boolean result = true ; DDiagramElement diagramElement = selectedElement . resolveDiagramElement ( ) ; if ( diagramElement == null ) { result = false ; } else { result = ! diagramElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( IStructuredSelection selectedElements ) { boolean result = true ; final Iterator < ? > iterator = selectedElements . iterator ( ) ; if ( ! iterator . hasNext ( ) ) { result = false ; } while ( iterator . hasNext ( ) ) { final Object next = iterator . next ( ) ; if ( next instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) next ) ; } else { result = false ; } } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElement * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( IDiagramElementEditPart selectedElement ) { boolean result = true ; DDiagramElement diagramElement = selectedElement . resolveDiagramElement ( ) ; if ( diagramElement == null ) { result = false ; } else { result = ! diagramElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( IStructuredSelection selectedElements ) { boolean result = true ; final Iterator < ? > iterator = selectedElements . iterator ( ) ; if ( ! iterator . hasNext ( ) ) { result = false ; } while ( iterator . hasNext ( ) ) { final Object next = iterator . next ( ) ; if ( next instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) next ) ; } else { result = false ; } } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElement * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( IDiagramElementEditPart selectedElement ) { boolean result = true ; DDiagramElement diagramElement = selectedElement . resolveDiagramElement ( ) ; if ( diagramElement == null ) { result = false ; } else { result = ! diagramElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( IStructuredSelection selectedElements ) { boolean result = true ; final Iterator < ? > iterator = selectedElements . iterator ( ) ; if ( ! iterator . hasNext ( ) ) { result = false ; } while ( iterator . hasNext ( ) ) { final Object next = iterator . next ( ) ; if ( next instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) next ) ; } else { result = false ; } } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElement * The current selection * @return true if all selected element is hidden hidden . */ public static boolean isActive ( IDiagramElementEditPart selectedElement ) { boolean result = true ; DDiagramElement diagramElement = selectedElement . resolveDiagramElement ( ) ; if ( diagramElement == null ) { result = false ; } else { result = ! diagramElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . */ public static boolean isActive ( IStructuredSelection selectedElements ) { boolean result = true ; final Iterator < ? > iterator = selectedElements . iterator ( ) ; if ( ! iterator . hasNext ( ) ) { result = false ; } while ( iterator . hasNext ( ) ) { final Object next = iterator . next ( ) ; if ( next instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEdit
public static boolean isActive ( IDiagramElementEditPart selectedElement ) { boolean result = true ; DDiagramElement diagramElement = selectedElement . resolveDiagramElement ( ) ; if ( diagramElement == null ) { result = false ; } else { result = ! diagramElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection < |startfocus| > * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . < |endfocus| > */ public static boolean isActive ( IStructuredSelection selectedElements ) { boolean result = true ; final Iterator < ? > iterator = selectedElements . iterator ( ) ; if ( ! iterator . hasNext ( ) ) { result = false ; } while ( iterator . hasNext ( ) ) { final Object next = iterator . next ( ) ; if ( next instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) next ) ; } else { result = false ; } } return result ; } /* * * { @inheritDoc } */ @Override public void run ( ) {
public static boolean isActive ( IDiagramElementEditPart selectedElement ) { boolean result = true ; DDiagramElement diagramElement = selectedElement . resolveDiagramElement ( ) ; if ( diagramElement == null ) { result = false ; } else { result = ! diagramElement . isVisible ( ) ; } return result ; } /* * * Tests whether the given selection is an hidden diagram graphical element . * * @param selectedElements * The current selection < |startfocus| > * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden . < |endfocus| > */ public static boolean isActive ( IStructuredSelection selectedElements ) { boolean result = true ; final Iterator < ? > iterator = selectedElements . iterator ( ) ; if ( ! iterator . hasNext ( ) ) { result = false ; } while ( iterator . hasNext ( ) ) { final Object next = iterator . next ( ) ; if ( next instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) next ) ; } else { result = false ; } } return result ; } /* * * { @inheritDoc } */ @Override
public static boolean isActive ( IStructuredSelection selectedElements ) { boolean result = true ; final Iterator < ? > iterator = selectedElements . iterator ( ) ; if ( ! iterator . hasNext ( ) ) { result = false ; } while ( iterator . hasNext ( ) ) { < |startfocus| > final Object selectedElement = iterator . next ( ) ; if ( selectedElement instanceof IDiagramElementEditPart ) { result = result && isActive ( ( IDiagramElementEditPart ) selectedElement ) ; < |endfocus| > } else { result = false ; } } return result ;
if ( vpe instanceof DDiagramElement && this . selection instanceof DiagramOutlinePage . TreeSelectionWrapper ) { final DiagramOutlinePage . TreeSelectionWrapper wrapper = ( DiagramOutlinePage . TreeSelectionWrapper ) this . selection ; final RootEditPart root = wrapper . getRoot ( ) ; final DDiagramEditor diagramEditor = ( DDiagramEditor ) wrapper . getViewer ( ) . getProperty ( DDiagramEditor . EDITOR_ID ) ; runRevealCommand ( root , diagramEditor , ( DDiagramElement ) vpe ) ; } else if ( vpe instanceof IDiagramElementEditPart ) { < |startfocus| > Optional < DDiagramElement > optional = Optional . of ( ( IGraphicalEditPart ) vpe ) . map ( IGraphicalEditPart : : resolveSemanticElement ) . filter ( DDiagramElement . class : : isInstance ) . map ( DDiagramElement . class : : cast ) ; if ( optional . isPresent ( ) ) { IDiagramElementEditPart diagramElementEditPart = ( IDiagramElementEditPart ) vpe ; SelectionRequest request = new SelectionRequest ( ) ; request . setType ( RequestConstants . REQ_OPEN ) ; diagramElementEditPart . performRequest ( request ) ; } < |endfocus| > }
private void runRevealCommand ( final RootEditPart root , final DDiagramEditor editor , final DDiagramElement vpe ) { final Object adapter = editor . getAdapter ( IDiagramCommandFactoryProvider . class ) ; final IDiagramCommandFactoryProvider cmdFactoryProvider = ( IDiagramCommandFactoryProvider ) adapter ; final TransactionalEditingDomain transactionalEditingDomain = TransactionUtil . getEditingDomain ( editor . getEditingDomain ( ) . getResourceSet ( ) ) ; final IDiagramCommandFactory emfCommandFactory = cmdFactoryProvider . getCommandFactory ( transactionalEditingDomain ) ; final Command cmd = emfCommandFactory . buildRevealCommand ( vpe ) ; < |startfocus| > final TransactionalEditingDomain domain = TransactionUtil . getEditingDomain ( editor . getEditingDomain ( ) . getResourceSet ( ) ) ; < |endfocus| > CompoundCommand allInOne = new CompoundCommand ( cmd . getLabel ( ) ) ; allInOne . append ( cmd ) ; domain . getCommandStack ( ) . execute ( allInOne ) ;
* * Contributors : * Obeo - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . sirius . diagram . ui . tools . internal . actions . visibility ; import org . eclipse . gef . Disposable ; import org . eclipse . gmf . runtime . diagram . ui . parts . IDiagramWorkbenchPart ; import org . eclipse . jface . action . IAction ; import org . eclipse . jface . viewers . ISelection ; import org . eclipse . jface . viewers . IStructuredSelection ; import org . eclipse . ui . IWorkbenchPart ; import org . eclipse . ui . PlatformUI ; /* * < |startfocus| > * Extends the { @link RevealElementsAction } to make it compatible with the tabbar by making it disposable and by handling * the selection changes . < |endfocus| > * * @author fbarbin */ public class TabbarRevealElementsAction extends RevealElementsAction implements Disposable { private IDiagramWorkbenchPart representationPart ; /* * * Constructor . * * @param text the label */ public TabbarRevealElementsAction ( final String text ) { super ( text ) ; } public void setActionPart ( IDiagramWorkbenchPart part ) { this . representationPart = part ; } @Override public void selectionChanged ( IAction action , ISelection s ) {
import org . eclipse . jface . viewers . ISelection ; import org . eclipse . jface . viewers . IStructuredSelection ; import org . eclipse . ui . IWorkbenchPart ; import org . eclipse . ui . PlatformUI ; /* * * Extends the { @link RevealElementsAction } to make it compatible with the tabbar by make it disposable and by handling * the selection changes . * * @author fbarbin */ public class TabbarRevealElementsAction extends RevealElementsAction implements Disposable { private IDiagramWorkbenchPart representationPart ; /* * * Constructor . * < |startfocus| > * @param text the label < |endfocus| > */ public TabbarRevealElementsAction ( final String text ) { super ( text ) ; } public void setActionPart ( IDiagramWorkbenchPart part ) { this . representationPart = part ; } @Override public void selectionChanged ( IAction action , ISelection s ) { IWorkbenchPart selectedPart = PlatformUI . getWorkbench ( ) . getActiveWorkbenchWindow ( ) . getActivePage ( ) . getActivePart ( ) ; if ( representationPart != null && ! representationPart . equals ( selectedPart ) ) { return ; } super . selectionChanged ( action , s ) ; setEnabled ( isEnabled ( ) ) ; } @Override public boolean isEnabled ( ) {
import org . eclipse . sirius . diagram . ui . tools . internal . actions . visibility . RevealElementsAction ; /* * * Tester to know if all selected elements can be revealed and are not visible . * * @author fbarbin * */ public class CanShowElementTester extends PropertyTester { < |startfocus| > /* * * { @inheritDoc } * * @see org . eclipse . core . expressions . IPropertyTester#test ( java . lang . Object , java . lang . String , java . lang . Object [ ] , * java . lang . Object ) */ < |endfocus| > @Override public boolean test ( Object receiver , String property , Object [ ] args , Object expectedValue ) { boolean result = false ; if ( "canShowElement" . equals ( property ) ) { // $NON - NLS - 1$ if ( receiver instanceof IStructuredSelection ) { result = RevealElementsAction . isActive ( ( IStructuredSelection ) receiver ) ; } else if ( receiver instanceof IDiagramElementEditPart ) { result = RevealElementsAction . isActive ( ( IDiagramElementEditPart ) receiver ) ; } } return result ; } }
bot . waitUntil ( done ) ; SWTBotUtils . waitAllUiEvents ( ) ; if ( isLabelHidden ) { assertFalse ( "The node should not have its label filtered . " , element . getGraphicalFilters ( ) . stream ( ) . anyMatch ( HideLabelFilter . class : : isInstance ) ) ; } else { assertFalse ( "The node should not be filtered . " , element . getGraphicalFilters ( ) . stream ( ) . anyMatch ( HideFilter . class : : isInstance ) ) ; } } } /* * < |startfocus| > * We perform the Show / Hide from each actions according to the i argument : < |endfocus| > * < ul > * < li > Double - click </ li > * < li > Contextual menu action </ li > * < li > Tabbar action </ li > * </ ul > * * @param swtBotEditPart * the selected edit part . * @param i * the action to perform : a double click , contextual menu or tabbar . * @param toolTip * the tooltip of the action to perform : Show element or Hide element . */ private void performHideReveal ( SWTBotGefEditPart swtBotEditPart , int i , String toolTip ) { switch ( i ) { case 0 :
pattern . setValue ( "yyyy / yyyy" ) ; input . setValue ( "2018 / 2019" ) ; new SimpleDateFormat ( pattern . getValue ( ) ) . parse ( input . getValue ( ) ) ; ScoutAssert . assertThrows ( ParseException . class , ( ) - > new StrictSimpleDateFormat ( pattern . getValue ( ) ) . parse ( input . getValue ( ) ) ) ; } @Test public void testJavaScriptJsonString ( ) throws ParseException { < |startfocus| > StringHolder pattern = new StringHolder ( ) ; String input = "2019 - 01 - 18T12 : 42 : 03 . 409Z" ; < |endfocus| > pattern . setValue ( IValueFormatConstants . DEFAULT_DATE_PATTERN ) ; ScoutAssert . assertThrows ( ParseException . class , ( ) - > new SimpleDateFormat ( pattern . getValue ( ) ) . parse ( input ) ) ; ScoutAssert . assertThrows ( ParseException . class , ( ) - > new StrictSimpleDateFormat ( pattern . getValue ( ) ) . parse ( input ) ) ; pattern . setValue ( IValueFormatConstants . TIMESTAMP_PATTERN ) ; ScoutAssert . assertThrows ( ParseException . class , ( ) - > new SimpleDateFormat ( pattern . getValue ( ) ) . parse ( input ) ) ; ScoutAssert . assertThrows ( ParseException . class , ( ) - > new StrictSimpleDateFormat ( pattern . getValue ( ) ) . parse ( input ) ) ;
* CAUSED AND ON ANY THEORY OF LIABILITY , WHETHER IN CONTRACT , * STRICT LIABILITY , OR TORT ( INCLUDING NEGLIGENCE OR OTHERWISE ) * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE , EVEN IF * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE . */ package org . eclipse . jgit . lib ; import static java . util . stream . Collectors . toList ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Collection ; import java . util . Collections ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; < |startfocus| > < |endfocus| > import java . util . Set ; import java . util . stream . Collectors ; import org . eclipse . jgit . annotations . NonNull ; import org . eclipse . jgit . annotations . Nullable ; /* * * Abstraction of name to { @link org . eclipse . jgit . lib . ObjectId } mapping . * < p > * A reference database stores a mapping of reference names to * { @link org . eclipse . jgit . lib . ObjectId } . Every * { @link org . eclipse . jgit . lib . Repository } has a single reference database , * mapping names to the tips of the object graph contained by the * repository . * < p > * References are stored as files within the { @code refs / } directory . * Sub - directories are allowed , and are often used to group related * references together . For example all references related to remote * repositories are stored under { @code refs / remotes / } . * < p > * References are stored as text files , with the name of the reference * being the file name , and the file contents being the object id the * reference resolves to . * < p > * References can be symbolic , where the file contains the name of another * reference , and the resolution of the symbolic reference is the object id * of the target reference . Symbolic references are stored as * { @code < source > : < target > } . * < p > * References can also be stored as packed references . Packed references are * stored in a single file , { @code packed - refs } , which contains all of the * references that are not already stored as loose references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a combination of loose and packed references . * Loose references take precedence over packed references . * < p > * References can be stored in a
* the reference space cannot be accessed . * @since 5 . 2 */ @NonNull public List < Ref > getRefsByPrefix ( String . . . prefixes ) throws IOException { List < Ref > result = new ArrayList < > ( ) ; for ( String prefix : prefixes ) { result . addAll ( getRefsByPrefix ( prefix ) ) ; } return Collections . unmodifiableList ( result ) ; } /* * * Returns all refs that resolve directly to the given { @link ObjectId } . < |startfocus| > * Includes peeled { @linkObjectId } s . This is the inverse lookup if < |endfocus| > * { @link #exactRef ( String . . . ) } . * * < p > * The default implementation uses a linear scan . Implementors of * { @link RefDatabase } should override this method directly if a better * implementation is possible . * * @param id * { @link ObjectId } to resolve * @return a { @link Set } of { @link Ref } s whose tip points to the provided * id . * @throws java . io . IOException * the reference space cannot be accessed . * @since 5 . 2 */ @NonNull public List < Ref > getRefsByPrefix ( String . . . prefixes ) throws IOException { List < Ref > result = new ArrayList < > ( ) ; for ( String prefix : prefixes ) { result . addAll ( getRefsByPrefix ( prefix ) ) ; } return Collections . unmodifiableList ( result ) ; } /* * * Returns all refs that resolve directly to the given { @link ObjectId } . < |startfocus| > * Includes peeled { @linkObjectId } s . This is the inverse lookup if < |endfocus| > * { @link #exactRef ( String . . . ) } . * * < p > * The default implementation uses a linear scan . Implementors of * { @link RefDatabase } should override this method directly if a better * implementation is possible . * * @param id * { @link ObjectId } to resolve * @return a { @link Set } of { @link Ref } s whose tip points to the provided * id . * @throws java . io . IOException * the reference space cannot be accessed .
* Includes peeled { @linkObjectId } s . This is the inverse lookup if * { @link #exactRef ( String . . . ) } . * * < p > * The default implementation uses a linear scan . Implementors of * { @link RefDatabase } should override this method directly if a better * implementation is possible . * * @param id * { @link ObjectId } to resolve < |startfocus| > * @return a { @link Set } of { @link Ref } s whose tips point to the provided < |endfocus| > * id . * @throws java . io . IOException * the reference space cannot be accessed . * @since 5 . 3 */ @NonNull public Set < Ref > resolveTipSha1 ( ObjectId id ) throws IOException { return getRefs ( ) . stream ( ) . filter ( r - > id . equals ( r . getObjectId ( ) ) || id . equals ( r . getPeeledObjectId ( ) ) ) . collect ( Collectors . toSet ( ) ) ; } /* * * Check if any refs exist in the ref database . * < p >
* @return a { @link Set } of { @link Ref } s whose tip points to the provided * id . * @throws java . io . IOException * the reference space cannot be accessed . * @since 5 . 3 */ @NonNull public Set < Ref > resolveTipSha1 ( ObjectId id ) throws IOException { < |startfocus| > return getRefs ( ) . stream ( ) . filter ( r - > id . equals ( r . getObjectId ( ) ) || id . equals ( r . getPeeledObjectId ( ) ) ) . collect ( Collectors . toSet ( ) ) ; < |endfocus| > } /* * * Check if any refs exist in the ref database . * < p > * This uses the same definition of refs as { @link #getRefs ( ) } . In * particular , returns { @code false } in a new repository with no refs * under { @code refs / } and { @code HEAD } pointing to a branch yet to be * born , and returns { @code true } in a repository with no refs under * { @code refs / } and a detached { @code HEAD } pointing to history . *
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . tracecompass . analysis . os . linux . core . inputoutput ; import org . eclipse . jdt . annotation . Nullable ; import org . eclipse . osgi . util . NLS ; /* * * Externalized message strings from the I / O Analysis * * @author Houssem Daoud */ public class Messages extends NLS { private static final String BUNDLE_NAME = "org . eclipse . linuxtools . lttng2 . kernel . core . inputoutput . analysis . messages" ; // $NON - NLS - 1$ < |startfocus| > /* * Help text for the Data provider */ public static @Nullable String DisksIODataProviderFactory_helpText ; /* * Help text for the IO analysis */ public static @Nullable String LttngInputOutputModule_Help ; static { // initialize resource bundle NLS . initializeMessages ( BUNDLE_NAME , Messages . class ) ; } private Messages ( ) { } }
* http :/ / www . eclipse . org / legal / epl - v10 . html ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . tracecompass . internal . analysis . os . linux . core . threadstatus ; import org . eclipse . osgi . util . NLS ; /* * * Externalized Strings for the { @link ThreadStatusDataProvider } package */ class Messages extends NLS { private static final String BUNDLE_NAME = "org . eclipse . tracecompass . internal . analysis . os . linux . core . threadstatus . messages" ; // $NON - NLS - 1$ /* * attribute cpu name */ public static String ThreadStatusDataProvider_attributeCpuName ; /* * * DataProvider help text */ public static String ThreadStatusDataProviderFactory_descriptionText ; /* * */ public static String ThreadStatusDataProviderFactory_title ; static { // initialize resource bundle NLS . initializeMessages ( BUNDLE_NAME , Messages . class ) ; } private Messages ( ) { } }
List < IDataProviderDescriptor > descriptors = new ArrayList < > ( ) ; Set < String > existingModules = new HashSet < > ( ) ; for ( ISegmentStoreProvider module : modules ) { IAnalysisModule analysis = ( IAnalysisModule ) module ; // Only add analysis once per trace ( which could be an experiment ) if ( ! existingModules . contains ( analysis . getId ( ) ) ) { DataProviderDescriptor . Builder builder = new DataProviderDescriptor . Builder ( ) ; < |startfocus| > builder . setId ( SegmentStoreScatterDataProvider . ID + ' : ' + analysis . getId ( ) ) // TODO check if colon works in the URL < |endfocus| > . setName ( Objects . requireNonNull ( NLS . bind ( Messages . SegmentStoreScatterGraphDataProvider_title , analysis . getName ( ) ) ) ) . setDescription ( Objects . requireNonNull ( NLS . bind ( Messages . SegmentStoreScatterGraphDataProvider_description , analysis . getName ( ) ) ) ) . setProviderType ( ProviderType . TREE_TIME_XY ) ; descriptors . add ( builder . build ( ) ) ; } } return descriptors ;
return Status . OK_STATUS ; } public File getPath ( ) { return path ; } public boolean isDirty ( ) { return false ; } public InputStream read ( String item , IProgressMonitor monitor ) throws IOException { File file = getFile ( item ) ; return new FileInputStream ( file ) ; } public void release ( ) { store . release ( this ) ; } public OutputStream write ( String item , IProgressMonitor monitor ) throws IOException { File file = getFile ( item ) ; < |startfocus| > return new FileOutputStream ( file ) ; < |endfocus| > } private File getFile ( String item ) { File file = new File ( path , item ) ; if ( ! file . getParentFile ( ) . exists ( ) ) { file . getParentFile ( ) . mkdirs ( ) ; } return file ; } }
* http :/ / www . eclipse . org / legal / epl - v10 . html * * Contributors : * Tasktop Technologies - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . mylyn . monitor . core ; import java . io . File ; import java . io . FileOutputStream ; import java . io . IOException ; import org . eclipse . core . runtime . IStatus ; import org . eclipse . core . runtime . Status ; import org . eclipse . mylyn . commons . core . StatusHandler ; import org . eclipse . mylyn . internal . monitor . core . IMonitorCoreConstants ; /* * * Used for logging interaction events . * * @author Mik Kersten * @since 2 . 0 */ public abstract class AbstractMonitorLog { protected File outputFile ; protected FileOutputStream outputStream ; protected boolean started = false ; public AbstractMonitorLog ( ) { super ( ) ; } public void startMonitoring ( ) { synchronized ( this ) { if ( started ) { return ; } else { started = true ; } } try { if ( ! outputFile . exists ( ) ) { outputFile . createNewFile ( ) ; } outputStream = new FileOutputStream ( outputFile , true ) ; } catch ( Exception e ) {
if ( ! destinationFile . exists ( ) ) { destinationFile . mkdirs ( ) ; } while ( entries . hasMoreElements ( ) ) { ZipEntry entry = entries . nextElement ( ) ; File outputFile = new File ( destinationFile , entry . getName ( ) ) ; if ( entry . isDirectory ( ) && ! outputFile . exists ( ) ) { outputFile . mkdirs ( ) ; continue ; } if ( ! outputFile . getParentFile ( ) . exists ( ) ) { outputFile . getParentFile ( ) . mkdirs ( ) ; } < |startfocus| > try ( InputStream inputStream = new BufferedInputStream ( zipFile . getInputStream ( entry ) ) ; OutputStream outStream = new BufferedOutputStream ( new FileOutputStream ( outputFile ) ) ) { copyStream ( inputStream , outStream ) ; } < |endfocus| > outputFiles . add ( outputFile ) ; if ( monitor != null ) { monitor . worked ( 1 ) ; } } return outputFiles ; } } private static void copyStream ( InputStream in , OutputStream out ) throws IOException { Assert . isNotNull ( in ) ; Assert . isNotNull ( out ) ; byte [ ] buffer = new byte [ 4096 ] ; int readCount ;
private final CommonStore store ; public CommonStorable ( CommonStore store , File path ) { this . store = store ; this . path = path ; } public void delete ( String item ) throws CoreException { getFile ( item ) . delete ( ) ; } public void deleteAll ( ) throws CoreException { File [ ] children = path . listFiles ( ) ; if ( children != null ) { // validate for ( File child : children ) { if ( child . isDirectory ( ) ) { < |startfocus| > throw new CoreException ( new Status ( IStatus . ERROR , CommonsCorePlugin . ID_PLUGIN , NLS . bind ( "The storage location '' { 0 } '' contains sub directories" , path ) ) ) ; // $NON - NLS - 1$ < |endfocus| > } } // delete all files for ( File child : children ) { child . delete ( ) ; } } if ( path . exists ( ) ) { path . delete ( ) ; } } public boolean exists ( String handle ) { if ( ! path . exists ( ) ) { return false ; } return getFile ( handle ) . exists ( ) ; } public IStatus flush ( ) { return Status . OK_STATUS ; }
public static void createZipFile ( File zipFile , List < File > files , String rootPath , IProgressMonitor monitor ) throws FileNotFoundException , IOException { if ( rootPath == null ) { rootPath = "" ; // $NON - NLS - 1$ } else if ( ! rootPath . endsWith ( "\\" ) || ! rootPath . endsWith ( " / " ) ) { // $NON - NLS - 1$ // $NON - NLS - 2$ rootPath += " / " ; // $NON - NLS - 1$ } < |startfocus| > try ( ZipOutputStream zipOut = new ZipOutputStream ( new BufferedOutputStream ( new FileOutputStream ( zipFile ) ) ) ) { < |endfocus| > for ( File file : files ) { try { addZipEntry ( zipOut , rootPath , file ) ; if ( monitor != null ) { monitor . worked ( 1 ) ; } } catch ( Exception e ) { StatusHandler . log ( new Status ( IStatus . ERROR , ICommonsCoreConstants . ID_PLUGIN , "Could not add " // $NON - NLS - 1$ + file . getName ( ) + " to zip" , e ) ) ; // $NON - NLS - 1$ } } } } /* * * @author Shawn Minto */
* a path separator character * @return the file path with its separator character changed from the given old separator to the given new * separator */ public static String changeSeparator ( String path , char oldSeparator , char newSeparator ) { return path . replace ( oldSeparator , newSeparator ) ; } /* * * Copies the given source file to the given destination file . */ public static void copy ( File source , File dest ) throws IOException { < |startfocus| > try ( InputStream in = new FileInputStream ( source ) ; OutputStream out = new BufferedOutputStream ( new FileOutputStream ( dest ) ) ) { < |endfocus| > transferData ( in , out ) ; } } /* * * Copies all files in the current data directory to the specified folder . Will overwrite . */ public static void copyFolder ( File sourceFolder , File targetFolder ) throws IOException { for ( File currFile : sourceFolder . listFiles ( ) ) { if ( currFile . isFile ( ) ) { File destFile = new File ( targetFolder , currFile . getName ( ) ) ; copy ( currFile , destFile ) ;
* http :/ / www . eclipse . org / legal / epl - v10 . html * * Contributors : * Tasktop Technologies - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . mylyn . monitor . core ; import java . io . File ; import java . io . FileOutputStream ; import java . io . IOException ; import org . eclipse . core . runtime . IStatus ; import org . eclipse . core . runtime . Status ; import org . eclipse . mylyn . commons . core . StatusHandler ; import org . eclipse . mylyn . internal . monitor . core . IMonitorCoreConstants ; /* * * Used for logging interaction events . < |startfocus| > * < |endfocus| > * @author Mik Kersten * @since 2 . 0 */ public abstract class AbstractMonitorLog { protected File outputFile ; protected FileOutputStream outputStream ; protected boolean started = false ; public AbstractMonitorLog ( ) { super ( ) ; } public void startMonitoring ( ) { synchronized ( this ) { if ( started ) { return ; } else { started = true ; } } try { if ( ! outputFile . exists ( ) ) { outputFile . createNewFile ( ) ; } outputStream = new FileOutputStream ( outputFile , true ) ; } catch ( Exception e ) {
public void dispose ( ) { < |startfocus| > fExpressionHistory . dispose ( ) ; fLocalExpressionHistory . clear ( ) ; if ( fDocumentListener != null && getSourceViewer ( ) != null && getSourceViewer ( ) . getDocument ( ) != null ) { getSourceViewer ( ) . getDocument ( ) . removeDocumentListener ( fDocumentListener ) ; } fListeners . clear ( ) ; super . dispose ( ) ; < |endfocus| >
DNode element = ( DNode ) ( ( Node ) part . getModel ( ) ) . getElement ( ) ; assertFalse ( "The node should not have its label filtered . " , element . getGraphicalFilters ( ) . stream ( ) . anyMatch ( HideLabelFilter . class : : isInstance ) ) ; activateShowHideModeUsingTabbar ( ) ; SWTBotGefEditPart swtBotEditPart = getEditPart ( "new EClass 4" , DNodeNameEditPart . class ) ; hideShow ( element , swtBotEditPart , true ) ; } /* * < |startfocus| > * Performs a hide and show actions on the diagram element by using those three different ways : < |endfocus| > * < ul > * < li > The double - click </ li > * < li > The contextual menu action </ li > * < li > The tabbar action </ li > * </ ul > * * @param element * element to hide and reveal * @param swtBotEditPart * the corresponding part . */ private void hideShow ( DDiagramElement element , SWTBotGefEditPart swtBotEditPart , boolean isLabelHidden ) { int count = 0 ; if ( ! isLabelHidden ) { count = 2 ; }
Diagram data = ( Diagram ) annotationEntry . getData ( ) ; Optional < ? > missingNode = data . getChildren ( ) . stream ( ) . filter ( child - > "_Sx9 - MCLeEemN0s24dvRntQ" . equals ( ( ( IdentifiedElement ) ( ( Node ) child ) . getElement ( ) ) . getUid ( ) ) ) . findFirst ( ) ; assertFalse ( "GMF cleaning has not been done while refreshing representation . " , missingNode . isPresent ( ) ) ; } < |startfocus| > @Override protected void tearDown ( ) throws Exception { /* Delete the temporary project */ super . tearDown ( ) ; } < |endfocus| > }
* which accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html * * Contributors : * Boeing - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . osee . framework . jdk . core . type ; import java . util . ArrayList ; import java . util . Collection ; import java . util . List ; public class TreeNode < TreeType > { private TreeType myself ; private TreeNode < TreeType > parent ; private List < TreeNode < TreeType > > children ; < |startfocus| > protected TreeNode ( TreeNode < TreeType > parent , TreeType myself ) { < |endfocus| > this . parent = parent ; this . myself = myself ; this . children = new ArrayList < > ( ) ; } public TreeNode ( TreeType myself ) { this ( null , myself ) ; } @SuppressWarnings ( "null" ) public TreeNode ( ) { this ( null ) ; } public TreeNode < TreeType > getParent ( ) { return parent ; } public TreeType getSelf ( ) { return myself ; } public List < TreeNode < TreeType > > getChildren ( ) { return children ; }
import java . util . List ; import java . util . Objects ; import java . util . function . Function ; import java . util . function . Predicate ; import org . eclipse . tracecompass . internal . tmf . analysis . xml . core . fsm . model . values . DataDrivenValue ; import org . eclipse . tracecompass . internal . tmf . analysis . xml . core . fsm . module . IAnalysisDataContainer ; import org . eclipse . tracecompass . statesystem . core . ITmfStateSystem ; import org . eclipse . tracecompass . tmf . core . event . ITmfEvent ; /* * * A data - driven condition . * * @author Genevive Bastien * @author Florian Wininger */ < |startfocus| > public abstract class DataDrivenCondition implements IDataDrivenRuntimeObject { < |endfocus| > /* * * Condition operators used to compare 2 values together */ public enum ConditionOperator implements Predicate < Integer > { /* * equal */ EQ ( i - > i == 0 ) , /* * not equal */ NE ( i - > i != 0 ) , /* * Greater or equal */ GE ( i - > i >= 0 ) , /* * Greater than */ GT ( i - > i > 0 ) , /* * Less or equal */ LE ( i - > i <= 0 ) , /* * Less than */ LT ( i - > i < 0 ) ;
private static String [ ] getProtocolsToKeep ( final String [ ] enabledProtocols ) { final List < String > remainingProtocols = new ArrayList < String > ( ) ; for ( final String protocol : enabledProtocols ) { if ( protocol . equals ( SSLV3 ) || protocol . equals ( SSLV2_HELLO ) ) { continue ; } remainingProtocols . add ( protocol ) ; } if ( remainingProtocols . isEmpty ( ) ) { < |startfocus| > /* no other protocol allowed */ throw new IllegalStateException ( "No other protocol allowed" ) ; < |endfocus| > } return remainingProtocols . toArray ( new String [ remainingProtocols . size ( ) ] ) ;
final SSLContext context = SSLContext . getInstance ( "TLS" ) ; // $NON - NLS - 1$ context . init ( ServerKeyStoreManager . getInstance ( ) . getKeyManagerFactory ( ) . getKeyManagers ( ) , null , null ) ; serverSocketFactory = context . getServerSocketFactory ( ) ; } catch ( final NoSuchAlgorithmException exception ) { shutdown ( serverSocketFactory , exception ) ; } catch ( final KeyManagementException exception ) { shutdown ( serverSocketFactory , exception ) ; } catch ( final ServerKeyStoreException exception ) { shutdown ( serverSocketFactory , exception ) ; } < |startfocus| > return disableSSLv3AndReturn ( serverSocketFactory . createServerSocket ( pPort , backlog , addr ) ) ; < |endfocus| > } private void shutdown ( SSLServerSocketFactory serverSocketFactory , Exception e ) { if ( serverSocketFactory == null ) { ModelUtil . logException ( Messages . XmlRpcBuiltinWebServer_ServerSocketInitFailed , e ) ; EMFStoreController . getInstance ( ) . shutdown ( new FatalESException ( ) ) ; } } }
private static final String TAG_SELECTION = "selection" ; // $NON - NLS - 1$ private static final String TAG_EXPANDED = "expanded" ; // $NON - NLS - 1$ private static final String TAG_ELEMENT = "element" ; // $NON - NLS - 1$ private static final String TAG_IS_ENABLED = "isEnabled" ; // $NON - NLS - 1$ private static final String TAG_PATH = "path" ; // $NON - NLS - 1$ private static final String TAG_CURRENT_FRAME = "currentFrame" ; // $NON - NLS - 1$ < |startfocus| > private EmptyWorkspaceHelper emptyWorkspaceHelper ; private IPartListener partListener = new IPartListener ( ) { @Override public void partActivated ( IWorkbenchPart part ) { if ( part instanceof IEditorPart ) { editorActivated ( ( IEditorPart ) part ) ; } } @Override public void partBroughtToTop ( IWorkbenchPart part ) { if ( part instanceof IEditorPart ) { editorActivated ( ( IEditorPart ) part ) ; } } @Override public void partClosed ( IWorkbenchPart part ) { } @Override public void partDeactivated ( IWorkbenchPart part ) { } @Override public void partOpened ( IWorkbenchPart part ) { < |endfocus| >
private static final String MEMENTO_REGEXP_FILTER_REGEXP_ATTRIBUTE = "regexp" ; // $NON - NLS - 1$ private static final String MEMENTO_REGEXP_FILTER_ENABLED_ATTRIBUTE = "enabled" ; // $NON - NLS - 1$ private int rootMode ; /* * * Used only in the case of top level = PROJECTS and only when some * working sets are selected . */ private String workingSetLabel ; private List < UserFilter > userFilters ; < |startfocus| > private EmptyWorkspaceHelper emptyWorkspaceHelper ; @Override public void init ( IViewSite site , IMemento memento ) throws PartInitException { super . init ( site , memento ) ; userFilters = new ArrayList < UserFilter > ( ) ; if ( memento != null ) { IMemento [ ] filters = memento . getChildren ( MEMENTO_REGEXP_FILTER_ELEMENT ) ; for ( IMemento filterMemento : filters ) { String regexp = filterMemento . getString ( MEMENTO_REGEXP_FILTER_REGEXP_ATTRIBUTE ) ; Boolean enabled = filterMemento . getBoolean ( MEMENTO_REGEXP_FILTER_ENABLED_ATTRIBUTE ) ; userFilters . add ( new UserFilter ( regexp , enabled ) ) ; } } } @Override public void saveState ( IMemento aMemento ) {
public void createPartControl ( Composite aParent ) { < |startfocus| > displayArea = new Composite ( aParent , SWT . NONE ) ; < |endfocus| > emptyWorkspaceHelper = new EmptyWorkspaceHelper ( aParent ) ; super . createPartControl ( aParent ) ; getCommonViewer ( ) . setMapper ( new ResourceToItemsMapper ( getCommonViewer ( ) ) ) ; getCommonViewer ( ) . setData ( NavigatorPlugin . RESOURCE_REGEXP_FILTER_DATA , this . userFilters ) ; if ( this . userFilters . stream ( ) . anyMatch ( UserFilter : : isEnabled ) ) { getCommonViewer ( ) . refresh ( ) ; }
private final Map < EPackage , String > packageToInferedSource = new LinkedHashMap < EPackage , String > ( ) ; private final Map < EPackage , Text > packageToSourceText = new LinkedHashMap < EPackage , Text > ( ) ; private final Map < EPackage , Text > packageToTargetText = new LinkedHashMap < EPackage , Text > ( ) ; private final Map < EPackage , Button > packageToUpdateButton = new LinkedHashMap < EPackage , Button > ( ) ; < |startfocus| > private final Pattern VERSION_NUMBER_PATTERN = Pattern . compile ( " ( ? <= \\bv ? | [ - _ ] ) \\d + \\b" ) ; // $NON - NLS - 1$ < |endfocus| > private final List < EPackage > packages ; private final Set < EPackage > changedPackages ; /* * * Constructs a new { @link ReleaseWizardPage } . * * @param pageName * @param description * @param titleImage * @param packages the packages * @param changedPackages the changed packages */ protected ReleaseWizardPage ( String pageName , String description , ImageDescriptor titleImage , List < EPackage > packages , Set < EPackage > changedPackages ) { super ( pageName , pageName , titleImage ) ; setDescription ( description ) ; this . packages = packages ; this . changedPackages = changedPackages ; }
IResourceDelta resourceDelta = event . getDelta ( ) ; if ( resourceDelta != null ) { IResourceDelta [ ] affectedChildren = resourceDelta . getAffectedChildren ( ) ; for ( IResourceDelta affectedChildResourceDelta : affectedChildren ) { IResource resource = affectedChildResourceDelta . getResource ( ) ; int kind = affectedChildResourceDelta . getKind ( ) ; if ( resource instanceof IProject && ( kind == IResourceDelta . ADDED || kind == IResourceDelta . REMOVED ) ) { PlatformUI . getWorkbench ( ) . getDisplay ( ) < |startfocus| > . asyncExec ( ( ) - > Display . getDefault ( ) . timerExec ( 200 , switchTopControlRunnable ) ) ; < |endfocus| > return ; } } }
* contains links to : * < ol > * < li > Project creation wizards specific to the current perspective </ li > * < li > The "New Project Wizard" to allow creation of project of any type </ li > * </ ol > * If no perspective specific project creation wizards are found then a simple * text with a link to the "New Project Wizard" is shown . * * This class also takes care of refreshing these links when the user switches * the perspective . * < |startfocus| > * @since 3 . 15 * < |endfocus| > */ public final class EmptyWorkspaceHelper implements IResourceChangeListener , IPerspectiveListener , IPropertyChangeListener { private Composite emptyArea ; private StackLayout layout ; private Control control ; private Composite displayArea ; private ArrayList < IAction > projectWizardActions = null ; private IAction newProjectAction = null ; /* * * This method should be called at the point in time when the view's controls * are created . * * @param parent The composite where the explanatory text should be put into . */ public EmptyWorkspaceHelper ( Composite parent ) {
* < li > The "New Project Wizard" to allow creation of project of any type </ li > * </ ol > * If no perspective specific project creation wizards are found then a simple * text with a link to the "New Project Wizard" is shown . * * This class also takes care of refreshing these links when the user switches * the perspective . * * @since 3 . 15 * */ < |startfocus| > public final class EmptyWorkspaceHelper implements IResourceChangeListener , IPerspectiveListener , IPropertyChangeListener { < |endfocus| > private Composite emptyArea ; private StackLayout layout ; private Control control ; private Composite displayArea ; private ArrayList < IAction > projectWizardActions = null ; private IAction newProjectAction = null ; /* * * This method should be called at the point in time when the view's controls * are created . * * @param parent The composite where the explanatory text should be put into . */ public EmptyWorkspaceHelper ( Composite parent ) { displayArea = parent ; layout = new StackLayout ( ) ; displayArea . setLayout ( layout ) ; createEmptyArea ( displayArea ) ;
* If no perspective specific project creation wizards are found then a simple * text with a link to the "New Project Wizard" is shown . * * This class also takes care of refreshing these links when the user switches * the perspective . * * @since 3 . 15 * */ public final class EmptyWorkspaceHelper implements IResourceChangeListener , IPerspectiveListener , IPropertyChangeListener { private Composite emptyArea ; private StackLayout layout ; private Control control ; private Composite displayArea ; < |startfocus| > private ArrayList < IAction > projectWizardActions ; private IAction newProjectAction ; < |endfocus| > /* * * This method should be called at the point in time when the view's controls * are created . * * @param parent The composite where the explanatory text should be put into . */ public EmptyWorkspaceHelper ( Composite parent ) { displayArea = parent ; layout = new StackLayout ( ) ; displayArea . setLayout ( layout ) ; createEmptyArea ( displayArea ) ; registerListeners ( ) ; } /* *
< |startfocus| > public void setNonEmptyControl ( Control control ) { < |endfocus| > this . control = control ; emptyArea . setBackground ( control . getBackground ( ) ) ; switchTopControl ( ) ;
< |startfocus| > private void dispose ( ) { PlatformUI . getWorkbench ( ) . getActiveWorkbenchWindow ( ) . removePerspectiveListener ( this ) ; ResourcesPlugin . getWorkspace ( ) . removeResourceChangeListener ( this ) ; JFaceResources . getColorRegistry ( ) . removeListener ( this ) ; < |endfocus| >
private void readProjectWizardActions ( ) { IWorkbench wb = PlatformUI . getWorkbench ( ) ; IWorkbenchWindow win = wb . getActiveWorkbenchWindow ( ) ; IWorkbenchPage page = win . getActivePage ( ) ; String [ ] wizardIds = page . getNewWizardShortcuts ( ) ; projectWizardActions . clear ( ) ; for ( String wizardId : wizardIds ) { < |startfocus| > IWizardDescriptor wizardDesc = WorkbenchPlugin . getDefault ( ) . getNewWizardRegistry ( ) . findWizard ( wizardId ) ; if ( wizardDesc == null ) < |endfocus| > continue ; String [ ] tags = wizardDesc . getTags ( ) ; for ( String tag : tags ) { if ( WorkbenchWizardElement . TAG_PROJECT . equals ( tag ) ) { IAction action = getAction ( WorkbenchPlugin . getDefault ( ) . getNewWizardRegistry ( ) , wizardId ) ; projectWizardActions . add ( action ) ; } } }
private void readProjectWizardActions ( ) { IWorkbench wb = PlatformUI . getWorkbench ( ) ; IWorkbenchWindow win = wb . getActiveWorkbenchWindow ( ) ; IWorkbenchPage page = win . getActivePage ( ) ; String [ ] wizardIds = page . getNewWizardShortcuts ( ) ; projectWizardActions . clear ( ) ; for ( String wizardId : wizardIds ) { < |startfocus| > IWizardDescriptor wizardDesc = WorkbenchPlugin . getDefault ( ) . getNewWizardRegistry ( ) . findWizard ( wizardId ) ; if ( wizardDesc == null ) { < |endfocus| > continue ; } String [ ] tags = wizardDesc . getTags ( ) ; for ( String tag : tags ) { if ( WorkbenchWizardElement . TAG_PROJECT . equals ( tag ) ) { IAction action = getAction ( WorkbenchPlugin . getDefault ( ) . getNewWizardRegistry ( ) , wizardId ) ; projectWizardActions . add ( action ) ; } } }
< |startfocus| > private boolean switchTopControl ( ) { < |endfocus| > Control oldTop = layout . topControl ; IProject [ ] projs = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) . getProjects ( ) ; if ( projs . length > 0 ) { layout . topControl = control ; } else { layout . topControl = emptyArea ; } return oldTop != layout . topControl ;
public void resourceChanged ( IResourceChangeEvent event ) { IResourceDelta resourceDelta = event . getDelta ( ) ; if ( resourceDelta != null ) { IResourceDelta [ ] affectedChildren = resourceDelta . getAffectedChildren ( ) ; for ( IResourceDelta affectedChildResourceDelta : affectedChildren ) { IResource resource = affectedChildResourceDelta . getResource ( ) ; int kind = affectedChildResourceDelta . getKind ( ) ; if ( resource instanceof IProject && ( kind == IResourceDelta . ADDED || kind == IResourceDelta . REMOVED ) ) { Display . getDefault ( ) . asyncExec ( ( ) - > Display . getDefault ( ) . timerExec ( 200 , switchTopControlRunnable ) ) ; return ; } } } < |startfocus| > < |endfocus| >
public void propertyChange ( PropertyChangeEvent event ) { if ( JFacePreferences . HYPERLINK_COLOR . equals ( event . getProperty ( ) ) ) { recreateEmptyArea ( ) ; < |startfocus| > } < |endfocus| >
IWorkingSetManager workingSetManager = getPlugin ( ) . getWorkbench ( ) . getWorkingSetManager ( ) ; workingSetManager . removePropertyChangeListener ( propertyChangeListener ) ; if ( collapseAllHandler != null ) { collapseAllHandler . dispose ( ) ; } if ( getActionGroup ( ) != null ) { getActionGroup ( ) . dispose ( ) ; } Control control = viewer . getControl ( ) ; if ( dragDetectListener != null && control != null && control . isDisposed ( ) == false ) { control . removeListener ( SWT . DragDetect , dragDetectListener ) ; } emptyWorkspaceHelper . dispose ( ) ; super . dispose ( ) ;
* content into here ? " * * This class uses a stack layout to switch between the "original" composite of * the view and an additional composite given the user the explanatory text . * This text is displayed when no projects are in the workspace . Once projects * are created this class switches back to the "original" composite of the view . * < |startfocus| > * The explanatory text for explains the current situation that no projects are < |endfocus| > * available and provides a list of options to create projects . This list * contains links to : * < ol > * < li > Project creation wizards specific to the current perspective </ li > * < li > The "New Project Wizard" to allow creation of project of any type </ li > * </ ol > * If no perspective specific project creation wizards are found then a simple * text with a link to the "New Project Wizard" is shown . * * This class also takes care of refreshing these links when the user switches * the perspective . * */ public final class EmptyWorkspaceHelper {
private void dispose ( Listener listener ) { PlatformUI . getWorkbench ( ) . getActiveWorkbenchWindow ( ) . removePerspectiveListener ( listener ) ; ResourcesPlugin . getWorkspace ( ) . removeResourceChangeListener ( listener ) ; JFaceResources . getColorRegistry ( ) . removeListener ( listener ) ; < |startfocus| > parent . removeDisposeListener ( listener ) ; parent = null ; < |endfocus| >
String [ ] wizardIds = page . getNewWizardShortcuts ( ) ; projectWizardActions . clear ( ) ; for ( String wizardId : wizardIds ) { IWizardRegistry newWizardRegistry = WorkbenchPlugin . getDefault ( ) . getNewWizardRegistry ( ) ; IWizardDescriptor wizardDesc = newWizardRegistry . findWizard ( wizardId ) ; if ( wizardDesc == null ) { continue ; } String [ ] tags = wizardDesc . getTags ( ) ; for ( String tag : tags ) { if ( WorkbenchWizardElement . TAG_PROJECT . equals ( tag ) ) { IAction action = getAction ( newWizardRegistry , wizardId ) ; if ( action != null ) { < |startfocus| > projectWizardActions . add ( action ) ; < |endfocus| > } } } }
public void resourceChanged ( IResourceChangeEvent event ) { IResourceDelta resourceDelta = event . getDelta ( ) ; if ( resourceDelta != null ) { IResourceDelta [ ] affectedChildren = resourceDelta . getAffectedChildren ( ) ; for ( IResourceDelta affectedChildResourceDelta : affectedChildren ) { IResource resource = affectedChildResourceDelta . getResource ( ) ; int kind = affectedChildResourceDelta . getKind ( ) ; if ( resource instanceof IProject && ( kind == IResourceDelta . ADDED || kind == IResourceDelta . REMOVED ) ) { < |startfocus| > PlatformUI . getWorkbench ( ) . getDisplay ( ) < |endfocus| > . asyncExec ( ( ) - > PlatformUI . getWorkbench ( ) . getDisplay ( ) . timerExec ( 200 , switchTopControlRunnable ) ) ; return ; } } }
* * Contributors : * Lucas Koehler - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** / package org . eclipse . emfforms . spi . common . sort ; import java . math . BigInteger ; import java . util . Comparator ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; /* * * A comparator for strings that compares numbers which are part of compared string as numbers and not as strings . < |startfocus| > * This allows to sort strings that are a mixture of numbers and text ( e . g . house numbers ) in an intuitive fashion . < |endfocus| > * For instance , plain string sorting sorts 200A greater than 1000A . This comparator sorts 1000A greater than 200A . * * @author Lucas Koehler * @since 1 . 20 * */ public final class NumberAwareStringComparator implements Comparator < String > { // First group matches zero or more non - digits . Second group matches zero or more digits private static final Pattern PATTERN = Pattern . compile ( " ( \\D * ) ( \\d * ) " ) ; // $NON - NLS - 1$ private static NumberAwareStringComparator instance ; /* * * @return the static { @link NumberAwareStringComparator } instance . */
private Action fOpenManifestAction ; private Action fOpenSchemaAction ; private Action fOpenSystemEditorAction ; private Action fOpenClassFileAction ; private Action fOpenTextEditorAction ; private Action fSelectDependentAction ; private Action fSelectInJavaSearchAction ; private Action fSelectAllAction ; private PDERefactoringAction fRefactorAction ; private CollapseAllAction fCollapseAllAction ; private DisabledFilter fHideExtEnabledFilter = new DisabledFilter ( true ) ; private DisabledFilter fHideExtDisabledFilter = new DisabledFilter ( false ) ; private WorkspaceFilter fHideWorkspaceFilter = new WorkspaceFilter ( ) ; private JavaFilter fJavaFilter = new JavaFilter ( ) ; private CopyToClipboardAction fCopyAction ; private Clipboard fClipboard ; private Object fRoot = null ; class DisabledFilter extends ViewerFilter { boolean fEnabled ; DisabledFilter ( boolean enabled ) { fEnabled = enabled ; } @Override public boolean select ( Viewer v , Object parent , Object element ) { if ( element instanceof IPluginModelBase ) { IPluginModelBase model = ( IPluginModelBase ) element ; return model . getUnderlyingResource ( ) != null || model . isEnabled ( ) != fEnabled ; } return true ;
boolean hideDisabledExternal = ! settings . getBoolean ( SHOW_EXDISABLED ) ; if ( hideWorkspace ) fTreeViewer . addFilter ( fHideWorkspaceFilter ) ; if ( hideEnabledExternal ) fTreeViewer . addFilter ( fHideExtEnabledFilter ) ; if ( hideDisabledExternal ) fTreeViewer . addFilter ( fHideExtDisabledFilter ) ; fHideWorkspaceFilterAction . setChecked ( ! hideWorkspace ) ; fHideExtEnabledFilterAction . setChecked ( ! hideEnabledExternal ) ; fHideExtDisabledFilterAction . setChecked ( ! hideDisabledExternal ) ; Job . createSystem ( "" , monitor - > { // $NON - NLS - 1$ PDEState state = TargetPlatformHelper . getPDEState ( ) ; < |startfocus| > try { Thread . sleep ( 3000l ) ; } catch ( InterruptedException e ) { // TODO Auto - generated catch block e . printStackTrace ( ) ; } < |endfocus| > Tree tree = fTreeViewer . getTree ( ) ; if ( ! tree . isDisposed ( ) ) { tree . getDisplay ( ) . asyncExec ( ( ) - > { fSourcePluginFilter = new SourcePluginFilter ( state ) ; fTreeViewer . addFilter ( fSourcePluginFilter ) ; } ) ; } } ) . schedule ( ) ;
boolean hideEnabledExternal = settings . getBoolean ( HIDE_EXENABLED ) ; boolean hideDisabledExternal = ! settings . getBoolean ( SHOW_EXDISABLED ) ; if ( hideWorkspace ) fTreeViewer . addFilter ( fHideWorkspaceFilter ) ; if ( hideEnabledExternal ) fTreeViewer . addFilter ( fHideExtEnabledFilter ) ; if ( hideDisabledExternal ) fTreeViewer . addFilter ( fHideExtDisabledFilter ) ; fHideWorkspaceFilterAction . setChecked ( ! hideWorkspace ) ; fHideExtEnabledFilterAction . setChecked ( ! hideEnabledExternal ) ; fHideExtDisabledFilterAction . setChecked ( ! hideDisabledExternal ) ; < |startfocus| > // when TP state is already initialized apply the SourcePluginFilter // directly , // otherwise defer state initialization to a background job and apply // the filter // when it is available . < |endfocus| > if ( PDECore . getDefault ( ) . getModelManager ( ) . isInitialized ( ) ) { PDEState state = PDECore . getDefault ( ) . getModelManager ( ) . getState ( ) ; fSourcePluginFilter = new SourcePluginFilter ( state ) ; } else { // try to avoid initialization in the UI Job . createSystem ( "" , monitor - > { // $NON - NLS - 1$ PDEState state = TargetPlatformHelper . getPDEState ( ) ; Tree tree = fTreeViewer . getTree ( ) ; if ( ! tree . isDisposed ( ) ) { tree . getDisplay ( ) . asyncExec ( ( ) - > {
fHideWorkspaceFilterAction . setChecked ( ! hideWorkspace ) ; fHideExtEnabledFilterAction . setChecked ( ! hideEnabledExternal ) ; fHideExtDisabledFilterAction . setChecked ( ! hideDisabledExternal ) ; // when TP state is already initialized apply the SourcePluginFilter // directly , // otherwise defer state initialization to a background job and apply // the filter // when it is available . if ( PDECore . getDefault ( ) . getModelManager ( ) . isInitialized ( ) ) { PDEState state = PDECore . getDefault ( ) . getModelManager ( ) . getState ( ) ; < |startfocus| > fSourcePluginFilter = new SourcePluginFilter ( state ) ; fTreeViewer . addFilter ( fSourcePluginFilter ) ; < |endfocus| > } else { Job . createSystem ( "" , monitor - > { // $NON - NLS - 1$ PDEState state = TargetPlatformHelper . getPDEState ( ) ; Tree tree = fTreeViewer . getTree ( ) ; if ( ! tree . isDisposed ( ) ) { tree . getDisplay ( ) . asyncExec ( ( ) - > { fSourcePluginFilter = new SourcePluginFilter ( state ) ; fTreeViewer . addFilter ( fSourcePluginFilter ) ; } ) ; } } ) . schedule ( ) ; }
IContainer parent = tpdFile . getParent ( ) ; String fileName = tpdFile . getFullPath ( ) . removeFileExtension ( ) . addFileExtension ( "target" ) . lastSegment ( ) ; // $NON - NLS - 1$ IFile portableTargetFile = parent . getFile ( new Path ( fileName ) ) ; IFolder eclipseFolder = parent . getParent ( ) . getFolder ( new Path ( targetSuffix ) ) ; if ( ! eclipseFolder . exists ( ) ) { eclipseFolder . create ( true , true , new NullProgressMonitor ( ) ) ; } < |startfocus| > IFile eclipseTargetFile = eclipseFolder . getFile ( fileName . replaceAll ( "portable" , targetSuffix ) ) ; < |endfocus| > InputStream convertedStream = convert ( portableTargetFile . getContents ( ) , "http :/ / download . eclipse . org / " , "file :/ home / data / httpd / download . eclipse . org / " ) ; // $NON - NLS - 1$ // $NON - NLS - 2$ convertedStream = convert ( convertedStream , "https :/ / download . eclipse . org / " , "file :/ home / data / httpd / download . eclipse . org / " ) ; // $NON - NLS - 1$ // $NON - NLS - 2$ if ( eclipseTargetFile . exists ( ) ) { eclipseTargetFile . setContents ( convertedStream , IResource . NONE , null ) ; } else { eclipseTargetFile . create ( convertedStream , true , null ) ; }
* { @link RefDatabase } should override this method directly if a better * implementation is possible . * * @param id * { @link ObjectId } to resolve * @return a { @link Set } of { @link Ref } s whose tips point to the provided * id . * @throws java . io . IOException * the reference space cannot be accessed . * @since 5 . 3 */ @NonNull < |startfocus| > public Set < Ref > resolveTipSha1 ( ObjectId id ) throws IOException { < |endfocus| > return getRefs ( ) . stream ( ) . filter ( r - > id . equals ( r . getObjectId ( ) ) || id . equals ( r . getPeeledObjectId ( ) ) ) . collect ( toSet ( ) ) ; } /* * * Check if any refs exist in the ref database . * < p > * This uses the same definition of refs as { @link #getRefs ( ) } . In * particular , returns { @code false } in a new repository with no refs * under { @code refs / } and { @code HEAD } pointing to a branch yet to be
protected IStatus run ( IProgressMonitor monitor ) { Diagnostic result = converter . generateTargetDefinitionFile ( tpdURI , new NullProgressMonitor ( ) ) ; if ( result . getSeverity ( ) >= Diagnostic . WARNING ) { Activator . getDefault ( ) . getLog ( ) . log ( BasicDiagnostic . toIStatus ( result ) ) ; } try { file . getParent ( ) . refreshLocal ( IResource . DEPTH_ONE , null ) ; generateEclipseTarget ( file ) ; } catch ( CoreException ex ) { < |startfocus| > return new Status ( IStatus . ERROR , Activator . PLUGIN_ID , Messages . UnexpectedException , ex ) ;/ / $NON - NLS - 1$ < |endfocus| > } return BasicDiagnostic . toIStatus ( result ) ;
* buttonFactory . text ( "Button 1" ) . create ( parent ) ; * buttonFactory . text ( "Button 2" ) . create ( parent ) ; * buttonFactory . text ( "Button 3" ) . create ( parent ) ; * </ pre > * < p > * The above example creates three buttons using the same instance of * ButtonFactory . * < p > */ public final class WidgetFactory { private WidgetFactory ( ) { } /* * * @param style SWT style applicable for Text . Refer to * { @link Button#Button ( Composite , int ) } for supported styles . * @return ButtonFactory */ public static ButtonFactory button ( int style ) { return ButtonFactory . newButton ( style ) ; } /* * * @param style SWT style applicable for Text . Refer to * { @link Text#Text ( Composite , int ) } for supported styles . * @return TextFactory */ public static TextFactory text ( int style ) { return TextFactory . newText ( style ) ; } /* * * @param style SWT style applicable for Label . Refer to
public void testUniqueLayoutData ( ) { < |startfocus| > TestFactory factory = TestFactory . newTest ( ) . tooltip ( "toolTip" ) . enabled ( false ) . layoutData ( GridDataFactory . fillDefaults ( ) . grab ( true , false ) : : create ) ; < |endfocus| > Label label = factory . create ( shell ) ; Label label2 = factory . create ( shell ) ; assertNotEquals ( label . getLayoutData ( ) , label2 . getLayoutData ( ) ) ;
public void testUniqueLayoutData ( ) { GridDataFactory gridDataFactory = GridDataFactory . fillDefaults ( ) . grab ( true , false ) ; TestFactory factory = TestFactory . newTest ( ) . tooltip ( "toolTip" ) . enabled ( false ) . layoutData ( gridDataFactory : : create ) ; Label label = factory . create ( shell ) ; Label label2 = factory . create ( shell ) ; < |startfocus| > assertNotSame ( label . getLayoutData ( ) , label2 . getLayoutData ( ) ) ; < |endfocus| >
indent . addSelectionListener ( widgetSelectedAdapter ( event - > { Spinner spinner = ( Spinner ) event . widget ; styledText . setIndent ( spinner . getSelection ( ) ) ; } ) ) ; label = new Label ( composite , SWT . NONE ) ; label . setText ( getResourceString ( "Spacing" ) ) ; // $NON - NLS - 1$ Spinner spacing = new Spinner ( composite , SWT . BORDER ) ; spacing . addSelectionListener ( widgetSelectedAdapter ( event - > { Spinner spinner = ( Spinner ) event . widget ; styledText . setLineSpacing ( spinner . getSelection ( ) ) ; } ) ) ; coolItem = new CoolItem ( coolBar , SWT . NONE ) ; coolItem . setControl ( composite ) ; CoolItem [ ] coolItems = coolBar . getItems ( ) ; for ( CoolItem item : coolItems ) { Control control = item . getControl ( ) ; Point size = control . computeSize ( SWT . DEFAULT , SWT . DEFAULT ) ; item . setMinimumSize ( size ) ; } < |startfocus| > // Button to Enable Mouse Navigator in StyledText Button enableMouseNavigator = new Button ( coolBar , SWT . CHECK ) ; enableMouseNavigator . setText ( getResourceString ( "MouseNav" ) ) ; enableMouseNavigator . addSelectionListener ( widgetSelectedAdapter ( event - > styledText . setMouseNavigatorEnabled ( enableMouseNavigator . getSelection ( ) ) ) ) ; < |endfocus| >
private static String internalGetString ( String key ) { try { return RESOURCE_BUNDLE . getString ( key ) ; } catch ( MissingResourceException e ) { < |startfocus| > return ' ! ' + key + ' ! ' ; < |endfocus| > } }
public String toString ( ) { if ( eObject == null ) { return " < null >- " + side ; // $NON - NLS - 1$ } < |startfocus| > return eObject . eClass ( ) . getName ( ) + " - " + side . getName ( ) ; < |endfocus| >
public String toString ( ) { < |startfocus| > return super . toString ( ) + ' - ' + side . getName ( ) ; < |endfocus| >
shortMessage += " . . . " ; // $NON - NLS - 1$ } // Get the author String author = null ; if ( lastCommit . getFullMessage ( ) . contains ( Constants . SIGNED_OFF_BY_TAG ) ) { try { final String subSignedOff = lastCommit . getFullMessage ( ) . substring ( lastCommit . getFullMessage ( ) . indexOf ( Constants . SIGNED_OFF_BY_TAG ) + Constants . SIGNED_OFF_BY_TAG . length ( ) ) ; < |startfocus| > author = subSignedOff . contains ( "\n" ) ? subSignedOff . substring ( 0 , subSignedOff . indexOf ( "\n" ) ) : subSignedOff ; < |endfocus| > } catch ( Exception e ) { // Do nothing } } if ( null == author || author . isEmpty ( ) ) { author = lastCommit . getAuthorIdent ( ) . getName ( ) ; } if ( ! shortMessage . isEmpty ( ) && ! author . isEmpty ( ) ) { constructName . append ( " ( " ) ; // $NON - NLS - 1$ if ( ! shortMessage . isEmpty ( ) ) { constructName . append ( "\"" ) ; // $NON - NLS - 1$ constructName . append ( shortMessage ) ; constructName . append ( "\" , " ) ; // $NON - NLS - 1$ } constructName . append ( "\"" ) ; // $NON - NLS - 1$ constructName . append ( author ) ; constructName . append ( "\" ) " ) ; // $NON - NLS - 1$ }
final String projectName = project . getName ( ) ; // Get the branch name final String fullBranchName = branch . getName ( ) ; final String shortBranchName = fullBranchName . substring ( fullBranchName . indexOf ( Constants . R_REMOTES ) + Constants . R_REMOTES . length ( ) + Constants . DEFAULT_REMOTE_NAME . length ( ) + 1 ) ; final List < IProject > importedProject = new ArrayList < IProject > ( 1 ) ; try { new ProgressMonitorDialog ( shell ) . run ( true , false , monitor - > { < |startfocus| > monitor . beginTask ( taskName , 6 ) ; < |endfocus| > try { // First , reset the current branch monitor . subTask ( "Reset the branch" ) ; // $NON - NLS - 1$ GitUtils . resetHardCurrentBranch ( git ) ; monitor . worked ( 1 ) ; // First , checkout the master branch ( else we can't delete the other branch ) monitor . subTask ( "Checkout the master" ) ; // $NON - NLS - 1$ GitUtils . checkoutExistingBranch ( git , Constants . MASTER ) ; monitor . worked ( 1 ) ; // Second , we have to delete local branch if exist monitor . subTask ( "Delete the local branch" ) ; // $NON - NLS - 1$
protected Element getRootElement ( final Object selectedObject ) { Element result = null ; // Manage the possible selected file final IFile file = PapyrusFileUtils . getFile ( selectedObject ) ; if ( null != file ) { String fullPath = file . getFullPath ( ) . toString ( ) ; < |startfocus| > if ( fullPath . endsWith ( "DomainsDefinition . uml" ) ) { fullPath = fullPath . replace ( "DomainsDefinition . uml" , " . uml" ) ; } < |endfocus| > URI modelURI = URI . createPlatformResourceURI ( fullPath , false ) ; if ( ! "uml" . equals ( modelURI . fileExtension ( ) ) ) { modelURI = modelURI . trimFileExtension ( ) . appendFileExtension ( "uml" ) ; } final ModelSet modelSet = new ModelSet ( ) ; final Resource resource = modelSet . getResource ( modelURI , true ) ; if ( null != resource ) { final EObject root = resource . getContents ( ) . get ( 0 ) ; if ( root instanceof Element ) { result = ( Element ) root ; } } } // Manage other possibilities if ( null == result && selectedObject instanceof IAdaptable ) {
public String getText ( Object element ) { if ( element instanceof Ref ) { final Git git = GitInstance . getInstance ( ) . getGit ( ) ; final RevCommit lastCommit = GitUtils . getLastCommitOfBranch ( git , ( Ref ) element ) ; PersonIdent authorIdent = lastCommit . getAuthorIdent ( ) ; Date authorDate = authorIdent . getWhen ( ) ; < |startfocus| > SimpleDateFormat dateFormat = new SimpleDateFormat ( "dd - MM - yyyy HH : mm : ss" ) ; < |endfocus| > return dateFormat . format ( authorDate ) ; } return "Not specified" ;
public String getText ( Object element ) { if ( element instanceof Ref ) { final Git git = GitInstance . getInstance ( ) . getGit ( ) ; final RevCommit lastCommit = GitUtils . getLastCommitOfBranch ( git , ( Ref ) element ) ; PersonIdent authorIdent = lastCommit . getAuthorIdent ( ) ; Date authorDate = authorIdent . getWhen ( ) ; SimpleDateFormat dateFormat = new SimpleDateFormat ( "dd - MM - yyyy HH : mm : ss" ) ; return dateFormat . format ( authorDate ) ; } < |startfocus| > return "Not specified" ; < |endfocus| >
final RevCommit lastCommit = GitUtils . getLastCommitOfBranch ( git , ( Ref ) element ) ; String author = null ; if ( lastCommit . getFullMessage ( ) . contains ( Constants . SIGNED_OFF_BY_TAG ) ) { try { final String subSignedOff = lastCommit . getFullMessage ( ) . substring ( lastCommit . getFullMessage ( ) . indexOf ( Constants . SIGNED_OFF_BY_TAG ) + Constants . SIGNED_OFF_BY_TAG . length ( ) ) ; < |startfocus| > author = subSignedOff . contains ( "\n" ) ? subSignedOff . substring ( 0 , subSignedOff . indexOf ( "\n" ) ) : subSignedOff ; < |endfocus| > } catch ( Exception e ) { // Do nothing } } if ( null == author || author . isEmpty ( ) ) { author = lastCommit . getAuthorIdent ( ) . getName ( ) ; } return author ; } return "Unknown" ;
author = subSignedOff . contains ( "\n" ) ? subSignedOff . substring ( 0 , subSignedOff . indexOf ( "\n" ) ) : subSignedOff ; } catch ( Exception e ) { // Do nothing } } if ( null == author || author . isEmpty ( ) ) { author = lastCommit . getAuthorIdent ( ) . getName ( ) ; } return author ; } < |startfocus| > return "Unknown" ; < |endfocus| >
public String getText ( Object element ) { if ( element instanceof Ref ) { final Git git = GitInstance . getInstance ( ) . getGit ( ) ; final RevCommit lastCommit = GitUtils . getLastCommitOfBranch ( git , ( Ref ) element ) ; return lastCommit . getShortMessage ( ) ; } < |startfocus| > return "Not specified" ; < |endfocus| >
* Nicolas FAUVERGUE ( CEA LIST ) nicolas . fauvergue@cea . fr - Initial API and implementation * ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . papyrus . gitlight . git . data ; import java . util . NoSuchElementException ; import java . util . StringTokenizer ; /* * * This class represent the catalog version . */ public class CatalogVersion { /* * The major version number . */ protected int major ; /* * The minor version number . */ protected int minor ; /* * The separator for the version string . */ < |startfocus| > private final static String SEPARATOR = " . " ; < |endfocus| > /* * The empty version "0 . 0" . Equivalent to calling < code > new Version ( 0 , 0 ) </ code > . */ public static final CatalogVersion emptyVersion = new CatalogVersion ( 0 , 0 ) ; /* * * Creates a new Version . * * @param major * The major version value ( should be positive ) . * @param minor * The minor version value ( should be positive ) . */ public CatalogVersion ( final int major , final int minor ) { updateVersion ( major , minor ) ; } /* *
/* * * The 'version' details name key . */ public static final String VERSION_DETAILS_NAME = "current" ; // $NON - NLS - 1$ /* * * The master repository path . */ public static final String MASTER_REPOSITORY_PATH = Constants . DEFAULT_REMOTE_NAME + " / " + Constants . MASTER ; // $NON - NLS - 1$ /* * * The contribution branch name prefix . */ < |startfocus| > public static final String CONTRIBUTION_BRANCH_PREFIX = "Review_" ; < |endfocus| > /* * * The initial commit message . */ public static final String INITIAL_COMMIT_MESSAGE = "Initial commit" ; /* * * The git folder . */ public static final String GIT_FOLDER = "\\" + Constants . DOT_GIT ; // $NON - NLS - 1$ /* * * The change id . */ public static final String CHANGE_ID = "Change - Id : I0000000000000000000000000000000000000000" ; // $NON - NLS - 1$ }
public static void copyProject ( final Git git , final IProject project ) { final Repository repository = git . getRepository ( ) ; final URI gitPath = URI . createURI ( repository . getWorkTree ( ) . toString ( ) . replace ( "\\" , " / " ) ) ; // $NON - NLS - 1$ // $NON - NLS - 2$ // Copy all project and sub files copySubFolder ( project , gitPath ) ; // Add this copied files to git < |startfocus| > addGitFiles ( git , repository . getWorkTree ( ) , "" ) ; < |endfocus| >
public static void copyFolder ( final String source , final String dest ) { final File srcFolder = getFolder ( source ) ; final File destFolder = getFolder ( dest ) ; if ( srcFolder . exists ( ) ) { if ( ! destFolder . exists ( ) ) { destFolder . mkdir ( ) ; } // Copy sub folders and files for ( final File subFile : srcFolder . listFiles ( ) ) { if ( subFile . isDirectory ( ) ) { < |startfocus| > copyFolder ( subFile . getAbsolutePath ( ) , dest + File . separator + subFile . getName ( ) ) ; < |endfocus| > } else { try { copyFile ( subFile . getAbsolutePath ( ) , dest + File . separator + subFile . getName ( ) ) ; } catch ( IOException e ) { Activator . getLogHelper ( ) . error ( e ) ; } } } }
* https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Nicolas FAUVERGUE ( CEA LIST ) nicolas . fauvergue@cea . fr - Initial API and implementation * ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . papyrus . gitlight . review . profile ; import org . eclipse . emf . common . EMFPlugin ; import org . eclipse . emf . common . util . ResourceLocator ; /* * * This is the central singleton for the Reviewprofile model plugin . < !- - * begin - user - doc -- > < !- - end - user - doc -- > < |startfocus| > * * @generated < |endfocus| > */ public final class Activator extends EMFPlugin { /* * * Keep track of the singleton . < !- - begin - user - doc -- > < !- - end - user - doc * -- > * * @generated */ public static final Activator INSTANCE = new Activator ( ) ; /* * * Keep track of the singleton . < !- - begin - user - doc -- > < !- - end - user - doc * -- > * * @generated */ private static Implementation plugin ; /* * * Create the instance . < !- - begin - user - doc -- > < !- - end - user - doc -- > * * @generated */ public Activator ( ) { super ( new ResourceLocator [ ] { } ) ; } /* * * Returns the singleton instance of the Eclipse plugin . < !- - begin - user - doc * -- > < !- - end - user - doc -- > * * @return the singleton instance . * @generated */ @Override public ResourceLocator getPluginResourceLocator ( ) { return plugin ; } /* * * Returns the singleton instance of the Eclipse plugin . < !- - begin - user - doc * -- > < !- - end - user - doc -- > * * @return the singleton instance . * @generated */ public static Implementation getPlugin ( ) { return plugin ; } /* * * The actual implementation of the Eclipse < b > Plugin </ b > . < !- - * begin - user - doc -- > < !- - end - user - doc -- > * * @generated */ public static class Implementation extends EclipsePlugin { /* * * Creates an instance . < !- - begin - user - doc -- > < !- - end - user - doc -- > * * @generated */ public Implementation ( ) { super ( ) ; // Remember the static instance . // plugin = this ; } } }
* the display to search for potential controls * @param locationToFind * the position , in display coordinates , to be located * @return the most specific SWT control at the given location */ public static Control findControl ( Display displayToSearch , Point locationToFind ) { Shell [ ] shells = displayToSearch . getShells ( ) ; fixShellOrder ( displayToSearch , shells ) ; return findControl ( shells , locationToFind ) ; } /* * < |startfocus| > * Finds the active shell and moves it to the end of the given array , so that * findControl ( ) will find the controls from the active shell first < |endfocus| > */ private static void fixShellOrder ( Display display , Shell [ ] shells ) { if ( shells . length <= 1 ) { return ; } Shell activeShell = display . getActiveShell ( ) ; int lastIndex = shells . length - 1 ; if ( activeShell == null || shells [ lastIndex ] == activeShell ) { return ; } // find the index of the active shell and exchange last one with active
* the position , in display coordinates , to be located * @return the most specific SWT control at the given location */ public static Control findControl ( Display displayToSearch , Point locationToFind ) { Shell [ ] shells = displayToSearch . getShells ( ) ; fixShellOrder ( displayToSearch , shells ) ; return findControl ( shells , locationToFind ) ; } /* * < |startfocus| > * Finds the active shell and moves it to the end of the given array , so the * findControl ( ) will find the controls from the active shell first . < |endfocus| > */ private static void fixShellOrder ( Display display , Shell [ ] shells ) { if ( shells . length <= 1 ) { return ; } Shell activeShell = display . getActiveShell ( ) ; int lastIndex = shells . length - 1 ; if ( activeShell == null || shells [ lastIndex ] == activeShell ) { return ; } // find the index of the active shell and exchange last one with active for ( int i = 0 ; i < shells . length ; i ++ ) { if ( shells [ i ] == activeShell ) {
private static void fixShellOrder ( Display display , Shell [ ] shells ) { if ( shells . length <= 1 ) { return ; } Shell activeShell = display . getActiveShell ( ) ; int lastIndex = shells . length - 1 ; if ( activeShell == null || shells [ lastIndex ] == activeShell ) { return ; } < |startfocus| > // Find the index of the active shell and exchange last one with active < |endfocus| > for ( int i = 0 ; i < shells . length ; i ++ ) { if ( shells [ i ] == activeShell ) { Shell toMove = shells [ lastIndex ] ; shells [ i ] = toMove ; shells [ lastIndex ] = activeShell ; break ; } }
* * All rights reserved . This program and the accompanying materials are * made available under the terms of the Eclipse Public License v1 . 0 which * accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . tracecompass . tmf . ui . widgets . timegraph . model ; import java . util . ArrayList ; import java . util . List ; /* * * Generic TimeEvent implementation * * @author Matthew Khouzam * @since 4 . 3 */ < |startfocus| > public class TimeLineEvent extends TimeEvent { < |endfocus| > private final List < Long > fValues ; /* * * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event * @param duration * The duration of the event */ public TimeLineEvent ( ITimeGraphEntry entry , long time , long duration ) { this ( entry , time , duration , new ArrayList < > ( ) ) ; } /* *
int columns = headers . length ; sheetWriter . startSheet ( setPrimary . getName ( ) , headers . length ) ; sheetWriter . writeRow ( ( Object [ ] ) headers ) ; for ( DispoItem item : items ) { Map < String , MCDCCoverageData > mcdcToCoverageData = new HashMap < > ( ) ; List < DispoAnnotationData > annotations = item . getAnnotationsList ( ) ; for ( DispoAnnotationData annotation : annotations ) { < |startfocus| > if ( item . getName ( ) . contains ( "cmond_scheduler . 2 . ada . PERIODIC_TASK" ) ) { System . out . println ( "" ) ; } < |endfocus| > writeRowAnnotation ( sheetWriter , columns , item , annotation , setPrimary . getName ( ) , levelToResolutionTypesToCount , leveltoUnitToCovered , mcdcToCoverageData , levelsInSet ) ; } } sheetWriter . endSheet ( ) ; // START COVER SHEET sheetWriter . startSheet ( "Cover Sheet" , headers . length ) ; List < String > coverSheetHeadersList = new ArrayList < > ( ) ; coverSheetHeadersList . add ( " " ) ; if ( levelsInSet . contains ( CoverageLevel . A ) ) { coverSheetHeadersList . add ( "MCDC" ) ; } if ( levelsInSet . contains ( CoverageLevel . B ) ) { coverSheetHeadersList . add ( "Branch" ) ; }
return null ; } String contextPath = contextControllers . iterator ( ) . next ( ) . getContextPath ( ) ; requestURI = requestURI . substring ( contextPath . length ( ) ) ; int pos = requestURI . lastIndexOf ( ' / ' ) ; String servletPath = requestURI ; String pathInfo = null ; if ( match == Match . CONTEXT_ROOT ) { pathInfo = Const . SLASH ; servletPath = Const . BLANK ; } < |startfocus| > else if ( match == Match . DEFAULT_SERVLET ) { pathInfo = servletPath ; servletPath = Const . SLASH ; } < |endfocus| > do { for ( ContextController contextController : contextControllers ) { DispatchTargets dispatchTargets = contextController . getDispatchTargets ( null , requestURI , servletPath , pathInfo , extension , queryString , match , requestInfoDTO ) ; if ( dispatchTargets != null ) { return dispatchTargets ; } } if ( ( match == Match . EXACT ) || ( match == Match . CONTEXT_ROOT ) || ( match == Match . DEFAULT_SERVLET ) ) { break ; } if ( pos > - 1 ) { String newServletPath = requestURI . substring ( 0 , pos ) ; pathInfo = requestURI . substring ( pos ) ; }
// check for new pack files . If set to true ( default ) we use the // lastmodified attribute of the folder and assume that no new // pack files can be in this folder if his modification time has // not changed . boolean trustFolderStat = config . getBoolean ( ConfigConstants . CONFIG_CORE_SECTION , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , true ) ; if ( force || ( ! trustFolderStat ) || old . snapshot . isModified ( packDirectory ) ) { < |startfocus| > PackList newList = scanPacks ( old , force ) ; < |endfocus| > return old != newList ; } return false ;
if ( mapping != null ) { Repository repository = mapping . getRepository ( ) ; if ( repository != null ) { try { createHeadLink ( repository , composite ) ; fillValues ( repository ) ; } catch ( IOException e ) { if ( GitTraceLocation . UI . isActive ( ) ) GitTraceLocation . getTrace ( ) . trace ( GitTraceLocation . UI . getLocation ( ) , e . getMessage ( ) , e ) ; } } } return composite ; } private void createHeadLink ( final Repository repository , Composite composite ) throws IOException { < |startfocus| > final ObjectId objectId = repository . getFullBranch ( ) != null ? repository . resolve ( repository . getFullBranch ( ) ) : null ; < |endfocus| > if ( objectId == null ) { Text headLabel = createLabeledReadOnlyText ( composite , UIText . GitProjectPropertyPage_LabelId ) ; if ( repository . getRefDatabase ( ) . getRefsByPrefix ( RefDatabase . ALL ) . isEmpty ( ) ) headLabel . setText ( UIText . GitProjectPropertyPage_ValueEmptyRepository ) ; else headLabel . setText ( UIText . GitProjectPropertyPage_ValueUnbornBranch ) ; } else { Hyperlink headLink = createHeadHyperLink ( composite , UIText . GitProjectPropertyPage_LabelId ) ;
private final Map < String , Object > nameMap ; public CapabilityIndex ( Iterator < IInstallableUnit > itor ) { nameMap = new HashMap < > ( 300 ) ; namespaceMap = new HashMap < > ( 10 ) ; while ( itor . hasNext ( ) ) { IInstallableUnit iu = itor . next ( ) ; Collection < IProvidedCapability > pcs = iu . getProvidedCapabilities ( ) ; for ( IProvidedCapability pc : pcs ) { < |startfocus| > namespaceMap . computeIfAbsent ( pc . getNamespace ( ) , n - > new HashSet < > ( ) ) . add ( iu ) ; nameMap . compute ( pc . getName ( ) , ( n , prev ) - > { if ( prev == null || prev == iu ) { < |endfocus| > return iu ; } else if ( prev instanceof IInstallableUnit ) { Collection < IInstallableUnit > list = new HashSet < > ( ) ; list . add ( ( IInstallableUnit ) prev ) ; list . add ( iu ) ; return list ; } else { ( ( Collection < IInstallableUnit > ) prev ) . add ( iu ) ; return prev ; } } ) ; } } } private Object getRequirementIDs ( IEvaluationContext ctx , IExpression requirement , Object queriedKeys ) { switch ( requirement . getExpressionType ( ) ) { case IExpression . TYPE_AND :
< |startfocus| > private static void collectMatchingIUs ( Map < String , ? > indexToUse , String name , Collection < IInstallableUnit > collector ) { < |endfocus| > Object v = indexToUse . get ( name ) ; if ( v == null ) return ; if ( v instanceof IInstallableUnit ) collector . add ( ( IInstallableUnit ) v ) ; else collector . addAll ( ( Collection < IInstallableUnit > ) v ) ;
private void validatePage ( ) { String message = null ; if ( userText . getText ( ) . trim ( ) . isEmpty ( ) ) { message = Messages . CredentialsWizardPage_ErrorUser ; } < |startfocus| > else if ( message == null && passwordText . getText ( ) . trim ( ) . isEmpty ( ) ) { < |endfocus| > message = Messages . CredentialsWizardPage_ErrorPassword ; } setErrorMessage ( message ) ; setPageComplete ( message == null ) ;
while ( itor . hasNext ( ) ) { IInstallableUnit iu = itor . next ( ) ; Collection < IProvidedCapability > pcs = iu . getProvidedCapabilities ( ) ; for ( IProvidedCapability pc : pcs ) { namespaceMap . computeIfAbsent ( pc . getNamespace ( ) , n - > new HashSet < > ( ) ) . add ( iu ) ; nameMap . compute ( pc . getName ( ) , ( n , v ) - > { if ( v == null || v == iu ) { return iu ; < |startfocus| > } else if ( v instanceof IInstallableUnit ) { Collection < IInstallableUnit > list = new LinkedList < > ( ) ; list . add ( ( IInstallableUnit ) v ) ; list . add ( iu ) ; return list ; < |endfocus| > } else { ( ( Collection < IInstallableUnit > ) v ) . add ( iu ) ; return v ; } } ) ; } } } private Object getRequirementIDs ( IEvaluationContext ctx , IExpression requirement , Object queriedKeys ) { switch ( requirement . getExpressionType ( ) ) { case IExpression . TYPE_AND : // AND is OK if at least one of the branches require the queried key for ( IExpression expr : ExpressionUtil . getOperands ( requirement ) ) {
public void createArtifact ( @Nullable ArtifactToken parent , ArtifactToken artifact ) { ArtifactToken art = createArtifact ( artifact ) ; < |startfocus| > if ( parent != null ) { addChild ( parent , art ) ; } < |endfocus| >
public void initializeSystemColorsTooltip ( ) { 		if ( OS . isX11 ( ) ) { 			long /* int */ xDisplay = OS . gdk_x11_display_get_xdisplay ( OS . gdk_display_get_default ( ) ) ; 			long /* int */ xScreen = OS . XDefaultScreenOfDisplay ( xDisplay ) ; 			int xScreenNumber = OS . XScreenNumberOfScreen ( xScreen ) ; 			long /* int */ xRootWindow = OS . XRootWindowOfScreen ( xScreen ) ; 			long /* int */ xColormap = OS . XDefaultColormapOfScreen ( xScreen ) ; 			long /* int */ xVisual = OS . XDefaultVisualOfScreen ( xScreen ) ; 			int xDepth = OS . XDefaultDepthOfScreen ( xScreen ) ; 			long /* int */ xGC = OS . XCreateGC ( xDisplay , xRootWindow , 0 , null ) ; 			long /* int */ xPixmap = OS . XCreatePixmap ( xDisplay , xRootWindow , 1 , 1 , xDepth ) ; 			OS . XSetForeground ( xDisplay , xGC , OS . XWhitePixel ( xDisplay , xScreenNumber ) ) ; 			OS . XFillRectangle ( xDisplay , xPixmap , xGC , 0 , 0 , 1 , 1 ) ; 			OS . XSetForeground ( xDisplay , xGC , OS . XBlackPixel ( xDisplay , xScreenNumber ) ) ; 			OS . XDrawPoint ( xDisplay , xPixmap , xGC , 0 , 0 ) ; 			OS . XFreeGC ( xDisplay , xGC ) ; 			long /* int */ xImage = OS . XGetImage ( xDisplay , xPixmap , 0 , 0 , 1 , 1 , OS . AllPlanes , OS . ZPixmap ) ; 			OS . XFreePixmap ( xDisplay , xPixmap ) ; 			int [ ] pixel = new int [ 1 ] ; 			OS . memmove ( pixel , OS . XGetImage_data ( xImage ) , 4 ) ; 			OS . XDestroyImage ( xImage ) ; 			if ( pixel [ 0 ] == 0 ) { 				COLOR_INFO_FOREGROUND = new GdkColor ( ) ; 				COLOR_INFO_BACKGROUND = new GdkColor ( ) ; 				OS . gdk_color_parse ( TOOLTIP_FOREGROUND_COLOR , COLOR_INFO_FOREGROUND ) ; 				OS . gdk_color_parse ( TOOLTIP_BACKGROUND_COLOR , COLOR_INFO_BACKGROUND ) ; 				OS . gdk_colormap_alloc_color ( xColormap , COLOR_INFO_FOREGROUND , true , true ) ; 				OS . gdk_colormap_alloc_color ( xColormap , COLOR_INFO_BACKGROUND , true , true ) ; 			 } 		 } 	 }
import org . eclipse . uml2 . uml . Type ; import org . eclipse . uml2 . uml . UMLFactory ; import org . eclipse . uml2 . uml . UMLPackage ; /* * * Utility class for < code > org . eclipse . uml2 . uml . Package </ code > < BR > */ public class PackageUtil { /* * * Extension of UML models ( also declared in class UmlModel . This class is not accessible here , * since oep . uml . tools depends on oep . uml . tools . utils , but not vice versa */ < |startfocus| > public static final String UML_EXT = org . eclipse . papyrus . uml . tools . model . UmlModel . UML_FILE_EXTENSION ; < |endfocus| > /* * * Apply a profile and every subprofiles to a package . Also import types defined in profile * * @param profileToApply * profile to apply on package * @param package_ * on which profiles are applied * @param withSubProfiles * true if subprofiles must be automatically imported */ public static boolean applyProfile ( org . eclipse . uml2 . uml . Package package_ , org . eclipse . uml2 . uml . Profile profileToApply , boolean withSubProfiles ) { // Returnstrue if the model was modified
public static Package getUserModel ( ExecutionEvent event ) { ServiceUtilsForHandlers serviceUtils = ServiceUtilsForHandlers . getInstance ( ) ; try { < |startfocus| > ModelSet modelSet = serviceUtils . getModelSet ( event ) ; URI uri = modelSet . getURIWithoutExtension ( ) . appendFileExtension ( UML_EXT ) ; Resource userResource = modelSet . getResource ( uri , false ) ; < |endfocus| > if ( userResource != null && userResource . getContents ( ) . size ( ) > 0 ) { EObject topEObj = userResource . getContents ( ) . get ( 0 ) ; if ( ( topEObj instanceof Package ) && ( ! ( topEObj instanceof Profile ) ) ) { return ( Package ) topEObj ; } } } catch ( ServiceException e ) { Activator . log . error ( e ) ; } return null ;
breakStatement . setSourceRange ( statement . sourceStart , statement . sourceEnd - statement . sourceStart + 1 ) ; } if ( statement . label != null ) { final SimpleName name = new SimpleName ( this . ast ) ; name . internalSetIdentifier ( new String ( statement . label ) ) ; retrieveIdentifierAndSetPositions ( statement . sourceStart , statement . sourceEnd , name ) ; breakStatement . setLabel ( name ) ; } else if ( statement . expression != null && this . ast . apiLevel >= AST . JLS12_INTERNAL ) { final Expression expression = convert ( statement . expression ) ; breakStatement . setExpression ( expression ) ; < |startfocus| > int sourceEnd = statement . sourceEnd ; < |endfocus| > if ( sourceEnd == - 1 ) { breakStatement . setSourceRange ( statement . sourceStart , statement . sourceEnd - statement . sourceStart + 2 ) ; } else { breakStatement . setSourceRange ( statement . sourceStart , sourceEnd - statement . sourceStart + 1 ) ; } } return breakStatement ;
private void disposeIfExited ( final Control control , MouseEvent e ) { 	Point pt = control . toDisplay ( e . x , e . y ) ; 	Shell tipShell = fTipShell ; 	if ( tipShell != null && ! tipShell . isDisposed ( ) ) { 		Rectangle bounds = tipShell . getBounds ( ) ; 		 < |startfocus| > if ( bounds . x == 0 && bounds . y == 0 ) { < |endfocus| > 			Point offset = tipShell . toDisplay ( bounds . x , bounds . y ) ; 			bounds . x = offset . x ; 			bounds . y = offset . y ; 		 } 		bounds . x -= OFFSET ; 		bounds . y -= OFFSET ; 		bounds . height += 2 * OFFSET ; 		bounds . width += 2 * OFFSET ; 		if ( ! bounds . contains ( pt ) ) { 			tipShell . dispose ( ) ; 		 } 	 }
Shell tipShell = fTipShell ; if ( tipShell != null && ! tipShell . isDisposed ( ) ) { Rectangle bounds = tipShell . getBounds ( ) ; if ( bounds . x == 0 && bounds . y == 0 ) { Point offset = tipShell . toDisplay ( bounds . x , bounds . y ) ; bounds . x = offset . x ; bounds . y = offset . y ; } bounds . x -= OFFSET ; bounds . y -= OFFSET ; bounds . height += 2 * OFFSET ; bounds . width += 2 * OFFSET ; < |startfocus| > if ( ! bounds . contains ( pt ) ) { < |endfocus| > tipShell . dispose ( ) ; } }
// TODO : How to determine number of frames in GIF ? int num_frames = 32 ; for ( int i = 0 ; i < num_frames ; i ++ ) { // Calculate time offset from start_time to next frame delay_time = GDK . gdk_pixbuf_animation_iter_get_delay_time ( animation_iter ) ; time_offset += delay_time ; OS . g_time_val_add ( start_time , time_offset * 1000 ) ; boolean update = GDK . gdk_pixbuf_animation_iter_advance ( animation_iter , start_time ) ; if ( update ) { long /* int */ curr_pixbuf = GDK . gdk_pixbuf_animation_iter_get_pixbuf ( animation_iter ) ; imgData = ImageData . gtk_new ( device , curr_pixbuf ) ; imgData . type = getImageFormat ( loader ) ; imgDataList . add ( imgData ) ; } }
delay_time = GDK . gdk_pixbuf_animation_iter_get_delay_time ( animation_iter ) ; time_offset += delay_time ; OS . g_time_val_add ( start_time , time_offset * 1000 ) ; boolean update = GDK . gdk_pixbuf_animation_iter_advance ( animation_iter , start_time ) ; if ( update ) { < |startfocus| > long /* int */ curr_pixbuf = GDK . gdk_pixbuf_animation_iter_get_pixbuf ( animation_iter ) ; long /* int */ pixbuf_copy = GDK . gdk_pixbuf_copy ( curr_pixbuf ) ; // copy because curr_pixbuf might get disposed on next advance < |endfocus| > ImageData imgData = pixbufToImageData ( pixbuf_copy ) ; if ( this . logicalScreenHeight == 0 && this . logicalScreenWidth == 0 ) { this . logicalScreenHeight = imgData . height ; this . logicalScreenWidth = imgData . width ; } imgData . type = getImageFormat ( loader ) ; imgData . delayTime = delay_time ; imgDataList . add ( imgData ) ; OS . g_object_unref ( pixbuf_copy ) ; } else { break ; } } } ImageData [ ] imgDataArray = new ImageData [ imgDataList . size ( ) ] ;
public ImageData [ ] load ( String filename ) { if ( filename == null ) SWT . error ( SWT . ERROR_NULL_ARGUMENT ) ; InputStream stream = null ; try { stream = new FileInputStream ( filename ) ; return load ( stream ) ; } catch ( IOException e ) { SWT . error ( SWT . ERROR_IO , e ) ; } finally { try { if ( stream != null ) stream . close ( ) ; } catch ( IOException e ) { // Ignore error } } return null ; < |startfocus| > return loadFromFile ( filename ) ; < |endfocus| >
} } return imgData ; } /* * * Returns GdkPixbuf pointer by loading an image from filename ( Java string ) * @param filename * @return */ static long /* int */ gdk_pixbuf_new_from_file ( String filename ) { int length = filename . length ( ) ; char [ ] chars = new char [ length ] ; filename . getChars ( 0 , length , chars , 0 ) ; byte [ ] buffer = Converter . wcsToMbcs ( chars , true ) ; < |startfocus| > long /* int */ pixbuf = GDK . gdk_pixbuf_new_from_file ( buffer , null ) ; return pixbuf ; < |endfocus| > } /* * * Convert java object ImageData to a new GdkPixbuf for saving * @param imgData * @return */ static long /* int */ imageDataToPixbuf ( ImageData imgData ) { int colorspace = GDK . GDK_COLORSPACE_RGB ; boolean has_alpha = imgData . alphaData != null ; int width = imgData . width ; int height = imgData . height ; int rowstride = imgData . scanlinePad ; long /* int */ buffer_ptr = OS . g_malloc ( imgData . data . length ) ; C . memmove ( buffer_ptr , imgData . data , imgData . data . length ) ; < |startfocus| > long /* int */ pixbuf = GDK . gdk_pixbuf_new_from_data ( buffer_ptr , colorspace , has_alpha , 8 , width , height , rowstride , null , null ) ; return pixbuf ; < |endfocus| > } /* * * Convert java object ImageData to a new GdkPixbuf for saving * @param imgData * @return */ static long /* int */ imageDataToPixbuf ( ImageData imgData ) { int colorspace = GDK . GDK_COLORSPACE_RGB ; boolean has_alpha = imgData . alphaData != null ; int width = imgData . width ; int height = imgData . height ; int rowstride = imgData . scanlinePad ; long /* int */ buffer_ptr = OS . g_malloc ( imgData . data . length ) ; C . memmove ( buffer_ptr , imgData . data , imgData . data . length ) ;
long /* int */ [ ] len = new long /* int */ [ 1 ] ; if ( type == null ) SWT . error ( SWT . ERROR_UNSUPPORTED_FORMAT ) ; GDK . gdk_pixbuf_save_to_bufferv ( pixbuf , buffer , len , type , null , null , null ) ; byte [ ] byteArray = new byte [ ( int ) len [ 0 ] ] ; C . memmove ( byteArray , buffer [ 0 ] , byteArray . length ) ; try { stream . write ( byteArray ) ; } catch ( IOException e ) { SWT . error ( SWT . ERROR_IO ) ; } < |startfocus| > // FileFormat . save ( stream , format , this ) ; < |endfocus| >
/* * * Abstract tool tip handler . * * @since 3 . 2 * @author Loic Prieur - Drevon - extracted from { @link TimeGraphTooltipHandler } */ public abstract class TmfAbstractToolTipHandler { private static final int OFFSET = 16 ; private Composite fTipComposite ; private Shell fTipShell ; private Rectangle fInitialDeadzone ; /* * * Important note : this is being added to a display filter , this may leak , * make sure it is removed when not needed . */ < |startfocus| > private final Listener fListener = event - > { Shell tipShell = fTipShell ; if ( tipShell != null ) { disposeIfExited ( tipShell , event ) ; } } ; < |endfocus| > private void disposeIfExited ( final Control control , Event e ) { if ( ! control . isDisposed ( ) ) { Point pt = control . toDisplay ( e . x , e . y ) ; Shell tipShell = fTipShell ; if ( tipShell != null && ! tipShell . isDisposed ( ) ) { Rectangle bounds = tipShell . getBounds ( ) ; if ( bounds . x == 0 && bounds . y == 0 ) {
private void disposeIfExited ( final Control control , Event e ) { if ( ! control . isDisposed ( ) ) { Point pt = control . toDisplay ( e . x , e . y ) ; Shell tipShell = fTipShell ; if ( tipShell != null && ! tipShell . isDisposed ( ) ) { Rectangle bounds = tipShell . getBounds ( ) ; bounds . x -= OFFSET ; bounds . y -= OFFSET ; bounds . height += 2 * OFFSET ; bounds . width += 2 * OFFSET ; if ( ! bounds . contains ( pt ) && ! fInitialDeadzone . contains ( pt ) ) { tipShell . dispose ( ) ; Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; }
Shell tipShell = fTipShell ; if ( tipShell != null && ! tipShell . isDisposed ( ) ) { Rectangle bounds = tipShell . getBounds ( ) ; if ( bounds . x == 0 && bounds . y == 0 ) { Point offset = tipShell . toDisplay ( bounds . x , bounds . y ) ; bounds . x = offset . x ; bounds . y = offset . y ; } bounds . x -= OFFSET ; bounds . y -= OFFSET ; bounds . height += 2 * OFFSET ; bounds . width += 2 * OFFSET ; < |startfocus| > < |endfocus| > if ( ! bounds . contains ( pt ) ) { tipShell . dispose ( ) ; Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; } } else { Display . getDefault ( ) . removeFilter ( SWT . MouseExit , fListener ) ; }
createTooltipShell ( timeGraphControl . getShell ( ) ) ; for ( Control child : fTipComposite . getChildren ( ) ) { child . dispose ( ) ; } fill ( control , event , pt ) ; if ( fTipComposite . getChildren ( ) . length == 0 ) { // avoid displaying empty tool tips . return ; } fTipShell . pack ( ) ; Point tipPosition = control . toDisplay ( pt ) ; setHoverLocation ( fTipShell , tipPosition ) ; fTipShell . setVisible ( true ) ; < |startfocus| > Display . getDefault ( ) . addFilter ( SWT . MouseExit , fListener ) ; Display . getDefault ( ) . addFilter ( SWT . MouseMove , fListener ) ; < |endfocus| >
public static void beforeClass ( ) { SWTBotUtils . initialize ( ) ; Thread . currentThread ( ) . setName ( "SWTBotTest" ) ; /* set up for swtbot */ SWTBotPreferences . TIMEOUT = 60000 ; /* 60 second timeout */ SWTBotPreferences . KEYBOARD_LAYOUT = "EN_US" ; SWTWorkbenchBot bot = new SWTWorkbenchBot ( ) ; < |startfocus| > SWTBotUtils . closeView ( "welcome" , bot ) ; < |endfocus| > /* Finish waiting for eclipse to load */ WaitUtils . waitForJobs ( ) ; /* Create project */ SWTBotUtils . createProject ( PROJECT_NAME ) ;
checkWidget ( ) ; if ( listener == null ) error ( SWT . ERROR_NULL_ARGUMENT ) ; if ( eventTable == null ) return ; eventTable . unhook ( SWT . Verify , listener ) ; } @Override GdkRGBA getContextBackgroundGdkRGBA ( ) { if ( background != null && ( state & BACKGROUND ) != 0 ) { return background ; } return defaultBackground ( ) ; } @Override void setBackgroundGdkRGBA ( long /* int */ context , long /* int */ handle , GdkRGBA rgba ) { if ( GTK . GTK4 ) { < |startfocus| > background = rgba ; < |endfocus| > super . setBackgroundGdkRGBA ( context , handle , rgba ) ; } else { if ( rgba == null ) { background = defaultBackground ( ) ; } else { background = rgba ; } String css ; String properties ; String name ; name = GTK . GTK_VERSION >= OS . VERSION ( 3 , 20 , 0 ) ? "spinbutton" : "GtkSpinButton" ; String color = display . gtk_rgba_to_css_string ( background ) ; }
assertNotNull ( testFile ) ; SWTBotUtils . openTrace ( TRACE_PROJECT_NAME , testFile . getAbsolutePath ( ) , TRACE_TYPE ) ; fEditorBot = SWTBotUtils . activateEditor ( fBot , testFile . getName ( ) ) ; fAbsolutePath = TmfTraceManager . getTemporaryDirPath ( ) + File . separator + "exportToTsvTest . tsv" ; TmfFileDialogFactory . setOverrideFiles ( fAbsolutePath ) ; } /* * * Test full export * * @throws IOException * File not found or such */ @Test public void testExport ( ) throws IOException { < |startfocus| > setup ( ) ; < |endfocus| > SWTBotEditor editorBot = fEditorBot ; assertNotNull ( editorBot ) ; final SWTBotTable tableBot = editorBot . bot ( ) . table ( ) ; tableBot . getTableItem ( 1 ) . contextMenu ( EXPORT_TO_TSV ) . click ( ) ; File file = new File ( fAbsolutePath ) ; fBot . waitUntil ( new FileLargerThanZeroCondition ( file ) ) ; try ( BufferedReader br = new BufferedReader ( new FileReader ( file ) ) ) { long lines = br . lines ( ) . count ( ) ; assertEquals ( "Line count" , 23 , lines ) ; } finally { new File ( fAbsolutePath ) . delete ( ) ; } } /* * * Test full export * * @throws IOException * File not found or such */ @Test public void testExport ( ) throws IOException { setup ( ) ; SWTBotEditor editorBot = fEditorBot ; assertNotNull ( editorBot ) ; final SWTBotTable tableBot = editorBot . bot ( ) . table ( ) ; tableBot . getTableItem ( 1 ) . contextMenu ( EXPORT_TO_TSV ) . click ( ) ; File file = new File ( fAbsolutePath ) ; fBot . waitUntil ( new FileLargerThanZeroCondition ( file ) ) ; try ( BufferedReader br = new BufferedReader ( new FileReader ( file ) ) ) { long lines = br . lines ( ) . count ( ) ; assertEquals ( "Line count" , 23 , lines ) ; } finally { new File ( fAbsolutePath ) . delete ( ) ; } } /* *
assertNotNull ( editorBot ) ; final SWTBotTable tableBot = editorBot . bot ( ) . table ( ) ; tableBot . getTableItem ( 0 ) . click ( 3 ) ; SWTBotText textBot = editorBot . bot ( ) . text ( ) ; textBot . typeText ( "LoggerA|LoggerB|LoggerC" ) ; textBot . pressShortcut ( Keystrokes . CTRL , Keystrokes . CR ) ; fBot . waitUntil ( Conditions . tableHasRows ( tableBot , 6 ) , 5000 ) ; tableBot . getTableItem ( 1 ) . contextMenu ( EXPORT_TO_TSV ) . click ( ) ; assertTsvContentsEquals ( ImmutableList . of ( HEADER_TEXT , EVENT1_TEXT , EVENT2_TEXT , EVENT3_TEXT ) ) ; < |startfocus| > fBot . closeAllEditors ( ) ; < |endfocus| > } private static void assertTsvContentsEquals ( final List < String > expected ) throws FileNotFoundException , IOException { File file = new File ( fAbsolutePath ) ; fBot . waitUntil ( new FileLargerThanZeroCondition ( file ) ) ; try ( BufferedReader br = new BufferedReader ( new FileReader ( file ) ) ) { List < String > lines = br . lines ( ) . collect ( Collectors . toList ( ) ) ; assertEquals ( "File content" , expected , lines ) ; } finally { file . delete ( ) ; } } }
import org . eclipse . sirius . viewpoint . Messages ; import com . google . common . base . Preconditions ; /* * * A class providing useful methods for refresh . * * @author mbats */ public final class RefreshHelper { private static List < Predicate < Notification > > impactingNotificationPredicates = new ArrayList < > ( ) ; /* * * Prevent instantiation . */ private RefreshHelper ( ) { } /* * < |startfocus| > * Checks whether at least one changes of which we are notified , concern a semantic model or a specific graphical < |endfocus| > * change ( registered through { @link #registerImpactingNotification ( Predicate ) } ) . * * @param notifications * the model changes . * @return < code > true </ code > if the changes impact a semantic model or a specific graphical change . */ public static boolean isImpactingNotification ( final Collection < Notification > notifications ) { boolean isImpactingNotification = false ; Set < EObject > alreadyDoneNotifiers = new HashSet < > ( ) ; for ( Notification notification : notifications ) { Object notifier = notification . getNotifier ( ) ; if ( notifier instanceof EObject ) { EObject eObjectNotifier = ( EObject ) notifier ;
import org . eclipse . sirius . viewpoint . Messages ; import com . google . common . base . Preconditions ; /* * * A class providing useful methods for refresh . * * @author mbats */ public final class RefreshHelper { private static List < Predicate < Notification > > impactingNotificationPredicates = new ArrayList < > ( ) ; /* * * Prevent instantiation . */ private RefreshHelper ( ) { } /* * < |startfocus| > * Checks whether at least one changes of which we are notified , concern a semantic model or a specific graphical < |endfocus| > * change ( registered through { @link #registerImpactingNotification ( Predicate ) } ) . * * @param notifications * the model changes . * @return < code > true </ code > if the changes impact a semantic model or a specific graphical change . */ public static boolean isImpactingNotification ( final Collection < Notification > notifications ) { boolean isImpactingNotification = false ; Set < EObject > alreadyDoneNotifiers = new HashSet < > ( ) ; for ( Notification notification : notifications ) { Object notifier = notification . getNotifier ( ) ; if ( notifier instanceof EObject ) { EObject eObjectNotifier = ( EObject ) notifier ; if ( ! alreadyDoneNotifiers . contains ( eObjectNotifier ) ) { alreadyDoneNotifiers . add ( eObjectNotifier ) ; isImpactingNotification = isImpactingNotification || isImpactingNotification ( notification ) ; } } } return isImpactingNotification ; } /* * * Checks whether the change of which we are notified , concern a semantic model or a specific graphical change ( registered < |startfocus| > * through { @link #registerImpactingNotification ( Predicate ) } ) . * * @param notification * the model change . * @return < code > true </ code > if the change impact a semantic model or a specific graphical change . */ public static boolean isImpactingNotification ( final Notification notification ) { boolean isImpactingNotification = false ; for ( Predicate < Notification > impactingNotificationPredicate : impactingNotificationPredicates ) { isImpactingNotification = isImpactingNotification || impactingNotificationPredicate . apply ( notification ) ; } return isImpactingNotification ; } /* * * Registers a predicate to check whether a notification is impacting or not . * * @param impactingNotificationPredicate * the predicate to register . */ public static void registerImpactingNotification ( Predicate < Notification > impactingNotificationPredicate ) { impactingNotificationPredicates . add ( impactingNotificationPredicate ) ; } /* * * Unregisters a predicate to check whether a notification is impacting or not . * * @param impactingNotificationPredicate * the predicate to unregister . */ public static void unregisterImpactingNotification ( Predicate < Notification > impactingNotificationPredicate ) { impactingNotificationPredicates . remove ( impactingNotificationPredicate ) ; } }
} } } return false ; } /* * * Checks whether this notification concerns a semantic model change or a specific graphical change ( registered * through { @link #registerImpactingNotification ( Predicate ) } ) . * * @param notification * the model change . * @param notifier * the EObject which is concerned by this notification * @param alreadyDoneNotifiers * list of notifiers that have already been checked before * @param notifierWithResource < |startfocus| > * map cache that for a notifier has its resource < |endfocus| > * @param notifierIsInAirdOrSrmResource * map cache that for a notifier has the result of the method * < code > ResourceQuery ( Resource ) . isAirdOrSrmResource ( ) </ code > * @return < code > true </ code > if the change impact a semantic model or a specific graphical change . */ protected static boolean isImpactingNotification ( Notification notification , EObject notifier , Set < EObject > alreadyDoneNotifiers , Map < EObject , Resource > notifierWithResource , Map < EObject , Boolean > notifierIsInAirdOrSrmResource ) { Resource notifierResource = notifierWithResource . get ( notifier ) ;
private static final int OFFSET = 16 ; private Composite fTipComposite ; private Shell fTipShell ; private Rectangle fInitialDeadzone ; /* * * Important note : this is being added to a display filter , this may leak , * make sure it is removed when not needed . */ private final Listener fListener = this : : disposeIfExited ; /* * < |startfocus| > * Dispose the shell if we exit the range . Also deregister the filter from * display if the tooltip is disposed OR if it should be disposed < |endfocus| > * * @param e * The event which occurred */ private void disposeIfExited ( Event e ) { if ( ! ( e . widget instanceof Control ) ) { return ; } Control control = ( Control ) e . widget ; if ( control != null && ! control . isDisposed ( ) ) { Point pt = control . toDisplay ( e . x , e . y ) ; Shell tipShell = fTipShell ; if ( tipShell != null && ! tipShell . isDisposed ( ) ) { Rectangle bounds = tipShell . getBounds ( ) ; bounds . x -= OFFSET ; bounds . y -= OFFSET ; bounds . width += 2 * OFFSET ; bounds . height += 2 * OFFSET ; if ( ! bounds . contains ( pt ) ) { dispose ( ) ; } } } }
createTooltipShell ( timeGraphControl . getShell ( ) ) ; for ( Control child : fTipComposite . getChildren ( ) ) { child . dispose ( ) ; } fill ( control , event , pt ) ; if ( fTipComposite . getChildren ( ) . length == 0 ) { // avoid displaying empty tool tips . return ; } fTipShell . pack ( ) ; Point tipPosition = control . toDisplay ( pt ) ; setHoverLocation ( fTipShell , tipPosition ) ; fTipShell . setVisible ( true ) ; < |startfocus| > Display . getDefault ( ) . addFilter ( SWT . MouseMove , fListener ) ; Display . getDefault ( ) . addFilter ( SWT . FocusOut , fListener ) ; < |endfocus| >
private void createTooltipShell ( Shell parent ) { final Display display = parent . getDisplay ( ) ; if ( fTipShell != null && ! fTipShell . isDisposed ( ) ) { fTipShell . dispose ( ) ; } fTipShell = new Shell ( parent , SWT . ON_TOP | SWT . TOOL ) ; < |startfocus| > fTipShell . addDisposeListener ( e - > e . display . removeFilter ( SWT . MouseMove , fListener ) ) ; < |endfocus| > GridLayout gridLayout = new GridLayout ( ) ; gridLayout . numColumns = 2 ; gridLayout . marginWidth = 2 ; gridLayout . marginHeight = 2 ; fTipShell . setLayout ( gridLayout ) ; fTipShell . setBackground ( display . getSystemColor ( SWT . COLOR_INFO_BACKGROUND ) ) ; fTipComposite = new Composite ( fTipShell , SWT . NONE ) ; fTipComposite . setLayout ( new GridLayout ( 3 , false ) ) ; setupControl ( fTipComposite ) ;
public static void cleanUp ( ) { SWTBotUtils . closeViewById ( UML2DVIEW_ID , fBot ) ; < |startfocus| > fFileLocation . delete ( ) ; fLogger . removeAllAppenders ( ) ; < |endfocus| >
public static void cleanUp ( ) { fLogger . removeAllAppenders ( ) ; < |startfocus| > fFileLocation . delete ( ) ; < |endfocus| >
for ( Control child : fTipComposite . getChildren ( ) ) { child . dispose ( ) ; } fill ( control , event , pt ) ; if ( fTipComposite . getChildren ( ) . length == 0 ) { // avoid displaying empty tool tips . return ; } fTipShell . pack ( ) ; Point tipPosition = control . toDisplay ( pt ) ; setHoverLocation ( fTipShell , tipPosition ) ; fTipShell . setVisible ( true ) ; Display display = Display . getDefault ( ) ; display . addFilter ( SWT . MouseMove , fListener ) ; < |startfocus| > display . addFilter ( SWT . FocusOut , fListener ) ; display . addFilter ( SWT . MouseExit , fListener ) ; < |endfocus| >
import org . eclipse . jdt . core . IJavaElement ; import org . eclipse . jdt . core . IMethod ; import org . eclipse . jdt . core . JavaModelException ; import org . eclipse . jdt . core . dom . CompilationUnit ; import org . eclipse . jdt . core . dom . ConstructorInvocation ; import org . eclipse . jdt . core . dom . Expression ; import org . eclipse . jdt . core . dom . IMethodBinding ; import org . eclipse . jdt . core . dom . MethodInvocation ; import org . eclipse . jdt . internal . corext . dom . HierarchicalASTVisitor ; import org . eclipse . jdt . internal . ui . JavaPlugin ; public class CalleeJavaMethodParameterVisitor extends HierarchicalASTVisitor { < |startfocus| > private final List < ICodeMining > minings ; private final ICodeMiningProvider provider ; public CalleeJavaMethodParameterVisitor ( CompilationUnit cu , List < ICodeMining > minings , ICodeMiningProvider provider ) { this . cu = cu ; this . minings = minings ; this . provider = provider ; } @Override public boolean visit ( ConstructorInvocation constructorInvocation ) { List < ? > arguments = constructorInvocation . arguments ( ) ; if ( ! arguments . isEmpty ( ) ) { IMethod method = resolveMethodBinding ( constructorInvocation . resolveConstructorBinding ( ) ) ; collectParameterNamesCodeMinings ( method , arguments ) ; } return super . visit ( constructorInvocation ) ; } @Override
String targets [ ] = { "peer1" , "peer2" } ; try ( BufferedRandomAccessFile braf = new BufferedRandomAccessFile ( fFileLocation , "rw" ) ) { braf . writeBytes ( TRACE_START ) ; for ( int i = 0 ; i < 20000 ; i ++ ) { braf . writeBytes ( makeEvent ( i * 100 , eventNames [ i % 2 ] , targets [ i % 2 ] , targets [ ( i + 1 ) % 2 ] , Integer . toString ( i % 2 + 1000 ) ) ) ; } braf . writeBytes ( TRACE_END ) ; } < |startfocus| > beforeTest ( ) ; } < |endfocus| > /* * * Open a trace in an editor */ public static void beforeTest ( ) { SWTBotUtils . createProject ( PROJECT_NAME ) ; SWTBotTreeItem treeItem = SWTBotUtils . selectTracesFolder ( fBot , PROJECT_NAME ) ; assertNotNull ( treeItem ) ; SWTBotUtils . openTrace ( PROJECT_NAME , fFileLocation . getAbsolutePath ( ) , XMLSTUB_ID ) ; SWTBotUtils . openView ( UML2DVIEW_ID ) ; } /* * * Delete the file */ @AfterClass public static void cleanUp ( ) { SWTBotUtils . closeViewById ( UML2DVIEW_ID , fBot ) ; fFileLocation . delete ( ) ; }
public void tearDown ( ) { fBot . closeAllEditors ( ) ; < |startfocus| > SWTBotUtils . deleteProject ( PROJECT_NAME , fBot ) ; < |endfocus| > }
fBot = new SWTWorkbenchBot ( ) ; /* finish waiting for eclipse to load */ WaitUtils . waitForJobs ( ) ; fFileLocation = File . createTempFile ( "sample" , " . xml" ) ; try ( BufferedRandomAccessFile braf = new BufferedRandomAccessFile ( fFileLocation , "rw" ) ) { braf . writeBytes ( TRACE_START ) ; for ( int i = 0 ; i < 100 ; i ++ ) { braf . writeBytes ( makeEvent ( i * 100 , i % 4 ) ) ; } braf . writeBytes ( TRACE_END ) ; } < |startfocus| > beforeTest ( ) ; } /* * * Open a trace in an editor */ public static void beforeTest ( ) { < |endfocus| > SWTBotUtils . createProject ( PROJECT_NAME ) ; SWTBotTreeItem treeItem = SWTBotUtils . selectTracesFolder ( fBot , PROJECT_NAME ) ; assertNotNull ( treeItem ) ; SWTBotUtils . openTrace ( PROJECT_NAME , fFileLocation . getAbsolutePath ( ) , XMLSTUB_ID ) ; SWTBotUtils . openView ( ColorsView . ID ) ; } /* * * Delete the file */ @AfterClass public static void cleanUp ( ) { fLogger . removeAllAppenders ( ) ; fFileLocation . delete ( ) ; tearDown ( ) ; } /* * * Close the editor and delete the project */ public static void tearDown ( ) { fBot . closeAllEditors ( ) ; SWTBotUtils . deleteProject ( PROJECT_NAME , fBot ) ; } /* * * Test that the colors view is correctly populated */ @Test public void testColorsView ( ) { SWTBotView viewBot = fBot . viewById ( ColorsView . ID ) ; viewBot . setFocus ( ) ; SWTBotTable tableBot = viewBot . bot ( ) . table ( ) ; assertEquals ( 4 , tableBot . rowCount ( ) ) ; assertEquals ( "0x000000" , tableBot . cell ( 0 , 0 ) ) ; assertEquals ( "0x0000FF" , tableBot . cell ( 1 , 0 ) ) ; assertEquals ( "0x00FF00" , tableBot . cell ( 2 , 0 ) ) ; assertEquals ( "0xFF0000" , tableBot . cell ( 3 , 0 ) ) ; } /* * * Test that the colors view is correctly populated */ @Test public void testColorsViewWithFilter ( ) { SWTBotView viewBot = fBot . viewById ( ColorsView . ID ) ; viewBot . setFocus ( ) ; SWTBotTable tableBot = viewBot . bot ( ) . table ( ) ; assertEquals ( 4 , tableBot . rowCount ( ) ) ; assertEquals ( "0x000000" , tableBot . cell ( 0 , 0 ) ) ; assertEquals ( "0x0000FF" , tableBot . cell ( 1 , 0 ) ) ; assertEquals ( "0x00FF00" , tableBot . cell ( 2 , 0 ) ) ; assertEquals ( "0xFF0000" , tableBot . cell ( 3 , 0 ) ) ; SWTBotToolbarDropDownButton button = viewBot . toolbarDropDownButton ( "Filter" ) ; button . menuItem ( "Show only selected" ) . click ( ) ; assertEquals ( 0 , tableBot . rowCount ( ) ) ; } /* * * Test that the colors view is correctly populated */ @Test public void testColorsViewWithFilterAndSelection ( ) { SWTBotView viewBot = fBot . viewById ( ColorsView . ID ) ; viewBot . setFocus ( ) ; SWTBotTable tableBot = viewBot . bot ( ) . table ( ) ; assertEquals ( 4 , tableBot . rowCount ( ) ) ; assertEquals ( "0x000000" , tableBot . cell ( 0 , 0 ) ) ; assertEquals ( "0x0000FF" , tableBot . cell ( 1 , 0 ) ) ; assertEquals ( "0x00FF00" , tableBot . cell ( 2 , 0 ) ) ; assertEquals ( "0xFF0000" , tableBot . cell ( 3 , 0 ) ) ; SWTBotToolbarDropDownButton button = viewBot . toolbarDropDownButton ( "Filter" ) ; button . menuItem ( "Show only selected" ) . click ( ) ; assertEquals ( 0 , tableBot . rowCount ( ) ) ; tableBot . select ( 0 ) ; assertEquals ( 1 , tableBot . rowCount ( ) ) ; assertEquals ( "0x000000" , tableBot . cell ( 0 , 0 ) ) ; } /* * * Test that the colors view is correctly populated */ @Test public void testColorsViewWithFilterAndSelection2 ( ) { SWTBotView viewBot = fBot . viewById ( ColorsView . ID ) ; viewBot . setFocus ( ) ; SWTBotTable tableBot = viewBot . bot ( ) . table ( ) ; assertEquals ( 4 , tableBot . rowCount ( ) ) ; assertEquals ( "0x000000" , tableBot . cell ( 0 , 0 ) ) ; assertEquals ( "0x0000FF" , tableBot . cell ( 1 , 0 ) ) ; assertEquals ( "0x00FF00" , tableBot . cell ( 2 , 0 ) ) ; assertEquals ( "0xFF0000" , tableBot . cell ( 3 , 0 ) ) ; SWTBotToolbarDropDownButton button = viewBot . toolbarDropDownButton ( "Filter" ) ; button . menuItem ( "Show only selected" ) . click ( ) ; assertEquals ( 0 , tableBot . rowCount ( ) ) ; tableBot . select ( 0 ) ; assertEquals ( 1 , tableBot . rowCount ( ) ) ; assertEquals ( "0x000000" , tableBot . cell ( 0 , 0 ) ) ; tableBot . select ( 1 ) ; assertEquals ( 2 , tableBot . rowCount ( ) ) ; assertEquals ( "0x000000" , tableBot . cell ( 0 , 0 ) ) ; assertEquals ( "0x0000FF" , tableBot . cell ( 1 , 0 ) ) ; } }
public static void cleanUp ( ) { fLogger . removeAllAppenders ( ) ; fFileLocation . delete ( ) ; < |startfocus| > tearDown ( ) ; < |endfocus| > }
mgr . addJobChangeListener ( changeListener ) ; for ( int i = 0 ; i < 10 ; i ++ ) { SWTBotUtils . openTrace ( TRACE_PROJECT_NAME , path , TRACE_TYPE , false ) ; SWTBotUtils . openTrace ( TRACE_PROJECT_NAME , path , TRACE_TYPE , false ) ; SWTBotUtils . openTrace ( TRACE_PROJECT_NAME , path , TRACE_TYPE , false ) ; SWTBotUtils . openTrace ( TRACE_PROJECT_NAME , path , TRACE_TYPE , false ) ; SWTBotUtils . openTrace ( TRACE_PROJECT_NAME , path , TRACE_TYPE , false ) ; // Add little delay so that treads have a chance to start < |startfocus| > SWTBotUtils . delay ( 500 ) ; < |endfocus| > workbenchbot . closeAllEditors ( ) ; if ( ! status . isOK ( ) ) { SWTBotUtils . deleteProject ( TRACE_PROJECT_NAME , workbenchbot ) ; fail ( handleErrorStatus ( status ) ) ; } } SWTBotUtils . deleteProject ( TRACE_PROJECT_NAME , workbenchbot ) ;
IKernelTrace trace = new TmfXmlKernelTraceStub ( ) ; IPath filePath = Activator . getAbsoluteFilePath ( CPU_USAGE_FILE ) ; IStatus status = trace . validate ( null , filePath . toOSString ( ) ) ; if ( ! status . isOK ( ) ) { fail ( status . getException ( ) . getMessage ( ) ) ; } try { trace . initTrace ( null , filePath . toOSString ( ) , TmfEvent . class ) ; } catch ( TmfTraceException e ) { fail ( e . getMessage ( ) ) ; } deleteSuppFiles ( trace ) ; < |startfocus| > ( ( TmfTrace ) trace ) . traceOpened ( new TmfTraceOpenedSignal ( this , trace , null ) ) ; < |endfocus| > /* * FIXME : Make sure this analysis is finished before running the CPU * analysis . This block can be removed once analysis dependency and * request precedence is implemented */ IAnalysisModule module = null ; for ( IAnalysisModule mod : TmfTraceUtils . getAnalysisModulesOfClass ( trace , TidAnalysisModule . class ) ) { module = mod ; } assertNotNull ( module ) ; module . schedule ( ) ; module . waitForCompletion ( ) ; /* End of the FIXME block */ fModule = TmfTraceUtils . getAnalysisModuleOfClass ( trace , KernelCpuUsageAnalysis . class , KernelCpuUsageAnalysis . ID ) ;
public static void setUp ( ) { ITmfTrace trace = KERNEL_TEST_CASE . getKernelTrace ( ) ; deleteSuppFiles ( trace ) ; < |startfocus| > ( ( TmfTrace ) trace ) . traceOpened ( new TmfTraceOpenedSignal ( this , trace , null ) ) ; < |endfocus| > IAnalysisModule module = null ; for ( IAnalysisModule mod : TmfTraceUtils . getAnalysisModulesOfClass ( trace , KernelAnalysisModule . class ) ) { module = mod ; } assertNotNull ( module ) ; module . schedule ( ) ; module . waitForCompletion ( ) ; fModule = TmfTraceUtils . getAnalysisModuleOfClass ( trace , KernelAnalysisModule . class , KernelAnalysisModule . ID ) ; fTrace = trace ;
* for a description of the problem . * < p > * XXX remove once the underlying problem ( https :/ / bugs . eclipse . org / bugs / show_bug . cgi ? id = 66176 ) is solved . * </ p > */ private final Object fReconcilerLock = new Object ( ) ; /* * * The templates page . * @since 3 . 4 */ private JavaTemplatesPage fTemplatesPage ; /* * * The Java reconciling listener used to update code minings */ private IJavaReconcilingListener fCodeMiningsReconcilingListener ; < |startfocus| > < |endfocus| > /* * * Creates a new compilation unit editor . */ public CompilationUnitEditor ( ) { setDocumentProvider ( JavaPlugin . getDefault ( ) . getCompilationUnitDocumentProvider ( ) ) ; setEditorContextMenuId ( "#CompilationUnitEditorContext" ) ; // $NON - NLS - 1$ setRulerContextMenuId ( "#CompilationUnitRulerContext" ) ; // $NON - NLS - 1$ setOutlinerContextMenuId ( "#CompilationUnitOutlinerContext" ) ; // $NON - NLS - 1$ // don't set help contextId , we install our own help context fSavePolicy = null ; fJavaEditorErrorTickUpdater = new JavaEditorErrorTickUpdater ( this ) ; fCorrectionCommands = null ; fCodeMiningsReconcilingListener = new JavaCodeMiningsReconciler ( this ) ;
package org . eclipse . jdt . ui . tests . activation ; import java . util . Arrays ; import java . util . HashSet ; import java . util . Set ; import org . junit . Assert ; < |startfocus| > // import org . junit . Assert ; < |endfocus| > import org . osgi . framework . Bundle ; import org . eclipse . jdt . testplugin . JavaProjectHelper ; import org . eclipse . core . runtime . Platform ; import org . eclipse . ui . IWorkbench ; import org . eclipse . ui . IWorkbenchPage ; import org . eclipse . ui . PlatformUI ; import org . eclipse . jdt . core . ICompilationUnit ; import org . eclipse . jdt . core . IJavaProject ; import org . eclipse . jdt . core . IPackageFragment ; import org . eclipse . jdt . core . IPackageFragmentRoot ; import org . eclipse . jdt . internal . ui . javaeditor . EditorUtility ; import junit . framework . TestCase ; public class JavaActivationTest extends TestCase { private IJavaProject project ;
// import org . junit . Assert ; import org . osgi . framework . Bundle ; import org . eclipse . jdt . testplugin . JavaProjectHelper ; import org . eclipse . core . runtime . Platform ; import org . eclipse . ui . IWorkbench ; import org . eclipse . ui . IWorkbenchPage ; import org . eclipse . ui . PlatformUI ; import org . eclipse . jdt . core . ICompilationUnit ; import org . eclipse . jdt . core . IJavaProject ; import org . eclipse . jdt . core . IPackageFragment ; import org . eclipse . jdt . core . IPackageFragmentRoot ; import org . eclipse . jdt . internal . ui . javaeditor . EditorUtility ; import junit . framework . TestCase ; public class JavaActivationTest extends TestCase { < |startfocus| > < |endfocus| > private IJavaProject project ; private static final String [ ] inactiveBundles = new String [ ] { "org . apache . xerces" , "org . eclipse . jdt . astview" , "org . eclipse . jdt . jeview" , "org . eclipse . reftracker" , "org . eclipse . swt . sleak" , "org . eclipse . swt . spy" , "com . jcraft . jsch" , "javax . servlet" , "javax . servlet . jsp" , "org . apache . ant" , "org . apache . commons . el" , "org . apache . commons . logging" , "org . apache . jasper" , "org . apache . lucene" , "org . apache . lucene . analysis" , "org . apache . lucene . demo" , "org . apache . lucene . gdata . server" , "org . apache . lucene . gdata . server . core" , "org . apache . lucene . gdata . server . indexer" , "org . apache . lucene . gdata . server . repository" , "org . apache . lucene . gdata . server . repository . provider" , "org . apache . lucene . gdata . server . repository . provider . jdo" , "org . apache . lucene . gdata . server . repository . provider . jdo . db4o" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . db4o" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . db4o" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . db4o" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . db4o" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql . db4o" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . db4o" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . db4o" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . db4o" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . db4o" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . db4o" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . db4o" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo . jdoql . jdo" , "org . apache . lucene . gdata . server . repository . provider . jdo . jdoql . jdo . jdoql
IPackageFragment pack = sourceFolder . createPackageFragment ( "pack0" , false , null ) ; StringBuffer buf = new StringBuffer ( ) ; buf . append ( "package pack0 ; \n" ) ; buf . append ( "public class List1 { \n } \n" ) ; return pack . createCompilationUnit ( "List1 . java" , buf . toString ( ) , false , null ) ; } public void testOpenJavaEditor ( ) throws Exception { ICompilationUnit unit = createTestCU ( ) ; EditorUtility . openInEditor ( unit ) ; < |startfocus| > Set set = new HashSet ( Arrays . asList ( inactiveBundles ) ) ; < |endfocus| > checkNotLoaded ( set ) ; } public void checkNotLoaded ( Set inactiveBundles ) { Bundle bundle = Platform . getBundle ( "org . eclipse . jdt . ui . tests" ) ; Bundle [ ] bundles = bundle . getBundleContext ( ) . getBundles ( ) ; for ( int i = 0 ; i < bundles . length ; i ++ ) { if ( bundles [ i ] . getState ( ) == Bundle . ACTIVE && inactiveBundles . contains ( bundles [ i ] . getSymbolicName ( ) ) ) { Assert . fail ( "plugin should not be activated : " + bundles [ i ] . getSymbolicName ( ) ) ; } } } }
private static IType createAutoType ( ICPPASTInitializerClause initClause , IASTDeclSpecifier declSpec , IASTDeclarator declarator ) { // C ++ 0x : 7 . 1 . 6 . 4 < |startfocus| > if ( initClause == null ) { return new ProblemType ( ISemanticProblem . TYPE_CANNOT_DEDUCE_AUTO_TYPE ) ; } < |endfocus| > IType type = AutoTypeResolver . AUTO_TYPE ; IType initType = null ; ValueCategory valueCat = null ; ICPPClassTemplate initializer_list_template = null ; if ( initClause instanceof ICPPASTInitializerList ) { initializer_list_template = get_initializer_list ( declSpec ) ; if ( initializer_list_template == null ) { return new ProblemType ( ISemanticProblem . TYPE_CANNOT_DEDUCE_AUTO_TYPE ) ; } type = ( IType ) CPPTemplates . instantiate ( initializer_list_template , new ICPPTemplateArgument [ ] { new CPPTemplateTypeArgument ( type ) } , initClause ) ; if ( type instanceof IProblemBinding ) { return new ProblemType ( ISemanticProblem . TYPE_CANNOT_DEDUCE_AUTO_TYPE ) ; } } type = decorateType ( type , declSpec , declarator ) ; final ICPPEvaluation evaluation = initClause . getEvaluation ( ) ; initType = evaluation . getTypeOrFunctionSet ( declarator ) ; valueCat = evaluation . getValueCategory ( declarator ) ; if ( valueCat == ValueCategory . PRVALUE ) { IValue v = evaluation . getValue ( declarator ) ; if ( v != null && v . numberValue ( ) != null ) { type = new CPPBasicType ( Kind . eInt , 0 ) ; } }
} return recreate ( ref , newLeaf , hasVersioning ( ) ) ; } Ref doPeel ( Ref leaf ) throws MissingObjectException , IOException { try ( RevWalk rw = new RevWalk ( repository ) ) { RevObject obj = rw . parseAny ( leaf . getObjectId ( ) ) ; if ( obj instanceof RevTag ) { return new ObjectIdRef . PeeledTag ( leaf . getStorage ( ) , leaf . getName ( ) , leaf . getObjectId ( ) , rw . peel ( obj ) . copy ( ) , hasVersioning ( ) ? leaf . getUpdateIndex ( ) < |startfocus| > : Ref . UNDEFINED_UPDATE_INDEX ) ; < |endfocus| > } else { return new ObjectIdRef . PeeledNonTag ( leaf . getStorage ( ) , leaf . getName ( ) , leaf . getObjectId ( ) , hasVersioning ( ) ? leaf . getUpdateIndex ( ) : Ref . UNDEFINED_UPDATE_INDEX ) ; } } } static Ref recreate ( Ref old , Ref leaf , boolean hasVersioning ) { if ( old . isSymbolic ( ) ) { Ref dst = recreate ( old . getTarget ( ) , leaf , hasVersioning ) ; return new SymbolicRef ( old . getName ( ) , dst , hasVersioning ? old . getUpdateIndex ( ) : Ref . UNDEFINED_UPDATE_INDEX ) ; } else { return new ObjectIdRef . PeeledNonTag ( old . getStorage ( ) , old . getName ( ) , leaf . getObjectId ( ) , hasVersioning ? old . getUpdateIndex ( ) : Ref . UNDEFINED_UPDATE_INDEX ) ; } } }
public abstract class TmfAbstractToolTipHandler { private static final int MOUSE_DEADZONE = 5 ; private static final int OFFSET = 16 ; private Composite fTipComposite ; private Shell fTipShell ; private Rectangle fInitialDeadzone ; /* * * Important note : this is being added to a display filter , this may leak , * make sure it is removed when not needed . */ private final Listener fListener = this : : disposeIfExited ; private final Listener fFocusLostListener = event - > { Shell tipShell = fTipShell ; < |startfocus| > if ( tipShell != null ) { < |endfocus| > tipShell . dispose ( ) ; } } ; /* * * Dispose the shell if we exit the range . * * @param e * The event which occurred */ private void disposeIfExited ( Event e ) { if ( ! ( e . widget instanceof Control ) ) { return ; } Control control = ( Control ) e . widget ; if ( control != null && ! control . isDisposed ( ) ) { Point pt = control . toDisplay ( e . x , e . y ) ; Shell tipShell = fTipShell ;
private static final int MOUSE_DEADZONE = 5 ; private static final int OFFSET = 16 ; private Composite fTipComposite ; private Shell fTipShell ; private Rectangle fInitialDeadzone ; /* * * Important note : this is being added to a display filter , this may leak , * make sure it is removed when not needed . */ private final Listener fListener = this : : disposeIfExited ; private final Listener fFocusLostListener = event - > { Shell tipShell = fTipShell ; < |startfocus| > if ( tipShell != null ) { < |endfocus| > tipShell . dispose ( ) ; } } ; /* * * Dispose the shell if we exit the range . * * @param e * The event which occurred */ private void disposeIfExited ( Event e ) { if ( ! ( e . widget instanceof Control ) ) { return ; } Control control = ( Control ) e . widget ; if ( control != null && ! control . isDisposed ( ) ) { Point pt = control . toDisplay ( e . x , e . y ) ; Shell tipShell = fTipShell ;
} return result ; } /* * * Sets the completion proposal categories which are excluded from the * default proposal list and reloads the registry . * * @param categories the array with the IDs of the excluded categories * @see #CODEASSIST_EXCLUDED_CATEGORIES * @since 3 . 4 */ public static void setExcludedCompletionProposalCategories ( String [ ] categories ) { Assert . isLegal ( categories != null ) ; StringBuilder buf = new StringBuilder ( 50 * categories . length ) ; < |startfocus| > for ( String category : categories ) { buf . append ( category ) ; < |endfocus| > buf . append ( '\0' ) ; } getPreferenceStore ( ) . setValue ( CODEASSIST_EXCLUDED_CATEGORIES , buf . toString ( ) ) ; CompletionProposalComputerRegistry . getDefault ( ) . reload ( ) ; } /* * * Returns the value for the given key in the given context . * @param key The preference key * @param project The current context or < code > null </ code > if no context is available and the * workspace setting should be taken . Note that passing < code > null </ code > should * be avoided .
public boolean visit ( ConstructorInvocation constructorInvocation ) { List < ? > arguments = constructorInvocation . arguments ( ) ; if ( ! arguments . isEmpty ( ) ) { IMethodBinding constructorBinding = constructorInvocation . resolveConstructorBinding ( ) ; < |startfocus| > IMethod method = resolveMethodBinding ( constructorBinding ) ; collectParameterNamesCodeMinings ( method , arguments , constructorBinding . isVarargs ( ) ) ; < |endfocus| > } return super . visit ( constructorInvocation ) ;
public boolean visit ( MethodInvocation methodInvocation ) { List < ? > arguments = methodInvocation . arguments ( ) ; if ( ! arguments . isEmpty ( ) ) { IMethodBinding methodBinding = methodInvocation . resolveMethodBinding ( ) ; < |startfocus| > IMethod method = resolveMethodBinding ( methodBinding ) ; collectParameterNamesCodeMinings ( method , arguments , methodBinding != null && methodBinding . isVarargs ( ) ) ; < |endfocus| > } return super . visit ( methodInvocation ) ;
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * * Copyright ( c ) 2010 - 2019 , Tamas Szabo , itemis AG , Gabor Bergmann , IncQuery Labs Ltd . * This program and the accompanying materials are made available under the * terms of the Eclipse Public License v . 2 . 0 which is available at * http :/ / www . eclipse . org / legal / epl - v20 . html . * * SPDX - License - Identifier : EPL - 2 . 0 ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . viatra . query . runtime . matchers . memories ; /* * < |startfocus| > * Represents a replacement between timestamps . * Either old or new can be null , but not at the same time . < |endfocus| > * * @author Tamas Szabo */ public class TimestampReplacement < Timestamp extends Comparable < Timestamp > > { public final Timestamp oldValue ; public final Timestamp newValue ; public TimestampReplacement ( final Timestamp oldValue , final Timestamp newValue ) { if ( oldValue == null && newValue == null ) { throw new IllegalArgumentException ( "Old and new cannot be both null at the same time ! " ) ; } this . oldValue = oldValue ; this . newValue = newValue ; } }
* This program and the accompanying materials are made available under the * terms of the Eclipse Public License v . 2 . 0 which is available at * http :/ / www . eclipse . org / legal / epl - v20 . html . * * SPDX - License - Identifier : EPL - 2 . 0 ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . viatra . query . runtime . matchers . memories ; /* * < |startfocus| > * Represents that a replacement between timestamps . * Either old or new can be null , but not at the same time . < |endfocus| > * * @author Tamas Szabo */ public class TimestampReplacement < Timestamp extends Comparable < Timestamp > > { public final Timestamp oldValue ; public final Timestamp newValue ; public TimestampReplacement ( final Timestamp oldValue , final Timestamp newValue ) { if ( oldValue == null && newValue == null ) { throw new IllegalArgumentException ( "Old and new cannot be both null at the same time ! " ) ; } this . oldValue = oldValue ; this . newValue = newValue ; } }
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * * Copyright ( c ) 2019 CEA LIST and others . * * All rights reserved . This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * CEA LIST - Initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . papyrus . model2doc . core . generatorconfiguration . operations ; import org . eclipse . emf . common . util . URI ; import org . eclipse . osgi . util . NLS ; import org . eclipse . papyrus . model2doc . core . generatorconfiguration . DefaultDocumentGeneratorConfiguration ; import org . eclipse . papyrus . model2doc . core . generatorconfiguration . DefaultDocumentStructureGeneratorConfiguration ; import org . eclipse . papyrus . model2doc . core . generatorconfiguration . internal . Activator ; /* * * utility class for the operations of GeneratorConfiguration metamodel */ public class GeneratorConfigurationOperations { /* * * * @param generatorConfiguration * a generatorConfiguration element * @param uriKind * the kind of expected URI * @param fileExtension
* * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * CEA LIST - Initial API and implementation * ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . papyrus . model2doc . core . generatorconfiguration . operations ; import org . eclipse . emf . common . util . URI ; import org . eclipse . osgi . util . NLS ; import org . eclipse . papyrus . model2doc . core . generatorconfiguration . DefaultDocumentGeneratorConfiguration ; import org . eclipse . papyrus . model2doc . core . generatorconfiguration . DefaultDocumentStructureGeneratorConfiguration ; import org . eclipse . papyrus . model2doc . core . generatorconfiguration . internal . Activator ; /* * < |startfocus| > * utility class for the operations of GeneratorConfiguration metamodel < |endfocus| > */ public class GeneratorConfigurationOperations { /* * * * @param generatorConfiguration * a generatorConfiguration element * @param uriKind * the kind of expected URI * @param fileExtension * the extension file * @return * the path of the file build from the paramaters */ public static final String getDocumentStructureFileEcoreURI ( final DefaultDocumentStructureGeneratorConfiguration generatorConfiguration , final String fileExtension ) { final String folderName = generatorConfiguration . getStructureFolder ( ) ; final String documentName = generatorConfiguration . getDocumentName ( ) ;
return newURI . toString ( ) ; } if ( false == uri . isPlatform ( ) ) { // we convert a local URI as platform resource URI final String projectName = generatorConfiguration . eResource ( ) . getURI ( ) . segment ( 1 ) ; uri = URI . createPlatformResourceURI ( projectName , true ) . appendSegment ( folderName ) ; } if ( uri . isPlatform ( ) ) { if ( uri . isPlatformPlugin ( ) ) { < |startfocus| > Activator . log . warn ( NLS . bind ( "The path { 0 } must not be a platform path" , uri . toString ( ) ) ) ; < |endfocus| > return null ; } return uri . appendSegment ( documentName ) . appendFileExtension ( fileExtension ) . toString ( ) ; } return null ; } /* * * TODO : check if used ! * * @param configuration * @param fileExtension * @return */ public static final String getDocumentFileOSURI ( final DefaultDocumentGeneratorConfiguration configuration , final String fileExtension ) { final String folderName = configuration . getDocumentFolder ( ) ; final String documentName = configuration . getDocumentName ( ) ; URI uri = URI . createURI ( folderName ) ;
return newURI . toString ( ) ; } if ( false == uri . isPlatform ( ) ) { // we convert a local URI as platform resource URI final String projectName = configuration . eResource ( ) . getURI ( ) . segment ( 1 ) ; uri = URI . createPlatformResourceURI ( projectName , true ) . appendSegment ( folderName ) ; } if ( uri . isPlatform ( ) ) { if ( uri . isPlatformPlugin ( ) ) { < |startfocus| > Activator . log . warn ( NLS . bind ( "The path { 0 } must not be a platform path" , uri . toString ( ) ) ) ; < |endfocus| > return null ; } uri = uri . appendSegment ( documentName ) . appendFileExtension ( fileExtension ) ; } return null ; } }
private static ITmfTrace fNewExperiment ; // -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- // Test instance maintenance // -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- /* * * Default constructor */ public CtfTmfExperimentTrimmingTest ( ) { // do nothing } /* * * Setup before the test suite * * @throws IOException * failed to load the file */ @BeforeClass public static void beforeClass ( ) throws IOException { SWTBotUtils . initialize ( ) ; /* set up for swtbot */ < |startfocus| > SWTBotPreferences . TIMEOUT = 20000 ; /* 20 second timeout */ < |endfocus| > fLogger . removeAllAppenders ( ) ; fLogger . addAppender ( new NullAppender ( ) ) ; File parentDir = FileUtils . toFile ( FileLocator . toFileURL ( CtfTestTrace . TRACE_EXPERIMENT . getTraceURL ( ) ) ) ; File [ ] traceFiles = parentDir . listFiles ( ) ; ITmfTrace traceValidator = new CtfTmfTrace ( ) ; fBot = new SWTWorkbenchBot ( ) ; SWTBotUtils . createProject ( PROJECT_NAME ) ; int openedTraces = 0 ; for ( File traceFile : traceFiles ) { String absolutePath = traceFile . getAbsolutePath ( ) ; if ( traceValidator . validate ( null , absolutePath ) . isOK ( ) ) { < |startfocus| > SWTBotPreferences . TIMEOUT = 20000 ; /* 20 second timeout */ < |endfocus| >
protected boolean hasJREInClassPath ( IJavaProject javaProject ) { if ( javaProject != null ) { try { IClasspathEntry [ ] oldClasspaths = javaProject . getRawClasspath ( ) ; for ( int i = 0 ; i < oldClasspaths . length ; i ++ ) { if ( isJREContainer ( oldClasspaths [ i ] . getPath ( ) ) ) { return true ; } } } catch ( JavaModelException e ) { < |startfocus| > // TODO Auto - generated catch block e . printStackTrace ( ) ; < |endfocus| > } } return false ;
getRequirementFilter ( symbolicName , versionRange ) ) ; Collection < BundleCapability > matchingBundleCapabilities = fwkWiring . findProviders ( ModuleContainer . createRequirement ( IdentityNamespace . IDENTITY_NAMESPACE , directives , Collections . emptyMap ( ) ) ) ; if ( matchingBundleCapabilities . isEmpty ( ) ) { return null ; } Bundle [ ] results = matchingBundleCapabilities . stream ( ) . map ( c - > c . getRevision ( ) . getBundle ( ) ) // Remove all the bundles that are installed or uninstalled . filter ( bundle - > ( bundle . getState ( ) & ( Bundle . INSTALLED | Bundle . UNINSTALLED ) ) == 0 ) < |startfocus| > . sorted ( ( b1 , b2 ) - > b2 . getVersion ( ) . compareTo ( b1 . getVersion ) ) // highest version first < |endfocus| > . toArray ( Bundle [ ] : : new ) ; return results . length > 0 ? results : null ;
try { XMultiServiceFactory xMultiServiceFactory = odtEditor . getXMultiServiceFactory ( ) ; // create a text table Object obj = xMultiServiceFactory . createInstance ( "com . sun . star . text . TextTable" ) ; // $NON - NLS - 1$ XTextTable textTable = UnoRuntime . queryInterface ( XTextTable . class , obj ) ; // Default background color Object backColor = 0x6AA84F ; // // If defined style then update backColor if ( style != null ) { backColor = style ; } < |startfocus| > if ( numRows > 0 && numCols > 0 ) { < |endfocus| > // Verify if there are row titles if ( table . getRowTitles ( ) != null && ! table . getRowTitles ( ) . isEmpty ( ) ) { // update column counters numCols ++ ; } // Verify if there are column titles if ( table . getColumnTitles ( ) != null ) { // update row counter numRows ++ ; } // Initialize and add table textTable . initialize ( numRows , numCols ) ; addTextContent ( xTextCursor , textTable ) ; endParagraph ( xTextCursor ) ;
/* * * Returns { @code true } if the value of the expression depends on template parameters . */ boolean isValueDependent ( ) ; /* * * Returns { @code true } if the expression is a compile - time constant expression . * * @param point the point of instantiation , determines the scope for name lookups */ boolean isConstantExpression ( ) ; /* * * Return the result of the noexcept - operator applied to the expression . * [ expr . unary . noexcept ] < |startfocus| > * @param inCalledContext TODO < |endfocus| > */ boolean isNoexcept ( boolean inCalledContext ) ; /* * * Returns { @code true } if this expression is equivalent to 'other' for * declaration matching purposes . */ boolean isEquivalentTo ( ICPPEvaluation other ) ; /* * * Returns the type of the expression . * * If the expression evaluates to a function set , a { @code FunctionSetType } is returned . */ IType getType ( ) ; /* * * Returns the value of the expression . */ IValue getValue ( ) ; /* * * Returns the template definition if the expression is a template parameter . */ IBinding getTemplateDefinition ( ) ; /* * * Returns the template parameter if the expression is a template parameter . */ ICPPTemplateParameter getTemplateParameter ( ) ; /* * * Returns the template argument if the expression is a template parameter . */ ICPPTemplateArgument getTemplateArgument ( ) ; /* * * Returns the template parameter position if the expression is a template parameter . */ int getParameterPosition ( ) ; /* * * Returns the template parameter depth if the expression is a template parameter . */ int getParameterDepth ( ) ; /* * * Returns the template parameter value if the expression is a non - type template parameter . */ IValue getNonTypeValue ( ) ; /* * * Returns the template parameter type if the expression is a non - type template parameter . */ IType getNonTypeType ( ) ; /* * * Returns the template parameter value if the expression is a non - type template parameter . */ ICPPTemplateArgument getNonTypeTemplateArgument ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getTemplateArgumentPack ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateParameter getTemplateParameterPack ( ) ; /* * * Returns the template parameter position if the expression is a template parameter pack . */ int getParameterPackOffset ( ) ; /* * * Returns the template parameter depth if the expression is a template parameter pack . */ int getParameterPackSize ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPackExpansion ( int index ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPackExpansion ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPack ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPacks ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPackExpansion ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPackExpansions ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPack ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPacks ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPackExpansion ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPackExpansions ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPack ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPacks ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPackExpansion ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPackExpansions ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPack ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPacks ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPackExpansion ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPackExpansions ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPack ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPacks ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPackExpansion ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPackExpansions ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPack ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPacks ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPackExpansion ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPackExpansions ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPack ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPacks ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPackExpansion ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPackExpansions ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPack ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPacks ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPackExpansion ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPackExpansions ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPack ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPacks ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPackExpansion ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPackExpansions ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPack ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPacks ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPackExpansion ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument [ ] getParameterPackExpansions ( ) ; /* * * Returns the template parameter value if the expression is a template parameter pack . */ ICPPTemplateArgument getParameterPack ( ) ;
public boolean isNoexcept ( boolean inCalledContext ) { < |startfocus| > return true ; < |endfocus| >
public boolean isNoexcept ( boolean inCalledContext ) { < |startfocus| > // TODO Auto - generated method stub return false ; < |endfocus| >
public boolean isNoexcept ( boolean inCalledContext ) { < |startfocus| > assert ! inCalledContext ; < |endfocus| > return true ;
public boolean isNoexcept ( boolean inCalledContext ) { < |startfocus| > assert false : "This should only be called in a dependent context" ; return true ; < |endfocus| >
public boolean isNoexcept ( boolean inCalledContext ) { < |startfocus| > return true ; < |endfocus| >
public boolean isNoexcept ( boolean inCalledContext ) { < |startfocus| > assert false ; < |endfocus| >
private void ensureSize ( int index ) { List < @Nullable IEventDeclaration > list = fEvents ; if ( list instanceof ArrayList ) { if ( index > 50000 ) { fEvents = new SparseList ( fEvents ) ; } ( ( ArrayList < @Nullable IEventDeclaration > ) list ) . ensureCapacity ( index ) ; while ( list . size ( ) <= index ) { list . add ( null ) ; } }
public SparseList ( List < @Nullable IEventDeclaration > events ) { < |startfocus| > for ( int i = 0 ; i < events . size ( ) ; i ++ ) { < |endfocus| > IEventDeclaration event = events . get ( i ) ; if ( event != null ) { add ( i , event ) ; } }
public boolean add ( @Nullable IEventDeclaration e ) { synchronized ( this ) { < |startfocus| > fInnerEvents . put ( fNextAdded , e ) ; fNextAdded ++ ; < |endfocus| > } return true ;
public boolean addAll ( int index , Collection < ? extends @Nullable IEventDeclaration > c ) { int key = index ; < |startfocus| > for ( IEventDeclaration event : c ) { if ( event != null ) { < |endfocus| > add ( key , event ) ; } key ++ ; } return true ;
public void add ( int index , @Nullable IEventDeclaration element ) { < |startfocus| > if ( index > fLastAdded ) { fLastAdded = index ; < |endfocus| > } add ( element ) ;
*/ public class Text extends Scrollable { int tabs , oldStart , oldEnd ; boolean doubleClick , ignoreModify , ignoreVerify , ignoreCharacter , allowPasswordChar ; String message ; int [ ] segments ; int clearSegmentsCount = 0 ; RECT searchRect , cancelRect ; boolean mouseInSearch , mouseInCancel ; static final char LTR_MARK = '\u200e' ; static final char RTL_MARK = '\u200f' ; static final int IDI_SEARCH = 101 ; < |startfocus| > static final int IDI_CANCEL = 102 ; < |endfocus| > static final int SEARCH_ICON_MARGIN = 4 ; /* * * The maximum number of characters that can be entered * into a text widget . * < p > * Note that this value is platform dependent , based upon * the native widget implementation . * </ p > */ public static final int LIMIT ; /* * * The delimiter used by multi - line text widgets . When text * is queried and from the widget , it will be delimited using * this delimiter . */ public static final String DELIMITER ; /* * This code is intentionally commented .
* header until end of trailer . * * @return time in milliseconds spent writing the pack output , from start of * header until end of trailer . The transfer speed can be * approximated by dividing { @link #getTotalBytes ( ) } by this value . */ public long getTimeWriting ( ) { return statistics . timeWriting ; } /* * < |startfocus| > * Get Number of trees traversed in the walk when writing the pack . * < |endfocus| > * @return number of trees traversed in the walk when writing the pack . * @since 5 . 4 */ public long getTreesTraversed ( ) { return statistics . treesTraversed ; } /* * * Get total time spent processing this pack . * * @return total time spent processing this pack . */ public long getTimeTotal ( ) { return statistics . timeCounting + statistics . timeSearchingForReuse + statistics . timeSearchingForSizes + statistics . timeCompressing + statistics . timeWriting ; } /* * * Get the average output speed in terms of bytes - per - second . * < |startfocus| > * @return the average output speed in terms of bytes - per - second . * < |endfocus| > */ public long getAverageBytesPerSecond ( ) { return getTotalBytes ( ) / getTimeTotal ( ) ; } /* * * Get the total number of bytes written to the output stream . * * @return total number of bytes written to the output stream . */ public long getTotalBytes ( ) { return statistics . totalBytes ; } /* * * Get the total number of objects written to the output stream . * * @return total number of objects written to the output stream . */ public long getTotalObjects ( ) { return statistics . totalObjects ; } /* * * Get the total number of deltas written to the output stream . * * @return total number of deltas written to the output stream . */ public long getTotalDeltas ( ) { return statistics . totalDeltas ; } /* * * Get the total number of reused objects written to the output stream . * * @return total number of reused objects written to the output stream . */ public long getTotalReused ( ) { return statistics . totalReused ; } /* * * Get the total number of reused deltas written to the output stream . * * @return total number of reused deltas written to the output stream . */ public long getTotalReusedDeltas ( ) { return statistics . totalReusedDeltas ; } /* * * Get the total number of reused objects that were not found in the * local repository . * * @return total number of reused objects that were not found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were not found in the * local repository . * * @return total number of reused deltas that were not found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedInPack ; } /* * * Get the total number of reused deltas that were found in the * local repository . * * @return total number of reused deltas that were found in the * local repository . */ public long getTotalReusedDeltasInPack ( ) { return statistics . totalReusedDeltasInPack ; } /* * * Get the total number of reused objects that were found in the * local repository . * * @return total number of reused objects that were found in the * local repository . */ public long getTotalReusedInPack ( ) { return statistics . totalReusedIn
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * < |startfocus| > * Copyright ( c ) 2017 Ericsson < |endfocus| > * * All rights reserved . This program and the accompanying materials are * made available under the terms of the Eclipse Public License v1 . 0 which * accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . tracecompass . tmf . ui . viewers ; import org . eclipse . swt . SWT ; import org . eclipse . swt . events . MouseEvent ; import org . eclipse . swt . events . MouseTrackAdapter ; import org . eclipse . swt . graphics . Point ; import org . eclipse . swt . graphics . Rectangle ; import org . eclipse . swt . layout . GridData ; import org . eclipse . swt . layout . GridLayout ; import org . eclipse . swt . widgets . Composite ; import org . eclipse . swt . widgets . Control ; import org . eclipse . swt . widgets . Display ; import org . eclipse . swt . widgets . Event ; import org . eclipse . swt . widgets . Label ; import org . eclipse . swt . widgets . Listener ; import org . eclipse . swt . widgets . Shell ; import org . eclipse . tracecompass . tmf . ui . widgets . timegraph . widgets . TimeGraphTooltipHandler ; /* * * Abstract tool tip handler . * * @since 3 . 2
final Display display = parent . getDisplay ( ) ; if ( fTipShell != null && ! fTipShell . isDisposed ( ) ) { fTipShell . dispose ( ) ; } fTipShell = new Shell ( parent , SWT . ON_TOP | SWT . TOOL ) ; // Deregister display filters on dispose fTipShell . addDisposeListener ( e - > e . display . removeFilter ( SWT . MouseMove , fListener ) ) ; fTipShell . addDisposeListener ( e - > e . display . removeFilter ( SWT . FocusOut , fFocusLostListener ) ) ; fTipShell . addListener ( SWT . Deactivate , e - > { < |startfocus| > if ( fTipShell . isDisposed ( ) ) { < |endfocus| > fTipShell . dispose ( ) ; } } ) ; GridLayout gridLayout = new GridLayout ( ) ; gridLayout . numColumns = 2 ; gridLayout . marginWidth = 2 ; gridLayout . marginHeight = 2 ; fTipShell . setLayout ( gridLayout ) ; fTipShell . setBackground ( display . getSystemColor ( SWT . COLOR_INFO_BACKGROUND ) ) ; fTipComposite = new Composite ( fTipShell , SWT . NONE ) ; fTipComposite . setLayout ( new GridLayout ( 3 , false ) ) ; setupControl ( fTipComposite ) ;
private boolean considerBinding ( IBinding binding , ASTNode node ) { if ( ! ( binding instanceof IVariableBinding ) ) return false ; boolean result = Bindings . equals ( fFieldBinding , ( ( IVariableBinding ) binding ) . getVariableDeclaration ( ) ) ; < |startfocus| > if ( ! result || ( fEncapsulateDeclaringClass && ! fGetter . isEmpty ( ) && ! fSetter . isEmpty ( ) ) ) < |endfocus| > return result ; AbstractTypeDeclaration type = ASTNodes . getParent ( node , AbstractTypeDeclaration . class ) ; if ( type != null ) { ITypeBinding declaringType = type . resolveBinding ( ) ; return ! Bindings . equals ( fDeclaringClassBinding , declaringType ) ; } return true ;
invocation . setName ( ast . newSimpleName ( fSetter ) ) ; if ( receiver != null ) invocation . setExpression ( ( Expression ) fRewriter . createCopyTarget ( receiver ) ) ; invocation . arguments ( ) . add ( argument ) ; if ( " ++ " . equals ( operator ) ) { // $NON - NLS - 1$ argument . setOperator ( InfixExpression . Operator . PLUS ) ; } else if ( " -- " . equals ( operator ) ) { // $NON - NLS - 1$ argument . setOperator ( InfixExpression . Operator . MINUS ) ; } else { Assert . isTrue ( false , "Should not happen" ) ; // $NON - NLS - 1$ } MethodInvocation getter = ast . newMethodInvocation ( ) ; getter . setName ( ast . newSimpleName ( fGetter ) ) ; if ( receiver != null ) getter . setExpression ( ( Expression ) fRewriter . createCopyTarget ( receiver ) ) ; argument . setLeftOperand ( getter ) ; argument . setRightOperand ( ast . newNumberLiteral ( "1" ) ) ; // $NON - NLS - 1$ < |startfocus| > fReferencingSetter = true ; fReferencingGetter = true ; < |endfocus| > return invocation ;
if ( fEncapsulateDeclaringClass ) comment . addSetting ( RefactoringCoreMessages . SelfEncapsulateField_use_accessors ) ; else comment . addSetting ( RefactoringCoreMessages . SelfEncapsulateField_do_not_use_accessors ) ; if ( fGenerateJavadoc ) comment . addSetting ( RefactoringCoreMessages . SelfEncapsulateField_generate_comments ) ; final EncapsulateFieldDescriptor descriptor = RefactoringSignatureDescriptorFactory . createEncapsulateFieldDescriptor ( project , description , comment . asString ( ) , arguments , flags ) ; arguments . put ( JavaRefactoringDescriptorUtil . ATTRIBUTE_INPUT , JavaRefactoringDescriptorUtil . elementToHandle ( project , fField ) ) ; < |startfocus| > arguments . put ( ATTRIBUTE_VISIBILITY , Integer . valueOf ( JdtFlags . getVisibilityCode ( visibility ) ) . toString ( ) ) ; < |endfocus| > arguments . put ( ATTRIBUTE_INSERTION , Integer . valueOf ( fInsertionIndex ) . toString ( ) ) ; if ( fCreateSetter ) { arguments . put ( ATTRIBUTE_SETTER , fSetterName ) ; } if ( fCreateGetter ) { arguments . put ( ATTRIBUTE_GETTER , fGetterName ) ; } arguments . put ( ATTRIBUTE_COMMENTS , Boolean . valueOf ( fGenerateJavadoc ) . toString ( ) ) ; arguments . put ( ATTRIBUTE_DECLARING , Boolean . valueOf ( fEncapsulateDeclaringClass ) . toString ( ) ) ; final DynamicValidationRefactoringChange result = new DynamicValidationRefactoringChange ( descriptor , getName ( ) ) ; TextChange [ ] changes = fChangeManager . getAllChanges ( ) ; pm . beginTask ( NO_NAME , changes . length ) ;
// extern "C" { // void func ( ) ; // } public void testLinkage2_Bug299482 ( ) throws Exception { fOptions . put ( DefaultCodeFormatterConstants . FORMATTER_INSERT_SPACE_BEFORE_OPENING_BRACE_IN_LINKAGE_DECLARATION , DefaultCodeFormatterConstants . FALSE ) ; assertFormatterResult ( ) ; } // extern "C" { // void func ( ) ; // } // extern "C" // { // void func ( ) ; // } public void testLinkage3_Bug299482 ( ) throws Exception { fOptions . put ( DefaultCodeFormatterConstants . FORMATTER_BRACE_POSITION_FOR_LINKAGE_DECLARATION , < |startfocus| > DefaultCodeFormatterConstants . NEXT_LINE ) ; < |endfocus| > } // #define EMPTY1 ( x ) // #define EMPTY2 ( x ) // int main ( ) { // EMPTY1 ( bool x = true ) ; // EMPTY2 ( bool x = true ) ; // return 0 ; // } // #define EMPTY1 ( x ) // #define EMPTY2 ( x ) // int main ( ) { // EMPTY1 ( bool x = true ) ; // EMPTY2 ( bool x = true ) ; // return 0 ; // } public void testEmptyMacros_Bug361768 ( ) throws Exception { assertFormatterResult ( ) ; }
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * < |startfocus| > * Copyright ( c ) 2015 Obeo . < |endfocus| > * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Obeo - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . sirius . tests . sample . component . service ; import java . util . ArrayList ; import java . util . Collection ; import java . util . HashSet ; import java . util . List ; import java . util . function . Predicate ; import org . eclipse . emf . common . notify . Notification ; import org . eclipse . emf . ecore . EObject ; import org . eclipse . gmf . runtime . notation . DrawerStyle ; import org . eclipse . gmf . runtime . notation . Node ; import org . eclipse . gmf . runtime . notation . NotationPackage ; import org . eclipse . sirius . diagram . DDiagram ; import org . eclipse . sirius . diagram . DDiagramElement ; import org . eclipse . sirius . diagram . DNodeContainer ; import org . eclipse . sirius . diagram . business . api . query . EObjectQuery ; import org . eclipse . sirius . diagram . ui . business . api . view . SiriusGMFHelper ; import org . eclipse . sirius . ext . base . Option ;
components . addAll ( component . getReferences2 ( ) ) ; for ( Component child : component . getChildren ( ) ) { components . addAll ( getReference2Hierarchy ( child ) ) ; } return components ; } /* * * A reference is to display if : * < UL > * < LI > the source is not collapsed and the target is not collapsed and there is no "shortest reference" to * display </ LI > * < LI > </ LI > * < LI > </ LI > * </ UL > * < |startfocus| > * @param source < |endfocus| > * @param sourceView * @param targetView * @return */ public boolean isReferenceToDisplay ( Component source , DNodeContainer sourceView , DNodeContainer targetView ) { if ( ! isIndirectlyCollapsed ( sourceView ) && ! isIndirectlyCollapsed ( targetView ) ) { for ( DDiagramElement child : sourceView . getOwnedDiagramElements ( ) ) { if ( child instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child2 : ( ( DNodeContainer ) child ) . getOwnedDiagramElements ( ) ) { if ( child2 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child2 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child3 : ( ( DNodeContainer ) child2 ) . getOwnedDiagramElements ( ) ) { if ( child3 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child3 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child4 : ( ( DNodeContainer ) child3 ) . getOwnedDiagramElements ( ) ) { if ( child4 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child4 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child5 : ( ( DNodeContainer ) child4 ) . getOwnedDiagramElements ( ) ) { if ( child5 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child5 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child6 : ( ( DNodeContainer ) child5 ) . getOwnedDiagramElements ( ) ) { if ( child6 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child6 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child7 : ( ( DNodeContainer ) child6 ) . getOwnedDiagramElements ( ) ) { if ( child7 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child7 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child8 : ( ( DNodeContainer ) child7 ) . getOwnedDiagramElements ( ) ) { if ( child8 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child8 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child9 : ( ( DNodeContainer ) child8 ) . getOwnedDiagramElements ( ) ) { if ( child9 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child9 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child10 : ( ( DNodeContainer ) child9 ) . getOwnedDiagramElements ( ) ) { if ( child10 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child10 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child11 : ( ( DNodeContainer ) child10 ) . getOwnedDiagramElements ( ) ) { if ( child11 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child11 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child12 : ( ( DNodeContainer ) child11 ) . getOwnedDiagramElements ( ) ) { if ( child12 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child12 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child13 : ( ( DNodeContainer ) child12 ) . getOwnedDiagramElements ( ) ) { if ( child13 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child13 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child14 : ( ( DNodeContainer ) child13 ) . getOwnedDiagramElements ( ) ) { if ( child14 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child14 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child15 : ( ( DNodeContainer ) child14 ) . getOwnedDiagramElements ( ) ) { if ( child15 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child15 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child16 : ( ( DNodeContainer ) child15 ) . getOwnedDiagramElements ( ) ) { if ( child16 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child16 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child17 : ( ( DNodeContainer ) child16 ) . getOwnedDiagramElements ( ) ) { if ( child17 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child17 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child18 : ( ( DNodeContainer ) child17 ) . getOwnedDiagramElements ( ) ) { if ( child18 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child18 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child19 : ( ( DNodeContainer ) child18 ) . getOwnedDiagramElements ( ) ) { if ( child19 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child19 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child20 : ( ( DNodeContainer ) child19 ) . getOwnedDiagramElements ( ) ) { if ( child20 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child20 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child21 : ( ( DNodeContainer ) child20 ) . getOwnedDiagramElements ( ) ) { if ( child21 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child21 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child22 : ( ( DNodeContainer ) child21 ) . getOwnedDiagramElements ( ) ) { if ( child22 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child22 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child23 : ( ( DNodeContainer ) child22 ) . getOwnedDiagramElements ( ) ) { if ( child23 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child23 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child24 : ( ( DNodeContainer ) child23 ) . getOwnedDiagramElements ( ) ) { if ( child24 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child24 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child25 : ( ( DNodeContainer ) child24 ) . getOwnedDiagramElements ( ) ) { if ( child25 instanceof DNodeContainer ) { if ( ( ( DNodeContainer ) child25 ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) { for ( DDiagramElement child26 : ( ( DNodeContainer ) child25 ) . getOwnedDiagramElements ( ) ) { if ( child26 instanceof DNode
if ( isReferenceDisplayByChild ( ( Component ) child2 . getTarget ( ) , ( DNodeContainer ) child2 , targetView ) ) { return true ; } } } } } return true ; } return false ; } protected boolean isIndirectlyCollapsed ( DNodeContainer container ) { if ( isContainerCollapsed ( container ) ) { return true ; } else if ( container . eContainer ( ) instanceof DNodeContainer && isContainerCollapsed ( ( DNodeContainer ) container . eContainer ( ) ) ) { return true ; } else { return false ; } < |startfocus| > } < |endfocus| > protected boolean isContainerCollapsed ( DNodeContainer container ) { Node gmfNode = SiriusGMFHelper . getGmfNode ( container ) ; if ( gmfNode != null ) { for ( Object subNode : gmfNode . getChildren ( ) ) { if ( subNode instanceof Node ) { for ( Object style : ( ( Node ) subNode ) . getStyles ( ) ) { if ( style instanceof DrawerStyle ) { return ( ( DrawerStyle ) style ) . isCollapsed ( ) ; } } } } } return false ; } private void appendChildren ( Component component , Collection < Component > allChildren ) {
SWTBotGefEditPart parentEdgeTargetEditPart = editor . getEditPart ( "DC . 2 . 1" , AbstractDiagramElementContainerEditPart . class ) ; DEdgeEditPart edgeEditPart = ( DEdgeEditPart ) ( ( AbstractDiagramElementContainerEditPart ) edgeSourceEditPart . part ( ) ) . getSourceConnections ( ) . get ( 0 ) ; assertTrue ( "The edge should be visible after diagram opening . " , edgeEditPart . getFigure ( ) . isVisible ( ) ) ; collapseOrExpandContainer ( parentEdgeSourceEditPart ) ; < |startfocus| > // Check that original edge is no longer visible but is always here assertFalse ( "The edge should be hidden after collapsing the container of the target of the edge . " , edgeEditPart . getFigure ( ) . isVisible ( ) ) ; assertEquals ( "The edge already exists , even if it is not visible . " , 1 , ( ( AbstractDiagramElementContainerEditPart ) edgeSourceEditPart . part ( ) ) . getSourceConnections ( ) . size ( ) ) ; < |endfocus| > // Check that no other edge appears ( because the collapse notification has not yet been registered ) assertEquals ( "No edge from the collapsed container should appear because the collapse notification has not yet been registered . " , 0 ,
private void collapseOrExpandContainer ( SWTBotGefEditPart container ) { ICondition editPartResizedCondition = new CheckEditPartResized ( container ) ; // Select the region contained in the container AbstractDiagramElementContainerEditPart part = ( AbstractDiagramElementContainerEditPart ) container . part ( ) ; GraphicalHelper . getAbsoluteBoundsIn100Percent ( part ) ; Point top = GraphicalHelper . getAbsoluteBoundsIn100Percent ( part ) . getTop ( ) ; editor . click ( top . getTranslated ( 0 , 40 ) ) ; // Collapse the region // Add a wait condition to have the collapse button displayed and click on it < |startfocus| > bot . waitUntil ( new ICondition ( ) { < |endfocus| > @Override public boolean test ( ) throws Exception { IFigure handleLayer = LayerManager . Helper . find ( part ) . getLayer ( LayerConstants . HANDLE_LAYER ) ; Point toggleFigureLocation ; if ( handleLayer != null ) { for ( Object figure : handleLayer . getChildren ( ) ) { if ( figure instanceof CompartmentCollapseHandle ) { toggleFigureLocation = ( ( CompartmentCollapseHandle ) figure ) . getLocation ( ) ; if ( toggleFigureLocation . x != 0 && toggleFigureLocation . y != 0 ) { // Use the center of the figure and click on it return true ; } } } } return false ; }
private Repository remoteRepository ; private URIish remoteURI ; @Override @Before public void setUp ( ) throws Exception { super . setUp ( ) ; final TestRepository < Repository > src = createTestRepository ( ) ; final String srcName = src . getRepository ( ) . getDirectory ( ) . getName ( ) ; ServletContextHandler app = server . addContext ( " / git" ) ; GitServlet gs = new GitServlet ( ) ; gs . setRepositoryResolver ( ( HttpServletRequest req , String name ) - > { < |startfocus| > if ( ! name . equals ( srcName ) ) { throw new RepositoryNotFoundException ( name ) ; } final Repository db = src . getRepository ( ) ; db . incrementOpen ( ) ; return db ; } ) ; < |endfocus| > gs . setReceivePackFactory ( new DefaultReceivePackFactory ( ) { @Override public ReceivePack create ( HttpServletRequest req , Repository db ) throws ServiceNotEnabledException , ServiceNotAuthorizedException { ReceivePack rp = super . create ( req , db ) ; rp . sendError ( "message line 1" ) ; rp . sendError ( "no soup for you ! " ) ; rp . sendError ( "come back next year ! " ) ; return rp ; } } ) ; app . addServlet ( new ServletHolder ( gs ) , " /* " ) ;
private URIish remoteURI ; @Override @Before public void setUp ( ) throws Exception { 	super . setUp ( ) ; 	final TestRepository < Repository > src = createTestRepository ( ) ; 	final String srcName = src . getRepository ( ) . getDirectory ( ) . getName ( ) ; 	ServletContextHandler app = server . addContext ( " / git" ) ; 	GitServlet gs = new GitServlet ( ) ; 	gs . setRepositoryResolver ( ( HttpServletRequest req , String name ) - > { 		 < |startfocus| > 		if ( ! name . equals ( srcName ) ) 			throw new RepositoryNotFoundException ( name ) ; 		final Repository db = src . getRepository ( ) ; 		db . incrementOpen ( ) ; 		return db ; 	 } ) ; 	 < |endfocus| > 	gs . setReceivePackFactory ( new DefaultReceivePackFactory ( ) { 		@Override 		public ReceivePack create ( HttpServletRequest req , Repository db ) throws ServiceNotEnabledException , ServiceNotAuthorizedException { 			ReceivePack rp = super . create ( req , db ) ; 			rp . sendError ( "message line 1" ) ; 			rp . sendError ( "no soup for you ! " ) ; 			rp . sendError ( "come back next year ! " ) ; 			return rp ; 		 } 	 } ) ; 	app . addServlet ( new ServletHolder ( gs ) , " /* " ) ; 	server . setUp ( ) ; }
private void verifyObjectsOrder ( ObjectId objectsOrder [ ] ) { final List < PackIndex . MutableEntry > entries = new ArrayList < > ( ) ; for ( MutableEntry me : pack ) { entries . add ( me . cloneEntry ( ) ) ; } < |startfocus| > Collections . sort ( entries , ( MutableEntry o1 , MutableEntry o2 ) - > Long . signum ( o1 . getOffset ( ) - o2 . getOffset ( ) ) ) ; < |endfocus| > int i = 0 ; for ( MutableEntry me : entries ) { assertEquals ( objectsOrder [ i ++ ] . toObjectId ( ) , me . toObjectId ( ) ) ; }
public Optional < T > getFirstResult ( ) { < |startfocus| > Collection < T > list = getResult ( ) ; if ( list != null ) { return list . stream ( ) . findFirst ( ) ; } return Optional . empty ( ) ; < |endfocus| >
protected void setResult ( Collection < T > newUserSelection ) { < |startfocus| > result = newUserSelection ; < |endfocus| >
if ( name1 == null ) { name1 = "" ; // $NON - NLS - 1$ } if ( name2 == null ) { name2 = "" ; // $NON - NLS - 1$ } return coll . compare ( name1 , name2 ) ; } } ) ; // Find primary feature for ( AboutInfo feature : features ) { if ( feature . getFeatureId ( ) . equals ( primaryFeatureId ) ) { setInitialSelection ( feature ) ; return ; } } < |startfocus| > < |endfocus| >
* selection ( via < code > getResult </ code > ) after completion . * < p > * Clients may subclass this dialog to inherit its selection facilities . * </ p > * * @param < T > * which declares the type of the elements in the * { @link AbstractSelectionDialog } . * @since 3 . 11 * */ public abstract class AbstractSelectionDialog < T > extends TrayDialog { // the final collection of selected elements < |startfocus| > private Collection < T > result ; < |endfocus| > // a list of the initially - selected elements private List < T > initialSelection ; // title of dialog private String title ; // message to show user private String message = "" ; // $NON - NLS - 1$ // dialog bounds strategy private int dialogBoundsStrategy = Dialog . DIALOG_PERSISTLOCATION | Dialog . DIALOG_PERSISTSIZE ; // dialog settings for storing bounds private IDialogSettings dialogBoundsSettings = null ; /* * * Creates a dialog instance . * * @param parentShell * the parent shell */ protected AbstractSelectionDialog ( Shell parentShell ) { super ( parentShell ) ; }
< |startfocus| > public Optional < T > getFirstResult ( ) { < |endfocus| > Collection < T > list = getResult ( ) ; if ( list == null ) { return Optional . empty ( ) ; } Iterator < T > iterator = list . iterator ( ) ; if ( iterator . hasNext ( ) ) { return Optional . of ( iterator . next ( ) ) ; } return Optional . empty ( ) ;
protected void setResult ( Collection < T > newUserSelection ) { if ( newUserSelection == null ) { < |startfocus| > result = newUserSelection ; < |endfocus| > } else { result = newUserSelection ; }
protected void setResult ( T . . . newUserSelection ) { if ( newUserSelection == null ) { < |startfocus| > result = null ; < |endfocus| > } else { result = Arrays . asList ( newUserSelection ) ; }
import org . eclipse . jgit . lib . Constants ; import org . eclipse . jgit . lib . NullProgressMonitor ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . junit . Test ; import org . junit . runner . RunWith ; import org . junit . runners . Parameterized ; import org . junit . runners . Parameterized . Parameters ; import org . junit . runners . Parameterized . Parameter ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; @RunWith ( Parameterized . class ) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats ; < |startfocus| > < |endfocus| > @Parameters ( name = "core . trustfolderstat = { 0 } " ) public static Iterable < ? extends Object > data ( ) { return Arrays . asList ( true , false ) ; } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory ( ) throws Exception { ExecutorService e = Executors . newCachedThreadPool ( ) ; for ( int i = 0 ; i < 100 ; ++ i ) { ObjectDirectory dir = createBareRepository ( ) . getObjectDatabase ( ) ; for ( Future f : e . invokeAll ( blobInsertersForTheSameFanOutDir ( dir ) ) ) { f . get ( ) ; } } } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory ( ) throws Exception { ExecutorService e = Executors . newCachedThreadPool ( ) ; for ( int i = 0 ; i < 100 ; ++ i ) { ObjectDirectory dir = createBareRepository ( ) . getObjectDatabase ( ) ; for ( Future f : e . invokeAll ( blobInsertersForTheSameFanOutDir ( dir ) ) ) { f . get ( ) ; } } }
ObjectDirectory dir = createBareRepository ( ) . getObjectDatabase ( ) ; for ( Future f : e . invokeAll ( blobInsertersForTheSameFanOutDir ( dir ) ) ) { f . get ( ) ; } } } @Test public void testShouldNotSearchPacksAgainTheSecondTime ( ) throws Exception { FileRepository bareRepository = newTestRepositoryWithOnePackfile ( ) ; ObjectDirectory dir = bareRepository . getObjectDatabase ( ) ; assertTrue ( dir . searchPacksAgain ( dir . packList . get ( ) ) ) ; < |startfocus| > // Make sure that the modified and read timestamps are different so that a full < |endfocus| > // file snapshot check is performed Thread . sleep ( 3000L ) ; assertFalse ( dir . searchPacksAgain ( dir . packList . get ( ) ) ) ; } private FileRepository newTestRepositoryWithOnePackfile ( ) throws Exception { FileRepository repository = createBareRepository ( ) ; TestRepository < FileRepository > testRepository = new TestRepository ( repository ) ; testRepository . commit ( ) ; testRepository . packAndPrune ( ) ; FileBasedConfig repoConfig = repository . getConfig ( ) ; repoConfig . setBoolean ( ConfigConstants . CONFIG_CORE_SECTION , null , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , trustFolderStats ) ; repoConfig . save ( ) ; return repository ; } private Collection < Callable < ObjectId > > blobInsertersForTheSameFanOutDir (
assertNotNull ( fIterator ) ; assertEquals ( fIterator , fIterator ) ; try ( CtfIterator obj = ( CtfIterator ) fTrace . createIterator ( ) ; ) { assertNotNull ( obj ) ; assertNotEquals ( fIterator , obj ) ; CtfLocation ctfLocation1 = new CtfLocation ( new CtfLocationInfo ( 1 , 0 ) ) ; obj . setLocation ( ctfLocation1 ) ; obj . increaseRank ( ) ; assertEquals ( fIterator , obj ) ; } CtfTmfTrace trace = CtfTmfTestTraceUtils . getTrace ( CtfTestTrace . FUNKY_TRACE ) ; assertNotNull ( trace ) ; < |startfocus| > try ( CtfIterator funky = ( CtfIterator ) trace . createIterator ( ) ) { < |endfocus| > assertNotEquals ( fIterator , funky ) ; } try ( CtfIterator iter = ( CtfIterator ) fTrace . createIterator ( ) ; ) { CTFTrace otherTrace = new CTFTrace ( fTrace . getPath ( ) ) ; try ( CTFTraceReader tr = new CTFTraceReader ( otherTrace ) ) { assertNotEquals ( iter , tr ) ; } } trace . dispose ( ) ; try ( CtfIterator iter1 = ( CtfIterator ) fTrace . createIterator ( ) ; CtfIterator iter2 = ( CtfIterator ) fTrace . createIterator ( ) ) { assertEquals ( iter1 , iter2 ) ; iter2 . setRank ( 2 ) ; assertNotEquals ( iter1 , iter2 ) ; } } /* *
assertNotNull ( obj ) ; assertNotEquals ( fIterator , obj ) ; CtfLocation ctfLocation1 = new CtfLocation ( new CtfLocationInfo ( 1 , 0 ) ) ; obj . setLocation ( ctfLocation1 ) ; obj . increaseRank ( ) ; assertEquals ( fIterator , obj ) ; } CtfTmfTrace trace = CtfTmfTestTraceUtils . getTrace ( CtfTestTrace . FUNKY_TRACE ) ; assertNotNull ( trace ) ; try ( CtfIterator funky = ( CtfIterator ) trace . createIterator ( ) ) { assertNotEquals ( fIterator , funky ) ; } < |startfocus| > try ( CtfIterator iter = ( CtfIterator ) fTrace . createIterator ( ) ; ) { < |endfocus| > CTFTrace otherTrace = new CTFTrace ( fTrace . getPath ( ) ) ; try ( CTFTraceReader tr = new CTFTraceReader ( otherTrace ) ) { assertNotEquals ( iter , tr ) ; } } trace . dispose ( ) ; try ( CtfIterator iter1 = ( CtfIterator ) fTrace . createIterator ( ) ; CtfIterator iter2 = ( CtfIterator ) fTrace . createIterator ( ) ) { assertEquals ( iter1 , iter2 ) ; iter2 . setRank ( 2 ) ; assertNotEquals ( iter1 , iter2 ) ; } } /* * * Run the boolean equals ( Object ) method test . Compare with an empty object . */ @Test public void testEquals_empty ( ) {
assertNotNull ( trace ) ; try ( CtfIterator funky = ( CtfIterator ) trace . createIterator ( ) ) { assertNotEquals ( fIterator , funky ) ; } try ( CtfIterator iter = ( CtfIterator ) fTrace . createIterator ( ) ; ) { CTFTrace otherTrace = new CTFTrace ( fTrace . getPath ( ) ) ; try ( CTFTraceReader tr = new CTFTraceReader ( otherTrace ) ) { assertNotEquals ( iter , tr ) ; } } trace . dispose ( ) ; < |startfocus| > try ( CtfIterator iter1 = ( CtfIterator ) fTrace . createIterator ( ) ; CtfIterator iter2 = ( CtfIterator ) fTrace . createIterator ( ) ) { < |endfocus| > assertEquals ( iter1 , iter2 ) ; iter2 . setRank ( 2 ) ; assertNotEquals ( iter1 , iter2 ) ; } } /* * * Run the boolean equals ( Object ) method test . Compare with an empty object . */ @Test public void testEquals_empty ( ) { assertNotEquals ( new Object ( ) , fIterator ) ; } /* * * Run the CtfTmfTrace getCtfTmfTrace ( ) method test . */ @Test public void testGetCtfTmfTrace ( ) { CtfTmfTrace result = fIterator . getCtfTmfTrace ( ) ; assertNotNull ( result ) ; } /* *
// if ret == true , then currentEvent is non - null if ( seekToTimestamp >= Objects . requireNonNull ( currentEvent ) . getTimestamp ( ) . getValue ( ) ) { index ++ ; } else { break ; } ret = advance ( ) ; previousEvent = currentEvent ; currentEvent = getCurrentEvent ( ) ; } /* Update the current location accordingly */ if ( ret ) { < |startfocus| > fCurLocation = new CtfLocation ( new CtfLocationInfo ( Objects . requireNonNull ( currentEvent ) . getTimestamp ( ) . getValue ( ) , index ) ) ; < |endfocus| > } else { fCurLocation = NULL_LOCATION ; } return ret ;
* STRICT LIABILITY , OR TORT ( INCLUDING NEGLIGENCE OR OTHERWISE ) * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE , EVEN IF * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE . */ package org . eclipse . jgit . internal . storage . file ; import java . util . Arrays ; import java . util . Collection ; import java . util . Collections ; import java . util . concurrent . Callable ; import java . util . concurrent . ExecutorService ; import java . util . concurrent . Executors ; import java . util . concurrent . Future ; < |startfocus| > import org . eclipse . jgit . internal . storage . pack . PackWriter ; < |endfocus| > import org . eclipse . jgit . junit . RepositoryTestCase ; import org . eclipse . jgit . junit . TestRepository ; import org . eclipse . jgit . lib . ConfigConstants ; import org . eclipse . jgit . lib . Constants ; import org . eclipse . jgit . lib . NullProgressMonitor ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . junit . Test ; import org . junit . runner . RunWith ; import org . junit . runners . Parameterized ; import org . junit . runners . Parameterized . Parameters ; import org . junit . runners . Parameterized . Parameter ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; @RunWith ( Parameterized . class ) public class ObjectDirectoryTest extends RepositoryTestCase {
package org . eclipse . jgit . internal . storage . file ; import java . util . Arrays ; import java . util . Collection ; import java . util . Collections ; import java . util . concurrent . Callable ; import java . util . concurrent . ExecutorService ; import java . util . concurrent . Executors ; import java . util . concurrent . Future ; import org . eclipse . jgit . internal . storage . pack . PackWriter ; import org . eclipse . jgit . junit . RepositoryTestCase ; import org . eclipse . jgit . junit . TestRepository ; import org . eclipse . jgit . lib . ConfigConstants ; import org . eclipse . jgit . lib . Constants ; < |startfocus| > import org . eclipse . jgit . lib . NullProgressMonitor ; < |endfocus| > import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . junit . Test ; import org . junit . runner . RunWith ; import org . junit . runners . Parameterized ; import org . junit . runners . Parameterized . Parameters ; import org . junit . runners . Parameterized . Parameter ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; @RunWith ( Parameterized . class ) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats ; @Parameters ( name = "core . trustfolderstat = { 0 } " ) public static Iterable < ? extends Object > data ( ) { return Arrays . asList ( true , false ) ;
import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; import java . util . Arrays ; import java . util . concurrent . ExecutorService ; import java . util . concurrent . Executors ; import org . eclipse . jgit . junit . RepositoryTestCase ; import org . eclipse . jgit . junit . TestRepository ; import org . eclipse . jgit . lib . ConfigConstants ; import org . eclipse . jgit . lib . Constants ; import org . eclipse . jgit . lib . NullProgressMonitor ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . junit . Test ; import org . junit . runner . RunWith ; import org . junit . runners . Parameterized ; import org . junit . runners . Parameterized . Parameter ; import org . junit . runners . Parameterized . Parameters ; @RunWith ( Parameterized . class ) public class ObjectDirectoryTest extends RepositoryTestCase { 	@Parameter 	public Boolean trustFolderStats ; 	@Parameters ( name = "core . trustfolderstat = { 0 } " ) 	public static Iterable < ? extends Object > data ( ) { 		return Arrays . asList ( true , false ) ; 	 } 	@Test 	public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory ( ) 			throws Exception { 		ExecutorService e = Executors . newCachedThreadPool ( ) ; 		for ( int i = 0 ; i < 100 ; ++ i ) { 			ObjectDirectory dir = createBareRepository ( ) . getObjectDatabase ( ) ;
import org . junit . Test ; import org . junit . runner . RunWith ; import org . junit . runners . Parameterized ; import org . junit . runners . Parameterized . Parameters ; import org . junit . runners . Parameterized . Parameter ; import static org . junit . Assert . assertFalse ; import static org . junit . Assert . assertTrue ; @RunWith ( Parameterized . class ) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats ; @Parameters ( name = "core . trustfolderstat = { 0 } " ) public static Iterable < ? extends Object > data ( ) { < |startfocus| > return Arrays . asList ( Boolean . TRUE , Boolean . FALSE ) ; < |endfocus| > } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory ( ) throws Exception { ExecutorService e = Executors . newCachedThreadPool ( ) ; for ( int i = 0 ; i < 100 ; ++ i ) { ObjectDirectory dir = createBareRepository ( ) . getObjectDatabase ( ) ; for ( Future f : e . invokeAll ( blobInsertersForTheSameFanOutDir ( dir ) ) ) { f . get ( ) ; } } } @Test public void testShouldNotSearchPacksAgainTheSecondTime ( ) throws Exception { FileRepository bareRepository = newTestRepositoryWithOnePackfile ( ) ; ObjectDirectory dir = bareRepository . getObjectDatabase ( ) ;
FileRepository bareRepository = newTestRepositoryWithOnePackfile ( ) ; ObjectDirectory dir = bareRepository . getObjectDatabase ( ) ; assertTrue ( dir . searchPacksAgain ( dir . packList . get ( ) ) ) ; // Make sure that the modified and read timestamps so that a full // file snapshot check is performed Thread . sleep ( 3000L ) ; assertFalse ( dir . searchPacksAgain ( dir . packList . get ( ) ) ) ; } private FileRepository newTestRepositoryWithOnePackfile ( ) throws Exception { FileRepository repository = createBareRepository ( ) ; < |startfocus| > TestRepository < FileRepository > testRepository = new TestRepository < FileRepository > ( repository ) ; < |endfocus| > testRepository . commit ( ) ; testRepository . packAndPrune ( ) ; FileBasedConfig repoConfig = repository . getConfig ( ) ; repoConfig . setBoolean ( ConfigConstants . CONFIG_CORE_SECTION , null , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , trustFolderStats ) ; repoConfig . save ( ) ; return repository ; } private Collection < Callable < ObjectId > > blobInsertersForTheSameFanOutDir ( final ObjectDirectory dir ) { Callable < ObjectId > callable = new Callable < ObjectId > ( ) { public ObjectId call ( ) throws Exception { return dir . newInserter ( ) . insert ( Constants . OBJ_BLOB , new byte [ 0 ] ) ; } } ;
// Copyright ( C ) 2009 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . git ; import static org . junit . Assert . assertFalse ; import com . google . gerrit . reviewdb . client . Project ; import com . google . gerrit . server . config . ConfigUtil ; import com . google . gerrit . server . config . GerritServerConfig ; import com . google . gerrit . server . config . SitePaths ; import com . google . inject . Inject ; import com . google . inject . Provider ; import com . google . inject . ProvisionException ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . eclipse . jgit . storage . file . FileSnapshot ; import org . eclipse . jgit . storage . file . FileSnapshot . FileChangeType ; import org . eclipse . jgit . storage . file . FileSnapshot . FileSnapshotWithAttributes ; import org . eclipse . jgit . storage . file . FileSnapshot . FileType ; import org . eclipse . jgit . storage . file . FileSnapshot . ModifiedFile ; import org . eclipse . jgit . storage . file . FileSnapshot . RegularFileSnapshot ; import org . eclipse . jgit . util . FS ; import org . eclipse . jgit . util . FileUtils ; import org . junit . After ; import org . junit . Before ; import org . junit . Test ; import java . io . File ; import java . io . IOException ; import java . util . Collections ; import java . util . List ; public class FileSnapshotTest { private FileSnapshot snapshot ; private File file ; @Before public void setUp ( ) throws Exception { file = File . createTempFile ( "FileSnapshotTest" , "tmp" ) ; snapshot = FileSnapshot . save ( file ) ; } @After public void tearDown ( ) throws Exception { FileUtils . delete ( file , FileUtils . RETRY ) ; } @Test public void testSave ( ) throws Exception { FileSnapshot . save ( file ) ; } @Test public void testSaveWithAttributes ( ) throws Exception { FileSnapshot . saveWithAttributes ( file ) ; } @Test public void testSaveWithAttributes_FileDoesNotExist ( ) throws Exception { FileUtils . delete ( file , FileUtils . RETRY ) ; FileSnapshot . saveWithAttributes ( file ) ; } @Test public void testSaveWithAttributes_FileIsDirectory ( ) throws Exception { FileUtils . delete ( file , FileUtils . RETRY ) ; file . mkdir ( ) ; FileSnapshot . saveWithAttributes ( file ) ; } @Test public void testSaveWithAttributes_FileIsSymlink ( ) throws Exception { FileUtils . delete ( file , FileUtils . RETRY ) ; FileUtils . symlink ( file . getAbsolutePath ( ) , file ) ; FileSnapshot . saveWithAttributes ( file ) ; } @Test public void testSaveWithAttributes_FileIsSymlinkToDirectory ( ) throws Exception { FileUtils . delete ( file , FileUtils . RETRY ) ; file . mkdir ( ) ; FileUtils . symlink ( file . getAbsolutePath ( ) , file ) ; FileSnapshot . saveWithAttributes ( file ) ; } @Test public void testSaveWithAttributes_FileIsSymlinkToNonExistingFile ( ) throws Exception { FileUtils . delete ( file , FileUtils . RETRY ) ; FileUtils . symlink ( file . getAbsolutePath ( ) , file ) ; FileSnapshot . saveWithAttributes ( file ) ; } @Test public void testSaveWithAttributes_FileIsSymlinkToNonExistingDirectory ( ) throws Exception { FileUtils . delete ( file , FileUtils . RETRY ) ; FileUtils . symlink ( file . getAbsolutePath ( ) , file ) ; FileSnapshot . saveWithAttributes ( file ) ; } @Test public void testSaveWithAttributes_FileIsSymlinkToSymlink ( ) throws Exception { FileUtils . delete ( file , FileUtils . RETRY ) ; FileUtils . symlink ( file . getAbsolutePath ( ) , file ) ; FileUtils . symlink ( file . getAbsolutePath ( ) , file ) ; FileSnapshot . saveWithAttributes ( file ) ; } @Test public void testSaveWithAttributes_FileIsSymlinkToSymlinkToDirectory ( ) throws Exception { FileUtils . delete ( file , FileUtils . RETRY ) ; file . mkdir ( ) ; FileUtils . symlink ( file . getAbsolutePath ( ) , file ) ; FileUtils . symlink ( file . getAbsolutePath ( ) , file ) ; FileSnapshot . saveWithAttributes ( file ) ; } @Test public void testSaveWithAttributes_FileIsSymlinkToSymlinkToNonExistingFile ( ) throws Exception { FileUtils . delete ( file , FileUtils . RETRY ) ; FileUtils . symlink ( file . getAbsolutePath ( ) , file ) ; FileUtils . symlink ( file . getAbsolutePath ( ) , file ) ; FileSnapshot . saveWithAttributes ( file ) ; } @Test public void testSaveWithAttributes_FileIsSymlinkToSymlinkToNonExistingDirectory ( ) throws Exception { FileUtils . delete ( file , FileUtils . RETRY ) ; FileUtils . symlink ( file . getAbsolutePath ( ) , file ) ; FileUtils . symlink ( file . getAbsolutePath ( ) , file ) ; FileSnapshot . saveWithAttributes ( file ) ; } @Test public void testSaveWithAttributes_FileIsSymlinkToSymlinkToSymlink ( ) throws Exception { FileUtils . delete ( file , FileUtils . RETRY ) ; FileUtils . symlink ( file . getAbsolutePath ( ) , file ) ;
assertTrue ( traceAdapter . isThereATraceBetween ( _A , _B , upDatedTraceModel ) ) ; // Clear selection view SelectionView . getOpenedView ( ) . clearSelection ( ) ; // create a selection with class A List < Object > selection = new ArrayList < > ( ) ; selection . add ( _A ) ; // test that internal links show for direct elements ToggleTransitivityHandler . setTraceViewTransitive ( false ) ; DisplayInternalLinksHandler . showInternalLinks ( true ) ; DiagramTextProviderHandler provider = new DiagramTextProviderHandler ( ) ; < |startfocus| > String directlyConnectedElements = provider . getDiagramText ( selection ) ; assertTrue ( directlyConnectedElements . equals ( EXPECTED_TEXT_FOR_INTERNAL_LINKS ) ) ; < |endfocus| > } }
assertEquals ( 1331668250328561095L , middleEvent . getTimestamp ( ) . toNanos ( ) ) ; assertEquals ( 1331668250328561095L , iterator . getCurrentTimestamp ( ) ) ; // double timestamp at 15 : 50 : 47 . 328921944 assertTrue ( iterator . seek ( new CtfLocationInfo ( 1331668247328921944L , 1L ) ) ) ; CtfTmfEvent doubleEvent = iterator . getCurrentEvent ( ) ; assertNotNull ( doubleEvent ) ; assertEquals ( 1331668247328921944L , doubleEvent . getTimestamp ( ) . toNanos ( ) ) ; assertEquals ( 1331668247328921944L , iterator . getCurrentTimestamp ( ) ) ; // test that events will be in cpu order < |startfocus| > assertEquals ( "sched_switch" , doubleEvent . getName ( ) ) ; < |endfocus| > assertTrue ( iterator . seek ( new CtfLocationInfo ( 1331668247328921944L , 9001000000L ) ) ) ; CtfTmfEvent overNineThousandEvent = iterator . getCurrentEvent ( ) ; assertNotNull ( overNineThousandEvent ) ; assertEquals ( 1331668247328925363L , overNineThousandEvent . getTimestamp ( ) . toNanos ( ) ) ; assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( "sys_poll" , overNineThousandEvent . getName ( ) ) ; assertTrue ( iterator . seek ( new CtfLocationInfo ( 1331668247328921944L , 4L ) ) ) ; CtfTmfEvent quadEvent = iterator . getCurrentEvent ( ) ; assertNotNull ( quadEvent ) ;
assertTrue ( iterator . seek ( new CtfLocationInfo ( 1331668247328921944L , 1L ) ) ) ; CtfTmfEvent doubleEvent = iterator . getCurrentEvent ( ) ; assertNotNull ( doubleEvent ) ; assertEquals ( 1331668247328921944L , doubleEvent . getTimestamp ( ) . toNanos ( ) ) ; assertEquals ( 1331668247328921944L , iterator . getCurrentTimestamp ( ) ) ; // test that events will be in cpu order assertEquals ( "sched_switch" , doubleEvent . getName ( ) ) ; < |startfocus| > assertTrue ( iterator . seek ( new CtfLocationInfo ( 1331668247328921944L , 3L ) ) ) ; CtfTmfEvent overNineThousandEvent = iterator . getCurrentEvent ( ) ; assertNotNull ( overNineThousandEvent ) ; assertEquals ( 1331668247328925363L , overNineThousandEvent . getTimestamp ( ) . toNanos ( ) ) ; < |endfocus| > assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( "sys_poll" , overNineThousandEvent . getName ( ) ) ; assertTrue ( iterator . seek ( new CtfLocationInfo ( 1331668247328921944L , 4L ) ) ) ; CtfTmfEvent quadEvent = iterator . getCurrentEvent ( ) ; assertNotNull ( quadEvent ) ; assertEquals ( 1331668247328925363L , quadEvent . getTimestamp ( ) . toNanos ( ) ) ; assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( "sys_poll" , quadEvent . getName ( ) ) ; assertFalse ( iterator . seek ( CtfLocation . INVALID_LOCATION ) ) ;
} } catch ( CTFException e ) { Activator . getDefault ( ) . logError ( e . getMessage ( ) , e ) ; return false ; } /* * Check if there is already one or more events for that timestamp , and * assign the location index correctly */ long index = 0 ; ITmfEvent currentEvent = getCurrentEvent ( ) ; ret &= ( currentEvent != null ) ; < |startfocus| > ITmfEvent previousEvent = currentEvent ; for ( long i = 0 ; ret && i < ctfLocationData . getIndex ( ) ; i ++ ) { // if ret == true , then currentEvent is non - null < |endfocus| > if ( seekToTimestamp >= Objects . requireNonNull ( currentEvent ) . getTimestamp ( ) . getValue ( ) ) { index ++ ; } else { index = 0 ; break ; } ret = advance ( ) ; previousEvent = currentEvent ; currentEvent = getCurrentEvent ( ) ; } /* Update the current location accordingly */ if ( ret ) { fCurLocation = new CtfLocation ( new CtfLocationInfo ( Objects . requireNonNull ( previousEvent ) . getTimestamp ( ) . getValue ( ) , index ) ) ; } else { fCurLocation = NULL_LOCATION ; }
// if ret == true , then currentEvent is non - null if ( seekToTimestamp >= Objects . requireNonNull ( currentEvent ) . getTimestamp ( ) . getValue ( ) ) { index ++ ; } else { index = 0 ; break ; } ret = advance ( ) ; previousEvent = currentEvent ; currentEvent = getCurrentEvent ( ) ; } /* Update the current location accordingly */ if ( ret ) { < |startfocus| > fCurLocation = new CtfLocation ( new CtfLocationInfo ( Objects . requireNonNull ( currentEvent ) . getTimestamp ( ) . getValue ( ) , index ) ) ; < |endfocus| > } else { fCurLocation = NULL_LOCATION ; } return ret ;
block . scope = this . scope ; // ( upper scope ) see Block . resolve ( ) for similar } else { Statement [ ] newArray = new Statement [ l + 1 ] ; System . arraycopy ( block . statements , 0 , newArray , 0 , l ) ; newArray [ l ] = breakStatement ; block . statements = newArray ; } return BREAKING ; } } return FALLTHROUGH ; } protected void completeNormallyCheck ( BlockScope blockScope ) { // do nothing } protected boolean checkNullDefaultFlow ( ) { < |startfocus| > return ! this . switchLabeledRules ; < |endfocus| > } @Override public FlowInfo analyseCode ( BlockScope currentScope , FlowContext flowContext , FlowInfo flowInfo ) { try { flowInfo = this . expression . analyseCode ( currentScope , flowContext , flowInfo ) ; if ( ( this . expression . implicitConversion & TypeIds . UNBOXING ) != 0 || ( this . expression . resolvedType != null && ( this . expression . resolvedType . id == T_JavaLangString || this . expression . resolvedType . isEnum ( ) ) ) ) { this . expression . checkNPE ( currentScope , flowContext , flowInfo , 1 ) ; } SwitchFlowContext switchContext = new SwitchFlowContext ( flowContext , this , this . expression . nullStatus ( flowInfo ) , this . expression . resolvedType ) ;
ServletContext ctx = config . getServletContext ( ) ; filter . init ( new NoParameterFilterConfig ( name , ctx ) ) ; } /* * { @inheritDoc } */ @Override public void destroy ( ) { filter . destroy ( ) ; } /* * { @inheritDoc } */ @Override protected void service ( HttpServletRequest req , HttpServletResponse res ) throws ServletException , IOException { < |startfocus| > filter . doFilter ( req , res , ( ServletRequest request , ServletResponse response ) - > { ( ( HttpServletResponse ) response ) . sendError ( SC_NOT_FOUND ) ; } ) ; < |endfocus| > } /* * * Configure a newly created binder . * * @param b * the newly created binder . * @return binder for the caller , potentially after adding one or more * filters into the pipeline . */ protected ServletBinder register ( ServletBinder b ) { return filter . register ( b ) ; } }
* made available under the terms of the Eclipse Public License v1 . 0 which * accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . tracecompass . internal . tmf . ui . views ; /* * * Interface with a method for time navigation in time - based views . * * @author Bernd Hufmann * */ public interface ITmfTimeNavigationProvider { /* * * Method to implement to scroll left or right * < |startfocus| > * @param left < |endfocus| > */ void horizontalScroll ( boolean left ) ; }
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * * Copyright ( c ) 2019 Ericsson * * All rights reserved . This program and the accompanying materials are * made available under the terms of the Eclipse Public License v1 . 0 which * accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . tracecompass . internal . tmf . ui . views ; /* * * Interface for a view to support zoom to selection . * * @author Bernd Hufmann * */ < |startfocus| > public interface ITmfZoomToSelectionProvider { /* * * Zoom to selection . */ void zoomToSelection ( ) ; < |endfocus| > }
* http :/ / www . eclipse . org / legal / epl - v10 . html ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . tracecompass . internal . tmf . ui . views . handler ; import org . eclipse . core . commands . AbstractHandler ; import org . eclipse . core . commands . ExecutionEvent ; import org . eclipse . core . commands . ExecutionException ; import org . eclipse . tracecompass . tmf . ui . views . TmfView ; import org . eclipse . ui . IWorkbenchPart ; import org . eclipse . ui . IWorkbenchWindow ; import org . eclipse . ui . PlatformUI ; import org . eclipse . ui . handlers . HandlerUtil ; /* * < |startfocus| > * Base handler , makes sure we have a timegraph control selected < |endfocus| > * * @author Matthew Khouzam * */ abstract class TmfViewBaseHandler extends AbstractHandler { @Override public Object execute ( ExecutionEvent event ) throws ExecutionException { // Check if we are closing down IWorkbenchWindow window = PlatformUI . getWorkbench ( ) . getActiveWorkbenchWindow ( ) ; if ( window == null ) { return null ; } IWorkbenchPart part = HandlerUtil . getActivePart ( event ) ; if ( part instanceof TmfView ) { execute ( ( TmfView ) part ) ; } return null ; } public abstract void execute ( TmfView timegraph ) ; }
* * @author Matthew Khouzam * */ abstract class TmfViewBaseHandler extends AbstractHandler { @Override public Object execute ( ExecutionEvent event ) throws ExecutionException { // Check if we are closing down IWorkbenchWindow window = PlatformUI . getWorkbench ( ) . getActiveWorkbenchWindow ( ) ; if ( window == null ) { return null ; } IWorkbenchPart part = HandlerUtil . getActivePart ( event ) ; if ( part instanceof TmfView ) { execute ( ( TmfView ) part ) ; } return null ; } < |startfocus| > public abstract void execute ( TmfView view ) ; < |endfocus| > }
* accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . tracecompass . internal . tmf . ui . views . handler ; import org . eclipse . tracecompass . internal . tmf . ui . views . ITmfTimeZoomProvider ; import org . eclipse . tracecompass . tmf . ui . views . TmfView ; /* * * Zoom - in handler for TMF views . * * @author Matthew Khouzam * @author Bernd Hufmann */ < |startfocus| > public class TmfViewZoomInHandler extends TmfViewBaseHandler { < |endfocus| > @Override public void execute ( TmfView view ) { ITmfTimeZoomProvider zoomer = view . getAdapter ( ITmfTimeZoomProvider . class ) ; if ( zoomer != null ) { zoomer . zoom ( true ) ; } } }
import org . eclipse . sirius . tests . swtbot . support . api . editor . SWTBotSiriusDiagramEditor ; import org . eclipse . sirius . tests . swtbot . support . utils . SWTBotUtils ; import org . eclipse . swt . SWT ; import org . eclipse . swtbot . eclipse . gef . finder . widgets . SWTBotGefEditPart ; /* * * Tests to check the behavior of the editor when selecting a node or edge edit * part . * * @author lfasani */ public class EditPartSelectionTest extends AbstractSiriusSwtBotGefTestCase { < |startfocus| > private static final String DATA_UNIT_DIR = " / data / unit / selection / " ; < |endfocus| > private static final String MODEL = "TestSelection . ecore" ; private static final String SESSION_FILE = "TestSelection . aird" ; private static final String VSM_FILE = "My . odesign" ; private static final String REPRESENTATION_DECRIPTION_NAME = "Entities" ; private static final String REPRESENTATION_NAME = "diagram" ; private static final PrecisionPoint INITIAL_NODE_CENTER_POSITION = new PrecisionPoint ( 856 . 0 , 412 . 0 ) ; private Session session ; @Override protected void onSetUpBeforeClosingWelcomePage ( ) throws Exception {
} /* * * Run the void setRank ( ) method test . */ @Test public void testSetRank ( ) { long rank = fIterator . getRank ( ) ; fIterator . increaseRank ( ) ; assertEquals ( rank + 1 , fIterator . getRank ( ) ) ; fIterator . setRank ( rank ) ; assertEquals ( rank , fIterator . getRank ( ) ) ; } /* * * Run the boolean seek ( long ) method test . */ @Test public void testSeek ( ) { < |startfocus| > // Good old trace 2 . You may just be perfect ! < |endfocus| > CtfTmfTrace trace = CtfTmfTestTraceUtils . getTrace ( CtfTestTrace . TRACE2 ) ; try ( CtfIterator iterator = ( CtfIterator ) trace . createIterator ( ) ) { assertTrue ( iterator . seek ( 1L ) ) ; CtfTmfEvent event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668247314038062L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247314038062L , iterator . getCurrentTimestamp ( ) ) ; assertFalse ( iterator . seek ( Long . MAX_VALUE ) ) ; assertNull ( getCurrentEvent ( iterator ) ) ; assertEquals ( 0L , iterator . getCurrentTimestamp ( ) ) ; assertFalse ( iterator . advance ( ) ) ; // seek to a time after trace start .
assertNull ( getCurrentEvent ( iterator ) ) ; assertEquals ( 0L , iterator . getCurrentTimestamp ( ) ) ; assertFalse ( iterator . advance ( ) ) ; // seek to a time after trace start . CtfLocationInfo middleLocation = new CtfLocationInfo ( 1331668250328561095L , 0L ) ; assertTrue ( iterator . seek ( middleLocation ) ) ; event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668250328561095L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668250328561095L , iterator . getCurrentTimestamp ( ) ) ; < |startfocus| > CtfLocationInfo middleLocationIndexedOne = new CtfLocationInfo ( 1331668250328561095L , 1L ) ; assertTrue ( iterator . seek ( middleLocationIndexedOne ) ) ; event = getCurrentEvent ( iterator ) ; < |endfocus| > assertNotNull ( event ) ; assertEquals ( 1331668250328561761L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668250328561761L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( new CtfLocationInfo ( 1331668250328561761L , 0L ) , iterator . getLocation ( ) . getLocationInfo ( ) ) ; // double timestamp at 15 : 50 : 47 . 328921944 CtfLocationInfo duplicateLocationIndexedOne = new CtfLocationInfo ( 1331668247328921944L , 1L ) ; assertTrue ( iterator . seek ( duplicateLocationIndexedOne ) ) ; event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668247328921944L , getTimestampInNanos ( event ) ) ;
assertTrue ( iterator . seek ( middleLocation ) ) ; event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668250328561095L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668250328561095L , iterator . getCurrentTimestamp ( ) ) ; CtfLocationInfo middleLocationIndexeOne = new CtfLocationInfo ( 1331668250328561095L , 1L ) ; assertTrue ( iterator . seek ( middleLocationIndexeOne ) ) ; event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668250328561761L , getTimestampInNanos ( event ) ) ; < |startfocus| > assertEquals ( 1331668250328561761L , iterator . getCurrentTimestamp ( ) ) ; < |endfocus| > assertEquals ( new CtfLocationInfo ( 1331668250328561761L , 0L ) , iterator . getLocation ( ) . getLocationInfo ( ) ) ; // double timestamp at 15 : 50 : 47 . 328921944 CtfLocationInfo duplicateLocationIndexedOne = new CtfLocationInfo ( 1331668247328921944L , 1L ) ; assertTrue ( iterator . seek ( duplicateLocationIndexedOne ) ) ; event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668247328921944L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247328921944L , iterator . getCurrentTimestamp ( ) ) ; // test that events will be in cpu order assertEquals ( "sched_switch" , event . getName ( ) ) ; assertEquals ( duplicateLocationIndexedOne , iterator . getLocation ( ) . getLocationInfo ( ) ) ; // next event location
CtfLocationInfo duplicateLocationOutOfBounds = new CtfLocationInfo ( 1331668247328921944L , 4L ) ; assertTrue ( iterator . seek ( duplicateLocationOutOfBounds ) ) ; event = getCurrentEvent ( iterator ) ; assertNotNull ( event ) ; assertEquals ( 1331668247328925363L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( "sys_poll" , event . getName ( ) ) ; // next event location assertEquals ( new CtfLocationInfo ( 1331668247328925363L , 0L ) , iterator . getLocation ( ) . getLocationInfo ( ) ) ; < |startfocus| > CtfLocationInfo duplicateLocationIndexedOver9000 = new CtfLocationInfo ( 1331668247328921944L , 9001000000L ) ; assertTrue ( iterator . seek ( duplicateLocationIndexedOver9000 ) ) ; event = getCurrentEvent ( iterator ) ; < |endfocus| > assertNotNull ( event ) ; assertEquals ( 1331668247328925363L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( "sys_poll" , event . getName ( ) ) ; // next event location assertEquals ( new CtfLocationInfo ( 1331668247328925363L , 0L ) , iterator . getLocation ( ) . getLocationInfo ( ) ) ; assertFalse ( iterator . seek ( CtfLocation . INVALID_LOCATION ) ) ; // last valid seek location assertEquals ( event , getCurrentEvent ( iterator ) ) ; } trace . dispose ( ) ; }
assertEquals ( 1331668247328925363L , getTimestampInNanos ( event ) ) ; assertEquals ( 1331668247328925363L , iterator . getCurrentTimestamp ( ) ) ; assertEquals ( "sys_poll" , event . getName ( ) ) ; // next event location assertEquals ( new CtfLocationInfo ( 1331668247328925363L , 0L ) , iterator . getLocation ( ) . getLocationInfo ( ) ) ; assertFalse ( iterator . seek ( CtfLocation . INVALID_LOCATION ) ) ; // last valid seek location assertEquals ( event , getCurrentEvent ( iterator ) ) ; } trace . dispose ( ) ; } < |startfocus| > private static CtfTmfEvent getCurrentEvent ( CtfIterator iterator ) { return iterator . getCurrentEvent ( ) ; } private static long getTimestampInNanos ( CtfTmfEvent event ) { return event . getTimestamp ( ) . toNanos ( ) ; } < |endfocus| > /* * * Run the void setLocation ( ITmfLocation < ? > ) method test . */ @Test public void testSetLocation ( ) { CtfLocation location = new CtfLocation ( new CtfLocationInfo ( 1 , 0 ) ) ; fIterator . setLocation ( location ) ; } }
assertEquals ( "sys_poll" , event . getName ( ) ) ; // next event location assertEquals ( new CtfLocationInfo ( 1331668247328925363L , 0L ) , iterator . getLocation ( ) . getLocationInfo ( ) ) ; assertFalse ( iterator . seek ( CtfLocation . INVALID_LOCATION ) ) ; // last valid seek location assertEquals ( event , getCurrentEvent ( iterator ) ) ; } trace . dispose ( ) ; } < |startfocus| > private static CtfTmfEvent getCurrentEvent ( CtfIterator iterator ) { return iterator . getCurrentEvent ( ) ; } private static long getTimestampInNanos ( CtfTmfEvent event ) { return event . getTimestamp ( ) . toNanos ( ) ; } < |endfocus| > /* * * Run the void setLocation ( ITmfLocation < ? > ) method test . */ @Test public void testSetLocation ( ) { CtfLocation location = new CtfLocation ( new CtfLocationInfo ( 1 , 0 ) ) ; fIterator . setLocation ( location ) ; } }
public boolean isReferenceToDisplay ( Component source , DNodeContainer sourceView , DNodeContainer targetView ) { < |startfocus| > // if ( ! isIndirectlyCollapsed ( sourceView ) && ! isIndirectlyCollapsed ( targetView ) ) { < |endfocus| > for ( DDiagramElement child : sourceView . getOwnedDiagramElements ( ) ) { if ( child instanceof DNodeContainer && ( ( ( DNodeContainer ) child ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) ) { for ( DDiagramElement grandchild : ( ( DNodeContainer ) child ) . getOwnedDiagramElements ( ) ) { if ( isReferenceDisplayedByChild ( ( DNodeContainer ) grandchild , targetView ) ) { return false ; } } } } return true ; // } // return false ;
// if ( ! isIndirectlyCollapsed ( sourceView ) && ! isIndirectlyCollapsed ( targetView ) ) { for ( DDiagramElement child : sourceView . getOwnedDiagramElements ( ) ) { if ( child instanceof DNodeContainer && ( ( ( DNodeContainer ) child ) . getActualMapping ( ) . getName ( ) . equals ( "ComponentRegion" ) ) ) { for ( DDiagramElement grandchild : ( ( DNodeContainer ) child ) . getOwnedDiagramElements ( ) ) { if ( isReferenceDisplayedByChild ( ( DNodeContainer ) grandchild , targetView ) ) { return false ; } } } } return true ; < |startfocus| > // } // return false ; < |endfocus| >
< |startfocus| > * Copyright ( c ) 2010 , 2017 THALES GLOBAL SERVICES < |endfocus| > * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Obeo - Initial API and implementation */ package org . eclipse . sirius . tests . swtbot . support . api . editor ; import java . util . Iterator ; import java . util . List ; import java . util . concurrent . atomic . AtomicBoolean ; import org . eclipse . core . runtime . IAdaptable ; import org . eclipse . draw2d . FigureCanvas ; import org . eclipse . draw2d . IFigure ; import org . eclipse . draw2d . Label ; import org . eclipse . draw2d . LightweightSystem ; import org . eclipse . draw2d . geometry . Point ; import org . eclipse . draw2d . text . TextFlow ; import org . eclipse . gef . EditPart ; import org . eclipse . gef . GraphicalEditPart ; import org . eclipse . gef . GraphicalViewer ; import org . eclipse . sirius . ext . gmf . runtime . gef . ui . figures . SiriusWrapLabel ; import org . eclipse . sirius . tests . swtbot . support . api . widget . SWTBotSiriusFigureCanvas ; import org . eclipse . swt . widgets . Control ; import org . eclipse . swt . widgets . Display ; import org . eclipse . swt . widgets . Event ; import org . eclipse . swt . widgets . Shell ; import org . eclipse . swtbot . eclipse . gef . finder . widgets . SWTBotGefEditPart ; import org . eclipse . swtbot . swt . finder . exceptions . WidgetNotFoundException ; import org . eclipse . swtbot . swt . finder . finders . UIThreadRunnable ; import org . eclipse . swtbot . swt . finder . results . VoidResult ; import org . eclipse . swtbot . swt . finder . utils . SWTBotPreferences ; import org . eclipse . swtbot . swt . finder . waits . DefaultCondition ; import org . eclipse . swtbot . swt . finder . widgets . SWTBotShell ; import org . eclipse . swtbot . swt . finder . widgets . SWTBotText ; import org . eclipse . swtbot . swt . finder . widgets . SWTBotTreeItem ; import org . eclipse . ui . IEditorPart ; import org . eclipse . ui . IWorkbenchPart ; import org . eclipse . ui . PlatformUI ; import org . eclipse . ui . views . properties . tabbed . TabbedPropertySheetPage ; import org . eclipse . ui . views . properties . tabbed . TabbedPropertySheetWidgetFactory ; /* * * SWTBot editor for Sirius . * * @author mchauvin */ public class SWTBotSiriusHelper {
* Copyright ( c ) 2012 , 2017 THALES GLOBAL SERVICES * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Obeo - Initial API and implementation */ package org . eclipse . sirius . tests . swtbot . support . api . widget ; import java . util . concurrent . atomic . AtomicBoolean ; import org . eclipse . draw2d . FigureCanvas ; import org . eclipse . draw2d . LightweightSystem ; import org . eclipse . swt . SWT ; import org . eclipse . swt . events . KeyEvent ; import org . eclipse . swt . widgets . Canvas ; import org . eclipse . swt . widgets . Event ; import org . eclipse . swt . widgets . Text ; import org . eclipse . swtbot . eclipse . gef . finder . widgets . SWTBotGefFigureCanvas ; import org . eclipse . swtbot . swt . finder . exceptions . WidgetNotFoundException ; import org . eclipse . swtbot . swt . finder . finders . UIThreadRunnable ; import org . eclipse . swtbot . swt . finder . results . Result ; import org . eclipse . swtbot . swt . finder . results . VoidResult ; import org . eclipse . swtbot . swt . finder . utils . SWTUtils ; /* *
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * < |startfocus| > * Copyright ( c ) 2017 THALES GLOBAL SERVICES . < |endfocus| > * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Obeo - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . sirius . tests . swtbot ; import org . eclipse . draw2d . IFigure ; import org . eclipse . draw2d . geometry . PrecisionPoint ; import org . eclipse . draw2d . geometry . Rectangle ; import org . eclipse . gef . GraphicalEditPart ; import org . eclipse . gef . LayerConstants ; import org . eclipse . gef . editparts . LayerManager ; import org . eclipse . gmf . runtime . diagram . ui . editparts . AbstractBorderedShapeEditPart ; import org . eclipse . gmf . runtime . diagram . ui . editparts . ConnectionEditPart ; import org . eclipse . gmf . runtime . diagram . ui . editparts . IGraphicalEditPart ; import org . eclipse . gmf . runtime . draw2d . ui . figures . PolylineConnectionEx ; import org . eclipse . sirius . business . api . session . Session ; import org . eclipse . sirius . diagram . DDiagram ; import org . eclipse . sirius . diagram . ui . edit . api . part . AbstractDiagramBorderNodeEditPart ; import org . eclipse . sirius . diagram . ui . edit . api . part . AbstractDiagramEdgeEditPart ;
} @Override protected void tearDown ( ) throws Exception { assertEquals ( "Test triggered errors . " , 0 , loggedErrors . get ( ) ) ; Platform . removeLogListener ( errorLogListener ) ; super . tearDown ( ) ; } /* * * Test if two byte UTF - 8 characters get disrupted on there way from process * console to the runtime process . * < p > * This test starts every two byte character on an even byte offset . * </ p > < |startfocus| > * * @throws Exception if the test gets in trouble < |endfocus| > */ public void testUTF8InputEven ( ) throws Exception { // 5000 characters result in 10000 bytes which should be more than most // common buffer sizes . processConsoleUTF8Input ( "" , 5000 ) ; } /* * * Test if two byte UTF - 8 characters get disrupted on there way from process * console to the runtime process . * < p > * This test starts every two byte character on an odd byte offset . * </ p > * * @throws Exception if the test gets in trouble
import org . eclipse . debug . tests . AbstractDebugTest ; /* * * Tests the { @link StreamsProxy } . */ public class StreamsProxyTests extends AbstractDebugTest { public StreamsProxyTests ( ) { super ( StreamsProxyTests . class . getSimpleName ( ) ) ; } public StreamsProxyTests ( String name ) { super ( name ) ; } /* * * Test console receiving UTF - 8 output from process where two - byte UTF - 8 * characters start at even offsets . < |startfocus| > * * @throws Exception if the test gets in trouble < |endfocus| > */ public void testReceiveUTF8Even ( ) throws Exception { // 4500 characters results in 9000 byte of output which should be more // than most common buffer sizes . receiveUTF8Test ( "" , 4500 ) ; } /* * * Test console receiving UTF - 8 output from process where two - byte UTF - 8 * characters start at odd offsets . * * @throws Exception if the test gets in trouble */ public void testReceiveUTF8Odd ( ) throws Exception { // 4500 characters results in 9000 byte of output which should be more // than most common buffer sizes . receiveUTF8Test ( "\u0080" , 4500 ) ; } /* * * Test console receiving UTF - 8 output from process where two - byte UTF - 8 * characters start at even offsets . * * @throws Exception if the test gets in trouble */ public void testReceiveUTF8Even2 ( ) throws Exception { // 4500 characters results in 9000 byte of output which should be more // than most common buffer sizes . receiveUTF8Test ( "\u0080" , 4500 ) ; } /* * * Test console receiving UTF - 8 output from process where two - byte UTF - 8 * characters start at odd offsets . * * @throws Exception if the test gets in trouble */ public void testReceiveUTF8Odd2 ( ) throws Exception { // 4500 characters results in 9000 byte of output which should be more
public void testSet ( ) { List < String > reference = Arrays . asList ( "Pomme" , "Peche" , "Poire" , "Banane" ) ; List < String > test = createList ( reference ) ; assertEquals ( reference , test ) ; < |startfocus| > assertEquals ( reference , test ) ; < |endfocus| > test . set ( 0 , "pomme" ) ; assertNotEquals ( reference , test ) ; try { test . set ( - 1 , "pomme" ) ; fail ( "Should not get here" ) ; } catch ( IndexOutOfBoundsException e ) { // correct flow } try { test . set ( 5 , "pomme" ) ; fail ( "Should not get here" ) ; } catch ( IndexOutOfBoundsException e ) { // correct flow }
assertEquals ( "yo" , iterator . next ( ) ) ; iterator . previous ( ) ; try { iterator . previous ( ) ; fail ( "Should not get here" ) ; } catch ( NoSuchElementException e ) { // correct flow } iterator . next ( ) ; iterator . next ( ) ; iterator . next ( ) ; iterator . next ( ) ; try { iterator . next ( ) ; fail ( "Should not get here" ) ; } catch ( NoSuchElementException e ) { // correct flow } iterator . previous ( ) ; < |startfocus| > assertEquals ( 3 , iterator . previousIndex ( ) ) ; assertEquals ( 4 , iterator . nextIndex ( ) ) ; < |endfocus| > try { iterator . remove ( ) ; fail ( "Should not get here" ) ; } catch ( UnsupportedOperationException e ) { // correct flow } try { iterator . set ( "hej" ) ; fail ( "Should not get here" ) ; } catch ( UnsupportedOperationException e ) { // correct flow } try { iterator . add ( "hi" ) ; fail ( "Should not get here" ) ; } catch ( UnsupportedOperationException e ) { // correct flow }
* accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . tracecompass . internal . ctf . core . utils ; import java . util . Collection ; import java . util . Iterator ; import java . util . LinkedHashMap ; import java . util . List ; import java . util . ListIterator ; import java . util . Map ; import java . util . Map . Entry ; import java . util . Objects ; import java . util . Spliterator ; import org . eclipse . jdt . annotation . NonNull ; /* * * Sparse list , a list that supports * < ul > * < li > { @link #add ( Object ) } </ li > * < li > { @link #contains ( Object ) } </ li > * < li > { @link #clear ( ) } </ li > * < li > { @link #iterator ( ) } , { @link #isEmpty ( ) } </ li > * < li > { @link #toArray ( ) } </ li > * < li > { @link #toArray ( Object [ ] ) } </ li > * < li > { @link #set ( int , Object ) } </ li > * < li > { @link #lastIndexOf ( Object ) } </ li > * </ ul > *
< |startfocus| > private int getThreshold ( ) { < |endfocus| > if ( ! selectFeedbackEnabled ) { if ( getViewer ( ) . getControl ( ) instanceof Table ) return ( ( Table ) getViewer ( ) . getControl ( ) ) . getItemHeight ( ) / 2 ; if ( getViewer ( ) . getControl ( ) instanceof Tree ) return ( ( Tree ) getViewer ( ) . getControl ( ) ) . getItemHeight ( ) / 2 ; if ( getViewer ( ) . getControl ( ) instanceof List ) return ( ( List ) getViewer ( ) . getControl ( ) ) . getItemHeight ( ) / 2 ; } // fixed default threshold return 5 ;
public GenericReadOnlyListIterator ( List < E > list , int start , int end ) { fList = list ; < |startfocus| > fStart = start ; fEnd = end ; < |endfocus| > fCursor = start ;
* http :/ / www . eclipse . org / legal / epl - v10 . html ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . tracecompass . internal . ctf . core . utils ; import java . util . Collection ; import java . util . HashMap ; import java . util . Iterator ; import java . util . List ; import java . util . ListIterator ; import java . util . Map ; import java . util . Map . Entry ; import java . util . Objects ; import java . util . Spliterator ; import org . eclipse . jdt . annotation . NonNull ; /* * < |startfocus| > * Sparse list , a list optimized for when most ( > 90 % ) of the data is * < code > null </ code > . < |endfocus| > * *
* < li > { @link #clear ( ) } </ li > * < li > { @link #iterator ( ) } </ li > * < li > { @link #isEmpty ( ) } </ li > * < li > { @link #toArray ( ) } </ li > * < li > { @link #toArray ( Object [ ] ) } </ li > * < li > { @link #set ( int , Object ) } </ li > * < li > { @link #lastIndexOf ( Object ) } </ li > * </ ul > * < |startfocus| > * TODO : remove when a public ( open source ) sparselist is available . < |endfocus| > * * @author Matthew Khouzam * @param < E > * the element type */ public class SparseList < E > implements List < E > { private final Map < Integer , E > fInnerEvents = new HashMap < > ( ) ; private int fSize = 0 ; /* * * Copy constructor * * @param events * list of events */ public SparseList ( List < E > events ) { ensureSize ( events . size ( ) ) ; for ( int i = 0 ; i < events . size ( ) ; i ++ ) { E element = events . get ( i ) ;
* < li > { @link #toArray ( Object [ ] ) } </ li > * < li > { @link #set ( int , Object ) } </ li > * < li > { @link #lastIndexOf ( Object ) } </ li > * </ ul > * * TODO : remove when a public ( open source ) sparselist is available . * * @author Matthew Khouzam * @param < E > * the element type */ public class SparseList < E > implements List < E > { < |startfocus| > private final Map < Integer , E > fElements = new HashMap < > ( ) ; < |endfocus| > private int fSize = 0 ; /* * * Copy constructor * * @param events * list of events */ public SparseList ( List < E > events ) { ensureSize ( events . size ( ) ) ; for ( int i = 0 ; i < events . size ( ) ; i ++ ) { E element = events . get ( i ) ; if ( element != null ) { set ( i , element ) ; } } } /* * * default constructor */ public SparseList ( ) { // Do nothing } @Override public int size ( ) {
public boolean contains ( Object o ) { < |startfocus| > return fInnerEvents . containsValue ( o ) ; < |endfocus| > }
public boolean add ( E e ) { < |startfocus| > synchronized ( this ) { fInnerEvents . put ( fSize , e ) ; fSize ++ ; } < |endfocus| > return true ;
public boolean containsAll ( Collection < ? > c ) { < |startfocus| > return fInnerEvents . values ( ) . containsAll ( c ) ; < |endfocus| >
public boolean addAll ( Collection < ? extends E > c ) { int key = fSize ; fSize += c . size ( ) ; for ( E event : c ) { < |startfocus| > if ( event != null ) { set ( key , event ) ; key ++ ; } < |endfocus| > } return true ;
public boolean addAll ( Collection < ? extends E > c ) { int key = fSize ; fSize += c . size ( ) ; for ( E event : c ) { < |startfocus| > set ( key , event ) ; < |endfocus| > key ++ ; } return true ;
} @Override public boolean containsAll ( Collection < ? > c ) { return fInnerEvents . values ( ) . containsAll ( c ) ; } @Override public boolean addAll ( Collection < ? extends E > c ) { int key = fSize ; fSize += c . size ( ) ; for ( E event : c ) { if ( event != null ) { set ( key , event ) ; } key ++ ; } return true ; } /* * * { @inheritDoc } * < |startfocus| > * returns null if there is no element found at that index . < |endfocus| > */ @Override public E get ( int index ) { if ( index < 0 || index >= fSize ) { throw new IndexOutOfBoundsException ( "Tried to access index " + index + " Sparse list size " + fSize ) ; // $NON - NLS - 1$ // $NON - NLS - 2$ } return fInnerEvents . get ( index ) ; } @Override public E set ( int index , E element ) { if ( index < 0 || index >= fSize ) { throw new IndexOutOfBoundsException ( "Tried to access index " + index + " Sparse list size " + fSize ) ; // $NON - NLS - 1$ // $NON - NLS - 2$ }
public ELEMENT next ( ) { if ( ! hasNext ( ) ) { throw new NoSuchElementException ( ) ; } < |startfocus| > ELEMENT element = fList . get ( fCursor ++ ) ; return element ; < |endfocus| >
public int nextIndex ( ) { < |startfocus| > return fCursor ; < |endfocus| > }
// constexpr bool comma_is_not_noexcept = noexcept ( fun ( ) , fun_noexcept ( ) ) ; // constexpr bool ctor_is_noexcept = noexcept ( myclass { } ) ; // constexpr bool ctor_is_not_noexcept = noexcept ( myclass { 1 } ) ; // constexpr bool constexpr_ctor_is_noexcept = noexcept ( myclass { 1 , 1 } ) ; // constexpr bool aggregate_init_is_noexcept = noexcept ( myaggregate { { 1 } } ) ; // constexpr bool aggregate_init_is_not_noexcept = noexcept ( myaggregate { { my_int } } ) ; // constexpr bool aggregate_access_is_noexcept = noexcept ( agg . a ) ; // constexpr bool not_noexcept_conditional = noexcept ( condition ( ) ? fun ( ) : fun_noexcept ( ) ) ; // constexpr bool is_noexcept_conditional = noexcept ( condition ( ) ? fun_noexcept ( ) : fun_noexcept ( ) ) ; // constexpr bool throw_is_not_noexcept = noexcept ( throw fun_noexcept ( ) ) ; < |startfocus| > public void testNoexceptOperator_545021 ( ) throws Exception { < |endfocus| > BindingAssertionHelper helper = getAssertionHelper ( ) ; helper . assertVariableValue ( "fun_is_not_noexcept" , 0 ) ; helper . assertVariableValue ( "unevaluated_fun_is_noexcept" , 1 ) ; helper . assertVariableValue ( "fun_noexcept_is_noexcept" , 1 ) ; helper . assertVariableValue ( "comma_is_not_noexcept" , 0 ) ;
// { dg - do compile } // { dg - options " - std = gnu ++ 11" } // Copyright ( C ) 2013 - 2014 Free Software Foundation , Inc . // // This file is part of the GNU ISO C ++ Library . This library is free // software ; you can redistribute it and / or modify it under the // terms of the GNU General Public License as published by the // Free Software Foundation ; either version 3 , or ( at your option ) // any later version . // // This library is distributed in the hope that it will be useful , // but WITHOUT ANY WARRANTY ; without even the implied warranty of // MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE . See the // GNU General Public License for more details . // // You should have received a copy of the GNU General Public License along // with this library ; see the file COPYING3 . If not see // < http :/ / www . gnu . org / licenses / > . // { dg - require - effective - target c ++ 11 } // { dg - require - cstdint "" } // { dg - require - gthreads "" } // { dg - require - atomic - builtins "" } // { dg - require - time "" } // { dg - require - cstdio "" } // { dg - require - cmath "" } // { dg - require - csetjmp "" } // { dg - require - cstdarg "" } // { dg - require - cstring "" } // { dg - require - clocale "" } // { dg - require - cwchar "" } // { dg - require - cstdlib "" } // { dg - require - cstddef "" } // { dg - require - exception "" } // { dg - require - exceptions "" } // { dg - require - typeinfo "" } // { dg - require - type_traits "" } // { dg - require - initializer_list "" } // { dg - require - system - errno "" } // { dg - require - system - stdlib "" } // { dg - require - system - stdio "" } // { dg - require - system - time "" } // { dg - require - system - signal "" } // { dg - require - system - setjmp "" } // { dg - require - system - stdarg "" } // { dg - require - system - string "" } // { dg - require - system - locale "" } // { dg - require - system - wchar "" } // { dg - require - system - cstdio "" } // { dg - require - system - cmath "" } // { dg - require - system - csetjmp "" } // { dg - require - system - cstdarg "" } // { dg - require - system - cstring "" } // { dg - require - system - clocale "" } // { dg - require - system - cwchar "" } // { dg - require - system - cstdlib "" } // { dg - require - system - cstddef "" } // { dg - require - system - exception "" } // { dg - require - system - exceptions "" } // { dg - require - system - typeinfo "" } // { dg - require - system - type_traits "" } // { dg - require - system - initializer_list "" } // { dg - require - system - errno "" } // { dg - require - system - stdlib "" } // { dg - require - system - stdio "" } // { dg - require - system - time "" } // { dg - require - system - signal "" } // { dg - require - system - setjmp "" } // { dg - require - system - stdarg "" } // { dg - require - system - string "" } // { dg - require - system - locale "" } // { dg - require - system - wchar "" } // { dg - require - system - cstdio "" } // { dg - require - system - cmath "" } // { dg - require - system - csetjmp "" } // { dg - require - system - cstdarg "" } // { dg - require - system - cstring "" } // { dg - require - system - clocale "" } // { dg - require - system - cwchar "" } // { dg - require - system - cstdlib "" } // { dg - require - system - cstddef "" } // { dg - require - system - exception "" } // { dg - require - system - exceptions "" } // { dg - require - system - typeinfo "" } // { dg - require - system - type_traits "" } // { dg - require - system - initializer_list "" } // { dg - require - system - errno "" } // { dg - require - system - stdlib "" } // { dg - require - system - stdio "" } // { dg - require - system - time "" } // { dg - require - system - signal "" } // { dg - require - system - setjmp "" } // { dg - require - system - stdarg "" } // { dg - require - system - string "" } // { dg - require - system - locale "" } // { dg - require - system - wchar "" } // { dg - require - system - cstdio "" } // { dg - require - system - cmath "" } // { dg - require - system - csetjmp "" } // { dg - require - system - cstdarg "" } // { dg - require - system - cstring "" } // { dg - require - system - clocale "" } // { dg - require - system - cwchar "" } // { dg - require - system - cstdlib "" } // { dg - require - system - cstddef "" } // { dg - require - system - exception "" } // { dg - require - system - exceptions "" } // { dg - require - system - typeinfo "" } // { dg - require - system - type_traits "" } // { dg - require - system - initializer_list "" } // { dg - require - system - errno "" } // { dg - require - system - stdlib "" } // { dg - require - system - stdio "" } // { dg - require - system - time "" } // { dg - require - system - signal "" } // { dg - require - system - setjmp "" } // { dg - require - system - stdarg "" } // { dg - require - system - string "" } // { dg - require - system - locale "" } // { dg - require - system - wchar "" } // { dg - require - system - cstdio "" } // { dg - require - system - cmath "" } // { dg - require - system - csetjmp "" } // { dg - require - system - cstdarg "" } // { dg - require - system - cstring "" } // { dg - require - system - clocale "" } // { dg - require - system - cwchar "" } // { dg - require - system - cstdlib "" } // { dg - require - system - cstddef "" } // { dg - require - system - exception "" } // { dg - require - system - exceptions "" } // { dg - require - system - typeinfo "" } // { dg - require - system - type_traits "" } // { dg
// void operator = ( int ) ; // bool operator ! ( ) ; // } ; // type1 t1 ; // struct type2 { // void operator = ( int ) noexcept ; // bool operator ! ( ) noexcept ; // } ; // type2 t2 ; // constexpr bool binaryop_is_not_noexcept = noexcept ( t1 = 1 ) ; // constexpr bool unaryop_is_not_noexcept = noexcept ( ! t1 ) ; // constexpr bool noexcept_binaryop_is_noexcept = noexcept ( t2 = 1 ) ; // constexpr bool noexcept_unaryop_is_noexcept = noexcept ( ! t2 ) ; public void testNoexceptOperator3_545021 ( ) throws Exception { BindingAssertionHelper helper = getAssertionHelper ( ) ; helper . assertVariableValue ( "binaryop_is_not_noexcept" , 0 ) ; helper . assertVariableValue ( "unaryop_is_not_noexcept" , 0 ) ; helper . assertVariableValue ( "noexcept_binaryop_is_noexcept" , 1 ) ; helper . assertVariableValue ( "noexcept_unaryop_is_noexcept" , 1 ) ; } // void fun ( ) ; // void fun_taking_funptr ( void ( * ptr ) ( ) ) noexcept ; // // constexpr bool is_noexcept = noexcept ( fun_taking_funptr ( fun ) ) ;
private final boolean isRValueReference ; private final boolean takesVarargs ; private final ICPPEvaluation noexceptSpecifier ; < |startfocus| > public CPPFunctionType ( IType returnType , IType [ ] types ) { this ( returnType , types , false , false , false , false , false , null ) ; < |endfocus| >
public boolean isNoexcept ( boolean inCalledContext ) { ICPPFunction overload = getOverload ( ) ; if ( overload != null ) { < |startfocus| > return EvalUtil . evaluateNoexceptSpecifier ( overload . getType ( ) . getNoexceptSpecifier ( ) ) && fArg1 . isNoexcept ( inCalledContext ) && fArg2 . isNoexcept ( inCalledContext ) ; < |endfocus| > } return fArg1 . isNoexcept ( inCalledContext ) && fArg2 . isNoexcept ( inCalledContext ) ;
public boolean isNoexcept ( boolean inCalledContext ) { < |startfocus| > return fPositive . isNoexcept ( inCalledContext ) && fNegative . isNoexcept ( inCalledContext ) && fCondition . isNoexcept ( inCalledContext ) ; < |endfocus| >
public boolean isNoexcept ( boolean inCalledContext ) { < |startfocus| > // It's possible you can't . I think that , like EvalReference , EvalConstructor is only created as an intermediate result during constexpr evaluation . < |endfocus| > return EvalUtil . evaluateNoexceptSpecifier ( fConstructor . getType ( ) . getNoexceptSpecifier ( ) ) ;
public boolean isNoexcept ( boolean inCalledContext ) { < |startfocus| > // assert false ; // TODO this assert is hit < |endfocus| > return true ; }
public boolean isNoexcept ( boolean inCalledContext ) { < |startfocus| > // assert false ; // TODO assert hit by original bug report < |endfocus| > return true ;
< |startfocus| > public boolean isNoexcept ( boolean inCalledContext ) { < |endfocus| > if ( inCalledContext ) { return EvalUtil . bindingIsNoexcept ( getMember ( ) ) && EvalUtil . bindingIsNoexcept ( fOwnerEval ) ; } else return true ; // in unevaluated context
public boolean isNoexcept ( boolean inCalledContext ) { < |startfocus| > assert false ; // This is a test < |endfocus| > return true ;
public boolean isNoexcept ( boolean inCalledContext ) { if ( fOperator == op_throw ) return false ; ICPPFunction overload = getOverload ( ) ; if ( overload != null ) { < |startfocus| > return EvalUtil . evaluateNoexceptSpecifier ( overload . getType ( ) . getNoexceptSpecifier ( ) ) && fArgument . isNoexcept ( inCalledContext ) ; < |endfocus| > } return fArgument . isNoexcept ( inCalledContext ) ;
public void testToString ( ) { < |startfocus| > List < String > reference = Arrays . asList ( "Pomme" , "Peche" , "Poire" , "Banane" ) ; < |endfocus| > List < String > test = createList ( reference ) ; assertEquals ( " [ 0 : Pomme , 1 : Peche , 2 : Poire , 3 : Banane ] " , test . toString ( ) ) ; }
private static void testListIterator ( List < String > test ) { ListIterator < String > iterator = test . listIterator ( 0 ) ; assertTrue ( iterator . hasNext ( ) ) ; assertFalse ( iterator . hasPrevious ( ) ) ; try { iterator . previous ( ) ; fail ( "Should not get here" ) ; } catch ( NoSuchElementException e ) { // correct flow } iterator . next ( ) ; assertEquals ( "yo" , iterator . next ( ) ) ; < |startfocus| > assertEquals ( "hej" , iterator . previous ( ) ) ; < |endfocus| > try { iterator . previous ( ) ; fail ( "Should not get here" ) ; } catch ( NoSuchElementException e ) { // correct flow } iterator . next ( ) ; iterator . next ( ) ; iterator . next ( ) ; iterator . next ( ) ; try { iterator . next ( ) ; fail ( "Should not get here" ) ; } catch ( NoSuchElementException e ) { // correct flow } iterator . previous ( ) ; assertEquals ( 3 , iterator . previousIndex ( ) ) ; assertEquals ( 4 , iterator . nextIndex ( ) ) ; try { iterator . remove ( ) ; fail ( "Should not get here" ) ; } catch ( UnsupportedOperationException e ) { // correct flow } try { iterator . set ( "hej" ) ; fail ( "Should not get here" ) ;
import java . util . HashMap ; import java . util . Iterator ; import java . util . List ; import java . util . ListIterator ; import java . util . Map ; import java . util . Map . Entry ; import java . util . Objects ; import java . util . Spliterator ; import org . eclipse . jdt . annotation . NonNull ; import org . eclipse . jdt . annotation . Nullable ; /* * * Sparse list , a list optimized for when most of the data is < code > null </ code > . < |startfocus| > * Nulls will increment the size of the datastructure but not stored as null * means the data is not present . * < p > *
import java . util . List ; import java . util . ListIterator ; import java . util . Map ; import java . util . Map . Entry ; import java . util . Objects ; import java . util . Spliterator ; import org . eclipse . jdt . annotation . NonNull ; import org . eclipse . jdt . annotation . Nullable ; /* * * Sparse list , a list optimized for when most of the data is < code > null </ code > . * Nulls will increment the size of the datastructure but not stored as null * means the data is not present . * * This implementation supports : * < ul > * < li > { @link #add ( Object ) } </ li > * < li > { @link #contains ( Object ) } </ li > * < li > { @link #clear ( ) } </ li > * < li > { @link #iterator ( ) } </ li > * < li > { @link #isEmpty ( ) } </ li > * < li > { @link #toArray ( ) } </ li > * < li > { @link #toArray ( Object [ ] ) } </ li > * < li > { @link #set ( int , Object ) } </ li >
public boolean isEmpty ( ) { < |startfocus| > return super . isEmpty ( ) ; < |endfocus| >
public boolean contains ( Object o ) { < |startfocus| > return fInnerElements . containsValue ( o ) ; < |endfocus| > }
int size = fInnerElements . size ( ) ; Object [ ] retVal = new Object [ size ] ; Iterator < E > iterator = iterator ( ) ; for ( int i = 0 ; i < size ; i ++ ) { Object next = null ; while ( iterator . hasNext ( ) && next == null ) { next = iterator . next ( ) ; } retVal [ i ] = next ; } return retVal ; } < |startfocus| > /* * * { @inheritDoc } * * Warning , will throw exceptions if a [ ] is the wrong type . */ < |endfocus| > @Override public < T > T [ ] toArray ( T [ ] a ) { int size = Math . min ( a . length , fInnerElements . size ( ) ) ; Iterator < E > iterator = iterator ( ) ; for ( int i = 0 ; i < size ; i ++ ) { @Nullable E next = null ; while ( iterator . hasNext ( ) && next == null ) { next = iterator . next ( ) ; } a [ i ] = ( T ) next ; } return a ; } @Override public boolean add ( E e ) { if ( e != null ) { fInnerElements . add ( e ) ; return true ; } return false ; } @Override public boolean remove ( Object o ) { return fInnerElements . remove ( o ) ; } @Override public boolean containsAll ( Collection < ? > c ) { return fInnerElements . containsAll ( c ) ; } @Override public boolean addAll ( Collection < ? extends E > c ) { return fInnerElements . addAll ( c ) ; } @Override public boolean addAll ( int index , Collection < ? extends E > c ) { return fInnerElements . addAll ( index , c ) ; } @Override public boolean removeAll ( Collection < ? > c ) { return fInnerElements . removeAll ( c ) ; } @Override public boolean retainAll ( Collection < ? > c ) { return fInnerElements . retainAll ( c ) ; } @Override public void clear ( ) { fInnerElements . clear ( ) ; } @Override public E get ( int index ) { return fInnerElements . get ( index ) ; } @Override public E set ( int index , E element ) { return fInnerElements . set ( index , element ) ; } @Override public void add ( int index , E element ) { fInnerElements . add ( index , element ) ; } @Override public E remove ( int index ) { return fInnerElements . remove ( index ) ; } @Override public int indexOf ( Object o ) { return fInnerElements . indexOf ( o ) ; } @Override public int lastIndexOf ( Object o ) { return fInnerElements . lastIndexOf ( o ) ; } @Override public ListIterator < E > listIterator ( ) { return fInnerElements . listIterator ( ) ; } @Override public ListIterator < E > listIterator ( int index ) { return fInnerElements . listIterator ( index ) ; } @Override public List < E > subList ( int fromIndex , int toIndex ) { return fInnerElements . subList ( fromIndex , toIndex ) ; } @Override public boolean equals ( Object obj ) { if ( obj == this ) { return true ; } if ( obj instanceof NullableArrayList ) { NullableArrayList < ? > other = ( NullableArrayList < ? > ) obj ; return fInnerElements . equals ( other . fInnerElements ) ; } return false ; } @Override public int hashCode ( ) { return fInnerElements . hashCode ( ) ; } }
< |startfocus| > public int indexOf ( Object o ) { < |endfocus| > for ( Entry < Integer , E > entry : fInnerElements . entrySet ( ) ) { if ( Objects . equals ( entry . getValue ( ) , o ) ) { return entry . getKey ( ) ; } } return - 1 ;
public int lastIndexOf ( Object o ) { < |startfocus| > int last = - 1 ; < |endfocus| > for ( Entry < Integer , E > entry : fInnerElements . entrySet ( ) ) { if ( entry . getValue ( ) == null ? o == null : entry . getValue ( ) . equals ( o ) ) { last = Math . max ( last , entry . getKey ( ) ) ; } } return last ;
private void fixSize ( ) { perspSwitcherToolbar . pack ( ) ; perspSwitcherToolbar . getParent ( ) . pack ( ) ; < |startfocus| > perspSwitcherToolbar . requestLayout ( ) ; < |endfocus| >
public TimeGraphEntry ( @NonNull ITmfTreeDataModel model ) { < |startfocus| > setModel ( model ) ; < |endfocus| >
public boolean equals ( Object obj ) { if ( ! super . equals ( obj ) ) { return false ; } < |startfocus| > if ( obj instanceof TimeLineEvent ) { < |endfocus| > TimeLineEvent lineEvent = ( TimeLineEvent ) obj ; return Objects . equals ( getValues ( ) , lineEvent . getValues ( ) ) ; } return false ;
protected IResource getResource ( IPath path ) { if ( path != null ) { IWorkspaceRoot root = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) ; // look for files or folders with the given path IFile file = root . getFileForLocation ( path ) ; if ( file != null ) { return file ; } if ( getType ( ) != ARCHIVE ) { IContainer container = root . getContainerForLocation ( path ) ; if ( container != null ) { return container ; } } @SuppressWarnings ( "deprecation" ) IFile [ ] files = root . findFilesForLocation ( path ) ; if ( files . length > 0 ) { return files [ 0 ] ; } if ( getType ( ) != ARCHIVE ) { @SuppressWarnings ( "deprecation" ) IContainer [ ] containers = root . findContainersForLocation ( path ) ; if ( containers . length > 0 ) { return containers [ 0 ] ; } } < |startfocus| > if ( path . getDevice ( ) == null ) { // search relative to the workspace if no device present IResource member = root . findMember ( path ) ; if ( member != null ) { return member ; } } < |endfocus| > } return null ;
import org . eclipse . jdt . core . IMember ; import org . eclipse . jdt . core . search . IJavaSearchConstants ; /* * * This class represents the general parts of a method call ( either to or from a * method ) . */ public abstract class MethodWrapper extends PlatformObject { 	public static IMethodWrapperDynamic fMethodWrapperCore = new MethodWrapperDynamicCore ( ) ; 	 /* * 	 * Set the IMethodWrapperCore class to use in MethodWrapper 	 * 	 * @param core 	 * the IMethodWrapperCore class to store < |startfocus| > 	 * @since 1 . 12 < |endfocus| > 	 */ 	public static final void setMethodWrapperDynamic ( IMethodWrapperDynamic core ) { 		fMethodWrapperCore = core ; 	 } 	private Map < String , MethodCall > fElements = null ; 	 /* 	 * A cache of previously found methods . This cache should be searched 	 * before adding a "new" method object reference to the list of elements . 	 * This way previously found methods won't be searched again . 	 */ 	private Map < String , Map < String , MethodCall > > fMethodCache ; 	private final MethodCall fMethodCall ; 	private final MethodWrapper fParent ; 	private int fLevel ;
private static void testListIterator ( List < String > test ) { ListIterator < String > iterator = test . listIterator ( 0 ) ; assertTrue ( iterator . hasNext ( ) ) ; assertFalse ( iterator . hasPrevious ( ) ) ; try { iterator . previous ( ) ; fail ( "Should not get here" ) ; } catch ( NoSuchElementException e ) { // correct flow } < |startfocus| > assertEquals ( "Hola" , iterator . next ( ) ) ; < |endfocus| > assertEquals ( "yo" , iterator . next ( ) ) ; assertEquals ( "yo" , iterator . previous ( ) ) ; assertEquals ( "Hola" , iterator . previous ( ) ) ; try { iterator . previous ( ) ; fail ( "Should not get here" ) ; } catch ( NoSuchElementException e ) { // correct flow } assertEquals ( "Hola" , iterator . next ( ) ) ; assertEquals ( "yo" , iterator . next ( ) ) ; assertEquals ( "quiero" , iterator . next ( ) ) ; assertEquals ( "un" , iterator . next ( ) ) ; assertEquals ( "UNSUPPORTEDOPERATIONEXCEPTION ! " , iterator . next ( ) ) ; try { iterator . next ( ) ; fail ( "Should not get here" ) ; } catch ( NoSuchElementException e ) { // correct flow } assertEquals ( "UNSUPPORTEDOPERATIONEXCEPTION ! " , iterator . previous ( ) ) ; assertEquals ( 3 , iterator . previousIndex ( ) ) ;
public GenericReadOnlyListIterator ( List < E > list , int start , int end ) { fList = list ; < |startfocus| > fStart = start ; fEnd = end ; < |endfocus| > fCursor = start - 1 ;
public GenericReadOnlyListIterator ( List < E > list , int start , int end ) { fList = list ; < |startfocus| > fStart = start ; fEnd = end ; < |endfocus| > fCursor = start ;
public boolean hasNext ( ) { < |startfocus| > return fCursor < fEnd ; < |endfocus| >
public boolean hasPrevious ( ) { < |startfocus| > return fCursor > 0 ; < |endfocus| >
public boolean contains ( Object o ) { < |startfocus| > return ( o == null ? size ( ) > fInnerElements . size ( ) : fInnerElements . containsValue ( o ) ) ; < |endfocus| >
@Nullable E next = null ; while ( iterator . hasNext ( ) && next == null ) { next = iterator . next ( ) ; } if ( next != null ) { Class < ? extends @NonNull Object > elementClass = next . getClass ( ) ; if ( ! Objects . equals ( elementClass , componentType ) && ! elementClass . isInstance ( componentType ) ) { throw new ArrayStoreException ( "Cannot convert from ( " + elementClass + " to " + newArray . getClass ( ) . getComponentType ( ) ) ; // $NON - NLS - 1$ // $NON - NLS - 2$ } } < |startfocus| > newArray [ i ] = ( T ) next ; < |endfocus| >
public int indexOf ( Object o ) { if ( o == null && contains ( null ) ) { for ( int i = 0 ; i < size ( ) ; i ++ ) { if ( ! fInnerElements . containsKey ( i ) ) { return i ; } } } for ( Entry < Integer , E > entry : fInnerElements . entrySet ( ) ) { if ( Objects . equals ( entry . getValue ( ) , o ) ) { < |startfocus| > return entry . getKey ( ) ; < |endfocus| > } } return - 1 ;
public Spliterator < E > spliterator ( ) { < |startfocus| > return fInnerElements . values ( ) . stream ( ) . filter ( Objects : : nonNull ) . collect ( Collectors . toList ( ) ) . spliterator ( ) ; < |endfocus| >
public ListIterator < E > listIterator ( int index ) { < |startfocus| > return new GenericReadOnlyListIterator < > ( this , index , size ( ) ) ; < |endfocus| >
public void add ( int index , E element ) { < |startfocus| > throw new UnsupportedOperationException ( "No add ( index ) in " + this . getClass ( ) . getName ( ) ) ; // $NON - NLS - 1$ < |endfocus| >
public E remove ( int index ) { < |startfocus| > throw new UnsupportedOperationException ( "No delete in " + this . getClass ( ) . getName ( ) ) ; // $NON - NLS - 1$ < |endfocus| >
public boolean remove ( Object o ) { < |startfocus| > throw new UnsupportedOperationException ( "No remove in " + this . getClass ( ) . getName ( ) ) ; // $NON - NLS - 1$ < |endfocus| >
public boolean addAll ( int index , Collection < ? extends E > c ) { < |startfocus| > throw new UnsupportedOperationException ( "No addAll ( index ) in " + this . getClass ( ) . getName ( ) ) ; // $NON - NLS - 1$ < |endfocus| >
throw new UnsupportedOperationException ( "No removeAll in " + this . getClass ( ) . getName ( ) ) ; // $NON - NLS - 1$ } @Override public boolean retainAll ( Collection < ? > c ) { throw new UnsupportedOperationException ( "No retainAll in " + this . getClass ( ) . getName ( ) ) ; // $NON - NLS - 1$ } @Override public @NonNull List < E > subList ( int fromIndex , int toIndex ) { < |startfocus| > return new UnmodifiableList < E > ( this . list . subList ( fromIndex , toIndex ) ) ; < |endfocus| > } }
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * < |startfocus| > * Copyright ( c ) 2019 vogella GmbH and others . < |endfocus| > * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Simon Scholz < simon . scholz@vogella . com > - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** / package org . eclipse . e4 . ui . tests . workbench ; import org . eclipse . e4 . core . di . annotations . Evaluate ; import org . eclipse . e4 . ui . model . application . ui . MImperativeExpression ; public class ImperativeExpressionTestEvaluationPersistedState { public static final String PERSISTED_STATE_TEST = "persisted - state - test" ; @Evaluate public boolean isVisible ( MImperativeExpression exp ) { return exp . getPersistedState ( ) . containsKey ( PERSISTED_STATE_TEST ) ; } }
* { @link BitmapWalker } . * * @since 5 . 5 */ final class BitmapCalculator { private final RevWalk walk ; private final BitmapIndex bitmapIndex ; private final ProgressMonitor pm ; private long countOfBitmapIndexMisses ; private final BitmapWalkHook preWalkHook ; private final BitmapWalkHook postWalkHook ; /* * * Hook that can be invoked before or after the walk building the bitmap of * a commit that doesn't have one . * < p > * This is intended to be used only by { @link BitmapWalker } . */ interface BitmapWalkHook { /* * * Hooked invoked before and after traversing the tree building a commit * bitmap . * * @param walk * revwalk in use . * @param bitmapResult * bitmap calculated so far . * @param pm * progress monitor * @throws IOException */ void run ( RevWalk walk , BitmapBuilder bitmapResult , ProgressMonitor pm ) throws IOException ; }
private final RevWalk walk ; private final BitmapIndex bitmapIndex ; private final ProgressMonitor pm ; private long countOfBitmapIndexMisses ; private final BitmapWalkHook preWalkHook ; private final BitmapWalkHook postWalkHook ; /* * * Hook that can be invoked before or after the walk building the bitmap of * a commit that doesn't have one . * < p > * This is intended to be used only by { @link BitmapWalker } . */ interface BitmapWalkHook { /* * < |startfocus| > * Hooked invoked before and after traversing the tree building a commit * bitmap . < |endfocus| > * * @param walk * revwalk in use . * @param bitmapResult * bitmap calculated so far . * @param pm * progress monitor * @throws IOException */ void run ( RevWalk walk , BitmapBuilder bitmapResult , ProgressMonitor pm ) throws IOException ; } private static final BitmapWalkHook NULL_BITMAP_HOOK = new BitmapWalkHook ( ) { @Override public void run ( RevWalk walk , BitmapBuilder bitmapResult , ProgressMonitor pm ) throws IOException {
BitmapBuilder seen , boolean ignoreMissing ) throws MissingObjectException , IncorrectObjectTypeException , IOException { return this . bitmapCalculator . getBitmapFor ( start , seen , ignoreMissing ) ; } /* * * Filter that excludes objects already in the given bitmap . */ static class BitmapObjectFilter extends ObjectFilter { private final BitmapBuilder bitmap ; BitmapObjectFilter ( BitmapBuilder bitmap ) { this . bitmap = bitmap ; } @Override public final boolean include ( ObjectWalk walker , AnyObjectId objid ) throws MissingObjectException , IncorrectObjectTypeException , IOException { return ! bitmap . contains ( objid ) ; } } }
public void set ( Object [ ] newContents ) { 	Assert . isNotNull ( newContents ) ; 	data . clear ( ) ; 	data . addAll ( Arrays . asList ( newContents ) ) ; 	 < |startfocus| > 	IConcurrentModelListener [ ] listeners = getListeners ( ) ; 	for ( IConcurrentModelListener listener : listeners ) { 		 < |endfocus| > 		listener . setContents ( newContents ) ; 	 } }
// copy only linked resource children ( 267173 ) if ( source . isLinked ( ) && source . getLocation ( ) . equals ( existing . getLocation ( ) ) ) children = filterNonLinkedResources ( children ) ; ResourceDescription [ ] overwritten = copy ( children , destinationPath , resourcesAtDestination , iterationProgress , uiInfo , false , createVirtual , createLinks , relativeToVariable ) ; < |startfocus| > // We don't record the copy since this recursive call will // do so . Just record the overwrites . overwrittenResources . addAll ( Arrays . asList ( overwritten ) ) ; < |endfocus| > } else { // delete the destination folder , copying a linked folder // over an unlinked one or vice versa . Fixes bug 28772 . ResourceDescription [ ] deleted = delete ( new IResource [ ] { existing } , iterationProgress . split ( 1 ) , uiInfo , false ) ; iterationProgress . setWorkRemaining ( 100 ) ; if ( ( createLinks || createVirtual ) && ( source . isLinked ( ) == false ) && ( source . isVirtual ( ) == false ) ) { IFolder folder = workspaceRoot . getFolder ( destinationPath ) ; if ( createVirtual ) { folder . create ( IResource . VIRTUAL , true , iterationProgress . split ( 1 ) ) ; }
if ( mapping == null ) continue ; ResourceTraversal [ ] traversals = null ; try { traversals = mapping . getTraversals ( ResourceMappingContext . LOCAL_CONTEXT , new NullProgressMonitor ( ) ) ; } catch ( CoreException e ) { StatusManager . getManager ( ) . handle ( e , IDEWorkbenchPlugin . IDE_WORKBENCH ) ; } if ( traversals != null ) { IResource [ ] resources = null ; for ( ResourceTraversal traversal : traversals ) { resources = traversal . getResources ( ) ; if ( resources != null ) { < |startfocus| > result . addAll ( Arrays . asList ( resources ) ) ; < |endfocus| > } } } } else result . add ( resource ) ; } // all that can be converted are done , answer new selection if ( result . isEmpty ( ) ) { return StructuredSelection . EMPTY ; } return new StructuredSelection ( result . toArray ( ) ) ;
static Set < IResource > getResourcesForFilter ( MarkerFieldFilterGroup group , IResource [ ] selectedResources , IWorkspaceRoot root ) { 	HashSet < IResource > resourceSet = new HashSet < > ( ) ; 	switch ( group . getScope ( ) ) { 		case MarkerFieldFilterGroup . ON_ANY : { 			resourceSet . add ( root ) ; 			break ; 		 } 		case MarkerFieldFilterGroup . ON_SELECTED_ONLY : 		case MarkerFieldFilterGroup . ON_SELECTED_AND_CHILDREN : { 			 < |startfocus| > 			resourceSet . addAll ( Arrays . asList ( selectedResources ) ) ; 			 < |endfocus| > 			break ; 		 } 		case MarkerFieldFilterGroup . ON_ANY_IN_SAME_CONTAINER : { 			for ( IResource resource : getProjects ( selectedResources ) ) { 				resourceSet . add ( resource ) ; 			 } 			break ; 		 } 		case MarkerFieldFilterGroup . ON_WORKING_SET : { 			group . refresh ( ) ; 			resourceSet . addAll ( Arrays . asList ( group . getResourcesInWorkingSet ( ) ) ) ; 			break ; 		 } 	 } 	return resourceSet ; }
* * @author Alvaro Sanchez - Leon * @author Patrick Tasse */ public interface ITimeGraphEntry extends ISelection { /* * * An enumeration of the display style of the time graph entries * * @author Genevive Bastien * @since 5 . 0 */ public enum DisplayStyle { /* * * Display states , ie rectangle representing a discrete state that has a * beginning and an end */ STATE , /* * < |startfocus| > * Display XY lines for this entry , ie continuous values that changes < |endfocus| > * over time */ LINE } /* * * Returns the parent of this entry , or < code > null </ code > if it has none . * * @return the parent element , or < code > null </ code > if it has none */ ITimeGraphEntry getParent ( ) ; /* * * Returns whether this entry has children . * * @return < code > true </ code > if the given element has children , * and < code > false </ code > if it has no children */ boolean hasChildren ( ) ; /* * * Returns the children of this entry , or an empty array if it has none . * * @return the children of this entry */ ITimeGraphEntry [ ] getChildren ( ) ; /* * * Returns the name of this entry . * * @return the name of this entry */ String getName ( ) ; /* * * Returns the start time of this entry . * * @return the start time of this entry */ long getStartTime ( ) ; /* * * Returns the end time of this entry . * * @return the end time of this entry */ long getEndTime ( ) ; /* * * Returns the list of events associated with this entry . * * @return the list of events associated with this entry */ List < ITimeEvent > getEventList ( ) ; /* * * Returns the list of links associated with this entry . * * @return the list of links associated with this entry */ List < ILinkEvent > getLinkList ( ) ; /* * * Returns the display style of this entry . * * @return the display style of this entry */ DisplayStyle getDisplayStyle ( ) ; /* * * Returns the list of labels associated with this entry . * * @return the list of labels associated with this entry */ List < String > getLabels ( ) ; /* * * Returns the list of tool tip texts associated with this entry . * * @return the list of tool tip texts associated with this entry */ List < String > getTooltip ( ) ; /* * * Returns the list of colors associated with this entry . * * @return the list of colors associated with this entry */ List < RGBAColor > getColors ( ) ; /* * * Returns the list of background colors associated with this entry . * * @return the list of background colors associated with this entry */ List < RGBAColor > getBackgroundColors ( ) ; /* * * Returns the list of foreground colors associated with this entry . * * @return the list of foreground colors associated with this entry */ List < RGBAColor > getForegroundColors ( ) ; /* * * Returns the list of font styles associated with this entry . * * @return the list of font styles associated with this entry */ List < FontStyle > getFontStyles ( ) ; /* * * Returns the list of font colors associated with this entry . * * @return the list of font colors associated with this entry */ List < RGBAColor > getFontColors ( ) ; /* * * Returns the list of font background colors associated with this entry . * * @return the list of font background colors associated with this entry */ List < RGBAColor > getFontBackgroundColors ( ) ; /* * * Returns the list of font foreground colors associated with this entry . * * @return the list of font foreground colors associated with this entry */ List < RGBAColor > getFontForegroundColors ( ) ; /* * * Returns the list of arrow styles associated with this entry . * * @return the list of arrow styles associated with this entry */ List < ArrowStyle > getArrowStyles ( ) ; /* * * Returns the list of arrow colors associated with this entry . * * @return the list of arrow colors associated with this entry */ List < RGBAColor > getArrowColors ( ) ; /* * * Returns the list of arrow background colors associated with this entry . * * @return the list of arrow background colors associated with this entry */ List < RGBAColor > getArrowBackgroundColors ( ) ; /* * * Returns the list of arrow foreground colors associated with this entry . * * @return the list of arrow foreground colors associated with this entry */ List < RGBAColor > getArrowForegroundColors ( ) ; /* * * Returns the list of line styles associated with this entry . * * @return the list of line styles associated with this entry */ List < LineStyle > getLineStyles ( ) ; /* * * Returns the list of line widths associated with this entry . * * @return the list of line widths associated with this entry */ List < Integer > getLineWidths ( ) ; /* * * Returns the list of line colors associated with this entry . * * @return the list of line colors associated with this entry */ List < RGBAColor > getLineColors ( ) ; /* * * Returns the list of line background colors associated with this entry . * * @return the list of line background colors associated with this entry */ List < RGBAColor > getLineBackgroundColors ( ) ; /* * * Returns the list of line foreground colors associated with this entry . * * @return the list of line foreground colors associated with this entry */ List < RGBAColor > getLineForegroundColors ( ) ; /* * * Returns the list of symbol styles associated with this entry . * * @return the list of symbol styles associated with this entry */ List < SymbolStyle > getSymbolStyles ( ) ; /* * * Returns the list of symbol colors associated with this entry . * * @return the list of symbol colors associated with this entry */ List < RGBAColor > getSymbolColors ( ) ; /* * * Returns the list of symbol background colors associated with this entry . * * @return the list of symbol background colors associated with this entry */ List < RGBAColor > getSymbolBackgroundColors ( ) ; /* * * Returns the list of symbol foreground colors associated with this entry . * * @return the list of symbol foreground colors associated with this entry */ List < RGBAColor > getSymbolForegroundColors ( ) ; /* * * Returns the list of symbol sizes associated with this entry . * * @return the list of symbol sizes associated with this entry */ List < Integer > getSymbolSizes ( ) ; }
public void addEvent ( ITimeEvent event ) { if ( ! ( event instanceof ITimeLineEvent ) ) { < |startfocus| > throw new IllegalArgumentException ( "Need to be a TimeLineEvent" ) ; // $NON - NLS - 1$ < |endfocus| > } super . addEvent ( event ) ;
public void addEvent ( ITimeEvent event ) { if ( ! ( event instanceof TimeLineEvent ) ) { < |startfocus| > throw new IllegalArgumentException ( "Needs to be a TimeLineEvent" ) ; // $NON - NLS - 1$ < |endfocus| > } super . addEvent ( event ) ;
< |startfocus| > public TimeLineEvent ( ITimeGraphEntry entry , long time , long duration ) { this ( entry , time , 0 , new ArrayList < > ( ) ) ; < |endfocus| >
< |startfocus| > public TimeLineEvent ( ITimeGraphEntry entry , long time , long duration , List < Long > values ) { super ( entry , time , duration ) ; < |endfocus| > fValues = values ;
public boolean equals ( Object obj ) { < |startfocus| > if ( ! super . equals ( obj ) ) { < |endfocus| > return false ; } if ( obj instanceof TimeLineEvent ) { TimeLineEvent lineEvent = ( TimeLineEvent ) obj ; return Objects . equals ( getValues ( ) , lineEvent . getValues ( ) ) ; } return false ;
public boolean equals ( Object obj ) { if ( ! super . equals ( obj ) ) { return false ; } < |startfocus| > if ( obj instanceof TimeLineEvent ) { < |endfocus| > TimeLineEvent lineEvent = ( TimeLineEvent ) obj ; return Objects . equals ( getValues ( ) , lineEvent . getValues ( ) ) ; } return false ;
public String toString ( ) { StringBuilder builder = new StringBuilder ( ) ; builder . append ( " [ TimeLineEvent Values = " ) . append ( getValues ( ) ) // $NON - NLS - 1$ . append ( " , Entry = " ) . append ( getEntry ( ) ) // $NON - NLS - 1$ . append ( " , Time = " ) . append ( getTime ( ) ) // $NON - NLS - 1$ < |startfocus| > . append ( ' ] ' ) ; return builder . toString ( ) ; < |endfocus| >
private void drawLineGraphEntry ( GC gc , long time0 , Rectangle rect , double pixelsPerNanoSec , Iterator < ITimeEvent > iterator ) { // clamp 0 - max positive long max = Long . MIN_VALUE ; long min = 0 ; List < @Nullable TimeLineEvent > refs = new ArrayList < > ( ) ; List < RGBA > colors = new ArrayList < > ( ) ; // todo : update when we want mutliple series ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider ( ) ; int nbSeries = 1 ; < |startfocus| > List < List < LongPoint > > toDraw = new ArrayList < > ( ) ; < |endfocus| > for ( int i = 0 ; i < nbSeries ; i ++ ) { toDraw . add ( new ArrayList < > ( ) ) ; } while ( iterator . hasNext ( ) ) { ITimeEvent event = iterator . next ( ) ; if ( ! ( event instanceof TimeLineEvent ) ) { continue ; } int x = SaturatedArithmetic . add ( rect . x , ( int ) ( ( event . getTime ( ) - time0 ) * pixelsPerNanoSec ) ) ; int xEnd = SaturatedArithmetic . add ( rect . x , ( int ) ( ( event . getTime ( ) + event . getDuration ( ) - time0 ) * pixelsPerNanoSec ) ) ;
private void drawLineGraphEntry ( GC gc , long time0 , Rectangle rect , double pixelsPerNanoSec , Iterator < ITimeEvent > iterator ) { // clamp 0 - max positive long max = Long . MIN_VALUE ; long min = 0 ; List < @Nullable TimeLineEvent > refs = new ArrayList < > ( ) ; < |startfocus| > List < List < LongPoint > > toDraw = new ArrayList < > ( ) ; < |endfocus| > List < RGBA > colors = new ArrayList < > ( ) ; // todo : update when we want mutliple series ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider ( ) ; int nbSeries = 1 ; for ( int i = 0 ; i < nbSeries ; i ++ ) { toDraw . add ( new ArrayList < > ( ) ) ; } while ( iterator . hasNext ( ) ) { ITimeEvent event = iterator . next ( ) ; if ( ! ( event instanceof TimeLineEvent ) ) { continue ; } int x = SaturatedArithmetic . add ( rect . x , ( int ) ( ( event . getTime ( ) - time0 ) * pixelsPerNanoSec ) ) ; int xEnd = SaturatedArithmetic . add ( rect . x , ( int ) ( ( event . getTime ( ) + event . getDuration ( ) - time0 ) * pixelsPerNanoSec ) ) ;
// clamp 0 - max positive long max = Long . MIN_VALUE ; long min = 0 ; List < @Nullable TimeLineEvent > refs = new ArrayList < > ( ) ; List < List < LongPoint > > toDraw = new ArrayList < > ( ) ; List < RGBA > colors = new ArrayList < > ( ) ; // todo : update when we want mutliple series ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider ( ) ; < |startfocus| > int nbSeries = 1 ; for ( int i = 0 ; i < nbSeries ; i ++ ) { toDraw . add ( new ArrayList < > ( ) ) ; } < |endfocus| > while ( iterator . hasNext ( ) ) { ITimeEvent event = iterator . next ( ) ; if ( ! ( event instanceof TimeLineEvent ) ) { continue ; } int x = SaturatedArithmetic . add ( rect . x , ( int ) ( ( event . getTime ( ) - time0 ) * pixelsPerNanoSec ) ) ; int xEnd = SaturatedArithmetic . add ( rect . x , ( int ) ( ( event . getTime ( ) + event . getDuration ( ) - time0 ) * pixelsPerNanoSec ) ) ; if ( x >= rect . x + rect . width || xEnd < rect . x ) { // event is out of bounds , skip it
} while ( iterator . hasNext ( ) ) { ITimeEvent event = iterator . next ( ) ; if ( ! ( event instanceof TimeLineEvent ) ) { continue ; } int x = SaturatedArithmetic . add ( rect . x , ( int ) ( ( event . getTime ( ) - time0 ) * pixelsPerNanoSec ) ) ; < |startfocus| > int xEnd = SaturatedArithmetic . add ( rect . x , ( int ) ( ( event . getTime ( ) + event . getDuration ( ) - time0 ) * pixelsPerNanoSec ) ) ; if ( x >= rect . x + rect . width || xEnd < rect . x ) { < |endfocus| > // event is out of bounds continue ; } TimeLineEvent timeEvent = ( TimeLineEvent ) event ; List < Long > values = timeEvent . getValues ( ) ; for ( int i = 0 ; i < nbSeries ; i ++ ) { long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; min = Math . min ( Math . abs ( val ) , min ) ; toDraw . get ( i ) . add ( new LongPoint ( x , val ) ) ; refs . add ( timeEvent ) ; } } if ( refs . isEmpty ( ) ) { return ; }
if ( ! ( event instanceof TimeLineEvent ) ) { continue ; } int x = SaturatedArithmetic . add ( rect . x , ( int ) ( ( event . getTime ( ) - time0 ) * pixelsPerNanoSec ) ) ; int xEnd = SaturatedArithmetic . add ( rect . x , ( int ) ( ( event . getTime ( ) + event . getDuration ( ) - time0 ) * pixelsPerNanoSec ) ) ; if ( x >= rect . x + rect . width || xEnd < rect . x ) { // event is out of bounds continue ; } TimeLineEvent timeEvent = ( TimeLineEvent ) event ; < |startfocus| > List < Long > values = timeEvent . getValues ( ) ; < |endfocus| > for ( int i = 0 ; i < nbSeries ; i ++ ) { long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; min = Math . min ( Math . abs ( val ) , min ) ; toDraw . get ( i ) . add ( new LongPoint ( x , val ) ) ; refs . add ( timeEvent ) ; } } if ( refs . isEmpty ( ) ) { return ; } for ( int i = 0 ; i < nbSeries ; i ++ ) {
} int x = SaturatedArithmetic . add ( rect . x , ( int ) ( ( event . getTime ( ) - time0 ) * pixelsPerNanoSec ) ) ; int xEnd = SaturatedArithmetic . add ( rect . x , ( int ) ( ( event . getTime ( ) + event . getDuration ( ) - time0 ) * pixelsPerNanoSec ) ) ; if ( x >= rect . x + rect . width || xEnd < rect . x ) { // event is out of bounds continue ; } TimeLineEvent timeEvent = ( TimeLineEvent ) event ; < |startfocus| > List < Long > values = timeEvent . getValues ( ) ; < |endfocus| > for ( int i = 0 ; i < timeEvent . getValues ( ) . size ( ) ; i ++ ) { long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; min = Math . min ( Math . abs ( val ) , min ) ; toDraw . get ( i ) . add ( new LongPoint ( x , val ) ) ; refs . add ( timeEvent ) ; } } if ( refs . isEmpty ( ) ) { return ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( refs . get ( i ) ) ;
if ( x >= rect . x + rect . width || xEnd < rect . x ) { // event is out of bounds continue ; } TimeLineEvent timeEvent = ( TimeLineEvent ) event ; List < Long > values = timeEvent . getValues ( ) ; for ( int i = 0 ; i < nbSeries ; i ++ ) { long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; < |startfocus| > toDraw . get ( i ) . add ( new LongPoint ( x , val ) ) ; < |endfocus| > refs . add ( timeEvent ) ; } } if ( refs . isEmpty ( ) ) { return ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( refs . get ( i ) ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; }
if ( x >= rect . x + rect . width || xEnd < rect . x ) { // event is out of bounds continue ; } TimeLineEvent timeEvent = ( TimeLineEvent ) event ; List < Long > values = timeEvent . getValues ( ) ; for ( int i = 0 ; i < nbSeries ; i ++ ) { long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; min = Math . min ( Math . abs ( val ) , min ) ; < |startfocus| > if ( i >= toDraw . size ( ) ) { toDraw . add ( new ArrayList < > ( ) ) ; } toDraw . get ( i ) . add ( new LongPoint ( x , val ) ) ; < |endfocus| > refs . add ( timeEvent ) ; } } if ( refs . isEmpty ( ) ) { return ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( refs . get ( i ) ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; }
List < Long > values = timeEvent . getValues ( ) ; for ( int i = 0 ; i < nbSeries ; i ++ ) { long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; min = Math . min ( Math . abs ( val ) , min ) ; toDraw . get ( i ) . add ( new LongPoint ( x , val ) ) ; refs . add ( timeEvent ) ; } } if ( refs . isEmpty ( ) ) { return ; } < |startfocus| > for ( int i = 0 ; i < toDraw . size ( ) ; i ++ ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( refs . get ( i ) ) ; < |endfocus| > int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; } double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; for ( int i = 0 ; i < nbSeries ; i ++ ) { RGBA rgba = colors . get ( i ) ;
long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; min = Math . min ( Math . abs ( val ) , min ) ; toDraw . get ( i ) . add ( new LongPoint ( x , val ) ) ; refs . add ( timeEvent ) ; } } if ( refs . isEmpty ( ) ) { return ; } < |startfocus| > for ( int i = 0 ; i < nbSeries ; i ++ ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( refs . get ( i ) ) ; < |endfocus| > int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; } double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; for ( int i = 0 ; i < nbSeries ; i ++ ) { RGBA rgba = colors . get ( i ) ; Color color = COLOR_REGISTRY . get ( rgba . toString ( ) ) ; Color prev = gc . getForeground ( ) ; int prevAlpha = gc . getAlpha ( ) ; gc . setAlpha ( rgba . alpha ) ; gc . setForeground ( color ) ;
Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( refs . get ( i ) ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; } double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; < |startfocus| > for ( int i = 0 ; i < toDraw . size ( ) ; i ++ ) { < |endfocus| > RGBA rgba = colors . get ( i ) ; Color color = COLOR_REGISTRY . get ( rgba . toString ( ) ) ; Color prev = gc . getForeground ( ) ; int prevAlpha = gc . getAlpha ( ) ; gc . setAlpha ( rgba . alpha ) ; gc . setForeground ( color ) ; List < LongPoint > series = toDraw . get ( i ) ; int [ ] points = new int [ series . size ( ) * 2 ] ; for ( int point = 0 ; point < series . size ( ) ; point ++ ) { LongPoint longPoint = series . get ( point ) ; points [ point * 2 ] = longPoint . x ;
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * < |startfocus| > * Copyright ( c ) 2000 , 2016 IBM Corporation and others . < |endfocus| > * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * IBM Corporation - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . jface . viewers ; import org . eclipse . core . runtime . Assert ; import org . eclipse . swt . dnd . DND ; import org . eclipse . swt . dnd . DropTargetAdapter ; import org . eclipse . swt . dnd . DropTargetEvent ; import org . eclipse . swt . dnd . TransferData ; import org . eclipse . swt . graphics . Point ; import org . eclipse . swt . graphics . Rectangle ; import org . eclipse . swt . widgets . Item ; import org . eclipse . swt . widgets . List ; import org . eclipse . swt . widgets . Table ; import org . eclipse . swt . widgets . TableItem ; import org . eclipse . swt . widgets . Tree ; import org . eclipse . swt . widgets . TreeItem ; /* * * This adapter class provides generic drag - and - drop support for a viewer . * < p >
for ( int i = 0 ; i < resources . length ; i ++ ) { // Copy the resources and record the overwrites that would // be restored if this operation were reversed ResourceDescription [ ] overwrites ; overwrites = WorkspaceUndoUtil . copy ( new IResource [ ] { resources [ i ] } , getDestinationPath ( resources [ i ] , i ) , resourcesAtDestination , subMonitor . split ( 1 ) , uiInfo , true , fCreateGroups , fCreateLinks , fRelativeToVariable ) ; < |startfocus| > // Accumulate the overwrites into the full list overwrittenResources . addAll ( Arrays . asList ( overwrites ) ) ; < |endfocus| > } // Are there any previously overwritten resources to restore now ? if ( resourceDescriptions != null ) { for ( ResourceDescription resourceDescription : resourceDescriptions ) { if ( resourceDescription != null ) { resourceDescription . createResource ( subMonitor . split ( 1 ) ) ; } } } // Reset resource descriptions to the just overwritten resources setResourceDescriptions ( overwrittenResources . toArray ( new ResourceDescription [ overwrittenResources . size ( ) ] ) ) ; // Reset the target resources to refer to the resources in their new // location . setTargetResources ( resourcesAtDestination
for ( int i = 0 ; i < resources . length ; i ++ ) { // Move the resources and record the overwrites that would // be restored if this operation were reversed ResourceDescription [ ] overwrites ; overwrites = WorkspaceUndoUtil . move ( new IResource [ ] { resources [ i ] } , getDestinationPath ( resources [ i ] , i ) , resourcesAtDestination , undoDestinationPaths , subMonitor . split ( 1 ) , uiInfo , true ) ; < |startfocus| > // Accumulate the overwrites into the full list overwrittenResources . addAll ( Arrays . asList ( overwrites ) ) ; < |endfocus| > } // Are there any previously overwritten resources to restore now ? if ( resourceDescriptions != null ) { for ( ResourceDescription resourceDescription : resourceDescriptions ) { if ( resourceDescription != null ) { resourceDescription . createResource ( subMonitor . split ( 1 ) ) ; } } } // Reset resource descriptions to the just overwritten resources setResourceDescriptions ( overwrittenResources . toArray ( new ResourceDescription [ overwrittenResources . size ( ) ] ) ) ; // Reset the target resources to refer to the resources in their new // location . setTargetResources ( resourcesAtDestination . toArray ( new IResource [ resourcesAtDestination . size ( ) ] ) ) ;
// copy only linked resource children ( 267173 ) if ( source . isLinked ( ) && source . getLocation ( ) . equals ( existing . getLocation ( ) ) ) children = filterNonLinkedResources ( children ) ; ResourceDescription [ ] overwritten = copy ( children , destinationPath , resourcesAtDestination , iterationProgress , uiInfo , false , createVirtual , createLinks , relativeToVariable ) ; < |startfocus| > // We don't record the copy since this recursive call will // do so . Just record the overwrites . overwrittenResources . addAll ( Arrays . asList ( overwritten ) ) ; < |endfocus| > } else { // delete the destination folder , copying a linked folder // over an unlinked one or vice versa . Fixes bug 28772 . ResourceDescription [ ] deleted = delete ( new IResource [ ] { existing } , iterationProgress . split ( 1 ) , uiInfo , false ) ; iterationProgress . setWorkRemaining ( 100 ) ; if ( ( createLinks || createVirtual ) && ( source . isLinked ( ) == false ) && ( source . isVirtual ( ) == false ) ) { IFolder folder = workspaceRoot . getFolder ( destinationPath ) ; if ( createVirtual ) { folder . create ( IResource . VIRTUAL , true , iterationProgress . split ( 1 ) ) ;
IResource [ ] children = ( ( IContainer ) resource ) . members ( ) ; // move only linked resource children ( 267173 ) if ( resource . isLinked ( ) && resource . getLocation ( ) . equals ( existing . getLocation ( ) ) ) children = filterNonLinkedResources ( children ) ; ResourceDescription [ ] overwritten = move ( children , destinationPath , resourcesAtDestination , reverseDestinations , iterationProgress . split ( 90 ) , uiInfo , false ) ; < |startfocus| > // We don't record the moved resources since the recursive // call has done so . Just record the overwrites . overwrittenResources . addAll ( Arrays . asList ( overwritten ) ) ; < |endfocus| > // Delete the source . No need to record it since it // will get moved back . delete ( resource , iterationProgress . split ( 10 ) , uiInfo , false , false ) ; } else { // delete the destination folder , moving a linked folder // over an unlinked one or vice versa . Fixes bug 28772 . ResourceDescription [ ] deleted = delete ( new IResource [ ] { existing } , iterationProgress . split ( 10 ) , uiInfo , false ) ; // Record the original path reverseDestinations . add ( resource . getFullPath ( ) ) ;
if ( mapping == null ) continue ; ResourceTraversal [ ] traversals = null ; try { traversals = mapping . getTraversals ( ResourceMappingContext . LOCAL_CONTEXT , new NullProgressMonitor ( ) ) ; } catch ( CoreException e ) { StatusManager . getManager ( ) . handle ( e , IDEWorkbenchPlugin . IDE_WORKBENCH ) ; } if ( traversals != null ) { IResource [ ] resources = null ; for ( ResourceTraversal traversal : traversals ) { resources = traversal . getResources ( ) ; if ( resources != null ) { < |startfocus| > result . addAll ( Arrays . asList ( resources ) ) ; < |endfocus| > } } } } else result . add ( resource ) ; } // all that can be converted are done , answer new selection if ( result . isEmpty ( ) ) { return StructuredSelection . EMPTY ; } return new StructuredSelection ( result . toArray ( ) ) ;
Map < MarkerQueryResult , Collection < IConfigurationElement > > resultsTable = entry . getValue ( ) ; if ( resultsTable . containsKey ( result ) ) { Iterator < IConfigurationElement > elements = resultsTable . get ( result ) . iterator ( ) ; while ( elements . hasNext ( ) ) { IConfigurationElement element = elements . next ( ) ; IMarkerResolutionGenerator generator = null ; try { generator = ( IMarkerResolutionGenerator ) element . createExecutableExtension ( ATT_CLASS ) ; IMarkerResolution [ ] res = generator . getResolutions ( marker ) ; if ( res != null ) { < |startfocus| > resolutions . addAll ( Arrays . asList ( res ) ) ; < |endfocus| > } else { StatusManager . getManager ( ) . handle ( new Status ( IStatus . ERROR , IDEWorkbenchPlugin . IDE_WORKBENCH , IStatus . ERROR , "Failure in " + generator . getClass ( ) . getName ( ) + // $NON - NLS - 1$ " from plugin " + element . getContributor ( ) . getName ( ) + // $NON - NLS - 1$ " : getResolutions ( IMarker ) must not return null" , // $NON - NLS - 1$ null ) , StatusManager . LOG ) ; } } catch ( CoreException e ) { Policy . handle ( e ) ; } } } } }
IPath location = resources [ i ] . getLocation ( ) ; // location may be null . See bug 29491 . if ( location != null ) { fileNames [ actualLength ++ ] = location . toOSString ( ) ; } } if ( actualLength > 0 ) { // was one or more of the locations null ? if ( actualLength < length ) { String [ ] tempFileNames = fileNames ; fileNames = new String [ actualLength ] ; < |startfocus| > System . arraycopy ( tempFileNames , 0 , fileNames , 0 , actualLength ) ; < |endfocus| > } anEvent . data = fileNames ; if ( Policy . DEBUG_DND ) System . out . println ( "ResourceDragAdapterAssistant . dragSetData set FileTransfer" ) ; // $NON - NLS - 1$ return true ; } } } return false ;
private INavigatorContentDescriptor contributor ; private INavigatorContentDescriptor firstClassContributor ; private NavigatorContentService contentService ; /* * * Construct a tracking set . * * @param aContentService */ public ContributorTrackingSet ( NavigatorContentService aContentService ) { contentService = aContentService ; } /* * * Construct a tracking set . * * @param aContentService * @param elements */ public ContributorTrackingSet ( NavigatorContentService aContentService , Object [ ] elements ) { < |startfocus| > super . addAll ( Arrays . asList ( elements ) ) ; < |endfocus| > contentService = aContentService ; } @Override public boolean add ( Object o ) { if ( contributor != null ) { contentService . rememberContribution ( contributor , firstClassContributor , o ) ; } return super . add ( o ) ; } @Override public boolean remove ( Object o ) { contentService . forgetContribution ( o ) ; return super . remove ( o ) ; } @Override public void clear ( ) { Iterator it = iterator ( ) ; while ( it . hasNext ( ) ) contentService . forgetContribution ( it . next ( ) ) ; super . clear ( ) ; } /* * *
updateFilterActivation = true ; } // We don't turn of non - UI visible filters here , they have to be manipulated explicitly if ( ! visibleFilterDescriptors [ i ] . isVisibleInUi ( ) ) { if ( nonUiVisible == null ) nonUiVisible = new ArrayList < String > ( ) ; nonUiVisible . add ( visibleFilterDescriptors [ i ] . getId ( ) ) ; } } /* If so , update */ if ( updateFilterActivation ) { if ( nonUiVisible != null ) { < |startfocus| > nonUiVisible . addAll ( Arrays . asList ( filterIdsToActivate ) ) ; < |endfocus| > filterIdsToActivate = nonUiVisible . toArray ( new String [ ] { } ) ; } setActiveFilterIds ( filterIdsToActivate ) ; persistFilterActivationState ( ) ; updateViewer ( ) ; // the action providers may no longer be enabled , so we // reset the selection . StructuredViewer commonViewer = ( StructuredViewer ) contentService . getViewer ( ) ; commonViewer . setSelection ( StructuredSelection . EMPTY ) ; }
new WizardPatternFilter ( ) , true ) ; viewer = filteredTree . getViewer ( ) ; filteredTree . setFont ( parent . getFont ( ) ) ; filteredTree . setQuickSelectionMode ( true ) ; viewer . setContentProvider ( new WizardContentProvider ( ) ) ; viewer . setLabelProvider ( new WorkbenchLabelProvider ( ) ) ; viewer . setComparator ( DataTransferWizardCollectionComparator . INSTANCE ) ; ArrayList inputArray = new ArrayList ( ) ; boolean expandTop = false ; if ( wizardCategories != null ) { if ( wizardCategories . getParent ( ) == null ) { < |startfocus| > inputArray . addAll ( Arrays . asList ( wizardCategories . getCategories ( ) ) ) ; < |endfocus| > } else { expandTop = true ; inputArray . add ( wizardCategories ) ; } } // ensure the category is expanded . If there is a remembered expansion it will // be set later . if ( expandTop ) { viewer . setAutoExpandLevel ( 2 ) ; } AdaptableList input = new AdaptableList ( inputArray ) ; // filter wizard list according to capabilities that are enabled viewer . addFilter ( new WizardActivityFilter ( ) ) ; viewer . setInput ( input ) ;
filterTree . setQuickSelectionMode ( true ) ; final TreeViewer treeViewer = filterTree . getViewer ( ) ; treeViewer . setContentProvider ( new WizardContentProvider ( ) ) ; treeViewer . setLabelProvider ( new WorkbenchLabelProvider ( ) ) ; treeViewer . setComparator ( NewWizardCollectionComparator . INSTANCE ) ; treeViewer . addSelectionChangedListener ( this ) ; ArrayList inputArray = new ArrayList ( ) ; inputArray . addAll ( Arrays . asList ( primaryWizards ) ) ; boolean expandTop = false ; if ( wizardCategories != null ) { if ( wizardCategories . getParent ( ) == null ) { < |startfocus| > inputArray . addAll ( Arrays . asList ( wizardCategories . getCategories ( ) ) ) ; < |endfocus| > } else { expandTop = true ; inputArray . add ( wizardCategories ) ; } } // ensure the category is expanded . If there is a remembered expansion it will // be set later . if ( expandTop ) { treeViewer . setAutoExpandLevel ( 2 ) ; } AdaptableList input = new AdaptableList ( inputArray ) ; treeViewer . setInput ( input ) ; filterTree . setBackground ( parent . getDisplay ( ) . getSystemColor ( SWT . COLOR_WIDGET_BACKGROUND ) ) ; treeViewer . getTree ( ) . setFont ( parent . getFont ( ) ) ; treeViewer . addDoubleClickListener ( event - > {
queuedEvents . add ( prefId ) ; return ; } if ( listeners != null ) { listeners . firePropertyChange ( prefId ) ; } } @Override public final void addListener ( String [ ] eventsOfInterest , IPropertyMapListener listener ) { if ( listeners == null ) { listeners = new PropertyListenerList ( ) ; attachListener ( ) ; } listeners . add ( eventsOfInterest , listener ) ; } protected final void firePropertyChange ( String [ ] prefIds ) { if ( ignoreCount > 0 ) { < |startfocus| > queuedEvents . addAll ( Arrays . asList ( prefIds ) ) ; < |endfocus| > return ; } if ( listeners != null ) { listeners . firePropertyChange ( prefIds ) ; } } public final void startTransaction ( ) { ignoreCount ++ ; } public final void endTransaction ( ) { ignoreCount -- ; if ( ignoreCount == 0 && ! queuedEvents . isEmpty ( ) ) { if ( listeners != null ) { listeners . firePropertyChange ( ( String [ ] ) queuedEvents . toArray ( new String [ queuedEvents . size ( ) ] ) ) ; } queuedEvents . clear ( ) ; } } @Override public boolean equals ( Object toCompare ) {
package org . eclipse . e4 . ui . tests . workbench ; import java . util . ArrayList ; import java . util . Arrays ; /* * * Class used to capture the SWT structure expected when rendering a partuclar * UI model . */ public class SWTResult { 	public Class clazz ; 	public String text ; 	public ArrayList kids = new ArrayList ( ) ; 	public SWTResult ( Class theClass , String theText , SWTResult [ ] children ) { 		clazz = theClass ; 		text = theText ; 		if ( children != null ) { 			 < |startfocus| > 			kids . addAll ( Arrays . asList ( children ) ) ; 			 < |endfocus| > 		 } 	 } }
public void setSize ( int size ) { currentElements = new TestElement [ size ] ; < |startfocus| > System . arraycopy ( allElements , 0 , currentElements , 0 , currentElements . length ) ; < |endfocus| >
public void addMember ( String person ) { 	TeamMember newMember = new TeamMember ( person , this ) ; 	TeamMember [ ] newMembers = new TeamMember [ members . length + 1 ] ; 	 < |startfocus| > 	System . arraycopy ( members , 0 , newMembers , 0 , members . length ) ; 	 < |endfocus| > 	newMembers [ newMembers . length - 1 ] = newMember ; 	members = null ; 	members = newMembers ; 	newMembers = null ; 	fireModelChanged ( new ComparatorModelChange ( TestModelChange . INSERT , this , newMember ) ) ; }
< |startfocus| > protected LeasedSmtpConnection withConnectionPool ( SmtpConnectionPool connectionPool ) { m_smtpConnectionPool = connectionPool ; < |endfocus| > return this ;
protected Transport getTransport ( ) { return m_transport ; < |startfocus| > < |endfocus| >
* which causes them to return to step 1 and recheck for idle connections or space left in the pool . < br > * As soon as a connection is created , a background job is started which monitors idle connections . If they reach the * max idle time ( { @link SmtpPoolMaxIdleTimeProperty } ) or max connection lifetime , they are closed and removed from the * pool . */ @ApplicationScoped public class SmtpConnectionPool { private static final Logger LOG = LoggerFactory . getLogger ( SmtpConnectionPool . class ) ; < |startfocus| > private static final String JOB_NAME_CLOSE_IDLE_CONNECTIONS = "smtp - close - idle - connections" ; < |endfocus| > protected final Object m_poolLock = new Object ( ) ; protected final Set < SmtpConnectionPoolEntry > m_idleEntries = new HashSet < > ( ) ; protected final Set < SmtpConnectionPoolEntry > m_leasedEntries = new HashSet < > ( ) ; protected final String m_jobExecutionHint = "smtp - connection - pool . " + UUID . randomUUID ( ) . toString ( ) ; protected long m_lastPoolEntryNo = 0 ; protected long m_maxIdleTime ; protected long m_maxConnectionLifetime ; protected boolean m_destroyed ; /* *
protected void destroy ( ) { 	if ( m_destroyed ) { 		return ; 	 } 	synchronized ( m_poolLock ) { 		if ( m_destroyed ) { 			return ; 		 } 		Jobs . getJobManager ( ) . cancel ( Jobs . newFutureFilterBuilder ( ) 			 . andMatchExecutionHint ( m_jobExecutionHint ) 			 . toFilter ( ) , true ) ; 		 < |startfocus| > 		Stream . of ( m_idleEntries , m_leasedEntries ) . flatMap ( Collection : : stream ) . forEach ( this : : safeCloseTransport ) ; 		 < |endfocus| > 		m_idleEntries . clear ( ) ; 		m_leasedEntries . clear ( ) ; 		m_destroyed = true ; 	 } }
package org . eclipse . scout . rt . mail . smtp ; import javax . mail . Session ; import javax . mail . Transport ; import org . eclipse . scout . rt . platform . Bean ; @Bean public class SmtpConnectionPoolEntry { private String m_name ; private SmtpServerConfig m_smtpServerConfig ; private Session m_session ; < |startfocus| > private Transport m_transport ; < |endfocus| > private long m_createTime ; private long m_idleSince ; public SmtpConnectionPoolEntry withName ( String name ) { m_name = name ; return this ; } public SmtpConnectionPoolEntry withSmtpServerConfig ( SmtpServerConfig smtpServerConfig ) { m_smtpServerConfig = smtpServerConfig ; return this ; } public SmtpConnectionPoolEntry withSession ( Session session ) { m_session = session ; return this ; } public SmtpConnectionPoolEntry withTransport ( Transport transport ) { m_transport = transport ; return this ; } public SmtpConnectionPoolEntry withCreateTime ( long createTime ) { m_createTime = createTime ; return this ; } public SmtpConnectionPoolEntry withIdleSince ( long idleSince ) { m_idleSince = idleSince ; return this ; } public Session getSession ( ) {
} public Map < String , String > getAdditionalSessionProperties ( ) { return m_additionalSessionProperties ; } /* * * These properties are added after the other properties , thus can override predefined properties such as host , port * or user . * * @param additionalSessionProperties * Additional properties used to create { @link Session } for SMTP server connection . */ public SmtpServerConfig withAdditionalSessionProperties ( Map < String , String > additionalSessionProperties ) { m_additionalSessionProperties = additionalSessionProperties ; return this ; } < |startfocus| > < |endfocus| > public int getPoolSize ( ) { return m_poolSize ; } /* * * @param poolSize * Specifies the size of the connection pool to use with this { @link SmtpServerConfig# } . If 0 , smtp * connection pooling is disabled . */ public SmtpServerConfig withPoolSize ( int poolSize ) { m_poolSize = poolSize ; return this ; } @Override public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( m_additionalSessionProperties == null ) ? 0 : m_additionalSessionProperties . hashCode ( ) ) ; result = prime * result + ( ( m_host == null ) ? 0 : m_host . hashCode ( ) ) ; result = prime * result + m_port ; result = prime * result + m_poolSize ; result = prime * result + ( ( m_user == null ) ? 0 : m_user . hashCode ( ) ) ; return result ; } @Override public boolean equals ( Object obj ) { if ( this == obj ) return true ; if ( obj == null ) return false ; if ( getClass ( ) != obj . getClass ( ) ) return false ; SmtpServerConfig other = ( SmtpServerConfig ) obj ; if ( m_additionalSessionProperties == null ) { if ( other . m_additionalSessionProperties != null ) return false ; } else if ( ! m_additionalSessionProperties . equals ( other . m_additionalSessionProperties ) ) return false ; if ( m_host == null ) { if ( other . m_host != null ) return false ; } else if ( ! m_host . equals ( other . m_host ) ) return false ; if ( m_port != other . m_port ) return false ; if ( m_poolSize != other . m_poolSize ) return false ; if ( m_user == null ) { if ( other . m_user != null ) return false ; } else if ( ! m_user . equals ( other . m_user ) ) return false ; return true ; } }
ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider ( ) ; int nbSeries = - 1 ; while ( iterator . hasNext ( ) ) { ITimeEvent event = iterator . next ( ) ; if ( ! ( event instanceof TimeLineEvent ) ) { continue ; } int x = SaturatedArithmetic . add ( rect . x , ( int ) ( ( event . getTime ( ) - time0 ) * pixelsPerNanoSec ) ) ; < |startfocus| > if ( x >= rect . x + rect . width ) { < |endfocus| > // event is out of bounds continue ; } TimeLineEvent timeEvent = ( TimeLineEvent ) event ; List < Long > values = timeEvent . getValues ( ) ; if ( nbSeries == - 1 ) { nbSeries = values . size ( ) ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { seriesModel . add ( new ArrayList < > ( ) ) ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { long val = values . get ( i ) ;
// event is out of bounds continue ; } TimeLineEvent timeEvent = ( TimeLineEvent ) event ; List < Long > values = timeEvent . getValues ( ) ; if ( nbSeries == - 1 ) { nbSeries = values . size ( ) ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { seriesModel . add ( new ArrayList < > ( ) ) ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; < |startfocus| > min = Math . min ( Math . abs ( val ) , min ) ; < |endfocus| > seriesModel . get ( i ) . add ( new LongPoint ( x , val ) ) ; refs . add ( timeEvent ) ; } } if ( refs . isEmpty ( ) ) { return ; } for ( TimeLineEvent ref : refs ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( ref ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; }
} TimeLineEvent timeEvent = ( TimeLineEvent ) event ; List < Long > values = timeEvent . getValues ( ) ; if ( nbSeries == - 1 ) { nbSeries = values . size ( ) ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { seriesModel . add ( new ArrayList < > ( ) ) ; } for ( int i = 0 ; i < nbSeries ; i ++ ) { long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; < |startfocus| > min = 0 ; < |endfocus| > seriesModel . get ( i ) . add ( new LongPoint ( x , val ) ) ; refs . add ( timeEvent ) ; } } if ( refs . isEmpty ( ) ) { return ; } for ( TimeLineEvent ref : refs ) { Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( ref ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; }
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * < |startfocus| > * Copyright ( c ) 2019 Review : This should be your name or Bachmann whoever has the copyright . See https :/ / wiki . eclipse . org / Platform_UI / How_to_Contribute#Coding_Conventions < |endfocus| > * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * Review : This should be your name or Bachmann whoever has the copyright . See https :/ / wiki . eclipse . org / Platform_UI / How_to_Contribute#Coding_Conventions - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** / package org . eclipse . e4 . ui . tests . workbench ; import org . eclipse . e4 . core . contexts . IEclipseContext ; import org . eclipse . e4 . ui . internal . workbench . E4Workbench ; import org . eclipse . e4 . ui . internal . workbench . swt . E4Application ; import org . eclipse . e4 . ui . internal . workbench . swt . PartRenderingEngine ; import org . eclipse . e4 . ui . model . application . MApplication ; import org . eclipse . e4 . ui . model . application . ui . advanced . MArea ; import org . eclipse . e4 . ui . model . application . ui . basic . MCompositePart ; import org . eclipse . e4 . ui . model . application . ui . basic . MPart ; import org . eclipse . e4 . ui . model . application . ui . basic . MPartStack ; import org . eclipse . e4 . ui . model . application . ui . basic . MWindow ;
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * * Copyright ( c ) 2019 IBM Corporation and others . * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : < |startfocus| > * IBM Corporation - initial API and implementation < |endfocus| > ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** / package org . eclipse . e4 . ui . tests . workbench ; import org . eclipse . e4 . core . contexts . IEclipseContext ; import org . eclipse . e4 . ui . internal . workbench . E4Workbench ; import org . eclipse . e4 . ui . internal . workbench . swt . E4Application ; import org . eclipse . e4 . ui . internal . workbench . swt . PartRenderingEngine ; import org . eclipse . e4 . ui . model . application . MApplication ; import org . eclipse . e4 . ui . model . application . ui . advanced . MArea ; import org . eclipse . e4 . ui . model . application . ui . basic . MCompositePart ; import org . eclipse . e4 . ui . model . application . ui . basic . MPart ; import org . eclipse . e4 . ui . model . application . ui . basic . MPartStack ; import org . eclipse . e4 . ui . model . application . ui . basic . MWindow ; import org . eclipse . e4 . ui . workbench . modeling . EModelService ; import org . eclipse . e4 . ui . workbench . modeling . EPartService ; import org . eclipse . swt . widgets . Display ; import org . eclipse . swt . widgets . Shell ; import org . junit . After ; import org . junit . Before ; import org . junit . Test ; import junit . framework . TestCase ; public class PartServiceTest extends TestCase { protected IEclipseContext appContext ; protected E4Workbench wb ; protected Display display ; protected Shell shell ; @Before public void setUp ( ) throws Exception { display = Display . getDefault ( ) ; shell = new Shell ( display ) ; appContext = E4Application . createDefaultContext ( ) ; appContext . set ( Display . class , display ) ; appContext . set ( Shell . class , shell ) ; MApplication application = EMFModelUtils . createApplication ( ) ; application . setContext ( appContext ) ; appContext . set ( MApplication . class , application ) ; wb = new E4Workbench ( application , appContext ) ; wb . createAndRunUI ( application ) ; } @After public void tearDown ( ) throws Exception { wb . close ( ) ; appContext . dispose ( ) ; } @Test public void testPartService ( ) { MApplication application = appContext . get ( MApplication . class ) ; EModelService modelService = appContext . get ( EModelService . class ) ; EPartService partService = appContext . get ( EPartService . class ) ; MWindow window = ( MWindow ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView" , application ) ; assertNotNull ( window ) ; MArea area = ( MArea ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . area" , window ) ; assertNotNull ( area ) ; MPartStack stack = ( MPartStack ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . stack" , window ) ; assertNotNull ( stack ) ; MPart part = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part" , window ) ; assertNotNull ( part ) ; MCompositePart compositePart = ( MCompositePart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . compositePart" , window ) ; assertNotNull ( compositePart ) ; MPart part2 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part2" , window ) ; assertNotNull ( part2 ) ; MPart part3 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part3" , window ) ; assertNotNull ( part3 ) ; MPart part4 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part4" , window ) ; assertNotNull ( part4 ) ; MPart part5 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part5" , window ) ; assertNotNull ( part5 ) ; MPart part6 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part6" , window ) ; assertNotNull ( part6 ) ; MPart part7 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part7" , window ) ; assertNotNull ( part7 ) ; MPart part8 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part8" , window ) ; assertNotNull ( part8 ) ; MPart part9 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part9" , window ) ; assertNotNull ( part9 ) ; MPart part10 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part10" , window ) ; assertNotNull ( part10 ) ; MPart part11 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part11" , window ) ; assertNotNull ( part11 ) ; MPart part12 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part12" , window ) ; assertNotNull ( part12 ) ; MPart part13 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part13" , window ) ; assertNotNull ( part13 ) ; MPart part14 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part14" , window ) ; assertNotNull ( part14 ) ; MPart part15 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part15" , window ) ; assertNotNull ( part15 ) ; MPart part16 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part16" , window ) ; assertNotNull ( part16 ) ; MPart part17 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part17" , window ) ; assertNotNull ( part17 ) ; MPart part18 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part18" , window ) ; assertNotNull ( part18 ) ; MPart part19 = ( MPart ) modelService . find ( "org . eclipse . e4 . ui . tests . workbench . SampleView . part19" , window ) ; assertNotNull ( part19
public void testMultipleStacksUnderTheAreaCreateACTabFolder ( ) { MWindow window = ems . createModelElement ( MWindow . class ) ; MArea area = ems . createModelElement ( MArea . class ) ; < |startfocus| > // Create two sash containers with MParts inside < |endfocus| > MPartStack stack1 = ems . createModelElement ( MPartStack . class ) ; stack1 . getChildren ( ) . add ( ems . createModelElement ( MPart . class ) ) ; stack1 . getChildren ( ) . add ( ems . createModelElement ( MPart . class ) ) ; MPartStack stack2 = ems . createModelElement ( MPartStack . class ) ; stack2 . getChildren ( ) . add ( ems . createModelElement ( MPart . class ) ) ; stack2 . getChildren ( ) . add ( ems . createModelElement ( MPart . class ) ) ; // Place the containers in the area area . getChildren ( ) . add ( stack1 ) ; area . getChildren ( ) . add ( stack2 ) ; // Add area to the window window . getChildren ( ) . add ( area ) ; MApplication application = ems . createModelElement ( MApplication . class ) ; application . getChildren ( ) . add ( window ) ; application . setContext ( appContext ) ; appContext . set ( MApplication . class , application ) ; wb = new E4Workbench ( application , appContext ) ; wb . createAndRunUI ( window ) ; // Make sure the widget is now a CTabFolder
public void testStackInsideMCompositePartDoesNotCreateACTabFolder ( ) { 	MWindow window = ems . createModelElement ( MWindow . class ) ; 	MArea area = ems . createModelElement ( MArea . class ) ; 	 < |startfocus| > // Create a sash container with MParts inside < |endfocus| > 	MCompositePart composite = ems . createModelElement ( MCompositePart . class ) ; 	MPartStack stack1 = ems . createModelElement ( MPartStack . class ) ; 	stack1 . getChildren ( ) . add ( ems . createModelElement ( MPart . class ) ) ; 	stack1 . getChildren ( ) . add ( ems . createModelElement ( MPart . class ) ) ; 	MPartStack stack2 = ems . createModelElement ( MPartStack . class ) ; 	stack2 . getChildren ( ) . add ( ems . createModelElement ( MPart . class ) ) ; 	stack2 . getChildren ( ) . add ( ems . createModelElement ( MPart . class ) ) ; 	composite . getChildren ( ) . add ( stack1 ) ; 	composite . getChildren ( ) . add ( stack2 ) ; 	 // Place the container in the area 	area . getChildren ( ) . add ( composite ) ; 	 // Add area to the window 	window . getChildren ( ) . add ( area ) ; 	MApplication application = ems . createModelElement ( MApplication . class ) ; 	application . getChildren ( ) . add ( window ) ; 	application . setContext ( appContext ) ; 	appContext . set ( MApplication . class , application ) ; 	wb = new E4Workbench ( application , appContext ) ; }
composite . getChildren ( ) . add ( stack1 ) ; composite . getChildren ( ) . add ( stack2 ) ; // Place the container in the area area . getChildren ( ) . add ( composite ) ; // Add area to the window window . getChildren ( ) . add ( area ) ; MApplication application = ems . createModelElement ( MApplication . class ) ; application . getChildren ( ) . add ( window ) ; application . setContext ( appContext ) ; appContext . set ( MApplication . class , application ) ; wb = new E4Workbench ( application , appContext ) ; wb . createAndRunUI ( window ) ; < |startfocus| > // Make sure the widget is now a CTabFolder < |endfocus| > Assert . assertFalse ( area . getWidget ( ) instanceof CTabFolder ) ; < |startfocus| > // Make sure the widget is now a CTabFolder < |endfocus| > Assert . assertFalse ( area . getWidget ( ) instanceof CTabFolder ) ;
public void testDynamicItem_AddOne ( ) { contextRule . createAndRunWorkbench ( window ) ; ToolBarManager tbm = getManager ( toolBar ) ; < |startfocus| > assertEquals ( 0 , tbm . getSize ( ) ) ; < |endfocus| > MToolItem toolItem1 = ems . createModelElement ( MDirectToolItem . class ) ; toolBar . getChildren ( ) . add ( toolItem1 ) ; assertEquals ( 1 , tbm . getSize ( ) ) ;
< |startfocus| > protected int getThreshold ( ) { < |endfocus| > return 5 ; // 5 is the default threshold
public void refresh ( ) { < |startfocus| > fCategoryViewer . setInput ( fModel ) ; < |endfocus| >
import org . eclipse . cdt . core . dom . ast . cpp . ICPPConstructor ; import org . eclipse . cdt . core . dom . ast . cpp . ICPPMethod ; import org . eclipse . cdt . core . dom . ast . cpp . SemanticQueries ; import org . eclipse . cdt . internal . core . dom . parser . ASTQueries ; import org . eclipse . cdt . internal . core . dom . parser . cpp . ClassTypeHelper ; import org . eclipse . cdt . internal . core . dom . parser . cpp . ICPPDeferredClassInstance ; @SuppressWarnings ( "restriction" ) public class VirtualMethodCallChecker extends AbstractIndexAstChecker { public static final String VIRTUAL_CALL_ID = "org . eclipse . cdt . codan . internal . checkers . VirtualMethodCallProblem" ; // $NON - NLS - 1$ < |startfocus| > public static final String THROW_ID = "org . eclipse . cdt . codan . internal . checkers . ThrowInDestructorProblem" ; // $NON - NLS - 1$ < |endfocus| > @Override public void processAst ( IASTTranslationUnit ast ) { ast . accept ( new OnEachClass ( ) ) ; } private enum DECL_TYPE { CTOR , DTOR } class OnEachClass extends ASTVisitor { // NOTE : Classes can be nested and even can be declared in constructors of the other classes private final Stack < DECL_TYPE > ctorDtorStack = new Stack < > ( ) ; OnEachClass ( ) { shouldVisitDeclarations = true ;
private static SyscallLookup create ( ) { try { IPath path = Activator . getDefault ( ) . getAbsolutePath ( new Path ( SYSCALL_TSV_PATH ) ) ; if ( path != null ) { File file = path . toFile ( ) ; if ( ! file . exists ( ) ) { < |startfocus| > Activator . getDefault ( ) . logError ( "Syscall names not available ! " ) ; // $NON - NLS - 1$ < |endfocus| > return new SyscallLookup ( Collections . emptyList ( ) ) ; } return new SyscallLookup ( FileUtils . readLines ( file , "UTF - 8" ) ) ; // $NON - NLS - 1$ } } catch ( IOException e ) { Activator . getDefault ( ) . logError ( "Failed to read file" , e ) ; // $NON - NLS - 1$ } return new SyscallLookup ( Collections . emptyList ( ) ) ;
* the provider is an instance of { @link IAnalysisModule } , analysis is also * scheduled . * < p > * If the trace has multiple analysis modules with the same secondary ID , * < code > null </ code > is returned so the caller can try to make a * { @link TmfTreeXYCompositeDataProvider } for all the traces instead * * @param trace < |startfocus| > * A trace on which we are interested to fetch a model < |endfocus| > * @param secondaryId * The ID of the analysis to use for this provider * @return An instance of SegmentStoreDataProvider . Returns a null if the * ISegmentStoreProvider is null . * @since 4 . 0 */ public static @Nullable ITmfTreeDataProvider < ? extends ITmfTreeDataModel > create ( ITmfTrace trace , String secondaryId ) { // The trace can be an experiment , so we need to know if there are multiple // analysis modules with the same ID Iterable < ISegmentStoreProvider > modules = TmfTraceUtils . getAnalysisModulesOfClass ( trace , ISegmentStoreProvider . class ) ;
public boolean visit ( LambdaExpression lambdaExpression ) { IMethodBinding binding = lambdaExpression . resolveMethodBinding ( ) ; < |startfocus| > IVariableBinding [ ] synVars = binding . getSyntheticOuterLocals ( ) ; < |endfocus| > List < Field > allFields = underlyingThisObject . referenceType ( ) . fields ( ) ; ListIterator < Field > listIterator = allFields . listIterator ( ) ; int i = 0 ; if ( getUnderlyingMethod ( ) . isStatic ( ) ) { if ( synVars . length == allFields . size ( ) ) { while ( listIterator . hasNext ( ) ) { FieldImpl field = ( FieldImpl ) listIterator . next ( ) ; String newName = synVars [ i ] . getName ( ) ; FieldImpl newField = new FieldImpl ( ( VirtualMachineImpl ) field . virtualMachine ( ) , ( ReferenceTypeImpl ) field . declaringType ( ) , field . getFieldID ( ) , newName , field . signature ( ) , field . genericSignature ( ) , field . modifiers ( ) ) ; listIterator . set ( newField ) ; } } } else { if ( synVars . length + 1 == allFields . size ( ) ) { while ( listIterator . hasNext ( ) ) { FieldImpl field = ( FieldImpl ) listIterator . next ( ) ; String newName = field . name ( ) ; if ( synVars [ i ] . getName ( ) . equals ( newName ) ) { FieldImpl newField = new FieldImpl ( ( VirtualMachineImpl ) field . virtualMachine ( ) , ( ReferenceTypeImpl ) field . declaringType ( ) , field . getFieldID ( ) , newName , field . signature ( ) , field . genericSignature ( ) , field . modifiers ( ) ) ; listIterator . set ( newField ) ; } } } } return false ; }
int auto = repo . getConfig ( ) . getInt ( ConfigConstants . CONFIG_GC_SECTION , ConfigConstants . CONFIG_KEY_AUTO , DEFAULT_AUTOLIMIT ) ; if ( auto <= 0 ) { return false ; } int n = 0 ; int threshold = ( auto + 255 ) / 256 ; Path dir = repo . getObjectsDirectory ( ) . toPath ( ) . resolve ( "17" ) ; // $NON - NLS - 1$ if ( ! Files . exists ( dir ) ) { return false ; } try ( DirectoryStream < Path > stream = Files . newDirectoryStream ( dir , new DirectoryStream . Filter < Path > ( ) { < |startfocus| > < |endfocus| > public boolean accept ( Path file ) throws IOException { return Files . isRegularFile ( file ) && PATTERN_LOOSE_OBJECT . matcher ( file . getFileName ( ) . toString ( ) ) . matches ( ) ; } } ) ) { Iterator < Path > iter = stream . iterator ( ) ; while ( iter . hasNext ( ) ) { if ( n ++ > threshold ) { return true ; } } } catch ( IOException e ) { LOG . error ( e . getMessage ( ) , e ) ; } return false ;
public void setAllChecked ( boolean state ) { for ( TreeItem item : super . getTree ( ) . getItems ( ) ) item . setChecked ( state ) ; if ( state ) { // Find all visible children , add only the visible leaf nodes to the check state cache Object [ ] visible = getFilteredChildren ( getRoot ( ) ) ; ITreeContentProvider contentProvider = null ; if ( getContentProvider ( ) instanceof ITreeContentProvider ) { contentProvider = ( ITreeContentProvider ) getContentProvider ( ) ; } if ( contentProvider == null ) { < |startfocus| > checkState . addAll ( Arrays . asList ( visible ) ) ; < |endfocus| > } else { Set < Object > toCheck = new HashSet < > ( ) ; for ( Object element : visible ) { addFilteredChildren ( element , contentProvider , toCheck ) ; } checkState . addAll ( toCheck ) ; } } else { // Remove any item in the check state that is visible ( passes the filters ) if ( checkState != null ) { Object [ ] visible = filter ( checkState . toArray ( ) ) ; for ( Object element : visible ) { checkState . remove ( element ) ; } } } }
* return the token . * * @return the { @link IToken } , or { @code null } if none . */ protected IToken scanToken ( ) { return null ; } private @NonNull Set < IHyperlinkDetector > getHyperlinkDetectors ( ) { Set < IHyperlinkDetector > allDetectors = new LinkedHashSet < > ( ) ; IHyperlinkDetector [ ] configuredDetectors = configuration . getHyperlinkDetectors ( viewer ) ; if ( configuredDetectors != null && configuredDetectors . length > 0 ) { < |startfocus| > allDetectors . addAll ( Arrays . asList ( configuredDetectors ) ) ; < |endfocus| > if ( preferenceStore . getBoolean ( URL_HYPERLINK_DETECTOR_KEY ) || ! preferenceStore . getBoolean ( AbstractTextEditor . PREFERENCE_HYPERLINKS_ENABLED ) ) { return allDetectors ; } // URLHyperlinkDetector can only detect hyperlinks at the start of // the range . We need one that can detect all hyperlinks in a given // region . allDetectors . add ( new MultiURLHyperlinkDetector ( ) ) ; } return allDetectors ; } /* * * A { @link URLHyperlinkDetector } that returns all hyperlinks in a region . * < p > * This internal class assumes that the region is either empty or else spans the entire line . * </ p > */ private static class MultiURLHyperlinkDetector extends URLHyperlinkDetector { @Override public IHyperlink [ ] detectHyperlinks ( ITextViewer textViewer , IRegion region , boolean canShowMultipleHyperlinks ) { if ( region . getLength ( ) == 0 ) { return null ; } try { IDocument document = textViewer . getDocument ( ) ; int line = document . getLineOfOffset ( region . getOffset ( ) ) ; IRegion lineRegion = document . getLineInformation ( line ) ; String lineText = document . get ( lineRegion . getOffset ( ) , lineRegion . getLength ( ) ) ; return detectHyperlinks ( textViewer , lineRegion , lineText ) ; } catch ( BadLocationException e ) { return null ; } } } }
public static boolean evaluateNoexceptSpecifier ( ICPPEvaluation noexceptSpecifier ) { < |startfocus| > if ( noexceptSpecifier != null ) { < |endfocus| > IValue v = noexceptSpecifier . getValue ( ) ; if ( v instanceof IntegralValue ) { IntegralValue iv = ( IntegralValue ) v ; if ( iv . numberValue ( ) != null ) return iv . numberValue ( ) . longValue ( ) == 1 ; } } return false ;
candidate = entry ; it . remove ( ) ; break ; } } if ( candidate != null && ! candidate . getTransport ( ) . isConnected ( ) ) { LOG . debug ( "Releasing pooled SMTP connection { } ; transport is already closed , not returning to idle pool . " , candidate ) ; candidate = null ; } if ( candidate != null ) { IDateProvider dateProvider = BEANS . get ( IDateProvider . class ) ; < |startfocus| > if ( dateProvider . currentMillis ( ) . getTime ( ) - candidate . getCreateTime ( ) < m_maxConnectionLifetime && candidate . getUsageCount ( ) < m_maxConnectionUsageCount ) { < |endfocus| > LOG . debug ( "Releasing pooled SMTP connection { } ; returning to idle pool . " , candidate ) ; candidate . withIdleSince ( dateProvider . currentMillis ( ) . getTime ( ) ) ; m_idleEntries . add ( candidate ) ; } else { LOG . debug ( "Releasing pooled SMTP connection { } ; pooled connection reached max lifetime of { } s , not returning to idle pool . " , candidate , m_maxConnectionLifetime / 1000d ) ; } } m_poolLock . notifyAll ( ) ; }
} /* * * These properties are added after the other properties , thus can override predefined properties such as host , port * or user . * * @param additionalSessionProperties * Additional properties used to create { @link Session } for SMTP server connection . */ public SmtpServerConfig withAdditionalSessionProperties ( Map < String , String > additionalSessionProperties ) { m_additionalSessionProperties = additionalSessionProperties ; return this ; } /* * < |startfocus| > * @return the size of the connection pool to use with this { @link SmtpServerConfig } . If 0 , smtp * connection pooling is disabled . < |endfocus| > */ public int getPoolSize ( ) { return m_poolSize ; } /* * * @param poolSize * Specifies the size of the connection pool to use with this { @link SmtpServerConfig# } . If 0 , smtp * connection pooling is disabled . */ public SmtpServerConfig withPoolSize ( int poolSize ) { m_poolSize = poolSize ; return this ; } @Override public int hashCode ( ) { final int prime = 31 ; int result = 1 ;
int cpusNode = cpuSs . getQuarkAbsolute ( Attributes . CPUS ) ; final @NonNull List < @NonNull Integer > subAttributes = cpuSs . getSubAttributes ( cpusNode , false ) ; int cpus = Integer . MIN_VALUE ; for ( Integer quark : subAttributes ) { cpus = Math . max ( Integer . parseInt ( cpuSs . getAttributeName ( quark ) ) , cpus ) ; } return Math . max ( subAttributes . size ( ) , cpus ) ; } catch ( AttributeNotFoundException e ) { < |startfocus| > Activator . getDefault ( ) . logError ( "Error : getting number of core " + e . getMessage ( ) , e ) ; // $NON - NLS - 1$ < |endfocus| > } } return - 1 ;
if ( cpuSs != null ) { try { int cpusNode = cpuSs . getQuarkAbsolute ( Attributes . CPUS ) ; final @NonNull List < @NonNull Integer > subAttributes = cpuSs . getSubAttributes ( cpusNode , false ) ; int cpus = Integer . MIN_VALUE ; for ( Integer quark : subAttributes ) { cpus = Math . max ( Integer . parseInt ( cpuSs . getAttributeName ( quark ) ) , cpus ) ; } return Math . max ( subAttributes . size ( ) , cpus ) ; } catch ( AttributeNotFoundException e ) { < |startfocus| > Activator . getDefault ( ) . logError ( e . getMessage ( ) , e ) ; < |endfocus| > } } return - 1 ;
if ( url == null ) { return false ; } if ( WORKSPACE_CHECK_REFERENCE_BUNDLE_VERSION == null ) { // no reference bundle installed , no check possible return true ; } Version version = readWorkspaceVersion ( url ) ; // if the version could not be read , then there is not any existing // workspace data to trample , e . g . , perhaps its a new directory that // is just starting to be used as a workspace if ( version == null ) { return true ; } < |startfocus| > final Version ide_version = toMajorMinorVersion ( WORKSPACE_CHECK_REFERENCE_BUNDLE_VERSION ) ; Version workspace_version = toMajorMinorVersion ( version ) ; int versionCompareResult = workspace_version . compareTo ( ide_version ) ; < |endfocus| > // equality test is required since any version difference ( newer // or older ) may result in data being trampled if ( versionCompareResult == 0 ) { return true ; } // At this point workspace has been detected to be from a version // other than the current ide version -- find out if the user wants // to use it anyhow .
< |startfocus| > public @Nullable ImageDescriptor getImageDescripterFromPath ( String path ) { return AbstractUIPlugin . imageDescriptorFromPlugin ( PLUGIN_ID , path ) ; < |endfocus| >
} else if ( columnIndex == 1 ) { try { return attribute . getDisplayableString ( ) ; } catch ( OseeCoreException ex ) { return Lib . exceptionToString ( ex ) ; } } else if ( columnIndex == 2 ) { try { return attribute . getId ( ) ; } catch ( OseeCoreException ex ) { return Lib . exceptionToString ( ex ) ; } } else if ( columnIndex == 3 ) { try { < |startfocus| > return attribute . getAttributeType ( ) . getIdString ( ) ; < |endfocus| > } catch ( OseeCoreException ex ) { return Lib . exceptionToString ( ex ) ; } } else { return attribute . getGammaId ( ) ; }
super . applyId ( value ) ; onUrlDependencyChanged ( value ) ; } @Override protected void applyVersion ( String value ) throws CoreException { super . applyVersion ( value ) ; onUrlDependencyChanged ( value ) ; } private void onUrlDependencyChanged ( String dependencyValue ) throws CoreException { boolean includeUrl = ( dependencyValue != null ) && fIncludeUrlCheckbox . getSelection ( ) ; applyUrl ( includeUrl ) ; updateUrlEnablement ( ) ; } private void applyUrl ( boolean include ) throws CoreException { < |startfocus| > String value = include ? recomputeUrl ( ) : null ; getCurrentItem ( ) . setURL ( value ) ; < |endfocus| > } private String recomputeUrl ( ) { ISiteFeature feature = getCurrentItem ( ) ; if ( feature == null ) { return null ; } StringBuilder sb = new StringBuilder ( ) ; sb . append ( "features / " ) . append ( feature . getId ( ) ) . append ( "_" ) ; // $NON - NLS - 1$ // $NON - NLS - 2$ try { sb . append ( new Version ( feature . getVersion ( ) ) ) ; } catch ( Exception e ) { sb . append ( "0 . 0 . 0" ) ; // $NON - NLS - 1$ } sb . append ( " . jar" ) ; // $NON - NLS - 1$ return sb . toString ( ) ; } }
public static SyscallLookup getInstance ( ) { < |startfocus| > SyscallLookup instance = INSTANCE ; < |endfocus| > if ( instance == null ) { instance = create ( ) ; INSTANCE = instance ; } return instance ;
private static SyscallLookup create ( ) { try { IPath path = Activator . getDefault ( ) . getAbsolutePath ( new Path ( SYSCALL_TSV_PATH ) ) ; if ( path != null ) { File file = path . toFile ( ) ; if ( ! file . exists ( ) ) { < |startfocus| > Activator . getDefault ( ) . logWarning ( "Syscall names not available ! " ) ; // $NON - NLS - 1$ < |endfocus| > return new SyscallLookup ( Collections . emptyList ( ) ) ; } return new SyscallLookup ( FileUtils . readLines ( file , "UTF - 8" ) ) ; // $NON - NLS - 1$ } } catch ( IOException e ) { Activator . getDefault ( ) . logError ( "Failed to read file" , e ) ; // $NON - NLS - 1$ } return new SyscallLookup ( Collections . emptyList ( ) ) ;
< |startfocus| > @Override < |endfocus| > public String getMessage ( ) { return "Dynamic import failed . " ; } @Override public Collection < Requirement > getUnresolvedRequirements ( ) { return Collections . singleton ( requirement ) ; } @Override public ResolutionException toException ( ) { return new ReasonException ( ReasonException . Reason . DynamicImport , getMessage ( ) , null , getUnresolvedRequirements ( ) ) ; } } static class FragmentNotSelectedError extends ResolutionError { private final Resource resource ; public FragmentNotSelectedError ( Resource resource ) { this . resource = resource ; } @Override public String getMessage ( ) {
if ( type == null ) { return value ; } IJavaStackFrame stackFrame = getStackFrame ( javaValue ) ; if ( stackFrame == null ) { return value ; } IJavaProject project = JavaDebugUtils . resolveJavaProject ( stackFrame ) ; if ( project == null ) { return value ; } IAstEvaluationEngine evaluationEngine = JDIDebugPlugin . getDefault ( ) . getEvaluationEngine ( project , ( IJavaDebugTarget ) stackFrame . getDebugTarget ( ) ) ; EvaluationBlock evaluationBlock = new EvaluationBlock ( javaValue , type , ( IJavaThread ) stackFrame . getThread ( ) , evaluationEngine ) ; < |startfocus| > < |endfocus| > if ( fValue == null ) { // evaluate each variable IJavaVariable [ ] variables = new IJavaVariable [ fVariables . length ] ; for ( int i = 0 ; i < fVariables . length ; i ++ ) { variables [ i ] = new JDIPlaceholderVariable ( fVariables [ i ] [ 0 ] , evaluationBlock . evaluate ( fVariables [ i ] [ 1 ] ) , javaValue ) ; } return new LogicalObjectStructureValue ( javaValue , variables ) ; } // evaluate the logical value IJavaValue logicalValue = evaluationBlock . evaluate ( fValue ) ; if ( logicalValue instanceof JDIValue ) { return new LogicalStructureValue ( javaValue , logicalValue ) ; } return new LogicalStructureValue ( javaValue , logicalValue . getValueString ( ) ) ;
package org . eclipse . jdt . internal . debug . eval . ast . instructions ; import org . eclipse . core . runtime . CoreException ; import org . eclipse . core . runtime . IStatus ; import org . eclipse . core . runtime . Status ; import org . eclipse . debug . core . DebugException ; import org . eclipse . jdt . debug . core . IJavaDebugTarget ; import org . eclipse . jdt . debug . core . IJavaObject ; import org . eclipse . jdt . debug . core . IJavaReferenceType ; import org . eclipse . jdt . debug . core . IJavaStackFrame ; import org . eclipse . jdt . debug . core . IJavaThread ; import org . eclipse . jdt . debug . core . IJavaValue ; import org . eclipse . jdt . debug . core . IJavaVariable ; import org . eclipse . jdt . internal . debug . core . JDIDebugPlugin ; import org . eclipse . jdt . internal . debug . core . logicalstructures . JDIPlaceholderVariable ; import org . eclipse . jdt . internal . debug . core . logicalstructures . LogicalObjectStructureValue ; import org . eclipse . jdt . internal . debug . core . model . JDIDebugTarget ; import org . eclipse . jdt . internal . debug . core . model . JDIValue ; import org . eclipse . jdt . internal . debug . eval . ast . engine . EvaluationBlock ; import org . eclipse . jdt . internal . debug . eval . ast . engine . EvaluationEngine ; import org . eclipse . jdt . internal . debug . eval . ast . engine . EvaluationException ; import org . eclipse . jdt . internal . debug . eval . ast . engine . EvaluationManager ; public class LogicalStructureInstruction extends CompoundInstruction { 	private String fValue ; 	private String [ ] [ ] fVariables ; 	public LogicalStructureInstruction ( String value , String [ ] [ ] variables ) { 		fValue = value ; 		fVariables = variables ; 	 } 	 /* 	 * @see Instruction#execute ( ) 	 */ 	@Override 	public void execute ( ) throws CoreException { 		IJavaStackFrame stackFrame = getStackFrame ( ) ; 		IJavaObject javaValue = ( IJavaObject ) popValue ( ) ; 		IJavaReferenceType type = javaValue . getJavaType ( ) ; 		try { 			EvaluationEngine evaluationEngine = EvaluationManager . newEvaluationEngine ( stackFrame . getDebugTarget ( ) ) ; 			EvaluationBlock evaluationBlock = new EvaluationBlock ( javaValue , type , ( IJavaThread ) stackFrame . getThread ( ) , evaluationEngine ) ; 			if ( fValue == null ) { 				 // evaluate each variable 				IJavaVariable [ ] variables = new IJavaVariable [ fVariables . length ] ; 				for ( int i = 0 ; i < fVariables . length ; i ++ ) { 					variables [ i ] = new JDIPlaceholderVariable ( fVariables [ i ] [ 0 ] , evaluationBlock . evaluate ( fVariables [ i ] [ 1 ] ) , javaValue ) ; 				 } 				return new LogicalObjectStructureValue ( javaValue , variables ) ; 			 } 			 // evaluate the logical value 			IJavaValue logicalValue = evaluationBlock . evaluate ( fValue ) ; 			if ( logicalValue instanceof JDIValue ) { 				 ( ( JDIValue ) logicalValue ) . setLogicalParent ( javaValue ) ; 			 } 			return logicalValue ; 		 } catch ( CoreException e ) { 			if ( e . getStatus ( ) . getCode ( ) == IJavaThread . ERR_THREAD_NOT_SUSPENDED ) { 				throw e ; 			 } 			JDIDebugPlugin . log ( e ) ; 		 } 		return value ; 	 } 	 /* * 	 * Returns the < code > IJavaReferenceType </ code > from the specified 	 * < code > IJavaObject </ code > . 	 * 	 * @param object 	 * the object to get the type from 	 * @return the type of the object 	 * @exception DebugException 	 * if this method fails . Reasons include : 	 * < ul > 	 * < li > Failure communicating with the VM . The 	 * DebugException's status code contains the underlying 	 * exception responsible for the failure . </ li > 	 * </ ul > 	 */ 	protected IJavaReferenceType getReferenceType ( IJavaObject object ) throws DebugException { 		return ( IJavaReferenceType ) object . getJavaType ( ) ; 	 } 	 /* 	 * @see Instruction#getType ( ) 	 */ 	@Override 	public String getType ( ) { 		return "logical structure" ; // $NON - NLS - 1$ 	 } }
private void createLink ( String prefix , final Artifact art , String action , Artifact thisArt , RelationTypeSide relation ) { try { < |startfocus| > Label label = editor . getToolkit ( ) . createLabel ( this , prefix + " \"" + getTeamName ( thisArt ) + "\" " + action + getCompletedCancelledString ( art ) + " \"" + getTeamName ( art ) + "\" " ) ; < |endfocus| > Hyperlink link = editor . getToolkit ( ) . createHyperlink ( this , String . format ( "\" % s\" - % s" , art . getName ( ) . length ( ) < 60 ? art . getName ( ) : art . getName ( ) . substring ( 0 , 60 ) , AtsClientService . get ( ) . getAtsId ( art ) ) , SWT . NONE ) ; if ( art . equals ( thisArt ) ) { artAndRelToHyperlink . put ( thisArt , relation , link ) ; artAndRelToLabel . put ( thisArt , relation , label ) ; } else { artAndRelToHyperlink . put ( art , relation , link ) ; artAndRelToLabel . put ( art , relation , label ) ; } link . addHyperlinkListener ( new IHyperlinkListener ( ) { @Override public void linkEntered ( HyperlinkEvent e ) { // do nothing
IASTExpression fNameExp = fCall . getFunctionNameExpression ( ) ; IBinding fBinding = null ; if ( fNameExp instanceof IASTIdExpression ) { IASTIdExpression fName = ( IASTIdExpression ) fNameExp ; fBinding = fName . getName ( ) . resolveBinding ( ) ; } else if ( fNameExp instanceof IASTFieldReference ) { IASTFieldReference fName = ( IASTFieldReference ) fNameExp ; if ( referencesThis ( fName . getFieldOwner ( ) ) ) fBinding = fName . getFieldName ( ) . resolveBinding ( ) ; } < |startfocus| > if ( fBinding instanceof ICPPMethod ) { < |endfocus| > ICPPMethod method = ( ICPPMethod ) fBinding ; if ( method . isPureVirtual ( ) || ClassTypeHelper . isVirtual ( method ) ) { reportProblem ( VIRTUAL_CALL_ID , expression ) ; } } } } return PROCESS_CONTINUE ;
if ( functionDefinition . isDefaulted ( ) && SemanticQueries . isCopyOrMoveConstructor ( constructor ) ) return null ; if ( constructor . getClassOwner ( ) . getKey ( ) == ICompositeType . k_union ) return null ; // Skip delegating constructors . for ( ICPPASTConstructorChainInitializer memberInitializer : functionDefinition . getMemberInitializers ( ) ) { IASTName memberName = memberInitializer . getMemberInitializerId ( ) ; if ( memberName != null ) { IBinding memberBinding = memberName . resolveBinding ( ) ; ICPPClassType classType = null ; < |startfocus| > if ( memberBinding instanceof ICPPClassType ) { classType = ( ICPPClassType ) memberBinding ; } else if ( memberBinding instanceof ICPPConstructor ) { classType = ( ( ICPPConstructor ) memberBinding ) . getClassOwner ( ) ; } < |endfocus| > if ( classType instanceof ICPPDeferredClassInstance ) { classType = ( ( ICPPDeferredClassInstance ) classType ) . getClassTemplate ( ) ; } if ( classType != null && classType . isSameType ( constructor . getClassOwner ( ) ) ) return null ; } } return constructor ; } } return null ;
* { @link org . eclipse . tracecompass . tmf . ui . viewers . events . TmfEventsTable#TmfEventsTable ( org . eclipse . swt . widgets . Composite , int , java . util . Collection ) } * * @author Alexandre Montplaisir * @noextend This class should not be extended directly . You should instead * implement an { @link ITmfEventAspect } . */ @NonNullByDefault public class TmfEventTableColumn { // -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- // Fields // -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- < |startfocus| > private final ITmfEventAspect < ? > fAspect ; private final List < ITmfEventAspect < ? > > fAspectDuplicate = new ArrayList < > ( ) ; < |endfocus| > // -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- // Constructors // -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- /* * * Constructor * * @param aspect * The { @link ITmfEventAspect } to be used to populate this * column . */ public TmfEventTableColumn ( ITmfEventAspect < ? > aspect ) { fAspect = aspect ; fAspectDuplicate . add ( aspect ) ; } // -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- // adders // -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- /* * * Add another Aspect with the same name * * @param duplicate * the aspect with the same name * @since 5 . 0 */
public TmfEventTableColumn ( ITmfEventAspect < ? > aspect ) { < |startfocus| > fAspect = aspect ; fAspectDuplicate . add ( aspect ) ; < |endfocus| > }
public String getItemString ( ITmfEvent event ) { final String EMPTY_STRING = "" ; // $NON - NLS - 1$ String s = NonNullUtils . nullToEmptyString ( fAspect . resolve ( event ) ) ; if ( fAspectDuplicate . size ( ) > 1 && s . equals ( EMPTY_STRING ) ) { for ( ITmfEventAspect < ? > aspect : fAspectDuplicate ) { String eventString = aspect . resolve ( event ) ; if ( eventString != EMPTY_STRING ) { s = eventString ; } } } < |startfocus| > return s ; < |endfocus| >
public String getItemString ( ITmfEvent event ) { < |startfocus| > private static final String EMPTY_STRING = "" ; // $NON - NLS - 1$ < |endfocus| > for ( ITmfEventAspect < ? > aspect : fAspects ) { String eventString = NonNullUtils . nullToEmptyString ( aspect . resolve ( event ) ) ; if ( eventString != EMPTY_STRING ) { return eventString ; } } return EMPTY_STRING ;
public String getItemString ( ITmfEvent event ) { final String EMPTY_STRING = "" ; // $NON - NLS - 1$ for ( ITmfEventAspect < ? > aspect : fAspects ) { String eventString = NonNullUtils . nullToEmptyString ( aspect . resolve ( event ) ) ; < |startfocus| > if ( eventString != EMPTY_STRING ) { < |endfocus| > return eventString ; } } return EMPTY_STRING ;
public String getItemString ( ITmfEvent event ) { for ( ITmfEventAspect < ? > aspect : fAspects ) { String eventString = NonNullUtils . nullToEmptyString ( aspect . resolve ( event ) ) ; < |startfocus| > if ( ! eventString . isEmpty ( ) ) { < |endfocus| > return eventString ; } } return EMPTY_STRING ;
package org . eclipse . emf . emfstore . client . test . ui . controllers ; import java . io . IOException ; import org . eclipse . emf . emfstore . common . ESObserver ; import org . eclipse . emf . emfstore . internal . client . model . ESWorkspaceProviderImpl ; import org . eclipse . emf . emfstore . internal . client . ui . controller . UIShowHistoryController ; import org . eclipse . emf . emfstore . internal . common . observer . ObserverExceptionListener ; import org . eclipse . emf . emfstore . server . exceptions . ESException ; import org . eclipse . swtbot . eclipse . finder . widgets . SWTBotView ; import org . eclipse . swtbot . swt . finder . finders . UIThreadRunnable ; import org . eclipse . swtbot . swt . finder . results . VoidResult ; import org . junit . Test ; public class UIHistoryViewCloseTest extends AbstractUIControllerTestWithCommit { @Override @Test public void testController ( ) throws ESException {
public void init ( IWorkbench workbench ) { < |startfocus| > setDescription ( CAPRA_PREFERENCE_PAGE_DESCRIPTION ) ; < |endfocus| > setPreferenceStore ( new ScopedPreferenceStore ( InstanceScope . INSTANCE , CAPRA_PREFERENCE_PAGE_ID ) ) ;
* side * * MasterDetailRenderer implements IEditingDomainProvider to allow Undo / Redo / Copy / Cut / Paste actions to be performed * externally . * * MasterDetailRenderer provides an ISelectionProvider to get the currently selected items in the tree * */ @SuppressWarnings ( "restriction" ) public class TreeMasterDetailComposite extends Composite implements IEditingDomainProvider { < |startfocus| > private static final String SELECT_A_NODE = "Select a node in the tree to edit it" ; private static final String LOADING = "Loading . . . " ; < |endfocus| > /* * The input . */ private final Object input ; /* * The editing domain . */ private final EditingDomain editingDomain ; /* * The tree viewer . */ private TreeViewer treeViewer ; /* * The selection provider . */ private IMasterDetailSelectionProvider selectionProvider ; /* * The vertical sash . */ private Sash verticalSash ; /* * The detail scrollable composite . */ private Composite detailComposite ; /* * Manager of the currently rendered ECPSWTView with caching . */ private DetailViewManager detailManager ; private Object lastRenderedObject ; private final TreeMasterDetailSWTCustomization customization ; private final String selectANode ; private final String loading ;
public static boolean containsMatchingProperty ( Set < IConfigurationProperty > existingProperties , String name , String os , String arch ) { boolean result = false ; for ( IConfigurationProperty property : existingProperties ) { if ( name . equals ( property . getName ( ) . trim ( ) ) ) { // check if os / arch is different String propOs = property . getOs ( ) . trim ( ) ; < |startfocus| > // length zero means all OS versions if ( propOs . length ( ) == 0 || os . length ( ) == 0 ) { result = true ; break ; } else if ( os . equals ( propOs ) ) { String propArch = property . getArch ( ) ; // length zero means all architecture versions if ( arch . length ( ) == 0 || propArch . length ( ) == 0 ) { result = true ; break ; } } else { continue ; } } } return result ;
public static boolean containsMatchingProperty ( Set < IConfigurationProperty > existingProperties , String name , String os , String arch ) { boolean result = false ; for ( IConfigurationProperty property : existingProperties ) { if ( name . equals ( property . getName ( ) . trim ( ) ) ) { // check if os / arch is different String propOs = property . getOs ( ) . trim ( ) ; < |startfocus| > // length zero means all OS versions if ( propOs . length ( ) == 0 || os . length ( ) == 0 ) { return true ; < |endfocus| > } else if ( os . equals ( propOs ) ) { String propArch = property . getArch ( ) ; // length zero means all architecture versions if ( arch . length ( ) == 0 || propArch . length ( ) == 0 ) { return true ; } } else { continue ; } } } return result ;
if ( name . equals ( property . getName ( ) . trim ( ) ) ) { // check if os / arch is different String propOs = property . getOs ( ) . trim ( ) ; // length zero means all OS versions if ( propOs . length ( ) == 0 || os . length ( ) == 0 ) { result = true ; break ; } else if ( os . equals ( propOs ) ) { String propArch = property . getArch ( ) ; < |startfocus| > // length zero means all architecture versions if ( arch . length ( ) == 0 || propArch . length ( ) == 0 ) { result = true ; break ; } else if ( arch . equals ( propArch ) ) { result = true ; break ; } < |endfocus| > } else { continue ; } } } return result ;
// check if os / arch is different String propOs = property . getOs ( ) . trim ( ) ; // length zero means all OS versions if ( propOs . length ( ) == 0 || os . length ( ) == 0 ) { result = true ; break ; } else if ( os . equals ( propOs ) ) { String propArch = property . getArch ( ) ; < |startfocus| > // length zero means all architecture versions if ( arch . length ( ) == 0 || propArch . length ( ) == 0 ) { result = true ; break ; < |endfocus| > } } else { continue ; } } } return result ;
String propOs = property . getOs ( ) . trim ( ) ; // length zero means all OS versions if ( propOs . length ( ) == 0 || os . length ( ) == 0 ) { result = true ; break ; } else if ( os . equals ( propOs ) ) { String propArch = property . getArch ( ) ; // length zero means all architecture versions if ( arch . length ( ) == 0 || propArch . length ( ) == 0 ) { result = true ; break ; } < |startfocus| > } else { continue ; } } } return result ;
IConfigurationProperty configuration = ( IConfigurationProperty ) obj ; switch ( index ) { case 0 : return configuration . getName ( ) ; // return super . getColumnText ( PluginRegistry . findModel ( configuration . getId ( ) ) , index ) ; case 1 : return configuration . getValue ( ) ; case 2 : return configuration . getOs ( ) ; case 3 : return configuration . getArch ( ) ; } return null ; } } private class PropertyDialog extends StatusDialog { < |startfocus| > private static final String EMPTY_STRING = "" ; // $NON - NLS - 1$ < |endfocus| > private Text fName ; private Text fValue ; private Combo fOS ; private Combo fArch ; private IConfigurationProperty fEdit ; private Set < IConfigurationProperty > fExistingProperties ; private String [ ] COMBO_OSLABELS = new String [ ] { PDEUIMessages . PropertiesSection_All , Platform . OS_LINUX , Platform . OS_MACOSX , Platform . OS_WIN32 } ; private String [ ] COMBO_ARCHLABELS = new String [ ] { PDEUIMessages . PropertiesSection_All , Platform . ARCH_X86 , Platform . ARCH_X86_64 } ; public PropertyDialog ( Shell shell , IConfigurationProperty property , Set < IConfigurationProperty > existingProperties ) { super ( shell ) ; fEdit = property ;
public void addEvent ( ITimeEvent event ) { if ( isValidEvent ( event ) ) { < |startfocus| > isValidEvent ( event ) ; < |endfocus| > } super . addEvent ( event ) ; }
public void setEventList ( List < ITimeEvent > eventList ) { < |startfocus| > if ( eventList != null ) { super . setEventList ( eventList . stream ( ) . filter ( TimeGraphLineEntry : : isValidEvent ) . collect ( Collectors . toList ( ) ) ) ; < |endfocus| > }
public void updateZoomedEvent ( ITimeEvent event ) { < |startfocus| > isValidEvent ( event ) ; super . updateZoomedEvent ( event ) ; < |endfocus| > }
private static boolean isValidEvent ( ITimeEvent event ) { < |startfocus| > return ( event instanceof TimeLineEvent ) ; < |endfocus| >
// add style Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( timeEvent ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; } long val = values . get ( i ) ; max = Math . max ( Math . abs ( val ) , max ) ; min = 0 ; < |startfocus| > seriesModel . get ( i ) . add ( new LongPoint ( x , val ) ) ; < |endfocus| > } } if ( isEmpty ) { return ; } double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; for ( int i = 0 ; i < seriesModel . size ( ) ; i ++ ) { RGBA rgba = colors . get ( i ) ; Color color = COLOR_REGISTRY . get ( rgba . toString ( ) ) ; Color prev = gc . getForeground ( ) ; int prevAlpha = gc . getAlpha ( ) ; gc . setAlpha ( rgba . alpha ) ; gc . setForeground ( color ) ; List < LongPoint > series = seriesModel . get ( i ) ;
public String toString ( ) { < |startfocus| > return getClass ( ) . getSimpleName ( ) + " time = " + fTime + ( hasValue ( ) ? ( " value = " + fValues . toString ( ) ) : "" ) ; // $NON - NLS - 1$ // $NON - NLS - 2$ // $NON - NLS - 3$ < |endfocus| >
seriesModel . add ( new ArrayList < > ( ) ) ; // add style Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( timeEvent ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; } /* * In the case of missing data , ( WHICH SHOULD NOT HAPPEN , just * persist the current value . */ < |startfocus| > if ( values . size ( ) < i ) { long val = values . get ( i ) ; < |endfocus| > // get max and min , this is a relative scale . max = Math . max ( Math . abs ( val ) , max ) ; min = 0 ; seriesModel . get ( i ) . add ( new LongPoint ( x , val ) ) ; } } } double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; for ( int i = 0 ; i < seriesModel . size ( ) ; i ++ ) { RGBA rgba = colors . get ( i ) ;
Map < String , Object > eventStyle = timeGraphProvider . getEventStyle ( timeEvent ) ; int color = ( int ) eventStyle . getOrDefault ( ITimeEventStyleStrings . fillColor ( ) , 0xff ) ; RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; } /* * In the case of missing data , ( WHICH SHOULD NOT HAPPEN , just * persist the current value . */ < |startfocus| > if ( values . size ( ) < i ) { long val = values . get ( i ) ; < |endfocus| > // get max and min , this is a relative scale . max = Math . max ( Math . abs ( val ) , max ) ; min = 0 ; seriesModel . get ( i ) . add ( new LongPoint ( x , val ) ) ; } } } double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; for ( int i = 0 ; i < seriesModel . size ( ) ; i ++ ) { RGBA rgba = colors . get ( i ) ; Color color = COLOR_REGISTRY . get ( rgba . toString ( ) ) ;
public void addEvent ( ITimeEvent event ) { < |startfocus| > if ( ! ( event instanceof TimeLineEvent ) ) { throw new IllegalArgumentException ( "Needs to be a TimeLineEvent" ) ; // $NON - NLS - 1$ } < |endfocus| > super . addEvent ( event ) ; }
RGBA rgba = RGBAUtil . fromInt ( color ) ; COLOR_REGISTRY . put ( rgba . toString ( ) , rgba . rgb ) ; colors . add ( rgba ) ; } /* * In the case of missing data , ( WHICH SHOULD NOT HAPPEN , just * persist the current value . */ < |startfocus| > List < LongPoint > seriesToAdd = seriesModel . get ( i ) ; long val = values . size ( ) >= nbSeries ? values . get ( i ) : seriesToAdd . get ( seriesToAdd . size ( ) - 1 ) . y ; < |endfocus| > // get max and min , this is a relative scale . max = Math . max ( Math . abs ( val ) , max ) ; min = 0 ; seriesToAdd . add ( new LongPoint ( x , val ) ) ; } } double scale = ( max - min ) == 0 ? 1 . 0 : ( double ) rect . height / ( max - min ) ; for ( int i = 0 ; i < seriesModel . size ( ) ; i ++ ) { RGBA rgba = colors . get ( i ) ; Color color = COLOR_REGISTRY . get ( rgba . toString ( ) ) ; Color prev = gc . getForeground ( ) ; int prevAlpha = gc . getAlpha ( ) ;
throw new IllegalArgumentException ( "Needs to be a TimeLineEvent" ) ; // $NON - NLS - 1$ } super . setEventList ( eventList ) ; } @Override public void updateZoomedEvent ( ITimeEvent event ) { if ( ! ( event instanceof TimeLineEvent ) ) { throw new IllegalArgumentException ( "Needs to be a TimeLineEvent" ) ; // $NON - NLS - 1$ } super . updateZoomedEvent ( event ) ; } @Override public DisplayStyle getStyle ( ) { return DisplayStyle . LINE ; } < |startfocus| > < |endfocus| > }
* accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . tracecompass . internal . tmf . ui . widgets . timegraph . model ; import java . text . NumberFormat ; import java . util . ArrayList ; import java . util . List ; import java . util . Locale ; import java . util . Objects ; import java . util . StringJoiner ; import org . eclipse . tracecompass . tmf . ui . widgets . timegraph . model . ITimeGraphEntry ; import org . eclipse . tracecompass . tmf . ui . widgets . timegraph . model . TimeEvent ; /* * < |startfocus| > * Generic TimeEvent implementation < |endfocus| > * * @author Matthew Khouzam */ public class TimeLineEvent extends TimeEvent { private final List < Long > fValues ; private String fLabel = null ; /* * * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent ( ITimeGraphEntry entry , long time ) { this ( entry , time , new ArrayList < > ( ) ) ; } /* * * Standard constructor * * @param entry * The entry matching this event
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . tracecompass . internal . tmf . ui . widgets . timegraph . model ; import java . text . NumberFormat ; import java . util . ArrayList ; import java . util . List ; import java . util . Locale ; import java . util . Objects ; import java . util . StringJoiner ; import org . eclipse . tracecompass . tmf . ui . widgets . timegraph . model . ITimeGraphEntry ; import org . eclipse . tracecompass . tmf . ui . widgets . timegraph . model . TimeEvent ; /* * * Generic TimeEvent implementation * * @author Matthew Khouzam */ public class TimeLineEvent extends TimeEvent { < |startfocus| > < |endfocus| > private final List < Long > fValues ; private String fLabel = null ; /* * * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent ( ITimeGraphEntry entry , long time ) { this ( entry , time , new ArrayList < > ( ) ) ; } /* * * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event * @param values
/* * * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent ( ITimeGraphEntry entry , long time ) { this ( entry , time , new ArrayList < > ( ) ) ; } /* * * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event * @param values < |startfocus| > * The values to display < |endfocus| > */ public TimeLineEvent ( ITimeGraphEntry entry , long time , List < Long > values ) { super ( entry , time , 0 ) ; fValues = values ; } /* * * Add a value * * @param value * the value to add , it will be displayed as a line */ public void addValue ( long value ) { fValues . add ( value ) ; } @Override public String getLabel ( ) { String label = fLabel ; if ( label == null ) {
private void drawLineGraphEntry ( GC gc , long time0 , Rectangle rect , double pixelsPerNanoSec , Iterator < ITimeEvent > iterator ) { // clamp 0 - max positive long max = Long . MIN_VALUE ; long min = 0 ; List < List < LongPoint > > seriesModel = new ArrayList < > ( ) ; List < RGBA > colors = new ArrayList < > ( ) ; ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider ( ) ; int nbSeries = - 1 ; < |startfocus| > boolean isEmpty = true ; < |endfocus| > while ( iterator . hasNext ( ) ) { ITimeEvent event = iterator . next ( ) ; if ( ! ( event instanceof TimeLineEvent ) ) { continue ; } int x = SaturatedArithmetic . add ( rect . x , ( int ) ( ( event . getTime ( ) - time0 ) * pixelsPerNanoSec ) ) ; if ( x >= rect . x + rect . width ) { // event is out of bounds continue ; } TimeLineEvent timeEvent = ( TimeLineEvent ) event ; List < Long > values = timeEvent . getValues ( ) ; if ( nbSeries == - 1 ) { nbSeries = values . size ( ) ; }
public void setEventList ( List < ITimeEvent > eventList ) { < |startfocus| > if ( eventList != null ) { // Sets a filtered list super . setEventList ( eventList . stream ( ) . filter ( timeEvent - > isValidEvent ( timeEvent ) ) . collect ( Collectors . toList ( ) ) ) ; } < |endfocus| >
public String getLabel ( ) { String label = fLabel ; if ( label == null ) { StringJoiner sj = new StringJoiner ( " , " ) ; // $NON - NLS - 1$ < |startfocus| > getValues ( ) . forEach ( ( Long value ) - > sj . add ( NumberFormat . getNumberInstance ( Locale . getDefault ( ) ) . format ( value ) ) ) ; < |endfocus| > label = sj . toString ( ) ; fLabel = label ; } return label ;
public List < Long > getValues ( ) { < |startfocus| > return new ArrayList < Long > ( fValues ) ; < |endfocus| >
public void register ( ) { Chart chart = getChart ( ) ; < |startfocus| > chart . getPlotArea ( ) . addMouseTrackListener ( this ) ; < |endfocus| > chart . getPlotArea ( ) . addMouseMoveListener ( this ) ; chart . getPlotArea ( ) . addPaintListener ( this ) ; fTooltipHandler . activateHoverHelp ( chart . getPlotArea ( ) ) ; }
public void deregister ( ) { Chart chart = getChart ( ) ; if ( ( chart != null ) && ! chart . isDisposed ( ) ) { < |startfocus| > chart . getPlotArea ( ) . removeMouseTrackListener ( this ) ; < |endfocus| > chart . getPlotArea ( ) . removeMouseMoveListener ( this ) ; chart . getPlotArea ( ) . removePaintListener ( this ) ; fTooltipHandler . deactivateHoverHelp ( chart . getPlotArea ( ) ) ; } }
for ( int i = 0 ; i < 10 ; i ++ ) { appendRandomLine ( f ) ; git . add ( ) . addFilepattern ( "file" ) . call ( ) ; git . commit ( ) . setMessage ( "message" + i ) . call ( ) ; } FileBasedConfig c = db . getConfig ( ) ; c . setInt ( ConfigConstants . CONFIG_GC_SECTION , null , ConfigConstants . CONFIG_KEY_AUTOPACKLIMIT , 1 ) ; c . save ( ) ; Collection < PackFile > packs = gc ( Deflater . NO_COMPRESSION ) ; assertEquals ( "expected 1 packfile after gc" , 1 , packs . size ( ) ) ; < |startfocus| > < |endfocus| > PackFile p1 = packs . iterator ( ) . next ( ) ; PackFileSnapshot snapshot = p1 . getFileSnapshot ( ) ; packs = gc ( Deflater . BEST_COMPRESSION ) ; assertEquals ( "expected 1 packfile after gc" , 1 , packs . size ( ) ) ; PackFile p2 = packs . iterator ( ) . next ( ) ; File pf = p2 . getPackFile ( ) ; // changing compression level with aggressive gc may change size , // fileKey ( on * nix ) and checksum . Hence FileSnapshot . isModified can // return true already based on size or fileKey .
public void setEventList ( List < ITimeEvent > eventList ) { < |startfocus| > if ( eventList != null ) { // Sets a filtered list super . setEventList ( eventList . stream ( ) . filter ( timeEvent - > isValidEvent ( timeEvent ) ) . collect ( Collectors . toList ( ) ) ) ; } < |endfocus| >
public void addValue ( @Nullable Long value ) { < |startfocus| > fValues . add ( value ) ; fLabel = null ; < |endfocus| >
protected SWTBotTreeItem [ ] getPaneBasedSelectionWizardTreeitems ( ) { SWTBotSiriusDiagramEditor representation = ( SWTBotSiriusDiagramEditor ) openRepresentation ( localSession . getOpenedSession ( ) , REPRESENTATION_DESCRIPTION_NAME , REPRESENTATION_NAME , DDiagram . class ) ; representation . setFocus ( ) ; representation . activateTool ( "Pane Based Selection" ) ; representation . click ( 50 , 100 ) ; < |startfocus| > SWTBot wizardBot = bot . waitAndGetBotForShell ( "Pane Based" ) ; < |endfocus| > SWTBotTree tree = wizardBot . tree ( ) . select ( 0 ) ; SWTBotTreeItem swtBotTreeItem = tree . getAllItems ( ) [ 0 ] ; SWTBotTreeItem [ ] items = swtBotTreeItem . getItems ( ) ; return items ;
assertEquals ( session . getStatus ( ) , SessionStatus . SYNC ) ; session . close ( new NullProgressMonitor ( ) ) ; } /* * * Test the cancel on the first wizard . * */ public void testCancelFirstWizard ( ) { cancelFirstWizard ( ) ; Session session = localSession . getOpenedSession ( ) ; assertNotNull ( THERE_IS_NO_SESSION , session ) ; assertEquals ( session . getStatus ( ) , SessionStatus . SYNC ) ; session . close ( new NullProgressMonitor ( ) ) ; } /* * < |startfocus| > * Test the cancel on the first wizard . < |endfocus| > * */ public void testCancelSecondWizard ( ) { cancelSecondWizard ( TREE_NAME ) ; Session session = localSession . getOpenedSession ( ) ; assertNotNull ( THERE_IS_NO_SESSION , session ) ; assertEquals ( session . getStatus ( ) , SessionStatus . SYNC ) ; session . close ( new NullProgressMonitor ( ) ) ; } /* * * Test that empty viewpoint are not displayed */ public void testEmptySirius ( ) { // create representation createOnContextMenu ( ) ; // select representation to create bot . waitUntil ( Conditions . shellIsActive ( "Create Representation Wizard" ) ) ; SWTBotShell shell = bot . shell ( "Create Representation Wizard" ) ;
public static boolean containsMatchingProperty ( Set < IConfigurationProperty > existingProperties , String name , String os , String arch ) { for ( IConfigurationProperty property : existingProperties ) { if ( name . equals ( property . getName ( ) . trim ( ) ) ) { // check if os / arch is different < |startfocus| > String propOs = property . getOs ( ) != null ? property . getOs ( ) . trim ( ) : ALL_OS ; // $NON - NLS - 1$ < |endfocus| > if ( ALL_OS . equals ( propOs ) || ALL_OS . equals ( os ) || propOs . equals ( os ) ) { String propArch = property . getArch ( ) != null ? property . getArch ( ) . trim ( ) : "" ; // $NON - NLS - 1$ if ( propArch . equals ( arch ) || ALL_ARCH . equals ( arch ) || ALL_ARCH . equals ( propArch ) ) { return true ; } } } } return false ;
* * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : * AixpertSoft GmbH - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . pde . core . tests . internal . util ; import java . util . HashSet ; import java . util . Set ; import junit . framework . TestCase ; import org . eclipse . core . runtime . Platform ; import org . eclipse . pde . internal . core . iproduct . IConfigurationProperty ; import org . eclipse . pde . internal . core . product . ProductModel ; import org . eclipse . pde . internal . core . product . ProductModelFactory ; import org . eclipse . pde . internal . core . util . PDESchemaHelper ; < |startfocus| > /* * * @author alexander * */ < |endfocus| > public class PDESchemaHelperTest extends TestCase { private ProductModelFactory fProductModelFactory ; Set < IConfigurationProperty > fConfigurationProperties = new HashSet < > ( ) ; public PDESchemaHelperTest ( ) { initConfigurationProperties ( ) ; } private void initConfigurationProperties ( ) { ProductModel productModel = new ProductModel ( ) ; fProductModelFactory = new ProductModelFactory ( productModel ) ; // create a single property for win32 / all architectures IConfigurationProperty property = fProductModelFactory . createConfigurationProperty ( ) ; property . setName ( "org . osgi . instance . area" ) ; property . setValue ( "@user . home / eclipse - workspace" ) ; property . setArch ( " * " ) ; property . setOs ( "win32" ) ; fConfigurationProperties . add ( property ) ; } public void testGetPropertyValue ( ) { String value = PDESchemaHelper . getPropertyValue ( fConfigurationProperties , "org . osgi . instance . area" , "win32" , " * " ) ; assertEquals ( "@user . home / eclipse - workspace" , value ) ; } }
private static void sanitizeList ( List < ITimeEvent > sourceList , Consumer < List < ITimeEvent > > listConsumer ) { if ( sourceList != null ) { // Sets a filtered list List < ITimeEvent > events = new ArrayList < > ( ) ; for ( ITimeEvent event : sourceList ) { if ( isValidEvent ( event ) ) { events . add ( event ) ; < |startfocus| > } else { < |endfocus| > } } listConsumer . accept ( events ) ; }
} private void appendRandomLine ( File f , int length , Random r ) throws IOException { try ( Writer w = Files . newBufferedWriter ( f . toPath ( ) , StandardOpenOption . APPEND ) ) { appendRandomLine ( w , length , r ) ; } } private void appendRandomLine ( File f ) throws IOException { appendRandomLine ( f , 5 , new Random ( ) ) ; } private void appendRandomLine ( Writer w , int len , Random r ) throws IOException { < |startfocus| > final int a = 32 ; // ' ' int e = 126 ; // '~' < |endfocus| > for ( int i = 0 ; i < len ; i ++ ) { w . append ( ( char ) ( a + r . nextInt ( 1 + e - a ) ) ) ; } } private Git createTestRepo ( int testDataSeed , int testDataLength ) throws IOException , GitAPIException , NoFilepatternException , NoHeadException , NoMessageException , UnmergedPathsException , ConcurrentRefUpdateException , WrongRepositoryStateException , AbortedByHookException { // Create a repo with two commits and one file . Each commit adds // testDataLength number of bytes . Data are random bytes . Since the
// Copyright ( C ) 2009 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . git ; import static com . google . gerrit . server . git . MultiProgressMonitor . UNKNOWN ; import com . google . gerrit . reviewdb . client . Project ; import com . google . gerrit . server . config . GerritServerConfig ; import com . google . gerrit . server . config . SitePaths ; import com . google . inject . Inject ; import com . google . inject . assistedinject . Assisted ; import org . eclipse . jgit . errors . RepositoryNotFoundException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . lib . ProgressMonitor ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . lib . RepositoryCache ; import org . eclipse . jgit . lib . RepositoryCache . FileKey ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . LenientRepositoryCache ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . RegularRepositoryCache ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . StandardKey ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version2 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version3 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version4 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version5 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version6 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version7 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version8 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version9 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version10 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version11 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version12 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version13 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version14 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version15 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version16 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version17 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version18 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version19 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version20 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version21 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version22 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version23 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version24 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version25 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version26 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version27 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version28 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version29 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version30 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version31 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version32 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version33 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version34 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version35 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version36 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version37 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version38 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version39 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version40 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version41 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version42 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version43 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version44 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version45 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version46 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version47 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version48 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version49 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version50 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version51 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version52 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version53 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version54 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version55 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version56 ; import org . eclipse . jgit . lib . RepositoryCache . FileKey . Version57 ; import org . eclipse . j
git . commit ( ) . setMessage ( "message2" ) . call ( ) . getId ( ) ; return git ; } // Try repacking so fast that you get two new packs which differ only in // content / chksum but have same name , size and lastmodified . // Since this is done with standard gc ( which creates new tmp files and // renames them ) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test < |startfocus| > public void testDetetctModificationAlthoughSameSizeAndModificationtime ( ) < |endfocus| > throws Exception { int testDataSeed = 1 ; int testDataLength = 100 ; FileBasedConfig config = db . getConfig ( ) ; // tell JGit not to used mtime of the parent folder to detect file // modifications . config . setBoolean ( ConfigConstants . CONFIG_CORE_SECTION , null , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , false ) ; config . save ( ) ; createTestRepo ( testDataSeed , testDataLength ) ; // Pack to create initial packfile PackFile pf = repackAndCheck ( 5 , null , null , null ) ; Path packFilePath = pf . getPackFile ( ) . toPath ( ) ; AnyObjectId chk1 = pf . getPackChecksum ( ) ;
git . commit ( ) . setMessage ( "message2" ) . call ( ) . getId ( ) ; return git ; } // Try repacking so fast that you get two new packs which differ only in // content / chksum but have same name , size and lastmodified . // Since this is done with standard gc ( which creates new tmp files and // renames them ) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test < |startfocus| > public void testDetectModificationAlthoughtSameSizeAndModificationtime ( ) < |endfocus| > throws Exception { int testDataSeed = 1 ; int testDataLength = 100 ; FileBasedConfig config = db . getConfig ( ) ; // tell JGit not to used mtime of the parent folder to detect file // modifications . config . setBoolean ( ConfigConstants . CONFIG_CORE_SECTION , null , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , false ) ; config . save ( ) ; createTestRepo ( testDataSeed , testDataLength ) ; // Pack to create initial packfile PackFile pf = repackAndCheck ( 5 , null , null , null ) ; Path packFilePath = pf . getPackFile ( ) . toPath ( ) ; AnyObjectId chk1 = pf . getPackChecksum ( ) ;
// content / chksum but have same name , size and lastmodified . // Since this is done with standard gc ( which creates new tmp files and // renames them ) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtime ( ) throws Exception { int testDataSeed = 1 ; int testDataLength = 100 ; FileBasedConfig config = db . getConfig ( ) ; < |startfocus| > // tell JGit not to used mtime of the parent folder to detect file // modifications . < |endfocus| > config . setBoolean ( ConfigConstants . CONFIG_CORE_SECTION , null , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , false ) ; config . save ( ) ; createTestRepo ( testDataSeed , testDataLength ) ; // Pack to create initial packfile PackFile pf = repackAndCheck ( 5 , null , null , null ) ; Path packFilePath = pf . getPackFile ( ) . toPath ( ) ; AnyObjectId chk1 = pf . getPackChecksum ( ) ; String name = pf . getPackName ( ) ; Long length = Long . valueOf ( pf . getPackFile ( ) . length ( ) ) ; long m1 = packFilePath . toFile ( ) . lastModified ( ) ; // Modify the packfile and the index file .
// Copyright ( C ) 2009 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . git ; import static com . google . common . base . Preconditions . checkArgument ; import static com . google . common . base . Preconditions . checkState ; import static com . google . common . collect . ImmutableList . toImmutableList ; import static com . google . common . collect . ImmutableSet . toImmutableSet ; import static com . google . common . collect . Iterables . getOnlyElement ; import static com . google . common . collect . Sets . difference ; import static com . google . common . collect . Sets . union ; import static com . google . gerrit . git . ObjectIds . abbreviateName ; import static com . google . gerrit . server . git . MultiProgressMonitor . UNKNOWN ; import static java . util . Comparator . comparing ; import static java . util . stream . Collectors . toList ; import static java . util . stream . Collectors . toSet ; import com . google . common . collect . ImmutableList ; import com . google . common . collect . ImmutableSet ; import com . google . common . collect . Iterables ; import com . google . common . collect . Lists ; import com . google . common . collect . Sets ; import com . google . common . flogger . FluentLogger ; import com . google . gerrit . common . Nullable ; import com . google . gerrit . common . data . ReceiveCommitsAdvice ; import com . google . gerrit . entities . BranchNameKey ; import com . google . gerrit . entities . Project ; import com . google . gerrit . entities . RefNames ; import com . google . gerrit . exceptions . StorageException ; import com . google . gerrit . extensions . api . GerritApi ; import com . google . gerrit . extensions . api . changes . NotifyHandling ; import com . google . gerrit . extensions . api . projects . BranchInput ; import com . google . gerrit . extensions . restapi . AuthException ; import com . google . gerrit . extensions . restapi . ResourceConflictException ; import com . google . gerrit . extensions . restapi . ResourceNotFoundException ; import com . google . gerrit . extensions . restapi . RestApiException ; import com . google . gerrit . server . GerritPersonIdent ; import com . google . gerrit . server . IdentifiedUser ; import com . google . gerrit . server . config . AllProjectsName ; import com . google . gerrit . server . config . AllUsersName ; import com . google . gerrit . server . config . GerritServerConfig ; import com . google . gerrit . server . git . MultiProgressMonitor . Task ; import com . google . gerrit . server . git . validators . CommitValidationException ; import com . google . gerrit . server . git . validators . CommitValidationListener ; import com . google . gerrit . server . git . validators . CommitValidationMessage ; import com . google . gerrit . server . git . validators . CommitValidators ; import com . google . gerrit . server . notedb . ChangeNotes ; import com . google . gerrit . server . permissions . PermissionBackendException ; import com . google . gerrit . server . project . NoSuchProjectException ; import com . google . gerrit . server . project . ProjectCache ; import com . google . gerrit . server . project . ProjectState ; import com . google . gerrit . server . query . change . ChangeData ; import com . google . gerrit . server . query . change . InternalChangeQuery ; import com . google . gerrit . server . update . BatchUpdate ; import com . google . gerrit . server . update . BatchUpdateOp ; import com . google . gerrit . server . update . ChangeContext ; import com . google . gerrit . server . update . Context ; import com . google . gerrit . server . update . RetryHelper ; import com . google . gerrit . server . update . RetryingRestModifyView ; import com . google . gerrit . server . update . UpdateException ; import com . google . gerrit . server . util . time . TimeUtil ; import com . google . inject . Inject ; import com . google . inject . Provider ; import com . google . inject . Singleton ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Collection ; import java . util . Collections ; import java . util . HashSet ; import java . util . List ; import java . util . Set ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . errors . IncorrectObjectTypeException ; import org . eclipse . jgit . errors . MissingObjectException ; import org . eclipse . jgit . lib . CommitBuilder ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . ObjectInserter ; import org . eclipse . jgit . lib . PersonIdent ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . RefUpdate ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . revwalk . RevCommit ; import org . eclipse . jgit . revwalk . RevWalk ; import org . eclipse . jgit . transport . ReceiveCommand ; import org . eclipse . jgit . transport . ReceiveCommand . Result ; import org . eclipse . jgit . transport . ReceiveCommand . Type ; /* * * Validates that the commit message of a change is not empty . * * < p > This validator is enabled by default . */ @Singleton public class EmptyCommitValidationListener implements CommitValidationListener { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; @Override public List < CommitValidationMessage > onCommitReceived ( CommitReceivedEvent receiveEvent , @Nullable ProjectState projectState ) throws CommitValidationException { if ( receiveEvent . commit
. getPackChecksum ( ) ) ; assumeTrue ( m3 == m2 ) ; } // Try repacking so fast that you get two new packs which differ only in // content / chksum but have same name , size and lastmodified . // To avoid that JGit detects modifications by checking the filekey create // two new packfiles upfront and create copies of them . Then modify the // packfiles inplace by opening them for write and copy content . @Test < |startfocus| > public void testDetetctModificationAlthoughSameSizeAndModificationtimeAndFileKey ( ) < |endfocus| > throws Exception { int testDataSeed = 1 ; int testDataLength = 100 ; FileBasedConfig config = db . getConfig ( ) ; config . setBoolean ( ConfigConstants . CONFIG_CORE_SECTION , null , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , false ) ; config . save ( ) ; createTestRepo ( testDataSeed , testDataLength ) ; // Pack to create initial packfile . Make a copy of it PackFile pf = repackAndCheck ( 5 , null , null , null ) ; Path packFilePath = pf . getPackFile ( ) . toPath ( ) ; Path packFileBasePath = packFilePath . resolveSibling (
. getPackChecksum ( ) ) ; assumeTrue ( m3 == m2 ) ; } // Try repacking so fast that you get two new packs which differ only in // content / chksum but have same name , size and lastmodified . // To avoid that JGit detects modifications by checking the filekey create // two new packfiles upfront and create copies of them . Then modify the // packfiles inplace by opening them for write and copy content . @Test < |startfocus| > public void testDetectModificationAlthoughtSameSizeAndModificationtimeAndFileKey ( ) < |endfocus| > throws Exception { int testDataSeed = 1 ; int testDataLength = 100 ; FileBasedConfig config = db . getConfig ( ) ; config . setBoolean ( ConfigConstants . CONFIG_CORE_SECTION , null , ConfigConstants . CONFIG_KEY_TRUSTFOLDERSTAT , false ) ; config . save ( ) ; createTestRepo ( testDataSeed , testDataLength ) ; // Pack to create initial packfile . Make a copy of it PackFile pf = repackAndCheck ( 5 , null , null , null ) ; Path packFilePath = pf . getPackFile ( ) . toPath ( ) ; Path packFileBasePath = packFilePath . resolveSibling (
// Copyright ( C ) 2009 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . git ; import static com . google . common . truth . Truth . assertThat ; import static com . google . common . truth . Truth . assertWithMessage ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollection ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionNotRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionRunWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesNotRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesRunWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesNotRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesRunWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesNotRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesRunWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesNotRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesRunWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesNotRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesRunWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesNotRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesRunWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesNotRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesRunWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstones ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesNotRun ; import static com . google . gerrit . server . git . GarbageCollectionTestUtil . assertGarbageCollectionWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesWithTombstonesRun ; import static com . google . gerrit . server . git . GarbageCollectionTest
public void setImage ( Image image ) { checkWidget ( ) ; if ( ( style & SWT . SEPARATOR ) != 0 ) return ; if ( image != null && image . isDisposed ( ) ) error ( SWT . ERROR_INVALID_ARGUMENT ) ; this . image = image ; < |startfocus| > updateStyleBits ( image == null ) ; < |endfocus| > OS . InvalidateRect ( handle , null , true ) ;
public void setText ( String string ) { checkWidget ( ) ; if ( string == null ) error ( SWT . ERROR_NULL_ARGUMENT ) ; if ( ( style & SWT . SEPARATOR ) != 0 ) return ; < |startfocus| > updateStyleBits ( true ) ; < |endfocus| > /* * Feature in Windows . For some reason , SetWindowText ( ) for * static controls redraws the control , even when the text has * has not changed . The fix is to check for this case and do * nothing . */ if ( string . equals ( text ) ) return ; text = string ; string = Display . withCrLf ( string ) ; TCHAR buffer = new TCHAR ( getCodePage ( ) , string , true ) ; OS . SetWindowText ( handle , buffer ) ; if ( ( state & HAS_AUTO_DIRECTION ) != 0 ) { updateTextDirection ( AUTO_TEXT_DIRECTION ) ; }
protected List < ISourceContainer > getEntriesAsList ( ) { ISourceContainer [ ] entries = getViewer ( ) . getEntries ( ) ; List < ISourceContainer > list = new ArrayList < > ( entries . length ) ; < |startfocus| > for ( ISourceContainer entry : entries ) { list . add ( entry ) ; < |endfocus| > } return list ;
public void setEntries ( ISourceContainer [ ] entries ) { fEntries . clear ( ) ; < |startfocus| > for ( ISourceContainer entrie : entries ) { if ( entrie != null ) { fEntries . add ( entrie ) ; < |endfocus| > } } if ( getInput ( ) == null ) { setInput ( fEntries ) ; // select first item in list if ( ! fEntries . isEmpty ( ) && fEntries . get ( 0 ) != null ) { setSelection ( new StructuredSelection ( fEntries . get ( 0 ) ) ) ; } } else { refresh ( ) ; } fPanel . setDirty ( true ) ; fPanel . updateLaunchConfigurationDialog ( ) ;
public void addEntries ( ISourceContainer [ ] entries ) { int index = 0 ; IStructuredSelection sel = getStructuredSelection ( ) ; if ( ! sel . isEmpty ( ) ) { < |startfocus| > index = fEntries . indexOf ( sel . getFirstElement ( ) ) ; } for ( ISourceContainer entrie : entries ) { if ( ! fEntries . contains ( entrie ) ) { fEntries . add ( index , entrie ) ; < |endfocus| > index ++ ; } } refresh ( ) ; if ( entries . length > 0 ) { setSelection ( new StructuredSelection ( entries ) ) ; } fPanel . setDirty ( true ) ; fPanel . updateLaunchConfigurationDialog ( ) ;
public void setOrganizers ( IBreakpointOrganizer [ ] organizers ) { // remove previous listeners if ( fOrganizers != null ) { for ( IBreakpointOrganizer organizer : fOrganizers ) { organizer . removePropertyChangeListener ( this ) ; } < |startfocus| > } < |endfocus| > fOrganizers = organizers ; if ( organizers != null && organizers . length == 0 ) { fOrganizers = null ; } // add listeners if ( fOrganizers != null ) { for ( IBreakpointOrganizer organizer : fOrganizers ) { organizer . addPropertyChangeListener ( this ) ; } } if ( ! fDisposed ) { fViewer . getControl ( ) . setRedraw ( false ) ; // maintain expansion based on visible breakpoints IBreakpoint [ ] breakpoints = null ; if ( isShowingGroups ( ) ) { breakpoints = fViewer . getVisibleBreakpoints ( ) ; } reorganize ( ) ; if ( isShowingGroups ( ) && breakpoints != null ) { // restore expansion for ( Object fElement : fElements ) { BreakpointContainer container = ( BreakpointContainer ) fElement ; for ( IBreakpoint breakpoint : breakpoints ) { if ( container . contains ( breakpoint ) ) { fViewer . expandToLevel ( container , AbstractTreeViewer . ALL_LEVELS ) ; fViewer . updateCheckedState ( container ) ;
public void setOrganizers ( IBreakpointOrganizer [ ] organizers ) { // remove previous listeners if ( fOrganizers != null ) { for ( IBreakpointOrganizer fOrganizer : fOrganizers ) { fOrganizer . removePropertyChangeListener ( this ) ; } } fOrganizers = organizers ; if ( organizers != null && organizers . length == 0 ) { fOrganizers = null ; } < |startfocus| > // add listeners if ( fOrganizers != null ) { for ( IBreakpointOrganizer fOrganizer : fOrganizers ) { fOrganizer . addPropertyChangeListener ( this ) ; < |endfocus| > } } if ( ! fDisposed ) { fViewer . getControl ( ) . setRedraw ( false ) ; // maintain expansion based on visible breakpoints IBreakpoint [ ] breakpoints = null ; if ( isShowingGroups ( ) ) { breakpoints = fViewer . getVisibleBreakpoints ( ) ; } reorganize ( ) ; if ( isShowingGroups ( ) && breakpoints != null ) { // restore expansion for ( Object fElement : fElements ) { BreakpointContainer container = ( BreakpointContainer ) fElement ; for ( IBreakpoint breakpoint : breakpoints ) { if ( container . contains ( breakpoint ) ) { fViewer . expandToLevel ( container , AbstractTreeViewer . ALL_LEVELS ) ; fViewer . updateCheckedState ( container ) ; } } } fViewer . getControl ( ) . setRedraw ( true ) ; } }
public boolean isValidProperty ( String property ) { if ( fFilters == null ) { return true ; } < |startfocus| > for ( String fFilter : fFilters ) { if ( fFilter . equals ( property ) ) { < |endfocus| > return true ; } } return false ;
} return ret . toArray ( new MemoryByte [ ret . size ( ) ] ) ; } public String getRawMemoryString ( ) { if ( fStrRep == null ) { StringBuffer buffer = new StringBuffer ( ) ; fStrRep = RenderingsUtil . convertByteArrayToHexString ( getByteArray ( ) ) ; fStrRep = fStrRep . toUpperCase ( ) ; buffer = buffer . append ( fStrRep ) ; // pad unavailable bytes with padded string from memory block String paddedString = null ; int bufferCounter = 0 ; < |startfocus| > for ( MemoryByte memoryByte : fBytes ) { < |endfocus| > // if byte is invalid if ( ! memoryByte . isReadable ( ) ) { if ( paddedString == null ) { paddedString = fPaddedString ; if ( paddedString . length ( ) > TableRenderingLine . numCharPerByteForHex ) { paddedString = paddedString . substring ( 0 , TableRenderingLine . numCharPerByteForHex ) ; } } buffer . replace ( bufferCounter , bufferCounter + TableRenderingLine . numCharPerByteForHex , paddedString ) ; } bufferCounter += TableRenderingLine . numCharPerByteForHex ; } fStrRep = buffer . toString ( ) ; } return fStrRep ; }
fSashForm . setMaximizedControl ( variablesViewer . getControl ( ) ) ; fDetailsAnchor = SWTFactory . createComposite ( fSashForm , parent . getFont ( ) , 1 , 1 , GridData . FILL_BOTH , 0 , 0 ) ; fSashForm . setWeights ( getLastSashWeights ( ) ) ; fSelectionProvider = new SelectionProviderWrapper ( variablesViewer ) ; getSite ( ) . setSelectionProvider ( fSelectionProvider ) ; createOrientationActions ( variablesViewer ) ; IPreferenceStore prefStore = DebugUIPlugin . getDefault ( ) . getPreferenceStore ( ) ; String orientation = prefStore . getString ( getDetailPanePreferenceKey ( ) ) ; < |startfocus| > for ( ToggleDetailPaneAction toggleDetailPaneAction : fToggleDetailPaneActions ) { toggleDetailPaneAction . setChecked ( toggleDetailPaneAction . getOrientation ( ) . equals ( orientation ) ) ; < |endfocus| > } fDetailPane = new DetailPaneProxy ( this ) ; fDetailPane . addProperyListener ( new IPropertyListener ( ) { @Override public void propertyChanged ( Object source , int propId ) { firePropertyChange ( propId ) ; } } ) ; setDetailPaneOrientation ( orientation ) ; IMemento memento = getMemento ( ) ; if ( memento != null ) { variablesViewer . initState ( memento ) ; } variablesViewer . addModelChangedListener ( this ) ; variablesViewer . addViewerUpdateListener ( this ) ; initDragAndDrop ( variablesViewer ) ; return variablesViewer ;
protected void saveAllCheckedActionStates ( ) { IToolBarManager tbm = getViewSite ( ) . getActionBars ( ) . getToolBarManager ( ) ; IContributionItem [ ] items = tbm . getItems ( ) ; < |startfocus| > for ( IContributionItem contributionItem : items ) { < |endfocus| > if ( contributionItem instanceof ActionContributionItem ) { ActionContributionItem item = ( ActionContributionItem ) contributionItem ; IAction action = item . getAction ( ) ; if ( action . getStyle ( ) == IAction . AS_CHECK_BOX && action . isEnabled ( ) ) { saveCheckedActionState ( action ) ; } } }
* * @param breakpoints the breakpoints to export * @since 3 . 5 */ public ExportBreakpointsOperation ( IBreakpoint [ ] breakpoints ) { fBreakpoints = breakpoints ; fWriter = new StringWriter ( ) ; } @Override public void run ( IProgressMonitor monitor ) throws InvocationTargetException { SubMonitor localmonitor = SubMonitor . convert ( monitor , ImportExportMessages . ExportOperation_0 , fBreakpoints . length ) ; XMLMemento memento = XMLMemento . createWriteRoot ( IImportExportConstants . IE_NODE_BREAKPOINTS ) ; try ( Writer writer = fWriter ; ) { < |startfocus| > for ( IBreakpoint fBreakpoint : fBreakpoints ) { < |endfocus| > if ( localmonitor . isCanceled ( ) ) { return ; } IBreakpoint breakpoint = fBreakpoint ; // in the event we are in working set view , we can have multiple selection of the same breakpoint // so do a simple check for it IMarker marker = breakpoint . getMarker ( ) ; IMemento root = memento . createChild ( IImportExportConstants . IE_NODE_BREAKPOINT ) ; root . putString ( IImportExportConstants . IE_BP_ENABLED , Boolean . toString ( breakpoint . isEnabled ( ) ) ) ; root . putString ( IImportExportConstants . IE_BP_REGISTERED , Boolean . toString ( breakpoint . isRegistered ( ) ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ID , marker . getType ( ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_HANDLE_ID , marker . getAttribute ( IImportExportConstants . IE_BP_MARKER_HANDLE_ID , null ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_HANDLE_ID , marker . getAttribute ( IImportExportConstants . IE_BP_MARKER_HANDLE_ID , null ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_ID , marker . getType ( ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_PATH , marker . getResource ( ) . getFullPath ( ) . toString ( ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_TYPE , marker . getType ( ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_CHAR_START , marker . getAttribute ( IMarker . CHAR_START , null ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_CHAR_END , marker . getAttribute ( IMarker . CHAR_END , null ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_LINE_NUMBER , marker . getAttribute ( IMarker . LINE_NUMBER , null ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_MESSAGE , marker . getAttribute ( IMarker . MESSAGE , null ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_SEVERITY , marker . getAttribute ( IMarker . SEVERITY , null ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_LOCATION , marker . getAttribute ( IMarker . LOCATION , null ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_SOURCE_ID , marker . getAttribute ( IMarker . SOURCE_ID , null ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_VARIABLE , marker . getAttribute ( IMarker . VARIABLE , null ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_EXPRESSION , marker . getAttribute ( IMarker . EXPRESSION , null ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_TEXT , marker . getAttribute ( IMarker . TEXT , null ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_CREATION_TIME , marker . getAttribute ( IMarker . CREATION_TIME , null ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_MODIFICATION_TIME , marker . getAttribute ( IMarker . MODIFICATION_TIME , null ) ) ; root . putString ( IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_ATTRIBUTE_PREFIX + IImportExportConstants . IE_BP_MARKER_ATTRIBUTE
public ExportBreakpointsOperation ( IBreakpoint [ ] breakpoints ) { fBreakpoints = breakpoints ; fWriter = new StringWriter ( ) ; } @Override public void run ( IProgressMonitor monitor ) throws InvocationTargetException { SubMonitor localmonitor = SubMonitor . convert ( monitor , ImportExportMessages . ExportOperation_0 , fBreakpoints . length ) ; XMLMemento memento = XMLMemento . createWriteRoot ( IImportExportConstants . IE_NODE_BREAKPOINTS ) ; try ( Writer writer = fWriter ; ) { for ( IBreakpoint fBreakpoint : fBreakpoints ) { if ( localmonitor . isCanceled ( ) ) { return ; } < |startfocus| > IBreakpoint breakpoint = fBreakpoint ; < |endfocus| > // in the event we are in working set view , we can have multiple selection of the same breakpoint // so do a simple check for it IMarker marker = breakpoint . getMarker ( ) ; IMemento root = memento . createChild ( IImportExportConstants . IE_NODE_BREAKPOINT ) ; root . putString ( IImportExportConstants . IE_BP_ENABLED , Boolean . toString ( breakpoint . isEnabled ( ) ) ) ; root . putString ( IImportExportConstants . IE_BP_REGISTERED , Boolean . toString ( breakpoint . isRegistered ( ) ) ) ; root . putString ( IImportExportConstants . IE_BP_PERSISTANT , Boolean . toString ( breakpoint . isPersisted ( ) ) ) ; // write out the resource information
if ( scroll != null && ! scroll . isDisposed ( ) ) { scroll . removeSelectionListener ( fScrollbarSelectionListener ) ; } if ( ! fTableCursor . isDisposed ( ) ) { fTableCursor . removeTraverseListener ( fCursorTraverseListener ) ; fTableCursor . removeKeyListener ( fCursorKeyAdapter ) ; fTableCursor . removeMouseListener ( fCursorMouseListener ) ; } fCursorEditor . dispose ( ) ; fTextViewer = null ; fTableViewer = null ; fTableCursor = null ; // clean up cell editors < |startfocus| > for ( CellEditor fEditor : fEditors ) { fEditor . dispose ( ) ; } < |endfocus| > // remove font change listener when the view tab is disposed JFaceResources . getFontRegistry ( ) . removeListener ( this ) ; // remove the view tab from the synchronizer IMemoryRenderingSynchronizationService syncService = getMemoryRenderingContainer ( ) . getMemoryRenderingSite ( ) . getSynchronizationService ( ) ; if ( syncService != null ) { syncService . removePropertyChangeListener ( this ) ; } DebugUIPlugin . getDefault ( ) . getPreferenceStore ( ) . removePropertyChangeListener ( this ) ; fToolTipShell . dispose ( ) ; if ( getPopupMenuManager ( ) != null ) { getPopupMenuManager ( ) . removeMenuListener ( fMenuListener ) ; } super . dispose ( ) ;
import org . eclipse . emf . edit . provider . ComposedAdapterFactory ; import org . eclipse . emf . edit . provider . ReflectiveItemProviderAdapterFactory ; import org . eclipse . jface . databinding . swt . WidgetValueProperty ; import org . eclipse . jface . viewers . CellEditor ; import org . eclipse . swt . SWT ; import org . eclipse . swt . events . FocusEvent ; import org . eclipse . swt . events . FocusListener ; import org . eclipse . swt . graphics . Image ; import org . eclipse . swt . widgets . Composite ; import org . eclipse . swt . widgets . Control ; /* * * Single reference cell editor implementation . * * @author Mat Hansen < mhansen@eclipsesource . com > < |startfocus| > * @since 1 . 22 < |endfocus| > * */ @SuppressWarnings ( "restriction" ) public class SingleReferenceCellEditor extends CellEditor implements ECPCellEditor , ECPElementAwareCellEditor { private EObject rowElement ; private ReferenceService referenceService ; private EReference eReference ; private Composite composite ; private ComposedAdapterFactory composedAdapterFactory ; private AdapterFactoryItemDelegator adapterFactoryItemDelegator ; /* * * The constructor . * * @param parent the parent composite */ public SingleReferenceCellEditor ( Composite parent ) { super ( parent ) ; } /* * * Alternate constructor with SWT style bits . *
public String getFormatedString ( Object value ) { if ( value == null ) { < |startfocus| > return "" ; < |endfocus| > } return adapterFactoryItemDelegator . getText ( value ) ;
* * Contributors : * EclipseSource Munich - initial API and implementation */ package org . eclipse . emf . ecp . view . internal . table . swt . cell ; import org . eclipse . emf . ecore . EObject ; import org . eclipse . emf . ecore . EReference ; import org . eclipse . emf . ecore . EStructuralFeature ; import org . eclipse . emf . ecp . edit . spi . swt . table . ECPCellEditorTester ; import org . eclipse . emf . ecp . view . spi . context . ViewModelContext ; /* * * Single reference cell editor tester . * * @author Mat Hansen < mhansen@eclipsesource . com > < |startfocus| > * @since 1 . 21 < |endfocus| > * */ public class SingleReferenceCellEditorTester implements ECPCellEditorTester { @Override public int isApplicable ( EObject eObject , EStructuralFeature eStructuralFeature , ViewModelContext viewModelContext ) { if ( ! EReference . class . isInstance ( eStructuralFeature ) ) { return NOT_APPLICABLE ; } final EReference eReference = EReference . class . cast ( eStructuralFeature ) ; if ( eReference . getUpperBound ( ) == 1 ) { return 10 ; } return NOT_APPLICABLE ; } }
private void analyseSomeReferencedPackages ( PackageVisibilityStatement [ ] stats , CompilationUnitScope skope ) { < |startfocus| > for ( PackageVisibilityStatement export : stats ) { PackageBinding pb = export . resolvedPackage ; < |endfocus| > if ( pb == null ) continue ; pb = pb . getIncarnation ( this . binding ) ; if ( pb != null && pb . hasCompilationUnit ( true ) ) continue ; skope . problemReporter ( ) . invalidPackageReference ( IProblem . PackageDoesNotExistOrIsEmpty , export ) ; } }
if ( checkForSplit && this . environment . useModuleSystem ) { char [ ] [ ] declaringModuleNames = null ; if ( isUnnamed ( ) ) { IModuleAwareNameEnvironment moduleEnv = ( IModuleAwareNameEnvironment ) this . environment . nameEnvironment ; declaringModuleNames = moduleEnv . getUniqueModulesDeclaringPackage ( new char [ ] [ ] { packageName } , ANY ) ; } packageBinding = combineWithPackagesFromOtherRelevantModules ( packageBinding , packageBinding . compoundName , declaringModuleNames ) ; } < |startfocus| > this . declaredPackages . put ( packageName , packageBinding . getIncarnation ( this ) ) ; < |endfocus| > if ( packageBinding . parent == null ) { this . environment . knownPackages . put ( packageName , packageBinding ) ; } } return packageBinding ; } private PackageBinding combineWithPackagesFromOtherRelevantModules ( PackageBinding currentBinding , char [ ] [ ] compoundName , char [ ] [ ] declaringModuleNames ) { boolean save = this . isPackageLookupActive ; this . isPackageLookupActive = true ; try { for ( ModuleBinding moduleBinding : otherRelevantModules ( declaringModuleNames ) ) { if ( ! moduleBinding . isPackageLookupActive ) { PackageBinding nextBinding = moduleBinding . getDeclaredPackage ( CharOperation . concatWith ( compoundName , ' . ' ) ) ;
PackageBinding combineWithSiblings ( PackageBinding childPackage , char [ ] name , ModuleBinding module ) { < |startfocus| > ModuleBinding primaryModule = childPackage . enclosingModule ; < |endfocus| > // see if other incarnations contribute to the child package , too : boolean activeSave = primaryModule . isPackageLookupActive ; primaryModule . isPackageLookupActive = true ; try { char [ ] flatName = CharOperation . concatWith ( childPackage . compoundName , ' . ' ) ; for ( PackageBinding incarnation : this . incarnations ) { ModuleBinding moduleBinding = incarnation . enclosingModule ; if ( moduleBinding == module ) continue ; if ( childPackage . isDeclaredIn ( moduleBinding ) ) continue ; PackageBinding next = moduleBinding . getDeclaredPackage ( flatName ) ; childPackage = combine ( next , childPackage , primaryModule ) ; } return childPackage ; } finally { primaryModule . isPackageLookupActive = activeSave ; }
final Object image = adapterFactoryItemDelegator . getImage ( value ) ; return SWTImageHelper . getImage ( image ) ; } @Override public int getColumnWidthWeight ( ) { return 0 ; } @Override public UpdateValueStrategy getTargetToModelStrategy ( DataBindingContext databindingContext ) { return null ; } @Override public UpdateValueStrategy getModelToTargetStrategy ( DataBindingContext databindingContext ) { return null ; } @Override public void setEditable ( boolean editable ) { } @Override public int getMinWidth ( ) { return 100 ; } < |startfocus| > /* * * { @inheritDoc } * * @see org . eclipse . jface . viewers . CellEditor#createControl ( org . eclipse . swt . widgets . Composite ) */ < |endfocus| > @Override protected Control createControl ( Composite parent ) { composite = new Composite ( parent , SWT . NONE ) ; composite . addFocusListener ( new FocusListener ( ) { private boolean focused ; @Override public void focusLost ( FocusEvent e ) { } @Override public void focusGained ( FocusEvent e ) { if ( focused ) { return ; } focused = true ; try {
* * Contributors : * Vincent Lorenzo ( CEA LIST ) vincent . lorenzo@cea . fr - Initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . papyrus . model2doc . odt . internal . transcription ; /* * * This class contains the custom fields used to generate LibreOffice document */ public class CustomFields { /* * * Constructor . * */ private CustomFields ( ) { // to prevent instanciation } /* * * The custom field Authors */ < |startfocus| > public static final String AUTHORS = "Authors" ; < |endfocus| > /* * * The custom field Version */ public static final String VERSION = "Version" ; }
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . papyrus . model2doc . odt . internal . transcription ; /* * * This class contains the custom fields used to generate LibreOffice document */ public class CustomFields { /* * * Constructor . * */ private CustomFields ( ) { // to prevent instanciation } /* * * The custom field Authors */ public static final String AUTHORS = "Authors" ; /* * * The custom field Version */ < |startfocus| > public static final String VERSION = "Version" ; < |endfocus| > }
public void writeAuthors ( final Collection < IAuthor > authors ) { if ( authors . size ( ) > 0 ) { final XTextDocument document = odtEditor . getXTextDocument ( ) ; final XDocumentPropertiesSupplier xsDocProp = UnoRuntime . queryInterface ( XDocumentPropertiesSupplier . class , document ) ; XDocumentProperties props = xsDocProp . getDocumentProperties ( ) ; final Iterator < IAuthor > iterator = authors . iterator ( ) ; < |startfocus| > String allAuthorsLabel = "" ; < |endfocus| > if ( iterator . hasNext ( ) ) { final IAuthor firstAuthor = iterator . next ( ) ; allAuthorsLabel = firstAuthor . buildMultiAuthorLabel ( ECollections . toEList ( authors ) ) ; props . setAuthor ( firstAuthor . buildAuthorLabel ( ) ) ; } XPropertyContainer userDefined = props . getUserDefinedProperties ( ) ; // we need to remove the property if it already exist , in order to be change its value try { userDefined . removeProperty ( CustomFields . AUTHORS ) ; } catch ( UnknownPropertyException | NotRemoveableException e ) { // nothing to do } try { userDefined . addProperty ( CustomFields . AUTHORS , com . sun . star . beans . PropertyAttribute . REMOVABLE , allAuthorsLabel ) ; } catch ( IllegalArgumentException | PropertyExistException | IllegalTypeException e ) { Activator . log . error ( e ) ; } }
String allAuthorsLabel = "" ; if ( iterator . hasNext ( ) ) { final IAuthor firstAuthor = iterator . next ( ) ; allAuthorsLabel = firstAuthor . buildMultiAuthorLabel ( ECollections . toEList ( authors ) ) ; props . setAuthor ( firstAuthor . buildAuthorLabel ( ) ) ; } XPropertyContainer userDefined = props . getUserDefinedProperties ( ) ; // we need to remove the property if it already exist , in order to be change its value try { userDefined . removeProperty ( CustomFields . AUTHORS ) ; } catch ( UnknownPropertyException | NotRemoveableException e ) { // nothing to do } try { userDefined . addProperty ( CustomFields . AUTHORS , com . sun . star . beans . PropertyAttribute . REMOVABLE , allAuthorsLabel ) ; } catch ( IllegalArgumentException | PropertyExistException | IllegalTypeException e ) { Activator . log . error ( e ) ; } }
/* * * Compare the execution of two state machines doing the same job , the tid * condition is ignored with the initial element and used with the * initialState element . The result should be different . */ @Test public void testInitialStateWithCondition ( ) { ITmfStateSystem stateSystem = fModule . getStateSystem ( fModule . getId ( ) ) ; assertNotNull ( "state system exist" , stateSystem ) ; try { int quark = stateSystem . getQuarkAbsolute ( "fsm1" ) ; @NonNull ITmfStateInterval interval = stateSystem . querySingleState ( END_TIME , quark ) ; long count1 = interval . getStateValue ( ) . unboxLong ( ) ; quark = stateSystem . getQuarkAbsolute ( "fsm2" ) ; interval = stateSystem . querySingleState ( END_TIME , quark ) ; long count2 = interval . getStateValue ( ) . unboxLong ( ) ; assertEquals ( "Test the count value" , count1 , count2 ) ; } catch ( AttributeNotFoundException | StateSystemDisposedException e ) { fail ( "Failed to query the state system" ) ; } } < |startfocus| > < |endfocus| >
if ( ! isPinned ) { // Remove and dispose any previous adorned image Image previouslyAdornedImage = ( Image ) element . getTransientData ( ) . get ( "previouslyAdorned" ) ; // $NON - NLS - 1$ if ( previouslyAdornedImage != null && ! previouslyAdornedImage . isDisposed ( ) ) previouslyAdornedImage . dispose ( ) ; element . getTransientData ( ) . remove ( IPresentationEngine . ADORNMENT_PIN ) ; } else { adornedImage = resUtils . adornImage ( image , pinImage ) ; if ( adornedImage != image ) element . getTransientData ( ) . put ( "previouslyAdorned" , adornedImage ) ; // $NON - NLS - 1$ } < |startfocus| > return adornedImage ; < |endfocus| >
public Image getImage ( MUILabel element ) { < |startfocus| > return getImage ( element , false ) ; < |endfocus| > }
private Image adornImage ( MUIElement element , Image image , boolean imageChanged ) { if ( element . getTags ( ) . contains ( IPresentationEngine . ADORNMENT_PIN ) ) { // Only if Pinned Image previousImage = ( Image ) element . getTransientData ( ) . get ( ADORN_ICON_IMAGE_KEY ) ; boolean exist = previousImage != null && ! previousImage . isDisposed ( ) ; // Cached image exist < |startfocus| > if ( ! exist ) { if ( exist ) { disposeAdornedImage ( element ) ;/ / Need to dispose old image . If image changed } < |endfocus| > Image adornedImage = resUtils . adornImage ( image , pinImage ) ; if ( adornedImage != image ) { element . getTransientData ( ) . put ( ADORN_ICON_IMAGE_KEY , adornedImage ) ; } return adornedImage ; } return previousImage ; } return image ;
< |startfocus| > protected void showTab ( MUIElement tabElement ) { < |endfocus| > MPerspective persp = ( MPerspective ) tabElement ; Control ctrl = ( Control ) persp . getWidget ( ) ; if ( ctrl == null ) { ctrl = ( Control ) renderer . createGui ( persp ) ; } else if ( ctrl . getParent ( ) != persp . getParent ( ) . getWidget ( ) ) { Composite parent = ( Composite ) persp . getParent ( ) . getWidget ( ) ; ctrl . setParent ( parent ) ; } super . showTab ( persp ) ; // relayout the perspective Composite psComp = ctrl . getParent ( ) ; StackLayout sl = ( StackLayout ) psComp . getLayout ( ) ; if ( sl != null ) { sl . topControl = ctrl ; psComp . layout ( ) ; } ctrl . moveAbove ( null ) ; // Force a context switch IEclipseContext context = persp . getContext ( ) ; context . get ( EPartService . class ) . switchPerspective ( persp ) ; // Move any other controls to 'limbo' Control [ ] kids = psComp . getChildren ( ) ; Shell limbo = ( Shell ) context . get ( "limbo" ) ; // $NON - NLS - 1$ for ( Control child : kids ) { if ( child != ctrl ) {
private boolean loadMappingsFromOldWorkspace ( Map < String , Integer > map ) { // File name of the persisted file type information String STATE_FILE = " . fileTypes" ; // $NON - NLS - 1$ IPath pluginStateLocation = TeamPlugin . getPlugin ( ) . getStateLocation ( ) . append ( STATE_FILE ) ; File f = pluginStateLocation . toFile ( ) ; if ( ! f . exists ( ) ) return false ; < |startfocus| > try ( DataInputStream input = new DataInputStream ( new FileInputStream ( f ) ) ) { map . putAll ( readOldFormatExtensionMappings ( input ) ) ; } catch ( IOException ex ) { TeamPlugin . log ( IStatus . ERROR , ex . getMessage ( ) , ex ) ; return false ; } < |endfocus| > f . delete ( ) ; return true ;
} return bytes ; } /* * * Converts an hex string ( in format "0123456789ABCDEF" ) into a byte array * * @param hexString the hex string * @return the corresponding byte array */ public static byte [ ] hexToBytes ( String hexString ) { return hexToBytes ( hexString , " ( ? <= \\G . { 2 } ) " ) ; } /* * * Convert an upper case hex character to a byte * * @param character an upper case hex character * @return the byte value of the character * @throws IllegalArgumentException if a value is found which is not an upper case hex character */ private static byte hexCharacterToBin ( char character ) { if ( '0' <= character && character <= '9' ) { return ( byte ) ( character - ASCII_DIGITS_START_POSITION ) ; } else if ( 'A' <= character && character <= 'F' ) { return ( byte ) ( character - ASCII_UPPERCASE_LETTERS_START_POSITION + 10 ) ; } else {
public TableUserFilterManager getUserFilterManager ( ) { return ( TableUserFilterManager ) propertySupport . getProperty ( PROP_USER_FILTER_MANAGER ) ; } @Override public void setUserFilterManager ( TableUserFilterManager m ) { propertySupport . setProperty ( PROP_USER_FILTER_MANAGER , m ) ; } @Override public ITableCustomizer getTableCustomizer ( ) { return ( ITableCustomizer ) propertySupport . getProperty ( PROP_TABLE_CUSTOMIZER ) ; } @Override public void setTableCustomizer ( ITableCustomizer c ) { propertySupport . setProperty ( PROP_TABLE_CUSTOMIZER , c ) ; } @Override < |startfocus| > public IPage < ? > getParentPage ( ) { return ( IPage < ? > ) propertySupport . getProperty ( PROP_PARENT_PAGE ) ; } @Override < |endfocus| > public ITypeWithClassId getContainer ( ) { IWidget parentWidget = getParent ( ) ; if ( parentWidget != null ) { return parentWidget ; } return getParentPage ( ) ; } /* * * do not use this internal method */ public void setParentPageInternal ( IPage < ? > container ) { propertySupport . setProperty ( PROP_PARENT_PAGE , container ) ; } @Override public boolean isSortEnabled ( ) { return propertySupport . getPropertyBool ( PROP_SORT_ENABLED ) ; } @Override
* drop can be aborted if appropriate . * * This class is not intended to be subclassed . * * @since 3 . 2 */ public class LocalSelectionTransfer extends ByteArrayTransfer { // First attempt to create a UUID for the type name to make sure that // different Eclipse applications use different "types" of // < code > LocalSelectionTransfer </ code > < |startfocus| > private static final String TYPE_NAME = "local - selection - transfer - format" + System . currentTimeMillis ( ) ; // $NON - NLS - 1$ ; < |endfocus| > private static final int TYPEID = registerType ( TYPE_NAME ) ; private static final LocalSelectionTransfer INSTANCE = new LocalSelectionTransfer ( ) ; private ISelection selection ; private long selectionSetTime ; /* * * Only the singleton instance of this class may be used . */ protected LocalSelectionTransfer ( ) { // do nothing } /* * * Returns the singleton . * * @return the singleton */ public static LocalSelectionTransfer getTransfer ( ) { return INSTANCE ; } /* * * Returns the local transfer data . *
private String convertToEditableTimeInterval ( String string ) { if ( string . length ( ) == 0 ) return string ; long value ; try { value = Long . parseLong ( string ) ; } catch ( NumberFormatException e ) { value = 0 ; } if ( value == 0 ) return Long . toString ( 0 ) ; for ( int i = 0 ; i < timeIntervalPrefixes . length - 1 ; i ++ ) { if ( value % timeIntervalScale [ i ] != 0 ) < |startfocus| > return value + timeIntervalPrefixes [ i ] ; < |endfocus| > value /= timeIntervalScale [ i ] ; } return value + timeIntervalPrefixes [ timeIntervalPrefixes . length - 1 ] ; } private String convertFromEditableTimeInterval ( String string ) { if ( string . length ( ) == 0 ) return string ; for ( int i = 1 ; i < timeIntervalPrefixes . length ; i ++ ) { if ( string . endsWith ( timeIntervalPrefixes [ i ] ) ) { long value = Long . parseLong ( string . substring ( 0 , string . length ( ) - 1 ) ) ; for ( int j = 0 ; j < i ; j ++ ) value *= timeIntervalScale [ j ] ; return Long . toString ( value ) ; } }
public String toString ( ) { String rv = "Item " ; < |startfocus| > if ( parent != null ) { rv = parent + " . " ; < |endfocus| > } rv += counter ; return rv ;
produce = false ; else { if ( filter . requiresCommitBody ( ) ) c . parseBody ( walker ) ; produce = filter . include ( walker , c ) ; } for ( int i = 0 ; i < c . parents . length ; i ++ ) { RevCommit p = c . parents [ i ] ; if ( ( p . flags & SEEN ) != 0 ) continue ; if ( ( p . flags & PARSED ) == 0 ) p . parseHeaders ( walker ) ; p . flags | = SEEN ; < |startfocus| > if ( firstParent && i > 0 ) { continue ; } < |endfocus| > pending . add ( p ) ; } walker . carryFlagsImpl ( c ) ; if ( ( c . flags & UNINTERESTING ) != 0 ) { if ( pending . everbodyHasFlag ( UNINTERESTING ) ) { final RevCommit n = pending . peek ( ) ; if ( n != null && n . commitTime >= last . commitTime ) { // This is too close to call . The next commit we // would pop is dated after the last one produced . // We have to keep going to ensure that we carry // flags as much as necessary . //
setTypes ( queryResp . getQueryResult ( ) ) ; } catch ( Exception e ) { logger . error ( MessageFormat . format ( Messages . DTL_QueryFailed , "FB Types" ) ) ; // $NON - NLS - 1$ } } @Override public void createFBInstance ( final FBDeploymentData fbData , final Resource res ) throws DeploymentException { // check first if FBType exists Map < String , AdapterType > adapters = getAdapterTypes ( fbData . getFb ( ) . getType ( ) . getInterfaceList ( ) ) ; if ( ! adapters . isEmpty ( ) ) { queryAdapterTypes ( adapters , res ) ; < |startfocus| > createAdapterTypes ( adapters , res ) ; < |endfocus| > } // if the FPType does not exist create it if ( ! getTypes ( ) . contains ( fbData . getFb ( ) . getType ( ) . getName ( ) ) ) { try { createFBType ( fbData . getFb ( ) . getType ( ) , res ) ; } catch ( DeploymentException ce ) { logger . error ( MessageFormat . format ( Messages . DTL_CreateTypeFailed , fbData . getFb ( ) . getType ( ) . getName ( ) ) ) ; } } super . createFBInstance ( fbData , res ) ; } private static Map < String , AdapterType > getAdapterTypes ( InterfaceList interfaceList ) {
RevCommit a = commit ( ) ; RevCommit b1 = commit ( a ) ; RevCommit b2 = commit ( a ) ; RevCommit c1 = commit ( b1 ) ; RevCommit c2 = commit ( b2 ) ; RevCommit d = commit ( c1 , c2 ) ; rw . reset ( ) ; rw . setFirstParent ( true ) ; markStart ( d ) ; assertCommit ( d , rw . next ( ) ) ; assertCommit ( c1 , rw . next ( ) ) ; assertCommit ( b1 , rw . next ( ) ) ; assertCommit ( a , rw . next ( ) ) ; assertNull ( rw . next ( ) ) ; } < |startfocus| > < |endfocus| > @Test public void testSecondParentAncestorOfFirstParent ( ) throws Exception { RevCommit a = commit ( ) ; RevCommit b = commit ( a ) ; RevCommit c = commit ( b , a ) ; rw . reset ( ) ; rw . setFirstParent ( true ) ; markStart ( c ) ; assertCommit ( c , rw . next ( ) ) ; assertCommit ( b , rw . next ( ) ) ; assertCommit ( a , rw . next ( ) ) ; assertNull ( rw . next ( ) ) ; } @Test public void testFirstParentMultipleOccurrences ( ) throws Exception { RevCommit a = commit ( ) ; RevCommit b = commit ( a ) ; RevCommit c = commit ( b ) ;
/* * Output may have { @link RevWalk#REWRITE } marked on it . */ static final int HAS_REWRITE = 1 < < 1 ; /* * Output needs { @link RewriteGenerator } . */ static final int NEEDS_REWRITE = 1 < < 2 ; /* * Topological ordering is enforced ( all children before parents ) . */ static final int SORT_TOPO = 1 < < 3 ; /* * Output may have { @link RevWalk#UNINTERESTING } marked on it . */ static final int HAS_UNINTERESTING = 1 < < 4 ; < |startfocus| > protected final boolean firstParent ; < |endfocus| > protected Generator ( boolean firstParent ) { this . firstParent = firstParent ; } /* * * Connect the supplied queue to this generator's own free list ( if any ) . * * @param q * another FIFO queue that wants to share our queue's free list . */ void shareFreeList ( BlockRevQueue q ) { // Do nothing by default . } /* * * Obtain flags describing the output behavior of this generator . *
} } return list ; } /* * * Remove a data provider from the instances * * @param < T > * The type of data provider * @param trace * The trace for which to remove the data provider * @param provider * The data provider to remove * @since 5 . 1 */ < |startfocus| > public < T extends ITmfTreeDataProvider < ? extends ITmfTreeDataModel > > void removeDataProvider ( ITmfTrace trace , T provider ) { fInstances . remove ( trace , provider ) ; provider . dispose ( ) ; < |endfocus| > } }
< |startfocus| > private void checkCreateFBType ( FB fb ) { < |endfocus| > // if the FPType does not exist create it if ( ! getTypes ( ) . contains ( fb . getType ( ) . getName ( ) ) ) { try { createFBType ( fb . getType ( ) ) ; } catch ( DeploymentException ce ) { logger . error ( MessageFormat . format ( Messages . DTL_CreateTypeFailed , fb . getType ( ) . getName ( ) ) ) ; } }
// if the FPType does not exist create it if ( ! getTypes ( ) . contains ( fb . getType ( ) . getName ( ) ) ) { try { createFBType ( fb . getType ( ) , res ) ; } catch ( DeploymentException ce ) { logger . error ( MessageFormat . format ( Messages . DTL_CreateTypeFailed , fb . getType ( ) . getName ( ) ) ) ; } } } < |startfocus| > public void createFBType ( final FBType fbType ) throws DeploymentException { setAttribute ( getDevice ( ) , "FBType" , getTypes ( ) ) ; // $NON - NLS - 1$ < |endfocus| > if ( fbType instanceof BasicFBType || fbType instanceof CompositeFBType ) { if ( fbType instanceof CompositeFBType ) { createFBTypesOfCFB ( fbType ) ; } String request = createLuaRequestMessage ( fbType ) ; sendCreateFBTypeREQ ( fbType , request ) ; } } private void sendCreateFBTypeREQ ( final FBType fbType , String request ) throws DeploymentException { try { String result = sendREQ ( "" , request ) ; // $NON - NLS - 1$ if ( result . contains ( "Reason" ) ) { // $NON - NLS - 1$
addLocalDeclarationSplit ( rewrite ) ; else addLocalDeclarationRemoval ( rewrite ) ; if ( fInitializeIn == INITIALIZE_IN_CONSTRUCTOR ) addInitializersToConstructors ( rewrite ) ; addTempRenames ( rewrite ) ; addFieldDeclaration ( rewrite ) ; CompilationUnitChange result = new CompilationUnitChange ( RefactoringCoreMessages . PromoteTempToFieldRefactoring_name , fCu ) ; result . setDescriptor ( new RefactoringChangeDescriptor ( getRefactoringDescriptor ( ) ) ) ; TextEdit resultingEdits ; < |startfocus| > Map < String , String > formatter = ( this . fFormatterOptions == null ) ? fCu . getJavaProject ( ) . getOptions ( true ) : this . fFormatterOptions ; try { resultingEdits = rewrite . rewriteAST ( new Document ( fCu . getSource ( ) ) , formatter ) ; } catch ( JavaModelException e ) { resultingEdits = rewrite . rewriteAST ( ) ; } < |endfocus| > TextChangeCompatibility . addTextEdit ( result , RefactoringCoreMessages . PromoteTempToFieldRefactoring_editName , resultingEdits ) ; return result ; } finally { pm . done ( ) ; } } private void addTempRenames ( ASTRewrite rewrite ) { boolean noNameChange = fFieldName . equals ( fTempDeclarationNode . getName ( ) . getIdentifier ( ) ) ; if ( fLinkedProposalModel == null && noNameChange ) { return ; // no changes needed }
addInitializersToConstructors ( rewrite ) ; addTempRenames ( rewrite ) ; addFieldDeclaration ( rewrite ) ; CompilationUnitChange result = new CompilationUnitChange ( RefactoringCoreMessages . PromoteTempToFieldRefactoring_name , fCu ) ; result . setDescriptor ( new RefactoringChangeDescriptor ( getRefactoringDescriptor ( ) ) ) ; TextEdit resultingEdits ; Map < String , String > formatter = ( this . fFormatterOptions == null ) ? fCu . getJavaProject ( ) . getOptions ( true ) : this . fFormatterOptions ; try { resultingEdits = rewrite . rewriteAST ( new Document ( fCu . getSource ( ) ) , formatter ) ; } catch ( JavaModelException e ) { resultingEdits = rewrite . rewriteAST ( ) ; } TextChangeCompatibility . addTextEdit ( result , RefactoringCoreMessages . PromoteTempToFieldRefactoring_editName , resultingEdits ) ; return result ; } finally { pm . done ( ) ; } } private void addTempRenames ( ASTRewrite rewrite ) { boolean noNameChange = fFieldName . equals ( fTempDeclarationNode . getName ( ) . getIdentifier ( ) ) ; if ( fLinkedProposalModel == null && noNameChange ) { return ; // no changes needed } TempOccurrenceAnalyzer analyzer = new TempOccurrenceAnalyzer ( fTempDeclarationNode , false ) ; analyzer . perform ( ) ;
* < code > ILabelProvider </ code > . If it is an * < code > ITableLabelProvider </ code > , then it provides a separate label * text and image for each column . If it is an < code > ILabelProvider </ code > , * then it provides only the label text and image for the first column , and * any remaining columns are blank . */ @Override public IBaseLabelProvider getLabelProvider ( ) { return super . getLabelProvider ( ) ; } < |startfocus| > @SuppressWarnings ( "rawtypes" ) < |endfocus| > @Override protected List getSelectionFromWidget ( ) { if ( virtualManager != null ) { return getVirtualSelection ( ) ; } Widget [ ] items = doGetSelection ( ) ; List < Object > list = new ArrayList < > ( items . length ) ; for ( Widget item : items ) { Object e = item . getData ( ) ; if ( e != null ) { list . add ( e ) ; } } return list ; } /* * * Get the virtual selection . Avoid calling SWT whenever possible to prevent * extra widget creation . * * @return List of Object */
Policy . getLog ( ) . log ( new Status ( IStatus . WARNING , Policy . JFACE , message , new RuntimeException ( ) ) ) ; return ; } } } } /* * * Returns all selected items for the given SWT control . * * @param control * the control * @return the list of selected items */ protected abstract Item [ ] getSelection ( Control control ) ; < |startfocus| > @SuppressWarnings ( "rawtypes" ) < |endfocus| > @Override protected List getSelectionFromWidget ( ) { Widget [ ] items = getSelection ( getControl ( ) ) ; List < Object > list = new ArrayList < > ( items . length ) ; for ( Widget item : items ) { Object e = item . getData ( ) ; if ( e != null ) { list . add ( e ) ; } } return list ; } /* * Overridden in AbstractTreeViewer to fix bug 108102 ( code copied from * StructuredViewer to avoid introducing new API ) */ @Override protected void handleDoubleSelect ( SelectionEvent event ) { // handle case where an earlier selection listener disposed the control . Control control = getControl ( ) ;
protected void setSelectionToWidget ( ISelection selection , boolean reveal ) { if ( selection instanceof ITreeSelection ) { ITreeSelection treeSelection = ( ITreeSelection ) selection ; < |startfocus| > setSelectionToWidget ( Arrays . asList ( treeSelection . getPaths ( ) ) , reveal ) ; < |endfocus| > } else { super . setSelectionToWidget ( selection , reveal ) ; }
* are made available under the terms of the Eclipse Public License 2 . 0 * which accompanies this distribution , and is available at * https :/ / www . eclipse . org / legal / epl - 2 . 0 / * * SPDX - License - Identifier : EPL - 2 . 0 * * Contributors : < |startfocus| > * IBM Corporation - initial API and implementation * Oakland Software ( Francis Upton - francisu@ieee . org ) * bug 197113 Project Explorer drag and drop selection not working properly * Alexander Fedorov < alexander . fedorov@arsysop . ru > - Bug 548314 < |endfocus| > ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . ui . navigator ; import java . util . ArrayList ; import java . util . Iterator ; import java . util . List ; import org . eclipse . jface . viewers . IBaseLabelProvider ; import org . eclipse . jface . viewers . ISelection ; import org . eclipse . jface . viewers . IStructuredSelection ; import org . eclipse . jface . viewers . LabelProviderChangedEvent ; import org . eclipse . jface . viewers . StructuredSelection ; import org . eclipse . jface . viewers . TreeViewer ; import org . eclipse . jface . viewers . ViewerSorter ; import org . eclipse . swt . dnd . DND ; import org . eclipse . swt . events . DisposeEvent ; import org . eclipse . swt . events . MouseAdapter ; import org . eclipse . swt . events . MouseEvent ;
< |startfocus| > private void checkCreateFBType ( FB fb ) { < |endfocus| > // if the FBType does not exist create it if ( ! getTypes ( ) . contains ( fb . getType ( ) . getName ( ) ) ) { try { createFBType ( fb . getType ( ) ) ; } catch ( DeploymentException ce ) { logger . error ( MessageFormat . format ( Messages . DTL_CreateTypeFailed , fb . getType ( ) . getName ( ) ) ) ; } }
private static List < IProject > getSelectedProjects ( ISelection selection ) { List < IProject > projectSelection = new ArrayList < > ( ) ; if ( selection instanceof IStructuredSelection ) { for ( Object element : ( ( StructuredSelection ) selection ) . toList ( ) ) { if ( element instanceof AutomationSystem ) { < |startfocus| > projectSelection . add ( ( ( AutomationSystem ) element ) . getProject ( ) ) ; < |endfocus| > } } } return projectSelection ;
public void reveal ( ) { < |startfocus| > resolved . ifPresent ( RevealStep : : reveal ) ; < |endfocus| >
< |startfocus| > private static Collection < LSBasedHyperlink > collectHyperlinks ( final IDocument document , final IRegion linkRegion , Either < List < ? extends Location > , List < ? extends LocationLink > > locations ) { < |endfocus| > if ( locations == null ) { return Collections . emptyList ( ) ; } else if ( locations . isLeft ( ) ) { return locations . getLeft ( ) . stream ( ) . filter ( Objects : : nonNull ) . map ( location - > new LSBasedHyperlink ( location , linkRegion ) ) . collect ( Collectors . toList ( ) ) ; } else { return locations . getRight ( ) . stream ( ) . filter ( Objects : : nonNull ) . map ( locationLink - > { IRegion selectionRegion = linkRegion ; Range originSelectionRange = locationLink . getOriginSelectionRange ( ) ; if ( originSelectionRange != null ) { try { int offset = LSPEclipseUtils . toOffset ( originSelectionRange . getStart ( ) , document ) ; int endOffset = LSPEclipseUtils . toOffset ( originSelectionRange . getEnd ( ) , document ) ; selectionRegion = new Region ( offset , endOffset - offset ) ; } catch ( BadLocationException e ) { LanguageServerPlugin . logError ( e . getMessage ( ) , e ) ; } }
protected void addChildVisual ( final EditPart childEditPart , final int index ) { boolean visible = true ; if ( childEditPart instanceof InterfaceEditPart ) { IInterfaceElement iElement = ( ( InterfaceEditPart ) childEditPart ) . getModel ( ) ; if ( iElement instanceof AdapterDeclaration ) { // if we are in a subapptype we want to show the adapter as type interface element visible = isVarVisible ( ) ; } } EditPart refEditPart = null ; < |startfocus| > if ( index < getChildren ( ) . size ( ) ) { refEditPart = ( EditPart ) getChildren ( ) . get ( index ) ; } < |endfocus| > if ( childEditPart instanceof InterfaceEditPart ) { IFigure child = ( ( GraphicalEditPart ) childEditPart ) . getFigure ( ) ; if ( ( ( InterfaceEditPart ) childEditPart ) . getModel ( ) . isIsInput ( ) ) { if ( ( ( InterfaceEditPart ) childEditPart ) . isEvent ( ) ) { insertChild ( getLeftEventInterfaceContainer ( ) , refEditPart , child ) ; } else { if ( visible ) { // add adapter interface elemetns directly to the container and set them to visible = false insertChild ( getLeftVarInterfaceContainer ( ) , refEditPart , child ) ;
protected void removeChildVisual ( final EditPart childEditPart ) { boolean visible = true ; if ( childEditPart . getModel ( ) instanceof AdapterDeclaration ) { visible = isVarVisible ( ) ; < |startfocus| > } < |endfocus| > if ( childEditPart instanceof InterfaceEditPart ) { if ( ( ( InterfaceEditPart ) childEditPart ) . getModel ( ) . isIsInput ( ) ) { IFigure child = ( ( GraphicalEditPart ) childEditPart ) . getFigure ( ) ; if ( ( ( InterfaceEditPart ) childEditPart ) . isEvent ( ) ) { getLeftEventInterfaceContainer ( ) . remove ( child ) ; } else { if ( visible ) { getLeftVarInterfaceContainer ( ) . remove ( child ) ; } else { getLeftInterfaceContainer ( ) . remove ( child ) ; } } } else { IFigure child = ( ( GraphicalEditPart ) childEditPart ) . getFigure ( ) ; if ( ( ( InterfaceEditPart ) childEditPart ) . isEvent ( ) ) { getRightEventInterfaceContainer ( ) . remove ( child ) ; } else { if ( visible ) { getRightVarInterfaceContainer ( ) . remove ( child ) ; } else { getRightInterfaceContainer ( ) . remove ( child ) ; } } } } else { super . removeChildVisual ( childEditPart ) ; } }
import org . eclipse . emf . ecore . EObject ; import org . eclipse . emf . ecore . EStructuralFeature ; import org . eclipse . emf . ecore . InternalEObject ; import org . eclipse . emf . ecore . resource . Resource ; import com . google . common . base . Objects ; /* * * An helper to check EObject equality . </ br > * It extends and override EcoreUtil . EqualityHelper so that equals methods ignore EAttribute that are ID = true . * * @author mchauvin */ public final class EqualityHelper extends org . eclipse . emf . ecore . util . EcoreUtil . EqualityHelper { < |startfocus| > private static boolean enableUriFragmentCache = false ; < |endfocus| > private static final Map < EObject , String > eUriFragmentCache = new HashMap < > ( ) ; private static final Map < EObject , EObject > eUriFragmentContainerCache = new HashMap < > ( ) ; private static final Map < EObject , EStructuralFeature > eUriFragmentContainingFeatureCache = new HashMap < > ( ) ; @Override protected boolean haveEqualAttribute ( EObject eObject1 , EObject eObject2 , EAttribute attribute ) { boolean isID = attribute . isID ( ) ; return isID || super . haveEqualAttribute ( eObject1 , eObject2 , attribute ) ; } /* *
} /* * * Check if a diagram element is in an activated layer or not and visible . * * @param session * the current session . * @param element * the diagram element . * @param parentDiagram * the parent diagram of the diagram element . This information can be retrieved from the diagram element < |startfocus| > * but sometimes it is already known by the caller or it can be null ( during drag'n'drop of element with < |endfocus| > * bordered nodes for example : PortLocationAfterDragAndDropTest . * testPortLocationFromParentDnDFromModelExplorerView ( ) ) this method is called before setting all parents * hierarchy of diagram element . * @return < code > true </ code > if it is , < code > false </ code > otherwise */ public static boolean isInActivatedLayer ( DiagramMappingsManager session , final DDiagramElement element , final DDiagram parentDiagram ) { final DiagramElementMapping mapping = element . getDiagramElementMapping ( ) ; if ( ! LayerHelper . withoutLayersMode ( mapping ) ) { final DDiagram diagram ; if ( parentDiagram != null ) { diagram = parentDiagram ;
*/ boolean reveal ( EObject object , EStructuralFeature feature ) ; /* * * Attempt to reveal an { @code object } in the most appropriate ( by best effort ) * control within the given { @code scope } . * * @param object an object to reveal * @param scope a control within which to attempt to reveal the { @code object } * < |startfocus| > * @return { @code true } if the { @code object } was revealed ; { @code false } , otherwise < |endfocus| > */ RevealStep reveal ( EObject object , VElement scope ) ; /* * * Attempt to reveal a { @code feature } of an { @code object } in the most appropriate * ( by best effort ) control within the given { @code scope } . * * @param object an object to reveal * @param feature a specific feature ( implying a detail control ) to reveal * @param scope a control within which to attempt to reveal the { @code object } * < |startfocus| > * @return { @code true } if the { @code object } was revealed ; { @code false } , otherwise < |endfocus| > */ boolean reveal ( EObject object , EStructuralFeature feature , VElement scope ) ; /* * * Attempt to reveal an { @code object } in the most appropriate ( by best effort ) * control within the given { @code scope } . * * @param object an object to reveal * @param scope a control within which to attempt to reveal the { @code object } *
/* * * Attempt to reveal a { @code feature } of an { @code object } in the most appropriate * ( by best effort ) control within the given { @code scope } . * * @param object an object to reveal * @param feature a specific feature ( implying a detail control ) to reveal * @param scope a control within which to attempt to reveal the { @code object } * < |startfocus| > * @return { @code true } if the { @code object } was revealed ; { @code false } , otherwise < |endfocus| > */ RevealStep reveal ( EObject object , EStructuralFeature feature , VElement scope ) ; /* * * Register a reveal provider . * * @param provider the reveal provider to register */ void addRevealProvider ( EMFFormsRevealProvider provider ) ; /* * * Unregister a reveal provider . * * @param provider the reveal provider to unregister */ void removeRevealProvider ( EMFFormsRevealProvider provider ) ; }
public int getRed ( ) { < |startfocus| > if ( isDisposed ( ) ) SWT . error ( SWT . ERROR_GRAPHIC_DISPOSED ) ; < |endfocus| > int r = ( ( ( int ) ( handle . red * 65535 . 0 + 0 . 5 ) ) > > 8 ) ; return Math . min ( r , 255 ) ; }
public int getBlue ( ) { < |startfocus| > if ( isDisposed ( ) ) SWT . error ( SWT . ERROR_GRAPHIC_DISPOSED ) ; < |endfocus| > int b = ( ( ( int ) ( handle . blue * 65535 . 0 + 0 . 5 ) ) > > 8 ) ; return Math . min ( b , 255 ) ;
buf . append ( " System . out . println ( list . get ( i ) ) ; \n" ) ; buf . append ( " } \n" ) ; buf . append ( " } \n" ) ; buf . append ( " } \n" ) ; ICompilationUnit cu = pack1 . createCompilationUnit ( "A . java" , buf . toString ( ) , false , null ) ; List < IJavaCompletionProposal > proposals = fetchConvertingProposal ( buf , cu ) ; assertNotNull ( fConvertLoopProposal ) ; String preview1 = getPreviewContent ( fConvertLoopProposal ) ; < |startfocus| > buf = new StringBuilder ( ) ; < |endfocus| > buf . append ( "package test1 ; \n" ) ; buf . append ( "public class A { \n" ) ; buf . append ( " public void foo ( ) { \n" ) ; buf . append ( " java . util . List list = new ArrayList ( ) ; \n" ) ; buf . append ( " list . add ( null ) ; \n" ) ; buf . append ( " for ( Object element : list ) { \n" ) ; buf . append ( " System . out . println ( element ) ; \n" ) ; buf . append ( " } \n" ) ; buf . append ( " } \n" ) ; buf . append ( " } \n" ) ; String expected = buf . toString ( ) ; assertEqualString ( preview1 , expected ) ; assertCorrectLabels ( proposals ) ; assertCorrectLabels ( proposals ) ; }
StaticProfileTest . class , DynamicProfileTest . class , StaticStereotypeTest . class , StaticStereotypedElementChangeTests . class , DynamicStereotypeTest . class , DynamicStereotypedElementChangeTests . class , ImplicationsAssociationTest . class , ImplicationsTransitionTest . class , ImplicationsInterfaceRealizationTest . class , StaticStereotypedElementItemProviderTest . class , DynamicStereotypedElementItemProviderTest . class , OpaqueElementBodyChangeDiffTest . class , OpaqueElementBodyChangeMergeTest . class , DanglingStereotypeApplicationTest . class , TestNonRegPseudoConflict_484576 . class , RemoveStereotypeApplicationPseudoConflictTest . class , MultiplicityElementChangesTest . class , InstanceSpecificationClassifiersMergeTest . class , AddMessageSubDiffTest . class , < |startfocus| > StereotypeApplicationConflictTests . class , < |endfocus| > public class AllTests { /* * * Standalone launcher for all of compare's tests . * * @generated */ public static void main ( String [ ] args ) { TestRunner . run ( suite ( ) ) ; } /* * * This will return a suite populated with all tests available through this class . * * @generated */ public static Test suite ( ) { return new JUnit4TestAdapter ( AllTests . class ) ; } }
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * * Copyright ( c ) 2014 , 2017 Obeo and others . * All rights reserved . This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1 . 0 * which accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html * * Contributors : * Obeo - initial API and implementation * Christian W . Damus - bug 522080 ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . emf . compare . uml2 . internal . postprocessor ; import java . util . Iterator ; import java . util . Map ; import org . eclipse . emf . common . util . Monitor ; import org . eclipse . emf . common . util . URI ; import org . eclipse . emf . compare . Comparison ; import org . eclipse . emf . compare . ComparisonCanceledException ; import org . eclipse . emf . compare . Diff ; import org . eclipse . emf . compare . Match ; import org . eclipse . emf . compare . diff . DefaultDiffEngine ; import org . eclipse . emf . compare . diff . FeatureFilter ; import org . eclipse . emf . compare . postprocessor . IPostProcessor ; import org . eclipse . emf . compare . uml2 . internal . postprocessor . extension . stereotype . UMLStereotypedElementChangeFactory ;
< |startfocus| > private static URI getStereotypeURI ( EObject stereotypeApplication ) { < |endfocus| > return EcoreUtil . getURI ( stereotypeApplication . eClass ( ) ) ;
* the second level key * @param value * the value * @return the previous value for these keys , if or { @code null } if there was none * @param < K > * the top level key type * @param < L > * the second level key type * @param < V > * the value type */ < |startfocus| > static < K , L , V > V put ( Map < K , Map < L , V > > mapOfMaps , K key1 , L key2 , V value ) { < |endfocus| > Map < L , V > map = mapOfMaps . get ( key1 ) ; if ( map == null ) { map = Maps . newHashMap ( ) ; mapOfMaps . put ( key1 , map ) ; } return map . put ( key2 , value ) ; } /* * * Queries whether an { @code object } is a stereotype application . * * @param object * an object * @return { @code true } if it is a stereotype application ; { @code false } , otherwise */ protected boolean isStereotypeApplication ( EObject object ) { < |startfocus| > if ( object instanceof StereotypeApplication ) { return true ; } < |endfocus| > if ( object instanceof EAnnotation ) { EAnnotation eAnnotation = ( EAnnotation ) object ; if ( eAnnotation . getSource ( ) != null && eAnnotation . getSource ( ) . startsWith ( STEREOTYPE_ANNOTATION_SOURCE_PREFIX ) ) { return true ; } } return false ; } /* * * Returns the { @link Stereotype } of a { @link StereotypeApplication } . * * @param stereotypeApplication * a stereotype application * @return the stereotype */ protected Stereotype getStereotype ( StereotypeApplication stereotypeApplication ) {
* http :/ / www . eclipse . org / legal / epl - v10 . html * * Contributors : * Boeing - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . eclipse . ote . simple . oteide . product . load ; import java . io . IOException ; import java . net . URL ; import java . util . ArrayList ; import java . util . List ; import java . util . logging . Level ; import org . eclipse . osee . framework . jdk . core . util . Lib ; import org . eclipse . osee . framework . logging . OseeLog ; import org . eclipse . ote . services . core . BundleUtility ; import org . eclipse . ote . services . core . LoadBundleProvider ; < |startfocus| > < |endfocus| > public class FileProvider implements LoadBundleProvider { @Override public List < String > getBundleSymbolicNames ( ) { List < String > names = new ArrayList < String > ( ) ; try { URL entry = BundleUtility . findEntry ( "org . eclipse . ote . simple . oteide . product . load" , "data / precompiledServerBundleList . txt" ) ; String fileContent = Lib . inputStreamToString ( entry . openStream ( ) ) ; String [ ] strNames = fileContent . split ( "\n" ) ; for ( int i = 0 ; i < strNames . length ; i ++ ) {
import java . util . Dictionary ; import java . util . logging . Level ; import java . util . regex . Matcher ; import java . util . regex . Pattern ; import org . eclipse . core . runtime . Platform ; import org . eclipse . core . runtime . preferences . IEclipsePreferences ; import org . eclipse . core . runtime . preferences . InstanceScope ; import org . eclipse . osee . framework . logging . OseeLog ; import org . eclipse . ote . services . core . ServiceUtility ; import org . eclipse . swt . widgets . Display ; import org . eclipse . ui . IStartup ; import org . osgi . framework . Bundle ; import org . osgi . framework . BundleEvent ; import org . osgi . framework . BundleListener ; < |startfocus| > < |endfocus| > public class SetTitleBar implements IStartup { @Override public void earlyStartup ( ) { String title = getTitle ( ) ; if ( title != null ) { setTitle ( title ) ; } else if ( ServiceUtility . getContext ( ) != null ) { ServiceUtility . getContext ( ) . addBundleListener ( new BundleListener ( ) { @Override public void bundleChanged ( BundleEvent event ) { if ( event . getType ( ) == Bundle . ACTIVE ) { if ( event . getBundle ( ) . getSymbolicName ( ) . equals ( "bundle . to . base . off . here" ) ) { String t = getTitle ( ) ; if ( t != null ) { setTitle ( t ) ; } } } } } ) ; } } private String getTitle ( ) { String title = null ; try { IEclipsePreferences prefs = InstanceScope . INSTANCE . getNode ( "org . eclipse . ui . workbench" ) ; title = prefs . get ( "windowTitle" , null ) ; } catch ( Exception ex ) { OseeLog . log ( Activator . class , Level . SEVERE , ex ) ; } return title ; } private void setTitle ( final String title ) { Display . getDefault ( ) . asyncExec ( new Runnable ( ) { @Override public void run ( ) { Pattern pattern = Pattern . compile ( "\\$\\ { ( .* ? ) \\ } " ) ; Matcher matcher = pattern . matcher ( title ) ; StringBuffer sb = new StringBuffer ( ) ; while ( matcher . find ( ) ) { String key = matcher . group ( 1 ) ; String value = Platform . getResourceString ( Platform . getBundle ( key ) , "" ) ; matcher . appendReplacement ( sb , value ) ; } matcher . appendTail ( sb ) ; Display . getDefault ( ) . getActiveShell ( ) . setText ( sb . toString ( ) ) ; } } ) ; } }
import java . io . File ; import org . eclipse . core . resources . ResourcesPlugin ; import org . eclipse . jface . action . Action ; import org . eclipse . jface . action . IContributionItem ; import org . eclipse . swt . program . Program ; import org . eclipse . swt . widgets . Display ; import org . eclipse . ui . IPartListener ; import org . eclipse . ui . IViewPart ; import org . eclipse . ui . IViewReference ; import org . eclipse . ui . IWorkbenchPage ; import org . eclipse . ui . IWorkbenchPart ; import org . eclipse . ui . IWorkbenchWindow ; import org . eclipse . ui . PlatformUI ; import org . eclipse . ui . part . ViewPart ; import org . eclipse . ui . texteditor . StatusLineContributionItem ; < |startfocus| > < |endfocus| > public class WorkspaceStatusLineContributionItem { private static String ID = "org . eclipse . ote . simple . oteide . product . load" ; private String shortText ; private StatusLineContributionItem item ; private String path ; public WorkspaceStatusLineContributionItem ( ) { path = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) . getLocation ( ) . toString ( ) ; shortText = getShortPath ( path ) ; item = new StatusLineContributionItem ( ID , true , shortText . length ( ) ) ; } private static String getShortPath ( String path ) {
} } else { uriFragment = container . eURIFragmentSegment ( eContainingFeature , eObj ) ; } return uriFragment ; } private static boolean sameType ( EObject eObj1 , EObject eObj2 ) { return eObj1 != null && eObj2 != null && eObj1 . getClass ( ) == eObj2 . getClass ( ) ; } /* * < |startfocus| > * Enable or disable the ability to cache the computed values . The cache is cleared when this method is called to < |endfocus| > * disable the cache . * * @param enable * < code > true </ code > to allow this helper to put the computed values in a cache , < code > false </ code > * otherwise . */ public static synchronized void setUriFragmentCacheEnabled ( boolean enable ) { enableUriFragmentCache = enable ; if ( ! enable ) { E_URI_FRAGMENT_CACHE . clear ( ) ; } } private static class Record { private final String uriFragment ; private final EObject eContainer ; private final EStructuralFeature containingFeature ; Record ( String uriFragment , EObject container , EStructuralFeature containingFeature ) { this . uriFragment = uriFragment ;
* return BEANS . get ( ApiDocGenerator . class ) . getWebContent ( staticResource ) ; * } * </ pre > */ @ApplicationScoped public class ApiDocGenerator { /* * * Query parameter for static resource file names . This is used by HTML content generated by * { @link #getWebContent ( String ) } . */ public static final String STATIC_RESOURCE_PARAM = "r" ; protected static final String TEXT_ELEMENT_SEPARATOR = "\t" ; < |startfocus| > protected static final String TEXT_LINE_SEPARATOR = "\n" ; < |endfocus| > public List < ResourceDescriptor > getResourceDescriptors ( ) { return BEANS . all ( IRestResource . class ) . stream ( ) . filter ( this : : acceptRestResource ) . sorted ( Comparator . comparing ( res - > res . getClass ( ) . getSimpleName ( ) ) ) . sorted ( Comparator . comparing ( res - > " / " + getPath ( res ) ) ) . map ( this : : toResourceDescriptor ) . filter ( Objects : : nonNull ) . collect ( Collectors . toList ( ) ) ; } protected ResourceDescriptor toResourceDescriptor ( IRestResource resource ) { String resourcePath = " / " + getPath ( resource ) ;
import org . eclipse . scout . rt . shared . AbstractIcons ; import org . eclipse . scout . rt . shared . data . basic . FontSpec ; import org . eclipse . scout . rt . shared . services . lookup . ILookupCall ; import org . eclipse . scout . rt . shared . services . lookup . ILookupRow ; import org . eclipse . scout . rt . shared . services . lookup . LocalLookupCall ; import org . eclipse . scout . rt . shared . services . lookup . LookupRow ; @ClassId ( "c6ee18fd - e630 - 4d92 - 81b1 - cd0147c902d4" ) public class DefaultTileTableHeaderBox extends AbstractGroupBox implements ITileTableHeaderBox { < |startfocus| > private TableListener m_tableListener ; private boolean m_isGrouping ; private boolean m_isSorting ; < |endfocus| > protected TableListener createTableListener ( ) { return new TableAdapter ( ) { @Override public void tableChanged ( TableEvent e ) { switch ( e . getType ( ) ) { case TableEvent . TYPE_COLUMN_HEADERS_UPDATED : syncSortingGroupingFields ( ) ; break ; } } } ; } protected void syncSortingGroupingFields ( ) { try { // don't call execChangedValue since it would trigger sort / group again getSortByField ( ) . setValueChangeTriggerEnabled ( false ) ;
protected void execChangedValue ( ) { try { m_isGrouping = true ; if ( getValue ( ) == null ) { getTable ( ) . getColumnSet ( ) . removeGroupColumn ( CollectionUtility . firstElement ( getTable ( ) . getColumnSet ( ) . getGroupedColumns ( ) ) ) ; } else { getTable ( ) . getColumnSet ( ) . handleGroupingEvent ( getValue ( ) , false , true ) ; } < |startfocus| > ClientUIPreferences . getInstance ( ) . setAllTableColumnPreferences ( getTable ( ) ) ; getTable ( ) . sort ( ) ; < |endfocus| > } finally { m_isGrouping = false ; }
protected void execChangedValue ( ) { try { m_isSorting = true ; if ( getValue ( ) == null ) { getTable ( ) . getColumnSet ( ) . removeSortColumn ( CollectionUtility . firstElement ( getTable ( ) . getColumnSet ( ) . getSortColumns ( ) ) ) ; < |startfocus| > ClientUIPreferences . getInstance ( ) . setAllTableColumnPreferences ( getTable ( ) ) ; getTable ( ) . sort ( ) ; < |endfocus| > } else { getTable ( ) . getColumnSet ( ) . handleSortEvent ( getValue ( ) . getLeft ( ) , false , getValue ( ) . getRight ( ) ) ; ClientUIPreferences . getInstance ( ) . setAllTableColumnPreferences ( getTable ( ) ) ; getTable ( ) . sort ( ) ; } } finally { m_isSorting = false ; } }
* BSI Business Systems Integration AG - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** / package org . eclipse . scout . rt . rest . error ; import javax . ws . rs . core . MediaType ; import javax . ws . rs . core . Response ; import javax . ws . rs . core . Response . Status ; import org . eclipse . scout . rt . platform . BEANS ; import org . eclipse . scout . rt . platform . Bean ; import org . eclipse . scout . rt . platform . context . CorrelationId ; /* * * Builder for { @link ErrorDo } and { @link ErrorResponse } objects . */ @Bean public class ErrorResponseBuilder { < |startfocus| > private int m_httpStatus ; private String m_code ; < |endfocus| > private String m_title ; private String m_message ; public ErrorResponseBuilder withStatus ( int status ) { m_httpStatus = status ; return this ; } public ErrorResponseBuilder withStatus ( Status status ) { m_httpStatus = status . getStatusCode ( ) ; return this ; } public ErrorResponseBuilder withTitle ( String title ) { m_title = title ; return this ; } public ErrorResponseBuilder withMessage ( String message ) { m_message = message ; return this ; } public ErrorResponseBuilder withCode ( int code ) {
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** / package org . eclipse . scout . rt . rest . error ; import javax . ws . rs . core . MediaType ; import javax . ws . rs . core . Response ; import javax . ws . rs . core . Response . Status ; import org . eclipse . scout . rt . platform . BEANS ; import org . eclipse . scout . rt . platform . Bean ; import org . eclipse . scout . rt . platform . context . CorrelationId ; /* * * Builder for { @link ErrorDo } and { @link ErrorResponse } objects . */ @Bean public class ErrorResponseBuilder { < |startfocus| > private int m_status ; private String m_errorCode ; < |endfocus| > private String m_title ; private String m_message ; public ErrorResponseBuilder withStatus ( int status ) { m_status = status ; return this ; } public ErrorResponseBuilder withStatus ( Status status ) { m_status = status . getStatusCode ( ) ; return this ; } public ErrorResponseBuilder withTitle ( String title ) { m_title = title ; return this ; } public ErrorResponseBuilder withMessage ( String message ) { m_message = message ; return this ; } public ErrorResponseBuilder withCode ( int code ) { m_errorCode = String . valueOf ( code ) ; return this ; }
< |startfocus| > public ErrorResponseBuilder withHttpStatus ( int status ) { m_status = status ; < |endfocus| > return this ;
< |startfocus| > public ErrorResponseBuilder withErrorCode ( int code ) { m_code = String . valueOf ( code ) ; < |endfocus| > return this ;
< |startfocus| > public ErrorResponseBuilder withErrorCode ( String code ) { m_code = code ; < |endfocus| > return this ;
@Override public Object execute ( ExecutionEvent event ) throws ExecutionException { Shell activeShell = HandlerUtil . getActiveShell ( event ) ; Object newNameValue = HandlerUtil . getVariable ( event , LTK_RENAME_COMMAND_NEWNAME_PARAMETER_KEY ) ; String newName = null ; if ( newNameValue instanceof String ) { newName = ( String ) newNameValue ; < |startfocus| > } else { RefactoringUIPlugin . logErrorMessage ( RefactoringUIMessages . RenameResourceHandler_newName_error ) ; < |endfocus| > } ISelection sel = HandlerUtil . getCurrentSelection ( event ) ; if ( sel instanceof IStructuredSelection ) { IResource resource = getCurrentResource ( ( IStructuredSelection ) sel ) ; if ( resource != null ) { RenameResourceWizard refactoringWizard ; if ( newName != null ) { refactoringWizard = new RenameResourceWizard ( resource , newName ) ; } else { refactoringWizard = new RenameResourceWizard ( resource ) ; } RefactoringWizardOpenOperation op = new RefactoringWizardOpenOperation ( refactoringWizard ) ; try { op . run ( activeShell , RefactoringUIMessages . RenameResourceHandler_title ) ; } catch ( InterruptedException e ) { // do nothing } } } return null ; }
protected void addUserInputPages ( ) { 	 RenameResourceProcessor processor = getRefactoring ( ) . getAdapter ( RenameResourceProcessor . class ) ; 	 < |startfocus| > 	 RenameResourceRefactoringConfigurationPage page = new RenameResourceRefactoringConfigurationPage ( processor ) ; 	 addPage ( page ) ; 	 < |endfocus| > }
@Override public Object execute ( ExecutionEvent event ) throws ExecutionException { Shell activeShell = HandlerUtil . getActiveShell ( event ) ; Object newNameValue = HandlerUtil . getVariable ( event , LTK_RENAME_COMMAND_NEWNAME_PARAMETER_KEY ) ; String newName = null ; if ( newNameValue instanceof String ) { newName = ( String ) newNameValue ; } else if ( newNameValue != null ) { < |startfocus| > RefactoringUIPlugin . logErrorMessage ( RefactoringUIMessages . RenameResourceHandler_ERROR_EXPECTED_STRING + newNameValue . getClass ( ) . getName ( ) ) ; < |endfocus| > } ISelection sel = HandlerUtil . getCurrentSelection ( event ) ; if ( sel instanceof IStructuredSelection ) { IResource resource = getCurrentResource ( ( IStructuredSelection ) sel ) ; if ( resource != null ) { RenameResourceWizard refactoringWizard ; if ( newName != null ) { refactoringWizard = new RenameResourceWizard ( resource , newName ) ; } else { refactoringWizard = new RenameResourceWizard ( resource ) ; } RefactoringWizardOpenOperation op = new RefactoringWizardOpenOperation ( refactoringWizard ) ; try { op . run ( activeShell , RefactoringUIMessages . RenameResourceHandler_title ) ; } catch ( InterruptedException e ) { // do nothing } } } return null ; }
inputViewer . setInput ( getType ( ) ) ; commandStack = commandStackBuffer ; } } ) ; } } private ChangeNameCommand getRenameCommand ( String newValue ) { INamedElement element = getType ( ) ; if ( element instanceof FBNetworkElement ) { return new ChangeFBNetworkElementName ( ( FBNetworkElement ) element , newValue ) ; } return new ChangeNameCommand ( getType ( ) , nameText . getText ( ) ) ; } < |startfocus| > private class VarDeclarationCellModifier implements ICellModifier { < |endfocus| > @Override public boolean canModify ( final Object element , final String property ) { return ( VALUE_PROPERTY . equals ( property ) || COMMENT_PROPERTY . equals ( property ) ) ; } @Override public Object getValue ( final Object element , final String property ) { switch ( property ) { case VALUE_PROPERTY : return getVarDeclarationValue ( ( VarDeclaration ) element ) ; case COMMENT_PROPERTY : return ( ( INamedElement ) element ) . getComment ( ) != null ? ( ( INamedElement ) element ) . getComment ( ) : "" ; // $NON - NLS - 1$ default : return null ; } } @Override public void modify ( final Object element , final String property , final Object value ) {
import org . eclipse . fordiac . ide . model . commands . change . ChangeCommentCommand ; import org . eclipse . fordiac . ide . model . commands . change . ChangeNameCommand ; import org . eclipse . fordiac . ide . model . libraryElement . Device ; import org . eclipse . gef . EditPart ; import org . eclipse . swt . SWT ; import org . eclipse . swt . events . SelectionAdapter ; import org . eclipse . swt . events . SelectionEvent ; import org . eclipse . swt . layout . GridData ; import org . eclipse . swt . layout . GridLayout ; import org . eclipse . swt . widgets . Button ; import org . eclipse . swt . widgets . Combo ; import org . eclipse . swt . widgets . Composite ; < |startfocus| > < |endfocus| > public class DeviceSection extends AbstractDevResInterfaceSection { protected static String [ ] profileNames = null ; protected Combo profile ; protected Button getResources ; @Override public void refresh ( ) { super . refresh ( ) ; if ( null != type ) { setProfile ( ) ; getResources . setEnabled ( "DynamicTypeLoad" . equals ( ( ( Device ) getType ( ) ) . getProfile ( ) ) ) ; } } private void setProfile ( ) { int i = 0 ; for ( String p : profile . getItems ( ) ) { if ( p . equals ( ( ( Device ) getType ( ) ) . getProfile ( ) ) ) { profile . select ( i ) ; break ; } i ++ ; } } @Override protected void createTypeSpecificContent ( ) { createProfileGroup ( ) ; createGetResourcesGroup ( ) ; } private void createGetResourcesGroup ( ) { getResources = getWidgetFactory ( ) . createButton ( composite , "Get Resources" , SWT . CHECK ) ; getResources . setLayoutData ( new GridData ( SWT . FILL , SWT . CENTER , true , false , 2 , 1 ) ) ; getResources . addSelectionListener ( new SelectionAdapter ( ) { @Override public void widgetSelected ( SelectionEvent e ) { if ( null != type ) { executeCommand ( new ChangeGetResourcesCommand ( ( Device ) type , getResources . getSelection ( ) ) ) ; } } } ) ; } private void createProfileGroup ( ) { Composite profileGroup = getWidgetFactory ( ) . createComposite ( composite ) ; profileGroup . setLayout ( new GridLayout ( 2 , false ) ) ; profileGroup . setLayoutData ( new GridData ( SWT . FILL , SWT . CENTER , true , false , 2 , 1 ) ) ; getWidgetFactory ( ) . createCLabel ( profileGroup , "Profile : " ) ; profile = new Combo ( profileGroup , SWT . READ_ONLY ) ; profile . setLayoutData ( new GridData ( SWT . FILL , SWT . CENTER , true , false ) ) ; profile . addSelectionListener ( new SelectionAdapter ( ) { @Override public void widgetSelected ( SelectionEvent e ) { if ( null != type ) { executeCommand ( new ChangeProfileCommand ( ( Device ) type , profile . getText ( ) ) ) ; } } } ) ; } @Override protected void setInputCode ( ) { if ( null != type ) { profile . setItems ( getProfileNames ( ) ) ; setProfile ( ) ; getResources . setSelection ( ( ( Device ) type ) . isGetResources ( ) ) ; } } private String [ ] getProfileNames ( ) { if ( null == profileNames ) { profileNames = new String [ ] { "DynamicTypeLoad" , "StaticTypeLoad" } ; } return profileNames ; } }
teamArt . getAtsId ( ) ) ; } // Confirm that all blocking reviews are completed // Loop through this state's blocking reviews to confirm complete if ( teamArt . isTeamWorkflow ( ) ) { for ( IAtsAbstractReview review : ReviewManager . getReviewsFromCurrentState ( teamArt ) ) { AbstractReviewArtifact reviewArt = ( AbstractReviewArtifact ) AtsClientService . get ( ) . getQueryService ( ) . getArtifact ( review ) ; if ( reviewArt . getReviewBlockType ( ) == ReviewBlockType . Commit && ! reviewArt . isCompletedOrCancelled ( ) ) { < |startfocus| > AWorkbench . popup ( "Committing Branch Error ! " , "All blocking reviews must be completed before committing a new branch . Please complete all blocking reviews in order to continue . " ) ; < |endfocus| > return ; } } } if ( ! overrideStateValidation ) { final MutableBoolean adminOverride = new MutableBoolean ( false ) ; // Check extension points for valid commit for ( IAtsStateItem item : AtsStateItemManager . getStateItems ( ) ) { final Result tempResult = item . committing ( teamArt ) ; if ( tempResult . isFalse ( ) ) { // Allow Admin to override state validation
null ) ; // private Collection derivedEntities ; @Override public String getMarkingTag ( ) { return ManagedEntityArtifact . MARKING_TAG ; } @Override public IAbstractArtifactInternal getModel ( ) { return MODEL ; } public String getLabel ( ) { return getMetadata ( ) . getLabel ( this ) ; } // public Collection getDerivedEntities ( ) { // return this . derivedEntities ; // } // public ManagedEntityArtifact ( ArtifactManager artifactMgr ) { super ( artifactMgr ) ; < |startfocus| > // this . derivedEntities = new ArrayList ( ) ; < |endfocus| > setIStandardSpecifics ( new OssjEntitySpecifics ( this ) ) ; } @Override public IAbstractArtifactInternal extractFromClass ( JavaClass javaClass , ArtifactManager artifactMgr , IProgressMonitor monitor ) { ManagedEntityArtifact result = new ManagedEntityArtifact ( javaClass , artifactMgr , monitor ) ; return result ; } public ManagedEntityArtifact ( JavaClass javaClass , ArtifactManager artifactMgr , IProgressMonitor monitor ) { super ( javaClass , artifactMgr , monitor ) ; // this . derivedEntities = new ArrayList ( ) ; OssjEntitySpecifics specifics = new OssjEntitySpecifics ( this ) ; specifics . build ( ) ; setIStandardSpecifics ( specifics ) ; } // @Override // public void resolveReferences ( IProgressMonitor monitor ) { // super . resolveReferences ( monitor ) ; // // for ( Iterator iter = this . derivedEntities . iterator ( ) ; iter . hasNext ( ) ; ) // { // ManagedEntityArtifact derivedEntity = ( ManagedEntityArtifact ) iter . next ( ) ; // derivedEntity . resolveReferences ( monitor ) ; // } // }
} else if ( OS . RegOpenKeyEx ( OS . HKEY_LOCAL_MACHINE , key , 0 , OS . KEY_READ , phkResult ) == 0 ) { // Try reading from HKLM regKeyFound = true ; } if ( regKeyFound ) { int [ ] lpcbData = new int [ 1 ] ; TCHAR buffer = new TCHAR ( 0 , "AppsUseLightTheme" , true ) ; // $NON - NLS - 1$ int result = OS . RegQueryValueEx ( phkResult [ 0 ] , buffer , 0 , null , ( TCHAR ) null , lpcbData ) ; if ( result == 0 ) { < |startfocus| > lpcbData [ 0 ] = 4 ; int [ ] lpData = new int [ 1 ] ; result = OS . RegQueryValueEx ( phkResult [ 0 ] , buffer , 0 , null , lpData , lpcbData ) ; if ( result == 0 ) { isDarkTheme = ( lpData [ 0 ] == 0 ) ; } < |endfocus| > } OS . RegCloseKey ( phkResult [ 0 ] ) ; } } return isDarkTheme ;
* instance is modified to represent a different object name . */ public abstract class AnyObjectId implements Comparable < AnyObjectId > { /* * * Compare to object identifier byte sequences for equality . * * @param firstObjectId * the first identifier to compare . Must not be null . * @param secondObjectId * the second identifier to compare . Must not be null . * @return true if the two identifiers are the same . */ < |startfocus| > // TODO ( ms ) : rename in next major release < |endfocus| > @SuppressWarnings ( "AmbiguousMethodReference" ) public static boolean equals ( final AnyObjectId firstObjectId , final AnyObjectId secondObjectId ) { if ( firstObjectId == secondObjectId ) return true ; // We test word 3 first since the git file - based ODB // uses the first byte of w1 , and we use w2 as the // hash code , one of those probably came up with these // two instances which we are comparing for equality . // Therefore the first two words are very likely to be < |startfocus| > // TODO ( ms ) : rename in next major release < |endfocus| >
handleMiddleClick ( event ) ; } ) ; } private void handleMiddleClick ( MouseEvent event ) throws CoreException { if ( event . button == 2 && event . widget instanceof Tree ) { TreeItem item = ( ( Tree ) event . widget ) . getItem ( new Point ( event . x , event . y ) ) ; if ( item == null ) { return ; } Object data = item . getData ( ) ; if ( data instanceof IProject ) { IProject project = ( IProject ) data ; < |startfocus| > if ( project . isOpen ( ) ) { project . close ( new NullProgressMonitor ( ) ) ; } < |endfocus| > } } } } ) ;
} @Override public boolean isHidden ( File path ) throws IOException { return FileUtil . isHidden ( path ) ; } @Override public void setHidden ( File path , boolean hidden ) throws IOException { FileUtil . setHidden ( path , hidden ) ; } @Override public String readSymLink ( File path ) throws IOException { return FileUtil . readSymlink ( path ) ; } @Override public void createSymLink ( File path , String target ) throws IOException { FileUtil . createSymLink ( path , target ) ; } /* * * @since 3 . 3 */ @Override public Attributes getAttributes ( File path ) { < |startfocus| > return FileUtil . getFileAttributesBasic ( this , path ) ; < |endfocus| > } }
RebaseTodoLine line = null ; String commentString = RawParseUtils . decode ( buf , tokenBegin , lineEnd + 1 ) ; try { int skip = tokenBegin + 1 ; // skip '#' skip = nextParsableToken ( buf , skip , lineEnd ) ; if ( skip != - 1 ) { // try to parse the line as non - comment line = parseLine ( buf , skip , lineEnd ) ; // successfully parsed as non - comment line // mark this line as a comment explicitly < |startfocus| > line . setAction ( Action . COMMENT ) ; // use the read line as comment string line . setComment ( commentString ) ; < |endfocus| > } } catch ( Exception e ) { // parsing as non - comment line failed line = null ; } finally { if ( line == null ) line = new RebaseTodoLine ( commentString ) ; r . add ( line ) ; }
* @param treeStyle the style bits for the < code > Tree </ code > * @param filter the filter to be used * * @deprecated As of 3 . 116 , replaced by * { @link #FilteredTree ( Composite , int , PatternFilter , boolean , boolean ) } * * */ @Deprecated public FilteredTree ( Composite parent , int treeStyle , PatternFilter filter ) { super ( parent , SWT . NONE ) ; this . parent = parent ; init ( treeStyle , filter ) ; } < |startfocus| > < |endfocus| > /* * * Create a new instance of the receiver . * * < p > * < b > WARNING : </ b > Using this constructor results in a slow performing tree and * should not be used if the underlying data model uses a stable and correct * hashCode and equals implementation . Prefer the usage of * { @link #FilteredTree ( Composite , int , PatternFilter , boolean , boolean ) } if * possible * </ p > * * @param parent the parent < code > Composite </ code >
< |startfocus| > private void addPatterns ( String . . . searchStrings ) { if ( searchStrings == null ) { return ; } for ( String searchString : searchStrings ) { if ( searchString == null || searchString . isEmpty ( ) ) { continue ; } Node node = root ; for ( char c : searchString . toCharArray ( ) ) { node = node . add ( c ) ; } node . match = searchString ; } < |endfocus| >
* * @since 3 . 9 */ public class MultiStringMatcher { // An implementation of the Aho - Corasick algorithm ( without the DFA construction from section 6 of the // paper ; just the failure and output links ) . // // See Aho , Alfred A . ; Corasick , Margaret J . : "Efficient String Matching : An Aid to Bibliographic Search" , // CACM 18 ( 6 ) , 1975 . // < |startfocus| > // The algorithm has been modified to support reporting leftmost longest matches only . < |endfocus| > /* * * Describes a match result of { @link MultiStringMatcher#indexOf ( String , int ) } , giving access to * the matched string and the offset in the text it was matched at . */ public static interface Match { /* * * Obtains the matched string . * * @return the text matched */ String getText ( ) ; /* * * Obtains the offset the { @link #getText ( ) text } was matched at . * * @return the offset */ int getOffset ( ) ; }
* < p > * Performs a simultaneous search for all the strings , returning the leftmost match . If multiple * search strings match at the same index , the longest match is returned . * </ p > * * @param text to search * @param offset to start searching at * @return the leftmost longest match found , or { @code null } if no match was found . < |startfocus| > * @throws IllegalStateException if no strings to search for have been added to this matcher < |endfocus| > */ public Match indexOf ( String text , int offset ) { List < Match > matches = find ( text , offset , true ) ; if ( matches . isEmpty ( ) ) { return null ; } // Find the leftmost longest match . Maybe there's an awfully clever way to keep only // one match ? Iterator < Match > m = matches . iterator ( ) ; Match result = m . next ( ) ; while ( m . hasNext ( ) ) { Match cand = m . next ( ) ; int cmp = Integer . compare ( cand . getOffset ( ) , result . getOffset ( ) ) ; if ( cmp < 0 ) { result = cand ; } else if ( cmp == 0 ) { if ( cand . getLength ( ) > result . getLength ( ) ) { result = cand ; } } } return result ; } /* * * < p > * Performs a simultaneous search for all the strings , returning the rightmost match . If multiple * search strings match at the same index , the longest match is returned . * </ p > * * @param text to search * @param offset to start searching at * @return the rightmost longest match found , or { @code null } if no match was found . */ public Match lastIndexOf ( String text , int offset ) { List < Match > matches = find ( text , offset , false ) ; if ( matches . isEmpty ( ) ) { return null ; } // Find the rightmost longest match . Maybe there's an awfully clever way to keep only // one match ? Iterator < Match > m = matches . iterator ( ) ; Match result = m . next ( ) ; while ( m . hasNext ( ) ) { Match cand = m . next ( ) ; int cmp = Integer . compare ( cand . getOffset ( ) , result . getOffset ( ) ) ; if ( cmp > 0 ) { result = cand ; } else if ( cmp == 0 ) { if ( cand . getLength ( ) > result . getLength ( ) ) { result = cand ; } } } return result ; } /* * * < p > * Performs a simultaneous search for all the strings , returning all matches . * </ p > * * @param text to search * @param offset to start searching at * @return a list of all matches found , in order of occurrence . */ public List < Match > findAll ( String text , int offset ) { return find ( text , offset , true ) ; } /* * * < p > * Performs a simultaneous search for all the strings , returning all matches . * </ p > * * @param text to search * @param offset to start searching at * @return a list of all matches found , in reverse order of occurrence . */ public List < Match > findAllReverse ( String text , int offset ) { return find ( text , offset , false ) ; } /* * * < p > * Performs a simultaneous search for all the strings , returning all matches . * </ p > * * @param text to search * @param offset to start searching at * @param forward whether to search forward or backward * @return a list of all matches found , in order of occurrence . */ private List < Match > find ( String text , int offset , boolean forward ) { if ( text == null ) { throw new IllegalArgumentException ( "text cannot be null" ) ; } if ( offset < 0 ) { throw new IllegalArgumentException ( "offset cannot be negative" ) ; } if ( offset > text . length ( ) ) { throw new IllegalArgumentException ( "offset cannot be greater than the length of the text" ) ; } if ( searchStrings . isEmpty ( ) ) { throw new IllegalStateException ( "no search strings have been added" ) ; } List < Match > matches = new ArrayList < > ( ) ; for ( String searchString : searchStrings ) { int index = forward ? text . indexOf ( searchString , offset ) : text . lastIndexOf ( searchString , offset ) ; if ( index >= 0 ) { matches . add ( new Match ( index , searchString . length ( ) ) ) ; } } return matches ; } /* * * < p > * A match found by { @link StringMatcher } . * </ p > * * @author < a href = "mailto : johannesd@torchmind . com" > Johannes Donath </ a > */ public static class Match { private final int offset ; private final int length ; public Match ( int offset , int length ) { this . offset = offset ; this . length = length ; } /* * * < p > * Retrieves the offset at which the match was found . * </ p > * * @return an offset . */ public int getOffset ( ) { return this . offset ; } /* * * < p > * Retrieves the length of the match . * </ p > * * @return a length . */ public int getLength ( ) { return this . length ; } } }
testList ( matches , " [ [ x , 2 ] ] " ) ; } @Test public void noStrings001 ( ) throws Exception { thrown . expect ( IllegalStateException . class ) ; MultiStringMatcher . builder ( ) . build ( ) ; } @Test public void noStrings002 ( ) throws Exception { thrown . expect ( IllegalStateException . class ) ; MultiStringMatcher . builder ( ) . add ( "" ) . build ( ) ; } @Test public void noStrings003 ( ) throws Exception { < |startfocus| > thrown . expect ( IllegalStateException . class ) ; MultiStringMatcher . builder ( ) . add ( ( String [ ] ) null ) . build ( ) ; < |endfocus| > } @Test public void fluent001 ( ) throws Exception { MultiStringMatcher m = MultiStringMatcher . builder ( ) . add ( "he" , "she" , "his" , "hers" ) . build ( ) ; test ( m . indexOf ( "ushers" , 0 ) , "she" , 1 ) ; } @Test public void fluent002 ( ) throws Exception { MultiStringMatcher m = MultiStringMatcher . builder ( ) . add ( "he" , "she" ) . add ( "his" , "hers" ) . build ( ) ; testList ( m . find ( "ushers" , 0 ) , " [ [ she , 1 ] , [ he , 2 ] , [ hers , 2 ] ] " ) ; } @Test public void fluent003 ( ) throws Exception { MultiStringMatcher m = MultiStringMatcher . builder ( ) . add ( "he" , "she" ) . add ( "his" , "hers" ) . build ( ) ; testList ( m . find ( "ushers" , 0 ) , " [ [ she , 1 ] , [ he , 2 ] , [ hers , 2 ] ] " ) ; }
public Match indexOf ( String text , int offset ) { List < Match > matches = find ( text , offset , true ) ; if ( matches . isEmpty ( ) ) { return null ; } // Find the leftmost longest match . Maybe there's an awfully clever way to keep only // one match ? Iterator < Match > m = matches . iterator ( ) ; Match result = m . next ( ) ; while ( m . hasNext ( ) ) { Match cand = m . next ( ) ; if ( cand . getOffset ( ) > result . getOffset ( ) ) { < |startfocus| > // Results are ordered by offset . There will be no leftmost match as all we checked . < |endfocus| > break ; } if ( cand . getText ( ) . length ( ) > result . getText ( ) . length ( ) ) { result = cand ; } } return result ;
package org . eclipse . tycho . pomless ; import java . io . File ; import java . io . FileFilter ; import java . io . IOException ; import org . apache . maven . model . Model ; import org . apache . maven . model . io . ModelParseException ; import org . codehaus . plexus . component . annotations . Component ; import org . sonatype . maven . polyglot . mapping . Mapping ; import org . w3c . dom . Element ; @Component ( role = Mapping . class , hint = TychoTargetMapping . ROLE ) public class TychoTargetMapping extends AbstractXMLTychoMapping { private static final String TARGET_EXTENSION = " . target" ; < |startfocus| > public static final String ROLE = "eclipse - target - definition" ; < |endfocus| > @Override public String getFlavour ( ) { return TychoTargetMapping . ROLE ; } @Override protected boolean isValidLocation ( String location ) { return location . endsWith ( TARGET_EXTENSION ) ; } @Override protected File getPrimaryArtifact ( File dir ) { File file = new File ( dir , dir . getName ( ) + TARGET_EXTENSION ) ; if ( file . exists ( ) ) { return file ; } File [ ] listFiles = dir . listFiles ( new FileFilter ( ) { @Override public boolean accept ( File file ) {
@Override public void checkPermission ( Permission requested ) { for ( Permission permission : permissions ) { if ( permission . implies ( requested ) ) { return ; } } super . checkPermission ( requested ) ; } } ) ; } @After public void tearDown ( ) throws Exception { System . setSecurityManager ( originalSecurityManager ) ; //
protected static File searchPath ( String path , String . . . lookFor ) { if ( path == null ) return null ; for ( String p : path . split ( File . pathSeparator ) ) { for ( String command : lookFor ) { final File file = new File ( p , command ) ; try { if ( file . isFile ( ) ) { return file . getAbsoluteFile ( ) ; } } catch ( SecurityException e ) { < |startfocus| > LOG . warn ( JGitText . get ( ) . pathIsntAccessible , file . getPath ( ) ) ; < |endfocus| > } } } return null ;
} catch ( InterruptedException ie ) { // Stop bothering me , I have a zombie to reap . } } } catch ( IOException e ) { LOG . error ( Messages . getString ( "FS . CaughtExceptionInReadPipe" ) , e ) ; // $NON - NLS - 1$ } catch ( AccessControlException e ) { LOG . warn ( Messages . getString ( "FS . ReadPipeNotAllowedForCommand" ) , // $NON - NLS - 1$ command , dir , e . getPermission ( ) ) ; } catch ( SecurityException e ) { < |startfocus| > LOG . warn ( Messages . getString ( "FS . ReadPipeNotAllowedForCommand" ) , // $NON - NLS - 1$ command , dir ) ; < |endfocus| > } if ( debug ) { LOG . debug ( Messages . getString ( "FS . ReadPipeReturnsNull" ) ) ; // $NON - NLS - 1$ } return null ; } private static class GobblerThread extends Thread { /* The process has 5 seconds to exit after closing stderr */ private static final int PROCESS_EXIT_TIMEOUT = 5 ; private final Process p ; private final String desc ;
* ( non - Javadoc ) * @see org . eclipse . ptp . rdt . sync . core . services . ISynchronizeService#synchronize ( org . eclipse . core . resources . IProject , * org . eclipse . ptp . rdt . sync . core . RemoteLocation , org . eclipse . core . resources . IResourceDelta , * org . eclipse . core . runtime . IProgressMonitor , java . util . EnumSet ) */ @Override public void synchronize ( final IProject project , RemoteLocation rl , IResourceDelta delta , IProgressMonitor monitor , Set < SyncFlag > syncFlags ) throws CoreException { if ( project == null || rl == null ) { throw new NullPointerException ( ) ; } < |startfocus| > if ( project != null && delta != null && project . getFile ( gitDir ) . getFullPath ( ) . isPrefixOf ( delta . getFullPath ( ) ) ) { // ignore deltas prefixed by gitDir < |endfocus| > return ; } // Make a copy to protect against the remote location // being changed by another thread . RemoteLocation remoteLoc = new RemoteLocation ( rl ) ; ProjectAndRemoteLocationPair syncTarget = new ProjectAndRemoteLocationPair ( project , remoteLoc ) ; if ( syncFlags . contains ( SyncFlag . WAIT_FOR_LR ) ) { try { SyncInt si = syncLRPending . get ( syncTarget ) ;
* org . eclipse . core . runtime . IProgressMonitor , java . util . EnumSet ) */ @Override public void synchronize ( final IProject project , RemoteLocation rl , IResourceDelta delta , IProgressMonitor monitor , Set < SyncFlag > syncFlags ) throws CoreException { if ( project == null || rl == null ) { throw new NullPointerException ( ) ; } < |startfocus| > if ( project != null && delta != null && project . getFile ( gitDir ) . getFullPath ( ) . isPrefixOf ( delta . getFullPath ( ) ) ) { < |endfocus| > // ignore deltas prefixed by gitDir return ; } // Make a copy to protect against the remote location // being changed by another thread . RemoteLocation remoteLoc = new RemoteLocation ( rl ) ; ProjectAndRemoteLocationPair syncTarget = new ProjectAndRemoteLocationPair ( project , remoteLoc ) ; if ( syncFlags . contains ( SyncFlag . WAIT_FOR_LR ) ) { try { SyncInt si = syncLRPending . get ( syncTarget ) ; if ( si != null ) { si . waitForZero ( ) ; } } catch ( InterruptedException e ) { // This shouldn't happen . Activator . log ( e ) ; } return ; }
/* * Verify that undocumented internal data is in expected location . * The test is performed at creation time , when the value of state flags is predictable . * For simplicity , only SWT . READ_ONLY combos are handled . */ boolean stateFlagsTest ( ) { final long tagCBoxPtr = OS . GetWindowLongPtr ( handle , 0 ) ; /* * Bug 550423 : When non - XP - theme COMMCTL32 . DLL gets loaded , undocumented < |startfocus| > * internal data is not there . We do not support that and is such case < |endfocus| > * GetWindowLongPtr function fails and return zero . */ if ( tagCBoxPtr == 0 ) return false ; final long stateFlagsPtr = tagCBoxPtr + stateFlagsOffset ; int stateFlags [ ] = new int [ 1 ] ; OS . MoveMemory ( stateFlags , stateFlagsPtr , 4 ) ; /* * 0x00000002 is unknown * 0x00002000 is set in WM_NCCREATE * 0x00004000 means CBS_DROPDOWNLIST ( SWT . READ_ONLY ) * 0x02000000 is set in WM_NCCREATE and reset after first WM_PAINT */ return ( stateFlags [ 0 ] == 0x02006002 ) ; }
} } /* * Verify that undocumented internal data is in expected location . * The test is performed at creation time , when the value of state flags is predictable . * For simplicity , only SWT . READ_ONLY combos are handled . */ boolean stateFlagsTest ( ) { final long tagCBoxPtr = OS . GetWindowLongPtr ( handle , 0 ) ; /* < |startfocus| > * If the GetWindowLongPtr function fails , the return value is zero . Hence the * state - flags test doesn't pass and should return false . < |endfocus| > */ if ( tagCBoxPtr != 0 ) { final long stateFlagsPtr = tagCBoxPtr + stateFlagsOffset ; int stateFlags [ ] = new int [ 1 ] ; OS . MoveMemory ( stateFlags , stateFlagsPtr , 4 ) ; /* * 0x00000002 is unknown * 0x00002000 is set in WM_NCCREATE * 0x00004000 means CBS_DROPDOWNLIST ( SWT . READ_ONLY ) * 0x02000000 is set in WM_NCCREATE and reset after first WM_PAINT */ return ( stateFlags [ 0 ] == 0x02006002 ) ; } return false ; } @Override void register ( ) {
if ( length == OS . CB_ERR ) { int count = ( int ) /* 64 */ OS . SendMessage ( handle , OS . CB_GETCOUNT , 0 , 0 ) ; if ( 0 <= index && index < count ) error ( SWT . ERROR_ITEM_NOT_REMOVED ) ; error ( SWT . ERROR_INVALID_RANGE ) ; } buffer = new TCHAR ( getCodePage ( ) , length + 1 ) ; int result = ( int ) /* 64 */ OS . SendMessage ( handle , OS . CB_GETLBTEXT , index , buffer ) ; if ( result == OS . CB_ERR ) { < |startfocus| > int count = ( int ) /* 64 */ OS . SendMessage ( handle , OS . CB_GETCOUNT , 0 , 0 ) ; if ( 0 <= index && index < count ) error ( SWT . ERROR_ITEM_NOT_REMOVED ) ; < |endfocus| > error ( SWT . ERROR_INVALID_RANGE ) ; } } int length = OS . GetWindowTextLength ( handle ) ; int code = ( int ) /* 64 */ OS . SendMessage ( handle , OS . CB_DELETESTRING , index , 0 ) ; if ( code == OS . CB_ERR ) { int count = ( int ) /* 64 */ OS . SendMessage ( handle , OS . CB_GETCOUNT , 0 , 0 ) ;
private static final String pageName = "Scripts" ; private ToolItem abortButton ; private ToolItem abortBatchButton ; private CoolBar coolBar ; private ToolItem deleteButton ; private Label hostConnectLabel ; private LoadWidget loadWidget ; protected ToolItem runButton ; private SaveWidget saveWidget ; private ScriptTableViewer scriptTable ; private StatusWindowWidget statusWindow ; private final TestManagerEditor testManagerEditor ; private ProgramButtonProviderService programButtonProviderService ; < |startfocus| > // private LibraryLinkerProviderService libraryLinkerProviderService ; // private LaunchAndKillProviderService launchAndKillProviderService ; < |endfocus| > public ScriptPage ( Composite parent , int style , TestManagerEditor parentTestManager ) { super ( parent , style , parentTestManager ) ; this . testManagerEditor = parentTestManager ; } public void addFile ( String fullPath ) { scriptTable . addFile ( fullPath ) ; } @Override public void createPage ( ) { super . createPage ( ) ; Composite parent = ( Composite ) getContent ( ) ; coolBar = new CoolBar ( parent , SWT . FLAT ) ; createControlsToolBar ( coolBar ) ; createConfigurationToolBar ( coolBar ) ; packCoolBar ( ) ; }
} // Example : As above , but to be moved to the appropriate class / location . ILibraryLinkerProviderService libraryLinkerProviderService = OsgiUtil . getService ( ILibraryLinkerProvider . class , LibraryLinkerProviderService . class ) ; for ( ILibraryLinkerProvider provider : libraryLinkerProviderService . getLibraryLinkerProviders ( ) ) { provider . getLibraryLinkers ( ) ; } // Example : As above , but to be moved to the appropriate class / location . ILaunchAndKillProviderService launchAndKillProviderService = OsgiUtil . getService ( ILaunchAndKillProvider . class , LaunchAndKillProviderService . class ) ; < |startfocus| > // @formatter : off < |endfocus| > // Example to launch and kill processes : for ( ILaunchAndKillProvider provider : launchAndKillProviderService . getLaunchAndKillProviders ( ) ) { Collection < ILaunchAndKill > launchers = provider . getLaunchers ( ) ; Collection < ILaunchAndKill > killers = provider . getKillers ( ) ; for ( ILaunchAndKill launcher : launchers ) { Process launchProcess ; // To access Process methods // launchProcess = launcher . executeProcess ( ) ; // Launches the process break ; } for ( ILaunchAndKill killer : killers ) { Process killProcess ; // To access Process methods // killProcess = killer . executeProcess ( ) ; // Kills the process break ; } }
if ( selection . getFirstElement ( ) instanceof Table ) { this . exportedTable = ( Table ) selection . getFirstElement ( ) ; } else if ( selection instanceof TableStructuredSelection ) { final TableStructuredSelection tss = ( TableStructuredSelection ) selection ; final INattableModelManager tableModelManager = ( INattableModelManager ) tss . getAdapter ( INattableModelManager . class ) ; if ( null != tableModelManager ) { this . exportedTable = tableModelManager . getTable ( ) ; } } < |startfocus| > Assert . isNotNull ( this . exportedTable , "We can't found the table to export" ) ; // $NON - NLS - 1$ < |endfocus| > IStatus status = TableChecker . checkTable ( this . exportedTable ) ; if ( false == status . isOK ( ) ) { addPage ( new WarningOnCurrentTableWizardPage ( status ) ) ; } this . outputPage = new DefineOutputPluginWizardPage ( ) ; this . tableDataPage = new DefineTableConfigurationDataWizardPage ( ) ; this . outputPage . setExportedTable ( this . exportedTable ) ; this . tableDataPage . setExportedTable ( this . exportedTable ) ; addPage ( outputPage ) ; addPage ( tableDataPage ) ; < |startfocus| > Review : add it into the message < |endfocus| >
if ( field != null ) { return new JDIFieldVariable ( debugTarget , field , getUnderlyingObject ( ) , fLogicalParent ) ; } // Check possible references of variables defined in outer class for ( Field outer : synteticFields ) { // retrieve the reference to the "outer" object JDIFieldVariable syntVariable = new JDIFieldVariable ( debugTarget , outer , getUnderlyingObject ( ) , fLogicalParent ) ; IValue value = syntVariable . getValue ( ) ; if ( value instanceof JDIObjectValue ) { JDIObjectValue outerObject = ( JDIObjectValue ) value ; < |startfocus| > // ask "outer" object about field probably declared within return outerObject . getField ( name , outer . signature ( ) ) ; < |endfocus| > } } } catch ( RuntimeException e ) { targetRequestFailed ( MessageFormat . format ( JDIDebugModelMessages . JDIObjectValue_exception_retrieving_field , e . toString ( ) ) , e ) ; } // it is possible to return null return null ; } static List < ReferenceType > superTypes ( ReferenceType type ) { List < ReferenceType > superTypes = new ArrayList < > ( ) ; ReferenceType t = type ;
import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . VppInterfaceAugmentation ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . interfaces . _interface . Routing ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . interfaces . _interface . RoutingBuilder ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . fib . table . management . rev180521 . VniReference ; import org . opendaylight . yangtools . yang . binding . InstanceIdentifier ; public class InterfaceRoutingCustomizerTest extends WriterCustomizerTest { private static final String IFACE_CTX_NAME = "interface - ctx" ; private static final String IF_NAME = "eth1" ; private static final int IF_INDEX = 1 ; private static final InstanceIdentifier < Routing > IID = InstanceIdentifier . create ( Interfaces . class ) . child ( Interface . class , new InterfaceKey ( IF_NAME ) ) . augmentation ( VppInterfaceAugmentation . class ) . child ( Routing . class ) ; private InterfaceRoutingCustomizer customizer ; @Override protected void setUpTest ( ) throws Exception { customizer = new InterfaceRoutingCustomizer ( api , new NamingContext ( "ifacePrefix" , IFACE_CTX_NAME ) ) ;
import java . util . Collections ; import java . util . Set ; import org . junit . Test ; import org . mockito . ArgumentCaptor ; import org . mockito . Captor ; import org . opendaylight . yang . gen . v1 . urn . ietf . params . xml . ns . yang . ietf . interfaces . rev140508 . Interfaces ; import org . opendaylight . yang . gen . v1 . urn . ietf . params . xml . ns . yang . ietf . interfaces . rev140508 . interfaces . Interface ; import org . opendaylight . yang . gen . v1 . urn . ietf . params . xml . ns . yang . ietf . interfaces . rev140508 . interfaces . InterfaceKey ; < |startfocus| > import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . fib . table . management . rev180521 . VniReference ; < |endfocus| > import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . vpp . vlan . rev180319 . SubinterfaceAugmentation ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . vpp . vlan . rev180319 . interfaces . _interface . SubInterfaces ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . vpp . vlan . rev180319 . interfaces . _interface . sub . interfaces . SubInterface ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . vpp . vlan . rev180319 . interfaces . _interface . sub . interfaces . SubInterfaceBuilder ;
import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . VppInterfaceAugmentation ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . VxlanVni ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . interfaces . _interface . Vxlan ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . interfaces . _interface . VxlanBuilder ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . fib . table . management . rev180521 . VniReference ; import org . opendaylight . yangtools . yang . binding . InstanceIdentifier ; public class VxlanCustomizerTest extends WriterCustomizerTest implements AddressTranslator { private static final byte ADD_VXLAN = 1 ; private static final byte DEL_VXLAN = 0 ; @Mock private DisabledInterfacesManager disableContext ; private VxlanCustomizer customizer ; private String ifaceName ; private InstanceIdentifier < Vxlan > id ; private static Vxlan generateVxlan ( long vni ) { final VxlanBuilder builder = new VxlanBuilder ( ) ; builder . setSrc ( new IpAddressNoZone ( new Ipv4AddressNoZone ( "192 . 168 . 20 . 10" ) ) ) ;
import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . VppInterfaceStateAugmentationBuilder ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . interfaces . state . _interface . Routing ; import org . opendaylight . yang . gen . v1 . urn . opendaylight . params . xml . ns . yang . v3po . rev181008 . interfaces . state . _interface . RoutingBuilder ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . fib . table . management . rev180521 . VniReference ; import org . opendaylight . yangtools . yang . binding . InstanceIdentifier ; public class InterfaceRoutingCustomizerTest extends ReaderCustomizerTest < Routing , RoutingBuilder > { private static final String IFC_CTX_NAME = "ifc - test - instance" ; private static final String IF_NAME = "local0" ; private static final int IF_ID = 1 ; private static final Long IP4_VRF_ID = 1L ; private static final Long IP6_VRF_ID = 2L ; private NamingContext interfacesContext ; public InterfaceRoutingCustomizerTest ( ) { super ( Routing . class , VppInterfaceStateAugmentationBuilder . class ) ; } @Override public void setUp ( ) {
namingContext . removeChild ( PARENT_1 , CHILD_1 , mappingContext ) ; verify ( mappingContext , times ( 1 ) ) . put ( instanceIdentifierArgumentCaptor . capture ( ) , mappingArgumentCaptor . capture ( ) ) ; assertEquals ( instanceIdentifierArgumentCaptor . getValue ( ) , parentKey ( PARENT_1 ) ) ; final Mapping mapping = mappingArgumentCaptor . getValue ( ) ; final List < Value > values = mapping . getValue ( ) ; assertEquals ( PARENT_1 , mapping . getName ( ) ) ; assertThat ( values , hasSize ( 2 ) ) ; < |startfocus| > assertThat ( values , containsInAnyOrder ( valueFor ( CHILD_2 , 2 ) , valueFor ( CHILD_3 , 3 ) ) ) ; < |endfocus| > } @Test public void removeChildNonExistingParent ( ) { namingContext . removeChild ( NON_EXISTING_PARENT , CHILD_1 , mappingContext ) ; // if parent doest not exist , do nothing verify ( mappingContext , times ( 0 ) ) . put ( Mockito . any ( ) , Mockito . any ( ) ) ; } private Value valueFor ( final String name , final int index ) { return new ValueBuilder ( ) . setName ( name ) . setIndex ( index ) . withKey ( new ValueKey ( name ) ) . build ( ) ; } }
import io . fd . hc2vpp . ipsec . read . IpsecReaderFactory ; import io . fd . hc2vpp . ipsec . write . IpsecWriterFactory ; import io . fd . honeycomb . translate . read . ReaderFactory ; import io . fd . honeycomb . translate . write . WriterFactory ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; /* * * Module class instantiating nat plugin components . */ public class IpsecModule extends AbstractModule { private static final Logger LOG = LoggerFactory . getLogger ( IpsecModule . class ) ; < |startfocus| > private static final String SAD_ENTRIES_MAPPING = "sad - entries - mapping" ; < |endfocus| > @Override protected void configure ( ) { LOG . info ( "Installing IPSec module" ) ; bind ( MultiNamingContext . class ) . toInstance ( new MultiNamingContext ( SAD_ENTRIES_MAPPING , 1 ) ) ; LOG . info ( "Injecting writers factories" ) ; final Multibinder < WriterFactory > writerFactoryBinder = Multibinder . newSetBinder ( binder ( ) , WriterFactory . class ) ; writerFactoryBinder . addBinding ( ) . to ( IpsecWriterFactory . class ) . in ( Singleton . class ) ; LOG . info ( "Injecting readers factories" ) ; final Multibinder < ReaderFactory > readerFactoryBinder = Multibinder . newSetBinder ( binder ( ) , ReaderFactory . class ) ; readerFactoryBinder . addBinding ( ) . to ( IpsecReaderFactory . class ) . in ( Singleton . class ) ;
import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . vpp . ipsec . rev181213 . IpsecStateSpdAugmentationBuilder ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . vpp . ipsec . rev181213 . ipsec . state . Spd ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . vpp . ipsec . rev181213 . ipsec . state . spd . SpdEntries ; import org . opendaylight . yangtools . yang . binding . InstanceIdentifier ; /* * < |startfocus| > * Factory producing writers for DHCP plugin's data . < |endfocus| > */ public final class IpsecReaderFactory implements ReaderFactory { private static final InstanceIdentifier < IpsecState > IPSEC_STATE_ID = InstanceIdentifier . create ( IpsecState . class ) ; private FutureJVppCore vppApi ; @Inject public IpsecReaderFactory ( final FutureJVppCore vppApi ) { this . vppApi = vppApi ; } @Override public void init ( @Nonnull final ModifiableReaderRegistryBuilder registry ) { registry . subtreeAdd ( Sets . newHashSet ( InstanceIdentifier . create ( IpsecState . class ) . child ( Sa . class ) , InstanceIdentifier . create ( IpsecState . class ) . augmentation ( IpsecStateSpdAugmentation . class ) . child ( Spd . class ) ) , new GenericReader < > ( IPSEC_STATE_ID , new IpsecStateCustomizer ( vppApi ) ) ) ;
import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . vpp . ipsec . rev181213 . IpsecStateSpdAugmentationBuilder ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . vpp . ipsec . rev181213 . ipsec . state . Spd ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . vpp . ipsec . rev181213 . ipsec . state . spd . SpdEntries ; import org . opendaylight . yangtools . yang . binding . InstanceIdentifier ; /* * < |startfocus| > * Factory producing writers for DHCP plugin's data . < |endfocus| > */ public final class IpsecReaderFactory implements ReaderFactory { private static final InstanceIdentifier < IpsecState > IPSEC_STATE_ID = InstanceIdentifier . create ( IpsecState . class ) ; private FutureJVppCore vppApi ; @Inject public IpsecReaderFactory ( final FutureJVppCore vppApi ) { this . vppApi = vppApi ; } @Override public void init ( @Nonnull final ModifiableReaderRegistryBuilder registry ) { registry . subtreeAdd ( Sets . newHashSet ( InstanceIdentifier . create ( IpsecState . class ) . child ( Sa . class ) , InstanceIdentifier . create ( IpsecState . class ) . augmentation ( IpsecStateSpdAugmentation . class ) . child ( Spd . class ) ) , new GenericReader < > ( IPSEC_STATE_ID , new IpsecStateCustomizer ( vppApi ) ) ) ;
registry . addStructuralReader ( IPSEC_STATE_ID , IpsecStateBuilder . class ) ; registry . add ( new GenericInitReader < > ( IPSEC_STATE_ID , new IpsecStateCustomizer ( vppApi ) ) ) ; registry . addStructuralReader ( IPSEC_STATE_ID . augmentation ( IpsecStateSpdAugmentation . class ) , IpsecStateSpdAugmentationBuilder . class ) ; registry . subtreeAdd ( Sets . newHashSet ( InstanceIdentifier . create ( IpsecState . class ) . augmentation ( IpsecStateSpdAugmentation . class ) . child ( Spd . class ) ) , new GenericReader < > ( IPSEC_STATE_ID , new IpsecStateCustomizer ( vppApi ) ) ) ; registry . addStructuralReader ( IPSEC_STATE_ID . augmentation ( IpsecStateSpdAugmentation . class ) , IpsecStateSpdAugmentationBuilder . class ) ; registry . subtreeAdd ( Sets . newHashSet ( InstanceIdentifier . create ( Spd . class ) . child ( SpdEntries . class ) ) , new GenericInitListReader < > ( IPSEC_STATE_ID . augmentation ( IpsecStateSpdAugmentation . class ) . child ( Spd . class ) , new IpsecStateSpdCustomizer ( vppApi ) ) ) ;
public IpsecStateCustomizer ( final FutureJVppCore vppApi ) { super ( vppApi ) ; < |startfocus| > this . ipsecSaDetailsReplyDumpManager = new DumpCacheManager . DumpCacheManagerBuilder < IpsecSaDetailsReplyDump , Void > ( ) . withExecutor ( new IpsecStateCustomizer . IpsecStateSaDetailsDumpExecutor ( vppApi ) ) . acceptOnly ( IpsecSaDetailsReplyDump . class ) . build ( ) ; < |endfocus| >
return Initialized . create ( id , readValue ) ; } @Nonnull @Override public IpsecStateBuilder getBuilder ( @Nonnull final InstanceIdentifier < IpsecState > id ) { return new IpsecStateBuilder ( ) ; } @Override public void readCurrentAttributes ( @Nonnull final InstanceIdentifier < IpsecState > id , @Nonnull final IpsecStateBuilder builder , @Nonnull final ReadContext ctx ) throws ReadFailedException { < |startfocus| > final Optional < IpsecSaDetailsReplyDump > dumpSa = ipsecSaDetailsReplyDumpManager . getDump ( id , ctx . getModificationCache ( ) ) ; < |endfocus| > if ( dumpSa . isPresent ( ) ) { LinkedList < Sa > listSa = new LinkedList < > ( ) ; IpsecSaDetailsReplyDump reply = dumpSa . get ( ) ; for ( IpsecSaDetails details : reply . ipsecSaDetails ) { SaBuilder saBuilder = new SaBuilder ( ) ; saBuilder . setSpi ( Integer . toUnsignedLong ( details . spi ) ) ; saBuilder . setAntiReplayWindow ( Long . valueOf ( details . replayWindow ) . intValue ( ) ) ; saBuilder . setAuthenticationAlgorithm ( IkeIntegrityAlgorithmT . forValue ( details . integAlg ) ) ; saBuilder . setEncryptionAlgorithm ( IkeEncryptionAlgorithmT . forValue ( details . cryptoAlg ) ) ; listSa . add ( saBuilder . build ( ) ) ; } builder . setSa ( listSa ) ; } } @Override
if ( dumpSa . isPresent ( ) ) { LinkedList < Sa > listSa = new LinkedList < > ( ) ; IpsecSaDetailsReplyDump reply = dumpSa . get ( ) ; for ( IpsecSaDetails details : reply . ipsecSaDetails ) { SaBuilder saBuilder = new SaBuilder ( ) ; < |startfocus| > saBuilder . setSpi ( Integer . toUnsignedLong ( details . spi ) ) . setAntiReplayWindow ( Long . valueOf ( details . replayWindow ) . intValue ( ) ) . setAuthenticationAlgorithm ( IkeIntegrityAlgorithmT . forValue ( details . integAlg ) ) . setEncryptionAlgorithm ( IkeEncryptionAlgorithmT . forValue ( details . cryptoAlg ) ) ; < |endfocus| > listSa . add ( saBuilder . build ( ) ) ; } builder . setSa ( listSa ) ; } } @Override public void merge ( @Nonnull final Builder < ? extends DataObject > parentBuilder , @Nonnull final IpsecState readValue ) { IpsecStateBuilder ipsecParentBuilder = ( IpsecStateBuilder ) parentBuilder ; ipsecParentBuilder . setHoldDown ( readValue . getHoldDown ( ) ) ; ipsecParentBuilder . setPolicy ( readValue . getPolicy ( ) ) ; ipsecParentBuilder . setProposal ( readValue . getProposal ( ) ) ; ipsecParentBuilder . setRedundancy ( readValue . getRedundancy ( ) ) ; ipsecParentBuilder . setSa ( readValue . getSa ( ) ) ;
implements EntityDumpExecutor < IpsecSaDetailsReplyDump , Void > , JvppReplyConsumer { private final FutureJVppCore jvpp ; IpsecStateSaDetailsDumpExecutor ( final FutureJVppCore jvpp ) { this . jvpp = jvpp ; } @Nonnull @Override public IpsecSaDetailsReplyDump executeDump ( final InstanceIdentifier < ? > identifier , final Void params ) throws ReadFailedException { IpsecSaDump dump = new IpsecSaDump ( ) ; dump . saId = - 1 ; < |startfocus| > return getReplyForRead ( jvpp . ipsecSaDump ( dump ) . toCompletableFuture ( ) , identifier ) ; < |endfocus| > } } }
} } } @Override public void updateCurrentAttributes ( @Nonnull final InstanceIdentifier < IkeGlobalConfiguration > id , @Nonnull final IkeGlobalConfiguration dataBefore , @Nonnull final IkeGlobalConfiguration dataAfter , @Nonnull final WriteContext writeContext ) throws WriteFailedException { writeCurrentAttributes ( id , dataAfter , writeContext ) ; } @Override public void deleteCurrentAttributes ( @Nonnull final InstanceIdentifier < IkeGlobalConfiguration > id , @Nonnull final IkeGlobalConfiguration dataBefore , @Nonnull final WriteContext writeContext ) throws WriteFailedException { < |startfocus| > // TODO : implement < |endfocus| > } }
String name = id . firstKeyOf ( Policy . class ) . getName ( ) ; if ( dataAfter . getLocal ( ) != null ) { setProfileId ( id , name , dataAfter . getLocal ( ) . getIdentity ( ) , true ) ; } if ( dataAfter . getRemote ( ) != null ) { setProfileId ( id , name , dataAfter . getRemote ( ) . getIdentity ( ) , false ) ; } } @Override < |startfocus| > public void deleteCurrentAttributes ( @Nonnull final InstanceIdentifier < Identity > id , @Nonnull final Identity dataBefore , @Nonnull final WriteContext writeContext ) throws WriteFailedException { } @Override < |endfocus| > public void updateCurrentAttributes ( @Nonnull final InstanceIdentifier < Identity > id , @Nonnull final Identity dataBefore , @Nonnull final Identity dataAfter , @Nonnull final WriteContext writeContext ) throws WriteFailedException { writeCurrentAttributes ( id , dataAfter , writeContext ) ; } private void setProfileId ( final InstanceIdentifier < Identity > id , final String profileName , final org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . hc2vpp . ipsec . rev181214 . identity . grouping . Identity data , final boolean isLocalId ) throws WriteFailedException {
IpsecSadEntriesAugmentation augment = dataAfter . augmentation ( IpsecSadEntriesAugmentation . class ) ; if ( augment != null && augment . getSaId ( ) != null ) { entry . sadId = augment . getSaId ( ) ; } if ( dataAfter . getSpi ( ) != null ) { entry . spi = dataAfter . getSpi ( ) . intValue ( ) ; } if ( dataAfter . getAntiReplayWindow ( ) != null ) { < |startfocus| > entry . useAntiReplay = dataAfter . getAntiReplayWindow ( ) > 0 ? BYTE_TRUE : BYTE_FALSE ; < |endfocus| > } if ( dataAfter . getSaMode ( ) != null ) { entry . isTunnel = Integer . valueOf ( dataAfter . getSaMode ( ) . getIntValue ( ) ) . byteValue ( ) ; } entry . isAdd = adding ? ByteDataTranslator . BYTE_TRUE : ByteDataTranslator . BYTE_FALSE ; if ( dataAfter . getEsp ( ) != null ) { entry . protocol = 1 ; fillEspAuthentication ( entry , dataAfter . getEsp ( ) ) ; fillEspEncryption ( entry , dataAfter . getEsp ( ) ) ; } else if ( dataAfter . getAh ( ) != null ) { entry . protocol = 0 ;
import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . vpp . ipsec . rev181213 . IpsecIkeGlobalConfAugmentation ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . vpp . ipsec . rev181213 . IpsecSadEntriesAugmentation ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . vpp . ipsec . rev181213 . IpsecSpdEntriesAugmentation ; import org . opendaylight . yangtools . yang . binding . InstanceIdentifier ; /* * < |startfocus| > * Factory producing writers for DHCP plugin's data . < |endfocus| > */ public final class IpsecWriterFactory implements WriterFactory { private static final InstanceIdentifier < Ikev2 > IKE2_ID = InstanceIdentifier . create ( Ikev2 . class ) ; private static final InstanceIdentifier < Ipsec > IPSEC_ID = InstanceIdentifier . create ( Ipsec . class ) ; private static final InstanceIdentifier < Sad > SAD_ID = IPSEC_ID . child ( Sad . class ) ; private static final InstanceIdentifier < SadEntries > SAD_ENTRIES_ID = SAD_ID . child ( SadEntries . class ) ; private static final InstanceIdentifier < Spd > SPD_ID = IPSEC_ID . child ( Spd . class ) ; private final FutureJVppCore vppApi ; private MultiNamingContext sadEntriesMapping ; @Inject public IpsecWriterFactory ( @Nonnull final FutureJVppCore vppApi , @Nonnull final MultiNamingContext sadEntriesMapping ) { this . vppApi = vppApi ; this . sadEntriesMapping = sadEntriesMapping ; } @Override public void init ( @Nonnull final ModifiableWriterRegistryBuilder registry ) { registry . subtreeAdd ( new GenericInitListWriter < > ( IKE2_ID , new Ikev2Customizer ( vppApi ) ) , IKE2_ID ) ; registry . add ( new GenericWriter < > ( IKE2_ID , new Ikev2Customizer ( vppApi ) ) ) ; registry . add ( new GenericWriter < > ( IPSEC_ID , new IpsecCustomizer ( vppApi ) ) ) ; registry . add ( new GenericWriter < > ( SAD_ID , new SadCustomizer ( vppApi ) ) ) ; registry . add ( new GenericWriter < > ( SPD_ID , new SpdCustomizer ( vppApi ) ) ) ; registry . add ( new GenericWriter < > ( SAD_ENTRIES_ID , new SadEntriesCustomizer ( vppApi , sadEntriesMapping ) ) ) ; } }
public void init ( @Nonnull final ModifiableWriterRegistryBuilder registry ) { < |startfocus| > registry . subtreeAdd ( Sets . newHashSet ( InstanceIdentifier . create ( SadEntries . class ) . child ( SourceAddress . class ) , < |endfocus| > InstanceIdentifier . create ( SadEntries . class ) . child ( DestinationAddress . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Ah . class ) . child ( org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . hc2vpp . ipsec . rev181214 . ipsec . sa . ah . grouping . ah . authentication . algorithm . hmac . sha1 . _96 . HmacSha196 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Ah . class ) . child ( org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . hc2vpp . ipsec . rev181214 . ipsec . sa . ah . grouping . ah . authentication . algorithm . hmac . md5 . _96 . HmacMd596 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Authentication . class ) . child ( HmacSha196 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Authentication . class ) . child ( HmacMd596 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes128Cbc . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes192Cbc . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes256Cbc . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( DesCbc . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( TripleDesCbc . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes128Gcm . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes192Gcm . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes256Gcm . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes128Ctr . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes192Ctr . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes256Ctr . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes128Ccm . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes192Ccm . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes256Ccm . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes128Gcm8 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes192Gcm8 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes256Gcm8 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes128Ctr8 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes192Ctr8 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes256Ctr8 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes128Ccm8 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes192Ccm8 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes256Ccm8 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes128Ctr96 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes192Ctr96 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes256Ctr96 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes128Ccm96 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes192Ccm96 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes256Ccm96 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes128Gcm96 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes192Gcm96 . class ) , InstanceIdentifier . create ( SadEntries . class ) . child ( Esp . class ) . child ( Encryption . class ) . child ( Aes256Gcm96 . class ) ) ) ; }
org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . hc2vpp . ipsec . rev181214 . ikev2 . policy . profile . grouping . Authentication . class ) , InstanceIdentifier . create ( Policy . class ) . child ( TrafficSelectors . class ) ) , new GenericListWriter < > ( IKE2_ID . child ( Policy . class ) , new Ikev2PolicyCustomizer ( vppApi ) ) ) ; registry . subtreeAdd ( Sets . newHashSet ( InstanceIdentifier . create ( Identity . class ) . child ( Local . class ) , InstanceIdentifier . create ( Identity . class ) . child ( Remote . class ) ) , < |startfocus| > new GenericWriter < > ( IKE2_ID . child ( Policy . class ) . child ( Identity . class ) , new Ikev2PolicyIdentityCustomizer ( vppApi ) ) ) ; < |endfocus| >
package io . fd . hc2vpp . ipsec ; import com . google . inject . AbstractModule ; import com . google . inject . Singleton ; import com . google . inject . multibindings . Multibinder ; import io . fd . hc2vpp . common . translate . util . MultiNamingContext ; import io . fd . hc2vpp . ipsec . read . IpsecReaderFactory ; import io . fd . hc2vpp . ipsec . write . IpsecWriterFactory ; import io . fd . honeycomb . translate . read . ReaderFactory ; import io . fd . honeycomb . translate . write . WriterFactory ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; /* * < |startfocus| > * Module class instantiating nat plugin components . < |endfocus| > */ public class IpsecModule extends AbstractModule { private static final Logger LOG = LoggerFactory . getLogger ( IpsecModule . class ) ; private static final String SAD_ENTRIES_MAPPING = "sad - entries - mapping" ; @Override protected void configure ( ) { LOG . info ( "Installing IPSec module" ) ; bind ( MultiNamingContext . class ) . toInstance ( new MultiNamingContext ( SAD_ENTRIES_MAPPING , 1 ) ) ; LOG . info ( "Injecting writers factories" ) ; final Multibinder < WriterFactory > writerFactoryBinder = Multibinder . newSetBinder ( binder ( ) , WriterFactory . class ) ; writerFactoryBinder . addBinding ( ) . to ( IpsecWriterFactory . class ) . in ( Singleton . class ) ;
super ( vppApi ) ; IpsecStateSpdsReplyDumpExecutor spdsExecutor = new IpsecStateSpdCustomizer . IpsecStateSpdsReplyDumpExecutor ( vppApi ) ; this . ipsecSpdsReplyDumpManager = new DumpCacheManager . DumpCacheManagerBuilder < IpsecSpdsDetailsReplyDump , Void > ( ) . withExecutor ( spdsExecutor ) . acceptOnly ( IpsecSpdsDetailsReplyDump . class ) . build ( ) ; this . ipsecSpdDetailsReplyDumpManager = new DumpCacheManager . DumpCacheManagerBuilder < IpsecSpdDetailsReplyDump , Void > ( ) . withExecutor ( new IpsecStateSpdCustomizer . IpsecStateSpdDetailsDumpExecutor ( vppApi , spdsExecutor ) ) . acceptOnly ( IpsecSpdDetailsReplyDump . class ) . build ( ) ; < |startfocus| > < |endfocus| >
public void init ( @Nonnull final ModifiableWriterRegistryBuilder registry ) { InstanceIdentifier < Policer > IID = InstanceIdentifier . create ( Policer . class ) ; registry . subtreeAdd ( < |startfocus| > Sets . newHashSet ( IID . child ( ConformAction . class ) , IID . child ( ExceedAction . class ) , IID . child ( ViolateAction . class ) ) , new GenericListWriter < > ( POLICER_IID , new PolicerCustomizer ( vppApi , policerContext ) , new PolicerValidator ( policerContext ) ) ) ; < |endfocus| > }
/* * Copyright ( c ) 2017 Cisco and / or its affiliates . * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at : * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package io . fd . hc2vpp . l3 . write . ipv4 ; import static com . google . common . base . Preconditions . checkNotNull ; import io . fd . hc2vpp . common . translate . util . NamingContext ; import io . fd . honeycomb . translate . write . DataValidationFailedException ; import io . fd . honeycomb . translate . write . Validator ; import io . fd . honeycomb . translate . write . WriteContext ; import javax . annotation . Nonnull ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . vlan . rev190527 . SubinterfaceAugmentation ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . vlan . rev190527 . interfaces . _interface . SubInterfaces ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . vlan . rev190527 . interfaces . _interface . sub . interfaces . SubInterface ; import org . opendaylight . yang . gen . v1 . http . fd . io . hc2vpp . yang . vpp . vlan . rev190527 . interfaces . _interface . sub . interfaces . SubInterfaceKey ; import org . opendaylight . yang . gen . v1 . urn . ietf . params . xml . ns . yang . ietf . interfaces . rev180220 . Interfaces ; import org . opendaylight . yang . gen . v1 . urn . ietf . params . xml . ns . yang . ietf . interfaces . rev180220 . interfaces . Interface ; import org . opendaylight . yang . gen . v1 . urn . ietf . params . xml . ns . yang . ietf . interfaces . rev180220 . interfaces . InterfaceKey ; import org . opendaylight . yangtools . yang . binding . InstanceIdentifier ; public class SubInterfaceValidator implements Validator < SubInterface > { private final NamingContext interfaceContext ; public SubInterfaceValidator ( final NamingContext interfaceContext ) { this . interfaceContext = interfaceContext ; } @Override public void validateWrite ( @Nonnull final InstanceIdentifier < SubInterface > id , @Nonnull final SubInterface dataAfter , @Nonnull final WriteContext writeContext ) throws DataValidationFailedException . CreateValidationFailedException { final String parentInterfaceName = id . firstKeyOf ( Interface . class ) . getName ( ) ; final int parentInterfaceId = interfaceContext . getIndex ( parentInterfaceName , writeContext . getMappingContext ( ) ) ; final int subInterfaceId = dataAfter . getIdentifier ( ) ; if ( subInterfaceId == parentInterfaceId ) { throw new DataValidationFailedException . CreateValidationFailedException ( id , dataAfter , new IllegalArgumentException ( "Sub - interface id cannot be the same as parent interface id" ) ) ; } } @Override public void validateDelete ( @Nonnull final InstanceIdentifier < SubInterface > id , @Nonnull final SubInterface dataBefore , @Nonnull final WriteContext writeContext ) throws DataValidationFailedException . DeleteValidationFailedException { final String parentInterfaceName = id . firstKeyOf ( Interface . class ) . getName ( ) ; final int parentInterfaceId = interfaceContext . getIndex ( parentInterfaceName , writeContext . getMappingContext ( ) ) ; final int subInterfaceId = dataBefore . getIdentifier ( ) ; if ( subInterfaceId == parentInterfaceId ) { throw new DataValidationFailedException . DeleteValidationFailedException ( id , new IllegalArgumentException ( "Sub - interface id cannot be the same as parent interface id" ) ) ; } } }
*/ public static final class StatsConnectionInfo { public final long queueAddress ; public final int clientIndex ; public final int status ; // FIXME throw exception instead public final int pid ; public StatsConnectionInfo ( long queueAddress , int clientIndex , int status , int pid ) { this . queueAddress = queueAddress ; this . clientIndex = clientIndex ; this . status = status ; this . pid = pid ; } } private static native StatsConnectionInfo statsConnect ( String clientName ) ; private static native void statsDisconnect ( ) ; < |startfocus| > < |endfocus| > }
public void onInterfaceStatisticsDetails ( final io . fd . jvpp . stats . dto . InterfaceStatisticsDetails reply ) { io . fd . jvpp . stats . callback . InterfaceStatisticsDetailsCallback callback ; final int replyId = reply . context ; if ( LOG . isLoggable ( java . util . logging . Level . FINE ) ) { LOG . fine ( String . format ( "Received InterfaceStatisticsDetails event message : % s" , reply ) ) ; } synchronized ( requests ) { callback = ( io . fd . jvpp . stats . callback . InterfaceStatisticsDetailsCallback ) requests . remove ( replyId ) ; } if ( callback != null ) { callback . onInterfaceStatisticsDetails ( reply ) ; } } < |startfocus| > < |endfocus| > }
* * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package io . fd . jvpp . stats . dto ; /* * * < p > This class represents request DTO . */ public final class InterfaceStatisticsDump implements io . fd . jvpp . dto . JVppDump { < |startfocus| > < |endfocus| > @Override @io . fd . jvpp . coverity . SuppressFBWarnings ( "UWF_UNWRITTEN_PUBLIC_OR_PROTECTED_FIELD" ) public int hashCode ( ) { return java . util . Objects . hash ( ) ; } @Override public boolean equals ( final Object o ) { if ( this == o ) { return true ; } if ( o == null || getClass ( ) != o . getClass ( ) ) { return false ; } return true ; } @Override public String toString ( ) { return "InterfaceStatisticsDump { } " ; }
} synchronized ( requests ) { CompletableFuture < ? extends JVppReply < ? > > replyFuture = requests . get ( contextId ) ; if ( replyFuture == null ) { // reply not received yet , put new future to map replyDumpFuture = new CompletableDumpFuture < > ( contextId , emptyReplyDump ) ; requests . put ( contextId , replyDumpFuture ) ; } else { // reply already received , save existing future replyDumpFuture = ( CompletableDumpFuture < DUMP > ) replyFuture ; } } < |startfocus| > < |endfocus| > synchronized ( requests ) { // reply already received , complete future replyDumpFuture . complete ( replyDumpFuture . getReplyDump ( ) ) ; requests . remove ( contextId ) ; } // TODO in case of timeouts / missing replies , requests from the map are not removed // consider adding cancel method , that would remove requests from the map and cancel // associated replyCompletableFuture return replyDumpFuture ; } catch ( VppInvocationException ex ) { final CompletableFuture < DUMP > replyCompletableFuture = new CompletableFuture < > ( ) ; replyCompletableFuture . completeExceptionally ( ex ) ; return replyCompletableFuture ; } }
. get ( replyId ) ; if ( completableFuture == null ) { // reply received before writer created future , // create new future , and put into map to notify sender that reply is already received , // following details replies will add information to this future completableFuture = new io . fd . jvpp . stats . future . AbstractFutureJVppInvoker . CompletableDumpFuture < > ( replyId , new InterfaceStatisticsDetailsReplyDump ( ) ) ; requests . put ( replyId , completableFuture ) ; } completableFuture . getReplyDump ( ) . interfaceStatisticsDetails = reply ; } } < |startfocus| > < |endfocus| > }
public InterfaceStatisticsCustomizer ( final NamingContext ifcNamingCtx , final FutureJVppStatsFacade jvppStats , final InterfaceStatisticsCollectionManager statisticsManager ) { this . ifcNamingCtx = checkNotNull ( ifcNamingCtx , "Naming context should not be null" ) ; this . jvppStats = checkNotNull ( jvppStats , "JVpp Stats facade should not be null" ) ; < |startfocus| > this . statisticsManager = checkNotNull ( statisticsManager , "Statistics Collection Manager should not be null" ) ; < |endfocus| >
. setInMulticastPkts ( new Counter64 ( BigInteger . valueOf ( detail . inMulticastPkts ) ) ) . setInBroadcastPkts ( new Counter64 ( BigInteger . valueOf ( detail . inBroadcastPkts ) ) ) . setInErrors ( new Counter32 ( new Long ( detail . inErrors ) ) ) ; } } } @Override public void merge ( @Nonnull final Builder < ? extends DataObject > builder , @Nonnull final Statistics statistics ) { ( ( InterfaceBuilder ) builder ) . setStatistics ( statistics ) ; } private InterfaceStatisticsDetails getStatisticsDump ( InstanceIdentifier < Statistics > id ) throws ReadFailedException { LOG . info ( "Sending InterfaceStatisticsDump request . . . " ) ; final InterfaceStatisticsDump request = new InterfaceStatisticsDump ( ) ; final Future < InterfaceStatisticsDetailsReplyDump > replyFuture = jvppStats . interfaceStatisticsDump ( request ) . toCompletableFuture ( ) ; final InterfaceStatisticsDetailsReplyDump reply ; try { reply = replyFuture . get ( ) ; } catch ( Exception e ) { throw new ReadFailedException ( id , e ) ; } if ( reply == null || reply . interfaceStatisticsDetails == null ) { throw new ReadFailedException ( id , new IllegalStateException ( "Received null response for empty dump : " + reply ) ) ; } return reply . interfaceStatisticsDetails ; } }
public L2Validator ( final NamingContext interfaceContext , final NamingContext bridgeDomainContext ) { checkNotNull ( interfaceContext , "interfaceContext should not be null" ) ; < |startfocus| > checkNotNull ( bridgeDomainContext , "bridgeDomainContext should not be null" ) ; < |endfocus| >
public SubInterfaceL2Validator ( final NamingContext interfaceContext , final NamingContext bridgeDomainContext ) { checkNotNull ( interfaceContext , "interfaceContext should not be null" ) ; < |startfocus| > checkNotNull ( bridgeDomainContext , "bridgeDomainContext should not be null" ) ; < |endfocus| >
public VxlanValidator ( @Nonnull final NamingContext interfaceNamingContext , @Nonnull final DisabledInterfacesManager disabledInterfacesManager ) { checkNotNull ( interfaceNamingContext , "interfaceContext should not be null" ) ; < |startfocus| > checkNotNull ( disabledInterfacesManager , "DisabledInterfacesManager should not be null" ) ; < |endfocus| >
< |startfocus| > private void validateVxlan ( final Vxlan data ) { < |endfocus| > checkNotNull ( data . getSrc ( ) , "Source cannot be null" ) ; checkNotNull ( data . getDst ( ) , "Destination cannot be null" ) ; if ( data . getSrc ( ) . getIpv4AddressNoZone ( ) == null ) { checkArgument ( data . getDst ( ) . getIpv4AddressNoZone ( ) == null , "Inconsistent ip addresses : % s , % s" , data . getSrc ( ) , data . getDst ( ) ) ; } else { checkArgument ( data . getDst ( ) . getIpv6AddressNoZone ( ) == null , "Inconsistent ip addresses : % s , % s" , data . getSrc ( ) , data . getDst ( ) ) ; } checkArgument ( data . getEncapVrfId ( ) != null && data . getEncapVrfId ( ) . getValue ( ) != null , "encap - vrf - id is mandatory but was not given" ) ; checkNotNull ( data . getVni ( ) , "VNI cannot be null" ) ;
< |startfocus| > public String getTxtProjectName ( ) { return mProjectNameResult ; < |endfocus| >
< |startfocus| > public String getTxtProjectID ( ) { return mTxtProjectID . getText ( ) ; } < |endfocus| >
< |startfocus| > public String getTxtProjectPath ( ) { return mTxtProjectPath . getText ( ) ; } < |endfocus| >
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * */ import javax . annotation . PostConstruct ; import org . eclipse . jface . viewers . TreeViewer ; import org . eclipse . swt . SWT ; import org . eclipse . swt . layout . FormAttachment ; import org . eclipse . swt . layout . FormData ; import org . eclipse . swt . layout . FormLayout ; import org . eclipse . swt . widgets . Composite ; import org . eclipse . swt . widgets . Tree ; < |startfocus| > import com . samsung . dali . modelconverter . view . dialogs . TizenPathDialog ; < |endfocus| > public class SceneGraphPart { @PostConstruct public void createComposite ( Composite parent ) { TizenPathDialog . VerifyTizenPath ( parent . getShell ( ) , false ) ; parent . setLayout ( new FormLayout ( ) ) ; TreeViewer treeViewer = new TreeViewer ( parent , SWT . BORDER ) ; Tree tree = treeViewer . getTree ( ) ; FormData fd_tree = new FormData ( ) ; fd_tree . bottom = new FormAttachment ( 100 , - 10 ) ; fd_tree . right = new FormAttachment ( 100 , - 5 ) ; fd_tree . top = new FormAttachment ( 0 , 5 ) ; fd_tree . left = new FormAttachment ( 0 , 5 ) ; tree . setLayoutData ( fd_tree ) ; } }
* See the License for the specific language governing permissions and * limitations under the License . * */ package com . ibm . disni . nvmef ; import java . io . IOException ; import java . net . URI ; import java . nio . ByteBuffer ; import com . ibm . disni . DiSNIEndpoint ; import com . ibm . disni . nvmef . spdk .* ; public class NvmeEndpoint implements DiSNIEndpoint { private final NvmeEndpointGroup group ; private NvmeQueuePair queuePair ; private NvmeNamespace namespace ; private NvmeController controller ; private volatile boolean open ; private NvmeControllerOptions controllerOptions ; < |startfocus| > < |endfocus| > public NvmeEndpoint ( NvmeEndpointGroup group , NvmfConnection newConnection ) { this . group = group ; this . queuePair = null ; this . namespace = null ; this . open = newConnection != null ; } // rdma :/ / < host > : < port > // nvmef : :/ / < host > : < port >/ controller / namespace" public synchronized void connect ( URI uri ) throws IOException { if ( open ) { return ; } NvmeResourceIdentifier nvmeResource = NvmeResourceIdentifier . parse ( uri ) ; NvmeTransportId transportId = nvmeResource . toTransportId ( ) ; this . controller = group . probe ( transportId , nvmeResource . getController ( ) ) ;
return namespace ; } NvmeQueuePair getQueuePair ( ) { return queuePair ; } public boolean isOpen ( ) { return open ; } public synchronized void close ( ) throws IOException , InterruptedException { queuePair . free ( ) ; open = false ; } public synchronized int processCompletions ( long [ ] completed ) throws IOException { return queuePair . processCompletions ( completed ) ; } public int getSectorSize ( ) { return namespace . getSectorSize ( ) ; } public long getNamespaceSize ( ) { return namespace . getSize ( ) ; } < |startfocus| > < |endfocus| > public int getMaxTransferSize ( ) { return namespace . getMaxIOTransferSize ( ) ; } public int getIOQueueSize ( ) { return controllerOptions . getIOQueueSize ( ) ; } public void keepAlive ( ) throws IOException { controller . keepAlive ( ) ; } }
this . open = false ; } // rdma :/ / < host > : < port > // nvmef : :/ / < host > : < port >/ controller / namespace" public synchronized void connect ( URI uri ) throws IOException { if ( open ) { return ; } NvmeResourceIdentifier nvmeResource = NvmeResourceIdentifier . parse ( uri ) ; NvmeTransportId transportId = nvmeResource . toTransportId ( ) ; NvmeController nvmecontroller = group . probe ( transportId , nvmeResource . getController ( ) ) ; this . namespace = nvmecontroller . getNamespace ( nvmeResource . getNamespace ( ) ) ; this . queuePair = nvmecontroller . allocQueuePair ( ) ; this . open = true ; < |startfocus| > this . controllerOptions = nvmecontroller . getOptions ( ) ; < |endfocus| > } private enum Operation { READ , WRITE } private NvmeCommand op ( Operation op , ByteBuffer buffer , long linearBlockAddress ) throws IOException { if ( open ) { throw new IOException ( "endpoint is closed" ) ; } if ( buffer . remaining ( ) % namespace . getSectorSize ( ) != 0 ) { throw new IOException ( "Remaining buffer a multiple of sector size" ) ; } IOCompletion completion = new IOCompletion ( ) ; return new NvmeCommand ( this , buffer , linearBlockAddress , completion , op == Operation . WRITE ) ; }
package com . samsung . dali . modelconverter . data . document ; import com . fasterxml . jackson . annotation . JsonIgnore ; public class Camera { < |startfocus| > @JsonIgnore < |endfocus| > public int getId ( ) { return mId ; } public void setId ( int id ) { mId = id ; } @Override public String toString ( ) { return "Camera " + mId ; } public double getFov ( ) { return mFov ; } public void setFov ( double fov ) { mFov = fov ; } public double getNear ( ) { return mNear ; } public void setNear ( double near ) { mNear = near ; } public double getFar ( ) { return mFar ; } public void setFar ( double far ) { mFar = far ; } public double [ ] getMatrix ( ) { return mMatrix ; } public void setMatrix ( double [ ] mtx ) { assert mtx == null || mtx . length == 16 ; mMatrix = mtx ; } private double mFov ; private double mNear ; private double mFar ;
} public ArrayList < Mesh > getMeshes ( ) { return mMeshes ; } public void setMeshes ( ArrayList < Mesh > meshes ) { mMeshes = meshes ; } public ArrayList < Material > getMaterials ( ) { return mMaterials ; } public void setMaterials ( ArrayList < Material > materials ) { mMaterials = materials ; } public ArrayList < Shader > getShaders ( ) { return mShaders ; } public void setShaders ( ArrayList < Shader > shaders ) { mShaders = shaders ; } < |startfocus| > @JsonProperty ( "environment" ) < |endfocus| > public ArrayList < Environment > getEnvironments ( ) { return mEnvironments ; } public void setEnvironments ( ArrayList < Environment > environments ) { mEnvironments = environments ; } public void setNodeParents ( ) { for ( Node n : mNodes ) { for ( Integer i : n . getChildIds ( ) ) { mNodes . get ( i . intValue ( ) ) . setParent ( n ) ; } } } public void setIds ( ) { int id = 1 ; for ( Scene s : mScenes ) { s . setId ( id ) ; ++ id ; }
kage com . samsung . dali . modelconverter . data . document ; import com . fasterxml . jackson . annotation . JsonProperty ; public class Environment { < |startfocus| > @JsonProperty ( "cubeSpecular" ) < |endfocus| > public String getSpecularPath ( ) { return mSpecularPath ; } public void setSpecularPath ( String path ) { mSpecularPath = path ; } @JsonProperty ( "cubeDiffuse" ) public String getDiffusePath ( ) { return mDiffusePath ; } public void setDiffusePath ( String path ) { mDiffusePath = path ; } private String mSpecularPath ; private String mDiffusePath ; }
public void setMatrix ( double [ ] data ) { < |startfocus| > if ( data != null ) { mMatrix = MatrixHelper . createMatrix ( data ) ; } else { // Null matrix means identity . mMatrix = MatrixHelper . createMatrix ( ) ; } < |endfocus| >
kage com . samsung . dali . modelconverter . data . document ; import com . fasterxml . jackson . annotation . JsonProperty ; public class Asset { public String getVersion ( ) { return mVersion ; } public void setVersion ( String version ) { mVersion = version ; } < |startfocus| > @JsonProperty ( "version" ) < |endfocus| > private String mVersion ; }
} public double getNear ( ) { return mNear ; } public void setNear ( double near ) { mNear = near ; } public double getFar ( ) { return mFar ; } public void setFar ( double far ) { mFar = far ; } public double [ ] getMatrix ( ) { return mMatrix ; } public void setMatrix ( double [ ] mtx ) { assert mtx == null || mtx . length == 16 ; mMatrix = mtx ; } < |startfocus| > @JsonProperty ( "fov" ) < |endfocus| > private double mFov ; @JsonProperty ( "near" ) private double mNear ; @JsonProperty ( "far" ) private double mFar ; @JsonProperty ( "matrix" ) private double [ ] mMatrix = MatrixHelper . createMatrix ( ) ; @JsonIgnore private int mId ; }
if ( rootId != null ) { Node n = getNodes ( ) . get ( rootId . intValue ( ) ) ; n . collect ( this , "" , map ) ; } } return map ; } public List < Node > getNodeChildren ( Node n ) { ArrayList < Node > kids = new ArrayList < Node > ( ) ; for ( Integer i : n . getChildIds ( ) ) { kids . add ( getNodes ( ) . get ( i . intValue ( ) ) ) ; } return kids ; } @JsonIgnoreProperties ( ignoreUnknown = true ) < |startfocus| > @JsonProperty ( "asset" ) < |endfocus| > private Asset mAsset = new Asset ( ) ; @JsonProperty ( "scene" ) private int mDefaultSceneId = 0 ; @JsonProperty ( "scenes" ) private ArrayList < Scene > mScenes = new ArrayList < Scene > ( ) ; @JsonProperty ( "nodes" ) private ArrayList < Node > mNodes = new ArrayList < Node > ( ) ; @JsonProperty ( "cameras" ) private ArrayList < Camera > mCameras = new ArrayList < Camera > ( ) ; @JsonProperty ( "skybox" ) private Skybox mSkybox ; @JsonProperty ( "meshes" ) private ArrayList < Mesh > mMeshes = new ArrayList < Mesh > ( ) ; @JsonProperty ( "materials" ) private ArrayList < Material > mMaterials = new ArrayList < Material > ( ) ;
} @JsonSetter ( "nodes" ) public void setNodes ( ArrayList < Integer > nodes ) { if ( nodes . size ( ) != 1 ) { throw new IllegalArgumentException ( "Scene . nodes must be an array of a single node index . Sorry about that . " ) ; } mRootId = nodes . get ( 0 ) . intValue ( ) ; } @JsonGetter ( "nodes" ) public ArrayList < Integer > getNodes ( ) { ArrayList < Integer > nodes = new ArrayList < Integer > ( ) ; nodes . add ( new Integer ( mRootId ) ) ; return nodes ; } < |startfocus| > @JsonIgnore < |endfocus| > private int mId = - 1 ; @JsonIgnore private boolean mIsOrphan = false ; @JsonIgnore // custom setter / getter provided -- json representation is an array of a // single integer element . private Integer mRootId = - 1 ; }
} } else { throw new IllegalArgumentException ( "Unknown type : " + value . getClass ( ) . getName ( ) ) ; } } @JsonAnyGetter public Map < String , Object > get ( ) { Map < String , Object > values = new TreeMap < String , Object > ( ) ; for ( Entry < String , Uniform > u : mUniforms . entrySet ( ) ) { values . put ( u . getKey ( ) , u . getValue ( ) . getValue ( ) ) ; } return values ; } < |startfocus| > @JsonProperty ( "vertex" ) < |endfocus| > private String mVertexPath ; @JsonProperty ( "fragment" ) private String mFragmentPath ; @JsonProperty ( "renderMode" ) private int mRenderMode ; @JsonIgnore // custom any getter / setter provided - uniforms may be arbitrary sibling // elements to vertex path / fragment path / render mode . private Map < String , Uniform > mUniforms ; }
kage com . samsung . dali . modelconverter . data . document ; import com . fasterxml . jackson . annotation . JsonProperty ; public class Skybox { public String getTexture ( ) { return mTexture ; } public void setTexture ( String mTexture ) { this . mTexture = mTexture ; } < |startfocus| > @JsonProperty ( "texture" ) < |endfocus| > private String mTexture ; }
* * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . * */ public class ModelExporter { public static void initialise ( ) { < |startfocus| > System . loadLibrary ( "model - exporter - jni" ) ; < |endfocus| > } /* * * @brief Performs model export , loading a . dae file , and writing . bin and * . dli files . * @param inputFile - path to the . dae file to process . Required . * @param outputName - the name and path to save the . dli and . bin files to . * Optional . Will use the input path and name if omitted .
import com . fasterxml . jackson . annotation . JsonIgnore ; import com . samsung . dali . modelconverter . data . document . property . Property ; public class Camera implements Property . Provider { @JsonIgnore public int getId ( ) { return mId ; } public void setId ( int id ) { mId = id ; } @Override public String toString ( ) { return "Camera " + mId ; } public double getFov ( ) { return mFov ; } public void setFov ( Number fov ) { mFov = fov . doubleValue ( ) ; } < |startfocus| > < |endfocus| > public double getNear ( ) { return mNear ; } public void setNear ( Number near ) { mNear = near . doubleValue ( ) ; } public double getFar ( ) { return mFar ; } public void setFar ( Number far ) { mFar = far . doubleValue ( ) ; } public double [ ] getMatrix ( ) { return mMatrix ; } public void setMatrix ( double [ ] mtx ) { assert mtx == null || mtx . length == 16 ; mMatrix = mtx ; } @Override
for ( int i = 0 ; i < 3 ; ++ i ) { matrix [ 12 + i ] = translation [ i ] ; } } public static double [ ] getRotation ( double [ ] matrix ) { double [ ] rotation = new double [ ] { Math . atan2 ( matrix [ 6 ] , matrix [ 10 ] ) , Math . atan2 ( - matrix [ 2 ] , Math . sqrt ( matrix [ 6 ] * matrix [ 6 ] + matrix [ 10 ] * matrix [ 10 ] ) ) , Math . atan2 ( matrix [ 1 ] , matrix [ 0 ] ) } ; return rotation ; } < |startfocus| > // TODO : public static void setRotation ( double [ ] rotation , double [ ] matrix ) < |endfocus| > public static double [ ] getScale ( double [ ] matrix ) { double [ ] scale = new double [ ] { getColumnMagnitude ( matrix , 0 ) , getColumnMagnitude ( matrix , 1 ) , getColumnMagnitude ( matrix , 2 ) } ; return scale ; } public static void setScale ( double [ ] scale , double [ ] matrix ) { double [ ] scaleCurr = getScale ( matrix ) ; for ( int i = 0 ; i < 3 ; ++ i ) { scale [ i ] /= scaleCurr [ i ] ; }
} public static SceneGraphPart getSceneGraphPart ( ) { if ( SceneGraphPart . sActiveInstance == null ) { createPart ( "com . samsung . dali . modelconverter . part . scenegraph" ) ; assert SceneGraphPart . sActiveInstance != null ; } return SceneGraphPart . sActiveInstance ; } public static NodePropertiesPart getNodePropertiesPart ( ) { if ( NodePropertiesPart . sActiveInstance == null ) { createPart ( "com . samsung . dali . modelconverter . part . nodeproperties" ) ; assert NodePropertiesPart . sActiveInstance != null ; } return NodePropertiesPart . sActiveInstance ; } < |startfocus| > static void createPart ( String id ) { < |endfocus| > Bundle bundle = FrameworkUtil . getBundle ( EPartService . class ) ; BundleContext bundleContext = bundle . getBundleContext ( ) ; IEclipseContext eclipseContext = EclipseContextFactory . getServiceContext ( bundleContext ) ; EPartService partService = ( EPartService ) eclipseContext . get ( EPartService . class ) ; partService . showPart ( id , PartState . CREATE ) ; } }
public void createComposite ( Composite parent ) { parent . setLayout ( new GridLayout ( 1 , false ) ) ; mParent = parent ; resetProperties ( ) ; < |startfocus| > < |endfocus| > sActiveInstance = this ;
public void populate ( SceneGraphContentProvider provider , SceneGraphSelectionChangedListener selectionChangedListener ) { 	mTree . removeAll ( ) ; 	if ( mSelectionChangedListener != null ) { 		mTreeViewer . removeSelectionChangedListener ( mSelectionChangedListener ) ; 	 } 	mTreeViewer . addSelectionChangedListener ( selectionChangedListener ) ; 	 < |startfocus| > 	 < |endfocus| > 	mTreeViewer . setContentProvider ( provider ) ; 	mTreeViewer . setInput ( provider . getDocument ( ) ) ; 	mTreeViewer . refresh ( ) ; }
GridData gd_mOptions = new GridData ( SWT . LEFT , SWT . CENTER , false , false , 1 , 1 ) ; gd_mOptions . widthHint = 240 ; mOptions . setLayoutData ( gd_mOptions ) ; } public IdPropertyWidget setRange ( Collection < ? > values ) { mOptions . removeAll ( ) ; for ( Object o : values ) { mOptions . add ( o . toString ( ) ) ; } return this ; } public IdPropertyWidget setWritable ( boolean isWritable ) { mOptions . setEnabled ( isWritable ) ; return this ; } < |startfocus| > < |endfocus| > public IdPropertyWidget setSelection ( int i ) { mOptions . select ( i ) ; mOptions . update ( ) ; return this ; } private Combo mOptions ; }
package com . samsung . dali . modelconverter . view . widgets ; import org . eclipse . swt . SWT ; import org . eclipse . swt . layout . GridData ; import org . eclipse . swt . widgets . Composite ; import org . eclipse . swt . widgets . Text ; /* < |startfocus| > * A widget for a property whose value can be presented as a text entry . < |endfocus| > */ public class TextPropertyWidget extends PropertyWidgetBase { public TextPropertyWidget ( Composite parent , int style ) { super ( parent , style ) ; mText = new Text ( parent , SWT . BORDER ) ; GridData gd_mText = new GridData ( SWT . LEFT , SWT . CENTER , false , false , 1 , 1 ) ; gd_mText . widthHint = 200 ; mText . setLayoutData ( gd_mText ) ; } public TextPropertyWidget setWritable ( boolean isWritable ) { mText . setEnabled ( isWritable ) ; return this ; } public TextPropertyWidget setValue ( String value ) { mText . setText ( value ) ; return this ; } private Text mText ; }
mRx . setText ( df . format ( rotation [ 0 ] ) ) ; mRy . setText ( df . format ( rotation [ 1 ] ) ) ; mRz . setText ( df . format ( rotation [ 2 ] ) ) ; return this ; } public TransformPropertyWidget setWritable ( boolean isWritable ) { mTx . setEnabled ( isWritable ) ; mTy . setEnabled ( isWritable ) ; mTz . setEnabled ( isWritable ) ; mSx . setEnabled ( isWritable ) ; mSy . setEnabled ( isWritable ) ; mSz . setEnabled ( isWritable ) ; mRx . setEnabled ( isWritable ) ; mRy . setEnabled ( isWritable ) ; mRz . setEnabled ( isWritable ) ; return this ; } < |startfocus| > < |endfocus| > private Text mTx ; private Text mTy ; private Text mTz ; private Text mSx ; private Text mSy ; private Text mSz ; private Text mRx ; private Text mRy ; private Text mRz ; }
public class Document { static public Document fromDli ( String dli ) throws JsonParseException , JsonMappingException , IOException { ObjectMapper mapper = new ObjectMapper ( ) ; mapper . disable ( DeserializationFeature . FAIL_ON_UNKNOWN_PROPERTIES ) ; Document d = mapper . readValue ( dli , Document . class ) ; // TODO : the following could perhaps be on an option to fromDli ( ) . d . setNodeParents ( ) ; d . setIds ( ) ; d . organizeOrphans ( ) ; return d ; } public String toDliString ( ) throws JsonProcessingException { ObjectMapper mapper = new ObjectMapper ( ) ; < |startfocus| > < |endfocus| > DefaultPrettyPrinter . Indenter indenter = new DefaultIndenter ( " " , DefaultIndenter . SYS_LF ) ; DefaultPrettyPrinter printer = new DefaultPrettyPrinter ( ) ; printer . indentObjectsWith ( indenter ) ; return mapper . writer ( printer ) . writeValueAsString ( this ) ; } public Asset getAsset ( ) { return mAsset ; } public void setAsset ( Asset asset ) { mAsset = asset ; } @JsonProperty ( "scene" ) public int getDefaultSceneId ( ) { return mDefaultSceneId ; } public void setDefaultSceneId ( int defaultSceneId ) { mDefaultSceneId = defaultSceneId ; }
public static void execute ( Shell shell , List < String > outProfiles ) { assert outProfiles != null ; OutputPart op = GlobalParts . getOutputPart ( ) ; LoggingProcessRunner lpr = LoggingProcessRunner . create ( shell . getDisplay ( ) , op . getText ( ) ) ; < |startfocus| > lpr . addCommand ( GlobalData . get ( ) . getTizenPath ( ) + " security - profiles list" , new LoggingProcessRunner . Parser ( ) { < |endfocus| > @Override public void parseLine ( String line ) { if ( mCare ) { if ( ! line . isEmpty ( ) ) { int iSpace = line . indexOf ( ' ' ) ; if ( iSpace != - 1 ) { line = line . substring ( 0 , iSpace ) ; } outProfiles . add ( line ) ; } } else { mCare = line . startsWith ( " [ Profile Name ] " ) ; } } private boolean mCare = false ; } ) . run ( ) ; }
package com . samsung . dali . modelconverter . controller ; import java . util . ArrayList ; import org . eclipse . jface . viewers . ITreeContentProvider ; import com . samsung . dali . modelconverter . data . document . Document ; /* < |startfocus| > * Provides descriptions of the meshes . < |endfocus| > */ public class ResourceContentProvider implements ITreeContentProvider { public ResourceContentProvider ( Document doc , Class < ? > type ) { mDocument = doc ; mType = type ; } public Object getDocument ( ) { return mDocument ; } /* * Get the top level nodes from an element , which should only be the Document * that the provider was created with . The nodes are meshes . */ @Override public Object [ ] getElements ( Object inputElement ) { assert inputElement == mDocument ; ArrayList < Object > kids = new ArrayList < Object > ( ) ; return kids . toArray ( ) ; } @Override public Object [ ] getChildren ( Object parentElement ) { return null ; } @Override public Object getParent ( Object element ) { return null ; } @Override public boolean hasChildren ( Object element ) { return false ; } private Document mDocument ;
import org . eclipse . jface . viewers . ITreeContentProvider ; import com . samsung . dali . modelconverter . data . document . Document ; /* * Provides descriptions of the meshes . */ public class ResourceContentProvider implements ITreeContentProvider { public ResourceContentProvider ( Document doc , Class < ? > type ) { mDocument = doc ; mType = type ; } public Object getDocument ( ) { return mDocument ; } /* < |startfocus| > * Get the top level nodes from an element , which should only be the Document * that the provider was created with . The nodes are meshes . < |endfocus| > */ @Override public Object [ ] getElements ( Object inputElement ) { assert inputElement == mDocument ; ArrayList < Object > kids = new ArrayList < Object > ( ) ; return kids . toArray ( ) ; } @Override public Object [ ] getChildren ( Object parentElement ) { return null ; } @Override public Object getParent ( Object element ) { return null ; } @Override public boolean hasChildren ( Object element ) { return false ; } private Document mDocument ; private Class < ? > mType ; }
* See the License for the specific language governing permissions and * limitations under the License . * */ import javax . annotation . PostConstruct ; import org . eclipse . jface . viewers . ISelectionChangedListener ; import org . eclipse . jface . viewers . TreeViewer ; import org . eclipse . swt . SWT ; import org . eclipse . swt . widgets . Composite ; import org . eclipse . swt . widgets . Tree ; import com . samsung . dali . modelconverter . controller . PropertyProviderSelectionChangedListener ; < |startfocus| > import com . samsung . dali . modelconverter . controller . ResourceContentProvider ; import com . samsung . dali . modelconverter . data . document . Animation ; < |endfocus| > public class AnimationPart { public static final String sId = "com . samsung . dali . modelconverter . part . animations" ; @PostConstruct public void createComposite ( Composite parent ) { mTreeViewer = new TreeViewer ( parent , SWT . BORDER ) ; mTree = mTreeViewer . getTree ( ) ; } public void populate ( ResourceContentProvider < Animation > provider , PropertyProviderSelectionChangedListener listener ) { mTree . removeAll ( ) ; if ( mSelectionChangedListener != null ) { mTreeViewer . removeSelectionChangedListener ( mSelectionChangedListener ) ; } mTreeViewer . addSelectionChangedListener ( listener ) ; mTreeViewer . setContentProvider ( provider ) ; mTreeViewer . setInput ( null ) ; mTreeViewer . refresh ( ) ; }
< |startfocus| > public void populate ( ITreeContentProvider provider , PropertyProviderSelectionChangedListener listener ) { < |endfocus| > mTree . removeAll ( ) ; if ( mSelectionChangedListener != null ) { mTreeViewer . removeSelectionChangedListener ( mSelectionChangedListener ) ; } mTreeViewer . addSelectionChangedListener ( listener ) ; mTreeViewer . setContentProvider ( provider ) ; mTreeViewer . setInput ( null ) ; mTreeViewer . refresh ( ) ;
mAttributes = a ; } public String getAttributeFlags ( ) { String flags = "" ; if ( mIndices != null ) { flags += "I" ; } if ( mUvs != null ) { flags += "U" ; } if ( mNormals != null ) { flags += "N" ; } if ( mTangents != null ) { flags += "T" ; } if ( mBitangents != null ) { flags += "B" ; } return flags ; } < |startfocus| > public BufferRef getIndices ( ) { return mIndices ; } public void setIndices ( BufferRef br ) { mIndices = br ; } public BufferRef getPositions ( ) { return mPositions ; } public void setPositions ( BufferRef br ) { mPositions = br ; } public BufferRef getNormals ( ) { return mNormals ; } public void setNormals ( BufferRef br ) {
public void provideProperties ( Document context , Property . IReceiver receiver ) { try { for ( int index = 0 ; index < mTextures . length ; index ++ ) { < |startfocus| > receiver . register ( "Texture" + ( index + 1 ) , new Property ( this , "TextureArray" , Property . Type . String , true , null , new ArrayElementSetter ( index ) , String [ ] . class ) ) ; < |endfocus| > } } catch ( NoSuchFieldException | NoSuchMethodException e ) { // TODO Auto - generated catch block e . printStackTrace ( ) ; }
// 1 change to the code // 2 change to the code // 3 change to the code // 4 change to the code // 5 change to the code // 6 change to the code // 7 change to the code // 8 change to the code // 9 change to the code // 10 change to the code // 11 change to the code // 12 change to the code // 13 change to the code // 14 change to the code // 15 change to the code // 16 change to the code // 17 change to the code // 18 change to the code // 19 change to the code // 20 change to the code // 21 change to the code // 22 change to the code // 23 change to the code // 24 change to the code // 25 change to the code // 26 change to the code // 27 change to the code // 28 change to the code // 29 change to the code // 30 change to the code // 31 change to the code // 32 change to the code // 33 change to the code // 34 change to the code // 35 change to the code // 36 change to the code // 37 change to the code // 38 change to the code // 39 change to the code // 40 change to the code // 41 change to the code // 42 change to the code // 43 change to the code // 44 change to the code // 45 change to the code // 46 change to the code // 47 change to the code // 48 change to the code // 49 change to the code // 50 change to the code // 51 change to the code // 52 change to the code // 53 change to the code // 54 change to the code // 55 change to the code // 56 change to the code // 57 change to the code // 58 change to the code // 59 change to the code // 60 change to the code // 61 change to the code // 62 change to the code // 63 change to the code // 64 change to the code // 65 change to the code // 66 change to the code // 67 change to the code // 68 change to the code // 69 change to the code // 70 change to the code // 71 change to the code // 72 change to the code // 73 change to the code // 74 change to the code // 75 change to the code // 76 change to the code // 77 change to the code // 78 change to the code // 79 change to the code // 80 change to the code // 81 change to the code // 82 change to the code // 83 change to the code // 84 change to the code // 85 change to the code // 86 change to the code // 87 change to the code // 88 change to the code // 89 change to the code // 90 change to the code // 91 change to the code // 92 change to the code // 93 change to the code // 94 change to the code // 95 change to the code // 96 change to the code // 97 change to the code // 98 change to the code // 99 change to the code // 100 change to the code // 101 change to the code // 102 change to the code // 103 change to the code // 104 change to the code // 105 change to the code // 106 change to the code // 107 change to the code // 108 change to the code // 109 change to the code // 110 change to the code // 111 change to the code // 112 change to the code // 113 change to the code // 114 change to the code // 115 change to the code // 116 change to the code // 117 change to the code // 118 change to the code // 119 change to the code // 120 change to the code // 121 change to the code // 122 change to the code // 123 change to the code // 124 change to the code // 125 change to the code // 126 change to the code // 127 change to the code // 128 change to the code // 129 change to the code // 130 change to the code // 131 change to the code // 132 change to the code // 133 change to the code // 134 change to the code // 135 change to the code // 136 change to the code // 137 change to the code // 138 change to the code // 139 change to the code // 140 change to the code // 141 change to the code // 142 change to the code // 143 change to the code // 144 change to the code // 145 change to the code // 146 change to the code // 147 change to the code // 148 change to the code // 149 change to the code // 150 change to the code // 151 change to the code // 152 change to the code // 153 change to the code // 154 change to the code // 155 change to the code // 156 change to the code // 157 change to the code // 158 change to the code // 159 change to the code // 160 change to the code // 161 change to the code // 162 change to the code // 163 change to the code // 164 change to the code // 165 change to the code // 166 change to the code // 167 change to the code // 168 change to the code // 169 change to the code // 170 change to the code // 171 change to the code // 172 change to the code // 173 change to the code // 174 change to the code // 175 change to the code // 176 change to the code // 177 change to the code // 178 change to the code // 179 change to the code // 180 change to the code // 181 change to the code // 182 change to the code // 183 change to the code // 184 change to the code // 185 change to the code // 186 change to the code // 187 change to the code // 188 change to the code // 189 change to the code // 190 change to the code // 191 change to the code // 192 change to the code // 193 change to the code // 194 change to the code // 195 change to the code // 196 change to the code // 197 change to the code // 198 change to the code // 199 change to the code // 200 change to the code // 201 change to the code // 202 change to the code // 203 change to the code // 204 change to the code // 205 change to the code // 206 change to the code // 207 change to the code // 208 change to the code // 209 change to the code // 210 change to the code // 211 change to the code // 212 change to the code // 213 change to the code // 214 change to the code // 215 change to the code // 216 change to the code // 217 change to the code // 218 change to the code // 219 change to the code // 220 change to the code // 221 change to the code // 222 change to the code // 223 change to the code // 224 change to the code
String issuanceProtCertNick = cmd . getOptionValue ( "n" ) ; String output = cmd . getOptionValue ( "o" ) ; try { CryptoManager . initialize ( databaseDir ) ; CryptoManager manager = CryptoManager . getInstance ( ) ; CryptoToken token = CryptoUtil . getKeyStorageToken ( tokenName ) ; tokenName = token . getName ( ) ; manager . setThreadToken ( token ) ; Password password = new Password ( tokenPassword . toCharArray ( ) ) ; < |startfocus| > token . login ( password ) ; < |endfocus| > X509Certificate issuanceProtCert = null ; if ( issuanceProtCertFilename != null ) { if ( verbose ) System . out . println ( "Loading issuance protection certificate" ) ; String encoded = new String ( Files . readAllBytes ( Paths . get ( issuanceProtCertFilename ) ) ) ; byte [ ] issuanceProtCertData = Cert . parseCertificate ( encoded ) ; issuanceProtCert = manager . importCACertPackage ( issuanceProtCertData ) ; if ( verbose ) System . out . println ( "issuance protection certificate imported" ) ; } else { // must have issuance protection cert nickname if file not provided
} } public void handleWriteEvent ( ) throws IOException { for ( int i = 0 ; i < maxBatchIoOps ; i ++ ) { final NetlinkRequest request = writeQueue . poll ( ) ; if ( request == null ) break ; final int ret = processWriteToChannel ( request ) ; if ( ret <= 0 ) { if ( ret < 0 ) { log . warn ( "NETLINK write ( ) error : { } " , CLibrary . strerror ( Native . getLastError ( ) ) ) ; } break ; } } < |startfocus| > expireOldRequests ( ) ; dispatcher . endBatch ( ) ; < |endfocus| > } private int processWriteToChannel ( final NetlinkRequest request ) { if ( request == null ) return 0 ; ByteBuffer outBuf = request . releaseRequestPayload ( ) ; if ( outBuf == null ) return 0 ; int seq = writeSeqToNetlinkRequest ( request , outBuf ) ; if ( request . hasCallback ( ) ) { pendingRequests . put ( seq , request ) ; } log . trace ( "Sending message for id { } " , seq ) ; int bytes = 0 ; try { bytes = channel . write ( outBuf ) ; } finally { if ( request . hasCallback ( ) ) expirationQueue . add ( request ) ;
wrList_recv . add ( recvWR ) ; // it's important to post those receive operations before connecting // otherwise the server may issue a send operation and which cannot be received // this class wraps soem of the RDMA data operations VerbsTools commRdma = new VerbsTools ( context , compChannel , qp , cq ) ; commRdma . initSGRecv ( wrList_recv ) ; // now let's connect to the server RdmaConnParam connParam = new RdmaConnParam ( ) ; < |startfocus| > < |endfocus| > connParam . setRetry_count ( ( byte ) 2 ) ; ret = idPriv . connect ( connParam ) ; if ( ret < 0 ) { System . out . println ( "VerbsClient : : connect failed" ) ; return ; } // wait until we are really connected cmEvent = cmChannel . getCmEvent ( - 1 ) ; if ( cmEvent == null ) { System . out . println ( "VerbsClient : : cmEvent null" ) ; return ; } else if ( cmEvent . getEvent ( ) != RdmaCmEvent . EventType . RDMA_CM_EVENT_ESTABLISHED . ordinal ( ) ) {
RdmaCmId connId = cmEvent . getConnIdPriv ( ) ; if ( connId == null ) { System . out . println ( "VerbsServer : : connId null" ) ; return ; } // get the device context of the new connection , typically the same as with the server id IbvContext context = connId . getVerbs ( ) ; if ( context == null ) { System . out . println ( "VerbsServer : : context null" ) ; return ; } < |startfocus| > // Query for on demand paging memory prefecth support int rcOdpCaps = context . queryOdpSupport ( ) ; if ( rcOdpCaps == - 1 ) { System . out . println ( "VerbsServer : : On demand paging is not supported for this device" ) ; } < |endfocus| > // create a new protection domain , we will use the pd later when registering memory IbvPd pd = context . allocPd ( ) ; if ( pd == null ) { System . out . println ( "VerbsServer : : pd null" ) ; return ; } // the comp channel is used to get CQ notifications IbvCompChannel compChannel = context . createCompChannel ( ) ; if ( compChannel == null ) { System . out . println ( "VerbsServer : : compChannel null" ) ; return ; }
if ( qp == null ) { System . out . println ( "VerbsServer : : qp null" ) ; return ; } int buffercount = 3 ; int buffersize = 100 ; ByteBuffer buffers [ ] = new ByteBuffer [ buffercount ] ; IbvMr mrlist [ ] = new IbvMr [ buffercount ] ; int access = IbvMr . IBV_ACCESS_LOCAL_WRITE | IbvMr . IBV_ACCESS_REMOTE_WRITE | IbvMr . IBV_ACCESS_REMOTE_READ ; RdmaConnParam connParam = new RdmaConnParam ( ) ; < |startfocus| > // connParam . setInitiator_depth ( ( byte ) 5 ) ; // connParam . setResponder_resources ( ( byte ) 5 ) ; < |endfocus| > connParam . setRetry_count ( ( byte ) 2 ) ; // once the client id is set up , accept the connection ret = connId . accept ( connParam ) ; if ( ret < 0 ) { System . out . println ( "VerbsServer : : accept failed" ) ; return ; } // wait until the connection is officially switched into established mode cmEvent = cmChannel . getCmEvent ( - 1 ) ; if ( cmEvent . getEvent ( ) != RdmaCmEvent . EventType . RDMA_CM_EVENT_ESTABLISHED . ordinal ( ) ) { System . out . println ( "VerbsServer : : wrong event received : " + cmEvent . getEvent ( ) ) ; return ; }
System . out . println ( "VerbsServer : : connId null" ) ; return ; } // get the device context of the new connection , typically the same as with the server id IbvContext context = connId . getVerbs ( ) ; if ( context == null ) { System . out . println ( "VerbsServer : : context null" ) ; return ; } < |startfocus| > // Query for on demand paging memory prefecth support int rcOdpCaps = context . queryOdpSupport ( ) ; if ( rcOdpCaps == - 1 ) { System . out . println ( "VerbsServer : : On demand paging is not supported for this device" ) ; } < |endfocus| > // create a new protection domain , we will use the pd later when registering memory IbvPd pd = context . allocPd ( ) ; if ( pd == null ) { System . out . println ( "VerbsServer : : pd null" ) ; return ; } // the comp channel is used to get CQ notifications IbvCompChannel compChannel = context . createCompChannel ( ) ; if ( compChannel == null ) { System . out . println ( "VerbsServer : : compChannel null" ) ; return ; } // create a completion queue IbvCQ cq = context . createCQ ( compChannel , 50 , 0 ) ; if ( cq == null ) { System . out . println ( "VerbsServer : : cq null" ) ; return ; }
return ; } // get the device context of the new connection , typically the same as with the server id IbvContext context = connId . getVerbs ( ) ; if ( context == null ) { System . out . println ( "VerbsServer : : context null" ) ; return ; } // Query for on demand paging memory prefecth support int rcOdpCaps = context . queryOdpSupport ( ) ; if ( rcOdpCaps == - 1 ) { System . out . println ( "VerbsServer : : On demand paging is not supported for this device" ) ; } // create a new protection domain , we will use the pd later when registering memory IbvPd pd = context . allocPd ( ) ; if ( pd == null ) { System . out . println ( "VerbsServer : : pd null" ) ; return ; } // the comp channel is used to get CQ notifications IbvCompChannel compChannel = context . createCompChannel ( ) ; if ( compChannel == null ) { System . out . println ( "VerbsServer : : compChannel null" ) ; return ; } // create a completion queue IbvCQ cq = context . createCQ ( compChannel , 50 , 0 ) ; if ( cq == null ) {
// have a chance to capture user identification info if ( issuerANY != null ) { try { byte [ ] issuerBytes = issuerANY . getEncoded ( ) ; X500Name issuerName = new X500Name ( issuerBytes ) ; CMS . debug ( method + "revRequest issuer name = " + issuerName . toString ( ) ) ; // capture issuer principal to be checked against // cert issuer principal later in CMCOutputTemplate auditContext . put ( SessionContext . CMC_ISSUER_PRINCIPAL , issuerName ) ; < |startfocus| > } catch ( Exception e ) { < |endfocus| > } } // authToken . set ( "uid" , uid ) ; // authToken . set ( "userid" , userid ) ; } } } } } else { CMS . debug ( method + "numReqs not 0 , assume enrollment request" ) ; // enrollment request // reset value of auditReqType auditReqType = SIGNED_AUDIT_ENROLLMENT_REQUEST_TYPE ; X509CertInfo [ ] certInfoArray = new X509CertInfo [ numReqs ] ; String [ ] reqIdArray = new String [ numReqs ] ;
encSafeContents . addElement ( safeBag ) ; } public ASN1Value create_EPKI_with_PBE_SHA1_DES3_CBC ( CryptoToken token , PrivateKey privateKey , Password password ) throws Exception { // The salt size and number of iterations are selected to match pk12util . byte [ ] salt = new byte [ 16 ] ; random . nextBytes ( salt ) ; return EncryptedPrivateKeyInfo . createPBE ( PBEAlgorithm . PBE_SHA1_DES3_CBC , password , salt , 100000 , // iterations < |startfocus| > new PasswordConverter ( ) , // password converter < |endfocus| > privateKey , token ) ; } public ASN1Value create_EPKI_with_PBE_PKCS5_PBES2 ( CryptoToken token , PrivateKey privateKey , Password password ) throws Exception { CryptoStore store = token . getCryptoStore ( ) ; byte [ ] bytes = store . getEncryptedPrivateKeyInfo ( // For compatibility with OpenSSL and NSS >= 3 . 31 , // do not BMPString - encode the passphrase when using // non - PKCS #12 PBE scheme such as PKCS #5 PBES2 . // // The resulting PKCS #12 is not compatible with // NSS < 3 . 31 . null , // password converter password ,
public void performCollectionAndGetResult ( String requestId , JsonObject feature , Handler < AsyncResult < CollectorJobResult > > resultHandler ) { dcs . performCollectionAndGetResult ( requestId , feature , res - > resultHandler . handle ( checkForError ( res ) ) ) ; < |startfocus| > < |endfocus| >
package info . pascalkrause . vertx . datacollector . client . error ; import info . pascalkrause . vertx . datacollector . client . error . DataCollectorError ; public class QueueLimitReached extends DataCollectorError { private static final long serialVersionUID = 1L ; < |startfocus| > < |endfocus| > }
package info . pascalkrause . vertx . datacollector . job ; import io . vertx . core . AsyncResult ; import io . vertx . core . Future ; import io . vertx . core . Handler ; import io . vertx . core . json . JsonObject ; /* * * A generic interface which must be implemented to run the collection job inside the CollectorJobExecutor worker pool . */ public interface CollectorJob { /* * * This method should be used to create a Future that contains the collection logic . The Future will be executed in < |startfocus| > * a worker thread pool , which allows blocking operations inside . < |endfocus| > * * @param requestId A request id to identify the collection request . * @param feature A JSON object to pass attributes and properties which are needed for the collection process . * @return A Handler with the Future which contains the collection logic . */ public Handler < Future < CollectorJobResult > > collect ( String requestId , JsonObject feature ) ; /* * * This method will be called after the { @link #collect ( String , JsonObject ) } and returns a Future which can be used
public class Test { public static void main ( String [ ] args ) { System . out . println ( "Hello World ! " ) ; } }
} public Optional < Error > getError ( ) { return Error . fromJson ( data . getJsonObject ( KEY_ERROR ) ) ; } public JsonObject toJson ( ) { return data ; } @Override public int hashCode ( ) { return data . hashCode ( ) ; } @Override public boolean equals ( Object obj ) { if ( ( obj instanceof CollectorJobResult ) && ( hashCode ( ) == obj . hashCode ( ) ) ) { return true ; } return false ; } @Override public String toString ( ) { return data . toString ( ) ; } < |startfocus| > < |endfocus| > }
public static final String METRIC_TOTAL_JOBS_COUNT = "totalJobsCount" ; private final Counter totalJobsCounter ; public static final String METRIC_TOTAL_JOBS_FAILED = "totalJobsFailed" ; private final Counter totalJobsFailed ; public static final String METRIC_TOTAL_JOBS_SUCCEEDED = "totalJobsSucceeded" ; private final Counter totalJobsSucceeded ; public static final String METRIC_TOTAL_JOBS_EXCEPTION = "totalJobsException" ; private final Counter totalJobsException ; private final MetricRegistry metricRegistry ; < |startfocus| > Map < String , AtomicLong > qualityMap = new ConcurrentHashMap < > ( ) ; Map < String , AtomicLong > errorMap = new ConcurrentHashMap < > ( ) ; < |endfocus| > private Map < String , Object > sortDescendingAndSlice ( Map < String , AtomicLong > unsorted , long maxEntries ) { return unsorted . entrySet ( ) . stream ( ) . map ( e - > new SimpleEntry < String , Long > ( e . getKey ( ) , e . getValue ( ) . get ( ) ) ) . sorted ( Map . Entry . comparingByValue ( ) ) . limit ( maxEntries ) . collect ( Collectors . toMap ( e - > e . getKey ( ) , e - > e . getValue ( ) , ( oldValue , newValue ) - > oldValue , LinkedHashMap : : new ) ) ; } private void updateQualityMap ( String quality , long value ) { qualityMap . computeIfAbsent ( quality , k - > new AtomicLong ( ) ) . addAndGet ( value ) ; } private void updateErrorMap ( String error , long value ) { errorMap . computeIfAbsent ( error , k - > new AtomicLong ( ) ) . addAndGet ( value ) ; }
public void addQueueMetrics ( AtomicInteger currentQueueSize , int queueSize ) { registerQueueMetrics ( currentQueueSize , queueSize ) ; } private void registerQueueMetrics ( AtomicInteger currentQueueSize , int queueSize ) { metricRegistry . register ( MetricRegistry . name ( METRIC_QUEUE_MAX_SIZE ) , ( Gauge < Integer > ) ( ) - > queueSize ) ; metricRegistry . register ( MetricRegistry . name ( METRIC_QUEUE_FREE ) , ( Gauge < Integer > ) ( ) - > queueSize - currentQueueSize . get ( ) ) ; metricRegistry . register ( MetricRegistry . name ( METRIC_QUEUE_OCCUPIED ) , ( Gauge < Integer > ) ( ) - > currentQueueSize . get ( ) ) ; }
< |startfocus| > public void registerTotalMetrics ( AsyncResult < CollectorJobResult > postResult ) { < |endfocus| > totalJobsCounter . inc ( ) ; if ( postResult . succeeded ( ) ) { final Optional < Error > e = postResult . result ( ) . getError ( ) ; if ( e . isPresent ( ) ) { totalJobsFailed . inc ( ) ; addOrIncrease ( errorMap , e . get ( ) . getName ( ) ) ; } else { totalJobsSucceeded . inc ( ) ; addOrIncrease ( qualityMap , postResult . result ( ) . getQuality ( ) ) ; } } else { totalJobsException . inc ( ) ; }
metricFactory . addTotalMetricsCounters ( postResult ) ; } resultHandler . handle ( postResult ) ; } ) ; } ) ; } else { resultHandler . handle ( Future . failedFuture ( ERROR_QUEUE_LIMIT_REACHED ) ) ; } } @Override public void performCollection ( String requestId , JsonObject feature , Handler < AsyncResult < Void > > resultHandler ) { performCollectionAndGetResult ( requestId , feature , res - > { resultHandler . handle ( res . failed ( ) ? Future . failedFuture ( res . cause ( ) ) : Future . succeededFuture ( ) ) ; } ) ; } /* * * Visible for Testing < |startfocus| > * * @return < |endfocus| > */ public JsonObject getMetricsSnapshot ( ) { return Objects . isNull ( metricFactory ) ? new JsonObject ( ) . put ( "Error" , "Metrics are not enabled" ) : metricFactory . getMetricsSnapshot ( ) ; } @Override public void getMetricsSnapshot ( Handler < AsyncResult < JsonObject > > resultHandler ) { resultHandler . handle ( Future . succeededFuture ( getMetricsSnapshot ( ) ) ) ; } @Override public void close ( ) { // Needed for generated Client } }
private CollectorJobResult generateResult ( String requestId , CollectorJobResult . Error error ) { < |startfocus| > return new CollectorJobResult ( requestId , "test - source" , "test - quality" , "test - created" , new JsonObject ( ) , error ) ; < |endfocus| >
} catch ( final InterruptedException e ) { e . printStackTrace ( ) ; } } if ( Objects . nonNull ( stopper ) && feature . containsKey ( KEY_STOP ) ) { stopper . await ( TimeUnit . SECONDS . toMillis ( 1 ) ) ; } if ( feature . containsKey ( KEY_UNHANDLED_EXCEPTION ) ) { throw new RuntimeException ( "Some unhandled excpetion" ) ; } else if ( feature . containsKey ( KEY_HANDLED_EXCEPTION ) ) { fut . fail ( new RuntimeException ( "Some handled exception" ) ) ; } else { fut . complete ( jobResult ) ; } } ; } < |startfocus| > < |endfocus| > }
import java . util . Collection ; import java . util . logging . Logger ; import javax . net . ssl . X509TrustManager ; import org . mozilla . jss . CryptoManager ; import org . mozilla . jss . CryptoManager . NotInitializedException ; import netscape . security . x509 . X509CertImpl ; public class PKITrustManager implements X509TrustManager { final static Logger logger = Logger . getLogger ( PKITrustManager . class . getName ( ) ) ; @Override public void checkClientTrusted ( X509Certificate [ ] certs , String authType ) throws CertificateException { logger . fine ( "PKITrustManager : checkClientTrusted ( " + authType + " ) : " ) ; < |startfocus| > for ( X509Certificate cert : certs ) { logger . fine ( "PKITrustManager : - " + cert . getSubjectDN ( ) ) ; < |endfocus| > } try { CryptoManager manager = CryptoManager . getInstance ( ) ; X509Certificate cert = certs [ 0 ] ; if ( ! manager . isCertValid ( cert . getEncoded ( ) , true , CryptoManager . CertUsage . SSLClient ) ) { throw new CertificateException ( "Missing SSLClient certificate usage : " + cert . getSubjectDN ( ) ) ; } logger . fine ( "PKITrustManager : certificate is valid" ) ; } catch ( CertificateException e ) { throw e ; } catch ( Exception e ) { throw new CertificateException ( "Error validating certificate" , e ) ; } } @Override public void checkServerTrusted ( X509Certificate [ ] certs , String authType ) throws CertificateException { logger . fine ( "PKITrustManager : checkServerTrusted ( " + authType + " ) : " ) ; < |startfocus| > for ( X509Certificate cert : certs ) { logger . fine ( "PKITrustManager : - " + cert . getSubjectDN ( ) ) ; < |endfocus| > } try { CryptoManager manager = CryptoManager . getInstance ( ) ; X509Certificate cert = certs [ 0 ] ; if ( ! manager . isCertValid ( cert . getEncoded ( ) , true , CryptoManager . CertUsage . SSLServer ) ) { throw new CertificateException ( "Missing SSLServer certificate usage : " + cert . getSubjectDN ( ) ) ; } logger . fine ( "PKITrustManager : certificate is valid" ) ; } catch ( CertificateException e ) { throw e ; } catch ( Exception e ) { throw new CertificateException ( "Error validating certificate" , e ) ; } } @Override public X509Certificate [ ] getAcceptedIssuers ( ) { return new X509Certificate [ 0 ] ; } }
} try { CryptoManager manager = CryptoManager . getInstance ( ) ; X509Certificate cert = certs [ 0 ] ; if ( ! manager . isCertValid ( cert . getEncoded ( ) , true , CryptoManager . CertUsage . SSLClient ) ) { throw new CertificateException ( "Missing SSLClient certificate usage : " + cert . getSubjectDN ( ) ) ; } logger . fine ( "PKITrustManager : certificate is valid" ) ; } catch ( CertificateException e ) { throw e ; } catch ( Exception e ) { throw new CertificateException ( e ) ; } } @Override < |startfocus| > public void checkServerTrusted ( X509Certificate [ ] certs , String authType ) throws CertificateException { < |endfocus| > logger . fine ( "PKITrustManager : checkServerTrusted ( " + authType + " ) : " ) ; for ( X509Certificate cert : certs ) { logger . fine ( "PKITrustManager : - " + cert . getSubjectDN ( ) ) ; } try { CryptoManager manager = CryptoManager . getInstance ( ) ; X509Certificate cert = certs [ 0 ] ; if ( ! manager . isCertValid ( cert . getEncoded ( ) , true , CryptoManager . CertUsage . SSLServer ) ) { throw new CertificateException ( "Missing SSLServer certificate usage : " + cert . getSubjectDN ( ) ) ; } logger . fine ( "PKITrustManager : certificate is valid" ) ; } catch ( CertificateException e ) { throw e ; } catch ( Exception e ) { throw new CertificateException ( e ) ; } }
} } if ( aid != null && adn != null ) { throw new Exception ( " -- issuer - id and -- issuer - dn options are mutually exclusive" ) ; } MainCLI mainCLI = ( MainCLI ) parent . getParent ( ) ; File certDatabase = mainCLI . certDatabase ; String password = mainCLI . config . getCertPassword ( ) ; if ( password == null ) { throw new Exception ( "Missing security database password . " ) ; } String csr ; PKIClient client ; if ( "pkcs10" . equals ( requestType ) ) { < |startfocus| > if ( "rsa" . equals ( algorithm ) ) { < |endfocus| > csr = generatePkcs10Request ( certDatabase , password , algorithm , Integer . toString ( length ) , subjectDN ) ; } else if ( "ecc" . equals ( algorithm ) ) { csr = generatePkcs10Request ( certDatabase , password , algorithm , curve , subjectDN ) ; } else { throw new Exception ( "Invalid algorithm specified . " ) ; } // initialize database after PKCS10Client to avoid conflict mainCLI . init ( ) ; client = getClient ( ) ; } else if ( "crmf" . equals ( requestType ) ) { // initialize database before CRMFPopClient to load transport certificate
} MainCLI mainCLI = ( MainCLI ) parent . getParent ( ) ; File certDatabase = mainCLI . certDatabase ; String password = mainCLI . config . getCertPassword ( ) ; if ( password == null ) { throw new Exception ( "Missing security database password . " ) ; } String csr ; PKIClient client ; if ( "pkcs10" . equals ( requestType ) ) { if ( "rsa" . equals ( algorithm ) ) { csr = generatePkcs10Request ( certDatabase , password , algorithm , Integer . toString ( length ) , subjectDN ) ; } < |startfocus| > else if ( "ecc" . equals ( algorithm ) ) { < |endfocus| > csr = generatePkcs10Request ( certDatabase , password , algorithm , curve , subjectDN ) ; } else { throw new Exception ( "Invalid algorithm specified . " ) ; } // initialize database after PKCS10Client to avoid conflict mainCLI . init ( ) ; client = getClient ( ) ; } else if ( "crmf" . equals ( requestType ) ) { // initialize database before CRMFPopClient to load transport certificate mainCLI . init ( ) ; client = getClient ( ) ; String encoded ; if ( transportCertFilename == null ) {
if ( password == null ) { throw new Exception ( "Missing security database password . " ) ; } String csr ; PKIClient client ; if ( "pkcs10" . equals ( requestType ) ) { if ( "rsa" . equals ( algorithm ) ) { csr = generatePkcs10Request ( certDatabase , password , algorithm , Integer . toString ( length ) , subjectDN ) ; } else if ( "ecc" . equals ( algorithm ) ) { csr = generatePkcs10Request ( certDatabase , password , algorithm , curve , subjectDN ) ; < |startfocus| > } else { throw new Exception ( "Invalid algorithm : " + algorithm ) ; } < |endfocus| > // initialize database after PKCS10Client to avoid conflict mainCLI . init ( ) ; client = getClient ( ) ; } else if ( "crmf" . equals ( requestType ) ) { // initialize database before CRMFPopClient to load transport certificate mainCLI . init ( ) ; client = getClient ( ) ; String encoded ; if ( transportCertFilename == null ) { SystemCertClient certClient = new SystemCertClient ( client , "ca" ) ; encoded = certClient . getTransportCert ( ) . getEncoded ( ) ; } else { encoded = new String ( Files . readAllBytes ( Paths . get ( transportCertFilename ) ) ) ;
CACertCLI . printCertRequestInfos ( infos ) ; } public String generatePkcs10Request ( File certDatabase , String password , String algorithm , String length , String subjectDN ) throws Exception { File csrFile = File . createTempFile ( "pki - client - cert - request - " , " . csr" , certDatabase ) ; csrFile . deleteOnExit ( ) ; String [ ] commands = { " / usr / bin / PKCS10Client" , " - d" , certDatabase . getAbsolutePath ( ) , " - p" , password , " - a" , algorithm , < |startfocus| > " - l" , "" + length , < |endfocus| > " - o" , csrFile . getAbsolutePath ( ) , " - n" , subjectDN } ; try { runExternal ( commands ) ; } catch ( Exception e ) { throw new Exception ( "CSR generation failed" , e ) ; } if ( verbose ) { System . out . println ( "CSR generated : " + csrFile ) ; } return new String ( Files . readAllBytes ( csrFile . toPath ( ) ) ) ; } public String generateCrmfRequest ( X509Certificate transportCert , String subjectDN , boolean attributeEncoding , String algorithm , int length , String curve , boolean sslECDH , boolean temporary ,
int sd_ee_port = config . getInteger ( "securitydomain . httpseeport" , - 1 ) ; MultivaluedMap < String , String > content = new MultivaluedHashMap < String , String > ( ) ; content . putSingle ( "requestor_name" , sysType + " - " + machineName + " - " + securePort ) ; logger . debug ( "configRemoteCert : subsystemCert : setting profileId to : " + profileId ) ; String actualProfileId = request . getSystemCertProfileID ( certTag , profileId ) ; logger . debug ( "configRemoteCert : subsystemCert : calculated profileId : " + actualProfileId ) ; < |startfocus| > content . putSingle ( "profileId" , actualProfileId ) ; < |endfocus| > content . putSingle ( "cert_request_type" , "pkcs10" ) ; content . putSingle ( "cert_request" , b64Request ) ; content . putSingle ( "xmlOutput" , "true" ) ; content . putSingle ( "sessionID" , session_id ) ; cert = CertUtil . createRemoteCert ( sd_hostname , sd_ee_port , content , response ) ; if ( cert == null ) { throw new IOException ( "Error : remote certificate is null" ) ; } } else if ( v . equals ( "sdca" ) ) { String ca_hostname = "" ; int ca_port = - 1 ; try {
try ( InputStream in = new BufferedInputStream ( getInputStream ( ) ) ) { // TODO : expose XStream the driver from XStream if ( nullOut ) { return ( ( XStream2 ) xs ) . unmarshal ( DEFAULT_DRIVER . createReader ( in ) , o , null , true ) ; } else { return xs . unmarshal ( DEFAULT_DRIVER . createReader ( in ) , o ) ; } } catch ( RuntimeException | Error e ) { throw new IOException ( "Unable to read " + file , e ) ; } } < |startfocus| > private InputStream getInputStream ( ) throws IOException { InputStream is = Files . newInputStream ( file . toPath ( ) ) ; if ( file . getName ( ) . toLowerCase ( ) . endsWith ( " . gz" ) ) { is = new GZIPInputStream ( is ) ; } return is ; } public void write ( Object o ) throws IOException { mkdirs ( ) ; AtomicFileWriter w = new AtomicFileWriter ( file ) ; try { w . write ( " < ? xml version = '1 . 1' encoding = 'UTF - 8' ? > \n" ) ; beingWritten . put ( o , null ) ; writing . set ( file ) ; try { xs . toXML ( o , w ) ; } finally { beingWritten . remove ( o ) ;
* from CA's internal certificate db based on serial number to revoke shared * secret based revocation * Note that unlike the shared token attribute for enrollment , the metaInfo * attribute for shared token in revocatoiin is not configurable . * *
* * But we do still want to check that the input looks something * like a profile configuration . So we use java . util . Properties * to do that . */ public static void checkConfiguration ( byte [ ] in , boolean requireProfileId , boolean requireDisabled ) throws PKIException { Properties p = new Properties ( ) ; try { p . load ( new ByteArrayInputStream ( in ) ) ; } catch ( IOException e ) { < |startfocus| > throw new PKIException ( "Failed to parse profile configuration : " + e . toString ( ) , e ) ; < |endfocus| > } if ( requireProfileId && p . getProperty ( "profileId" ) == null ) throw new PKIException ( "Missing profileId property in profile data . " ) ; String enabled = p . getProperty ( "enable" ) ; if ( requireDisabled && Boolean . valueOf ( enabled ) ) { throw new PKIException ( "Cannot edit profile . Profile must be disabled . " ) ; } } public static void saveEnrollmentTemplateToFile ( String filename , CertEnrollmentRequest request ) throws JAXBException , FileNotFoundException { JAXBContext context = JAXBContext . newInstance ( CertEnrollmentRequest . class ) ; Marshaller marshaller = context . createMarshaller ( ) ;
* easier to tell if a config name represents a plugin permission or not . Note " - " isn't clear * enough for this purpose since some core permissions , e . g . "label - " , also contain " - " . */ private static final Pattern PLUGIN_PERMISSION_NAME_IN_CONFIG_PATTERN = < |startfocus| > Pattern . compile ( " ^ plugin - " + PLUGIN_NAME_PATTERN_STRING + " - [ a - zA - Z ] + $" ) ; < |endfocus| > /* * Name pattern for a Gerrit plugin . */ private static final Pattern PLUGIN_NAME_PATTERN = Pattern . compile ( " ^ " + PLUGIN_NAME_PATTERN_STRING + "$" ) ; private final DynamicMap < CapabilityDefinition > capabilityDefinitions ; private final DynamicMap < PluginProjectPermissionDefinition > pluginProjectPermissionDefinitions ; @Inject private PluginPermissionsUtil ( DynamicMap < CapabilityDefinition > capabilityDefinitions , DynamicMap < PluginProjectPermissionDefinition > pluginProjectPermissionDefinitions ) { this . capabilityDefinitions = capabilityDefinitions ; this . pluginProjectPermissionDefinitions = pluginProjectPermissionDefinitions ; } /* * * Collects all the plugin declared capabilities . *
< |startfocus| > PluginPermissionsUtil ( < |endfocus| > DynamicMap < CapabilityDefinition > capabilityDefinitions , DynamicMap < PluginProjectPermissionDefinition > pluginProjectPermissionDefinitions ) { this . capabilityDefinitions = capabilityDefinitions ; this . pluginProjectPermissionDefinitions = pluginProjectPermissionDefinitions ;
public boolean testOrFalse ( ProjectPermission perm ) { try { return test ( perm ) ; } catch ( PermissionBackendException e ) { logger . warn ( "Cannot test " + perm + " ; assuming false" , e ) ; return false ; } } public BooleanCondition testCond ( ProjectPermission perm ) { return new PermissionBackendCondition . ForProject ( this , perm ) ; } /* * * @return a partition of the provided refs that are visible to the user that this instance is < |startfocus| > * scoped to . < |endfocus| > */ public abstract Map < String , Ref > filter ( Map < String , Ref > refs , Repository repo , RefFilterOptions opts ) throws PermissionBackendException ; } /* * Options for filtering refs using { @link ForProject } . */ @AutoValue public abstract static class RefFilterOptions { /* * Remove all NoteDb refs ( refs / changes /* , refs / users /* , edit refs ) from the result . */ public abstract boolean filterMeta ( ) ; /* * Separately add reachable tags . */ public abstract boolean filterTagsSeparately ( ) ; public abstract Builder toBuilder ( ) ;
public Map < String , Ref > filter ( Map < String , Ref > refs , Repository repo , RefFilterOptions opts ) throws PermissionBackendException { if ( refFilter == null ) { refFilter = refFilterFactory . create ( ProjectControl . this ) ; } return refFilter . filter ( refs , repo , opts ) ; } private boolean can ( CoreOrPluginProjectPermission perm ) throws PermissionBackendException { if ( perm instanceof ProjectPermission ) { return can ( ( ProjectPermission ) perm ) ; } else if ( perm instanceof PluginProjectPermission ) { < |startfocus| > // TODO : implement for plugin defined project permissions . < |endfocus| > return false ; } throw new PermissionBackendException ( perm . describeForException ( ) + " unsupported" ) ; } private boolean can ( ProjectPermission perm ) throws PermissionBackendException { switch ( perm ) { case ACCESS : return user . isInternalUser ( ) || isOwner ( ) || canPerformOnAnyRef ( Permission . READ ) ; case READ : return allRefsAreVisible ( Collections . emptySet ( ) ) ; case CREATE_REF : return canAddRefs ( ) ; case CREATE_TAG_REF : return canAddTagRefs ( ) ; case CREATE_CHANGE : return canCreateChanges ( ) ; case
private final Timer1 < String > latencyPerPush ; private final Counter0 timeouts ; @Inject Metrics ( MetricMaker metricMaker ) { changes = metricMaker . newHistogram ( "receivecommits / changes" , new Description ( "number of changes uploaded in a single push . " ) . setCumulative ( ) , Field . ofEnum ( ResultChangeIds . Key . class , "type" , "type of update ( replace , create , autoclose ) " ) ) ; latencyPerChange = metricMaker . newTimer ( "receivecommits / latency" , < |startfocus| > new Description ( "average delay per updated change for a push ( calculated as duration_of_push / number_of_changes_in_push ) . " ) < |endfocus| > . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( "type" , "type of update ( create / replace , autoclose ) " ) ) ; latencyPerPush = metricMaker . newTimer ( "receivecommits / push_latency" , new Description ( "delay for a processing single batch of pushes" ) . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( "type" , "type of push ( create / replace , autoclose ) " ) ) ; timeouts = metricMaker . newCounter ( "receivecommits / timeout" , new Description ( "rate of push timeouts" ) . setRate ( ) ) ;
Field . ofEnum ( ResultChangeIds . Key . class , "type" , "type of update ( replace , create , autoclose ) " ) ) ; latencyPerChange = metricMaker . newTimer ( "receivecommits / latency" , new Description ( "average delay per updated change" ) . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( "type" , "type of update ( create / replace , autoclose ) " ) ) ; latencyPerPush = metricMaker . newTimer ( "receivecommits / push_latency" , < |startfocus| > new Description ( "delay for processing a single push ( which may consist of multiple changes ) " ) < |endfocus| > . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( "type" , "type of push ( create / replace , autoclose ) " ) ) ; timeouts = metricMaker . newCounter ( "receivecommits / timeout" , new Description ( "rate of push timeouts" ) . setRate ( ) ) ; } } private final Metrics metrics ; private final ReceiveCommits receiveCommits ; private final ResultChangeIds resultChangeIds ; private final PermissionBackend . ForProject perm ; private final ReceivePack receivePack ; private final ExecutorService executor ; private final RequestScopePropagator scopePropagator ;
metricMaker . newTimer ( "receivecommits / latency" , new Description ( "average delay per updated change" ) . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( "type" , "type of update ( create / replace , autoclose ) " ) ) ; latencyPerPush = metricMaker . newTimer ( "receivecommits / push_latency" , new Description ( "delay for a processing single batch of pushes" ) . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , < |startfocus| > Field . ofString ( "type" , "type of push ( create / replace , autoclose ) " ) ) ; < |endfocus| > timeouts = metricMaker . newCounter ( "receivecommits / timeout" , new Description ( "rate of push timeouts" ) . setRate ( ) ) ; } } private final Metrics metrics ; private final ReceiveCommits receiveCommits ; private final ResultChangeIds resultChangeIds ; private final PermissionBackend . ForProject perm ; private final ReceivePack receivePack ; private final ExecutorService executor ; private final RequestScopePropagator scopePropagator ; private final ReceiveConfig receiveConfig ; private final ContributorAgreementsChecker contributorAgreements ; private final long timeoutMillis ; private final ProjectState projectState ; private final IdentifiedUser user ; private final ChangeInserter . Factory changeInserterFactory ;
List < Change . Id > created = resultChangeIds . get ( ResultChangeIds . Key . CREATED ) ; metrics . changes . record ( ResultChangeIds . Key . CREATED , created . size ( ) ) ; List < Change . Id > replaced = resultChangeIds . get ( ResultChangeIds . Key . REPLACED ) ; metrics . changes . record ( ResultChangeIds . Key . REPLACED , replaced . size ( ) ) ; totalChanges += replaced . size ( ) + created . size ( ) ; } else { List < Change . Id > autoclosed = resultChangeIds . get ( ResultChangeIds . Key . AUTOCLOSED ) ; < |startfocus| > metrics . changes . record ( ResultChangeIds . Key . AUTOCLOSED , autoclosed . size ( ) ) ; totalChanges += autoclosed . size ( ) ; < |endfocus| > } String pushType ; if ( resultChangeIds . isMagicPush ( ) ) { pushType = "CREATE_REPLACE" ; } else if ( totalChanges > 0 ) { pushType = ResultChangeIds . Key . AUTOCLOSED . name ( ) ; } else { pushType = "NORMAL" ; } if ( totalChanges > 0 ) { metrics . latencyPerChange . record ( pushType , deltaNanos / totalChanges , NANOSECONDS ) ; } metrics . latencyPerPush . record ( pushType , deltaNanos , NANOSECONDS ) ; metrics . changes . record ( pushType , totalChanges ) ;
public TestCheckerUpdate . Builder forUpdate ( ) { return TestCheckerUpdate . builder ( this : : updateChecker ) ; } private void updateChecker ( TestCheckerUpdate testCheckerUpdate ) throws Exception { CheckerUpdate checkerUpdate = toCheckerUpdate ( testCheckerUpdate ) ; checkersUpdate . updateChecker ( checkerUuid , checkerUpdate ) ; < |startfocus| > if ( testCheckerUpdate . forceInvalidConfig ( ) . orElse ( false ) ) { < |endfocus| > try ( Repository repo = repoManager . openRepository ( allProjectsName ) ) { new TestRepository < > ( repo ) . branch ( CheckerRef . refsCheckers ( checkerUuid ) ) . commit ( ) . add ( CheckerConfig . CHECKER_CONFIG_FILE , "invalid - config" ) . create ( ) ; } } } private CheckerUpdate toCheckerUpdate ( TestCheckerUpdate checkerUpdate ) { CheckerUpdate . Builder builder = CheckerUpdate . builder ( ) ; checkerUpdate . name ( ) . ifPresent ( builder : : setName ) ; checkerUpdate . description ( ) . ifPresent ( builder : : setDescription ) ; checkerUpdate . url ( ) . ifPresent ( builder : : setUrl ) ;
import com . google . gerrit . reviewdb . client . Project ; import java . util . Arrays ; import java . util . Optional ; import java . util . stream . Stream ; @AutoValue public abstract class TestCheckerUpdate { public abstract Optional < String > name ( ) ; public abstract Optional < String > description ( ) ; public abstract Optional < String > url ( ) ; public abstract Optional < Project . NameKey > repository ( ) ; public abstract Optional < CheckerStatus > status ( ) ; public abstract Optional < ImmutableSortedSet < BlockingCondition > > blockingConditions ( ) ; public abstract Optional < String > query ( ) ; < |startfocus| > public abstract boolean forceInvalidConfig ( ) ; < |endfocus| > abstract ThrowingConsumer < TestCheckerUpdate > checkerUpdater ( ) ; public static Builder builder ( ThrowingConsumer < TestCheckerUpdate > checkerUpdater ) { return new AutoValue_TestCheckerUpdate . Builder ( ) . checkerUpdater ( checkerUpdater ) . forceInvalidConfig ( false ) ; } @AutoValue . Builder public abstract static class Builder { public abstract Builder name ( String name ) ; public abstract Builder description ( String description ) ; public Builder clearDescription ( ) { return description ( "" ) ; } public abstract Builder url ( String url ) ; public Builder clearUrl ( ) { return url ( "" ) ; } public abstract Builder repository ( Project . NameKey repository ) ;
checkOperations . newCheck ( key ) . setState ( CheckState . RUNNING ) . upsert ( ) ; checkerOperations . checker ( checkerUuid ) . forUpdate ( ) . forceInvalidConfig ( ) . update ( ) ; exception . expect ( RestApiException . class ) ; exception . expectMessage ( "Cannot retrieve checker " + checkerUuid ) ; checksApiFactory . revision ( patchSetId ) . id ( checkerUuid . toString ( ) ) . get ( ) ; } @Test public void getNonExistingCheckFails ( ) throws Exception { exception . expect ( ResourceNotFoundException . class ) ; exception . expectMessage ( "Not found : non - existing" ) ; checksApiFactory . revision ( patchSetId ) . id ( "non - existing" ) . get ( ) ; } @Test public void getCheckWithInvalidUuidFails ( ) throws Exception { exception . expect ( ResourceNotFoundException . class ) ; exception . expectMessage ( "Not found : invalid - uuid" ) ; checksApiFactory . revision ( patchSetId ) . id ( "invalid - uuid" ) . get ( ) ; < |startfocus| > } < |endfocus| > }
parseTag ( commit ) ; if ( branch == null ) { branch = parseBranch ( commit ) ; } PatchSet . Id psId = parsePatchSetId ( commit ) ; PatchSetState psState = parsePatchSetState ( commit ) ; if ( psState != null ) { if ( ! patchSetStates . containsKey ( psId ) ) { patchSetStates . put ( psId , psState ) ; } if ( psState == PatchSetState . DELETED ) { deletedPatchSets . add ( psId ) ; } } Account . Id accountId = parseIdent ( commit ) ; if ( accountId != null ) { < |startfocus| > ownerId = Optional . ofNullable ( accountId ) ; < |endfocus| > } Account . Id realAccountId = parseRealAccountId ( commit , accountId ) ; if ( changeId == null ) { changeId = parseChangeId ( commit ) ; } String currSubject = parseSubject ( commit ) ; if ( currSubject != null ) { if ( subject == null ) { subject = currSubject ; } originalSubject = currSubject ; } parseChangeMessage ( psId , accountId , realAccountId , commit , ts ) ; if ( topic == null ) { topic = parseTopic ( commit ) ; }
} @Override public void flush ( ) { receiveCommits . getMessageSender ( ) . flush ( ) ; } } } @Singleton private static class Metrics { private final Histogram1 < ResultChangeIds . Key > changes ; private final Timer1 < String > latencyPerChange ; private final Timer1 < String > latencyPerPush ; private final Counter0 timeouts ; @Inject Metrics ( MetricMaker metricMaker ) { changes = metricMaker . newHistogram ( "receivecommits / changes" , new Description ( "number of changes uploaded in a single push . " ) . setCumulative ( ) , < |startfocus| > Field . ofEnum ( ResultChangeIds . Key . class , "type" , "type of push ( replace , create , autoclose ) " ) ) ; < |endfocus| > latencyPerChange = metricMaker . newTimer ( "receivecommits / latency" , new Description ( "processing delay per push , averaged over the updated changes in a push . " ) . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofEnum ( ResultChangeIds . Key . class , "type" , "type of push ( replace , create , autoclose ) " ) ) ; latencyPerPush = metricMaker . newTimer ( "receivecommits / push_latency" ,
private final Counter0 timeouts ; @Inject Metrics ( MetricMaker metricMaker ) { changes = metricMaker . newHistogram ( "receivecommits / changes" , new Description ( "number of changes uploaded in a single push . " ) . setCumulative ( ) , Field . ofEnum ( ResultChangeIds . Key . class , "type" , "type of push ( replace , create , autoclose ) " ) ) ; latencyPerChange = metricMaker . newTimer ( "receivecommits / latency" , new Description ( < |startfocus| > "processing delay per push divided by the number of changes in said push . ( Only includes pushes which contain changes . ) " ) < |endfocus| > . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( "type" , "type of push ( create / replace , autoclose ) " ) ) ; latencyPerPush = metricMaker . newTimer ( "receivecommits / push_latency" , new Description ( "processing delay for a processing single push" ) . setUnit ( Units . MILLISECONDS ) . setCumulative ( ) , Field . ofString ( "type" , "type of push ( create / replace , autoclose , normal ) " ) ) ; timeouts = metricMaker . newCounter ( "receivecommits / timeout" , new Description ( "rate of push timeouts" ) . setRate ( ) ) ;
< |startfocus| > private static ProjectAccessInput createAccessInput ( String accessSection , String permissionName ) { < |endfocus| > ProjectAccessInput accessInput = new ProjectAccessInput ( ) ; PermissionRuleInfo ruleInfo = new PermissionRuleInfo ( PermissionRuleInfo . Action . ALLOW , false ) ; PermissionInfo email = new PermissionInfo ( null , null ) ; email . rules = ImmutableMap . of ( SystemGroupBackend . REGISTERED_USERS . get ( ) , ruleInfo ) ; AccessSectionInfo accessSectionInfo = new AccessSectionInfo ( ) ; accessSectionInfo . permissions = ImmutableMap . of ( permissionName , email ) ; accessInput . add = ImmutableMap . of ( accessSection , accessSectionInfo ) ; return accessInput ;
< |startfocus| > public void isPluginPermissionNameValidReturnTrue ( ) { < |endfocus| > // " - " is allowed for a plugin name . Here "foo - a" should be the name of the plugin . ImmutableList < String > validPluginPermissions = ImmutableList . of ( "plugin - foo - a" , "plugin - foo - a - b" ) ; for ( String permission : validPluginPermissions ) { assertThat ( isPluginPermission ( permission ) ) . named ( "valid plugin permission : % s" , permission ) . isTrue ( ) ; }
< |startfocus| > public void isPluginPermissionInvalidNameReturnFalse ( ) { ImmutableList < String > validPluginPermissions = < |endfocus| > ImmutableList . of ( "create" , "label - Code - Review" , "plugin - foo" , "plugin - foo" , "plugin - foo - a - " , "plugin - foo - a1" ) ; for ( String permission : validPluginPermissions ) { assertThat ( isPluginPermissionNameInvalid ( permission ) ) . named ( "invalid plugin permission : % s" , permission ) . isFalse ( ) ; }
< |startfocus| > public void isPluginPermissionInvalidNameReturnFalse ( ) { ImmutableList < String > invalidPluginPermissions = < |endfocus| > ImmutableList . of ( "create" , "label - Code - Review" , "plugin - foo" , "plugin - foo" , "plugin - foo - a - " , "plugin - foo - a1" ) ; for ( String permission : invalidPluginPermissions ) { assertThat ( isPluginPermission ( permission ) ) . named ( "invalid plugin permission : % s" , permission ) . isFalse ( ) ; }
. annotatedWith ( Exports . named ( TEST_PLUGIN_CAPABILITY ) ) . toInstance ( new CapabilityDefinition ( ) { @Override public String getDescription ( ) { return "A Plugin Capability" ; } } ) ; bind ( PluginProjectPermissionDefinition . class ) . annotatedWith ( Exports . named ( TEST_PLUGIN_PROJECT_PERMISSION ) ) . toInstance ( new PluginProjectPermissionDefinition ( ) { @Override public String getDescription ( ) { return "A Plugin Project Permission" ; } } ) ; } } ; } @Test < |startfocus| > public void setAccessAddPluginCapabilitySucceed ( ) throws Exception { < |endfocus| > String pluginCapability = TEST_PLUGIN_NAME + " - " + TEST_PLUGIN_CAPABILITY ; ProjectAccessInput accessInput = createAccessInput ( AccessSection . GLOBAL_CAPABILITIES , pluginCapability ) ; ProjectAccessInfo projectAccessInfo = gApi . projects ( ) . name ( allProjects . get ( ) ) . access ( accessInput ) ; Set < String > capabilities = projectAccessInfo . local . get ( AccessSection . GLOBAL_CAPABILITIES ) . permissions . keySet ( ) ; assertThat ( capabilities ) . contains ( pluginCapability ) ; // Verifies the plugin defined capability could be listed . assertThat ( pluginPermissionsUtil . collectPluginCapabilities ( ) ) . containsKey ( pluginCapability ) ; } @Test
} @Override public void addRelatedLink ( String issueKey , URL relatedUrl , String description ) throws IOException { addComment ( issueKey , "Related URL : " + createLinkForWebui ( relatedUrl . toExternalForm ( ) , description ) ) ; } @Override public void addValueToField ( String issueKey , String value , String fieldId ) throws IOException { execute ( ( ) - > { log . debug ( "Adding value { } to field { } on issue { } " , value , fieldId , issueKey ) ; < |startfocus| > jiraClient . addValueToField ( issueKey , value , fieldId ) ; < |endfocus| > return null ; } ) ; } @Override public void performAction ( String issueKey , String actionName ) throws IOException { execute ( ( ) - > { log . debug ( "Performing action { } on issue { } " , actionName , issueKey ) ; doPerformAction ( issueKey , actionName ) ; return issueKey ; } ) ; } private void doPerformAction ( String issueKey , String actionName ) throws IOException , InvalidTransitionException { log . debug ( "Trying to perform action : { } on issue { } " , actionName , issueKey ) ; < |startfocus| > return null ; < |endfocus| > }
private final Checks checks ; private final Provider < ChecksUpdate > checksUpdate ; private final CheckJson checkJson ; @Inject PostCheck ( Checks checks , @UserInitiated Provider < ChecksUpdate > checksUpdate , CheckJson checkJson ) { this . checks = checks ; this . checksUpdate = checksUpdate ; this . checkJson = checkJson ; } @Override public CheckInfo apply ( RevisionResource rsrc , CheckInput input ) throws OrmException , IOException , RestApiException { if ( input == null ) { < |startfocus| > input = new CheckInput ( ) ; < |endfocus| > } if ( input . checkerUuid == null ) { throw new BadRequestException ( "checkerUuid is required" ) ; } CheckKey key = CheckKey . create ( rsrc . getProject ( ) , rsrc . getPatchSet ( ) . getId ( ) , CheckerUuid . parse ( input . checkerUuid ) ) ; Optional < Check > check = checks . getCheck ( key ) ; if ( ! check . isPresent ( ) ) { if ( input . state == null ) { throw new BadRequestException ( "state is required on creation" ) ; } Check updatedCheck = checksUpdate . get ( ) . createCheck ( key , toCheckUpdate ( input ) ) ;
import com . google . gerrit . extensions . restapi . RestModifyView ; import com . google . gerrit . plugins . checks . PostCheck ; import com . google . gwtorm . server . OrmException ; import com . google . inject . Inject ; import com . google . inject . Singleton ; import java . io . IOException ; @Singleton public class UpdateCheck implements RestModifyView < CheckResource , CheckInput > { private final PostCheck postCheck ; @Inject UpdateCheck ( PostCheck postCheck ) { this . postCheck = postCheck ; } @Override public CheckInfo apply ( CheckResource checkResource , CheckInput input ) < |startfocus| > throws RestApiException , IOException , OrmException { < |endfocus| > if ( input == null ) { input = new CheckInput ( ) ; } if ( input . checkerUuid == null ) { input . checkerUuid = checkResource . getCheckerUuid ( ) . toString ( ) ; } else if ( ! checkResource . getCheckerUuid ( ) . toString ( ) . equals ( input . checkerUuid ) ) { throw new BadRequestException ( String . format ( "checkerUuid must either be null or the same as on the resource : \n" + "the check resource belongs to checker % s , " + " but in the input checker % s was specified" , checkResource . getCheckerUuid ( ) , input . checkerUuid ) ) ; }
private static int getInt ( Config cfg , String section , String name , int defaultValue ) { try { return cfg . getInt ( section , name , defaultValue ) ; } catch ( IllegalArgumentException e ) { < |startfocus| > multisiteLog . error ( "invalid value for { } ; using default value { } " , name , defaultValue ) ; multisiteLog . error ( "Failed to retrieve integer value : { } " , e . getMessage ( ) , e ) ; < |endfocus| > return defaultValue ; }
for ( String name : config . getNames ( KAFKA_SECTION , section , true ) ) { if ( name . startsWith ( KAFKA_PROPERTY_PREFIX ) ) { Object value = config . getString ( KAFKA_SECTION , subsectionName , name ) ; String configProperty = name . replaceFirst ( KAFKA_PROPERTY_PREFIX , "" ) ; String propName = CaseFormat . LOWER_CAMEL . to ( CaseFormat . LOWER_HYPHEN , configProperty ) . replaceAll ( " - " , " . " ) ; < |startfocus| > multisiteLog . info ( " [ { } ] Setting kafka property : { } = { } " , subsectionName , propName , value ) ; < |endfocus| > target . put ( propName , value ) ; } } } } target . put ( "bootstrap . servers" , getString ( config , KAFKA_SECTION , null , "bootstrapServers" , DEFAULT_KAFKA_BOOTSTRAP_SERVERS ) ) ;
private static boolean getBoolean ( Config cfg , String section , String name , boolean defaultValue ) { try { return cfg . getBoolean ( section , name , defaultValue ) ; } catch ( IllegalArgumentException e ) { < |startfocus| > multisiteLog . error ( "invalid value for { } ; using default value { } " , name , defaultValue ) ; multisiteLog . debug ( "Failed to retrieve boolean value : { } " , e . getMessage ( ) , e ) ; < |endfocus| > return defaultValue ; } }
import com . googlesource . gerrit . plugins . multisite . forwarder . ForwarderModule ; import com . googlesource . gerrit . plugins . multisite . forwarder . broker . BrokerForwarderModule ; import com . googlesource . gerrit . plugins . multisite . index . IndexModule ; import com . googlesource . gerrit . plugins . multisite . kafka . consumer . KafkaConsumerModule ; import com . googlesource . gerrit . plugins . multisite . kafka . router . ForwardedEventRouterModule ; import java . io . BufferedReader ; import java . io . BufferedWriter ; import java . io . FileReader ; import java . io . IOException ; import java . nio . file . Files ; import java . nio . file . Paths ; import java . util . UUID ; < |startfocus| > public class Module extends LifecycleModule { < |endfocus| > private final Configuration config ; @Inject public Module ( Configuration config ) { this . config = config ; } @Override protected void configure ( ) { bind ( LifecycleListener . class ) . annotatedWith ( UniqueAnnotations . create ( ) ) . to ( MultiSiteLogFile . class ) ; install ( new ForwarderModule ( ) ) ; if ( config . cache ( ) . synchronize ( ) ) { install ( new CacheModule ( ) ) ; } if ( config . event ( ) . synchronize ( ) ) { install ( new EventModule ( ) ) ; } if ( config . index ( ) . synchronize ( ) ) { install ( new IndexModule ( ) ) ; }
protected void configure ( ) { < |startfocus| > bind ( LifecycleListener . class ) . annotatedWith ( UniqueAnnotations . create ( ) ) . to ( MultiSiteLogFile . class ) ; < |endfocus| > install ( new ForwarderModule ( ) ) ; if ( config . cache ( ) . synchronize ( ) ) { install ( new CacheModule ( ) ) ; } if ( config . event ( ) . synchronize ( ) ) { install ( new EventModule ( ) ) ; } if ( config . index ( ) . synchronize ( ) ) { install ( new IndexModule ( ) ) ; } if ( config . kafkaSubscriber ( ) . enabled ( ) ) { install ( new KafkaConsumerModule ( config . kafkaSubscriber ( ) ) ) ; install ( new ForwardedEventRouterModule ( ) ) ; } if ( config . kafkaPublisher ( ) . enabled ( ) ) { install ( new BrokerForwarderModule ( config . kafkaPublisher ( ) ) ) ; } bind ( Gson . class ) . toProvider ( GsonProvider . class ) . in ( Singleton . class ) ; }
// You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . broker . kafka ; < |startfocus| > import static com . googlesource . gerrit . plugins . multisite . MultiSiteLogFile . msgLog ; < |endfocus| > import com . google . inject . Inject ; import com . googlesource . gerrit . plugins . multisite . Configuration ; import com . googlesource . gerrit . plugins . multisite . InstanceId ; import com . googlesource . gerrit . plugins . multisite . broker . BrokerSession ; import com . googlesource . gerrit . plugins . multisite . forwarder . events . EventFamily ; import java . util . UUID ; import java . util . concurrent . ExecutionException ; import java . util . concurrent . Future ; import org . apache . kafka . clients . producer . KafkaProducer ; import org . apache . kafka . clients . producer . Producer ; import org . apache . kafka . clients . producer . ProducerRecord ; import org . apache . kafka . clients . producer . RecordMetadata ; public class KafkaSession implements BrokerSession { private final Configuration properties ;
public void connect ( ) { if ( isOpen ( ) ) { < |startfocus| > multisiteLog . error ( "Already connected . " ) ; < |endfocus| > return ; } multisiteLog . info ( "Connect to { } . . . " , properties . getKafka ( ) . getBootstrapServers ( ) ) ; /* Need to make sure that the thread of the running connection uses * the correct class loader otherwize you can endup with hard to debug * ClassNotFoundExceptions */ setConnectionClassLoader ( ) ; producer = new KafkaProducer < > ( properties . kafkaPublisher ( ) ) ; multisiteLog . info ( "Connection established . " ) ;
public void evict ( CacheEntry entry ) throws CacheNotFoundException { Cache < ? , ? > cache = cacheMap . get ( entry . getPluginName ( ) , entry . getCacheName ( ) ) ; if ( cache == null ) { throw new CacheNotFoundException ( entry . getPluginName ( ) , entry . getCacheName ( ) ) ; } try { Context . setForwardedEvent ( true ) ; if ( Constants . PROJECT_LIST . equals ( entry . getCacheName ( ) ) ) { // One key is holding the list of projects cache . invalidateAll ( ) ; < |startfocus| > multisiteLog . debug ( "Invalidated cache { } " , entry . getCacheName ( ) ) ; < |endfocus| > } else { cache . invalidate ( entry . getKey ( ) ) ; multisiteLog . debug ( "Invalidated cache { } [ { } ] " , entry . getCacheName ( ) , entry . getKey ( ) ) ; } } finally { Context . unsetForwardedEvent ( ) ; } } }
if ( cache == null ) { throw new CacheNotFoundException ( entry . getPluginName ( ) , entry . getCacheName ( ) ) ; } try { Context . setForwardedEvent ( true ) ; if ( Constants . PROJECT_LIST . equals ( entry . getCacheName ( ) ) ) { // One key is holding the list of projects cache . invalidateAll ( ) ; multisiteLog . debug ( "Invalidated cache { } " , entry . getCacheName ( ) ) ; } else { cache . invalidate ( entry . getKey ( ) ) ; < |startfocus| > multisiteLog . debug ( "Invalidated cache { } [ { } ] " , entry . getCacheName ( ) , entry . getKey ( ) ) ; < |endfocus| > } } finally { Context . unsetForwardedEvent ( ) ; } } }
SourceAwareEventWrapper event = valueDeserializer . deserialize ( consumerRecord . topic ( ) , consumerRecord . value ( ) ) ; if ( event . getHeader ( ) . getSourceInstanceId ( ) . equals ( instanceId ) ) { multisiteLog . debug ( "Dropping event { } produced by our instanceId { } " , event . toString ( ) , instanceId . toString ( ) ) ; droppedEventListeners . forEach ( l - > l . onEventDropped ( event ) ) ; } else { try { < |startfocus| > multisiteLog . info ( "Header [ { } ] Body [ { } ] " , event . getHeader ( ) , event . getBody ( ) ) ; < |endfocus| > eventRouter . route ( event . getEventBody ( gsonProvider ) ) ; } catch ( IOException e ) { multisiteLog . error ( "Malformed event ' { } ' : [ Exception : { } ] " , event . getHeader ( ) . getEventType ( ) , e ) ; } catch ( PermissionBackendException | OrmException e ) { multisiteLog . error ( "Cannot handle message { } : [ Exception : { } ] " , event . getHeader ( ) . getEventType ( ) , e ) ; } } } catch ( Exception e ) { multisiteLog . error ( "Malformed event ' { } ' : [ Exception : { } ] " , new String ( consumerRecord . value ( ) ) , e ) ;
// Copyright ( C ) 2018 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . // Copyright ( C ) 2018 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software
< |startfocus| > public static String stripEndSlash ( String name ) { name = name . replaceAll ( " / $" , "" ) ; < |endfocus| > return name ;
< |startfocus| > private static String strip ( String name ) { < |endfocus| > projectName = ProjectUtil . stripGitSuffix ( name ) ; projectName = ProjectUtil . stripEndSlash ( projectName ) ; return projectName ;
} @Test public void createProjectWithGitSuffix ( ) throws Exception { String newProjectName = name ( "newProject" ) ; ProjectInfo p = gApi . projects ( ) . create ( newProjectName + " . git" ) . get ( ) ; assertThat ( p . name ) . isEqualTo ( newProjectName ) ; ProjectState projectState = projectCache . get ( new Project . NameKey ( newProjectName ) ) ; assertThat ( projectState ) . isNotNull ( ) ; assertProjectInfo ( projectState . getProject ( ) , p ) ; assertHead ( newProjectName , "refs / heads / master" ) ; } < |startfocus| > @Test < |endfocus| > public void createProjectThatEndsWithSlash ( ) throws Exception { String newProjectName = name ( "newProject" ) ; ProjectInfo p = gApi . projects ( ) . create ( newProjectName + " / " ) . get ( ) ; assertThat ( p . name ) . isEqualTo ( newProjectName ) ; ProjectState projectState = projectCache . get ( new Project . NameKey ( newProjectName ) ) ; assertThat ( projectState ) . isNotNull ( ) ; assertProjectInfo ( projectState . getProject ( ) , p ) ; assertHead ( newProjectName , "refs / heads / master" ) ; } public void createProjectThatContainsSlash ( ) throws Exception { String newProjectName = name ( "newProject / newProject" ) ;
assertHead ( newProjectName , "refs / heads / master" ) ; } public void createProjectThatEndsWithSlash ( ) throws Exception { String newProjectName = name ( "newProject" ) ; ProjectInfo p = gApi . projects ( ) . create ( newProjectName + " / " ) . get ( ) ; assertThat ( p . name ) . isEqualTo ( newProjectName ) ; ProjectState projectState = projectCache . get ( new Project . NameKey ( newProjectName ) ) ; assertThat ( projectState ) . isNotNull ( ) ; assertProjectInfo ( projectState . getProject ( ) , p ) ; assertHead ( newProjectName , "refs / heads / master" ) ; } < |startfocus| > < |endfocus| > public void createProjectThatContainsSlash ( ) throws Exception { String newProjectName = name ( "newProject / newProject" ) ; ProjectInfo p = gApi . projects ( ) . create ( newProjectName ) . get ( ) ; assertThat ( p . name ) . isEqualTo ( newProjectName ) ; ProjectState projectState = projectCache . get ( new Project . NameKey ( newProjectName ) ) ; assertThat ( projectState ) . isNotNull ( ) ; assertProjectInfo ( projectState . getProject ( ) , p ) ; assertHead ( newProjectName , "refs / heads / master" ) ; } @Test public void createProjectWithProperties ( ) throws Exception { String newProjectName = name ( "newProject" ) ; ProjectInfo p = gApi . projects ( ) . create ( newProjectName ) . get ( ) ; assertThat ( p . name ) . isEqualTo ( newProjectName ) ; ProjectState projectState = projectCache . get ( new Project . NameKey ( newProjectName ) ) ; assertThat ( projectState ) . isNotNull ( ) ; assertProjectInfo ( projectState . getProject ( ) , p ) ; assertHead ( newProjectName , "refs / heads / master" ) ; }
adminSshSession . assertFailure ( ) ; ProjectState projectState = projectCache . get ( new Project . NameKey ( newProjectName ) ) ; assertThat ( projectState ) . isNull ( ) ; } @Test public void withDotGit ( ) throws Exception { String newGroupName = "newGroup" ; adminRestSession . put ( " / groups / " + newGroupName ) ; String newProjectName = "newProject" ; adminSshSession . exec ( < |startfocus| > "gerrit create - project -- branch master -- owner " + newGroupName + " " + newProjectName + " . git" ) ; < |endfocus| > adminSshSession . assertSuccess ( ) ; ProjectState projectState = projectCache . get ( new Project . NameKey ( newProjectName ) ) ; assertThat ( projectState ) . isNotNull ( ) ; assertThat ( projectState . getName ( ) ) . isEqualTo ( newProjectName ) ; } @Test public void withEndSlash ( ) throws Exception { String newGroupName = "newGroup" ; adminRestSession . put ( " / groups / " + newGroupName ) ; String newProjectName = "newProject" ; adminSshSession . exec ( "gerrit create - project -- branch master -- owner " + newGroupName + " " + newProjectName + " / " ) ; adminSshSession . assertSuccess ( ) ; ProjectState projectState = projectCache . get ( new Project . NameKey ( newProjectName ) ) ; assertThat ( projectState ) . isNotNull ( ) ; assertThat ( projectState . getName ( ) ) . isEqualTo ( newProjectName ) ; } }
} @VisibleForTesting void setReportSyntaxError ( boolean value ) { reportSyntaxError = value ; } int getMinOwnerVoteLevel ( ProjectState projectState , ChangeData c ) { if ( projectState == null ) { logger . atSevere ( ) . log ( "Null projectState for change % s" , getChangeId ( c ) ) ; return minOwnerVoteLevel ; } return getPluginConfig ( projectState ) . getInt ( MIN_OWNER_VOTE_LEVEL , minOwnerVoteLevel ) ; } } < |startfocus| > enum EnforcementLevel { DISABLED , WARN , ENFORCE ; static final String CONFIG_NAME = "enforce_level" ; } < |endfocus| >
protected Destination ( Injector injector , RemoteSiteUser . Factory replicationUserFactory , PluginUser pluginUser , GitRepositoryManager gitRepositoryManager , PermissionBackend permissionBackend , Provider < CurrentUser > userProvider , ProjectCache projectCache , GroupBackend groupBackend , ReplicationStateListener stateLog , GroupIncludeCache groupIncludeCache , DynamicItem < EventDispatcher > eventDispatcher , < |startfocus| > @Assisted DestinationConfiguration cfg < |endfocus| > ) { config = cfg ; this . eventDispatcher = eventDispatcher ; gitManager = gitRepositoryManager ; this . permissionBackend = permissionBackend ; this . userProvider = userProvider ; this . projectCache = projectCache ; this . stateLog = stateLog ; CurrentUser remoteUser ; if ( ! cfg . getAuthGroupNames ( ) . isEmpty ( ) ) { ImmutableSet . Builder < AccountGroup . UUID > builder = ImmutableSet . builder ( ) ; for ( String name : cfg . getAuthGroupNames ( ) ) { GroupReference g = GroupBackends . findExactSuggestion ( groupBackend , name ) ; if ( g != null ) { builder . add ( g . getUUID ( ) ) ; addRecursiveParents ( g . getUUID ( ) , builder , groupIncludeCache ) ; } else {
protected void configure ( ) { DynamicSet . bind ( binder ( ) , RefOperationValidationListener . class ) . to ( InSyncChangeValidator . class ) ; < |startfocus| > bind ( DfsRefDatabase . class ) . to ( InMemoryDfsRefDatabase . class ) ; < |endfocus| >
private boolean isImmutableRef ( String refName ) { < |startfocus| > return refName . startsWith ( "refs / changes" ) && ! refName . endsWith ( " / meta" ) ; < |endfocus| >
< |startfocus| > Copyright ( C ) 2018 The Android Open Source Project < |endfocus| > // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation ; import com . google . gerrit . extensions . registration . DynamicSet ; import com . google . gerrit . server . git . validators . RefOperationValidationListener ; import com . google . inject . AbstractModule ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . NoOpDfsRefDatabase ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . SharedRefDatabase ; public class ValidationModule extends AbstractModule { @Override protected void configure ( ) { DynamicSet . bind ( binder ( ) , RefOperationValidationListener . class ) . to ( InSyncChangeValidator . class ) ;
// Copyright ( C ) 2018 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation ; import static com . google . common . truth . Truth . assertThat ; import static org . hamcrest . CoreMatchers . nullValue ; import static org . hamcrest . CoreMatchers . sameInstance ; import static org . mockito . Mockito . any ; import static org . mockito . Mockito . argThat ; import static org . mockito . Mockito . doReturn ; import static org . mockito . Mockito . doThrow ; import static org . mockito . Mockito . eq ; import static org . mockito . Mockito . verify ; import static org . mockito . Mockito . verifyZeroInteractions ;
. when ( dfsRefDatabase ) . compareAndPut ( any ( ) , eq ( null ) , any ( ) ) ; doThrow ( new NullPointerException ( "newRef is null" ) ) . when ( dfsRefDatabase ) . compareAndPut ( any ( ) , any ( ) , eq ( null ) ) ; doThrow ( new NullPointerException ( "project name is null" ) ) . when ( dfsRefDatabase ) . compareAndPut ( eq ( null ) , any ( ) , any ( ) ) ; < |startfocus| > // doReturn ( false ) . when ( dfsRefDatabase ) . compareAndPut ( eq ( PROJECT_NAME ) , eqRef ( REF_NAME , // REF_OBJID_OLD ) , eqRef ( REF_NAME , REF_OBJID ) ) ; < |endfocus| > validator = new InSyncChangeValidator ( dfsRefDatabase , repoManager ) ; repoManager . createRepository ( PROJECT_NAMEKEY ) ; } @Test public void shouldNotVerifyStatusOfImmutablePatchSetRefs ( ) throws Exception { testRefReceivedEvent . command = RECEIVE_COMMAND_CREATE_PATCHSET_REF ; final List < ValidationMessage > validationMessages = validator . onRefOperation ( testRefReceivedEvent ) ; assertThat ( validationMessages ) . isEmpty ( ) ; verifyZeroInteractions ( dfsRefDatabase ) ; } @Test public void shouldInsertNewRefInDfsDatabaseWhenHandlingRefCreationEvents ( ) throws Exception { testRefReceivedEvent . command = RECEIVE_COMMAND_CREATE_REF ;
< |startfocus| > Copyright ( C ) 2018 The Android Open Source Project < |endfocus| > // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation ; import com . google . common . flogger . FluentLogger ; import com . google . gerrit . acceptance . LightweightPluginDaemonTest ; import com . google . gerrit . acceptance . LogThreshold ; import com . google . gerrit . acceptance . NoHttpd ; import com . google . gerrit . acceptance . PushOneCommit ; import com . google . gerrit . acceptance . TestPlugin ; import com . google . inject . AbstractModule ; import org . junit . Test ; @NoHttpd @LogThreshold ( level = "INFO" ) @TestPlugin ( name = "multi - site" ,
* Starts the fluent chain for querying or modifying a check . Please see the methods of { @link * PerCheckOperations } for details on possible operations . * * @param key key of the check * @return an aggregation of operations on a specific check */ PerCheckOperations check ( CheckKey key ) ; /* * * Starts the fluent chain to create a check . The returned builder can be used to specify the < |startfocus| > * attributes of the new check . To create the check for real , { @link < |endfocus| > * TestCheckUpdate . Builder#upsert ( ) } must be called . * * < p > Example : * * < pre > * checkOperations * . newCheck ( checkKey ) * . setState ( CheckState . RUNNING ) * . upsert ( ) ; * </ pre > * * < p > < strong >
< |startfocus| > Copyright ( C ) 2015 The Android Open Source Project < |endfocus| > // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite ; import com . google . gerrit . server . notedb . NotesMigration ; import com . google . inject . Inject ; public class GerritNoteDbStatus implements NoteDbStatus { private final NotesMigration notesMigration ; @Inject public GerritNoteDbStatus ( NotesMigration notesMigration ) { this . notesMigration = notesMigration ; } @Override public boolean enabled ( ) { return notesMigration . commitChangeWrites ( ) ; } }
< |startfocus| > Copyright ( C ) 2015 The Android Open Source Project < |endfocus| > // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite ; /* * Returns the status of changes migration . */ public interface NoteDbStatus { /* * * Status of NoteDb migration . * * @return true if Gerrit has been migrated to NoteDb */ boolean enabled ( ) ; }
// Name of plugin and namespace . static final String PLUGIN_NAME = "find - owners" ; static final String PROLOG_NAMESPACE = "find_owners" ; private final PluginConfigFactory configFactory ; // Global / plugin config parameters . private boolean addDebugMsg = false ; private int minOwnerVoteLevel = 1 ; private int maxCacheAge = 0 ; private int maxCacheSize = 1000 ; private boolean reportSyntaxError = false ; private boolean alwaysShowButton = false ; private String ownersFileName = OWNERS ; < |startfocus| > < |endfocus| > private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; Config ( PluginConfigFactory configFactory ) { this . configFactory = configFactory ; if ( configFactory == null ) { // When called from integration tests . return ; } PluginConfig gc = configFactory . getFromGerritConfig ( PLUGIN_NAME ) ; // Get config variables from the plugin section of gerrit . config addDebugMsg = gc . getBoolean ( ADD_DEBUG_MSG , false ) ; reportSyntaxError = gc . getBoolean ( REPORT_SYNTAX_ERROR , false ) ; alwaysShowButton = gc . getBoolean ( ALWAYS_SHOW_BUTTON , false ) ;
private final DestinationConfiguration config ; private final DynamicItem < EventDispatcher > eventDispatcher ; protected enum RetryReason { TRANSPORT_ERROR , COLLISION , REPOSITORY_MISSING ; } public static class QueueInfo { public final Map < URIish , PushOne > pending ; public final Map < URIish , PushOne > inFlight ; public QueueInfo ( Map < URIish , PushOne > pending , Map < URIish , PushOne > inFlight ) { this . pending = ImmutableMap . copyOf ( pending ) ; this . inFlight = ImmutableMap . copyOf ( inFlight ) ; } } < |startfocus| > < |endfocus| > protected Destination ( Injector injector , RemoteSiteUser . Factory replicationUserFactory , PluginUser pluginUser , GitRepositoryManager gitRepositoryManager , PermissionBackend permissionBackend , Provider < CurrentUser > userProvider , ProjectCache projectCache , GroupBackend groupBackend , ReplicationStateListener stateLog , GroupIncludeCache groupIncludeCache , DynamicItem < EventDispatcher > eventDispatcher , @Assisted DestinationConfiguration cfg ) { this . eventDispatcher = eventDispatcher ; gitManager = gitRepositoryManager ; this . permissionBackend = permissionBackend ; this . userProvider = userProvider ; this . projectCache = projectCache ; this . stateLog = stateLog ; config = cfg ; }
import com . googlesource . gerrit . plugins . multisite . forwarder . events . ChangeIndexEvent ; import java . util . ArrayList ; import java . util . List ; import java . util . concurrent . LinkedBlockingQueue ; import java . util . concurrent . TimeUnit ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . revwalk . RevCommit ; import org . eclipse . jgit . revwalk . RevWalk ; import org . junit . Before ; import org . junit . Test ; import org . testcontainers . containers . KafkaContainer ; @NoHttpd @LogThreshold ( level = "INFO" ) < |startfocus| > @Sandboxed < |endfocus| > @TestPlugin ( name = "multi - site" , sysModule = "com . googlesource . gerrit . plugins . multisite . kafka . consumer . EventConsumerIT$KafkaTestContainerModule" ) public class EventConsumerIT extends LightweightPluginDaemonTest { private static final int QUEUE_POLL_TIMEOUT_MSECS = 30000 ; static { System . setProperty ( "gerrit . notedb" , "READ_WRITE" ) ; } public static class KafkaTestContainerModule extends LifecycleModule { public class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka ; public KafkaStopAtShutdown ( KafkaContainer kafka ) { this . kafka = kafka ; } @Override
super . setUpTestPlugin ( ) ; if ( ! notesMigration . commitChangeWrites ( ) ) { throw new IllegalStateException ( "NoteDb is mandatory for running the multi - site plugin" ) ; } } @Test public void createChangeShouldPropagateChangeIndexAndRefUpdateStreamEvent ( ) throws Exception { LinkedBlockingQueue < SourceAwareEventWrapper > droppedEventsQueue = captureDroppedEvents ( ) ; drainQueue ( droppedEventsQueue ) ; PushOneCommit . Result r = createChange ( ) ; < |startfocus| > List < Event > createdChangeEvents = receiveFromQueue ( droppedEventsQueue , 4 ) ; assertThat ( createdChangeEvents ) . hasSize ( 4 ) ; ChangeData change = r . getChange ( ) ; assertThat ( createdChangeEvents . stream ( ) . filter ( e - > e . type . equals ( "change - index" ) ) . collect ( toSet ( ) ) ) . containsExactlyElementsIn ( ImmutableList . of ( createChangeIndexEvent ( change . project ( ) . get ( ) , change . getId ( ) . get ( ) , getParentCommit ( change ) ) ) ) ; assertThat ( createdChangeEvents . stream ( ) . filter ( e - > e . type . equals ( "ref - updated" ) ) . map ( RefUpdatedEvent . class : : cast ) . map ( e - > e . getRefName ( ) ) . collect ( toSet ( ) ) ) . containsExactlyElementsIn ( < |endfocus| >
. collect ( toSet ( ) ) ) . containsExactlyElementsIn ( ImmutableList . of ( createChangeIndexEvent ( change . project ( ) . get ( ) , change . getId ( ) . get ( ) , getParentCommit ( change ) ) ) ) ; assertThat ( createdChangeEvents . stream ( ) . filter ( e - > e . type . equals ( "ref - updated" ) ) . map ( RefUpdatedEvent . class : : cast ) . map ( e - > e . getRefName ( ) ) . collect ( toSet ( ) ) ) < |startfocus| > . containsExactlyElementsIn ( ImmutableList . of ( "refs / sequences / changes" , change . currentPatchSet ( ) . getRefName ( ) , "refs / changes / " + change . getId ( ) . get ( ) + " / meta" ) ) ; < |endfocus| > PatchSetCreatedEvent patchSetCreated = createdChangeEvents . stream ( ) . filter ( e - > e . type . equals ( "patchset - created" ) ) . map ( PatchSetCreatedEvent . class : : cast ) . findFirst ( ) . get ( ) ; PatchSetAttribute patchSetAttribute = patchSetCreated . patchSet . get ( ) ; PatchSet currentPatchSet = change . currentPatchSet ( ) ; assertThat ( patchSetAttribute . number ) . isEqualTo ( currentPatchSet . getPatchSetId ( ) ) ; assertThat ( patchSetAttribute . revision ) . isEqualTo ( currentPatchSet . getRevision ( ) . get ( ) ) ; assertThat ( patchSetAttribute . ref ) . isEqualTo ( currentPatchSet . getRefName ( ) ) ; } @Test
import com . google . inject . TypeLiteral ; import com . googlesource . gerrit . plugins . multisite . Configuration ; import com . googlesource . gerrit . plugins . multisite . Module ; import com . googlesource . gerrit . plugins . multisite . broker . GsonProvider ; import com . googlesource . gerrit . plugins . multisite . forwarder . events . ChangeIndexEvent ; import java . util . ArrayList ; import java . util . List ; import java . util . concurrent . LinkedBlockingQueue ; import java . util . concurrent . TimeUnit ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . revwalk . RevCommit ; < |startfocus| > import org . eclipse . jgit . revwalk . RevWalk ; < |endfocus| > import org . junit . Test ; import org . testcontainers . containers . KafkaContainer ; @NoHttpd @LogThreshold ( level = "INFO" ) @TestPlugin ( name = "multi - site" , sysModule = "com . googlesource . gerrit . plugins . multisite . kafka . consumer . EventConsumerIT$KafkaTestContainerModule" ) public class EventConsumerIT extends LightweightPluginDaemonTest { private static final int QUEUE_POLL_TIMEOUT_MSECS = 30000 ; public static class KafkaTestContainerModule extends LifecycleModule { public class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka ; public KafkaStopAtShutdown ( KafkaContainer kafka ) {
protected void configure ( ) { if ( ! noteDb . enabled ( ) ) { throw new ProvisionException ( < |startfocus| > "Gerrit is still running on ReviewDb : please migrate to NoteDb and then reload the multi - site plugin . " ) ; < |endfocus| > } listener ( ) . to ( Log4jMessageLogger . class ) ; bind ( MessageLogger . class ) . to ( Log4jMessageLogger . class ) ; install ( new ForwarderModule ( ) ) ; if ( config . cache ( ) . synchronize ( ) ) { install ( new CacheModule ( ) ) ; } if ( config . event ( ) . synchronize ( ) ) { install ( new EventModule ( ) ) ; } if ( config . index ( ) . synchronize ( ) ) { install ( new IndexModule ( ) ) ; } if ( config . kafkaSubscriber ( ) . enabled ( ) ) { install ( new KafkaConsumerModule ( config . kafkaSubscriber ( ) ) ) ; install ( new ForwardedEventRouterModule ( ) ) ; } if ( config . kafkaPublisher ( ) . enabled ( ) ) { install ( new BrokerForwarderModule ( config . kafkaPublisher ( ) ) ) ; } install ( new ValidationModule ( ) ) ; bind ( Gson . class ) . toProvider ( GsonProvider . class ) . in ( Singleton . class ) ;
import com . google . inject . Inject ; import com . google . inject . Provider ; import com . google . inject . Singleton ; import java . util . List ; import java . util . stream . Stream ; @Singleton public class PendingChecksImpl implements PendingChecks { private final Provider < ListPendingChecks > listPendingChecksProvider ; @Inject PendingChecksImpl ( Provider < ListPendingChecks > listPendingChecksProvider ) { this . listPendingChecksProvider = listPendingChecksProvider ; } @Override public List < PendingChecksInfo > list ( String checkerUuidString , CheckState . . . checkStates ) throws RestApiException { < |startfocus| > CheckerUuid checkerUuid = CheckerUuid . tryParse ( checkerUuidString ) . orElseThrow ( ( ) - > new BadRequestException ( String . format ( "invalid checker UUID : % s" , checkerUuidString ) ) ) ; < |endfocus| > return list ( checkerUuid , checkStates ) ; } @Override public List < PendingChecksInfo > list ( CheckerUuid checkerUuid , CheckState . . . checkStates ) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider . get ( ) ; listPendingChecks . setChecker ( checkerUuid ) ; if ( checkStates != null ) { Stream . of ( checkStates ) . forEach ( listPendingChecks : : addState ) ; } return listPendingChecks . apply ( TopLevelResource . INSTANCE ) ; } catch ( Exception e ) { throw asRestApiException ( "Cannot list pending checks" , e ) ; } } @Override
this . listPendingChecksProvider = listPendingChecksProvider ; } @Override public List < PendingChecksInfo > list ( String checkerUuidString , CheckState . . . checkStates ) throws RestApiException { CheckerUuid checkerUuid = CheckerUuid . tryParse ( checkerUuidString ) . orElseThrow ( ( ) - > new BadRequestException ( String . format ( "invalid checker UUID : % s" , checkerUuidString ) ) ) ; try { ListPendingChecks listPendingChecks = listPendingChecksProvider . get ( ) ; listPendingChecks . setChecker ( checkerUuid ) ; < |startfocus| > Stream . of ( checkStates ) . forEach ( listPendingChecks : : addState ) ; < |endfocus| > return listPendingChecks . apply ( TopLevelResource . INSTANCE ) ; } catch ( Exception e ) { throw asRestApiException ( "Cannot list pending checks" , e ) ; } } @Override public List < PendingChecksInfo > listForScheme ( String scheme , CheckState . . . checkStates ) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider . get ( ) ; listPendingChecks . setScheme ( scheme ) ; if ( checkStates != null ) { Stream . of ( checkStates ) . forEach ( listPendingChecks : : addState ) ; }
if ( checkStates != null ) { Stream . of ( checkStates ) . forEach ( listPendingChecks : : addState ) ; } return listPendingChecks . apply ( TopLevelResource . INSTANCE ) ; } catch ( Exception e ) { throw asRestApiException ( "Cannot list pending checks" , e ) ; } } @Override public List < PendingChecksInfo > listForScheme ( String scheme , CheckState . . . checkStates ) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider . get ( ) ; listPendingChecks . setScheme ( scheme ) ; < |startfocus| > Stream . of ( checkStates ) . forEach ( listPendingChecks : : addState ) ; < |endfocus| > return listPendingChecks . apply ( TopLevelResource . INSTANCE ) ; } catch ( Exception e ) { throw asRestApiException ( "Cannot list pending checks for scheme" , e ) ; } } }
// You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . its . jira ; < |startfocus| > import static com . googlesource . gerrit . plugins . its . jira . JiraConfig . JIRA_URL ; import static com . googlesource . gerrit . plugins . its . jira . JiraConfig . JIRA_USERNAME ; import static com . googlesource . gerrit . plugins . its . jira . JiraConfig . JIRA_PASSWORD ; < |endfocus| > import com . google . gerrit . extensions . annotations . Exports ; import com . google . gerrit . extensions . annotations . PluginName ; import com . google . gerrit . server . config . PluginConfigFactory ; import com . google . gerrit . server . config . ProjectConfigEntry ; import com . google . inject . AbstractModule ; import com . google . inject . Inject ; import com . googlesource . gerrit . plugins . its . base . ItsHookModule ; import com . googlesource . gerrit . plugins . its . base . its . ItsConfig ; import com . googlesource . gerrit . plugins . its . base . its . ItsFacade ; import com . googlesource . gerrit . plugins . its . base . its . ItsFacadeFactory ; import com . googlesource . gerrit . plugins . its . base . workflow . CustomAction ;
String email = preferredEmails . get ( owner ) ; for ( String path : result . owner2paths . get ( owner ) ) { addOwnerPathPair ( email , path ) ; } } for ( String glob : result . noParentGlobs ) { add2dir2Globs ( Util . getDirName ( glob ) + " / " , glob ) ; } if ( config . getReportSyntaxError ( ) ) { Ordering . natural ( ) . sortedCopy ( result . warnings ) . forEach ( w - > logger . atWarning ( ) . log ( w ) ) ; < |startfocus| > Ordering . natural ( ) . sortedCopy ( result . errors ) . forEach ( e - > logger . atSevere ( ) . log ( e ) ) ; < |endfocus| > }
private static void saveReadFile ( Map < String , String > readFiles , String project , String file , String content ) { if ( readFiles != null ) { < |startfocus| > readFiles . put ( includedFileKey ( project , file ) , content ) ; < |endfocus| > }
private static void checkIncludeOrFile ( List < CommitValidationMessage > messages , String path , int num , String line ) { < |startfocus| > // TODO : Check if an included file exists and with valid syntax . < |endfocus| > // An included file could be a new file added by a CL and not in the repository yet add ( messages , "unchecked : " + path + " : " + num + " : " + Parser . getIncludeOrFile ( line ) , false ) ;
private GitRepositoryManager repoManager ; private String branch ; // All owners files are read from the same branch . private IncludeStack stack ; // a stack of including files . private List < String > logs ; // Keeps debug / trace messages . private Map < String , Result > savedResults ; // projectName : filePath = > Parser . Result static class IncludeStack { Deque < String > projectName ; // project / repository name of included file Deque < String > filePath ; // absolute or relative path of included file < |startfocus| > Set < String > allFiles ; // to detect recursive inclusion quickly < |endfocus| > IncludeStack ( String project , String file ) { projectName = new ArrayDeque < > ( ) ; filePath = new ArrayDeque < > ( ) ; allFiles = new HashSet < > ( ) ; push ( project , file ) ; } void push ( String project , String file ) { projectName . push ( project ) ; filePath . push ( file ) ; allFiles . add ( project + " : " + file ) ; } void pop ( ) { allFiles . remove ( currentProject ( ) + " : " + currentFile ( ) ) ; projectName . pop ( ) ; filePath . pop ( ) ; }
void push ( String project , String file ) { projectName . push ( project ) ; filePath . push ( file ) ; < |startfocus| > allFiles . add ( getFileName ( project , file ) ) ; < |endfocus| >
void pop ( ) { < |startfocus| > allFiles . remove ( currentProject ( ) + " : " + currentFile ( ) ) ; < |endfocus| > projectName . pop ( ) ; filePath . pop ( ) ; }
boolean contains ( String project , String file ) { < |startfocus| > return allFiles . contains ( project + " : " + file ) ; < |endfocus| > }
rp . sendError ( "internal error while processing changes" ) ; // ReceiveCommits has tried its best to catch errors , so anything at this // point is very bad . for ( ReceiveCommand c : commands ) { if ( c . getResult ( ) == Result . NOT_ATTEMPTED ) { c . setResult ( Result . REJECTED_OTHER_REASON , "internal error" ) ; } } } finally { w . sendMessages ( ) ; } long deltaNanos = System . nanoTime ( ) - startNanos ; int totalChanges = 0 ; < |startfocus| > String pushType ; < |endfocus| > if ( resultChangeIds . isMagicPush ( ) ) { pushType = "CREATE_REPLACE" ; List < Change . Id > created = resultChangeIds . get ( ResultChangeIds . Key . CREATED ) ; List < Change . Id > replaced = resultChangeIds . get ( ResultChangeIds . Key . REPLACED ) ; metrics . changes . record ( pushType , created . size ( ) + replaced . size ( ) ) ; totalChanges += replaced . size ( ) + created . size ( ) ; } else { List < Change . Id > autoclosed = resultChangeIds . get ( ResultChangeIds . Key . AUTOCLOSED ) ; if ( ! autoclosed . isEmpty ( ) ) { pushType = ResultChangeIds . Key . AUTOCLOSED . name ( ) ; metrics . changes . record ( pushType , autoclosed . size ( ) ) ; totalChanges += autoclosed . size ( ) ; } else { pushType = ResultChangeIds . Key . UPDATED . name ( ) ; List < Change . Id > updated = resultChangeIds . get ( ResultChangeIds . Key . UPDATED ) ; metrics . changes . record ( pushType , updated . size ( ) ) ; totalChanges += updated . size ( ) ; } } metrics . delta . record ( deltaNanos , TimeUnit . NANOSECONDS ) ; metrics . commits . record ( commits . size ( ) ) ; metrics . changesPerCommit . record ( commits . size ( ) == 0 ? 0 : totalChanges / commits . size ( ) ) ; } }
} finally { w . sendMessages ( ) ; } long deltaNanos = System . nanoTime ( ) - startNanos ; int totalChanges = 0 ; String pushType ; if ( resultChangeIds . isMagicPush ( ) ) { pushType = "CREATE_REPLACE" ; List < Change . Id > created = resultChangeIds . get ( ResultChangeIds . Key . CREATED ) ; List < Change . Id > replaced = resultChangeIds . get ( ResultChangeIds . Key . REPLACED ) ; metrics . changes . record ( pushType , created . size ( ) + replaced . size ( ) ) ; < |startfocus| > totalChanges = replaced . size ( ) + created . size ( ) ; < |endfocus| > } else { List < Change . Id > autoclosed = resultChangeIds . get ( ResultChangeIds . Key . AUTOCLOSED ) ; if ( ! autoclosed . isEmpty ( ) ) { pushType = ResultChangeIds . Key . AUTOCLOSED . name ( ) ; metrics . changes . record ( ResultChangeIds . Key . AUTOCLOSED . name ( ) , autoclosed . size ( ) ) ; totalChanges = autoclosed . size ( ) ; } else { pushType = "NORMAL" ; } } if ( totalChanges > 0 ) { metrics . latencyPerChange . record ( pushType , deltaNanos / totalChanges , NANOSECONDS ) ; } metrics . latencyPerPush . record ( pushType , deltaNanos , NANOSECONDS ) ;
String patchsetRevision = change . currentPatchSet ( ) . getRevision ( ) . get ( ) ; String patchsetRef = change . currentPatchSet ( ) . getRefName ( ) ; Map < String , List < Event > > eventsByType = receiveEventsByType ( droppedEventsQueue ) ; assertThat ( eventsByType . get ( "change - index" ) ) . containsExactly ( createChangeIndexEvent ( project , changeNum , getParentCommit ( change ) ) ) ; assertThat ( eventsByType . get ( "ref - updated" ) . stream ( ) . map ( e - > ( ( RefUpdatedEvent ) e ) . getRefName ( ) ) . collect ( toSet ( ) ) ) < |startfocus| > . containsAllOf ( changeNotesRef , patchsetRef ) ; < |endfocus| > List < Event > patchSetCreatedEvents = eventsByType . get ( "patchset - created" ) ; assertThat ( patchSetCreatedEvents ) . hasSize ( 1 ) ; assertPatchSetAttributes ( ( PatchSetCreatedEvent ) patchSetCreatedEvents . get ( 0 ) , patchsetNum , patchsetRevision , patchsetRef ) ; } private void assertPatchSetAttributes ( PatchSetCreatedEvent patchSetCreated , int patchsetNum , String patchsetRevision , String patchsetRef ) { PatchSetAttribute patchSetAttribute = patchSetCreated . patchSet . get ( ) ; assertThat ( patchSetAttribute . number ) . isEqualTo ( patchsetNum ) ; assertThat ( patchSetAttribute . revision ) . isEqualTo ( patchsetRevision ) ; assertThat ( patchSetAttribute . refName ) . isEqualTo ( patchsetRef ) ; }
. collect ( Collectors . groupingBy ( e - > e . type ) ) ; } private List < Event > drainQueue ( LinkedBlockingQueue < SourceAwareEventWrapper > queue ) throws InterruptedException { GsonProvider gsonProvider = plugin . getSysInjector ( ) . getInstance ( Key . get ( GsonProvider . class ) ) ; SourceAwareEventWrapper event ; List < Event > eventsList = new ArrayList < > ( ) ; while ( ( event = queue . poll ( QUEUE_POLL_TIMEOUT_MSECS , TimeUnit . MILLISECONDS ) ) != null ) { < |startfocus| > System . out . println ( "Received event : " + event . getHeader ( ) + " / " + event . getBody ( ) ) ; < |endfocus| > eventsList . add ( event . getEventBody ( gsonProvider ) ) ; } return eventsList ; } }
private final CheckResource checkResource ; @Inject CheckApiImpl ( GetCheck getCheck , UpdateCheck updateCheck , @Assisted CheckResource checkResource ) { this . getCheck = getCheck ; this . updateCheck = updateCheck ; this . checkResource = checkResource ; } @Override public CheckInfo get ( ListChecksOption . . . options ) throws RestApiException { try { Arrays . stream ( options ) . forEach ( getCheck : : addOption ) ; return getCheck . apply ( checkResource ) ; } catch ( Exception e ) { < |startfocus| > throw asRestApiException ( "Cannot retrieve check" , e ) ; < |endfocus| > } } @Override public CheckInfo update ( CheckInput input ) throws RestApiException { try { return updateCheck . apply ( checkResource , input ) ; } catch ( Exception e ) { throw asRestApiException ( "Cannot update check" , e ) ; } } }
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . extensions . client ; import java . lang . reflect . InvocationTargetException ; import java . util . EnumSet ; /* * Enum that can be expressed as a bitset in query parameters . */ public interface ListOption { int getValue ( ) ; < |startfocus| > static < T extends Enum < T > & ListOption > EnumSet < T > fromBits ( Class < T > clazz , int v ) { EnumSet < T > r = EnumSet . noneOf ( clazz ) ; T [ ] values ; < |endfocus| > try { @SuppressWarnings ( "unchecked" ) T [ ] tmp = ( T [ ] ) clazz . getMethod ( "values" ) . invoke ( null ) ; values = tmp ; } catch ( IllegalAccessException | NoSuchMethodException | InvocationTargetException e ) { throw new IllegalStateException ( e ) ; } for ( T o : values ) { if ( ( v & ( 1 < < o . getValue ( ) ) ) != 0 ) { r . add ( o ) ; v &= ~ ( 1 < < o . getValue ( ) ) ; }
import com . google . gerrit . server . git . PureRevertCache ; import com . google . gerrit . server . notedb . ChangeNotes ; import com . google . gwtorm . server . OrmException ; import com . google . inject . Inject ; import com . google . inject . Singleton ; import java . io . IOException ; import org . eclipse . jgit . errors . InvalidObjectIdException ; import org . eclipse . jgit . lib . ObjectId ; @Singleton public class PureRevert { private final PureRevertCache pureRevertCache ; @Inject PureRevert ( PureRevertCache pureRevertCache ) { this . pureRevertCache = pureRevertCache ; } < |startfocus| > public PureRevertInfo get ( ChangeNotes notes , @Nullable String claimedOriginal ) < |endfocus| > throws OrmException , IOException , BadRequestException , ResourceConflictException { PatchSet currentPatchSet = notes . getCurrentPatchSet ( ) ; if ( currentPatchSet == null ) { throw new ResourceConflictException ( "current revision is missing" ) ; } if ( claimedOriginal == null ) { return new PureRevertInfo ( pureRevertCache . isPureRevert ( notes ) ) ; } ObjectId claimedOriginalObjectId ; try { claimedOriginalObjectId = ObjectId . fromString ( claimedOriginal ) ; } catch ( InvalidObjectIdException e ) { throw new BadRequestException ( "invalid object ID" ) ; }
PatchSet currentPatchSet = notes . getCurrentPatchSet ( ) ; if ( currentPatchSet == null ) { throw new ResourceConflictException ( "current revision is missing" ) ; } if ( claimedOriginal == null ) { return new PureRevertInfo ( pureRevertCache . isPureRevert ( notes ) ) ; } ObjectId claimedOriginalObjectId ; try { claimedOriginalObjectId = ObjectId . fromString ( claimedOriginal ) ; } catch ( InvalidObjectIdException e ) { throw new BadRequestException ( "invalid object ID" ) ; } < |startfocus| > boolean result = pureRevertCache . isPureRevert ( notes . getProjectName ( ) , ObjectId . fromString ( notes . getCurrentPatchSet ( ) . getRevision ( ) . get ( ) ) , claimedOriginalObjectId ) ; return new PureRevertInfo ( result ) ; < |endfocus| > } }
import org . eclipse . jgit . diff . DiffFormatter ; import org . eclipse . jgit . errors . InvalidObjectIdException ; import org . eclipse . jgit . errors . MissingObjectException ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . ObjectInserter ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . merge . ThreeWayMerger ; import org . eclipse . jgit . revwalk . RevCommit ; import org . eclipse . jgit . revwalk . RevWalk ; /* * Computes and caches if a change is a pure revert of another change . */ @Singleton public class PureRevertCache { < |startfocus| > static final String ID_CACHE = "pure_revert" ; < |endfocus| > public static class Module extends CacheModule { @Override protected void configure ( ) { persist ( ID_CACHE , Cache . PureRevertKeyProto . class , Boolean . class ) . maximumWeight ( 100 ) . loader ( Loader . class ) . version ( 1 ) . keySerializer ( new ProtobufSerializer < > ( Cache . PureRevertKeyProto . parser ( ) ) ) . valueSerializer ( BooleanCacheSerializer . INSTANCE ) ; } } private final LoadingCache < PureRevertKeyProto , Boolean > cache ; private final PatchSetUtil psUtil ; private final ChangeNotes . Factory notesFactory ; @Inject PureRevertCache (
private final LoadingCache < PureRevertKeyProto , Boolean > cache ; private final PatchSetUtil psUtil ; private final ChangeNotes . Factory notesFactory ; @Inject PureRevertCache ( @Named ( ID_CACHE ) LoadingCache < PureRevertKeyProto , Boolean > cache , PatchSetUtil psUtil , ChangeNotes . Factory notesFactory ) { this . cache = cache ; this . psUtil = psUtil ; this . notesFactory = notesFactory ; } /* * < |startfocus| > * Returns { @code true } if { @code claimedRevert } is a pure ( clean ) revert . < |endfocus| > * * @return { @code true } if { @code claimedRevert } is a pure ( clean ) revert . * @throws IOException if there was a priblem with the storage layer * @throws OrmException if there was a priblem with the storage layer * @throws BadRequestException if there is a problem with the provided { @link ChangeNotes } */ public boolean isPureRevert ( ChangeNotes claimedRevert ) throws OrmException , IOException , BadRequestException {
*/ public boolean isPureRevert ( ChangeNotes claimedRevert ) throws OrmException , IOException , BadRequestException { if ( claimedRevert . getChange ( ) . getRevertOf ( ) == null ) { throw new BadRequestException ( "revertOf not set" ) ; } PatchSet ps = psUtil . current ( notesFactory . createChecked ( claimedRevert . getProjectName ( ) , claimedRevert . getChange ( ) . getRevertOf ( ) ) ) ; return isPureRevert ( claimedRevert . getProjectName ( ) , ObjectId . fromString ( claimedRevert . getCurrentPatchSet ( ) . getRevision ( ) . get ( ) ) , < |startfocus| > ObjectId . fromString ( ps . getRevision ( ) . get ( ) ) ) ; < |endfocus| > } /* * * Returns { @code true } if { @code claimedRevert } is a pure ( clean ) revert of { @code * claimedOriginal } . * * @return { @code true } if { @code claimedRevert } is a pure ( clean ) revert of { @code * claimedOriginal } . * @throws IOException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided { @link ObjectId } s */ public boolean isPureRevert (
ObjectId . fromString ( claimedRevert . getCurrentPatchSet ( ) . getRevision ( ) . get ( ) ) , ObjectId . fromString ( ps . getRevision ( ) . get ( ) ) ) ; } /* * * Returns { @code true } if { @code claimedRevert } is a pure ( clean ) revert of { @code * claimedOriginal } . * * @return { @code true } if { @code claimedRevert } is a pure ( clean ) revert of { @code * claimedOriginal } . < |startfocus| > * @throws IOException if there was a problem with the storage layer < |endfocus| > * @throws BadRequestException if there is a problem with the provided { @link ObjectId } s */ public boolean isPureRevert ( Project . NameKey project , ObjectId claimedRevert , ObjectId claimedOriginal ) throws IOException , BadRequestException { try { return cache . get ( key ( project , claimedRevert , claimedOriginal ) ) ; } catch ( ExecutionException e ) { Throwables . throwIfInstanceOf ( e . getCause ( ) , BadRequestException . class ) ; throw new IOException ( e ) ; } } @VisibleForTesting static PureRevertKeyProto key (
Project . NameKey project = new Project . NameKey ( key . getProject ( ) ) ; try ( Repository repo = repoManager . openRepository ( project ) ; ObjectInserter oi = repo . newObjectInserter ( ) ; RevWalk rw = new RevWalk ( repo ) ) { RevCommit claimedOriginalCommit ; try { claimedOriginalCommit = rw . parseCommit ( original ) ; } catch ( InvalidObjectIdException | MissingObjectException e ) { throw new BadRequestException ( "invalid object ID" ) ; } if ( claimedOriginalCommit . getParentCount ( ) == 0 ) { < |startfocus| > return true ; < |endfocus| > } RevCommit claimedRevertCommit = rw . parseCommit ( revert ) ; if ( claimedRevertCommit . getParentCount ( ) == 0 ) { return false ; } // Rebase claimed revert onto claimed original ThreeWayMerger merger = mergeUtilFactory . create ( projectCache . checkedGet ( project ) ) . newThreeWayMerger ( oi , repo . getConfig ( ) ) ; merger . setBase ( claimedRevertCommit . getParent ( 0 ) ) ; boolean success = merger . merge ( claimedRevertCommit , claimedOriginalCommit ) ; if ( ! success || merger . getResultTreeId ( ) == null ) { // Merge conflict during rebase return false ; }
} starsOf = StarsOf . create ( accountId , starredChangesUtil . getLabels ( accountId , legacyId ) ) ; } } return starsOf . stars ( ) ; } /* * * @return { @code null } if { @code revertOf } is { @code null } ; true if the change is a pure revert ; * false otherwise . */ @Nullable public Boolean isPureRevert ( ) throws OrmException { if ( change ( ) . getRevertOf ( ) == null ) { return null ; } try { < |startfocus| > return pureRevert . isPureRevert ( notes ( ) ) ; } catch ( IOException | BadRequestException e ) { < |endfocus| > throw new OrmException ( "could not compute pure revert" , e ) ; } } @Override public String toString ( ) { MoreObjects . ToStringHelper h = MoreObjects . toStringHelper ( this ) ; if ( change != null ) { h . addValue ( change ) ; } else { h . addValue ( legacyId ) ; } return h . toString ( ) ; } public static class ChangedLines { public final int insertions ; public final int deletions ; public ChangedLines ( int insertions , int deletions ) {
< |startfocus| > public void testKey ( ) { < |endfocus| > ObjectId revert = ObjectId . zeroId ( ) ; ObjectId original = ObjectId . fromString ( "deadbeefdeadbeefdeadbeefdeadbeefdeadbeef" ) ; byte [ ] serializedRevert = new byte [ 20 ] ; byte [ ] serializedOriginal = new byte [ 20 ] ; revert . copyRawTo ( serializedRevert , 0 ) ; original . copyRawTo ( serializedOriginal , 0 ) ; Cache . PureRevertKeyProto key = PureRevertCache . key ( new Project . NameKey ( "test" ) , revert , original ) ; assertThat ( key ) . isEqualTo ( Cache . PureRevertKeyProto . newBuilder ( ) . setProject ( "test" ) . setClaimedRevert ( ByteString . copyFrom ( serializedRevert ) ) . setClaimedOriginal ( ByteString . copyFrom ( serializedOriginal ) ) . build ( ) ) ;
< |startfocus| > static String combine ( String project , String file ) { < |endfocus| > return project + " : " + file ;
Copyright ( C ) 2019 The Android Open Source Project Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; you may not use this file except in compliance with the License . You may obtain a copy of the License at http :/ / www . apache . org / licenses / LICENSE - 2 . 0 Unless required by applicable law or agreed to in writing , software distributed under the License is distributed on an "AS IS" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . See the License for the specific language governing permissions and limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . zookeeper ; import static com . google . common . base . Preconditions . checkArgument ; import java . io . IOException ; import org . apache . curator . framework . CuratorFramework ; import org . apache . curator . framework . CuratorFrameworkFactory ; import org . apache . curator . retry . ExponentialBackoffRetry ; public class CuratorFrameworkBuilder { private ZkConfig config = null ; public CuratorFrameworkBuilder config ( ZkConfig config ) { this . config = config ; return this ; } public CuratorFramework build ( ) throws IOException {
// Copyright ( C ) 2012 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . zookeeper ; import com . google . common . base . MoreObjects ; import java . io . Serializable ; import org . apache . curator . framework . CuratorFrameworkFactory ; import org . eclipse . jgit . lib . Config ; /* * Configuration for a Zookeeper setup . */ public class ZkConfig implements Serializable { private static final long serialVersionUID = 1L ; public static final int DEFAULT_SESSION_TIMEOUT_MS ; public static final int DEFAULT_CONNECTION_TIMEOUT_MS ; static { DEFAULT_SESSION_TIMEOUT_MS = CuratorFrameworkFactory . builder ( ) . getSessionTimeoutMs ( ) ; DEFAULT_CONNECTION_TIMEOUT_MS = CuratorFrameworkFactory . builder ( ) . getConnectionTimeoutMs ( ) ; } public String zkHosts ; public int sessionTimeoutMs ; public int connectionTimeoutMs ; public ZkConfig ( ) { sessionTimeoutMs = DEFAULT_SESSION_TIMEOUT_MS ; connectionTimeoutMs = DEFAULT_CONNECTION_TIMEOUT_MS ; } public ZkConfig ( Config cfg ) { zkHosts = cfg . getString ( "zookeeper" , null , "hosts" ) ; sessionTimeoutMs = cfg . getInt ( "zookeeper" , "sessionTimeoutMs" , DEFAULT_SESSION_TIMEOUT_MS ) ; connectionTimeoutMs = cfg . getInt ( "zookeeper" , "connectionTimeoutMs" , DEFAULT_CONNECTION_TIMEOUT_MS ) ; } @Override public String toString ( ) { return MoreObjects . toStringHelper ( this ) . add ( "zkHosts" , zkHosts ) . add ( "sessionTimeoutMs" , sessionTimeoutMs ) . add ( "connectionTimeoutMs" , connectionTimeoutMs ) . toString ( ) ; } }
public static final int DEFAULT_CONNECTION_TIMEOUT_MS ; static { CuratorFrameworkFactory . Builder b = CuratorFrameworkFactory . builder ( ) ; DEFAULT_SESSION_TIMEOUT_MS = b . getSessionTimeoutMs ( ) ; DEFAULT_CONNECTION_TIMEOUT_MS = b . getConnectionTimeoutMs ( ) ; } private static final String SECTION = "zookeeper" ; private static final String KEY_CONNECT_STRING = "connectString" ; private static final String KEY_SESSION_TIMEOUT = "sessionTimeout" ; < |startfocus| > private static final String KEY_CONNECTION_TIMEOUT = "connectionTimeout" ; private final String connectString ; private final int sessionTimeoutMs ; private final int connectionTimeoutMs ; private final String zookeeperRoot ; ZkConfig ( final String connectString , final String zookeeperRoot , final int sessionTimeoutMs , final int connectionTimeoutMs ) { this . connectString = connectString ; this . sessionTimeoutMs = sessionTimeoutMs ; this . connectionTimeoutMs = connectionTimeoutMs ; this . zookeeperRoot = zookeeperRoot ; } public static ZkConfig fromConfig ( Config cfg ) { return new ZkConfig ( cfg . getString ( SECTION , null , KEY_CONNECT_STRING ) ,
return true ; } private boolean doCreate ( ZkRefInfoMarshaller marshaller , Optional < ZkRefInfo > infoCurrentlyInZkMaybe , ZkRefInfo newRefInfo ) throws Exception { if ( infoCurrentlyInZkMaybe . isPresent ( ) ) { logger . atWarning ( ) . log ( "Asked to create ref % s but it is already in ZK at path % s" , newRefInfo . refName ( ) , ZkRefInfoMarshaller . pathFor ( newRefInfo ) ) ; return false ; } marshaller . create ( newRefInfo ) ; return true ; } < |startfocus| > < |endfocus| > static class TombstoneRef implements Ref { static TombstoneRef forRef ( final Ref targetRef ) { return new TombstoneRef ( targetRef . getName ( ) ) ; } private final String name ; private TombstoneRef ( String name ) { this . name = name ; } @Override public String getName ( ) { return name ; } @Override public boolean isSymbolic ( ) { return false ; } @Override public Ref getLeaf ( ) { return null ; } @Override public Ref getTarget ( ) { return null ; } @Override public ObjectId getObjectId ( ) { return null ; } @Override public boolean isPeeled ( ) { return false ; } @Override public Ref peel ( ) throws IOException { return null ; } @Override public RefDatabase getRefDatabase ( ) { return null ; } @Override public boolean isPacked ( ) { return false ; } } }
assertThat ( marshaller . read ( aProjectName ( ) , aChangeRefName ( ) ) ) . isEqualTo ( Optional . empty ( ) ) ; } @Test public void shouldUpdateAZrefInfo ( ) throws Exception { ZkRefInfo newRefInfo = aZkRefInfo ( ) ; ZkRefInfo updateRefInfo = new ZkRefInfo ( newRefInfo . projectName ( ) , newRefInfo . refName ( ) , anObjectId ( ) , Instant . now ( ) , UUID . randomUUID ( ) ) ; < |startfocus| > // Make sure new refInfo and updateRefInfo are never the same assertThat ( newRefInfo ) . isNotEqualTo ( updateRefInfo ) ; < |endfocus| > marshaller . create ( newRefInfo ) ; marshaller . update ( updateRefInfo ) ; Optional < ZkRefInfo > readUpdatedRefInfo = marshaller . read ( updateRefInfo . projectName ( ) , updateRefInfo . refName ( ) ) ; assertThat ( readUpdatedRefInfo ) . isEqualTo ( Optional . of ( updateRefInfo ) ) ; } @Test public void shouldFailToReadZkRefInfoIfSomeOfTheInfoIsMissing ( ) throws Exception { String projectName = aProjectName ( ) ; String refName = aChangeRefName ( ) ; curator . createContainers ( ZkRefInfoMarshaller . pathFor ( projectName , refName ) ) ; expectedException . expect ( CorruptedZkStorageException . class ) ;
< |startfocus| > public boolean equals ( Object other ) { if ( this == other ) { < |endfocus| > return true ; } if ( other == null || getClass ( ) != other . getClass ( ) ) { return false ; } ZkRefInfo zkRefInfo = ( ZkRefInfo ) other ; return Objects . equal ( refName , zkRefInfo . refName ) && Objects . equal ( projectName , zkRefInfo . projectName ) && Objects . equal ( objectId , zkRefInfo . objectId ) && Objects . equal ( lastWriterInstanceId , zkRefInfo . lastWriterInstanceId ) && Objects . equal ( lastUpdatedAt , zkRefInfo . lastUpdatedAt ) ;
marshaller . read ( projectName , newRef . getName ( ) ) ; final ZkRefInfo newRefInfo = new ZkRefInfo ( projectName , newRef , instanceId ) ; if ( isCreate ) { return doCreate ( marshaller , infoCurrentlyInZkMaybe , newRefInfo ) ; } else { return doUpdate ( oldRef , marshaller , infoCurrentlyInZkMaybe , newRefInfo ) ; } } catch ( Exception e ) { logger . atWarning ( ) . withCause ( e ) . log ( "Error trying to perform CAS at path % s" , ZkRefInfoMarshaller . pathFor ( projectName , newRef ) ) ; throw new IOException ( String . format ( "Error trying to perform CAS at path % s" , ZkRefInfoMarshaller . pathFor ( projectName , newRef ) ) , e ) ; } } private boolean doUpdate ( Ref oldRef , ZkRefInfoMarshaller marshaller , Optional < ZkRefInfo > infoCurrentlyInZkMaybe , ZkRefInfo newRefInfo ) throws Exception { if ( ! infoCurrentlyInZkMaybe . isPresent ( ) ) { logger . atWarning ( ) . log ( "Asked to update ref % s but it is not in ZK at path % s" ,
} } catch ( Exception e ) { logger . atWarning ( ) . withCause ( e ) . log ( "Error trying to perform CAS at path % s" , ZkRefInfoMarshaller . pathFor ( projectName , newRef ) ) ; throw new IOException ( String . format ( "Error trying to perform CAS at path % s" , ZkRefInfoMarshaller . pathFor ( projectName , newRef ) ) , e ) ; } } private boolean doUpdate ( Ref oldRef , < |startfocus| > ZkRefInfoMarshaller marshaller , < |endfocus| > Optional < ZkRefInfo > infoCurrentlyInZkMaybe , ZkRefInfo newRefInfo ) throws Exception { if ( ! infoCurrentlyInZkMaybe . isPresent ( ) ) { logger . atWarning ( ) . log ( "Asked to update ref % s but it is not in ZK at path % s" , newRefInfo . refName ( ) , ZkRefInfoMarshaller . pathFor ( newRefInfo ) ) ; return false ; } if ( ! infoCurrentlyInZkMaybe . get ( ) . objectId ( ) . equals ( oldRef . getObjectId ( ) ) ) { logger . atWarning ( ) . log ( "Asked to update ref % s but it is not in ZK at path % s" , newRefInfo . refName ( ) , ZkRefInfoMarshaller . pathFor ( newRefInfo ) ) ; return false ; } if ( ! infoCurrentlyInZkMaybe . get ( ) . objectId ( ) . equals ( oldRef . getObjectId ( ) ) ) { logger . atWarning ( ) . log (
import java . io . IOException ; import org . apache . curator . framework . CuratorFramework ; import org . apache . curator . test . TestingServer ; import org . junit . Test ; @NoHttpd @LogThreshold ( level = "INFO" ) @TestPlugin ( name = "multi - site" , sysModule = "com . googlesource . gerrit . plugins . multisite . validation . ValidationIT$Module" ) public class ValidationIT extends LightweightPluginDaemonTest { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; CuratorFramework framework ; public static class Module extends LifecycleModule { public class ZookeeperStopAtShutdown implements LifecycleListener { < |startfocus| > private final TestingServer zookeeper ; < |endfocus| > public ZookeeperStopAtShutdown ( TestingServer zookeeper ) { this . zookeeper = zookeeper ; } @Override public void stop ( ) { try { zookeeper . stop ( ) ; } catch ( IOException e ) { logger . atWarning ( ) . withCause ( e ) . log ( "Cannot start zookeeper" ) ; throw new RuntimeException ( "Cannot start zookeeper" , e ) ; } } @Override public void start ( ) { try { zookeeper . start ( ) ; } catch ( Exception e ) {
protected void configure ( ) { TestingServer zookeeper = null ; try { zookeeper = new TestingServer ( ) ; } catch ( Exception e ) { throw new RuntimeException ( "Cannot init zookeeper" , e ) ; } install ( new ValidationModule ( ) ) ; < |startfocus| > super . configure ( ) ; listener ( ) . toInstance ( new ZookeeperStopAtShutdown ( zookeeper ) ) ; < |endfocus| >
import org . junit . Ignore ; @Ignore public interface RefFixture { String ALLOWED_CHARS = "abcdefghilmnopqrstuvz" ; String ALLOWED_DIGITS = "1234567890" ; String ALLOWED_NAME_CHARS = ALLOWED_CHARS + ALLOWED_CHARS . toUpperCase ( ) + ALLOWED_DIGITS ; static ZkRefInfo aZkRefInfo ( ) { return new ZkRefInfo ( aProjectName ( ) , aChangeRefName ( ) , anObjectId ( ) , Instant . now ( ) , UUID . randomUUID ( ) ) ; } < |startfocus| > static String aProjectName ( ) { return RandomStringUtils . random ( 20 , ALLOWED_NAME_CHARS ) ; < |endfocus| > } static ObjectId anObjectId ( ) { return ObjectId . fromString ( RandomStringUtils . randomNumeric ( 40 ) ) ; } static String aChangeRefName ( ) { return "refs / for / " + RandomStringUtils . random ( 10 , ALLOWED_NAME_CHARS ) ; } static Ref aRefObject ( String refName , ObjectId objectId ) { return new TestRef ( refName , objectId ) ; } static Ref aRefObject ( String refName ) { return aRefObject ( refName , anObjectId ( ) ) ; } static Ref aRefObject ( ) { return aRefObject ( aChangeRefName ( ) , anObjectId ( ) ) ; }
public void shouldCreateANewRef ( ) { < |startfocus| > ObjectId objectId = anObjectId ( ) ; String refName = aChangeRefName ( ) ; < |endfocus| > Ref aNewRef = zkSharedRefDatabase . newRef ( refName , objectId ) ; assertThat ( aNewRef . getName ( ) ) . isEqualTo ( refName ) ; assertThat ( aNewRef . getObjectId ( ) ) . isEqualTo ( objectId ) ; assertThat ( aNewRef . getStorage ( ) ) . isEqualTo ( Storage . NETWORK ) ;
Ref aNewRef = zkSharedRefDatabase . newRef ( refName , objectId ) ; assertThat ( aNewRef . getName ( ) ) . isEqualTo ( refName ) ; assertThat ( aNewRef . getObjectId ( ) ) . isEqualTo ( objectId ) ; assertThat ( aNewRef . getStorage ( ) ) . isEqualTo ( Storage . NETWORK ) ; } @Test public void shouldCompareAndPutSuccessfully ( ) throws Exception { Ref oldRef = aRefObject ( ) ; String projectName = RefFixture . aProjectName ( ) ; < |startfocus| > marshaller . create ( new ZkRefInfo ( projectName , oldRef , UUID . randomUUID ( ) ) ) ; < |endfocus| > assertThat ( zkSharedRefDatabase . compareAndPut ( projectName , oldRef , aRefObject ( oldRef . getName ( ) ) ) ) . isTrue ( ) ; } @Test public void compareAndPutShouldFailIfTheObjectionHasNotTheExpectedValue ( ) throws Exception { String projectName = RefFixture . aProjectName ( ) ; Ref oldRef = aRefObject ( ) ; Ref expectedRef = aRefObject ( oldRef . getName ( ) ) ; marshaller . create ( new ZkRefInfo ( projectName , oldRef , UUID . randomUUID ( ) ) ) ; assertThat ( zkSharedRefDatabase . compareAndPut ( projectName , expectedRef , aRefObject ( oldRef . getName ( ) ) ) ) . isFalse ( ) ; }
marshaller . create ( new ZkRefInfo ( projectName , oldRef , UUID . randomUUID ( ) ) ) ; assertThat ( zkSharedRefDatabase . compareAndRemove ( projectName , oldRef ) ) . isTrue ( ) ; Optional < ZkRefInfo > inZk = marshaller . read ( projectName , oldRef . getName ( ) ) ; assertThat ( inZk . isPresent ( ) ) . isTrue ( ) ; < |startfocus| > assertThat ( inZk . get ( ) . projectName ( ) ) . isEqualTo ( projectName ) ; assertThat ( inZk . get ( ) . refName ( ) ) . isEqualTo ( oldRef . getName ( ) ) ; assertThat ( inZk . get ( ) . objectId ( ) ) . isEqualTo ( Tombstone . INSTANCE . objectId ( ) ) ; < |endfocus| > } @Test public void shouldNotCompareAndPutSuccessfullyAfterACompareAndRemove ( ) throws Exception { Ref oldRef = aRefObject ( ) ; String projectName = RefFixture . aProjectName ( ) ; marshaller . create ( new ZkRefInfo ( projectName , oldRef , UUID . randomUUID ( ) ) ) ; zkSharedRefDatabase . compareAndRemove ( projectName , oldRef ) ; assertThat ( zkSharedRefDatabase . compareAndPut ( projectName , oldRef , aRefObject ( oldRef . getName ( ) ) ) ) . isFalse ( ) ; } }
return " / " + projectName + " / " + refName ; } private final CuratorFramework client ; public ZkRefInfoDAO ( CuratorFramework client ) { this . client = client ; } public Optional < ZkRefInfo > read ( String projectName , String refName ) throws Exception { final String rootPath = pathFor ( projectName , refName ) ; if ( ! exists ( rootPath ) ) return Optional . empty ( ) ; < |startfocus| > final ObjectId objectId = readObjectIdAt ( rootPath + " / " + OBJECT_ID_PATH ) ; < |endfocus| > return Optional . of ( new ZkRefInfo ( projectName , refName , objectId ) ) ; } public void update ( ZkRefInfo info ) throws Exception { writeInTransaction ( info , ( ) - > client . transactionOp ( ) . setData ( ) ) ; } public void create ( ZkRefInfo info ) throws Exception {
import org . apache . curator . framework . recipes . locks . InterProcessMutex ; import org . apache . curator . framework . recipes . locks . Locker ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . Ref ; public class ZkSharedRefDatabase implements SharedRefDatabase { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; private final CuratorFramework client ; private final Duration lockTimeout ; private final UUID instanceId ; @Inject public ZkSharedRefDatabase ( CuratorFramework client , < |startfocus| > @Named ( "ZkLockTimeout" ) Duration lockTimeout , @InstanceId UUID instanceId ) { < |endfocus| > this . client = client ; this . lockTimeout = lockTimeout ; this . instanceId = instanceId ; } @Override public boolean compareAndRemove ( String project , Ref oldRef ) throws IOException { return compareAndPut ( project , oldRef , TombstoneRef . forRef ( oldRef ) ) ; } @Override public boolean compareAndPut ( String projectName , Ref oldRef , Ref newRef ) throws IOException { boolean isCreate = oldRef == NULL_REF ; final ZkRefInfoDAO marshaller = new ZkRefInfoDAO ( client ) ; final InterProcessMutex refPathMutex = new InterProcessMutex ( client , ZkPath . refs ( projectName ) ) ; try ( Locker locker = new Locker ( refPathMutex , lockTimeout , instanceId ) ) { if ( ! locker . lock ( ) ) { logger . atWarning ( ) . log ( "Unable to acquire lock for % s" , projectName ) ; return false ; }
import com . google . gerrit . plugins . checks . api . CheckerStatus ; import com . google . gerrit . reviewdb . client . PatchSet ; import com . google . gerrit . reviewdb . client . Project ; import org . junit . Before ; import org . junit . Test ; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private String testChangeId ; private PatchSet . Id testPatchSetId ; private CheckerUuid testCheckerUuid ; @Before public void setUp ( ) throws Exception { PushOneCommit . Result result = createChange ( ) ; < |startfocus| > testChangeId = result . getChangeId ( ) ; < |endfocus| > testPatchSetId = result . getPatchSetId ( ) ; // Approves "Code - Review" label so that the change only needs to meet the submit requirements // about checks . approve ( testChangeId ) ; // Creates a test Checker which is enabled and required for the test repository . testCheckerUuid = checkerOperations . newChecker ( ) . repository ( project ) . blockingConditions ( BlockingCondition . STATE_NOT_PASSING ) . status ( CheckerStatus . ENABLED ) . create ( ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getStatus ( ) ) . isEqualTo ( CheckerStatus . ENABLED ) ;
import com . google . gerrit . reviewdb . client . PatchSet ; import com . google . gerrit . reviewdb . client . Project ; import org . junit . Before ; import org . junit . Test ; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private PatchSet . Id testPatchSetId ; private CheckerUuid testCheckerUuid ; @Before public void setUp ( ) throws Exception { PushOneCommit . Result result = createChange ( ) ; result . assertOkStatus ( ) ; < |startfocus| > testPatchSetId = result . getPatchSetId ( ) ; < |endfocus| > // Approves "Code - Review" label so that the change only needs to meet the submit requirements // about checks . approve ( testPatchSetId . changeId ( ) ) ; // Creates a test Checker which is enabled and required for the test repository . testCheckerUuid = checkerOperations . newChecker ( ) . repository ( project ) . blockingConditions ( BlockingCondition . STATE_NOT_PASSING ) . status ( CheckerStatus . ENABLED ) . create ( ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getStatus ( ) ) . isEqualTo ( CheckerStatus . ENABLED ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getBlockingConditions ( ) ) . containsExactly ( BlockingCondition . STATE_NOT_PASSING ) ;
// about checks . approve ( testChangeId ) ; // Creates a test Checker which is enabled and required for the test repository . testCheckerUuid = checkerOperations . newChecker ( ) . repository ( project ) . blockingConditions ( BlockingCondition . STATE_NOT_PASSING ) . status ( CheckerStatus . ENABLED ) . create ( ) ; < |startfocus| > assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getStatus ( ) ) . isEqualTo ( CheckerStatus . ENABLED ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getBlockingConditions ( ) ) . containsExactly ( BlockingCondition . STATE_NOT_PASSING ) ; < |endfocus| > } @Test public void nonApplicableCheckerNotBlockingSubmit ( ) throws Exception { postCheckResult ( testCheckerUuid , CheckState . FAILED ) ; // Updates the checker so that it isn't applicable to the change any more . Project . NameKey otherRepo = new Project . NameKey ( "other - project" ) ; gApi . projects ( ) . create ( otherRepo . get ( ) ) ; checkerOperations . checker ( testCheckerUuid ) . forUpdate ( ) . repository ( otherRepo ) . update ( ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getRepository ( ) ) . isEqualTo ( otherRepo ) ; gApi . changes ( ) . id ( testChangeId ) . current ( ) . submit ( ) ; assertThat ( gApi . changes ( ) . id ( testChangeId ) . get ( ) . status ) . isEqualTo ( ChangeStatus . MERGED ) ; }
Project . NameKey otherRepo = new Project . NameKey ( "other - project" ) ; gApi . projects ( ) . create ( otherRepo . get ( ) ) ; checkerOperations . checker ( testCheckerUuid ) . forUpdate ( ) . repository ( otherRepo ) . update ( ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getRepository ( ) ) . isEqualTo ( otherRepo ) ; gApi . changes ( ) . id ( testChangeId ) . current ( ) . submit ( ) ; assertThat ( gApi . changes ( ) . id ( testChangeId ) . get ( ) . status ) . isEqualTo ( ChangeStatus . MERGED ) ; } @Test < |startfocus| > public void disabledCheckerDoesNotBlockSubmit ( ) throws Exception { < |endfocus| > postCheckResult ( testCheckerUuid , CheckState . FAILED ) ; checkerOperations . checker ( testCheckerUuid ) . forUpdate ( ) . disable ( ) . update ( ) ; assertThat ( checkerOperations . checker ( testCheckerUuid ) . get ( ) . getStatus ( ) ) . isEqualTo ( CheckerStatus . DISABLED ) ; gApi . changes ( ) . id ( testChangeId ) . current ( ) . submit ( ) ; assertThat ( gApi . changes ( ) . id ( testChangeId ) . get ( ) . status ) . isEqualTo ( ChangeStatus . MERGED ) ; } @Test public void enabledCheckerNotBlockingSubmitIfNoBlockingCondition ( ) throws Exception { postCheckResult ( testCheckerUuid , CheckState . FAILED ) ; checkerOperations . checker ( testCheckerUuid ) . forUpdate ( )
gApi . changes ( ) . id ( testChangeId ) . current ( ) . submit ( ) ; assertThat ( gApi . changes ( ) . id ( testChangeId ) . get ( ) . status ) . isEqualTo ( ChangeStatus . MERGED ) ; } @Test public void enabledCheckerBlockingSubmitIfInBlockingState ( ) throws Exception { postCheckResult ( testCheckerUuid , CheckState . FAILED ) ; exception . expect ( ResourceConflictException . class ) ; exception . expectMessage ( "Passing all blocking checks required" ) ; gApi . changes ( ) . id ( testChangeId ) . current ( ) . submit ( ) ; } @Test @Sandboxed < |startfocus| > public void multipleCheckerBlockingSubmit ( ) throws Exception { < |endfocus| > // Two enabled and required checkers . They are blocking if any of them isn't passing . CheckerUuid testCheckerUuid2 = checkerOperations . newChecker ( ) . repository ( project ) . blockingConditions ( BlockingCondition . STATE_NOT_PASSING ) . create ( ) ; postCheckResult ( testCheckerUuid , CheckState . SUCCESSFUL ) ; postCheckResult ( testCheckerUuid2 , CheckState . FAILED ) ; exception . expect ( ResourceConflictException . class ) ; exception . expectMessage ( "Passing all blocking checks required" ) ; gApi . changes ( ) . id ( testChangeId ) . current ( ) . submit ( ) ; } @Test @Sandboxed public void multipleCheckerNotBlockingSubmit ( ) throws Exception {
if ( path . isEmpty ( ) || addAll ) { Util . addToMap ( owner2paths , key , dir + path ) ; } } } } } /* * * Parse given lines of an OWNERS file ; return parsed Result . * It can recursively call itself to parse included files . * * @param dir is the directory that contains "changed files" of a CL , * not necessarily the OWNERS or included file directory . < |startfocus| > * "owners" found in lines controls changed files in 'dir' . < |endfocus| > * 'dir' ends with ' / ' or is empty when parsing an included file . * @param lines are the source lines of the file to be parsed . * @return the parsed data */ Result parseFile ( String dir , String [ ] lines ) { Result result = new Result ( ) ; int n = 0 ; for ( String line : lines ) { parseLine ( result , dir , line , ++ n ) ; } return result ; } Result parseFile ( String dir , String content ) {
/* * * Find and parse an included file and append data to the 'result' . * For an 'include' statement , parsed data is all append to the given result parameter . * For a 'file : ' statement or directive , only owner emails are appended . * If the project + file name is found in the stored result set , the stored result is reused . < |startfocus| > * The inclusion is skipped if to be included file is already on the including file stack . < |endfocus| > * * @param result to where the included file data should be added . * @param dir the including file's directory or glob . * @param num source code line number * @param parsedKPF the parsed line of include or file directive . * @param addAll to add all parsed data into result or not . */ private void includeFile ( Result result , String dir , int num , String [ ] parsedKPF , boolean addAll ) { String keyword = parsedKPF [ 0 ] ; String project = parsedKPF [ 1 ] ;
assertThat ( r2 . owner2paths ) . isEmpty ( ) ; assertThat ( r2 . warnings ) . containsExactly ( w2 , w1 ) ; assertThat ( r2 . noParentGlobs ) . containsExactly ( b2 , b1 ) ; assertThat ( r1 . noParentGlobs ) . containsExactly ( b1 ) ; assertThat ( r2 . errors ) . containsExactly ( e2 , e1 ) ; r1 . append ( r2 , "" , true ) ; assertThat ( r1 . owner2paths ) . isEmpty ( ) ; assertThat ( r2 . owner2paths ) . isEmpty ( ) ; // warnings , errors , and noParentGlobs are sets of strings . < |startfocus| > // containsExactly does not check order of elements . < |endfocus| > assertThat ( r1 . warnings ) . containsExactly ( w1 , w2 ) ; assertThat ( r1 . warnings ) . containsExactly ( w2 , w1 ) ; assertThat ( r1 . noParentGlobs ) . containsExactly ( b2 , b1 ) ; assertThat ( r1 . errors ) . containsExactly ( e1 , e2 ) ; assertThat ( r1 . errors ) . containsExactly ( e2 , e1 ) ;
import org . eclipse . jgit . treewalk . filter . PathFilterGroup ; import org . junit . Test ; @TestPlugin ( name = "find - owners" , sysModule = "com . googlesource . gerrit . plugins . findowners . Module" ) public class OwnersFileSubmitRuleIT extends AbstractDaemonTest { @Test public void TestChangeWithoutPermissions ( ) throws Exception { createTestRepositoryContent ( ) ; < |startfocus| > setProjectConfig ( "enforceLevel" , "ENFORCE" ) ; PushOneCommit . Result r = createCommitAndPush ( testRepo , "refs / for / master" , "test message" , "A / 1 / foo . c" , "void main ( ) \n" ) ; < |endfocus| > approve ( r . getChangeId ( ) ) ; ChangeInfo result = gApi . changes ( ) . id ( r . getChangeId ( ) ) . get ( ) ; assertThat ( result . submittable ) . isFalse ( ) ; } private void createTestRepositoryContent ( ) throws Exception { grant ( project , "refs / for / master" , Permission . PUSH ) ; TestRepository < InMemoryRepository > . CommitBuilder cb = testRepo . branch ( "master" ) . commit ( ) ; cb . add ( "OWNERS" , "alice@example . com\nbob@example . com\n" ) ; cb . add ( "A / 1 / foo . c" , "int main ( ) \n" ) ; cb . create ( ) ; } }
} } private final LoadingCache < PureRevertKeyProto , Boolean > cache ; private final ChangeNotes . Factory notesFactory ; @Inject PureRevertCache ( @Named ( ID_CACHE ) LoadingCache < PureRevertKeyProto , Boolean > cache , ChangeNotes . Factory notesFactory ) { this . cache = cache ; this . notesFactory = notesFactory ; } /* * * Returns { @code true } if { @code claimedRevert } is a pure ( clean ) revert of the change that is < |startfocus| > * referenced in { @link com . google . gerrit . reviewdb . client . Change#getRevertOf ( ) } . < |endfocus| > * * @return { @code true } if { @code claimedRevert } is a pure ( clean ) revert . * @throws IOException if there was a problem with the storage layer * @throws OrmException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided { @link ChangeNotes } */ public boolean isPureRevert ( ChangeNotes claimedRevert ) throws OrmException , IOException , BadRequestException { if ( claimedRevert . getChange ( ) . getRevertOf ( ) == null ) { return false ; } PureRevertKeyProto key = PureRevertKeyProto . newBuilder ( ) . setRevertChangeId ( claimedRevert . getChange ( ) . getId ( ) . get ( ) ) . setRevertOfChangeId ( claimedRevert . getChange ( ) . getRevertOf ( ) . get ( ) ) . build ( ) ; try { return cache . get ( key ) ; } catch ( ExecutionException e ) { Throwables . throwIfInstanceOf ( e . getCause ( ) , OrmException . class ) ; Throwables . throwIfInstanceOf ( e . getCause ( ) , IOException . class ) ; Throwables . throwIfInstanceOf ( e . getCause ( ) , BadRequestException . class ) ; throw new StorageException ( e . getCause ( ) ) ; } } private static class PureRevertKeyProto { private static final ProtobufCodec < PureRevertKeyProto > CODEC = ProtobufCodec . of ( PureRevertKeyProto . class ) ; private static final String REVERT_CHANGE_ID = "revertChangeId" ; private static final String REVERT_OF_CHANGE_ID = "revertOfChangeId" ; private static final String REVERT_OF_PATCH_SET_ID = "revertOfPatchSetId" ; private static final String REVERT_OF_PATCH_SET_UUID = "revertOfPatchSetUuid" ; private static final String REVERT_OF_PATCH_SET_UUID_STR = "revertOfPatchSetUuidStr" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES = "revertOfPatchSetUuidBytes" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_STR = "revertOfPatchSetUuidBytesStr" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES = "revertOfPatchSetUuidBytesBytes" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_STR = "revertOfPatchSetUuidBytesBytesStr" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES = "revertOfPatchSetUuidBytesBytesBytes" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_STR = "revertOfPatchSetUuidBytesBytesBytesStr" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES = "revertOfPatchSetUuidBytesBytesBytesBytes" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES_STR = "revertOfPatchSetUuidBytesBytesBytesBytesStr" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES_BYTES = "revertOfPatchSetUuidBytesBytesBytesBytesBytes" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES_BYTES_STR = "revertOfPatchSetUuidBytesBytesBytesBytesBytesStr" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES = "revertOfPatchSetUuidBytesBytesBytesBytesBytesBytes" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_STR = "revertOfPatchSetUuidBytesBytesBytesBytesBytesBytesStr" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES = "revertOfPatchSetUuidBytesBytesBytesBytesBytesBytesBytes" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_STR = "revertOfPatchSetUuidBytesBytesBytesBytesBytesBytesBytesStr" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES = "revertOfPatchSetUuidBytesBytesBytesBytesBytesBytesBytesBytes" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_STR = "revertOfPatchSetUuidBytesBytesBytesBytesBytesBytesBytesBytesStr" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES = "revertOfPatchSetUuidBytesBytesBytesBytesBytesBytesBytesBytesBytes" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_STR = "revertOfPatchSetUuidBytesBytesBytesBytesBytesBytesBytesBytesBytesStr" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES = "revertOfPatchSetUuidBytesBytesBytesBytesBytesBytesBytesBytesBytesBytes" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_STR = "revertOfPatchSetUuidBytesBytesBytesBytesBytesBytesBytesBytesBytesBytesStr" ; private static final String REVERT_OF_PATCH_SET_UUID_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_BYTES_
* @throws IOException if there was a problem with the storage layer * @throws OrmException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided { @link ChangeNotes } */ public boolean isPureRevert ( ChangeNotes claimedRevert ) throws OrmException , IOException , BadRequestException { if ( claimedRevert . getChange ( ) . getRevertOf ( ) == null ) { throw new BadRequestException ( "revertOf not set" ) ; } < |startfocus| > ChangeNotes claimedOriginal = < |endfocus| > notesFactory . createChecked ( claimedRevert . getProjectName ( ) , claimedRevert . getChange ( ) . getRevertOf ( ) ) ; return isPureRevert ( claimedRevert . getProjectName ( ) , ObjectId . fromString ( claimedRevert . getCurrentPatchSet ( ) . getRevision ( ) . get ( ) ) , ObjectId . fromString ( claimedOriginal . getCurrentPatchSet ( ) . getRevision ( ) . get ( ) ) ) ; } /* * * Returns { @code true } if { @code claimedRevert } is a pure ( clean ) revert of { @code * claimedOriginal } . *
cb . add ( "A / 1 / info . txt" , "information\n" ) ; cb . add ( "A / 1 / OWNERS" , "xyz@example . com\n" ) ; cb . add ( "A / no_inherit / spam . py" , "def main ( ) \n" ) ; cb . add ( "A / no_inherit / ham . py" , "def func ( ) \n" ) ; cb . add ( "A / no_inherit / info . txt" , "python information\n" ) ; cb . add ( "A / no_inherit / OWNERS" , "set noparent\nabc@example . com\n" ) ; cb . message ( "initial commit" ) ; cb . insertChangeId ( ) ; cb . create ( ) ; } < |startfocus| > private org . eclipse . jgit . lib . Config readProjectConfig ( ) throws Exception { git ( ) . fetch ( ) . setRefSpecs ( new RefSpec ( REFS_CONFIG + " : " + REFS_CONFIG ) ) . call ( ) ; testRepo . reset ( RefNames . REFS_CONFIG ) ; < |endfocus| > RevWalk rw = testRepo . getRevWalk ( ) ; RevTree tree = rw . parseTree ( testRepo . getRepository ( ) . resolve ( "HEAD" ) ) ; try ( TreeWalk treeWalk = new TreeWalk ( rw . getObjectReader ( ) ) ) { treeWalk . setFilter ( PathFilterGroup . createFromStrings ( "project . config" ) ) ; treeWalk . reset ( tree ) ;
public Collection < SubmitRecord > evaluate ( ChangeData cd , SubmitRuleOptions options ) { 	ProjectState projectState = projectCache . get ( cd . project ( ) ) ; 	 < |startfocus| > PluginConfig pluginConfig = pluginConfigFactory . getFromProjectConfigWithInheritance ( projectState , pluginName ) ; < |endfocus| > 	EnforcementLevel enforce_level = pluginConfig . getEnum ( EnforcementLevel . CONFIG_NAME , EnforcementLevel . DISABLED ) ; 	if ( enforce_level == EnforcementLevel . DISABLED ) { 		return ImmutableList . of ( ) ; 	 } 	Checker checker = new Checker ( repoManager , pluginConfigFactory , projectState , cd , 1 ) ; 	int result ; 	try { 		OwnersDb db = Cache . getInstance ( pluginConfigFactory , repoManager ) . get ( true , projectState , accounts , emails , repoManager , pluginConfigFactory , cd ) ; 		result = checker . findApproval ( accounts , db ) ; 	 } catch ( OrmException | IOException e ) { 		this . logger . atSevere ( ) . withCause ( e ) . log ( "Exception for % s" , Config . getChangeId ( cd ) ) ; 		SubmitRecord rec = new SubmitRecord ( ) ; 		rec . status = SubmitRecord . Status . RULE_ERROR ; 		rec . errorMessage = LOOKUP_ERROR_MSG ; 		return ImmutableList . of ( rec ) ; 	 } }
public Collection < SubmitRecord > evaluate ( ChangeData cd , SubmitRuleOptions options ) { ProjectState projectState = projectCache . get ( cd . project ( ) ) ; PluginConfig pluginConfig = pluginConfigFactory . getFromProjectConfigWithInheritance ( projectState , pluginName ) ; EnforcementLevel enforce_level = pluginConfig . getEnum ( EnforcementLevel . CONFIG_NAME , EnforcementLevel . DISABLED ) ; < |startfocus| > if ( enforce_level == EnforcementLevel . DISABLED ) { < |endfocus| > return ImmutableList . of ( ) ; } Checker checker = new Checker ( repoManager , pluginConfigFactory , projectState , cd , 1 ) ; int result ; try { OwnersDb db = Cache . getInstance ( pluginConfigFactory , repoManager ) . get ( true , projectState , accounts , emails , repoManager , pluginConfigFactory , cd ) ; result = checker . findApproval ( accounts , db ) ; } catch ( OrmException | IOException e ) { this . logger . atSevere ( ) . withCause ( e ) . log ( "Exception for % s" , Config . getChangeId ( cd ) ) ; SubmitRecord rec = new SubmitRecord ( ) ; rec . status = SubmitRecord . Status . RULE_ERROR ; rec . errorMessage = LOOKUP_ERROR_MSG ; return ImmutableList . of ( rec ) ; }
public Collection < SubmitRecord > evaluate ( ChangeData cd , SubmitRuleOptions options ) { ProjectState projectState = projectCache . get ( cd . project ( ) ) ; PluginConfig pluginConfig = pluginConfigFactory . getFromProjectConfigWithInheritance ( projectState , pluginName ) ; EnforcementLevel enforce_level = pluginConfig . getEnum ( EnforcementLevel . CONFIG_NAME , EnforcementLevel . DISABLED ) ; if ( enforce_level == EnforcementLevel . DISABLED ) { return ImmutableList . of ( ) ; } Checker checker = new Checker ( repoManager , pluginConfigFactory , projectState , cd , 1 ) ; int result ; try { < |startfocus| > OwnersDb db = Cache . getInstance ( pluginConfigFactory , repoManager ) . get ( true , projectState , accounts , emails , repoManager , pluginConfigFactory , cd ) ; < |endfocus| > result = checker . findApproval ( accounts , db ) ; } catch ( OrmException | IOException e ) { this . logger . atSevere ( ) . withCause ( e ) . log ( "Exception for % s" , Config . getChangeId ( cd ) ) ; SubmitRecord rec = new SubmitRecord ( ) ; rec . status = SubmitRecord . Status . RULE_ERROR ; rec . errorMessage = LOOKUP_ERROR_MSG ; return ImmutableList . of ( rec ) ; }
pluginConfigFactory , cd ) ; result = checker . findApproval ( accounts , db ) ; } catch ( OrmException | IOException e ) { this . logger . atSevere ( ) . withCause ( e ) . log ( "Exception for % s" , Config . getChangeId ( cd ) ) ; SubmitRecord rec = new SubmitRecord ( ) ; rec . status = SubmitRecord . Status . RULE_ERROR ; rec . errorMessage = LOOKUP_ERROR_MSG ; return ImmutableList . of ( rec ) ; } SubmitRecord sr = new SubmitRecord ( ) ; sr . requirements = SUBMIT_REQUIREMENTS ; < |startfocus| > if ( result >= 0 ) { sr . status = OK ; return sr ; } sr . stats = enforceLevel == ENFORCE ? Status . NOT_READY : Status . OK ; return sr ; < |endfocus| >
import com . google . gerrit . extensions . api . changes . SubmitInput ; import com . google . gerrit . extensions . common . ChangeInfo ; import com . google . gerrit . server . config . PluginConfig ; import org . eclipse . jgit . lib . ObjectLoader ; import org . eclipse . jgit . revwalk . RevObject ; import org . eclipse . jgit . revwalk . RevTree ; import org . eclipse . jgit . revwalk . RevWalk ; import org . junit . Test ; @TestPlugin ( name = "find - owners" , sysModule = "com . googlesource . gerrit . plugins . findowners . Module" ) public class OwnersFileSubmitRuleIT extends LightweightPluginDaemonTest { @Test < |startfocus| > public void testChangeWithoutPermissions ( ) throws Exception { < |endfocus| > createTestRepositoryContent ( ) ; configurePlugin ( "enforceLevel" , "ENFORCE" ) ; PushOneCommit . Result r = createChange ( "test message" , "A / 1 / foo . c" , "void main ( ) \n" ) ; approve ( r . getChangeId ( ) ) ; ChangeInfo result = gApi . changes ( ) . id ( r . getChangeId ( ) ) . get ( ) ; assertThat ( result . submittable ) . isFalse ( ) ; } private void createTestRepositoryContent ( ) throws Exception { addFile ( "init" , "OWNERS" , "per - file * . c = alice@example . com , bob@example . com\n" ) ;
return pathFor ( projectName , ref . getName ( ) ) ; } public static String pathFor ( String projectName , String refName ) { return " / " + projectName + " / " + refName ; } private final CuratorFramework client ; public ZkRefInfoDAO ( CuratorFramework client ) { this . client = client ; } public Optional < ZkRefInfo > read ( String projectName , String refName ) throws Exception { final String rootPath = pathFor ( projectName , refName ) ; < |startfocus| > if ( ! exists ( rootPath ) ) return Optional . empty ( ) ; < |endfocus| > final ObjectId objectId = readObjectIdAt ( rootPath + " / " + OBJECT_ID_PATH ) ; return Optional . of ( new ZkRefInfo ( projectName , refName , objectId ) ) ; } public void update ( ZkRefInfo info ) throws Exception { writeInTransaction ( info , ( ) - > client . transactionOp ( ) . setData ( ) ) ; } public void create ( ZkRefInfo info ) throws Exception { client . createContainers ( pathFor ( info ) ) ; writeInTransaction ( info , ( ) - > client . transactionOp ( ) . create ( ) . withMode ( PERSISTENT ) ) ; } private void writeInTransaction ( ZkRefInfo info , Function < TransactionCreateBuilder , TransactionCreateBuilder > op ) throws Exception { final String rootPath = pathFor ( info ) ; final TransactionCreateBuilder builder = client . transactionOp ( ) . create ( ) . forPath ( rootPath + " / " + OBJECT_ID_PATH , info . getObjectId ( ) . getByteArray ( ) ) ; op . apply ( builder ) . and ( ) . commit ( ) ; } private boolean exists ( String rootPath ) throws Exception { return client . checkExists ( ) . forPath ( rootPath ) != null ; } private ObjectId readObjectIdAt ( String path ) throws Exception { final byte [ ] bytes = client . getData ( ) . forPath ( path ) ; return ObjectId . fromRaw ( bytes ) ; } }
import com . google . gerrit . server . query . change . ChangeData ; import com . google . gerrit . server . rules . SubmitRule ; import com . google . gwtorm . server . OrmException ; import com . google . inject . Inject ; import com . google . inject . Singleton ; import java . io . IOException ; import java . util . Collection ; @Singleton public class ChecksSubmitRule implements SubmitRule { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; private static final SubmitRequirement DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS = SubmitRequirement . builder ( ) < |startfocus| > . setFallbackText ( "All required checks must pass" ) . setType ( "passing_all_blocking_checks" ) < |endfocus| > . build ( ) ; public static class Module extends FactoryModule { @Override public void configure ( ) { bind ( SubmitRule . class ) . annotatedWith ( Exports . named ( "ChecksSubmitRule" ) ) . to ( ChecksSubmitRule . class ) ; } } private final Checks checks ; @Inject public ChecksSubmitRule ( Checks checks ) { this . checks = checks ; } @Override public Collection < SubmitRecord > evaluate ( ChangeData changeData , SubmitRuleOptions options ) { Project . NameKey project = changeData . project ( ) ; Change . Id changeId = changeData . getId ( ) ;
import com . google . gerrit . server . rules . SubmitRule ; import com . google . gwtorm . server . OrmException ; import com . google . inject . Inject ; import com . google . inject . Singleton ; import java . io . IOException ; import java . util . Collection ; @Singleton public class ChecksSubmitRule implements SubmitRule { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; private static final SubmitRequirement DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS = SubmitRequirement . builder ( ) < |startfocus| > . setFallbackText ( "Passing all blocking checks required" ) . setType ( "checks_pass" ) < |endfocus| > . build ( ) ; public static class Module extends FactoryModule { @Override public void configure ( ) { bind ( SubmitRule . class ) . annotatedWith ( Exports . named ( "ChecksSubmitRule" ) ) . to ( ChecksSubmitRule . class ) ; } } private final Checks checks ; @Inject public ChecksSubmitRule ( Checks checks ) { this . checks = checks ; } @Override public Collection < SubmitRecord > evaluate ( ChangeData changeData , SubmitRuleOptions options ) { Project . NameKey project = changeData . project ( ) ; Change . Id changeId = changeData . getId ( ) ; PatchSet . Id currentPathSetId ; try {
import com . google . gerrit . plugins . checks . api . CheckState ; import com . google . gerrit . plugins . checks . api . CheckerStatus ; import com . google . gerrit . reviewdb . client . PatchSet ; import com . google . gerrit . reviewdb . client . Project ; import org . junit . Before ; import org . junit . Test ; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private String testChangeId ; private PatchSet . Id testPatchSetId ; private CheckerUuid testCheckerUuid ; @Before public void setUp ( ) throws Exception { PushOneCommit . Result result = createChange ( ) ; testPatchSetId = result . getPatchSetId ( ) ; testChangeId = result . getChangeId ( ) ; // Approves "Code - Review" label so that the change only needs to meet the submit requirements // about checks . approve ( testChangeId ) ; // Creates a test Checker which is enabled and required for the test repository . testCheckerUuid = checkerOperations . newChecker ( ) . repository ( project ) . blockingConditions ( BlockingCondition . STATE_NOT_PASSING ) . status ( CheckerStatus . ENABLED ) . create ( ) ; } @Test public void nonApplicableCheckerNotBlockingSubmit ( ) throws Exception {
testCheckerUuid = checkerOperations . newChecker ( ) . repository ( project ) . blockingConditions ( BlockingCondition . STATE_NOT_PASSING ) . status ( CheckerStatus . ENABLED ) . create ( ) ; } @Test public void nonApplicableCheckerNotBlockingSubmit ( ) throws Exception { postCheckResult ( testCheckerUuid , CheckState . FAILED ) ; // Updates the checker so that it isn't applicable to the change any more . < |startfocus| > checkerOperations . checker ( testCheckerUuid ) . forUpdate ( ) . repository ( allProjects ) . update ( ) ; < |endfocus| > gApi . changes ( ) . id ( testChangeId ) . current ( ) . submit ( ) ; assertThat ( gApi . changes ( ) . id ( testChangeId ) . get ( ) . status ) . isEqualTo ( ChangeStatus . MERGED ) ; } @Test public void disabledCheckerDoesNotBlockingSubmit ( ) throws Exception { postCheckResult ( testCheckerUuid , CheckState . FAILED ) ; checkerOperations . checker ( testCheckerUuid ) . forUpdate ( ) . disable ( ) . update ( ) ; gApi . changes ( ) . id ( testChangeId ) . current ( ) . submit ( ) ; assertThat ( gApi . changes ( ) . id ( testChangeId ) . get ( ) . status ) . isEqualTo ( ChangeStatus . MERGED ) ; }
} } public static String pathFor ( String projectName , Ref ref ) { return pathFor ( projectName , ref . getName ( ) ) ; } public static String pathFor ( String projectName , String refName ) { return " / " + projectName + " / " + refName ; } public static ObjectId readObjectId ( byte [ ] value ) { return ObjectId . fromRaw ( value ) ; } < |startfocus| > private static byte [ ] writeObjectId ( ObjectId value ) throws IOException { < |endfocus| > final ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; final DataOutputStream stream = new DataOutputStream ( out ) ; value . copyRawTo ( stream ) ; return out . toByteArray ( ) ; } }
ListChecks ( CheckBackfiller checkBackfiller , CheckJson . Factory checkJsonFactory , Checkers checkers , Checks checks ) { this . checkBackfiller = checkBackfiller ; this . checkJsonFactory = checkJsonFactory ; this . checkers = checkers ; this . checks = checks ; } @Override public ImmutableList < CheckInfo > apply ( RevisionResource resource ) throws AuthException , BadRequestException , ResourceConflictException , OrmException , IOException { CheckJson checkJson = checkJsonFactory . create ( options ) ; Map < CheckerUuid , Checker > checkersByUuid = < |startfocus| > checkers . checkersOf ( resource . getProject ( ) ) . stream ( ) < |endfocus| > . collect ( toMap ( Checker : : getUuid , c - > c ) ) ; ImmutableList . Builder < CheckInfo > result = ImmutableList . builderWithExpectedSize ( checkersByUuid . size ( ) ) ; for ( Check check : checks . getChecks ( resource . getProject ( ) , resource . getPatchSet ( ) . getId ( ) ) ) { checkersByUuid . remove ( check . key ( ) . checkerUuid ( ) ) ; result . add ( checkJson . format ( check ) ) ; } for ( Check check : checkBackfiller . getBackfilledChecksForRelevantCheckers ( checkersByUuid . values ( ) , resource . getNotes ( ) , resource . getPatchSet ( ) . getId ( ) ) ) {
* not exist . */ Optional < Check > getCheck ( CheckKey checkKey ) throws OrmException , IOException ; @AutoValue abstract class GetChecksOptions { /* * Backfills checks for relevant checkers with default when they don't exist yet . */ public abstract boolean backfillChecks ( ) ; public abstract Builder toBuilder ( ) ; public static Builder builder ( ) { return new AutoValue_Checks_GetChecksOptions . Builder ( ) . setBackfillChecks ( false ) ; } public static GetChecksOptions defaults ( ) { return builder ( ) . build ( ) ; } @AutoValue . Builder public abstract static class Builder { public abstract Builder setBackfillChecks ( boolean backfillChecks ) ; public abstract GetChecksOptions build ( ) ; } } }
private final CuratorFramework client ; private final RetryPolicy retryPolicy ; @Inject public ZkSharedRefDatabase ( CuratorFramework client , @Named ( "ZkLockRetryPolicy" ) RetryPolicy retryPolicy ) { this . client = client ; this . retryPolicy = retryPolicy ; } @Override public boolean compareAndRemove ( String project , Ref oldRef ) throws IOException { return compareAndPut ( project , oldRef , NULL_REF ) ; } @Override public boolean compareAndPut ( String projectName , Ref oldRef , Ref newRef ) throws IOException { final DistributedAtomicValue distributedRefValue = < |startfocus| > new DistributedAtomicValue ( client , pathFor ( projectName , oldRef ) , retryPolicy ) ; < |endfocus| > try { if ( oldRef == NULL_REF ) { return distributedRefValue . initialize ( writeObjectId ( newRef . getObjectId ( ) ) ) ; } else { final ObjectId newValue = newRef . getObjectId ( ) == null ? ObjectId . zeroId ( ) : newRef . getObjectId ( ) ; final AtomicValue < byte [ ] > newDistributedValue = distributedRefValue . compareAndSet ( writeObjectId ( oldRef . getObjectId ( ) ) , writeObjectId ( newValue ) ) ; return newDistributedValue . succeeded ( ) ; }
@Inject public ZkSharedRefDatabase ( CuratorFramework client , @Named ( "ZkLockRetryPolicy" ) RetryPolicy retryPolicy ) { this . client = client ; this . retryPolicy = retryPolicy ; } @Override public boolean compareAndRemove ( String project , Ref oldRef ) throws IOException { return compareAndPut ( project , oldRef , NULL_REF ) ; } @Override public boolean compareAndPut ( String projectName , Ref oldRef , Ref newRef ) throws IOException { final DistributedAtomicValue distributedRefValue = < |startfocus| > new DistributedAtomicValue ( client , pathFor ( projectName , newRef ) , retryPolicy ) ; < |endfocus| > try { if ( oldRef == NULL_REF ) { return distributedRefValue . initialize ( writeObjectId ( newRef . getObjectId ( ) ) ) ; } else { final ObjectId newValue = newRef . getObjectId ( ) == null ? ObjectId . zeroId ( ) : newRef . getObjectId ( ) ; final AtomicValue < byte [ ] > newDistributedValue = distributedRefValue . compareAndSet ( writeObjectId ( oldRef . getObjectId ( ) ) , writeObjectId ( newValue ) ) ; return newDistributedValue . succeeded ( ) ; } } catch ( Exception e ) { logger . atWarning ( ) . withCause ( e ) . log (
import com . google . gerrit . reviewdb . client . PatchSet ; import com . google . gerrit . server . config . AllProjectsName ; import org . junit . Before ; import org . junit . Test ; /* * * TODO ( xchangcheng ) : add more tests after figuring out the expecting behavior of { @code * CombinedCheckState } . */ public class ChecksSubmitRuleIT extends AbstractCheckersTest { private static final SubmitRequirementInfo SUBMIT_REQUIREMENT_INFO = new SubmitRequirementInfo ( "NOT_READY" , "All required checks must pass" , "checks_pass" , ImmutableMap . of ( ) ) ; < |startfocus| > @Inject private AllProjectsName allProjects ; < |endfocus| > private String testChangeId ; private PatchSet . Id testPatchSetId ; @Before public void setUp ( ) throws Exception { PushOneCommit . Result result = createChange ( ) ; testPatchSetId = result . getPatchSetId ( ) ; testChangeId = result . getChangeId ( ) ; // Approves "Code - Review" label so that the change only needs to meet the submit requirements // about checks . approve ( testChangeId ) ; } @Test public void nonApplicableCheckerNotBlockingSubmit ( ) throws Exception {
* CombinedCheckState } . */ public class ChecksSubmitRuleIT extends AbstractCheckersTest { private static final SubmitRequirementInfo SUBMIT_REQUIREMENT_INFO = new SubmitRequirementInfo ( "NOT_READY" , "All required checks must pass" , "checks_pass" , ImmutableMap . of ( ) ) ; private AllProjectsName allProjects ; private String testChangeId ; private PatchSet . Id testPatchSetId ; @Before public void setUp ( ) throws Exception { < |startfocus| > allProjects = plugin . getSysInjector ( ) . getInstance ( AllProjectsName . class ) ; < |endfocus| > PushOneCommit . Result result = createChange ( ) ; testPatchSetId = result . getPatchSetId ( ) ; testChangeId = result . getChangeId ( ) ; // Approves "Code - Review" label so that the change only needs to meet the submit requirements // about checks . approve ( testChangeId ) ; } @Test public void nonApplicableCheckerNotBlockingSubmit ( ) throws Exception { CheckerUuid checkerUuid = newRequiredChecker ( ) . create ( ) ; postCheckResult ( checkerUuid , CheckState . FAILED ) ; // Updates the checker so that it isn't applicable to the change any more . checkerOperations . checker ( checkerUuid ) . forUpdate ( ) . repository ( allProjects ) . update ( ) ;
} @Before public void setUpCheckersPlugin ( ) throws Exception { checkerOperations = plugin . getSysInjector ( ) . getInstance ( CheckerOperations . class ) ; checkOperations = plugin . getSysInjector ( ) . getInstance ( CheckOperations . class ) ; checkersApi = plugin . getHttpInjector ( ) . getInstance ( Checkers . class ) ; checksApiFactory = plugin . getHttpInjector ( ) . getInstance ( ChecksFactory . class ) ; pendingChecksApi = plugin . getHttpInjector ( ) . getInstance ( PendingChecks . class ) ; allowGlobalCapabilities ( group ( "Administrators" ) . getGroupUUID ( ) , "checks - administrateCheckers" ) ; } < |startfocus| > protected TestCheckerCreation . Builder newRequiredChecker ( ) { return checkerOperations . newChecker ( ) . repository ( project ) . status ( CheckerStatus . ENABLED ) . blockingConditions ( BlockingCondition . STATE_NOT_PASSING ) ; } < |endfocus| > }
fetch ( repo , checkerRef + " : checkerRef" ) ; repo . reset ( "checkerRef" ) ; grant ( allProjects , CheckerRef . REFS_CHECKERS + " * " , Permission . PUSH ) ; PushOneCommit . Result r = pushFactory . create ( admin . getIdent ( ) , repo ) . to ( checkerRef ) ; r . assertErrorStatus ( ) ; r . assertMessage ( "direct update of checker ref not allowed" ) ; } @Test public void submitToCheckerRefsIsDisabled ( ) throws Exception { < |startfocus| > // TODO ( xchangcheng ) : remove the "disable" after figuring out the expecting behavior of // CombinedCheckState . Currently , this ** not - required ** checker is blocking submission but // it shouldn't . < |endfocus| > CheckerUuid checkerUuid = checkerOperations . newChecker ( ) . status ( CheckerStatus . DISABLED ) . create ( ) ; String checkerRef = checkerUuid . toRefName ( ) ; String changeId = createChangeWithoutCommitValidation ( checkerRef ) ; grantLabel ( "Code - Review" , - 2 , 2 , allProjects , CheckerRef . REFS_CHECKERS + " * " , false , adminGroupUuid ( ) , false ) ; approve ( changeId ) ; grant ( allProjects , CheckerRef . REFS_CHECKERS + " * " , Permission . SUBMIT ) ; exception . expect ( ResourceConflictException . class ) ;
testChangeId = result . getChangeId ( ) ; // Approves "Code - Review" label so that the change only needs to meet the submit requirements // about checks . approve ( testChangeId ) ; } @Test public void nonApplicableCheckerNotBlockingSubmit ( ) throws Exception { CheckerUuid checkerUuid = newRequiredChecker ( ) . create ( ) ; postCheckResult ( checkerUuid , CheckState . FAILED ) ; // Updates the checker so that it isn't applicable to the change any more . < |startfocus| > Project . NameKey otherRepo = new Project . NameKey ( "All - Projects" ) ; checkerOperations . checker ( checkerUuid ) . forUpdate ( ) . repository ( otherRepo ) . update ( ) ; < |endfocus| > ChangeInfo changeInfo = gApi . changes ( ) . id ( testChangeId ) . get ( ) ; assertThat ( changeInfo . submittable ) . isTrue ( ) ; } @Test public void disabledCheckerDoesNotBlockingSubmit ( ) throws Exception { CheckerUuid checkerUuid = newRequiredChecker ( ) . create ( ) ; postCheckResult ( checkerUuid , CheckState . FAILED ) ; checkerOperations . checker ( checkerUuid ) . forUpdate ( ) . disable ( ) . update ( ) ; ChangeInfo changeInfo = gApi . changes ( ) . id ( testChangeId ) . get ( ) ; assertThat ( changeInfo . submittable ) . isTrue ( ) ; } // @Test public void nonApplicableCheckerNotBlockingSubmit ( ) throws Exception { CheckerUuid checkerUuid = newRequiredChecker ( ) . create ( ) ; postCheckResult ( checkerUuid , CheckState . FAILED ) ; // Updates the checker so that it isn't applicable to the change any more . < |startfocus| > Project . NameKey otherRepo = new Project . NameKey ( "All - Projects" ) ; checkerOperations . checker ( checkerUuid ) . forUpdate ( ) . repository ( otherRepo ) . update ( ) ; < |endfocus| > ChangeInfo changeInfo = gApi . changes ( ) . id ( testChangeId ) . get ( ) ; assertThat ( changeInfo . submittable ) . isTrue ( ) ; } @Test public void disabledCheckerDoesNotBlockingSubmit ( ) throws Exception { CheckerUuid checkerUuid = newRequiredChecker ( ) . create ( ) ; postCheckResult ( checkerUuid , CheckState . FAILED ) ; checkerOperations . checker ( checkerUuid ) . forUpdate ( ) . disable ( ) . update ( ) ; ChangeInfo changeInfo = gApi . changes ( ) . id ( testChangeId ) . get ( ) ; assertThat ( changeInfo . submittable ) . isTrue ( ) ; } // @Test
checkerOperations . checker ( checkerUuid ) . forUpdate ( ) . repository ( otherRepo ) . update ( ) ; ChangeInfo changeInfo = gApi . changes ( ) . id ( testChangeId ) . get ( ) ; assertThat ( changeInfo . submittable ) . isTrue ( ) ; } @Test public void disabledCheckerDoesNotBlockingSubmit ( ) throws Exception { CheckerUuid checkerUuid = newRequiredChecker ( ) . create ( ) ; postCheckResult ( checkerUuid , CheckState . FAILED ) ; checkerOperations . checker ( checkerUuid ) . forUpdate ( ) . disable ( ) . update ( ) ; ChangeInfo changeInfo = gApi . changes ( ) . id ( testChangeId ) . get ( ) ; < |startfocus| > assertThat ( changeInfo . submittable ) . isTrue ( ) ; assertThat ( changeInfo . requirements ) . isEmpty ( ) ; < |endfocus| > } // @Test // public void enabledCheckerNotBlockingSubmitIfNotRequired ( ) throws Exception { // CheckerUuid checkerUuid = newRequiredChecker ( ) . create ( ) ; // postCheckResult ( checkerUuid , CheckState . FAILED ) ; // checkerOperations // . checker ( checkerUuid ) // . forUpdate ( ) // . blockingConditions ( ImmutableSortedSet . of ( ) ) // . update ( ) ; // // ChangeInfo changeInfo = gApi . changes ( ) . id ( testChangeId ) . get ( ) ; // // assertThat ( changeInfo . submittable ) . isTrue ( ) ; // } @Test
CheckerUuid checkerUuid = newRequiredChecker ( ) . create ( ) ; postCheckResult ( checkerUuid , CheckState . SUCCESSFUL ) ; ChangeInfo changeInfo = gApi . changes ( ) . id ( testChangeId ) . get ( ) ; assertThat ( changeInfo . submittable ) . isTrue ( ) ; } @Test public void enabledCheckerBlockingSubmitIfInBlockingState ( ) throws Exception { CheckerUuid checkerUuid = newRequiredChecker ( ) . create ( ) ; postCheckResult ( checkerUuid , CheckState . FAILED ) ; ChangeInfo changeInfo = gApi . changes ( ) . id ( testChangeId ) . get ( ) ; < |startfocus| > assertThat ( changeInfo . requirements ) . containsExactly ( checkerUuid . get ( ) ) ; < |endfocus| > } @Test public void multipleCheckerBlockingSubmit ( ) throws Exception { CheckerUuid checkerUuid = newRequiredChecker ( ) . create ( ) ; // Two enabled and required checkers . They are blocking if any of them isn't passing . CheckerUuid testCheckerUuid2 = newRequiredChecker ( ) . create ( ) ; postCheckResult ( checkerUuid , CheckState . SUCCESSFUL ) ; postCheckResult ( testCheckerUuid2 , CheckState . FAILED ) ; ChangeInfo changeInfo = gApi . changes ( ) . id ( testChangeId ) . get ( ) ; assertThat ( changeInfo . submittable ) . isFalse ( ) ; } // @Test // public void multipleCheckerNotBlockingSubmit ( ) throws Exception {
return Collections . emptyList ( ) ; } public int getCount ( ) { return count ; } public void reset ( ) { count = 0 ; } } @Override public Module createModule ( ) { return new AbstractModule ( ) { @Override protected void configure ( ) { testRefOperationListener = new TestRefOperationValidationListener ( ) ; DynamicSet . bind ( binder ( ) , RefOperationValidationListener . class ) . toInstance ( testRefOperationListener ) ; } } ; } < |startfocus| > static { System . setProperty ( "gerrit . notedb" , "ON" ) ; < |endfocus| > } @After public void cleanup ( ) { testRefOperationListener . reset ( ) ; } @Test public void aNormalPushShouldTriggerARefOperationValidation ( ) throws Exception { PushOneCommit . Result r = createCommitAndPush ( testRepo , "refs / heads / master" , "msg" , "file" , "content" ) ; assertThat ( testRefOperationListener . getCount ( ) ) . isEqualTo ( 1 ) ; } @Test public void aMagicRefUpdateShouldTriggerARefOperationValidationOnChangesBranch ( ) throws Exception { PushOneCommit . Result r = createChange ( "refs / for / master" ) ;
String . format ( "checker % s not found" , checkerUuid ) ) ) ; if ( checker . getStatus ( ) == CheckerStatus . DISABLED ) { return ImmutableList . of ( ) ; } // The query system can only match against the current patch set ; ignore non - current patch sets // for now . List < ChangeData > changes = queryMatchingChangesFor ( checker ) ; List < PendingChecksInfo > pendingChecks = new ArrayList < > ( changes . size ( ) ) ; for ( ChangeData cd : changes ) { < |startfocus| > getPostFilteredPendingChecks ( cd . project ( ) , cd . currentPatchSet ( ) . getId ( ) ) < |endfocus| > . ifPresent ( pendingChecks : : add ) ; } return pendingChecks ; } private List < ChangeData > queryMatchingChangesFor ( Checker checker ) throws ConfigInvalidException , OrmException { Predicate < ChangeData > predicate = new ProjectPredicate ( checker . getRepository ( ) . get ( ) ) ; if ( checker . getQuery ( ) . isPresent ( ) ) { String query = checker . getQuery ( ) . get ( ) ; try { predicate = Predicate . and ( predicate , queryBuilderProvider . get ( ) . parse ( query ) ) ; } catch ( QueryParseException e ) { logger . atWarning ( ) . withCause ( e ) . log (
CheckablePatchSetInfo patchSet = actual ( ) . patchSet ; < |startfocus| > check ( "patchSet" ) . that ( patchSet ) . isNotNull ( ) ; < |endfocus| > return patchSet ; }
install ( new NoteDbCheckersModule ( ) ) ; bind ( CapabilityDefinition . class ) . annotatedWith ( Exports . named ( AdministrateCheckersCapability . NAME ) ) . to ( AdministrateCheckersCapability . class ) ; DynamicSet . bind ( binder ( ) , CommitValidationListener . class ) . to ( CheckerCommitValidator . class ) . in ( SINGLETON ) ; DynamicSet . bind ( binder ( ) , MergeValidationListener . class ) . to ( CheckerMergeValidator . class ) . in ( SINGLETON ) ; DynamicSet . bind ( binder ( ) , RefOperationValidationListener . class ) . to ( CheckerRefOperationValidator . class ) . in ( SINGLETON ) ; < |startfocus| > DynamicSet . bind ( binder ( ) , ChangeAttributeFactory . class ) < |endfocus| > . annotatedWith ( Exports . named ( "checks" ) ) . to ( ChangeCheckAttributeFactory . class ) ; bind ( DynamicOptions . DynamicBean . class ) . annotatedWith ( Exports . named ( GetChange . class ) ) . to ( GetChangeOptions . class ) ; install ( new ApiModule ( ) ) ;
import org . eclipse . jgit . lib . ObjectId ; import org . junit . Test ; public class CheckerDefinitionTest { @Test public void notRequiredIfNoBlockingCondition ( ) { Checker checker = newChecker ( ) . setBlockingConditions ( ImmutableSortedSet . of ( ) ) . build ( ) ; assertThat ( checker . isRequired ( ) ) . isFalse ( ) ; } @Test public void requiredIfHasBlockingConditionStateNotPassing ( ) { Checker checker = newChecker ( ) . setBlockingConditions ( ImmutableSortedSet . of ( STATE_NOT_PASSING ) ) . build ( ) ; assertThat ( checker . isRequired ( ) ) . isTrue ( ) ; } < |startfocus| > < |endfocus| > private Checker . Builder newChecker ( ) { return Checker . builder ( ) . setRepository ( new NameKey ( "test - repo" ) ) . setStatus ( CheckerStatus . ENABLED ) . setBlockingConditions ( ImmutableSortedSet . of ( STATE_NOT_PASSING ) ) . setUuid ( CheckerUuid . parse ( "schema : any - id" ) ) . setCreatedOn ( TimeUtil . nowTs ( ) ) . setUpdatedOn ( TimeUtil . nowTs ( ) ) . setRefState ( ObjectId . zeroId ( ) ) ; } }
assertThat ( checker . isRequired ( ) ) . isFalse ( ) ; } @Test public void requiredIfHasBlockingConditionStateNotPassing ( ) { Checker checker = newChecker ( ) . setBlockingConditions ( ImmutableSortedSet . of ( STATE_NOT_PASSING ) ) . build ( ) ; assertThat ( checker . isRequired ( ) ) . isTrue ( ) ; } private Checker . Builder newChecker ( ) { return Checker . builder ( ) . setRepository ( new NameKey ( "test - repo" ) ) . setStatus ( CheckerStatus . ENABLED ) < |startfocus| > . setBlockingConditions ( ImmutableSortedSet . of ( STATE_NOT_PASSING ) ) < |endfocus| > . setUuid ( CheckerUuid . parse ( "schema : any - id" ) ) . setCreatedOn ( TimeUtil . nowTs ( ) ) . setUpdatedOn ( TimeUtil . nowTs ( ) ) ; } }
* * @param project project containing the change . * @param psId patch set to which the state corresponds . * @return combined check state . */ public CombinedCheckState reload ( Project . NameKey project , PatchSet . Id psId ) throws OrmException { CombinedCheckStateCacheKeyProto key = key ( project , psId ) ; CombinedCheckState newState = loader . load ( key ) ; CombinedCheckState oldState = cache . getIfPresent ( key ) ; if ( newState != oldState ) { cache . put ( key , newState ) ; } < |startfocus| > return newState ; < |endfocus| > } /* * * Directly put a state into the cache . * * @param project project containing the change . * @param psId patch set to which the state corresponds . * @param state combined check state . */ @VisibleForTesting public void putForTest ( Project . NameKey project , PatchSet . Id psId , CombinedCheckState state ) { cache . put ( key ( project , psId ) , state ) ; } @VisibleForTesting public CacheStats getStats ( ) { return cache . stats ( ) ; }
} throw new IllegalStateException ( "unexpected options type : " + opts ) ; } private ChangeCheckInfo forGetChange ( ChangeData cd , GetChangeOptions opts ) throws OrmException { if ( opts == null || ! opts . combined ) { return null ; } return new ChangeCheckInfo ( combinedCheckStateCache . reload ( cd . project ( ) , cd . change ( ) . currentPatchSetId ( ) ) ) ; } private ChangeCheckInfo forQueryChanges ( ChangeData cd , QueryChangesOptions opts ) throws OrmException { < |startfocus| > if ( ! opts . combined ) { < |endfocus| > return null ; } return new ChangeCheckInfo ( combinedCheckStateCache . get ( cd . project ( ) , cd . change ( ) . currentPatchSetId ( ) ) ) ; } }
RefUpdate refUpdate = repo . updateRef ( refName ) ; refUpdate . setExpectedOldObjectId ( parent ) ; refUpdate . setNewObjectId ( newCommitId ) ; refUpdate . setRefLogIdent ( personIdent ) ; refUpdate . setRefLogMessage ( message , false ) ; refUpdate . update ( ) ; RefUpdateUtil . checkResult ( refUpdate ) ; try { combinedCheckStateCache . reload ( checkKey . project ( ) , checkKey . patchSet ( ) ) ; } catch ( OrmException e ) { logger . atWarning ( ) . withCause ( e ) . log ( "failed to reload CombinedCheckState for % s" , checkKey ) ; } gitRefUpdated . fire ( < |startfocus| > checkKey . project ( ) , refUpdate , currentUser . map ( user - > user . state ( ) ) . orElse ( null ) ) ; < |endfocus| > return readSingleCheck ( checkKey , repo , rw , newCommitId ) ; } } private void assertCheckerIsPresent ( CheckerUuid checkerUuid ) throws ConfigInvalidException , IOException { checkers . getChecker ( checkerUuid ) . orElseThrow ( ( ) - > new IOException ( checkerUuid + " missing" ) ) ; } private boolean updateNotesMap ( CheckKey checkKey , CheckUpdate checkUpdate , Repository repo , RevWalk rw , ObjectInserter ins , ObjectId curr ,
stats = cache . getStats ( ) . minus ( start ) ; // Incurs a cache hit during read - then - write . assertThat ( stats . hitCount ( ) ) . isEqualTo ( 2 ) ; assertThat ( stats . missCount ( ) ) . isEqualTo ( 0 ) ; assertThat ( queryChangeCheckInfo ( changeId ) ) . hasValue ( new ChangeCheckInfo ( "checks" , CombinedCheckState . NOT_RELEVANT ) ) ; stats = cache . getStats ( ) . minus ( start ) ; assertThat ( stats . hitCount ( ) ) . isEqualTo ( 3 ) ; assertThat ( stats . missCount ( ) ) . isEqualTo ( 0 ) ; } @Test < |startfocus| > public void updatingCheckStateUpatesCache ( ) throws Exception { < |endfocus| > CheckerUuid checkerUuid = checkerOperations . newChecker ( ) . repository ( project ) . create ( ) ; cache . putForTest ( project , psId , CombinedCheckState . IN_PROGRESS ) ; CacheStats start = clone ( cache . getStats ( ) ) ; assertThat ( queryChangeCheckInfo ( changeId ) ) . hasValue ( new ChangeCheckInfo ( "checks" , CombinedCheckState . IN_PROGRESS ) ) ; CacheStats stats = cache . getStats ( ) . minus ( start ) ; assertThat ( stats . hitCount ( ) ) . isEqualTo ( 1 ) ; assertThat ( stats . missCount ( ) ) . isEqualTo ( 0 ) ; // Set non - required checker to FAILED , updating combined check state to WARNING . assertThat ( queryChangeCheckInfo ( changeId ) ) . hasValue ( new ChangeCheckInfo ( "checks" , CombinedCheckState . IN_PROGRESS ) ) ;
/* * * This is public so that plugins that implement a web session , < |startfocus| > * can also implement a way to clear per user sessions . < |endfocus| > */ public Account . Id getAccountId ( ) { return accountId ; } ExternalId . Key getExternalId ( ) { return externalId ; } String getSessionId ( ) { return sessionId ; } String getAuth ( ) { return auth ; } boolean needsCookieRefresh ( ) { return refreshCookieAt <= nowMs ( ) ; } boolean isPersistentCookie ( ) { return persistentCookie ; } private void writeObject ( ObjectOutputStream out ) throws IOException { writeVarInt32 ( out , 1 ) ;
private transient String auth ; Val ( Account . Id accountId , long refreshCookieAt , boolean persistentCookie , ExternalId . Key externalId , long expiresAt , String sessionId , String auth ) { this . accountId = accountId ; this . refreshCookieAt = refreshCookieAt ; this . persistentCookie = persistentCookie ; this . externalId = externalId ; this . expiresAt = expiresAt ; this . sessionId = sessionId ; this . auth = auth ; } public long getExpiresAt ( ) { return expiresAt ; } < |startfocus| > < |endfocus| > public Account . Id getAccountId ( ) { return accountId ; } ExternalId . Key getExternalId ( ) { return externalId ; } String getSessionId ( ) { return sessionId ; } String getAuth ( ) { return auth ; } boolean needsCookieRefresh ( ) { return refreshCookieAt <= nowMs ( ) ; } boolean isPersistentCookie ( ) { return persistentCookie ; } private void writeObject ( ObjectOutputStream out ) throws IOException { writeVarInt32 ( out , 1 ) ; writeVarInt32 ( out , accountId . get ( ) ) ; /* * * @return the refreshCookieAt */ public long getRefreshCookieAt ( ) { return refreshCookieAt ; }
// See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation ; import com . google . gerrit . extensions . registration . DynamicSet ; import com . google . gerrit . server . git . validators . RefOperationValidationListener ; import com . google . inject . AbstractModule ; import com . google . inject . name . Names ; import com . googlesource . gerrit . plugins . multisite . Configuration ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . SharedRefDatabase ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . zookeeper . ZkSharedRefDatabase ; import org . apache . curator . RetryPolicy ; import org . apache . curator . framework . CuratorFramework ; public class ValidationModule extends AbstractModule { private Configuration cfg ; public ValidationModule ( Configuration cfg ) { this . cfg = cfg ; } @Override protected void configure ( ) { DynamicSet . bind ( binder ( ) , RefOperationValidationListener . class ) . to ( InSyncChangeValidator . class ) ; bind ( SharedRefDatabase . class ) . to ( ZkSharedRefDatabase . class ) ; bind ( CuratorFramework . class ) . toInstance ( cfg . getSplitBrain ( ) . getZookeeper ( ) . buildCurator ( ) ) ; bind ( RetryPolicy . class ) . annotatedWith ( Names . named ( "ZkLockRetryPolicy" ) )
ZookeeperTestContainerSupport zookeeperContainer ; ZkSharedRefDatabase zkSharedRefDatabase ; @Before public void setup ( ) { zookeeperContainer = new ZookeeperTestContainerSupport ( ) ; zkSharedRefDatabase = new ZkSharedRefDatabase ( zookeeperContainer . getCurator ( ) , new RetryNTimes ( 5 , 30 ) ) ; } @After public void cleanup ( ) { zookeeperContainer . cleanup ( ) ; } @Test public void shouldCompareAndCreateSuccessfully ( ) throws Exception { Ref ref = refOf ( AN_OBJECT_ID_1 ) ; < |startfocus| > assertThat ( zkSharedRefDatabase . compareAndCreate ( A_TEST_PROJECT_NAME , ref ) ) . isTrue ( ) ; < |endfocus| > assertThat ( zookeeperContainer . readRefValueFromZk ( A_TEST_PROJECT_NAME , ref ) ) . isEqualTo ( ref . getObjectId ( ) ) ; } @Test public void shouldCompareAndPutSuccessfully ( ) throws Exception { Ref oldRef = refOf ( AN_OBJECT_ID_1 ) ; Ref newRef = refOf ( AN_OBJECT_ID_2 ) ; String projectName = A_TEST_PROJECT_NAME ; zookeeperContainer . createRefInZk ( projectName , oldRef ) ;
private static void assertInvalidQuery ( String query , String expectedMessage ) { try { CheckerQuery . clean ( query ) ; assert_ ( ) . fail ( "expected BadRequestException" ) ; } catch ( BadRequestException e ) { < |startfocus| > assertThat ( e ) . hasMessageThat ( ) . contains ( expectedMessage ) ; < |endfocus| > }
public void hasType ( int expectedType ) { isNotNull ( ) ; < |startfocus| > int actualType = actual ( ) . getType ( ) ; check ( "type ( ) " ) . that ( actualType ) . named ( "expected % s , actual % s" , typeName ( expectedType ) , typeName ( actualType ) ) . isEqualTo ( expectedType ) ; < |endfocus| >
< |startfocus| > public static Check newBackfilledCheck ( Project . NameKey project , PatchSet ps , Checker checker ) { return Check . builder ( CheckKey . create ( project , ps . getId ( ) , checker . getUuid ( ) ) ) < |endfocus| > . setState ( CheckState . NOT_STARTED ) . setCreated ( ps . getCreatedOn ( ) ) . setUpdated ( ps . getCreatedOn ( ) ) . build ( ) ;
} if ( checkerUuid == null ) { throw new BadRequestException ( "checker UUID is required" ) ; } Checker checker = checkers . getChecker ( checkerUuid ) . orElseThrow ( ( ) - > new UnprocessableEntityException ( String . format ( "checker % s not found" , checkerUuid ) ) ) ; if ( checker . getStatus ( ) == CheckerStatus . DISABLED ) { return ImmutableList . of ( ) ; } // The query system can only match against the current patch set ; ignore non - current patch sets // for now . List < ChangeData > changes = < |startfocus| > checker . queryMatchingChanges ( retryHelper , queryBuilderProvider . get ( ) , changeQueryProvider ) ; < |endfocus| > List < PendingChecksInfo > pendingChecks = new ArrayList < > ( changes . size ( ) ) ; for ( ChangeData cd : changes ) { getPostFilteredPendingChecks ( cd . project ( ) , cd . currentPatchSet ( ) . getId ( ) ) . ifPresent ( pendingChecks : : add ) ; } return pendingChecks ; } private Optional < PendingChecksInfo > getPostFilteredPendingChecks ( Project . NameKey project , PatchSet . Id patchSetId ) throws OrmException , IOException { CheckState checkState = getCheckState ( project , patchSetId ) ;
// See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . plugins . checks . index ; import static com . google . common . base . Preconditions . checkNotNull ; import com . google . gerrit . index . query . QueryParseException ; import com . google . gerrit . plugins . checks . Check ; import com . google . gerrit . plugins . checks . api . CheckState ; import com . google . gwtorm . server . OrmException ; public class CheckStatePredicate extends CheckPredicate { public static CheckStatePredicate parse ( String value ) throws QueryParseException { return new CheckStatePredicate ( < |startfocus| > CheckState . tryParse ( value ) < |endfocus| > . orElseThrow ( ( ) - > new QueryParseException ( String . format ( "invalid check state : % s" , value ) ) ) ) ; } private final CheckState checkState ; public CheckStatePredicate ( CheckState checkState ) { super ( CheckQueryBuilder . FIELD_STATE , checkState . name ( ) ) ; this . checkState = checkNotNull ( checkState , "checkState" ) ; } @Override public boolean match ( Check check ) throws OrmException { return checkState . equals ( check . state ( ) ) ; } }
public CheckerPredicate ( CheckerUuid checkerUuid ) { super ( CheckQueryBuilder . FIELD_CHECKER , checkerUuid . toString ( ) ) ; < |startfocus| > this . checkerUuid = requireNonNull ( checkerUuid , "checkerUuid" ) ; < |endfocus| >
boolean isRest ( ServletRequest req ) { return req instanceof HttpServletRequest < |startfocus| > && restPath . matcher ( ( ( HttpServletRequest ) req ) . getServletPath ( ) ) . matches ( ) ; < |endfocus| >
public void containsMessages ( String . . . expectedLines ) { checkArgument ( expectedLines . length > 0 , "use hasNoMessages ( ) " ) ; isNotNull ( ) ; Iterable < String > got = Splitter . on ( "\n" ) . split ( trimMessages ( ) ) ; < |startfocus| > check ( "trimmedMessages ( ) " ) . that ( got ) . containsAllIn ( expectedLines ) . inOrder ( ) ; < |endfocus| >
} @Test public void insertCheckerTwice ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; CheckerUuid checkerUuid = CheckerUuid . parse ( "foo : bar" ) ; Project . NameKey project = new Project . NameKey ( "some - project" ) ; checkersByRepositoryNotes . insert ( checkerUuid , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid ) ; checkersByRepositoryNotes . insert ( checkerUuid , project ) ; commit ( checkersByRepositoryNotes ) ; < |startfocus| > assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid ) ; < |endfocus| > } @Test public void removeCheckers ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( "some - project" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( "bar : baz" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( "foo : bar" ) ; CheckerUuid checkerUuid3 = CheckerUuid . parse ( "foo : baz" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid3 , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 , checkerUuid3 ) ; checkersByRepositoryNotes . remove ( checkerUuid2 , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid3 ) ; } @Test public void removeCheckersFromEmptyRepository ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( "some - project" ) ; CheckerUuid checkerUuid = CheckerUuid . parse ( "foo : bar" ) ; checkersByRepositoryNotes . remove ( checkerUuid , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . isEmpty ( ) ; } @Test public void removeCheckersFromNonExistingRepository ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( "some - project" ) ; CheckerUuid checkerUuid = CheckerUuid . parse ( "foo : bar" ) ; checkersByRepositoryNotes . remove ( checkerUuid , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . isEmpty ( ) ; } @Test public void removeCheckersFromNonExistingChecker ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( "some - project" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( "bar : baz" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( "foo : bar" ) ; CheckerUuid checkerUuid3 = CheckerUuid . parse ( "foo : baz" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid3 , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 , checkerUuid3 ) ; checkersByRepositoryNotes . remove ( CheckerUuid . parse ( "foo : baz" ) , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 ) ; } @Test public void removeCheckersFromNonExistingCheckerAndRepository ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( "some - project" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( "bar : baz" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( "foo : bar" ) ; CheckerUuid checkerUuid3 = CheckerUuid . parse ( "foo : baz" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid3 , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 , checkerUuid3 ) ; checkersByRepositoryNotes . remove ( CheckerUuid . parse ( "foo : baz" ) , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 ) ; } @Test public void removeCheckersFromNonExistingCheckerAndRepository2 ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( "some - project" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( "bar : baz" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( "foo : bar" ) ; CheckerUuid checkerUuid3 = CheckerUuid . parse ( "foo : baz" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project ) ; checkersByRepositoryNotes . insert ( checkerUuid3 , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 , checkerUuid3 ) ; checkersByRepositoryNotes . remove ( CheckerUuid . parse ( "foo : baz" ) , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project ) ) . containsExactly ( checkerUuid1 , checkerUuid2 ) ; } @Test public void removeCheckersFromNonExistingCheckerAndRepository3 ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( "some - project" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( "bar : baz" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( "foo : bar" ) ; CheckerUuid checkerUuid3 = CheckerUuid . parse ( "foo : baz" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; checkersByRepositoryNotes . insert ( checkerU
CheckerUuid checkerUuid2 = CheckerUuid . parse ( "foo : baz" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project1 ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project1 ) ) . containsExactly ( checkerUuid1 ) ; assertThat ( checkersByRepositoryNotes . get ( project2 ) ) . isEmpty ( ) ; checkersByRepositoryNotes . remove ( checkerUuid2 , project1 ) ; checkersByRepositoryNotes . remove ( checkerUuid1 , project2 ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project1 ) ) . containsExactly ( checkerUuid1 ) ; < |startfocus| > assertThat ( checkersByRepositoryNotes . get ( project2 ) ) . isEmpty ( ) ; < |endfocus| > } @Test public void updateCheckers ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project1 = new Project . NameKey ( "some - project" ) ; Project . NameKey project2 = new Project . NameKey ( "other - project" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( "foo : bar" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( "foo : baz" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project1 ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project1 ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project1 ) ) . containsExactly ( checkerUuid1 , checkerUuid2 ) ; < |startfocus| > assertThat ( checkersByRepositoryNotes . get ( project2 ) ) . isEmpty ( ) ; < |endfocus| > } @Test public void removeCheckers ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project1 = new Project . NameKey ( "some - project" ) ; Project . NameKey project2 = new Project . NameKey ( "other - project" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( "foo : bar" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( "foo : baz" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project1 ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project1 ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project1 ) ) . containsExactly ( checkerUuid1 , checkerUuid2 ) ; checkersByRepositoryNotes . remove ( checkerUuid2 , project1 ) ; checkersByRepositoryNotes . remove ( checkerUuid1 , project2 ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project1 ) ) . containsExactly ( checkerUuid1 ) ; < |startfocus| > assertThat ( checkersByRepositoryNotes . get ( project2 ) ) . isEmpty ( ) ; < |endfocus| > } @Test public void updateCheckers ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project1 = new Project . NameKey ( "some - project" ) ; Project . NameKey project2 = new Project . NameKey ( "other - project" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( "foo : bar" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( "foo : baz" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project1 ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project1 ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project1 ) ) . containsExactly ( checkerUuid1 , checkerUuid2 ) ; < |startfocus| > assertThat ( checkersByRepositoryNotes . get ( project2 ) ) . isEmpty ( ) ; < |endfocus| > } @Test public void removeCheckers ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project1 = new Project . NameKey ( "some - project" ) ; Project . NameKey project2 = new Project . NameKey ( "other - project" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( "foo : bar" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( "foo : baz" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project1 ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project1 ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project1 ) ) . containsExactly ( checkerUuid1 , checkerUuid2 ) ; checkersByRepositoryNotes . remove ( checkerUuid2 , project1 ) ; checkersByRepositoryNotes . remove ( checkerUuid1 , project2 ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project1 ) ) . containsExactly ( checkerUuid1 ) ; < |startfocus| > assertThat ( checkersByRepositoryNotes . get ( project2 ) ) . isEmpty ( ) ; < |endfocus| > } @Test public void updateCheckers ( ) throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project1 = new Project . NameKey ( "some - project" ) ; Project . NameKey project2 = new Project . NameKey ( "other - project" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( "foo : bar" ) ; CheckerUuid checkerUuid2 = CheckerUuid . parse ( "foo : baz" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project1 ) ; checkersByRepositoryNotes . insert ( checkerUuid2 , project1 ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( checkersByRepositoryNotes . get ( project1 ) )
CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; CheckerUuid checkerUuid = CheckerUuid . parse ( "foo : bar" ) ; Project . NameKey project = new Project . NameKey ( "some - project" ) ; checkersByRepositoryNotes . insert ( checkerUuid , project ) ; commit ( checkersByRepositoryNotes ) ; assertThatCommitMessage ( ) . isEqualTo ( "Update checkers by repository\n\nChecker : " + checkerUuid . toString ( ) + "\nRepository : " + project . get ( ) ) ; } @Test < |startfocus| > public void noNewCommitOnNoOp ( ) throws Exception { < |endfocus| > CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes ( ) ; Project . NameKey project = new Project . NameKey ( "some - project" ) ; CheckerUuid checkerUuid1 = CheckerUuid . parse ( "foo : bar" ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; commit ( checkersByRepositoryNotes ) ; ObjectId commitId = getRefsMetaCheckersState ( ) ; checkersByRepositoryNotes . insert ( checkerUuid1 , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( getRefsMetaCheckersState ( ) ) . isEqualTo ( commitId ) ; checkersByRepositoryNotes . update ( checkerUuid1 , project , project ) ; commit ( checkersByRepositoryNotes ) ; assertThat ( getRefsMetaCheckersState ( ) ) . isEqualTo ( commitId ) ; }
List < SQLEntry > entries = new ArrayList < > ( ) ; for ( Entry < String , Collection < SQLEntry > > entry : eventsDb . getEvents ( query ) . asMap ( ) . entrySet ( ) ) { String projectName = entry . getKey ( ) ; try { permissionBackend . currentUser ( ) . project ( new Project . NameKey ( projectName ) ) . check ( ProjectPermission . ACCESS ) ; entries . addAll ( entry . getValue ( ) ) ; } catch ( AuthException e ) { // Ignore } catch ( PermissionBackendException e ) { < |startfocus| > log . atWarning ( ) . withCause ( e ) . log ( "Cannot check project access permission" ) ; < |endfocus| > } } return entries . stream ( ) . sorted ( ) . map ( SQLEntry : : getEvent ) . collect ( toList ( ) ) ; } /* * * { @inheritDoc } If storing the event fails due to a connection problem , storage will be * re - attempted as specified in gerrit . config . After failing the maximum amount of times , the * event will be stored in a local h2 database . */ @Override public void storeEvent ( ProjectEvent event ) { Project . NameKey projectName = event . getProjectNameKey ( ) ;
} } } . doFilter ( req , res ) ; } } private final ListMultimap < GitilesView . Type , Filter > filters = LinkedListMultimap . create ( ) ; private final Map < GitilesView . Type , HttpServlet > servlets = Maps . newHashMap ( ) ; private Config config ; private Renderer renderer ; private GitilesUrls urls ; private Linkifier linkifier ; private GitilesAccess . Factory accessFactory ; private RepositoryResolver < HttpServletRequest > resolver ; private VisibilityCache visibilityCache ; private TimeCache timeCache ; private BlameCache blameCache ; private GitwebRedirectFilter gitwebRedirect ; < |startfocus| > private Filter errorHandler ; < |endfocus| > private boolean initialized ; GitilesFilter ( ) { } GitilesFilter ( Config config , Renderer renderer , GitilesUrls urls , GitilesAccess . Factory accessFactory , final RepositoryResolver < HttpServletRequest > resolver , VisibilityCache visibilityCache , TimeCache timeCache , BlameCache blameCache , GitwebRedirectFilter gitwebRedirect , Filter errorHandler ) { this . config = checkNotNull ( config , "config" ) ; this . renderer = renderer ; this . urls = urls ; this . accessFactory = accessFactory ; this . visibilityCache = visibilityCache ; this . timeCache = timeCache ; this . blameCache = blameCache ; this . gitwebRedirect = gitwebRedirect ; this . errorHandler = errorHandler ; } @Override public void init ( FilterConfig filterConfig ) throws ServletException { if ( initialized ) { throw new IllegalStateException ( "already initialized" ) ; } initialized = true ; } @Override public void doFilter ( ServletRequest request , ServletResponse response , FilterChain chain ) throws IOException , ServletException { HttpServletRequest req = ( HttpServletRequest ) request ; HttpServletResponse res = ( HttpServletResponse ) response ; try { GitilesView view = urls . parse ( req ) ; if ( view == null ) { res . sendError ( HttpServletResponse . SC_NOT_FOUND ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REPO_INDEX ) { res . sendRedirect ( urls . getRepositoryIndexUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . ROOT_INDEX ) { res . sendRedirect ( urls . getRootIndexUrl ( ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . HOST_INDEX ) { res . sendRedirect ( urls . getHostIndexUrl ( ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . LOGIN ) { res . sendRedirect ( urls . getLoginUrl ( req ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . LOGOUT ) { res . sendRedirect ( urls . getLogoutUrl ( req ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . GITWEB ) { gitwebRedirect . doFilter ( req , res , chain ) ; return ; } if ( view . getType ( ) == GitilesView . Type . ROBOTS_TXT ) { res . setContentType ( "text / plain" ) ; res . setCharacterEncoding ( UTF_8 . name ( ) ) ; res . getWriter ( ) . write ( config . getRobotsTxt ( ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . FAVICON_ICO ) { res . sendRedirect ( urls . getFaviconUrl ( ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . OPENSEARCH_XML ) { res . setContentType ( "application / opensearchdescription + xml" ) ; res . setCharacterEncoding ( UTF_8 . name ( ) ) ; res . getWriter ( ) . write ( config . getOpenSearchXml ( ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_API ) { res . sendRedirect ( urls . getRestApiUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC ) { res . sendRedirect ( urls . getRestDocUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC_API ) { res . sendRedirect ( urls . getRestDocApiUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC_API_JSON ) { res . sendRedirect ( urls . getRestDocApiJsonUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC_API_HTML ) { res . sendRedirect ( urls . getRestDocApiHtmlUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC_API_TEXT ) { res . sendRedirect ( urls . getRestDocApiTextUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC_API_JSONP ) { res . sendRedirect ( urls . getRestDocApiJsonpUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC_API_UI ) { res . sendRedirect ( urls . getRestDocApiUiUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC_API_UI_INDEX ) { res . sendRedirect ( urls . getRestDocApiUiIndexUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC_API_UI_RESOURCES ) { res . sendRedirect ( urls . getRestDocApiUiResourcesUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC_API_UI_SCRIPTS ) { res . sendRedirect ( urls . getRestDocApiUiScriptsUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC_API_UI_STYLES ) { res . sendRedirect ( urls . getRestDocApiUiStylesUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC_API_UI_IMAGES ) { res . sendRedirect ( urls . getRestDocApiUiImagesUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC_API_UI_LAYOUTS ) { res . sendRedirect ( urls . getRestDocApiUiLayoutsUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC_API_UI_PARTIALS ) { res . sendRedirect ( urls . getRestDocApiUiPartialsUrl ( view . getRepositoryName ( ) ) ) ; return ; } if ( view . getType ( ) == GitilesView . Type . REST_DOC_API_UI_VIEWS ) { res . sendRedirect ( urls . getRestDocApiUiViewsUrl ( view . getRepositoryName ( ) ) ) ; return ; } if
kage com . google . gitiles ; import javax . annotation . Nullable ; import javax . servlet . http . HttpServletResponse ; /* * Indicates the request should be failed . */ < |startfocus| > public class RequestFailureException extends RuntimeException { < |endfocus| > private final FailureReason reason ; private String publicErrorMessage = null ; public RequestFailureException ( FailureReason reason ) { super ( ) ; this . reason = reason ; } public RequestFailureException ( FailureReason reason , Throwable cause ) { super ( cause ) ; this . reason = reason ; } public RequestFailureException withPublicErrorMessage ( String format , Object . . . params ) { this . publicErrorMessage = String . format ( format , params ) ; return this ; } public FailureReason getReason ( ) { return reason ; } @Nullable public String getPublicErrorMessage ( ) { return publicErrorMessage ; } /* * The request failure reason . */ public enum FailureReason { AMBIGUOUS_OBJECT ( HttpServletResponse . SC_BAD_REQUEST ) , BLAME_REGION_NOT_FOUND ( HttpServletResponse . SC_NOT_FOUND ) , CANNOT_PARSE_GITILES_VIEW ( HttpServletResponse . SC_NOT_FOUND ) , INCORECT_PARAMETER ( HttpServletResponse . SC_BAD_REQUEST ) , INCORRECT_OBJECT_TYPE ( HttpServletResponse . SC_NOT_FOUND ) , INVALID_OBJECT ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_LARGE ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_REVISIONS ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_REVISION ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION_IN_FILE ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE ( HttpServletResponse . SC_BAD_REQUEST ) , INVALID_REVISION_RANGE_TOO_MANY_FILES_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN_DIRECTORY_IN_REVISION_IN_FILE_IN
public MultiSiteGitRepositoryManager ( < |startfocus| > MultiSiteRepository . Factory multiSiteRepoFactory , GitRepositoryManager gitRepositoryManager ) { < |endfocus| > this . gitRepositoryManager = gitRepositoryManager ; this . multiSiteRepoFactory = multiSiteRepoFactory ;
protected void configure ( ) { factory ( MultiSiteRepository . Factory . class ) ; factory ( MultiSiteRefDatabase . Factory . class ) ; factory ( MultiSiteRefUpdate . Factory . class ) ; < |startfocus| > bind ( GitRepositoryManager . class ) . to ( MultiSiteGitRepositoryManager . class ) ; bind ( SharedRefDatabase . class ) . to ( ZkSharedRefDatabase . class ) ; < |endfocus| > install ( new ZkValidationModule ( cfg ) ) ;
protected void configure ( ) { factory ( MultiSiteRepository . Factory . class ) ; factory ( MultiSiteRefDatabase . Factory . class ) ; factory ( MultiSiteRefUpdate . Factory . class ) ; < |startfocus| > DynamicSet . bind ( binder ( ) , GitRepositoryManager . class ) . to ( MultiSiteGitRepositoryManager . class ) ; DynamicSet . bind ( binder ( ) , SharedRefDatabase . class ) . to ( ZkSharedRefDatabase . class ) ; install ( new ZkValidationModule ( cfg ) ) ; < |endfocus| >
doReturn ( oldRef ) . when ( refUpdate ) . getRef ( ) ; doReturn ( "refs / heads / master" ) . when ( refUpdate ) . getName ( ) ; doReturn ( AN_OBJECT_ID_2 ) . when ( refUpdate ) . getNewObjectId ( ) ; doReturn ( newRef ) . when ( sharedRefDb ) . newRef ( "refs / heads / master" , AN_OBJECT_ID_2 ) ; } @Test public void newUpdateShouldValidateAndSucceed ( ) throws IOException { setMockRequiredReturnValues ( ) ; // When compareAndPut succeeds < |startfocus| > doReturn ( true ) . when ( sharedRefDb ) . compareAndPut ( A_TEST_PROJECT_NAME , oldRef , newRef ) ; < |endfocus| > doReturn ( Result . NEW ) . when ( refUpdate ) . update ( ) ; MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate ( sharedRefDb , A_TEST_PROJECT_NAME , refUpdate ) ; assertThat ( multiSiteRefUpdate . update ( ) ) . isEqualTo ( Result . NEW ) ; } @Test ( expected = IOException . class ) public void newUpdateShouldValidateAndFailWithIOException ( ) throws IOException { setMockRequiredReturnValues ( ) ; // When compareAndPut fails doReturn ( false ) . when ( sharedRefDb ) . compareAndPut ( A_TEST_PROJECT_NAME , oldRef , newRef ) ; MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate ( sharedRefDb , A_TEST_PROJECT_NAME , refUpdate ) ;
public MultiSiteRepository ( MultiSiteRefDatabase . Factory multiSiteRefDbFactory , @Assisted String projectName , < |startfocus| > @Assisted Repository repository , @Assisted BaseRepositoryBuilder repositoryBuilder ) { super ( repositoryBuilder ) ; < |endfocus| > this . multiSiteRefDbFactory = multiSiteRefDbFactory ; this . projectName = projectName ; this . repository = repository ;
public RefDatabase getRefDatabase ( ) { < |startfocus| > return multiSiteRefDbFactory . create ( projectName , repository . getRefDatabase ( ) ) ; < |endfocus| >
import com . googlecode . prolog_cafe . lang . SymbolTerm ; import java . io . File ; import java . io . IOException ; import java . util . ArrayList ; import java . util . List ; import org . kohsuke . args4j . Option ; public class PrologShell extends AbstractProgram { @Option ( name = " - s" , metaVar = "FILE . pl" , usage = "file to load" ) private List < String > fileName = new ArrayList < > ( ) ; @Option ( name = " - q" , usage = "quiet mode without banner" ) < |startfocus| > private boolean quiet ; < |endfocus| > @Override public int run ( ) { if ( ! quiet ) { banner ( ) ; } BufferingPrologControl pcl = new BufferingPrologControl ( ) ; pcl . setPrologClassLoader ( new PrologClassLoader ( getClass ( ) . getClassLoader ( ) ) ) ; pcl . setEnabled ( Prolog . Feature . IO , true ) ; pcl . setEnabled ( Prolog . Feature . STATISTICS , true ) ; pcl . configureUserIO ( System . in , System . out , System . err ) ; pcl . initialize ( Prolog . BUILTIN ) ; for ( String file : fileName ) { String path ; try { path = new File ( file ) . getCanonicalPath ( ) ; } catch ( IOException e ) {
* commit SHA - 1 , but in ReviewDb it was generated randomly . Taking the target message as an index * rather than an ID allowed us to delete the message from both NoteDb and ReviewDb . * * @param update change update . * @param targetMessageId the id of the target change message . * @param newMessage the new message which is going to replace the old . */ < |startfocus| > // TODO ( xchangcheng ) : Reconsider implementation now that there is only a single ID . < |endfocus| > public void replaceChangeMessage ( ChangeUpdate update , String targetMessageId , String newMessage ) { update . deleteChangeMessageByRewritingHistory ( targetMessageId , newMessage ) ; } /* * * @param tag value of a tag , or null . * @return whether the tag starts with the autogenerated prefix . */ public static boolean isAutogenerated ( @Nullable String tag ) { return tag != null && tag . startsWith ( AUTOGENERATED_TAG_PREFIX ) ; } public static ChangeMessageInfo createChangeMessageInfo ( ChangeMessage message , AccountLoader accountLoader ) { PatchSet . Id patchNum = message . getPatchSetId ( ) ; < |startfocus| > // TODO ( xchangcheng ) : Reconsider implementation now that there is only a single ID . < |endfocus| >
@Singleton public class MultiSiteGitRepositoryManager implements GitRepositoryManager { private final GitRepositoryManager gitRepositoryManager ; @Inject MultiSiteRepository . Factory multiSiteRepoFactory ; @Inject public MultiSiteGitRepositoryManager ( LocalDiskRepositoryManager localDiskRepositoryManager ) { this . gitRepositoryManager = localDiskRepositoryManager ; } public MultiSiteGitRepositoryManager ( GitRepositoryManager gitRepositoryManager ) { this . gitRepositoryManager = gitRepositoryManager ; } @Override public Repository openRepository ( NameKey name ) throws RepositoryNotFoundException , IOException { < |startfocus| > return multiSiteRepoFactory . create ( name . get ( ) , gitRepositoryManager . openRepository ( name ) ) ; < |endfocus| > } @Override public Repository createRepository ( NameKey name ) throws RepositoryCaseMismatchException , RepositoryNotFoundException , IOException { Repository createdRepository = gitRepositoryManager . createRepository ( name ) ; return multiSiteRepoFactory . create ( name . get ( ) , createdRepository ) ; } @Override public SortedSet < NameKey > list ( ) { return gitRepositoryManager . list ( ) ; } }
this . gitRepositoryManager = localDiskRepositoryManager ; } public MultiSiteGitRepositoryManager ( GitRepositoryManager gitRepositoryManager ) { this . gitRepositoryManager = gitRepositoryManager ; } @Override public Repository openRepository ( NameKey name ) throws RepositoryNotFoundException , IOException { Repository openRepository = gitRepositoryManager . openRepository ( name ) ; return multiSiteRepoFactory . create ( name . get ( ) , openRepository ) ; } @Override public Repository createRepository ( NameKey name ) throws RepositoryCaseMismatchException , RepositoryNotFoundException , IOException { < |startfocus| > return multiSiteRepoFactory . create ( name . get ( ) , gitRepositoryManager . createRepository ( name ) ) ; < |endfocus| > } @Override public SortedSet < NameKey > list ( ) { return gitRepositoryManager . list ( ) ; } }
import org . apache . curator . RetryPolicy ; import org . apache . curator . framework . CuratorFramework ; import org . apache . curator . framework . CuratorFrameworkFactory ; import org . apache . curator . retry . BoundedExponentialBackoffRetry ; import org . apache . kafka . common . serialization . StringSerializer ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . eclipse . jgit . util . FS ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; @Singleton public class Configuration { private static final Logger log = LoggerFactory . getLogger ( Configuration . class ) ; < |startfocus| > public static final String PLUGIN_NAME = "multi - site" ; < |endfocus| > static final String INSTANCE_ID_FILE = "instanceId . data" ; // common parameters to cache and index sections static final String THREAD_POOL_SIZE_KEY = "threadPoolSize" ; static final int DEFAULT_INDEX_MAX_TRIES = 2 ; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000 ; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000 ; static final int DEFAULT_THREAD_POOL_SIZE = 4 ; static final String NUM_STRIPED_LOCKS = "numStripedLocks" ; static final int DEFAULT_NUM_STRIPED_LOCKS = 10 ; static final String DEFAULT_REPLICATION_TYPE = "defaultReplicationType" ; static final String DEFAULT_REPLICATION_TYPE_VALUE = "SYNC" ; static final String DEFAULT_REPLICATION_DELAY = "defaultReplicationDelay" ; static final int DEFAULT_REPLICATION_DELAY_VALUE = 0 ; static final String DEFAULT_REPLICATION_DELAY_UNIT = "defaultReplicationDelayUnit" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_VALUE = "SECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_SECONDS = "SECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_MINUTES = "MINUTES" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_HOURS = "HOURS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_DAYS = "DAYS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_WEEKS = "WEEKS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_MONTHS = "MONTHS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_YEARS = "YEARS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_FOREVER = "FOREVER" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_MILLISECONDS = "MILLISECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_MICROSECONDS = "MICROSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_NANOSECONDS = "NANOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_PICOSECONDS = "PICOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_FEMTOSECONDS = "FEMTOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_ATTOSECONDS = "ATTOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_ZEPTOSECONDS = "ZEPTOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_YOCTOSECONDS = "YOCTOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_DECASECONDS = "DECASECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_HECTOSECONDS = "HECTOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_KILOSECONDS = "KILOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_MEGASECONDS = "MEGASECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_GIGASECONDS = "GIGASECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_TERASECONDS = "TERASECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_PETASECONDS = "PETASECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_EXASECONDS = "EXASECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_ZETTASECONDS = "ZETTASECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_YOTTASECONDS = "YOTTASECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_DECISECONDS = "DECISECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_CENTISECONDS = "CENTISECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_MILLISECONDS = "MILLISECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_MICROSECONDS = "MICROSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_NANOSECONDS = "NANOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_PICOSECONDS = "PICOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_FEMTOSECONDS = "FEMTOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_ATTOSECONDS = "ATTOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_ZEPTOSECONDS = "ZEPTOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_YOCTOSECONDS = "YOCTOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_DECASECONDS = "DECASECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_HECTOSECONDS = "HECTOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_KILOSECONDS = "KILOSECONDS" ; static final String DEFAULT_REPLICATION_DELAY_UNIT_MEGASECONDS = "MEGASECON
import org . eclipse . jgit . lib . PersonIdent ; import org . eclipse . jgit . lib . ProgressMonitor ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . RefDatabase ; import org . eclipse . jgit . revwalk . RevWalk ; import org . eclipse . jgit . transport . PushCertificate ; import org . eclipse . jgit . transport . ReceiveCommand ; import org . eclipse . jgit . util . time . ProposedTimestamp ; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { private final BatchRefUpdate batchRefUpdate ; private final RefDatabase refDb ; private final SharedRefDatabase sharedRefDb ; < |startfocus| > private final List < ReceiveCommand > receiveCommands ; < |endfocus| > private final String projectName ; public static class RefPair { final Ref oldRef ; final Ref newRef ; final Exception exception ; RefPair ( Ref oldRef , Ref newRef ) { this . oldRef = oldRef ; this . newRef = newRef ; this . exception = null ; } RefPair ( Ref newRef , Exception e ) { this . newRef = newRef ; this . oldRef = SharedRefDatabase . NULL_REF ; this . exception = e ; } public boolean hasFailed ( ) { return exception != null ; } }
private final Index index ; private final KafkaSubscriber subscriber ; private final Kafka kafka ; private final ZookeeperConfig zookeeperConfig ; @Inject Configuration ( SitePaths sitePaths ) { < |startfocus| > this ( new FileBasedConfig ( sitePaths . etc_dir . resolve ( PLUGIN_NAME + " . config" ) . toFile ( ) , FS . DETECTED ) ) ; this . load ( ) ; < |endfocus| >
< |startfocus| > protected void configure ( ) { < |endfocus| > bind ( ReplicationQueue . class ) . in ( Scopes . SINGLETON ) ; bind ( LifecycleListener . class ) . annotatedWith ( UniqueAnnotations . create ( ) ) . to ( ReplicationQueue . class ) ; DynamicSet . bind ( binder ( ) , GitReferenceUpdatedListener . class ) . to ( ReplicationQueue . class ) ; DynamicSet . bind ( binder ( ) , NewProjectCreatedListener . class ) . to ( ReplicationQueue . class ) ; DynamicSet . bind ( binder ( ) , ProjectDeletedListener . class ) . to ( ReplicationQueue . class ) ; DynamicSet . bind ( binder ( ) , HeadUpdatedListener . class ) . to ( ReplicationQueue . class ) ; bind ( OnStartStop . class ) . in ( Scopes . SINGLETON ) ; bind ( LifecycleListener . class ) . annotatedWith ( UniqueAnnotations . create ( ) ) . to ( OnStartStop . class ) ; bind ( LifecycleListener . class ) . annotatedWith ( UniqueAnnotations . create ( ) ) . to ( ReplicationLogFile . class ) ; bind ( CredentialsFactory . class ) . to ( AutoReloadSecureCredentialsFactoryDecorator . class ) . in ( Scopes . SINGLETON ) ; bind ( CapabilityDefinition . class ) . annotatedWith ( Exports . named ( START_REPLICATION ) ) . to ( StartReplicationCapability . class ) ; install ( new FactoryModuleBuilder ( ) . build ( PushAll . Factory . class ) ) ; install ( new FactoryModuleBuilder ( ) . build ( ReplicationState . Factory . class ) ) ; bind ( ReplicationConfig . class ) . to ( AutoReloadConfigDecorator . class ) ; DynamicSet . setOf ( binder ( ) , ReplicationStateListener . class ) ; bind ( ReplicationState . class ) . in ( Scopes . SINGLETON ) ;
try { rateLimiterHolder = limitsPerAccount . get ( accountId ) ; } catch ( ExecutionException e ) { rateLimiterHolder = Holder . EMPTY ; log . warn ( "Cannot get rate limits for account '' { } ''" , accountId , e ) ; } } else { try { rateLimiterHolder = limitsPerRemoteHost . get ( req . getRemoteHost ( ) ) ; } catch ( ExecutionException e ) { rateLimiterHolder = Holder . EMPTY ; log . warn ( < |startfocus| > "Cannot get rate limits for anonymous access from remote host '' % s''" , req . getRemoteHost ( ) , e ) ; < |endfocus| > } } if ( ! rateLimiterHolder . hasGracePermits ( ) && rateLimiterHolder . get ( ) != null && ! rateLimiterHolder . get ( ) . tryAcquire ( ) ) { String msg = MessageFormat . format ( limitExceededMsg , rateLimiterHolder . get ( ) . getRate ( ) * SECONDS_PER_HOUR , rateLimiterHolder . getBurstPermits ( ) ) ; ( ( HttpServletResponse ) res ) . sendError ( SC_TOO_MANY_REQUESTS , msg ) ; return ; } } chain . doFilter ( req , res ) ; } boolean isRest ( ServletRequest req ) { < |startfocus| >
public void run ( ) { try { dispatcher . get ( ) . postEvent ( new HeartbeatEvent ( ) ) ; } catch ( OrmException e ) { < |startfocus| > logger . error ( "Failed to post heartbeat event : { } " , e . getMessage ( ) , e ) ; < |endfocus| > }
if ( itemTs . isPresent ( ) ) { count ++ ; newLastIndexTs = maxTimestamp ( newLastIndexTs , itemTs . get ( ) ) ; } } catch ( Exception e ) { log . atSevere ( ) . withCause ( e ) . log ( "Unable to reindex % s % s" , itemNameString , c ) ; errors ++ ; } } long elapsedNanos = stopwatch . stop ( ) . elapsed ( TimeUnit . NANOSECONDS ) ; if ( count > 0 ) { log . atInfo ( ) . log ( < |startfocus| > " % s % ss reindexed in % d msec ( % d / sec ) , % d failed" , < |endfocus| > count , itemNameString , elapsedNanos / 1000000L , ( count * 1000L ) / ( elapsedNanos / 1000000L ) , errors ) ; } else if ( errors > 0 ) { log . atInfo ( ) . log ( " % d % ss failed to reindex" , errors , itemNameString ) ; } else { log . atFine ( ) . log ( "Scanning finished" ) ; } indexTs . update ( itemName , newLastIndexTs . toLocalDateTime ( ) ) ; } catch ( Exception e ) { log . atSevere ( ) . withCause ( e ) . log ( "Unable to scan % ss" , itemNameString ) ; }
try { ChangeChecker checker = changeCheckerFactory . create ( id ) ; Optional < ChangeNotes > changeNotes = checker . getChangeNotes ( ) ; if ( changeNotes . isPresent ( ) ) { ChangeNotes notes = changeNotes . get ( ) ; reindex ( notes ) ; if ( checker . isChangeUpToDate ( indexEvent ) ) { if ( retryCount > 0 ) { log . atWarning ( ) . log ( "Change % s has been eventually indexed after % d attempt ( s ) " , id , retryCount ) ; } else { log . atFine ( ) . log ( "Change { } successfully indexed" , id ) ; } } else { < |startfocus| > log . atWarning ( ) . log ( "Change % s seems too old compared to the event timestamp ( event - Ts = % s > > change - Ts = % s ) " , id , indexEvent , checker ) ; rescheduleIndex ( id , indexEvent , retryCount + 1 ) ; < |endfocus| > } } else { indexer . delete ( parseChangeId ( id ) ) ; log . atWarning ( ) . log ( "Change % s could not be found in the local Git repository ( eventTs = % s ) , deleted from index" , id , indexEvent ) ; } } catch ( Exception e ) {
setHeaders ( rsp ) ; try { List < String > params = Splitter . on ( ' / ' ) . splitToList ( req . getPathInfo ( ) ) ; String cacheName = params . get ( CACHENAME_INDEX ) ; String json = req . getReader ( ) . readLine ( ) ; forwardedCacheEvictionHandler . evict ( CacheEntry . from ( cacheName , GsonParser . fromJson ( cacheName , json ) ) ) ; rsp . setStatus ( SC_NO_CONTENT ) ; } catch ( CacheNotFoundException e ) { < |startfocus| > log . atSevere ( ) . log ( "Failed to process eviction request : { } " , e . getMessage ( ) ) ; < |endfocus| > sendError ( rsp , SC_BAD_REQUEST , e . getMessage ( ) ) ; } catch ( IOException e ) { log . atSevere ( ) . withCause ( e ) . log ( "Failed to process eviction request" ) ; sendError ( rsp , SC_BAD_REQUEST , e . getMessage ( ) ) ; }
for ( ; ; ) { try { execCnt ++ ; tryOnce ( ) ; log . atFine ( ) . log ( " % s % s towards % s OK" , action , key , destination ) ; return true ; } catch ( ForwardingException e ) { int maxTries = cfg . http ( ) . maxTries ( ) ; log . atFine ( ) . withCause ( e ) . log ( < |startfocus| > "Failed to % s % s on % s [ % d / % s ] " , action , key , destination , execCnt , maxTries ) ; < |endfocus| > if ( ! e . isRecoverable ( ) ) { log . atSevere ( ) . withCause ( e ) . log ( " % s % s towards % s failed with unrecoverable error ; giving up" , action , key , destination ) ; return false ; } if ( execCnt >= maxTries ) { log . atSevere ( ) . log ( "Failed to % s % s on % s after % d tries ; giving up" , action , key , destination , maxTries ) ; return false ; } log . atFine ( ) . log ( "Retrying to % s % s on % s" , action , key , destination ) ; try { Thread . sleep ( cfg . http ( ) . retryInterval ( ) ) ;
action , key , destination ) ; return false ; } if ( execCnt >= maxTries ) { log . atSevere ( ) . log ( "Failed to % s % s on % s after % d tries ; giving up" , action , key , destination , maxTries ) ; return false ; } log . atFine ( ) . log ( "Retrying to % s % s on % s" , action , key , destination ) ; try { Thread . sleep ( cfg . http ( ) . retryInterval ( ) ) ; } catch ( InterruptedException ie ) { < |startfocus| > log . atSevere ( ) . withCause ( ie ) . log ( < |endfocus| > " % s % s towards % s was interrupted ; giving up" , action , key , destination ) ; Thread . currentThread ( ) . interrupt ( ) ; return false ; } } }
public void viewAccepted ( View view ) { log . atInfo ( ) . log ( "viewAccepted ( view : % s ) called" , view ) ; synchronized ( this ) { if ( view . getMembers ( ) . size ( ) > 2 ) { log . atWarning ( ) . log ( " % d members joined the jgroups cluster % s ( % s ) . " < |startfocus| > + " Only two members are supported . Members : { } " , < |endfocus| > view . getMembers ( ) . size ( ) , jgroupsConfig . clusterName ( ) , channel . getName ( ) , view . getMembers ( ) ) ; } if ( peerAddress != null && ! view . getMembers ( ) . contains ( peerAddress ) ) { log . atInfo ( ) . log ( "viewAccepted ( ) : removed peerInfo" ) ; peerAddress = null ; peerInfo = Optional . empty ( ) ; } } if ( view . size ( ) > 1 ) { try { channel . send ( new Message ( null , myUrl ) ) ; } catch ( Exception e ) { // channel communication caused an error . Can't do much about it . log . atSevere ( ) . withCause ( e ) . log ( "Sending a message over channel % s to cluster % s failed" , channel . getName ( ) , jgroupsConfig . clusterName ( ) ) ; } } }
public void connect ( ) { try { channel = getChannel ( ) ; Optional < InetAddress > address = finder . findAddress ( ) ; if ( address . isPresent ( ) ) { log . atFine ( ) . log ( "Protocol stack : % s" , channel . getProtocolStack ( ) ) ; channel . getProtocolStack ( ) . getTransport ( ) . setBindAddress ( address . get ( ) ) ; < |startfocus| > log . atFine ( ) . log ( "Channel bound to { } " , address . get ( ) ) ; < |endfocus| > } else { log . atWarning ( ) . log ( "Channel not bound : address not present" ) ; } channel . setReceiver ( this ) ; channel . setDiscardOwnMessages ( true ) ; channel . connect ( jgroupsConfig . clusterName ( ) ) ; log . atInfo ( ) . log ( "Channel % s successfully joined jgroups cluster % s" , channel . getName ( ) , jgroupsConfig . clusterName ( ) ) ; } catch ( Exception e ) { if ( channel != null ) { log . atSevere ( ) . withCause ( e ) . log ( "joining cluster % s ( channel % s ) failed" , jgroupsConfig . clusterName ( ) , channel . getName ( ) ) ; } else { log . atSevere ( ) . withCause ( e ) . log ( "joining cluster % s failed" , jgroupsConfig . clusterName ( ) ) ; } throw new RuntimeException ( e ) ; } }
@Override public Ref getTarget ( ) { return null ; } @Override public ObjectId getObjectId ( ) { return null ; } @Override public ObjectId getPeeledObjectId ( ) { return null ; } @Override public boolean isPeeled ( ) { return false ; } @Override public Storage getStorage ( ) { return Storage . NEW ; } } ; ImmutableList < String > refsToIgnoreInSharedDb = < |startfocus| > ImmutableList . of ( "refs / draft - comments / .* " , "refs / changes / .* / [ 0 - 9 ] [ 0 - 9 ] " ) ; < |endfocus| > /* * * Create a new in - memory Ref name associated with an objectId . * * @param refName ref name * @param objectId object id */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param project project name of the ref * @param newRef new reference to store .
import javax . servlet . http . HttpServletResponse ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; @Singleton public class RestApiRateLimiter extends AllRequestFilter { private static final Logger log = LoggerFactory . getLogger ( RestApiRateLimiter . class ) ; private static final int SECONDS_PER_HOUR = 3600 ; static final int SC_TOO_MANY_REQUESTS = 429 ; private final Provider < CurrentUser > user ; private final LoadingCache < Account . Id , Holder > limitsPerAccount ; private final LoadingCache < String , Holder > limitsPerRemoteHost ; < |startfocus| > private final Pattern servletPath = < |endfocus| > Pattern . compile ( " ^/ ( ? : a / ) ? " + " ( access|accounts|changes|config|groups|plugins|projects|Documentation|tools ) / ( .* ) $" ) ; private final String limitExceededMsg ; @Inject RestApiRateLimiter ( Provider < CurrentUser > user , @Named ( HttpModule . CACHE_NAME_RESTAPI_ACCOUNTID ) LoadingCache < Account . Id , Holder > limitsPerAccount , @Named ( HttpModule . CACHE_NAME_RESTAPI_REMOTEHOST ) LoadingCache < String , Holder > limitsPerRemoteHost , @Named ( RateMsgHelper . RESTAPI_CONFIGURABLE_MSG_ANNOTATION ) String limitExceededMsg ) { this . user = user ;
AdministrateCheckersPermission permission ) { this . self = self ; this . permissionBackend = permissionBackend ; this . listCheckers = listCheckers ; this . checkers = checkers ; this . views = views ; this . permission = permission ; } @Override public RestView < TopLevelResource > list ( ) throws RestApiException { return listCheckers ; } @Override public CheckerResource parse ( TopLevelResource parent , IdString id ) throws AuthException , ResourceNotFoundException , PermissionBackendException , IOException , ConfigInvalidException { < |startfocus| > if ( ! self . get ( ) . isIdentifiedUser ( ) ) { < |endfocus| > throw new AuthException ( "Authentication required" ) ; } permissionBackend . currentUser ( ) . check ( permission ) ; Checker checker = checkers . getChecker ( id . get ( ) ) . orElseThrow ( ( ) - > new ResourceNotFoundException ( id ) ) ; return new CheckerResource ( checker ) ; } @Override public DynamicMap < RestView < CheckerResource > > views ( ) { return views ; } }
return null ; } @Override public ObjectId getObjectId ( ) { return null ; } @Override public ObjectId getPeeledObjectId ( ) { return null ; } @Override public boolean isPeeled ( ) { return false ; } @Override public Storage getStorage ( ) { return Storage . NEW ; } } ; < |startfocus| > ImmutableList < String > refsToIgnoreInSharedDb = ImmutableList . of ( "refs / draft - comments / .* " , "refs / changes / [ 0 - 9 ] +/ [ 0 - 9 ] +/ [ 0 - 9 ] + " ) ; < |endfocus| > /* * * Create a new in - memory Ref name associated with an objectId . * * @param refName ref name * @param objectId object id */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param project project name of the ref * @param newRef new reference to store . * @return new ref */ default Ref newRef ( Project . NameKey project , Ref newRef ) { return newRef ( RefNames . fullName ( newRef . getName ( ) , project ) , newRef . getObjectId ( ) ) ; } /* * * Utility method for new refs . * * @param project project name of the ref * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( Project . NameKey project , String refName , ObjectId objectId ) { return newRef ( RefNames . fullName ( refName , project ) , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref */ default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } /* * * Utility method for new refs . * * @param refName name of the ref * @param objectId object id * @return new ref
*/ boolean compareAndRemove ( String project , Ref oldRef ) throws IOException ; /* * * Some references should not be stored in the SharedRefDatabase . * * @param ref * @return true if it's to be ignore ; false otherwise */ default boolean ignoreRefInSharedDb ( Ref ref ) { < |startfocus| > String refName = ref . getName ( ) ; return refName . startsWith ( "refs / draft - comments" ) || ( refName . startsWith ( "refs / changes" ) && ! refName . endsWith ( " / meta" ) ) ; < |endfocus| > } }
@Inject public ZkSharedRefDatabase ( CuratorFramework client , @Named ( "ZkLockRetryPolicy" ) RetryPolicy retryPolicy ) { this . client = client ; this . retryPolicy = retryPolicy ; } @Override public boolean compareAndRemove ( String project , Ref oldRef ) throws IOException { return compareAndPut ( project , oldRef , NULL_REF ) ; } @Override public boolean compareAndPut ( String projectName , Ref oldRef , Ref newRef ) throws IOException { < |startfocus| > if ( newRef != NULL_REF && ignoreRefInSharedDb ( newRef ) ) { return true ; } < |endfocus| > final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue ( client , pathFor ( projectName , oldRef , newRef ) , retryPolicy ) ; try { if ( oldRef == NULL_REF ) { return distributedRefValue . initialize ( writeObjectId ( newRef . getObjectId ( ) ) ) ; } final ObjectId newValue = newRef . getObjectId ( ) == null ? ObjectId . zeroId ( ) : newRef . getObjectId ( ) ; final AtomicValue < byte [ ] > newDistributedValue = distributedRefValue . compareAndSet (
static final ObjectId AN_OBJECT_ID_2 = new ObjectId ( 1 , 2 , 3 , 4 , 6 ) ; static final ObjectId AN_OBJECT_ID_3 = new ObjectId ( 1 , 2 , 3 , 4 , 7 ) ; static final String A_TEST_REF_NAME = "refs / heads / master" ; default String aBranchRef ( ) { return RefNames . REFS_HEADS + testBranch ( ) ; } < |startfocus| > default Ref newRef ( String refName , ObjectId objectId ) { return new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , refName , objectId ) ; } < |endfocus| > String testBranch ( ) ; }
* @return true if the remove was successful ; false otherwise . * @throws java . io . IOException the reference could not be removed due to a system error . */ boolean compareAndRemove ( String project , Ref oldRef ) throws IOException ; /* * * Some references should not be stored in the SharedRefDatabase . * * @param ref * @return true if it's to be ignore ; false otherwise */ default boolean ignoreRefInSharedDb ( Ref ref ) { String refName = ref . getName ( ) ; < |startfocus| > return refName == null || refName . startsWith ( "refs / draft - comments" ) < |endfocus| > || ( refName . startsWith ( "refs / changes" ) && ! refName . endsWith ( " / meta" ) ) ; } }
CuratorFramework client , @Named ( "ZkLockRetryPolicy" ) RetryPolicy retryPolicy ) { this . client = client ; this . retryPolicy = retryPolicy ; } @Override public boolean compareAndRemove ( String project , Ref oldRef ) throws IOException { return ignoreRefInSharedDb ( oldRef ) || compareAndPut ( project , oldRef , NULL_REF ) ; } @Override public boolean compareAndPut ( String projectName , Ref oldRef , Ref newRef ) throws IOException { final DistributedAtomicValue distributedRefValue = < |startfocus| > new DistributedAtomicValue ( client , pathFor ( projectName , oldRef ) , retryPolicy ) ; < |endfocus| > try { if ( oldRef == NULL_REF ) { return distributedRefValue . initialize ( writeObjectId ( newRef . getObjectId ( ) ) ) ; } final ObjectId newValue = newRef . getObjectId ( ) == null ? ObjectId . zeroId ( ) : newRef . getObjectId ( ) ; final AtomicValue < byte [ ] > newDistributedValue = distributedRefValue . compareAndSet ( writeObjectId ( oldRef . getObjectId ( ) ) , writeObjectId ( newValue ) ) ; return newDistributedValue . succeeded ( ) ; } catch ( Exception e ) { logger . atWarning ( ) . withCause ( e ) . log (
new ZkSharedRefDatabase ( zookeeperContainer . getCurator ( ) , new RetryNTimes ( 5 , 30 ) ) ; } @After public void cleanup ( ) { zookeeperContainer . cleanup ( ) ; } @Test public void shouldCompareAndCreateSuccessfully ( ) throws Exception { Ref ref = refOf ( AN_OBJECT_ID_1 ) ; assertThat ( zkSharedRefDatabase . compareAndCreate ( A_TEST_PROJECT_NAME , ref ) ) . isTrue ( ) ; < |startfocus| > String data = zookeeperContainer . readRefValueFromZk ( A_TEST_PROJECT_NAME , ref ) . getName ( ) ; assertThat ( data ) . isEqualTo ( ref . getObjectId ( ) . getName ( ) ) ; < |endfocus| > } @Test public void shouldCompareAndPutSuccessfully ( ) throws Exception { Ref oldRef = refOf ( AN_OBJECT_ID_1 ) ; Ref newRef = refOf ( AN_OBJECT_ID_2 ) ; String projectName = A_TEST_PROJECT_NAME ; zookeeperContainer . createRefInZk ( projectName , oldRef ) ; assertThat ( zkSharedRefDatabase . compareAndPut ( projectName , oldRef , newRef ) ) . isTrue ( ) ; } @Test public void shouldCompareAndPutWithNullOldRefSuccessfully ( ) throws Exception { Ref oldRef = refOf ( null ) ; Ref newRef = refOf ( AN_OBJECT_ID_2 ) ; String projectName = A_TEST_PROJECT_NAME ;
private final AtomicReference < Command > atomicCmd ; private final DynamicSet < SshCommandPreExecutionFilter > commandFilters ; @Argument ( index = 0 , required = false , metaVar = "COMMAND" , handler = SubcommandHandler . class ) private String commandName ; @Argument ( index = 1 , multiValued = true , metaVar = "ARG" ) private List < String > args = new ArrayList < > ( ) ; @Inject < |startfocus| > DispatchCommand ( PermissionBackend permissionBackend , @Assisted Map < String , CommandProvider > all , DynamicSet < SshCommandPreExecutionFilter > commandFilters ) { < |endfocus| > this . permissionBackend = permissionBackend ; commands = all ; atomicCmd = Atomics . newReference ( ) ; this . commandFilters = commandFilters ; } Map < String , CommandProvider > getMap ( ) { return commands ; } @Override public void start ( Environment env ) throws IOException { try { parseCommandLine ( ) ; if ( Strings . isNullOrEmpty ( commandName ) ) { StringWriter msg = new StringWriter ( ) ; msg . write ( usage ( ) ) ; throw die ( msg . toString ( ) ) ; } final CommandProvider p = commands . get ( commandName ) ; if ( p == null ) { String msg = "\"" + commandName + "\" is not a git review command .
Optional < ExternalId > other = null ; try { other = externalIds . get ( key ) ; } catch ( IOException | ConfigInvalidException e ) { throw new IllegalArgumentException ( "Internal error while fetching username = '" + username + "'" ) ; } try { accountsUpdateProvider . get ( ) . update ( "Set Username from GitHub" , accountId , u - > u . addExternalId ( ExternalId . create ( key , accountId , null , null ) ) ) ; } catch ( OrmDuplicateKeyException dupeErr ) { < |startfocus| > // If we are using this identity , don't report the exception . if ( ! other . isPresent ( ) || ! other . get ( ) . accountId ( ) . equals ( accountId ) ) { throw new IllegalArgumentException ( "username " + username + " already in use" ) ; } < |endfocus| > } catch ( Exception e ) { throw new IllegalArgumentException ( "Internal error while trying to set username = '" + username + "'" ) ; } log . debug ( "Account { } updated with preferredEmail = { } , fullName = { } , username = { } " , accountId , email , fullName , username ) ;
import java . util . Objects ; import java . util . Set ; import java . util . function . Predicate ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . transport . RefSpec ; import org . eclipse . jgit . transport . RemoteConfig ; import org . eclipse . jgit . transport . URIish ; /* * Collection of Git repositories destinations for replication . */ public class DestinationsCollection { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; private final ReplicationConfig replicationConfig ; private final Destination . Factory destinationFactory ; < |startfocus| > private final List < Destination > allDestinations = Collections . emptyList ( ) ; < |endfocus| > @Inject DestinationsCollection ( ReplicationConfig replicationConfig , Destination . Factory destinationFactory ) { this . replicationConfig = replicationConfig ; this . destinationFactory = destinationFactory ; } /* * * Get all destinations matching the specified type . * * @param filterType type of destination . * @return list of destinations matching the specified filter type . */ public List < Destination > getAll ( FilterType filterType ) { if ( replicationConfig . reloadIfNeeded ( ) ) { try { load ( ) ; } catch ( ConfigInvalidException e ) {
import java . util . Objects ; import java . util . Set ; import java . util . function . Predicate ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . transport . RefSpec ; import org . eclipse . jgit . transport . RemoteConfig ; import org . eclipse . jgit . transport . URIish ; /* * Collection of Git repositories destinations for replication . */ public class DestinationsCollection { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; private final ReplicationConfig replicationConfig ; private final Destination . Factory destinationFactory ; < |startfocus| > private List < Destination > allDestinations = Collections . emptyList ( ) ; < |endfocus| > @Inject DestinationsCollection ( ReplicationConfig replicationConfig , Destination . Factory destinationFactory ) { this . replicationConfig = replicationConfig ; this . destinationFactory = destinationFactory ; } /* * * Get all destinations matching the specified type . * * @param filterType type of destination . * @return list of destinations matching the specified filter type . */ public List < Destination > getAll ( FilterType filterType ) { if ( replicationConfig . reloadIfNeeded ( ) ) { try { load ( ) ; } catch ( ConfigInvalidException e ) {
CheckerUuid checkerUuid = createCheckerInServer ( createArbitraryCheckerInput ( ) ) ; boolean exists = checkerOperations . checker ( checkerUuid ) . exists ( ) ; assertThat ( exists ) . isTrue ( ) ; } @Test public void notExistingCheckerCanBeCheckedForExistence ( ) throws Exception { String notExistingCheckerUuid = "test : not - existing - checker" ; boolean exists = checkerOperations . checker ( notExistingCheckerUuid ) . exists ( ) ; assertThat ( exists ) . isFalse ( ) ; } @Test public void retrievingCheckerForInvalidUuidFails ( ) throws Exception { < |startfocus| > String notExistingCheckerUuid = "invalid - uuid" ; < |endfocus| > exception . expect ( IllegalArgumentException . class ) ; checkerOperations . checker ( notExistingCheckerUuid ) . get ( ) ; } @Test public void retrievingNotExistingCheckerFails ( ) throws Exception { String notExistingCheckerUuid = "foo : bar" ; exception . expect ( IllegalStateException . class ) ; checkerOperations . checker ( notExistingCheckerUuid ) . get ( ) ; } @Test public void checkerNotCreatedByTestApiCanBeRetrieved ( ) throws Exception { CheckerInput input = createArbitraryCheckerInput ( ) ; input . uuid = "test : unique - checker - not - created - via - test - API" ; CheckerUuid checkerUuid = createCheckerInServer ( input ) ;
} @Override public Check get ( ) throws Exception { return checks . getCheck ( key , GetCheckOptions . defaults ( ) ) . orElseThrow ( ( ) - > new IllegalStateException ( "Tried to get non - existing test check" ) ) ; } @Override public ImmutableMap < RevId , String > notesAsText ( ) throws Exception { try ( Repository repo = repoManager . openRepository ( key . repository ( ) ) ; < |startfocus| > RevWalk rw = new RevWalk ( repo ) ; ObjectReader reader = rw . getObjectReader ( ) ) { < |endfocus| > Ref checkRef = repo . getRefDatabase ( ) . exactRef ( CheckerRef . checksRef ( key . patchSet ( ) . changeId ) ) ; checkNotNull ( checkRef ) ; NoteMap notes = NoteMap . read ( reader , rw . parseCommit ( checkRef . getObjectId ( ) ) ) ; ImmutableMap . Builder < RevId , String > raw = ImmutableMap . builder ( ) ; for ( Note note : notes ) { raw . put ( new RevId ( note . name ( ) ) , new String ( notes . getCachedBytes ( note . toObjectId ( ) , Integer . MAX_VALUE ) ) ) ; } return raw . build ( ) ; } } @Override public CheckInfo asInfo ( ListChecksOption . . . options ) throws Exception {
Ref immutableChangeRef = zkSharedRefDatabase . newRef ( "refs / heads / stable - 2 . 16" , AN_OBJECT_ID_1 ) ; assertThat ( zkSharedRefDatabase . ignoreRefInSharedDb ( immutableChangeRef ) ) . isFalse ( ) ; } @Test public void compareAndPutShouldAlwaysIngoreIgnoredRefs ( ) throws Exception { Ref existingRef = zkSharedRefDatabase . newRef ( "refs / draft - comments / 56 / 450756 / 1013728" , AN_OBJECT_ID_1 ) ; Ref oldRefToIgnore = zkSharedRefDatabase . newRef ( "refs / draft - comments / 56 / 450756 / 1013728" , AN_OBJECT_ID_2 ) ; < |startfocus| > Ref newRef = SharedRefDatabase . NULL_REF ; < |endfocus| > String projectName = A_TEST_PROJECT_NAME ; assertThat ( zkSharedRefDatabase . compareAndPut ( A_TEST_PROJECT_NAME , existingRef , SharedRefDatabase . NULL_REF ) ) . isTrue ( ) ; assertThat ( zkSharedRefDatabase . compareAndPut ( projectName , oldRefToIgnore , newRef ) ) . isTrue ( ) ; } @Override public String testBranch ( ) { return "branch_" + nameRule . getMethodName ( ) ; } }
} @Test public void compareAndPutShouldAlwaysIngoreIgnoredRefs ( ) throws Exception { Ref existingRef = zkSharedRefDatabase . newRef ( "refs / draft - comments / 56 / 450756 / 1013728" , AN_OBJECT_ID_1 ) ; Ref oldRefToIgnore = zkSharedRefDatabase . newRef ( "refs / draft - comments / 56 / 450756 / 1013728" , AN_OBJECT_ID_2 ) ; Ref newRef = SharedRefDatabase . NULL_REF ; String projectName = A_TEST_PROJECT_NAME ; < |startfocus| > assertThat ( zkSharedRefDatabase . compareAndPut ( A_TEST_PROJECT_NAME , existingRef , SharedRefDatabase . NULL_REF ) ) < |endfocus| > . isTrue ( ) ; assertThat ( zkSharedRefDatabase . compareAndPut ( projectName , oldRefToIgnore , newRef ) ) . isTrue ( ) ; } @Override public String testBranch ( ) { return "branch_" + nameRule . getMethodName ( ) ; } }
} return predicate ; } private static boolean hasStatusPredicate ( Predicate < ChangeData > predicate ) { if ( predicate instanceof IndexPredicate ) { return ( ( IndexPredicate < ChangeData > ) predicate ) . getField ( ) . getName ( ) . equals ( ChangeField . STATUS . getName ( ) ) ; } return predicate . getChildren ( ) . stream ( ) . anyMatch ( CheckerQuery : : hasStatusPredicate ) ; } // TODO ( ekempin ) : Retrying the query should be done by ChangeQueryProcessor . < |startfocus| > private List < ChangeData > executeIndexQueryWithRetry ( RetryHelper retryHelper , Provider < ChangeQueryProcessor > changeQueryProcessorProvider , Predicate < ChangeData > predicate ) < |endfocus| > throws OrmException { try { return retryHelper . execute ( ActionType . INDEX_QUERY , ( ) - > changeQueryProcessorProvider . get ( ) . query ( predicate ) . entities ( ) , OrmException . class : : isInstance ) ; } catch ( Exception e ) { Throwables . throwIfUnchecked ( e ) ; Throwables . throwIfInstanceOf ( e , OrmException . class ) ; throw new OrmException ( e ) ; } } }
try { predicate = createQueryPredicate ( checker ) ; } catch ( ConfigInvalidException e ) { logger . atWarning ( ) . withCause ( e ) . log ( "skipping invalid query for checker % s" , checker . getUuid ( ) ) ; return false ; } return predicate . asMatchable ( ) . match ( cd ) ; } public List < ChangeData > queryMatchingChanges ( Checker checker ) throws ConfigInvalidException , OrmException { < |startfocus| > return executeIndexQueryWithRetry ( retryHelper , changeQueryProcessorProvider , createQueryPredicate ( checker ) ) ; < |endfocus| > } private Predicate < ChangeData > createQueryPredicate ( Checker checker ) throws ConfigInvalidException { Predicate < ChangeData > predicate = new ProjectPredicate ( checker . getRepository ( ) . get ( ) ) ; if ( checker . getQuery ( ) . isPresent ( ) ) { String query = checker . getQuery ( ) . get ( ) ; Predicate < ChangeData > predicateForQuery ; try { predicateForQuery = queryBuilder . parse ( query ) ; } catch ( QueryParseException e ) { throw new ConfigInvalidException ( String . format ( "change query of checker % s is invalid : % s" , checker . getUuid ( ) , query ) , e ) ; } if ( ! predicateForQuery . isMatchable ( ) ) { throw new ConfigInvalidException ( String . format ( "change query of checker % s is not matchable : % s" , checker . getUuid ( ) , query ) ) ; } predicate = Predicate . and ( predicate , predicateForQuery ) ; } return predicate ; } }
try { UrlValidator . clean ( CheckerTestData . INVALID_URL ) ; assert_ ( ) . fail ( "expected BadRequestException" ) ; } catch ( BadRequestException e ) { assertMessage ( e , "only http / https URLs supported" , CheckerTestData . INVALID_URL ) ; } } @Test public void verifyTestQueries ( ) throws Exception { assertInvalidQuery ( CheckerTestData . QUERY_WITH_UNSUPPORTED_OPERATOR , "unsupported operator" , CheckerTestData . UNSUPPORTED_OPERATOR ) ; assertInvalidQuery ( CheckerTestData . INVALID_QUERY , "invalid" , CheckerTestData . INVALID_QUERY ) ; } < |startfocus| > < |endfocus| > private static void assertInvalidQuery ( String query , String . . . expectedMessageParts ) { try { CheckerQuery . clean ( query ) ; assert_ ( ) . fail ( "expected ConfigInvalidException" ) ; } catch ( ConfigInvalidException e ) { assertMessage ( e , expectedMessageParts ) ; } } private static void assertMessage ( Exception e , String . . . expectedMessageParts ) { for ( String expectedMessagePart : expectedMessageParts ) { assertThat ( e ) . hasMessageThat ( ) . ignoringCase ( ) . contains ( expectedMessagePart ) ; } } }
private void queueEvaluationIfNecessary ( String repositoryPath ) { if ( lastCheckExpired ( repositoryPath ) ) { EvaluationTask evaluationTask = evaluationTaskFactory . create ( repositoryPath ) ; if ( queuedEvaluationTasks . add ( evaluationTask ) ) { < |startfocus| > Future < ? > future = executor . submit ( evaluationTask ) ; < |endfocus| > addTaskListener ( future , evaluationTask ) ; timestamps . put ( repositoryPath , System . currentTimeMillis ( ) ) ; } }
< |startfocus| > private void addTaskListener ( Future < ? > future , EvaluationTask evaluationTask ) { ListenableFuture listenableFuture = JdkFutureAdapters . listenInPoolThread ( future ) ; < |endfocus| > listenableFuture . addListener ( new Runnable ( ) { public void run ( ) { queuedEvaluationTasks . remove ( evaluationTask ) ; } } , MoreExecutors . directExecutor ( ) ) ;
< |startfocus| > private void addTaskListener ( Future future , EvaluationTask evaluationTask ) { ListenableFuture < ? > listenableFuture = JdkFutureAdapters . listenInPoolThread ( future ) ; < |endfocus| > listenableFuture . addListener ( new Runnable ( ) { public void run ( ) { queuedEvaluationTasks . remove ( evaluationTask ) ; } } , MoreExecutors . directExecutor ( ) ) ;
public void createEvaluator ( ) { when ( event . getProjectName ( ) ) . thenReturn ( NAME_KEY . get ( ) ) ; < |startfocus| > when ( config . getExpireTimeRecheck ( ) ) . thenReturn ( 0L ) ; when ( gerritConfig . getInt ( "receive" , null , "threadPoolSize" , Runtime . getRuntime ( ) . availableProcessors ( ) ) ) . thenReturn ( 1 ) ; < |endfocus| > when ( repository . getDirectory ( ) ) . thenReturn ( new File ( REPOSITORY_PATH ) ) ; when ( repositoryOther . getDirectory ( ) ) . thenReturn ( new File ( REPOSITORY_PATH_OTHER ) ) ; taskSamePathCompleted = new EvaluationTask ( null , null , null , REPOSITORY_PATH ) ; taskSamePathNotCompleted = new EvaluationTask ( null , null , null , REPOSITORY_PATH ) ; taskDifferentPath = new EvaluationTask ( null , null , null , REPOSITORY_PATH_OTHER ) ; Factory eventTaskFactory = mock ( Factory . class ) ; when ( eventTaskFactory . create ( REPOSITORY_PATH ) ) . thenReturn ( taskSamePathNotCompleted ) . thenReturn ( taskSamePathCompleted ) ; when ( eventTaskFactory . create ( REPOSITORY_PATH_OTHER ) ) . thenReturn ( taskDifferentPath ) ; when ( executor . submit ( taskSamePathCompleted ) ) . thenReturn ( CompletableFuture . completedFuture ( null ) ) ;
taskDifferentPath = new EvaluationTask ( null , null , null , REPOSITORY_PATH_OTHER ) ; /* * Task factory */ Factory eventTaskFactory = mock ( Factory . class ) ; when ( eventTaskFactory . create ( REPOSITORY_PATH ) ) . thenReturn ( taskSamePathNotCompleted ) . thenReturn ( taskSamePathCompleted ) ; when ( eventTaskFactory . create ( REPOSITORY_PATH_OTHER ) ) . thenReturn ( taskDifferentPath ) ; /* * Executor */ when ( executor . submit ( taskSamePathCompleted ) ) . thenReturn ( CompletableFuture . completedFuture ( null ) ) ; < |startfocus| > when ( executor . submit ( taskSamePathNotCompleted ) ) . thenReturn ( new CompletableFuture < > ( ) ) ; < |endfocus| > when ( executor . submit ( taskDifferentPath ) ) . thenReturn ( CompletableFuture . completedFuture ( null ) ) ; evaluator = new Evaluator ( executor , eventTaskFactory , repoManager , config , gerritConfig ) ;
public static final String GLOBAL_CAPABILITIES = "GLOBAL_CAPABILITIES" ; /* * Pattern that matches all references in a project . */ public static final String ALL = "refs /* " ; /* * Pattern that matches all branches in a project . */ public static final String HEADS = "refs / heads /* " ; /* * Prefix that triggers a regular expression pattern . */ public static final String REGEX_PREFIX = " ^ " ; < |startfocus| > /* * Name of the access section . It could be a ref pattern or else . */ < |endfocus| > private String name ; private List < Permission > permissions ; public AccessSection ( String name ) { this . name = name ; this . permissions = new ArrayList < > ( ) ; } /* * @return true if the name is likely to be a valid reference section name . */ public static boolean isValidRefSectionName ( String name ) { return name . startsWith ( "refs / " ) || name . startsWith ( " ^ refs / " ) ; } public String getName ( ) { return name ; } public ImmutableList < Permission > getPermissions ( ) { return ImmutableList . copyOf ( permissions ) ; } public void addPermission ( Permission permission ) { permissions . add ( permission ) ; } public void removePermission ( Permission permission ) { permissions . remove ( permission ) ; } public void removePermission ( String permissionName ) { for ( Permission permission : permissions ) { if ( permission . getName ( ) . equals ( permissionName ) ) { permissions . remove ( permission ) ; break ; } } } public Permission getPermission ( String permissionName ) { for ( Permission permission : permissions ) { if ( permission . getName ( ) . equals ( permissionName ) ) { return permission ; } } return null ; } public boolean containsPermission ( String permissionName ) { return getPermission ( permissionName ) != null ; } public boolean containsExclusiveGroup ( ) { for ( Permission permission : permissions ) { if ( permission . getExclusiveGroup ( ) != null ) { return true ; } } return false ; } public boolean containsPermission ( Permission . Builder permission ) { return containsPermission ( permission . getName ( ) ) ; } public boolean containsPermission ( Permission permission ) { return containsPermission ( permission . getName ( ) ) ; } public boolean containsPermission ( String permissionName , String ref ) { Permission permission = getPermission ( permissionName ) ; if ( permission == null ) { return false ; } return permission . getRefPatterns ( ) . contains ( ref ) ; } public boolean containsPermission ( Permission . Builder permission , String ref ) { return containsPermission ( permission . getName ( ) , ref ) ; } public boolean containsPermission ( Permission permission , String ref ) { return containsPermission ( permission . getName ( ) , ref ) ; } public boolean containsPermission ( String permissionName , RefPattern ref ) { Permission permission = getPermission ( permissionName ) ; if ( permission == null ) { return false ; } return permission . getRefPatterns ( ) . contains ( ref ) ; } public boolean containsPermission ( Permission . Builder permission , RefPattern ref ) { return containsPermission ( permission . getName ( ) , ref ) ; } public boolean containsPermission ( Permission permission , RefPattern ref ) { return containsPermission ( permission . getName ( ) , ref ) ; } public boolean containsPermission ( String permissionName , ProjectPermission projectPermission ) { Permission permission = getPermission ( permissionName ) ; if ( permission == null ) { return false ; } return permission . getProjectPermissions ( ) . contains ( projectPermission ) ; } public boolean containsPermission ( Permission . Builder permission , ProjectPermission projectPermission ) { return containsPermission ( permission . getName ( ) , projectPermission ) ; } public boolean containsPermission ( Permission permission , ProjectPermission projectPermission ) { return containsPermission ( permission . getName ( ) , projectPermission ) ; } public boolean containsPermission ( String permissionName , GlobalPermission globalPermission ) { Permission permission = getPermission ( permissionName ) ; if ( permission == null ) { return false ; } return permission . getGlobalPermissions ( ) . contains ( globalPermission ) ; } public boolean containsPermission ( Permission . Builder permission , GlobalPermission globalPermission ) { return containsPermission ( permission . getName ( ) , globalPermission ) ; } public boolean containsPermission ( Permission permission , GlobalPermission globalPermission ) { return containsPermission ( permission . getName ( ) , globalPermission ) ; } public boolean containsPermission ( String permissionName , LabelPermission labelPermission ) { Permission permission = getPermission ( permissionName ) ; if ( permission == null ) { return false ; } return permission . getLabelPermissions ( ) . contains ( labelPermission ) ; } public boolean containsPermission ( Permission . Builder permission , LabelPermission labelPermission ) { return containsPermission ( permission . getName ( ) , labelPermission ) ; } public boolean containsPermission ( Permission permission , LabelPermission labelPermission ) { return containsPermission ( permission . getName ( ) , labelPermission ) ; } public boolean containsPermission ( String permissionName , PluginPermission pluginPermission ) { Permission permission = getPermission ( permissionName ) ; if ( permission == null ) { return false ; } return permission . getPluginPermissions ( ) . contains ( pluginPermission ) ; } public boolean containsPermission ( Permission . Builder permission , PluginPermission pluginPermission ) { return containsPermission ( permission . getName ( ) , pluginPermission ) ; } public boolean containsPermission ( Permission permission , PluginPermission pluginPermission ) { return containsPermission ( permission . getName ( ) , pluginPermission ) ; } public boolean containsPermission ( String permissionName , RefPermission refPermission ) { Permission permission = getPermission ( permissionName ) ; if ( permission == null ) { return false ; } return permission . getRefPermissions ( ) . contains ( refPermission ) ; } public boolean containsPermission ( Permission . Builder permission , RefPermission refPermission ) { return containsPermission ( permission . getName ( ) , refPermission ) ; } public boolean containsPermission ( Permission permission , RefPermission refPermission ) { return containsPermission ( permission . getName ( ) , refPermission ) ; } public boolean containsPermission ( String permissionName , ChangePermission changePermission ) { Permission permission = getPermission ( permissionName ) ; if ( permission == null ) { return false ; } return permission . getChangePermissions ( ) . contains ( changePermission ) ; } public boolean containsPermission ( Permission . Builder permission , ChangePermission changePermission ) { return containsPermission ( permission . getName ( ) , changePermission ) ; } public boolean containsPermission ( Permission permission , ChangePermission changePermission ) { return containsPermission ( permission . getName ( ) , changePermission ) ; } public boolean containsPermission ( String permissionName , GroupPermission groupPermission ) { Permission permission = getPermission ( permissionName ) ; if ( permission == null ) { return false ; } return permission . getGroupPermissions ( ) . contains ( groupPermission ) ; } public boolean containsPermission ( Permission . Builder permission , GroupPermission groupPermission ) { return containsPermission ( permission . getName ( ) , groupPermission ) ; } public boolean containsPermission ( Permission permission , GroupPermission groupPermission ) { return containsPermission ( permission . getName ( ) , groupPermission ) ; } public boolean containsPermission ( String permissionName , GroupName groupName ) { Permission permission = getPermission ( permissionName ) ; if ( permission == null ) { return false ; } return permission . getGroupNames ( ) . contains ( groupName ) ; } public boolean containsPermission ( Permission . Builder permission , GroupName groupName ) { return containsPermission ( permission . getName ( ) , groupName ) ; } public boolean containsPermission ( Permission permission , GroupName groupName ) { return containsPermission ( permission . getName ( ) , groupName ) ; } public boolean containsPermission ( String permissionName , AccountGroup . UUID groupUUID ) { Permission permission = getPermission ( permissionName ) ; if ( permission == null ) { return false ; } return permission . getGroupUUIDs ( ) . contains ( groupUUID ) ; } public boolean containsPermission ( Permission
public static final String GLOBAL_CAPABILITIES = "GLOBAL_CAPABILITIES" ; /* * Pattern that matches all references in a project . */ public static final String ALL = "refs /* " ; /* * Pattern that matches all branches in a project . */ public static final String HEADS = "refs / heads /* " ; /* * Prefix that triggers a regular expression pattern . */ public static final String REGEX_PREFIX = " ^ " ; < |startfocus| > /* * Name of the access section . It could be a ref pattern or else . */ < |endfocus| > private String name ; private List < Permission > permissions ; public AccessSection ( String name ) { this . name = name ; this . permissions = new ArrayList < > ( ) ; } /* * @return true if the name is likely to be a valid reference section name . */ public static boolean isValidRefSectionName ( String name ) { return name . startsWith ( "refs / " ) || name . startsWith ( " ^ refs / " ) ; } public String getName ( ) { return name ; } public ImmutableList < Permission > getPermissions ( ) { return ImmutableList . copyOf ( permissions ) ; }
public AccessSection ( String name ) { this . name = name ; < |startfocus| > this . permissions = new ArrayList < > ( ) ; < |endfocus| > }
Copyright ( C ) 2013 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . replication ; import org . eclipse . jgit . errors . ConfigInvalidException ; /* * Listener of the configuration loading events . */ public interface ReplicationConfigListener { /* * Invoked just before replication . config is about to be loaded . */ void beforeLoad ( ) ; /* * * Invoked just after replication . config is loaded into memory . * * @throws ConfigInvalidException if the loaded configuration is not valid */
private void innerTest ( ) throws Exception { try { outer ( ) ; fail ( "should throw" ) ; } catch ( IllegalStateException e ) { StackTraceElement [ ] trimmed = < |startfocus| > trimStack ( < |endfocus| > e . getStackTrace ( ) , Thread . currentThread ( ) . getStackTrace ( ) [ 1 ] ) ; String str = Arrays . toString ( trimmed ) ; assertThat ( str ) . doesNotContain ( "trimStackTrace" ) ; assertThat ( str ) . contains ( "innerTest" ) ; }
// Project name is scoped by test , so we need to get it from our initial change Project . NameKey projectNameKey = initialResult . getChange ( ) . project ( ) ; String projectName = projectNameKey . get ( ) ; createBranch ( new Branch . NameKey ( projectName , "ds_one" ) ) ; createBranch ( new Branch . NameKey ( projectName , "ds_two" ) ) ; initialResult . assertOkStatus ( ) ; merge ( initialResult ) ; < |startfocus| > // Create normalUserGroup , containing current user , and contextUserGroup , containing contextUser < |endfocus| > String normalUserGroup = groupOperations . newGroup ( ) . name ( "normalUserGroup" ) . create ( ) . get ( ) ; gApi . groups ( ) . id ( normalUserGroup ) . addMembers ( user . id ( ) . toString ( ) ) ; AccountApi contextUserApi = gApi . accounts ( ) . create ( "someContextUser" ) ; String contextUserGroup = groupOperations . newGroup ( ) . name ( "contextUserGroup" ) . create ( ) . get ( ) ; gApi . groups ( ) . id ( contextUserGroup ) . addMembers ( contextUserApi . get ( ) . name ) ; // Grant exclusive + 2 to context user grantLabel ( "Code - Review" , - 2 , 2 , projectNameKey , "refs / heads / ds_one" , false , "refs / heads / ds_two" , false ,
// Project name is scoped by test , so we need to get it from our initial change Project . NameKey projectNameKey = initialResult . getChange ( ) . project ( ) ; String projectName = projectNameKey . get ( ) ; createBranch ( new Branch . NameKey ( projectName , "ds_one" ) ) ; createBranch ( new Branch . NameKey ( projectName , "ds_two" ) ) ; initialResult . assertOkStatus ( ) ; merge ( initialResult ) ; < |startfocus| > // Create normalUserGroup , containing current user , and contextUserGroup , containing contextUser < |endfocus| > String normalUserGroup = groupOperations . newGroup ( ) . name ( "normalUserGroup" ) . create ( ) . get ( ) ; gApi . groups ( ) . id ( normalUserGroup ) . addMembers ( user . id ( ) . toString ( ) ) ; AccountApi contextUserApi = gApi . accounts ( ) . create ( "randomContextUser" ) ; String contextUserGroup = groupOperations . newGroup ( ) . name ( "contextUserGroup" ) . create ( ) . get ( ) ; gApi . groups ( ) . id ( contextUserGroup ) . addMembers ( contextUserApi . get ( ) . name ) ; // Grant + 2 to context user , since it doesn't have it by default grantLabel ( "Code - Review" , - 2 , 2 , projectNameKey , "refs / heads /* " , false , "refs / heads /* " ,
private final PermissionBackend permissionBackend ; private final Map < String , CommandProvider > commands ; private final AtomicReference < Command > atomicCmd ; private final DynamicSet < SshExecuteCommandInterceptor > commandInterceptors ; @Argument ( index = 0 , required = false , metaVar = "COMMAND" , handler = SubcommandHandler . class ) private String commandName ; @Argument ( index = 1 , multiValued = true , metaVar = "ARG" ) private List < String > args = new ArrayList < > ( ) ; @Inject DispatchCommand ( PermissionBackend permissionBackend , DynamicSet < SshExecuteCommandInterceptor > commandInterceptors , < |startfocus| > @Assisted Map < String , CommandProvider > all ) { < |endfocus| > this . permissionBackend = permissionBackend ; commands = all ; atomicCmd = Atomics . newReference ( ) ; this . commandInterceptors = commandInterceptors ; } Map < String , CommandProvider > getMap ( ) { return commands ; } @Override public void start ( Environment env ) throws IOException { try { parseCommandLine ( ) ; if ( Strings . isNullOrEmpty ( commandName ) ) { StringWriter msg = new StringWriter ( ) ; msg . write ( usage ( ) ) ; throw die ( msg . toString ( ) ) ; }
} bc . setName ( actualCommandName ) ; bc . setArguments ( args . toArray ( new String [ args . size ( ) ] ) ) ; } else if ( ! args . isEmpty ( ) ) { throw die ( commandName + " does not take arguments" ) ; } for ( SshExecuteCommandInterceptor commandInterceptor : commandInterceptors ) { if ( ! commandInterceptor . accept ( actualCommandName , args ) ) { throw new UnloggedFailure ( 126 , < |startfocus| > String . format ( "blocked by % s , contact gerrit administrators for more details" , commandInterceptor . name ( ) ) ) ; < |endfocus| > } } provideStateTo ( cmd ) ; atomicCmd . set ( cmd ) ; cmd . start ( env ) ; } catch ( UnloggedFailure e ) { String msg = e . getMessage ( ) ; if ( ! msg . endsWith ( "\n" ) ) { msg += "\n" ; } err . write ( msg . getBytes ( ENC ) ) ; err . flush ( ) ; onExit ( e . exitCode ) ; } } private void checkRequiresCapability ( Command cmd ) throws UnloggedFailure { String pluginName = null ; if ( cmd instanceof BaseCommand ) { pluginName = ( ( BaseCommand ) cmd ) . getPluginName ( ) ;
// See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . sshd ; import com . google . gerrit . extensions . annotations . ExtensionPoint ; import java . util . List ; @ExtensionPoint public interface SshExecuteCommandInterceptor { /* * * Check the command and return false if this command must not be run . * * @param command the command * @param arguments the list of arguments < |startfocus| > * @return whether or not this command with these arguments can be executed < |endfocus| > */ boolean accept ( String command , List < String > arguments ) ; default String name ( ) { return this . getClass ( ) . getSimpleName ( ) ; } }
if ( ! getName ( ) . isEmpty ( ) ) { actualCommandName = getName ( ) + " " + commandName ; } bc . setName ( actualCommandName ) ; bc . setArguments ( args . toArray ( new String [ args . size ( ) ] ) ) ; } else if ( ! args . isEmpty ( ) ) { throw die ( commandName + " does not take arguments" ) ; } < |startfocus| > for ( SshExecuteCommandInterceptor filter : commandFilters ) { if ( ! filter . accept ( actualCommandName , args ) ) { throw new UnloggedFailure ( 126 , "blocked by " + filter . name ( ) + " , contact gerrit administrators for more details" ) ; < |endfocus| > } } provideStateTo ( cmd ) ; atomicCmd . set ( cmd ) ; cmd . start ( env ) ; } catch ( UnloggedFailure e ) { String msg = e . getMessage ( ) ; if ( ! msg . endsWith ( "\n" ) ) { msg += "\n" ; } err . write ( msg . getBytes ( ENC ) ) ; err . flush ( ) ; onExit ( e . exitCode ) ; } } private void checkRequiresCapability ( Command cmd ) throws UnloggedFailure { String pluginName = null ; if ( cmd instanceof BaseCommand ) {
// See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . sshd ; import com . google . gerrit . extensions . annotations . ExtensionPoint ; import java . util . List ; @ExtensionPoint public interface SshExecuteCommandInterceptor { /* * * Check the command and return false if this command must not be run . * * @param command the command * @param arguments the list of arguments < |startfocus| > * @return whether or not this command with this arguments can be executed < |endfocus| > */ boolean accept ( String command , List < String > arguments ) ; default String name ( ) { return this . getClass ( ) . getSimpleName ( ) ; } }
RevisionCreatedListener . Event event , Map < String , ImmutableList < Match > > findings ) throws RestApiException { long startNanos = System . nanoTime ( ) ; metrics . reviewCount . increment ( ) ; metrics . reviewCountByProject . increment ( project ) ; try { boolean tpAllowed = scannerConfig . isThirdPartyAllowed ( project ) ; boolean reviewRequired = false ; boolean hasAlwaysReview = false ; for ( Map . Entry < String , ImmutableList < Match > > entry : findings . entrySet ( ) ) { if ( entry . getValue ( ) == ALWAYS_REVIEW ) { reviewRequired = true ; < |startfocus| > hasAlwaysReview = true ; break ; } PartyType pt = partyType ( entry . getValue ( ) ) ; if ( pt . compareTo ( THIRD_PARTY ) > 0 ) { reviewRequired = true ; break ; } if ( pt == THIRD_PARTY && ! tpAllowed ) { reviewRequired = true ; break ; } } ChangeResource change = getChange ( event , scannerConfig . fromAccountId ) ; ReviewInput ri = new ReviewInput ( ) . message ( "Copyright scan" ) . label ( scannerConfig . reviewLabel , reviewRequired ? - 1 : + 2 ) ; if ( reviewRequired ) {
< |startfocus| > public String toString ( ) { return "FlatFile WebSession Cleaner" ; } < |endfocus| >
batchUpdate . addCommand ( new ReceiveCommand ( ref . getObjectId ( ) , ObjectId . zeroId ( ) , refName ) ) ; } batchUpdate . execute ( rw , NullProgressMonitor . INSTANCE ) ; for ( ReceiveCommand command : batchUpdate . getCommands ( ) ) { if ( command . getResult ( ) != ReceiveCommand . Result . OK ) { throw new IOException ( String . format ( "Unstar change % d failed , ref % s could not be deleted : % s" , changeId . get ( ) , command . getRefName ( ) , command . getResult ( ) ) ) ; } } < |startfocus| > indexer . index ( project , changeId ) ; } catch ( IOException e ) { throw new OrmException ( String . format ( "Unstar change % d failed" , changeId . get ( ) ) , e ) ; } } public ImmutableMap < Account . Id , StarRef > byChange ( Change . Id changeId ) throws OrmException { try ( Repository repo = repoManager . openRepository ( allUsers ) ) { ImmutableMap . Builder < Account . Id , StarRef > builder = ImmutableMap . builder ( ) ; for ( String refPart : getRefNames ( repo , RefNames . refsStarredChangesPrefix ( changeId ) ) ) { Integer id = Ints . tryParse ( refPart ) ;
void execute ( PersonIdent refLogIdent , String refLogMessage , PushCertificate pushCert ) { if ( allUsersRepo == null || allUsersRepo . cmds . isEmpty ( ) ) { return ; } // There are operations to be performed asynchronously , so we can't close this early . The async // operation will close the repo . canCloseEarly = false ; @SuppressWarnings ( "unused" ) Future < ? > possiblyIgnoredError = executor . submit ( ( ) - > { < |startfocus| > try { < |endfocus| > allUsersRepo . flush ( ) ; BatchRefUpdate bru = allUsersRepo . repo . getRefDatabase ( ) . newBatchUpdate ( ) ; bru . setPushCertificate ( pushCert ) ; if ( refLogMessage != null ) { bru . setRefLogMessage ( refLogMessage , false ) ; } else { bru . setRefLogMessage ( firstNonNull ( NoteDbUtil . guessRestApiHandler ( ) , "Update NoteDb refs" ) , false ) ; } bru . setRefLogIdent ( refLogIdent != null ? refLogIdent : serverIdent . get ( ) ) ; bru . setAtomic ( true ) ; allUsersRepo . cmds . addTo ( bru ) ; bru . setAllowNonFastForwards ( true ) ; RefUpdateUtil . executeChecked ( bru , allUsersRepo . rw ) ; } finally { allUsersRepo . close ( ) ; } } ) ; }
import com . google . gerrit . server . config . AllProjectsName ; import com . google . gerrit . server . config . AllUsersName ; import com . google . gerrit . server . git . GitRepositoryManager ; import com . google . inject . Inject ; import com . google . inject . Singleton ; /* * * Schema upgrade implementation . * * < p > Implementations must have a single non - private constructor with no arguments ( e . g . the default * constructor ) . */ interface NoteDbSchemaVersion { @Singleton class Arguments { final GitRepositoryManager repoManager ; final AllProjectsName allProjects ; < |startfocus| > final AllUsersName allUsers ; < |endfocus| > @Inject Arguments ( GitRepositoryManager repoManager , AllProjectsName allProjects , AllUsersName allUsers ) { this . repoManager = repoManager ; this . allProjects = allProjects ; this . allUsers = allUsers ; } } void upgrade ( Arguments args , UpdateUI ui ) throws Exception ; }
protected boolean shouldSendMessage ( ) { < |startfocus| > if ( sshKey == null && gpgKeys == null ) { // Don't email if no keys were added . return false ; } < |endfocus| > if ( user . equals ( callingUser ) ) { // Send email if the user self - added a key ; this notification is necessary to alert // the user if their account was compromised and a key was unexpectedly added . return true ; } try { // Don't email if an administrator added a key on behalf of the user . permissionBackend . user ( callingUser ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; return false ; } catch ( AuthException | PermissionBackendException e ) { // Send email if a non - administrator modified the keys , e . g . by MODIFY_ACCOUNT . return true ; }
protected boolean shouldSendMessage ( ) { if ( sshKey == null && gpgKeys == null ) { // Don't email if no keys were added . return false ; } if ( user . equals ( callingUser ) ) { // Send email if the user self - added a key ; this notification is necessary to alert // the user if their account was compromised and a key was unexpectedly added . return true ; } try { // Don't email if an administrator added a key on behalf of the user . permissionBackend . user ( callingUser ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; return false ; } catch ( AuthException | PermissionBackendException e ) { // Send email if a non - administrator modified the keys , e . g . by MODIFY_ACCOUNT . return true ; }
} @Override public Response < ? > apply ( AccountResource . SshKey rsrc , Input input ) throws AuthException , OrmException , RepositoryNotFoundException , IOException , ConfigInvalidException , PermissionBackendException { if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) { permissionBackend . user ( self ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; } IdentifiedUser user = rsrc . getUser ( ) ; authorizedKeys . deleteKey ( user . getAccountId ( ) , rsrc . getSshKey ( ) . getKey ( ) . get ( ) ) ; try { < |startfocus| > deleteKeyFactory . create ( user , "SSH" ) . send ( ) ; < |endfocus| > } catch ( EmailException e ) { log . error ( "Cannot send SSH key deletion message to "" + user . getAccount ( ) . getPreferredEmail ( ) , e ) ; } sshKeyCache . evict ( user . getUserName ( ) ) ; return Response . none ( ) ; } }
if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) { permissionBackend . user ( self ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; } IdentifiedUser user = rsrc . getUser ( ) ; authorizedKeys . deleteKey ( user . getAccountId ( ) , rsrc . getSshKey ( ) . getKey ( ) . get ( ) ) ; try { deleteKeyFactory . create ( rsrc . getUser ( ) , "SSH" ) . send ( ) ; } catch ( EmailException e ) { log . error ( < |startfocus| > "Cannot send SSH key deletion message to { } " , user . getAccount ( ) . getPreferredEmail ( ) , e ) ; < |endfocus| > } sshKeyCache . evict ( user . getUserName ( ) ) ; return Response . none ( ) ; } }
import java . util . List ; import java . util . stream . Collectors ; import java . util . stream . Stream ; import org . eclipse . jgit . lib . BatchRefUpdate ; import org . eclipse . jgit . lib . PersonIdent ; import org . eclipse . jgit . lib . ProgressMonitor ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . RefDatabase ; import org . eclipse . jgit . revwalk . RevWalk ; import org . eclipse . jgit . transport . PushCertificate ; import org . eclipse . jgit . transport . ReceiveCommand ; import org . eclipse . jgit . transport . ReceiveCommand . Result ; import org . eclipse . jgit . util . time . ProposedTimestamp ; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { < |startfocus| > private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; < |endfocus| > private final BatchRefUpdate batchRefUpdate ; private final RefDatabase refDb ; private final SharedRefDatabase < ? extends AutoCloseable > sharedRefDb ; private final String projectName ; public static class RefPair { public final Ref oldRef ; public final Ref newRef ; public final Exception exception ; RefPair ( Ref oldRef , Ref newRef ) { this . oldRef = oldRef ; this . newRef = newRef ; this . exception = null ; }
} @Override public BatchRefUpdate addProposedTimestamp ( ProposedTimestamp ts ) { return batchRefUpdate . addProposedTimestamp ( ts ) ; } @Override public void execute ( RevWalk walk , ProgressMonitor monitor , List < String > options ) throws IOException { executeWrapper ( walk , monitor , options ) ; } @Override public void execute ( RevWalk walk , ProgressMonitor monitor ) throws IOException { executeWrapper ( walk , monitor , Collections . EMPTY_LIST ) ; } @Override public String toString ( ) { return batchRefUpdate . toString ( ) ; } < |startfocus| > private void executeWrapper ( < |endfocus| > RevWalk walk , ProgressMonitor monitor , List < String > options ) throws Exception { Stream < RefPair > oldRefs = batchRefUpdate . getRefs ( ) . stream ( ) . map ( ref - > new RefPair ( ref , getOldRef ( ref ) ) ) ; batchRefUpdate . execute ( walk , monitor , options ) ; updateSharedRefDb ( oldRefs , walk , monitor , options ) ; }
} try ( CloseableSet < AutoCloseable > locks = new CloseableSet ( ) ) { assertBatchCommandsAreInSync ( refsToUpdate , locks ) ; if ( options . isEmpty ( ) ) { batchRefUpdate . execute ( walk , monitor ) ; } else { batchRefUpdate . execute ( walk , monitor , options ) ; } updateSharedDBForSuccessfulCommands ( batchRefUpdate . getCommands ( ) . stream ( ) ) ; } catch ( Exception e ) { < |startfocus| > logger . atWarning ( ) . log ( "Failed to apply full batch % s" , e . getMessage ( ) ) ; < |endfocus| > throw e ; } } private void updateSharedDBForSuccessfulCommands ( Stream < ReceiveCommand > commandStream ) throws IOException { List < RefPair > successfulRefPairs = commandStream . filter ( cmd - > cmd . getResult ( ) == Result . OK ) . map ( cmd - > new RefPair ( cmd . getOldId ( ) == null ? sharedRefDb . NULL_REF : sharedRefDb . newRef ( cmd . getRefName ( ) , cmd . getOldId ( ) ) , sharedRefDb . newRef ( cmd . getRefName ( ) , cmd . getNewId ( ) ) ) ) . collect ( Collectors . toList ( ) ) ; for ( RefPair successfulRefPair : successfulRefPairs ) { < |startfocus| > sharedRefDb . update ( successfulRefPair . oldRef , successfulRefPair . newRef ) ; < |endfocus| > } } private static class RefPair { private final Ref oldRef ; private final Ref newRef ;
logger . atWarning ( ) . log ( "Failed to apply full batch % s" , e . getMessage ( ) ) ; throw e ; } } private void updateSharedDBForSuccessfulCommands ( Stream < ReceiveCommand > commandStream ) throws IOException { List < RefPair > successfulRefPairs = commandStream . filter ( cmd - > cmd . getResult ( ) == Result . OK ) . map ( cmd - > new RefPair ( < |startfocus| > cmd . getOldId ( ) == null ? sharedRefDb . NULL_REF : sharedRefDb . newRef ( cmd . getRefName ( ) , cmd . getOldId ( ) ) , < |endfocus| > sharedRefDb . newRef ( cmd . getRefName ( ) , cmd . getNewId ( ) ) ) ) . collect ( Collectors . toList ( ) ) ; for ( RefPair successfulRefPair : successfulRefPairs ) { sharedRefDb . compareAndPut ( projectName , successfulRefPair . oldRef , successfulRefPair . newRef ) ; } } private void assertBatchCommandsAreInSync ( List < RefPair > refsToUpdate , CloseableSet < AutoCloseable > locks ) throws Exception { for ( RefPair refPair : refsToUpdate ) { Ref nonNullRef = refPair . oldRef == sharedRefDb . NULL_REF || refPair . oldRef == null
} } private void assertBatchCommandsAreInSync ( List < RefPair > refsToUpdate , CloseableSet < AutoCloseable > locks ) throws Exception { for ( RefPair refPair : refsToUpdate ) { Ref nonNullRef = refPair . oldRef == sharedRefDb . NULL_REF || refPair . oldRef == null ? refPair . newRef : refPair . oldRef ; < |startfocus| > // Doesn't have to be the actual Path we lock but just a unique identifier of the ref < |endfocus| > String resourceLockKey = String . format ( " % s - % s" , projectName , nonNullRef . getName ( ) ) ; locks . addResourceIfNotExist ( resourceLockKey , ( ) - > sharedRefDb . lockRef ( projectName , nonNullRef ) ) ; boolean isInSync ; if ( refPair . oldRef != sharedRefDb . NULL_REF && refPair . oldRef != null ) { isInSync = sharedRefDb . isMostRecentRefVersion ( projectName , refPair . oldRef ) ; } else { isInSync = ! sharedRefDb . isPresent ( projectName , refPair . getName ( ) ) ; } if ( ! isInSync ) { String errorMessage = String . format (
Ref nonNullRef = refPair . oldRef == sharedRefDb . NULL_REF || refPair . oldRef == null ? refPair . newRef : refPair . oldRef ; // Doesn't have to be the actual Path we lock but just a unique identifier of the ref String resourceLockKey = String . format ( " % s - % s" , projectName , nonNullRef . getName ( ) ) ; locks . addResourceIfNotExist ( resourceLockKey , ( ) - > sharedRefDb . lockRef ( projectName , nonNullRef ) ) ; < |startfocus| > boolean isInSync ; < |endfocus| > if ( refPair . oldRef != sharedRefDb . NULL_REF && refPair . oldRef != null ) { isInSync = sharedRefDb . isMostRecentRefVersion ( projectName , refPair . oldRef ) ; } else { isInSync = ! sharedRefDb . isPresent ( projectName , refPair . getName ( ) ) ; } if ( ! isInSync ) { String errorMessage = String . format ( "Ref % s not in sync with sharedDb , aborting batch" , refPair . oldRef . getName ( ) ) ; logger . atWarning ( ) . log ( errorMessage ) ; throw new Exception ( errorMessage ) ; } } }
if ( refPair . oldRef != sharedRefDb . NULL_REF && refPair . oldRef != null ) { isInnSync = sharedRefDb . isMostRecentRefVersion ( projectName , refPair . oldRef ) ; } else { isInnSync = ! sharedRefDb . isPresent ( projectName , refPair . getName ( ) ) ; } if ( ! isInnSync ) { String errorMessage = String . format ( "Ref % s not in sync with sharedDb , aborting batch" , refPair . oldRef . getName ( ) ) ; logger . atWarning ( ) . log ( errorMessage ) ; < |startfocus| > throw new RefNotInSyncException ( errorMessage ) ; < |endfocus| > } } } private Stream < RefPair > getRefsPairs ( List < ReceiveCommand > receivedCommands ) { return receivedCommands . stream ( ) . map ( this : : getRefPairForCommand ) ; } private RefPair getRefPairForCommand ( ReceiveCommand command ) { try { switch ( command . getType ( ) ) { case CREATE : return new RefPair ( SharedRefDatabase . NULL_REF , getNewRef ( command ) ) ; case UPDATE : case UPDATE_NONFASTFORWARD : return new RefPair ( refDb . getRef ( command . getRefName ( ) ) , getNewRef ( command ) ) ; case DELETE :
} } catch ( IOException e ) { return new RefPair ( command . getRef ( ) , e ) ; } } private void executeWrapper ( RevWalk walk , ProgressMonitor monitor , List < String > options ) throws IOException { try { updateSharedRefDb ( getRefsPairs ( batchRefUpdate . getCommands ( ) ) , walk , monitor , options ) ; } catch ( Exception e ) { < |startfocus| > String errorMessage = String . format ( "Failing batch executeWrapper in MultiSiteBatchRefUpdate with exception % s" , e . getMessage ( ) ) ; logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; < |endfocus| > throw new IOException ( errorMessage ) ; } } private Ref getNewRef ( ReceiveCommand command ) { return sharedRefDb . newRef ( command . getRefName ( ) , command . getNewId ( ) ) ; } public static class CloseableSet < T extends AutoCloseable > implements AutoCloseable { private final HashMap < String , AutoCloseable > elements ; public CloseableSet ( ) { this ( new HashMap < String , AutoCloseable > ( ) ) ; } public CloseableSet ( HashMap < String , AutoCloseable > elements ) { this . elements = elements ; } public void addResourceIfNotExist (
if ( refUpdateBase . getRef ( ) . getObjectId ( ) == null || refUpdateBase . getRef ( ) . getObjectId ( ) . equals ( ObjectId . zeroId ( ) ) ) { // If we are CREATING a new ref we don't want it to have been written by // any other instance if ( sharedDb . isPresent ( projectName , refUpdateBase . getName ( ) ) ) throw new IOException ( String . format ( < |startfocus| > "Unable to update ref ' % s' , trying to create a new ref but there is a value " < |endfocus| > + "already in the shared ref db" , refUpdateBase . getName ( ) ) ) ; } else { if ( ! sharedDb . isMostRecentRefVersion ( projectName , refUpdateBase . getRef ( ) ) ) throw new IOException ( String . format ( "Unable to update ref ' % s' , the local objectId ' % s' is not equal to the one " + "in the shared ref datasuper" , refUpdateBase . getName ( ) , refUpdateBase . getOldObjectId ( ) ) ) ; } } private void checkSharedDbForRefDelete ( ) throws IOException { Ref oldRef = this . getRef ( ) ; try { < |startfocus| > if ( sharedDb . isPresent ( projectName , oldRef . getName ( ) ) ) { if ( ! sharedDb . isMostRecentRefVersion ( projectName , oldRef ) ) throw new IOException ( String . format ( "Unable to delete ref ' % s' , the local objectId ' % s' is not equal to the one " + "in the shared ref db" , oldRef . getName ( ) , oldRef . getObjectId ( ) ) ) ; } < |endfocus| > } catch ( IOException e ) { throw new IOException ( String . format ( "Unable to delete ref ' % s'" , oldRef . getName ( ) ) , e ) ; } }
*/ boolean compareAndRemove ( String project , Ref oldRef ) throws IOException ; /* * * Some references should not be stored in the SharedRefDatabase . * * @param ref * @return true if it's to be ignore ; false otherwise */ default boolean ignoreRefInSharedDb ( Ref ref ) { String refName = ref . getName ( ) ; return refName == null || refName . startsWith ( "refs / draft - comments" ) || ( refName . startsWith ( "refs / changes" ) && ! refName . endsWith ( " / meta" ) ) ; < |startfocus| > } < |endfocus| > }
public ZkSharedRefDatabase ( CuratorFramework client , @Named ( "ZkLockRetryPolicy" ) RetryPolicy retryPolicy ) { this . client = client ; this . retryPolicy = retryPolicy ; } @Override public boolean compareAndRemove ( String project , Ref oldRef ) throws IOException { return ignoreRefInSharedDb ( oldRef ) || compareAndPut ( project , oldRef , NULL_REF ) ; } @Override public boolean compareAndPut ( String projectName , Ref oldRef , Ref newRef ) throws IOException { < |startfocus| > if ( newRef != NULL_REF && ignoreRefInSharedDb ( newRef ) ) { < |endfocus| > return true ; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue ( client , pathFor ( projectName , oldRef , newRef ) , retryPolicy ) ; try { if ( oldRef == NULL_REF ) { return distributedRefValue . initialize ( writeObjectId ( newRef . getObjectId ( ) ) ) ; } final ObjectId newValue = newRef . getObjectId ( ) == null ? ObjectId . zeroId ( ) : newRef . getObjectId ( ) ; final AtomicValue < byte [ ] > newDistributedValue = distributedRefValue . compareAndSet ( writeObjectId ( oldRef . getObjectId ( ) ) , writeObjectId ( newValue ) ) ; if ( newDistributedValue . succeeded ( ) ) { return true ; } else { if ( newDistributedValue . preValue ( ) == null ) { throw new IOException ( "Failed to compare and set " + oldRef + " to " + newRef + " : " + newDistributedValue . failedReason ( ) ) ; } else { return false ; } } } catch ( Exception e ) { throw new IOException ( "Failed to compare and set " + oldRef + " to " + newRef , e ) ; } } @Override public boolean compareAndPut ( String projectName , Ref oldRef , Ref newRef ) throws IOException { if ( newRef != NULL_REF && ignoreRefInSharedDb ( newRef ) ) { return true ; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue ( client , pathFor ( projectName , oldRef , newRef ) , retryPolicy ) ; try { if ( oldRef == NULL_REF ) { return distributedRefValue . initialize ( writeObjectId ( newRef . getObjectId ( ) ) ) ; } final ObjectId newValue = newRef . getObjectId ( ) == null ? ObjectId . zeroId ( ) : newRef . getObjectId ( ) ; final AtomicValue < byte [ ] > newDistributedValue = distributedRefValue . compareAndSet ( writeObjectId ( oldRef . getObjectId ( ) ) , writeObjectId ( newValue ) ) ; if ( newDistributedValue . succeeded ( ) ) { return true ; } else { if ( newDistributedValue . preValue ( ) == null ) { throw new IOException ( "Failed to compare and set " + oldRef + " to " + newRef + " : " + newDistributedValue . failedReason ( ) ) ; } else { return false ; } } } catch ( Exception e ) { throw new IOException ( "Failed to compare and set " + oldRef + " to " + newRef , e ) ; } } @Override public boolean compareAndPut ( String projectName , Ref oldRef , Ref newRef ) throws IOException { if ( newRef != NULL_REF && ignoreRefInSharedDb ( newRef ) ) { return true ; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue ( client , pathFor ( projectName , oldRef , newRef ) , retryPolicy ) ; try { if ( oldRef == NULL_REF ) { return distributedRefValue . initialize ( writeObjectId ( newRef . getObjectId ( ) ) ) ; } final ObjectId newValue = newRef . getObjectId ( ) == null ? ObjectId . zeroId ( ) : newRef . getObjectId ( ) ; final AtomicValue < byte [ ] > newDistributedValue = distributedRefValue . compareAndSet ( writeObjectId ( oldRef . getObjectId ( ) ) , writeObjectId ( newValue ) ) ; if ( newDistributedValue . succeeded ( ) ) { return true ; } else { if ( newDistributedValue . preValue ( ) == null ) { throw new IOException ( "Failed to compare and set " + oldRef + " to " + newRef + " : " + newDistributedValue . failedReason ( ) ) ; } else { return false ; } } } catch ( Exception e ) { throw new IOException ( "Failed to compare and set " + oldRef + " to " + newRef , e ) ; } } @Override public boolean compareAndPut ( String projectName , Ref oldRef , Ref newRef ) throws IOException { if ( newRef != NULL_REF && ignoreRefInSharedDb ( newRef ) ) { return true ; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue ( client , pathFor ( projectName , oldRef , newRef ) , retryPolicy ) ; try { if ( oldRef == NULL_REF ) { return distributedRefValue . initialize ( writeObjectId ( newRef . getObjectId ( ) ) ) ; } final ObjectId newValue = newRef . getObjectId ( ) == null ? ObjectId . zeroId ( ) : newRef . getObjectId ( ) ; final AtomicValue < byte [ ] > newDistributedValue = distributedRefValue . compareAndSet ( writeObjectId ( oldRef . getObjectId ( ) ) , writeObjectId ( newValue ) ) ; if ( newDistributedValue . succeeded ( ) ) { return true ; } else { if ( newDistributedValue . preValue ( ) == null ) { throw new IOException ( "Failed to compare and set " + oldRef + " to " + newRef + " : " + newDistributedValue . failedReason ( ) ) ; } else { return false ; } } } catch ( Exception e ) { throw new IOException ( "Failed to compare and set " + oldRef + " to " + newRef , e ) ; } } @Override public boolean compareAndPut ( String projectName , Ref oldRef , Ref newRef ) throws IOException { if ( newRef != NULL_REF && ignoreRefInSharedDb ( newRef ) ) { return true ; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue ( client , pathFor ( projectName , oldRef , newRef ) , retryPolicy ) ; try { if ( oldRef == NULL_REF ) { return distributedRefValue . initialize ( writeObjectId ( newRef . getObjectId ( ) ) ) ; } final ObjectId newValue = newRef . getObjectId ( ) == null ? ObjectId . zeroId ( ) : newRef . getObjectId ( ) ; final AtomicValue < byte [ ] > newDistributedValue = distributedRefValue . compareAndSet ( writeObjectId ( oldRef . getObjectId ( ) ) , writeObjectId ( newValue ) ) ; if ( newDistributedValue . succeeded ( ) ) { return true ; } else { if ( newDistributedValue . preValue ( ) == null ) { throw new IOException ( "Failed to compare and set " + oldRef + " to " + newRef + " : " + newDistributedValue . failedReason ( ) ) ; } else { return false ; } } } catch ( Exception e ) { throw new IOException ( "Failed to compare and set " + oldRef + " to " + newRef , e ) ; } } @Override public boolean compareAndPut ( String projectName , Ref oldRef , Ref newRef ) throws IOException { if ( newRef != NULL_REF && ignoreRefInSharedDb ( newRef ) ) { return true ; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue ( client , pathFor ( projectName , oldRef , newRef ) , retryPolicy ) ; try { if ( oldRef == NULL_REF ) { return distributedRefValue . initialize ( writeObjectId ( newRef . getObjectId ( ) ) ) ; } final ObjectId newValue = newRef . getObjectId ( ) == null ? ObjectId . zeroId ( ) : newRef . getObjectId ( ) ; final AtomicValue < byte [ ] > newDistributedValue = distributedRefValue . compareAndSet ( writeObjectId ( oldRef . getObjectId
// When validation of status fails doReturn ( false ) . when ( sharedRefDb ) . isMostRecentRefVersion ( A_TEST_PROJECT_NAME , oldRef ) ; RefUpdate refUpdate = RefFixture . RefUpdateStub . forSuccessfulUpdate ( oldRef , newRef . getObjectId ( ) ) ; MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate ( sharedRefDb , A_TEST_PROJECT_NAME , refUpdate ) ; multiSiteRefUpdate . update ( ) ; } @Test ( expected = Exception . class ) public void newUpdateShouldFailIfSharedDBUpdateFailsLeavingSystemInInconsistentStatus ( ) throws Exception { < |startfocus| > doReturn ( true ) . when ( sharedRefDb ) . isMostRecentRefVersion ( A_TEST_PROJECT_NAME , oldRef ) ; < |endfocus| > // When compareAndPut fails doReturn ( false ) . when ( sharedRefDb ) . compareAndPut ( A_TEST_PROJECT_NAME , oldRef , newRef ) ; RefUpdate refUpdate = RefFixture . RefUpdateStub . forSuccessfulUpdate ( oldRef , newRef . getObjectId ( ) ) ; MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate ( sharedRefDb , A_TEST_PROJECT_NAME , refUpdate ) ; multiSiteRefUpdate . update ( ) ; } @Test public void deleteShouldValidateAndSucceed ( ) throws Exception { // When validation succeeds
// Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb ; import static com . google . common . truth . Truth . assertThat ; import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . zookeeper . RefFixture ; import java . io . IOException ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . Ref . Storage ; import org . junit . Rule ; import org . junit . Test ; import org . junit . rules . TestName ; public class RefSharedDatabaseTest implements RefFixture { @Rule public TestName nameRule = new TestName ( ) ; @Override public String testBranch ( ) { return "branch_" + nameRule . getMethodName ( ) ; } @Test public void shouldCreateANewRef ( ) { ObjectId objectId = AN_OBJECT_ID_1 ;
public void setup ( ) { zookeeperContainer = new ZookeeperTestContainerSupport ( false ) ; zkSharedRefDatabase = < |startfocus| > new ZkSharedRefDatabase ( zookeeperContainer . getCurator ( ) , new RetryNTimes ( 5 , 30 ) ) ; < |endfocus| >
protected boolean shouldSendMessage ( ) { if ( user . equals ( callingUser ) ) { // Send email if the user self - removed a key ; this notification is necessary to alert // the user if their account was compromised and a key was unexpectedly deleted . return true ; } try { < |startfocus| > // Don't email if an administrator removed a password on behalf of the user . < |endfocus| > permissionBackend . user ( callingUser ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; return false ; } catch ( AuthException | PermissionBackendException e ) { // Send email if a non - administrator modified the keys , e . g . by MODIFY_ACCOUNT . return true ; }
if ( extId == null ) { throw new ResourceNotFoundException ( ) ; } ExternalId newExtId = ExternalId . createWithPassword ( extId . key ( ) , extId . accountId ( ) , extId . email ( ) , newPassword ) ; externalIdsUpdate . create ( ) . upsert ( newExtId ) ; try { httpPasswordSenderFactory . create ( user ) . send ( ) ; } catch ( EmailException e ) { log . error ( < |startfocus| > "Cannot send HttpPassword added or changed message to { } " , user . getAccount ( ) . getPreferredEmail ( ) , e ) ; < |endfocus| > } return Strings . isNullOrEmpty ( newPassword ) ? Response . < String > none ( ) : Response . ok ( newPassword ) ; } public static String generate ( ) { byte [ ] rand = new byte [ LEN ] ; rng . nextBytes ( rand ) ; byte [ ] enc = Base64 . encodeBase64 ( rand , false ) ; StringBuilder r = new StringBuilder ( enc . length ) ; for ( int i = 0 ; i < enc . length ; i ++ ) { if ( enc [ i ] == ' = ' ) { break ; } r . append ( ( char ) enc [ i ] ) ; } return r . toString ( ) ; } }
/* * First line of { @link #message } . */ protected String subject ; /* * The complete description of the change the patch set introduces . */ protected String message ; /* * Identity of who wrote the patch set . May differ from { @link #committer } . */ protected UserIdentity author ; /* * Identity of who committed the patch set to the VCS . */ protected UserIdentity committer ; /* * List of parents of the patch set . */ protected List < ParentInfo > parents ; < |startfocus| > /* * SHA - 1 of commit */ < |endfocus| > protected ObjectId commitId ; /* * Optional user - supplied description for the patch set . */ protected String description ; protected PatchSetInfo ( ) { } public PatchSetInfo ( PatchSet . Id k ) { key = k ; } public PatchSet . Id getKey ( ) { return key ; } public String getSubject ( ) { return subject ; } public void setSubject ( String s ) { if ( s != null && s . length ( ) > 255 ) { subject = s . substring ( 0 , 255 ) ; } else { subject = s ; } } public String getMessage ( ) { return message ; } public void setMessage ( String m ) { message = m ; } public UserIdentity getAuthor ( ) { return author ; } public void setAuthor ( UserIdentity a ) { author = a ; } public UserIdentity getCommitter ( ) { return committer ; } public void setCommitter ( UserIdentity c ) { committer = c ; } public List < ParentInfo > getParents ( ) { return parents ; } public void setParents ( List < ParentInfo > p ) { parents = p ; } public ObjectId getCommitId ( ) { return commitId ; } public void setCommitId ( ObjectId c ) { commitId = c ; } public String getDescription ( ) { return description ; } public void setDescription ( String d ) { description = d ; } @Override public String toString ( ) { return new StringBuilder ( "PatchSetInfo { " ) . append ( "key = " ) . append ( key ) . append ( " , subject = " ) . append ( subject ) . append ( " , message = " ) . append ( message ) . append ( " , author = " ) . append ( author ) . append ( " , committer = " ) . append ( committer ) . append ( " , parents = " ) . append ( parents ) . append ( " , commitId = " ) . append ( commitId ) . append ( " , description = " ) . append ( description ) . append ( " } " ) . toString ( ) ; } }
public String message ; public String parentUuid ; public Range range ; public String tag ; // Hex commit SHA1 of the commit of the patchset to which this comment applies . Other classes call // this "commitId" , but this class uses the old ReviewDb term "revId" , and this field name is // serialized into JSON in NoteDb , so it can't easily be changed . Callers do not access this field < |startfocus| > // directly , and instead use the public getter / setter that wraps in an ObjectId . < |endfocus| > private String revId ; public String serverId ; public boolean unresolved ; /* * * Whether the comment was parsed from a JSON representation ( false ) or the legacy custom notes * format ( true ) . */ public transient boolean legacyFormat ; public Comment ( Comment c ) { this ( new Key ( c . key ) , c . author . getId ( ) , new Timestamp ( c . writtenOn . getTime ( ) ) , c . side , c . message , c . serverId , c . unresolved ) ; this . lineNbr = c . lineNbr ; this . realAuthor = c . realAuthor ; public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side ; this . message = message ; this . serverId = serverId ; this . unresolved = unresolved ; } public Comment ( Key key , Account . Id author , Timestamp writtenOn , short side , String message , String serverId , boolean unresolved ) { this . key = key ; this . author = author ; this . writtenOn = writtenOn ; this . side = side
Copyright ( C ) 2018 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . reviewdb . converter ; import com . google . gerrit . proto . Entities ; import com . google . protobuf . Parser ; import org . eclipse . jgit . lib . ObjectId ; /* * * Proto converter for { @code ObjectId } s . * * < p > This converter uses the hex representation of object IDs embedded in a wrapper proto type , * rather than a more parsimonious implementation ( e . g . a raw byte array ) , for two reasons : * * < ul >
// Copyright ( C ) 2018 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . reviewdb . converter ; import static com . google . common . truth . Truth . assertThat ; import static com . google . gerrit . proto . testing . SerializedClassSubject . assertThatSerializedClass ; import com . google . common . collect . ImmutableMap ; import com . google . gerrit . proto . Entities ; import com . google . gerrit . proto . testing . SerializedClassSubject ; import com . google . protobuf . Parser ; import org . eclipse . jgit . lib . ObjectId ; import org . junit . Test ; public class ObjectIdProtoConverterTest {
public static String abbreviateName ( AnyObjectId id ) { < |startfocus| > return abbreviateName ( id , ABBREVIATED_STRING_LENGTH ) ; < |endfocus| >
/* * * Abbreviate an ID's hex string representation to 7 chars . * * @param id object ID . * @return abbreviated hex string representation , exactly 7 chars . */ public static String abbreviateName ( AnyObjectId id ) { return abbreviateName ( id , 7 ) ; } /* * * Abbreviate an ID's hex string representation to { @code n } chars . * * @param id object ID . < |startfocus| > * @param n number of hex chars . < |endfocus| > * @return abbreviated hex string representation , exactly { @code n } chars . */ public static String abbreviateName ( AnyObjectId id , int n ) { checkValidLength ( n ) ; return requireNonNull ( id ) . abbreviate ( n ) . name ( ) ; } /* * * Abbreviate an ID's hex string representation uniquely to at least 7 chars . * * @param id object ID . * @param reader object reader for determining uniqueness . * @return abbreviated hex string representation , unique according to { @code reader } at least 7 * chars . */
*/ public static String abbreviateName ( AnyObjectId id , int n ) { checkValidLength ( n ) ; return requireNonNull ( id ) . abbreviate ( n ) . name ( ) ; } /* * * Abbreviate an ID's hex string representation uniquely to at least 7 chars . * * @param id object ID . * @param reader object reader for determining uniqueness . * @return abbreviated hex string representation , unique according to { @code reader } at least 7 < |startfocus| > * chars . < |endfocus| > */ public static String abbreviateName ( AnyObjectId id , ObjectReader reader ) throws IOException { return abbreviateName ( id , ABBREVIATED_STRING_LENGTH , reader ) ; } /* * * Abbreviate an ID's hex string representation uniquely to at least { @code n } chars . * * @param id object ID . * @param n minimum number of hex chars . * @param reader object reader for determining uniqueness . * @return abbreviated hex string representation , unique according to { @code reader } at least * { @code } chars . */
* @param reader object reader for determining uniqueness . * @return abbreviated hex string representation , unique according to { @code reader } at least 7 * chars . */ public static String abbreviateName ( AnyObjectId id , ObjectReader reader ) throws IOException { return abbreviateName ( id , ABBREVIATED_STRING_LENGTH , reader ) ; } /* * * Abbreviate an ID's hex string representation uniquely to at least { @code n } chars . * * @param id object ID . < |startfocus| > * @param n minimum number of hex chars . < |endfocus| > * @param reader object reader for determining uniqueness . * @return abbreviated hex string representation , unique according to { @code reader } at least * { @code } chars . */ public static String abbreviateName ( AnyObjectId id , int n , ObjectReader reader ) throws IOException { checkValidLength ( n ) ; return reader . abbreviate ( id , n ) . name ( ) ; } private static void checkValidLength ( int n ) { checkArgument ( n > 0 ) ; checkArgument ( n <= Constants . OBJECT_ID_STRING_LENGTH ) ; } private ObjectIds ( ) { }
return abbreviateName ( id , ABBREVIATED_STRING_LENGTH , reader ) ; } /* * * Abbreviate an ID's hex string representation uniquely to at least { @code n } chars . * * @param id object ID . * @param n minimum number of hex chars . * @param reader object reader for determining uniqueness . * @return abbreviated hex string representation , unique according to { @code reader } at least < |startfocus| > * { @code } chars . < |endfocus| > */ public static String abbreviateName ( AnyObjectId id , int n , ObjectReader reader ) throws IOException { checkValidLength ( n ) ; return reader . abbreviate ( id , n ) . name ( ) ; } private static void checkValidLength ( int n ) { checkArgument ( n > 0 ) ; checkArgument ( n <= Constants . OBJECT_ID_STRING_LENGTH ) ; } private ObjectIds ( ) { } }
private static String implicitMergeOf ( ObjectId commit ) { < |startfocus| > return abbreviateName ( commit , 7 ) ; < |endfocus| >
} @FunctionalInterface private interface Func { void call ( ) throws Exception ; } private static void assertRuntimeException ( Func func ) throws Exception { try { func . call ( ) ; assert_ ( ) . fail ( "Expected RuntimeException" ) ; } catch ( RuntimeException e ) { // Expected . } } private static ObjectReader newReaderWithAmbiguousIds ( ) throws Exception { < |startfocus| > // Recipe for creating ambiguous IDs courtesy of t1512 - rev - parse - disambiguation . sh in git core . < |endfocus| > TestRepository < ? > tr = new TestRepository < > ( new InMemoryRepository ( new DfsRepositoryDescription ( "repo" ) ) ) ; String blobData = "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\nb1rwzyc3\n" ; RevBlob blob = tr . blob ( blobData ) ; assertThat ( blob . name ( ) ) . isEqualTo ( AMBIGUOUS_BLOB_ID . name ( ) ) ; assertThat ( tr . tree ( tr . file ( "a0blgqsjc" , blob ) ) . name ( ) ) . isEqualTo ( AMBIGUOUS_TREE_ID . name ( ) ) ; return tr . getRevWalk ( ) . getObjectReader ( ) ; } }
private static String implicitMergeOf ( ObjectId commit ) { < |startfocus| > return "implicit merge of " + abbreviateName ( commit ) ; < |endfocus| >
import com . googlesource . gerrit . plugins . lfs . LfsConfigurationFactory ; import java . io . IOException ; import java . nio . file . Files ; import java . nio . file . Path ; import java . nio . file . Paths ; @Singleton public class LfsFsDataDirectoryManager { private static final String KEY_DIRECTORY = "directory" ; private final LfsConfigurationFactory configFactory ; private final Path defaultDataDir ; @Inject LfsFsDataDirectoryManager ( LfsConfigurationFactory configFactory , @PluginData Path defaultDataDir ) { this . configFactory = configFactory ; this . defaultDataDir = defaultDataDir ; } < |startfocus| > < |endfocus| > public Path getForBackend ( LfsBackend backend , boolean ensure ) throws IOException { String dataDir = configFactory . getGlobalConfig ( ) . getString ( backend . type . name ( ) , backend . name , KEY_DIRECTORY ) ; if ( Strings . isNullOrEmpty ( dataDir ) ) { return defaultDataDir ; } if ( ensure ) { // note that the following method not only creates missing // directory / directories but throws exception when path // exists and points to file Path ensured = Files . createDirectories ( Paths . get ( dataDir . toString ( ) ) ) ; return ensured ; } return Paths . get ( dataDir . toString ( ) ) ; } }
} public Path getForBackend ( LfsBackend backend , boolean ensure ) throws IOException { String dataDir = configFactory . getGlobalConfig ( ) . getString ( backend . type . name ( ) , backend . name , KEY_DIRECTORY ) ; if ( Strings . isNullOrEmpty ( dataDir ) ) { return defaultDataDir ; } if ( ensure ) { // note that the following method not only creates missing // directory / directories but throws exception when path // exists and points to file < |startfocus| > Path ensured = Files . createDirectories ( Paths . get ( dataDir ) ) ; < |endfocus| > // we should at least make sure that directory is readable if ( ! Files . isReadable ( ensured ) ) { throw new IOException ( "Path '" + ensured . toAbsolutePath ( ) + "' cannot be accessed" ) ; } return ensured ; } return Paths . get ( dataDir ) ; } }
Integer id = Ints . tryParse ( email . substring ( 0 , at ) ) ; if ( id != null ) { return Optional . of ( Account . id ( id ) ) ; } } } return Optional . empty ( ) ; } public static String formatTime ( PersonIdent ident , Timestamp t ) { GitDateFormatter dateFormatter = new GitDateFormatter ( Format . DEFAULT ) ; // TODO ( dborowitz ) : Use a ThreadLocal or use Joda . PersonIdent newIdent = new PersonIdent ( ident , t ) ; return dateFormatter . formatDate ( newIdent ) ; } < |startfocus| > /* * Returns the name of */ < |endfocus| > static String guessRestApiHandler ( ) { StackTraceElement [ ] trace = Thread . currentThread ( ) . getStackTrace ( ) ; int i = findRestApiServlet ( trace ) ; if ( i < 0 ) { return null ; } try { for ( i -- ; i >= 0 ; i -- ) { String cn = trace [ i ] . getClassName ( ) ; Class < ? > cls = Class . forName ( cn ) ; if ( RestModifyView . class . isAssignableFrom ( cls ) && cls != RetryingRestModifyView . class ) { return viewName ( cn ) ; } } return null ; }
Future < ? > possiblyIgnoredError = executor . submit ( ( ) - > { try ( OpenRepo allUsersRepo = OpenRepo . open ( repoManager , allUsersName ) ) { allUsersRepo . addUpdates ( draftUpdates ) ; allUsersRepo . flush ( ) ; BatchRefUpdate bru = allUsersRepo . repo . getRefDatabase ( ) . newBatchUpdate ( ) ; bru . setPushCertificate ( pushCert ) ; if ( refLogMessage != null ) { bru . setRefLogMessage ( refLogMessage , false ) ; } else { bru . setRefLogMessage ( < |startfocus| > "Delete draft comments" , false ) ; < |endfocus| > } bru . setRefLogIdent ( refLogIdent != null ? refLogIdent : serverIdent . get ( ) ) ; bru . setAtomic ( true ) ; allUsersRepo . cmds . addTo ( bru ) ; bru . setAllowNonFastForwards ( true ) ; RefUpdateUtil . executeChecked ( bru , allUsersRepo . rw ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Failed to delete draft comments asynchronously after publishing them" ) ; } } ) ;
< |startfocus| > public void markCommentPublished ( Comment c ) { < |endfocus| > verifyComment ( c ) ; delete . put ( key ( c ) , DeleteReason . PUBLISHED ) ;
private void addCommands ( ) throws IOException { changeRepo . addUpdates ( changeUpdates , Optional . of ( maxUpdates ) ) ; if ( ! draftUpdates . isEmpty ( ) ) { < |startfocus| > boolean publishOnly = draftUpdates . values ( ) . stream ( ) . allMatch ( ChangeDraftUpdate : : isPublishOnly ) ; < |endfocus| > if ( publishOnly ) { updateAllUsersAsync . setDraftUpdates ( draftUpdates ) ; } else { allUsersRepo . addUpdates ( draftUpdates ) ; } } if ( ! robotCommentUpdates . isEmpty ( ) ) { changeRepo . addUpdates ( robotCommentUpdates ) ; } if ( ! rewriters . isEmpty ( ) ) { addRewrites ( rewriters , changeRepo ) ; } for ( Change . Id id : toDelete ) { doDelete ( id ) ; }
// See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . mail . send ; import com . google . gerrit . common . errors . EmailException ; import com . google . gerrit . extensions . api . changes . RecipientType ; import com . google . gerrit . server . IdentifiedUser ; import com . google . gerrit . server . mail . Address ; import com . google . inject . assistedinject . Assisted ; import com . google . inject . assistedinject . AssistedInject ; public class HttpPasswordUpdateSender extends OutgoingEmail { public interface Factory { HttpPasswordUpdateSender create ( IdentifiedUser user ) ; } < |startfocus| > private final IdentifiedUser user ; < |endfocus| > @AssistedInject public HttpPasswordUpdateSender ( EmailArguments ea , @Assisted IdentifiedUser user ) { super ( ea , "HttpPasswordUpdate" ) ; this . user = user ; } @Override protected void init ( ) throws EmailException { super . init ( ) ; setHeader ( "Subject" , " [ Gerrit Code Review ] HTTP password was either added , changed or deleted" ) ; add ( RecipientType . TO , new Address ( getEmail ( ) ) ) ; } @Override protected boolean shouldSendMessage ( ) {
// See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . extensions . api . config ; import com . google . gerrit . extensions . client . DiffPreferencesInfo ; import com . google . gerrit . extensions . client . EditPreferencesInfo ; import com . google . gerrit . extensions . client . GeneralPreferencesInfo ; import com . google . gerrit . extensions . common . ServerInfo ; import com . google . gerrit . extensions . restapi . NotImplementedException ; import com . google . gerrit . extensions . restapi . RestApiException ; import com . google . gerrit . extensions . webui . TopMenu ; < |startfocus| > import com . google . gerrit . extensions . webui . TopMenu . MenuEntry ; < |endfocus| > import java . util . List ; public interface Server { /* * @return Version of server . */ String getVersion ( ) throws RestApiException ; ServerInfo getInfo ( ) throws RestApiException ; GeneralPreferencesInfo getDefaultPreferences ( ) throws RestApiException ; GeneralPreferencesInfo setDefaultPreferences ( GeneralPreferencesInfo in ) throws RestApiException ; DiffPreferencesInfo getDefaultDiffPreferences ( ) throws RestApiException ; DiffPreferencesInfo setDefaultDiffPreferences ( DiffPreferencesInfo in ) throws RestApiException ; EditPreferencesInfo getDefaultEditPreferences ( ) throws RestApiException ; EditPreferencesInfo setDefaultEditPreferences ( EditPreferencesInfo in ) throws RestApiException ;
throws RestApiException { throw new NotImplementedException ( ) ; } @Override public EditPreferencesInfo getDefaultEditPreferences ( ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override public EditPreferencesInfo setDefaultEditPreferences ( EditPreferencesInfo in ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override public ConsistencyCheckInfo checkConsistency ( ConsistencyCheckInput in ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override < |startfocus| > public List < TopMenu . MenuEntry > topMenus ( ) throws RestApiException { < |endfocus| > throw new NotImplementedException ( ) ; } } }
ChangeCheckerImpl . Factory changeCheckerFactory ) { super ( configuration . index ( ) . numStripedLocks ( ) ) ; this . indexer = indexer ; this . indexExecutor = indexExecutor ; this . oneOffCtx = oneOffCtx ; this . changeCheckerFactory = changeCheckerFactory ; Index indexConfig = configuration . index ( ) ; this . retryInterval = indexConfig != null ? indexConfig . retryInterval ( ) : 0 ; this . maxTries = indexConfig != null ? indexConfig . maxTries ( ) : 0 ; } @Override < |startfocus| > protected void doIndex ( String id , Optional < ChangeIndexEvent > indexEvent ) { < |endfocus| > doIndex ( id , indexEvent , 0 ) ; } private void doIndex ( String id , Optional < ChangeIndexEvent > indexEvent , int retryCount ) { try { ChangeChecker checker = changeCheckerFactory . create ( id ) ; Optional < ChangeNotes > changeNotes = checker . getChangeNotes ( ) ; if ( changeNotes . isPresent ( ) ) { ChangeNotes notes = changeNotes . get ( ) ; reindex ( notes ) ; if ( checker . isChangeUpToDate ( indexEvent ) ) { if ( retryCount > 0 ) {
ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . setColumns ( colsProto . toBuilder ( ) . setTopic ( "topic" ) . setHasTopic ( true ) ) . build ( ) ) ; } @Test public void serializeOriginalSubject ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . columns ( cols . toBuilder ( ) . originalSubject ( "The first patch set" ) . build ( ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . setColumns ( < |startfocus| > colsProto . toBuilder ( ) < |endfocus| > . setOriginalSubject ( "The first patch set" ) . setHasOriginalSubject ( true ) ) . build ( ) ) ; } @Test public void serializeSubmissionId ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . columns ( cols . toBuilder ( ) . submissionId ( "xyz" ) . build ( ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . setColumns ( colsProto . toBuilder ( ) . setSubmissionId ( "xyz" ) . setHasSubmissionId ( true ) ) . build ( ) ) ; } @Test public void serializeAssignee ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . columns ( cols . toBuilder ( ) . assignee ( accountId ) . build ( ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . setColumns ( colsProto . toBuilder ( ) . setAssignee ( accountId . get ( ) ) . setHasAssignee ( true ) ) . build ( ) ) ; } @Test public void serializeHashtags ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . columns ( cols . toBuilder ( ) . hashtags ( ImmutableSet . of ( "foo" , "bar" ) ) . build ( ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . setColumns ( colsProto . toBuilder ( ) . addAllHashtags ( "foo" , "bar" ) . setHasHashtags ( true ) ) . build ( ) ) ; } @Test public void serializePrivate ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . columns ( cols . toBuilder ( ) . isPrivate ( true ) . build ( ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . setColumns ( colsProto . toBuilder ( ) . setIsPrivate ( true ) . setHasIsPrivate ( true ) ) . build ( ) ) ; } @Test public void serializeWorkInProgress ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . columns ( cols . toBuilder ( ) . workInProgress ( true ) . build ( ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . setColumns ( colsProto . toBuilder ( ) . setWorkInProgress ( true ) . setHasWorkInProgress ( true ) ) . build ( ) ) ; } @Test public void serializeReviewStarted ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . columns ( cols . toBuilder ( ) . reviewStarted ( true ) . build ( ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . setColumns ( colsProto . toBuilder ( ) . setReviewStarted ( true ) . setHasReviewStarted ( true ) ) . build ( ) ) ; } @Test public void serializeReviewedBy ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . columns ( cols . toBuilder ( ) . reviewedBy ( ImmutableSet . of ( accountId ) ) . build ( ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . setColumns ( colsProto . toBuilder ( ) . addAllReviewedBy ( accountId . get ( ) ) . setHasReviewedBy ( true ) ) . build ( ) ) ; } @Test public void serializeReviewedOn ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . columns ( cols . toBuilder ( ) . reviewedOn ( ImmutableSet . of ( ts ) ) . build ( ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . setColumns ( colsProto . toBuilder ( ) . addAllReviewedOn ( ts . getTime ( ) ) . setHasReviewedOn ( true ) ) . build ( ) ) ; } @Test public void serializeStar ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . columns ( cols . toBuilder ( ) . star ( ImmutableSet . of ( accountId ) ) . build ( ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . setColumns ( colsProto . toBuilder ( ) . addAllStar ( accountId . get ( ) ) . setHasStar ( true ) ) . build ( ) ) ; } @Test public void serializeStarredOn ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . columns ( cols . toBuilder ( ) . starredOn ( ImmutableSet . of ( ts ) ) . build ( ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . setColumns ( colsProto . toBuilder ( ) . addAllStarredOn ( ts . getTime ( ) ) . setHasStarredOn ( true ) ) . build ( ) ) ; } @Test public void serializeDraftBy ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . columns ( cols . toBuilder ( ) . draftBy ( ImmutableSet . of ( accountId ) ) . build ( ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . setColumns ( colsProto . toBuilder ( ) . addAllDraftBy ( accountId . get ( ) ) . setHasDraftBy ( true ) ) . build ( ) ) ; } @Test public void serializeDraftOn ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . columns ( cols . toBuilder ( ) . draftOn ( ImmutableSet . of ( ts ) ) . build ( ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . setColumns ( colsProto . toBuilder ( ) . addAllDraftOn ( ts . getTime ( ) ) . setHasDraftOn ( true ) ) . build ( ) ) ; } @Test public void serializePatchSets ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . patchSets ( ImmutableList . of ( ps1 , ps2 ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . addAllPatchSets ( ImmutableList . of ( ps1Proto , ps2Proto ) ) . build ( ) ) ; } @Test public void serializeComments ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . comments ( ImmutableList . of ( c1 , c2 ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . addAllComments ( ImmutableList . of ( c1Proto , c2Proto ) ) . build ( ) ) ; } @Test public void serializeChangeMessages ( ) throws Exception { assertRoundTrip ( newBuilder ( ) . changeMessages ( ImmutableList . of ( cm1 , cm2 ) ) . build ( ) , ChangeNotesStateProto . newBuilder ( ) . setMetaId ( SHA_BYTES ) . setChangeId ( ID . get ( ) ) . addAllChangeMessages ( ImmutableList . of ( cm1Proto , cm2Proto ) ) . build ( ) ) ; } @Test public void serializePendingReview
public void onProjectDeleted ( Event event ) { String projectName = event . getProjectName ( ) ; logger . atInfo ( ) . log ( "Deleting project ' % s' . Will perform a cleanup in Shared - Ref database . " , projectName ) ; try { sharedDb . removeProject ( projectName ) ; } catch ( IOException e ) { // TODO : Add metrics for monitoring if it fails to delete < |startfocus| > logger . atSevere ( ) . log ( < |endfocus| > String . format ( "Project ' % s' deleted from GIT but it was not able to fully cleanup" + " from Shared - Ref database" , projectName ) , e ) ; }
} public void addChange ( String id , Map < Change . Id , ChangeResource > changes ) throws UnloggedFailure , OrmException , PermissionBackendException , IOException { addChange ( id , changes , null ) ; } public void addChange ( String id , Map < Change . Id , ChangeResource > changes , ProjectState projectState ) throws UnloggedFailure , OrmException , PermissionBackendException , IOException { addChange ( id , changes , projectState , true ) ; } public void addChange ( String id , Map < Change . Id , ChangeResource > changes , < |startfocus| > ProjectState projectState , < |endfocus| > boolean useIndex ) throws UnloggedFailure , OrmException , PermissionBackendException , IOException { List < ChangeNotes > matched = useIndex ? changeFinder . find ( id ) : changeFromNotesFactory ( id ) ; List < ChangeNotes > toAdd = new ArrayList < > ( changes . size ( ) ) ; boolean canMaintainServer ; try { permissionBackend . currentUser ( ) . check ( GlobalPermission . MAINTAIN_SERVER ) ; canMaintainServer = true ; } catch ( AuthException | PermissionBackendException e ) { canMaintainServer = false ; } for ( ChangeNotes notes : matched ) { if ( ! changes . containsKey ( notes . getChangeId ( ) ) ) { toAdd . add ( notes ) ; } } if ( toAdd . isEmpty ( ) ) { return ; } if ( projectState == null ) { projectState = projectCache . checkedGet ( toAdd . get ( 0 ) . getProjectName ( ) ) ; } if ( projectState == null ) { throw new UnloggedFailure ( 1 , "project not found : " + toAdd . get ( 0 ) . getProjectName ( ) ) ; } if ( ! canMaintainServer && ! projectState . statePermitsRead ( ) ) { throw new UnloggedFailure ( 1 , "project state does not permit read : " + projectState . getName ( ) ) ; } for ( ChangeNotes notes : toAdd ) { ChangeResource rsrc = changes . get ( notes . getChangeId ( ) ) ; if ( rsrc == null ) { rsrc = new ChangeResource ( notes ) ; } rsrc . setProject ( projectState ) ; rsrc . setUser ( userProvider . get ( ) ) ; rsrc . setChangeData ( changeDataFactory . create ( notes ) ) ; rsrc . setCommit ( commitProvider . get ( ) ) ; rsrc . setPatchSet ( patchSetProvider . get ( ) ) ; rsrc . setRevision ( revisionProvider . get ( ) ) ; rsrc . setMergeable ( mergeableProvider . get ( ) ) ; rsrc . setReviewedBy ( reviewedByProvider . get ( ) ) ; rsrc . setChangeKind ( changeKindCache . getChangeKind ( rsrc . getChange ( ) , rsrc . getPatchSet ( ) ) ) ; rsrc . setSubmitRecord ( submitRecordCache . get ( rsrc . getNotes ( ) ) ) ; rsrc . setSubmitter ( submitterByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setChangeMessage ( changeMessageByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setReviewedBy ( reviewedByProvider . get ( ) ) ; rsrc . setChangeKind ( changeKindCache . getChangeKind ( rsrc . getChange ( ) , rsrc . getPatchSet ( ) ) ) ; rsrc . setSubmitRecord ( submitRecordCache . get ( rsrc . getNotes ( ) ) ) ; rsrc . setSubmitter ( submitterByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setChangeMessage ( changeMessageByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setReviewedBy ( reviewedByProvider . get ( ) ) ; rsrc . setChangeKind ( changeKindCache . getChangeKind ( rsrc . getChange ( ) , rsrc . getPatchSet ( ) ) ) ; rsrc . setSubmitRecord ( submitRecordCache . get ( rsrc . getNotes ( ) ) ) ; rsrc . setSubmitter ( submitterByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setChangeMessage ( changeMessageByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setReviewedBy ( reviewedByProvider . get ( ) ) ; rsrc . setChangeKind ( changeKindCache . getChangeKind ( rsrc . getChange ( ) , rsrc . getPatchSet ( ) ) ) ; rsrc . setSubmitRecord ( submitRecordCache . get ( rsrc . getNotes ( ) ) ) ; rsrc . setSubmitter ( submitterByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setChangeMessage ( changeMessageByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setReviewedBy ( reviewedByProvider . get ( ) ) ; rsrc . setChangeKind ( changeKindCache . getChangeKind ( rsrc . getChange ( ) , rsrc . getPatchSet ( ) ) ) ; rsrc . setSubmitRecord ( submitRecordCache . get ( rsrc . getNotes ( ) ) ) ; rsrc . setSubmitter ( submitterByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setChangeMessage ( changeMessageByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setReviewedBy ( reviewedByProvider . get ( ) ) ; rsrc . setChangeKind ( changeKindCache . getChangeKind ( rsrc . getChange ( ) , rsrc . getPatchSet ( ) ) ) ; rsrc . setSubmitRecord ( submitRecordCache . get ( rsrc . getNotes ( ) ) ) ; rsrc . setSubmitter ( submitterByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setChangeMessage ( changeMessageByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setReviewedBy ( reviewedByProvider . get ( ) ) ; rsrc . setChangeKind ( changeKindCache . getChangeKind ( rsrc . getChange ( ) , rsrc . getPatchSet ( ) ) ) ; rsrc . setSubmitRecord ( submitRecordCache . get ( rsrc . getNotes ( ) ) ) ; rsrc . setSubmitter ( submitterByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setChangeMessage ( changeMessageByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setReviewedBy ( reviewedByProvider . get ( ) ) ; rsrc . setChangeKind ( changeKindCache . getChangeKind ( rsrc . getChange ( ) , rsrc . getPatchSet ( ) ) ) ; rsrc . setSubmitRecord ( submitRecordCache . get ( rsrc . getNotes ( ) ) ) ; rsrc . setSubmitter ( submitterByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setChangeMessage ( changeMessageByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setReviewedBy ( reviewedByProvider . get ( ) ) ; rsrc . setChangeKind ( changeKindCache . getChangeKind ( rsrc . getChange ( ) , rsrc . getPatchSet ( ) ) ) ; rsrc . setSubmitRecord ( submitRecordCache . get ( rsrc . getNotes ( ) ) ) ; rsrc . setSubmitter ( submitterByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setChangeMessage ( changeMessageByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setReviewedBy ( reviewedByProvider . get ( ) ) ; rsrc . setChangeKind ( changeKindCache . getChangeKind ( rsrc . getChange ( ) , rsrc . getPatchSet ( ) ) ) ; rsrc . setSubmitRecord ( submitRecordCache . get ( rsrc . getNotes ( ) ) ) ; rsrc . setSubmitter ( submitterByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setChangeMessage ( changeMessageByPatchSet . get ( rsrc . getPatchSet ( ) . id ( ) ) ) ; rsrc . setReviewedBy ( reviewedByProvider . get ( ) ) ; rsrc . setChangeKind ( changeKindCache . getChangeKind ( rsrc . getChange ( ) , rsrc . getPatchSet ( ) ) ) ; rsrc . setSubmitRecord ( submitRecordCache . get ( rsrc . getNotes ( ) ) ) ; rsrc . setSubmitter ( submitterByPatchSet . get ( rsrc . getPatch
import java . io . IOException ; import java . util . concurrent . ExecutionException ; import java . util . concurrent . TimeUnit ; /* * * Cache of { @link CombinedCheckState } per change . * * < p > In the absence of plugin - defined index fields , this cache is used to performantly populate the * { @code combinedState } field in { @code ChangeCheckInfo } in the query path . */ @Singleton public class CombinedCheckStateCache { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; < |startfocus| > private static final String NAME = "combined_check_state" ; < |endfocus| > public static Module module ( ) { return new CacheModule ( ) { @Override public void configure ( ) { persist ( NAME , CombinedCheckStateCacheKeyProto . class , CombinedCheckState . class ) . version ( 1 ) . maximumWeight ( 10000 ) . diskLimit ( - 1 ) . keySerializer ( new ProtobufSerializer < > ( CombinedCheckStateCacheKeyProto . parser ( ) ) ) . valueSerializer ( new EnumCacheSerializer < > ( CombinedCheckState . class ) ) . loader ( Loader . class ) ; } } ; } @Singleton static class Metrics {
// Pair of metric and manual counters , to work around the fact that metric classes have no // getters . private final Timer1 < Boolean > reloadLatency ; private final AtomicLongMap < Boolean > reloadCount ; @Inject Metrics ( MetricMaker metricMaker ) { reloadLatency = metricMaker . newTimer ( "checks / reload_combined_check_state" , new Description ( "Latency for reloading combined check state" ) . setCumulative ( ) . setUnit ( Units . MILLISECONDS ) , < |startfocus| > Field . ofBoolean ( "updated" , "whether reloading resulted in updating the cached value" ) ) ; < |endfocus| > reloadCount = AtomicLongMap . create ( ) ; } void recordReload ( boolean updated , long elapsed , TimeUnit timeUnit ) { reloadLatency . record ( updated , elapsed , timeUnit ) ; reloadCount . incrementAndGet ( updated ) ; } long getReloadCount ( boolean updated ) { return reloadCount . get ( updated ) ; } } private final LoadingCache < CombinedCheckStateCacheKeyProto , CombinedCheckState > cache ; private final Loader loader ; private final Metrics metrics ; @Inject CombinedCheckStateCache ( @Named ( NAME ) LoadingCache < CombinedCheckStateCacheKeyProto , CombinedCheckState > cache , Loader loader ,
< |startfocus| > void recordReload ( boolean dirty , Duration elapsed ) { reloadLatency . record ( dirty , elapsed . toNanos ( ) , TimeUnit . NANOSECONDS ) ; reloadCount . incrementAndGet ( dirty ) ; < |endfocus| >
CombinedCheckState newState = loader . load ( key ) ; CombinedCheckState oldState = cache . getIfPresent ( key ) ; if ( newState != oldState ) { dirty = true ; cache . put ( key , newState ) ; } else { dirty = false ; } return newState ; } finally { < |startfocus| > boolean dirty = true ; try { metrics . recordReload ( dirty , sw . elapsed ( NANOSECONDS ) , NANOSECONDS ) ; } catch ( Exception e ) { // Exception while loading value , so we don't know if it's dirty . Record a metric anyway , // arbitrarily assuming dirty . } < |endfocus| > } } /* * * Update the state in the cache only if it changed . * * < p > This method does a cache lookup followed by a write , which is inherently racy . * Inconsistencies between the cache and the actual state should tend to get fixed up immediately * after a user views the change , since the read path calls { @link #reload ( Project . NameKey , * PatchSet . Id ) } . * * @param project project containing the change .
assertThat ( cache . getStats ( ) ) . since ( start ) . hasHitCount ( 1 ) ; assertThat ( cache . getStats ( ) ) . since ( start ) . hasMissCount ( 0 ) ; assertThat ( cache . getReloadCount ( false ) - startReloadsFalse ) . isEqualTo ( 0 ) ; assertThat ( cache . getReloadCount ( true ) - startReloadsTrue ) . isEqualTo ( 0 ) ; // Set non - required checker to FAILED , updating combined check state to WARNING . < |startfocus| > checkOperations . newCheck ( CheckKey . create ( project , psId , checkerUuid ) ) . state ( CheckState . FAILED ) . upsert ( ) ; < |endfocus| > // Incurs reload after updating check state . assertThat ( cache . getStats ( ) ) . since ( start ) . hasHitCount ( 2 ) ; assertThat ( cache . getStats ( ) ) . since ( start ) . hasMissCount ( 0 ) ; assertThat ( cache . getReloadCount ( false ) - startReloadsFalse ) . isEqualTo ( 0 ) ; assertThat ( cache . getReloadCount ( true ) - startReloadsTrue ) . isEqualTo ( 1 ) ; assertThat ( queryChangeCheckInfo ( changeId ) ) . hasValue ( new ChangeCheckInfo ( "checks" , CombinedCheckState . WARNING ) ) ; assertThat ( cache . getStats ( ) ) . since ( start ) . hasHitCount ( 3 ) ; assertThat ( cache . getStats ( ) ) . since ( start ) . hasMissCount ( 0 ) ; assertThat ( cache . getReloadCount ( false ) - startReloadsFalse ) . isEqualTo ( 0 ) ; assertThat ( cache . getReloadCount ( true ) - startReloadsTrue ) . isEqualTo ( 1 ) ;
import org . easymock . EasyMock ; import org . junit . Test ; public class ChecksSubmitRuleTest extends GerritBaseTests { @Test public void loadingCurrentPatchSetFails ( ) throws Exception { ChecksSubmitRule checksSubmitRule = new ChecksSubmitRule ( EasyMock . createStrictMock ( CombinedCheckStateCache . class ) ) ; ChangeData cd = EasyMock . createStrictMock ( ChangeData . class ) ; < |startfocus| > expect ( cd . project ( ) ) . andReturn ( new Project . NameKey ( "My - Project" ) ) ; expect ( cd . getId ( ) ) . andReturn ( new Change . Id ( 1 ) ) ; expect ( cd . currentPatchSet ( ) ) . andThrow ( new OrmException ( "Fail for test" ) ) ; < |endfocus| > replay ( cd ) ; Collection < SubmitRecord > submitRecords = checksSubmitRule . evaluate ( cd , SubmitRuleOptions . defaults ( ) ) ; assertErrorRecord ( submitRecords , "failed to load the current patch set of change 1" ) ; } @Test public void getCombinedCheckStateFails ( ) throws Exception { CombinedCheckStateCache cache = EasyMock . createStrictMock ( CombinedCheckStateCache . class ) ; expect ( cache . reload ( anyObject ( ) , anyObject ( ) ) ) . andThrow ( new OrmException ( "Fail for test" ) ) ; replay ( cache ) ; ChecksSubmitRule checksSubmitRule = new ChecksSubmitRule ( cache ) ;
// Copyright ( C ) 2014 The Android Open Source Project // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . events ; import com . google . gson . Gson ; import com . google . gson . TypeAdapter ; import com . google . gson . TypeAdapterFactory ; import com . google . gson . reflect . TypeToken ; public final class AutoValueAdapterFactory implements TypeAdapterFactory { @SuppressWarnings ( "unchecked" ) @Override public < T > TypeAdapter < T > create ( Gson gson , TypeToken < T > type ) { Class < ? super T > rawType = type . getRawType ( ) ;
< |startfocus| > Copyright ( C ) 2014 The Android Open Source Project < |endfocus| > // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . events ; import com . google . common . base . Supplier ; import com . google . gson . Gson ; import com . google . gson . GsonBuilder ; import com . google . inject . Provider ; public class GsonEventDeserializerProvider implements Provider < Gson > { @Override public Gson get ( ) { return new GsonBuilder ( ) . registerTypeAdapter ( Event . class , new EventDeserializer ( ) ) . registerTypeAdapter ( Supplier . class , new SupplierSerializer ( ) ) . registerTypeAdapter ( Supplier . class , new SupplierDeserializer ( ) ) . registerTypeAdapter ( Supplier . class , new SupplierDeserializer ( ) )
< |startfocus| > private Change newChange ( ) { < |endfocus| > Change change = new Change ( Change . key ( "Iabcd1234" ) , Change . id ( 1000 ) , Account . id ( 1000 ) , Branch . nameKey ( Project . nameKey ( "myproject" ) , "mybranch" ) , new Timestamp ( System . currentTimeMillis ( ) ) ) ; return change ;
public void refUpdatedEvent ( ) { RefUpdatedEvent event = new RefUpdatedEvent ( ) ; RefUpdateAttribute refUpdatedAttribute = new RefUpdateAttribute ( ) ; refUpdatedAttribute . refName = "refs / heads / master" ; event . refUpdate = createSupplier ( refUpdatedAttribute ) ; < |startfocus| > AccountAttribute accountAttribute = new AccountAttribute ( ) ; accountAttribute . email = "some . user@domain . com" ; event . submitter = createSupplier ( accountAttribute ) ; < |endfocus| > assertThatJsonMap ( event ) . containsExactly ( "submitter" , ImmutableMap . of ( "email" , "some . user@domain . com" ) , "refUpdate" , ImmutableMap . of ( "refName" , "refs / heads / master" ) , "type" , "ref - updated" , "eventCreatedOn" , 1 . 2543444E9 ) ; }
* @return combined state . */ public static CombinedCheckState combine ( ImmutableListMultimap < CheckState , Boolean > statesAndRequired ) { CheckStateCount checkStateCount = CheckStateCount . create ( statesAndRequired ) ; return combine ( checkStateCount ) ; } /* * * Combines multiple per - check states into a single combined state based on the count result of * each check state . * * < p > See documentation of specific enum values for precise semantics . * < |startfocus| > * @param checkStateCount count of < |endfocus| > * @return combined state . */ private static CombinedCheckState combine ( CheckStateCount checkStateCount ) { if ( checkStateCount . failedRequiredCount ( ) > 0 ) { return FAILED ; } if ( checkStateCount . inProgressOptionalCount ( ) > 0 || checkStateCount . inProgressRequiredCount ( ) > 0 ) { return IN_PROGRESS ; } if ( checkStateCount . failedOptionalCount ( ) > 0 ) { return WARNING ; } if ( checkStateCount . successfulCount ( ) > 0 ) { return SUCCESSFUL ; } return NOT_RELEVANT ; } private final boolean passing ; private CombinedCheckState ( boolean passing ) { this . passing = passing ; } /* * * Returns whether this combined state is passing . * * < p > A passing state is one that is either successful or not relevant . */ public boolean isPassing ( ) { return passing ; } /* * * Returns whether this combined state is failing . * * < p > A failing state is one that is either failed or in progress . */ public boolean isFailing ( ) { return ! passing ; } /* * * Returns whether this combined state is successful . */ public boolean isSuccessful ( ) { return this == SUCCESSFUL ; } /* * * Returns whether this combined state is failed . */ public boolean isFailed ( ) { return this == FAILED ; } /* * * Returns whether this combined state is in progress . */ public boolean isInProgress ( ) { return this == IN_PROGRESS ; } /* * * Returns whether this combined state is not relevant . */ public boolean isNotRelevant ( ) { return this == NOT_RELEVANT ; } /* * * Returns whether this combined state is warning . */ public boolean isWarning ( ) { return this == WARNING ; } }
* @return whether the state represents a passing state . */ public boolean isPassing ( ) { return passing ; } @AutoValue public abstract static class CheckStateCount { /* * * Get the count of each { @link CheckState } . * * @param statesAndRequired map of state to a list of booleans , one per check , indicating * whether that particular check is required in the context of a particular change . < |startfocus| > * @return the { @link CheckState } of the given state map . < |endfocus| > */ public static CheckStateCount create ( ImmutableListMultimap < CheckState , Boolean > statesAndRequired ) { int failedRequiredCount = 0 ; int failedOptionalCount = 0 ; int inProgressRequiredCount = 0 ; int inProgressOptionalCount = 0 ; int successfulCount = 0 ; for ( Map . Entry < CheckState , Boolean > e : statesAndRequired . entries ( ) ) { CheckState state = e . getKey ( ) ; if ( state . isInProgress ( ) ) { if ( e . getValue ( ) ) { inProgressRequiredCount ++ ; } else { inProgressOptionalCount ++ ; } } else if ( state . isPassing ( ) ) { successfulCount ++ ; } else { if ( e . getValue ( ) ) { failedRequiredCount ++ ; } else { failedOptionalCount ++ ; } } } return new AutoValue_CheckStateCount ( failedRequiredCount , failedOptionalCount , inProgressRequiredCount , inProgressOptionalCount , successfulCount ) ; } /* * * Get the count of failed required checks . * * @return the count of failed required checks . */ public abstract int failedRequiredCount ( ) ; /* * * Get the count of failed optional checks . * * @return the count of failed optional checks . */ public abstract int failedOptionalCount ( ) ; /* * * Get the count of in - progress required checks . * * @return the count of in - progress required checks . */ public abstract int inProgressRequiredCount ( ) ; /* * * Get the count of in - progress optional checks . * * @return the count of in - progress optional checks . */ public abstract int inProgressOptionalCount ( ) ; /* * * Get the count of successful checks . * * @return the count of successful checks . */ public abstract int successfulCount ( ) ; }
* whether that particular check is required in the context of a particular change . * @return the { @link CheckState } of the given state map . */ public static CheckStateCount create ( ImmutableListMultimap < CheckState , Boolean > statesAndRequired ) { int failedRequiredCount = 0 ; int failedOptionalCount = 0 ; int inProgressRequiredCount = 0 ; int inProgressOptionalCount = 0 ; int successfulCount = 0 ; < |startfocus| > for ( Map . Entry < CheckState , Boolean > entry : statesAndRequired . entries ( ) ) { CheckState state = entry . getKey ( ) ; < |endfocus| > if ( state . isInProgress ( ) ) { if ( entry . getValue ( ) ) { inProgressRequiredCount ++ ; } else { inProgressOptionalCount ++ ; } } else if ( state == CheckState . FAILED ) { if ( entry . getValue ( ) ) { failedRequiredCount ++ ; } else { failedOptionalCount ++ ; } } else if ( state == CheckState . SUCCESSFUL ) { successfulCount ++ ; } else if ( state != CheckState . NOT_RELEVANT ) {
public Collection < SubmitRecord > evaluate ( ChangeData changeData , SubmitRuleOptions options ) { Project . NameKey project = changeData . project ( ) ; Change . Id changeId = changeData . getId ( ) ; < |startfocus| > // Gets all check results of the given change . ImmutableMap < String , CheckInfo > checks ; < |endfocus| > try { checks = listChecks . getAllChecks ( project , changeData . notes ( ) , changeData . currentPatchSet ( ) . getId ( ) ) . stream ( ) . collect ( ImmutableMap . toImmutableMap ( c - > c . checkerUuid , c - > c ) ) ; } catch ( OrmException | IOException e ) { String errorMessage = String . format ( "failed to get all checks for change % s" , changeId ) ; logger . atSevere ( ) . withCause ( e ) . log ( errorMessage ) ; return singletonRecordForRuleError ( errorMessage ) ; } // Gets all checkers applicable to the given change . ImmutableMap < String , Checker > appliedCheckers ; try { appliedCheckers = checkers . checkersOf ( project ) . stream ( ) . collect ( ImmutableMap . toImmutableMap ( c - > c . getUuid ( ) . toString ( ) , c - > c ) ) ; } catch ( IOException e ) { String errorMessage = String . format ( "failed to get all checkers for change % s" , changeId ) ; logger . atSevere ( ) . withCause ( e ) . log ( errorMessage ) ; return singletonRecordForRuleError ( errorMessage ) ; } // Gets all required checkers . ImmutableSet < String > requiredCheckers = appliedCheckers . values ( ) . stream ( ) . filter ( c - > c . isRequired ( ) ) . map ( c - > c . getUuid ( ) . toString ( ) ) . collect ( toImmutableSet ( ) ) ; // Gets all required check results . ImmutableMap < String , CheckInfo > requiredChecks = checks . entrySet ( ) . stream ( ) . filter ( e - > requiredCheckers . contains ( e . getKey ( ) ) ) . collect ( toImmutableMap ( Entry : : getKey , Entry : : getValue ) ) ; // Gets all required check results that are not passing . ImmutableMap < String , CheckInfo > failingRequiredChecks = requiredChecks . entrySet ( ) . stream ( ) . filter ( e - > ! e . getValue ( ) . isOk ( ) ) . collect ( toImmutableMap ( Entry : : getKey , Entry : : getValue ) ) ; // Gets all required checkers that are not passing . ImmutableSet < String > failingRequiredCheckers = failingRequiredChecks . keySet ( ) ; // Gets all required checkers that are passing . ImmutableSet < String > passingRequiredCheckers = requiredCheckers . stream ( ) . filter ( c - > ! failingRequiredCheckers . contains ( c ) ) . collect ( toImmutableSet ( ) ) ; // Gets all required checkers that are not applied . ImmutableSet < String > missingRequiredCheckers = requiredCheckers . stream ( ) . filter ( c - > ! checks . containsKey ( c ) ) . collect ( toImmutableSet ( ) ) ; // Gets all required checkers that are not passing and not applied . ImmutableSet < String > failingAndMissingRequiredCheckers = Sets . union ( failingRequiredCheckers . keySet ( ) , missingRequiredCheckers ) ; // Gets all required checkers that are passing and applied . ImmutableSet < String > passingAndAppliedRequiredCheckers = Sets . intersection ( passingRequiredCheckers , checks . keySet ( ) ) ; // Gets all required checkers that are passing and not applied . ImmutableSet < String > passingAndMissingRequiredCheckers = Sets . intersection ( passingRequiredCheckers , missingRequiredCheckers ) ; // Gets all required checkers that are not passing and applied . ImmutableSet < String > failingAndAppliedRequiredCheckers = Sets . intersection ( failingRequiredCheckers . keySet ( ) , checks . keySet ( ) ) ; // Gets all required checkers that are not passing and not applied . ImmutableSet < String > failingAndMissingRequiredCheckers = Sets . intersection ( failingRequiredCheckers . keySet ( ) , missingRequiredCheckers ) ; // Gets all required checkers that are passing and applied . ImmutableSet < String > passingAndAppliedRequiredCheckers = Sets . intersection ( passingRequiredCheckers , checks . keySet ( ) ) ; // Gets all required checkers that are passing and not applied . ImmutableSet < String > passingAndMissingRequiredCheckers = Sets . intersection ( passingRequiredCheckers , missingRequiredCheckers ) ; // Gets all required checkers that are not passing and applied . ImmutableSet < String > failingAndAppliedRequiredCheckers = Sets . intersection ( failingRequiredCheckers . keySet ( ) , checks . keySet ( ) ) ; // Gets all required checkers that are not passing and not applied . ImmutableSet < String > failingAndMissingRequiredCheckers = Sets . intersection ( failingRequiredCheckers . keySet ( ) , missingRequiredCheckers ) ; // Gets all required checkers that are passing and applied . ImmutableSet < String > passingAndAppliedRequiredCheckers = Sets . intersection ( passingRequiredCheckers , checks . keySet ( ) ) ; // Gets all required checkers that are passing and not applied . ImmutableSet < String > passingAndMissingRequiredCheckers = Sets . intersection ( passingRequiredCheckers , missingRequiredCheckers ) ; // Gets all required checkers that are not passing and applied . ImmutableSet < String > failingAndAppliedRequiredCheckers = Sets . intersection ( failingRequiredCheckers . keySet ( ) , checks . keySet ( ) ) ; // Gets all required checkers that are not passing and not applied . ImmutableSet < String > failingAndMissingRequiredCheckers = Sets . intersection ( failingRequiredCheckers . keySet ( ) , missingRequiredCheckers ) ; // Gets all required checkers that are passing and applied . ImmutableSet < String > passingAndAppliedRequiredCheckers = Sets . intersection ( passingRequiredCheckers , checks . keySet ( ) ) ; // Gets all required checkers that are passing and not applied . ImmutableSet < String > passingAndMissingRequiredCheckers = Sets . intersection ( passingRequiredCheckers , missingRequiredCheckers ) ; // Gets all required checkers that are not passing and applied . ImmutableSet < String > failingAndAppliedRequiredCheckers = Sets . intersection ( failingRequiredCheckers . keySet ( ) , checks . keySet ( ) ) ; // Gets all required checkers that are not passing and not applied . ImmutableSet < String > failingAndMissingRequiredCheckers = Sets . intersection ( failingRequiredCheckers . keySet ( ) , missingRequiredCheckers ) ; // Gets all required checkers that are passing and applied . ImmutableSet < String > passingAndAppliedRequiredCheckers = Sets . intersection ( passingRequiredCheckers , checks . keySet ( ) ) ; // Gets all required checkers that are passing and not applied . ImmutableSet < String > passingAndMissingRequiredCheckers = Sets . intersection ( passingRequiredCheckers , missingRequiredCheckers ) ; // Gets all required checkers that are not passing and applied . ImmutableSet < String > failingAndAppliedRequiredCheckers = Sets . intersection ( failingRequiredCheckers . keySet ( ) , checks . keySet ( ) ) ; // Gets all required checkers that are not passing and not applied . ImmutableSet < String > failingAndMissingRequiredCheckers = Sets . intersection ( failingRequiredCheckers . keySet ( ) , missingRequiredCheckers ) ; // Gets all required checkers that are passing and applied . ImmutableSet < String > passingAndAppliedRequiredCheckers = Sets . intersection ( passingRequiredCheckers , checks . keySet ( ) ) ; // Gets all required checkers that are passing and not applied . ImmutableSet < String > passingAndMissingRequiredCheckers = Sets . intersection ( passingRequiredCheckers , missingRequiredCheckers ) ; // Gets all required checkers that are not passing and applied . ImmutableSet < String > failingAndAppliedRequiredCheckers = Sets . intersection ( failingRequiredCheckers . keySet ( ) , checks . keySet ( ) ) ; // Gets all required checkers that are not passing and not applied . ImmutableSet < String > failingAndMissingRequiredCheckers = Sets . intersection ( failingRequiredCheckers . keySet ( ) , missingRequiredCheckers ) ; // Gets all required checkers that are passing and applied . ImmutableSet < String > passingAndAppliedRequiredCheckers = Sets
* * @param projectName project to be enforced * @param refName ref name to be enforced * @return the { @link EnforcePolicy } value */ public EnforcePolicy getPolicy ( String projectName , String refName ) ; /* * * Get the enforcement policy for a project * * @param projectName * @return the { @link EnforcePolicy } value */ public EnforcePolicy getPolicy ( String projectName ) ; < |startfocus| > default boolean ignoreRefInSharedDb ( String refName ) { < |endfocus| > return refName == null || refName . startsWith ( "refs / draft - comments" ) || ( refName . startsWith ( "refs / changes" ) && ! refName . endsWith ( " / meta" ) ) ; } }
Module sitePathModule = new AbstractModule ( ) { @Override protected void configure ( ) { bind ( Path . class ) . annotatedWith ( SitePath . class ) . toInstance ( sitePath ) ; } } ; modules . add ( sitePathModule ) ; Module configModule = new GerritServerConfigModule ( ) ; modules . add ( configModule ) ; } else { modules . add ( new GerritServerConfigModule ( ) ) ; } modules . add ( new DropWizardMetricMaker . ApiModule ( ) ) ; return Guice . createInjector ( < |startfocus| > PRODUCTION , ModuleOverloader . override ( modules , LibModuleLoader . loadModules ( cfgInjector , LibModuleType . SYS_MODULE ) ) ) ; < |endfocus| >
// You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server ; < |startfocus| > /* * Loadable module type for the different Gerrit injectors . */ < |endfocus| > public enum LibModuleType { /* * Module for the sysInjector . */ SYS_MODULE ( "Module" ) , /* * Module for the dbInjector . */ DB_MODULE ( "DbModule" ) ; private final String configKey ; LibModuleType ( String configKey ) { this . configKey = configKey ; } /* * * Returns the module type for loading from gerrit . config . * * @return module type string */ public String getConfigKey ( ) { return configKey ; } }
// limitations under the License . package com . google . gerrit . server ; /* * Loadable module type for the different Gerrit daemon injectors . */ public enum LibModuleType { /* * Module for the sysInjector . */ SYS_MODULE ( "Module" ) , /* * Module for the dbInjector . */ DB_MODULE ( "DbModule" ) ; private final String configKey ; LibModuleType ( String configKey ) { this . configKey = configKey ; } /* * < |startfocus| > * Returns the module type for loading from gerrit . config . < |endfocus| > * * @return module type string */ public String getConfigKey ( ) { return configKey ; } }
* an infinite forwarding loop between the 2 nodes . It will also make sure no concurrent indexing is * done for the same account id */ @Singleton public class ForwardedIndexAccountHandler extends ForwardedIndexingHandler < Account . Id > { private final AccountIndexer indexer ; @Inject ForwardedIndexAccountHandler ( AccountIndexer indexer , Configuration config ) { super ( config . index ( ) ) ; this . indexer = indexer ; } @Override < |startfocus| > protected void doIndex ( Account . Id id , Optional < IndexEvent > indexEvent ) throws IOException { < |endfocus| > indexer . index ( id ) ; log . atFine ( ) . log ( "Account % s successfully indexed" , id ) ; } @Override protected void doDelete ( Account . Id id , Optional < IndexEvent > indexEvent ) { throw new UnsupportedOperationException ( "Delete from account index not supported" ) ; } }
import com . google . gerrit . testing . TestTimeUtil ; import com . google . gson . Gson ; import com . google . gson . GsonBuilder ; import com . google . gson . reflect . TypeToken ; import java . util . Map ; import java . util . concurrent . TimeUnit ; import org . junit . Before ; import org . junit . Test ; public class EventJsonTest extends GerritBaseTests { private static final String BRANCH = "mybranch" ; private static final String CHANGE_ID = "Ideadbeefdeadbeefdeadbeefdeadbeefdeadbeef" ; private static final int CHANGE_NUM = 1000 ; < |startfocus| > private static final double CHANGE_NUM_DOUBLE = CHANGE_NUM ; < |endfocus| > private static final String COMMIT_MESSAGE = "This is a test commit message" ; private static final String PROJECT = "myproject" ; private static final String REF = "refs / heads / " + BRANCH ; private static final double TS1 = 1 . 2543444E9 ; private static final double TS2 = 1 . 254344401E9 ; private static final String URL = "http :/ / somewhere . com" ; // Must match StreamEvents#gson . ( In master , the definition is refactored to be hared . ) private final Gson gson = new GsonBuilder ( )
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb ; import com . google . common . base . MoreObjects ; import com . google . common . collect . ImmutableMap ; import com . google . common . flogger . FluentLogger ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; public class CustomSharedRefEnforcementByProject implements SharedRefEnforcement { < |startfocus| > private static final String ALL = " .* " ; < |endfocus| > private final Map < String , Map < String , EnforcePolicy > > PREDEF_ENFORCEMENTS ; private final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; public CustomSharedRefEnforcementByProject ( List < String > enforcementRules ) { logger . atInfo ( ) . log ( String . format ( "Running with Custom Shared Ref - Db Enforcement Policy with follosing rules % s" , enforcementRules . toString ( ) ) ) ; this . PREDEF_ENFORCEMENTS = parseDryRunEnforcementsToMap ( enforcementRules ) ; } private Map < String , Map < String , EnforcePolicy > > parseDryRunEnforcementsToMap ( List < String > dryRunRefEnforcement ) {
assert ( refAndPolicy . length == 2 ) ; String refName = refAndPolicy [ 0 ] . trim ( ) . isEmpty ( ) ? ALL : refAndPolicy [ 0 ] . trim ( ) ; Map < String , EnforcePolicy > existingOrDefaultRef = projectAndRefsEnforcements . getOrDefault ( projectName , new HashMap < > ( ) ) ; existingOrDefaultRef . put ( refName , EnforcePolicy . valueOf ( refAndPolicy [ 1 ] . trim ( ) . toUpperCase ( ) ) ) ; < |startfocus| > projectAndRefsEnforcements . put ( projectName , existingOrDefaultRef ) ; } } catch ( AssertionError e ) { throw e ; } return projectAndRefsEnforcements ; } @Override public EnforcePolicy getPolicy ( String projectName , String refName ) { if ( isRefToBeIgnoredBySharedRefDb ( refName ) ) { return EnforcePolicy . IGNORED ; } return getRefEnforcePolicy ( projectName , refName ) ; } private EnforcePolicy getRefEnforcePolicy ( String projectName , String refName ) { if ( ! PREDEF_ENFORCEMENTS . containsKey ( projectName ) && PREDEF_ENFORCEMENTS . containsKey ( ALL ) ) { return PREDEF_ENFORCEMENTS . get ( ALL ) . getOrDefault ( refName , EnforcePolicy . REQUIRED ) ; } EnforcePolicy policyFromProjectRefOrProjectAllRefs =
private EnforcePolicy getRefEnforcePolicy ( String projectName , String refName ) { if ( ! PREDEF_ENFORCEMENTS . containsKey ( projectName ) && PREDEF_ENFORCEMENTS . containsKey ( ALL ) ) { return PREDEF_ENFORCEMENTS . get ( ALL ) . getOrDefault ( refName , EnforcePolicy . REQUIRED ) ; } EnforcePolicy policyFromProjectRefOrProjectAllRefs = < |startfocus| > PREDEF_ENFORCEMENTS . get ( projectName ) . get ( refName ) == null ? PREDEF_ENFORCEMENTS . get ( projectName ) . get ( ALL ) : PREDEF_ENFORCEMENTS . get ( projectName ) . get ( refName ) ; < |endfocus| > return MoreObjects . firstNonNull ( policyFromProjectRefOrProjectAllRefs , EnforcePolicy . REQUIRED ) ;
private EnforcePolicy getRefEnforcePolicy ( String projectName , String refName ) { if ( ! PREDEF_ENFORCEMENTS . containsKey ( projectName ) && PREDEF_ENFORCEMENTS . containsKey ( ALL ) ) { return PREDEF_ENFORCEMENTS . get ( ALL ) . getOrDefault ( refName , EnforcePolicy . REQUIRED ) ; } EnforcePolicy policyFromProjectRefOrProjectAllRefs = < |startfocus| > Optional . ofNullable ( PREDEF_ENFORCEMENTS . get ( projectName ) . get ( refName ) ) . orElse ( PREDEF_ENFORCEMENTS . get ( projectName ) . get ( ALL ) ) ; < |endfocus| > return MoreObjects . firstNonNull ( policyFromProjectRefOrProjectAllRefs , EnforcePolicy . REQUIRED ) ;
* @throws IOException */ default boolean compareAndCreate ( String project , Ref newRef ) throws IOException { return compareAndPut ( project , NULL_REF , newRef ) ; } /* * * Verify in shared db if Ref is the most recent * * @param project project name of the ref * @param ref to be checked against shared - ref db * @return true if it is ; false otherwise */ < |startfocus| > boolean isMostRecentRefVersion ( String project , Ref ref ) throws IOException ; < |endfocus| > /* * * Compare a reference , and put if it matches . * * < p > Two reference match if and only if they satisfy the following : * * < ul > * < li > If one reference is a symbolic ref , the other one should be a symbolic ref . * < li > If both are symbolic refs , the target names should be same . * < li > If both are object ID refs , the object IDs should be same . * </ ul > * * @param project project name of the ref * @param oldRef old ref to be compared against * @param newRef new ref to be compared against * @return true if the newRef is the most recent version ; false otherwise */ boolean compareAndPut ( String project , Ref oldRef , Ref newRef ) throws IOException ; /* * * Compare a reference , and put if it matches . * * < p > Two reference match if and only if they satisfy the following : * * < ul > * < li > If one reference is a symbolic ref , the other one should be a symbolic ref . * < li > If both are symbolic refs , the target names should be same . * < li > If both are object ID refs , the object IDs should be same . * </ ul > * * @param project project name of the ref * @param newRef new ref to be compared against * @return true if the newRef is the most recent version ; false otherwise */ default boolean compareAndCreate ( String project , Ref newRef ) throws IOException { return compareAndPut ( project , NULL_REF , newRef ) ; } /* * * Verify in shared db if Ref is the most recent * * @param project project name of the ref * @param ref to be checked against shared - ref db * @return true if it is ; false otherwise */ boolean isMostRecentRefVersion ( String project , Ref ref ) throws IOException ; /* * * Compare a reference , and put if it matches . * * < p > Two reference match if and only if they satisfy the following : * * < ul > * < li > If one reference is a symbolic ref , the other one should be a symbolic ref . * < li > If both are symbolic refs , the target names should be same . * < li > If both are object ID refs , the object IDs should be same . * </ ul > * * @param project project name of the ref * @param oldRef old ref to be compared against * @param newRef new ref to be compared against * @return true if the newRef is the most recent version ; false otherwise */ boolean compareAndPut ( String project , Ref oldRef , Ref newRef ) throws IOException ; /* * * Compare a reference , and put if it matches . * * < p > Two reference match if and only if they satisfy the following : * * < ul > * < li > If one reference is a symbolic ref , the other one should be a symbolic ref . * < li > If both are symbolic refs , the target names should be same . * < li > If both are object ID refs , the object IDs should be same . * </ ul > * * @param project project name of the ref * @param newRef new ref to be compared against * @return true if the newRef is the most recent version ; false otherwise */ default boolean compareAndCreate ( String project , Ref newRef ) throws IOException { return compareAndPut ( project , NULL_REF , newRef ) ; } /* * * Verify in shared db if Ref is the most recent * * @param project project name of the ref * @param ref to be checked against shared - ref db * @return true if it is ; false otherwise */ boolean isMostRecentRefVersion ( String project , Ref ref ) throws IOException ; /* * * Compare a reference , and put if it matches . * * < p > Two reference match if and only if they satisfy the following : * * < ul > * < li > If one reference is a symbolic ref , the other one should be a symbolic ref . * < li > If both are symbolic refs , the target names should be same . * < li > If both are object ID refs , the object IDs should be same . * </ ul > * * @param project project name of the ref * @param oldRef old ref to be compared against * @param newRef new ref to be compared against * @return true if the newRef is the most recent version ; false otherwise */ boolean compareAndPut ( String project , Ref oldRef , Ref newRef ) throws IOException ; /* * * Compare a reference , and put if it matches . * * < p > Two reference match if and only if they satisfy the following : * * < ul > * < li > If one reference is a symbolic ref , the other one should be a symbolic ref . * < li > If both are symbolic refs , the target names should be same . * < li > If both are object ID refs , the object IDs should be same . * </ ul > * * @param project project name of the ref * @param newRef new ref to be compared against * @return true if the newRef is the most recent version ; false otherwise */ default boolean compareAndCreate ( String project , Ref newRef ) throws IOException { return compareAndPut ( project , NULL_REF , newRef ) ; } /* * * Verify in shared db if Ref is the most recent * * @param project project name of the ref * @param ref to be checked against shared - ref db * @return true if it is ; false otherwise */ boolean isMostRecentRefVersion ( String project , Ref ref ) throws IOException ; /* * * Compare a reference , and put if it matches . * * < p > Two reference match if and only if they satisfy the following : * * < ul > * < li > If one reference is a symbolic ref , the other one should be a symbolic ref . * < li > If both are symbolic refs , the target names should be same . * < li > If both are object ID refs , the object IDs should be same . * </ ul > * * @param project project name of the ref * @param oldRef old ref to be compared against * @param newRef new ref to be compared against * @return true if the newRef is the most recent version ; false otherwise */ boolean compareAndPut ( String project , Ref oldRef , Ref newRef ) throws IOException ; /* * * Compare a reference , and put if it matches . * * < p > Two reference match if and only if they satisfy the following : * * < ul > * < li > If one reference is a symbolic ref , the other one should be a symbolic ref . * < li > If both are symbolic refs , the target names should be same . * < li > If both are object ID refs , the object IDs should be same . * </ ul > * * @param project project name of the ref * @param newRef new ref to be compared against * @return true if the newRef is the most recent version ; false otherwise */ default boolean compareAndCreate ( String project , Ref newRef ) throws IOException { return compareAndPut ( project , NULL_REF , newRef ) ; } /* * * Verify in shared db if Ref is the most recent * * @param project project name of the ref * @param ref to be checked against shared - ref db * @return true if it is ; false otherwise */ boolean isMostRecentRefVersion ( String project , Ref ref ) throws IOException ; /* * * Compare a reference , and put if it matches . * * < p > Two reference match if and only if they satisfy the following : * * < ul > * < li > If one reference is a symbolic ref , the other one should be a symbolic ref . * < li > If both are symbolic refs , the target names should be same . * < li > If both are object ID refs , the object IDs should be same . * </ ul > * * @param project project name of the ref * @param oldRef old ref to be compared against * @param newRef new ref to be compared against * @return true if the
/* * * Compare a reference , and delete if it matches . * * @param project project name of the ref * @param oldRef the old reference information that was previously read . * @return true if the remove was successful ; false otherwise . * @throws java . io . IOException the reference could not be removed due to a system error . */ boolean compareAndRemove ( String project , Ref oldRef ) throws IOException ; < |startfocus| > /* * * Lock the ref in the database . * * @param projectName the name of the project * @param ref the ref to lock * @return a lock object that must be closed to release the lock . * @throws java . io . IOException the lock could not be acquired due to a system error . */ AutoCloseable lockRef ( String projectName , Ref ref ) throws IOException ; < |endfocus| > /* * * Some references should not be stored in the SharedRefDatabase . * * @param refName * @return true if it's to be ignore ; false otherwise */ default boolean ignoreRefInSharedDb ( String refName ) { return refName == null || refName . startsWith ( "refs / draft - comments" ) || ( refName . startsWith ( "refs / changes" ) && ! refName . endsWith ( " / meta" ) ) ; } /* * * Verify if the DB contains a value for the specific project and ref name *
/* * * Compare a reference , and delete if it matches . * * @param project project name of the ref * @param oldRef the old reference information that was previously read . * @return true if the remove was successful ; false otherwise . * @throws java . io . IOException the reference could not be removed due to a system error . */ boolean compareAndRemove ( String project , Ref oldRef ) throws IOException ; < |startfocus| > AutoCloseable lockRef ( String project , Ref ref ) throws IOException ; < |endfocus| > /* * * Some references should not be stored in the SharedRefDatabase . * * @param refName * @return true if it's to be ignore ; false otherwise */ default boolean ignoreRefInSharedDb ( String refName ) { return refName == null || refName . startsWith ( "refs / draft - comments" ) || ( refName . startsWith ( "refs / changes" ) && ! refName . endsWith ( " / meta" ) ) ; } /* * * Verify if the DB contains a value for the specific project and ref name *
import org . apache . curator . RetryPolicy ; import org . apache . curator . framework . CuratorFramework ; import org . apache . curator . framework . recipes . atomic . AtomicValue ; import org . apache . curator . framework . recipes . atomic . DistributedAtomicValue ; import org . apache . curator . framework . recipes . locks . InterProcessMutex ; import org . apache . curator . framework . recipes . locks . Locker ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . Ref ; public class ZkSharedRefDatabase implements SharedRefDatabase { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; private final CuratorFramework client ; private final RetryPolicy retryPolicy ; < |startfocus| > private final SharedRefEnforcement refEnforcement ; < |endfocus| > private final Long transactionLockTimeOut ; @Inject public ZkSharedRefDatabase ( CuratorFramework client , ZkConnectionConfig connConfig , SharedRefEnforcement refEnforcement ) { this . client = client ; this . retryPolicy = connConfig . curatorRetryPolicy ; this . transactionLockTimeOut = connConfig . transactionLockTimeout ; this . refEnforcement = refEnforcement ; } @Override public boolean isMostRecentRefVersion ( String project , Ref ref ) throws IOException { if ( ! exists ( project , ref . getName ( ) ) ) { logger . atWarning ( ) . log (
"Checking if this ref % s is the most recent , but not present in sharedDb , assuming " + "this is an old reference in Gerrit . Returning true" , ref . getName ( ) ) ; return true ; } try { final byte [ ] valueInZk = client . getData ( ) . forPath ( pathFor ( project , ref . getName ( ) ) ) ; // Assuming this is a delete node NULL_REF if ( valueInZk == null ) return false ; < |startfocus| > final ObjectId objectIdInZk = readObjectId ( valueInZk ) ; return objectIdInZk . equals ( ref . getObjectId ( ) ) ; < |endfocus| > } catch ( Exception e ) { throw new IOException ( String . format ( "Unable to read data for path % s" , pathFor ( project , ref . getName ( ) ) ) , e ) ; } } @Override public boolean compareAndRemove ( String project , Ref oldRef ) throws IOException { return compareAndPut ( project , oldRef , NULL_REF ) ; } @Override public boolean exists ( String projectName , String refName ) throws IOException { try { < |startfocus| >
} @Override public boolean compareAndRemove ( String project , Ref oldRef ) throws IOException { return compareAndPut ( project , oldRef , NULL_REF ) ; } @Override public boolean exists ( String projectName , String refName ) throws IOException { try { return client . checkExists ( ) . forPath ( pathFor ( projectName , refName ) ) != null ; } catch ( Exception e ) { throw new IOException ( "Failed to check if path exists in Zookeeper" , e ) ; } } < |startfocus| > @Override public Locker lockRef ( String projectName , Ref ref ) throws IOException { < |endfocus| > InterProcessMutex refPathMutex = new InterProcessMutex ( client , " / locks" + pathFor ( projectName , ref . getName ( ) ) ) ; try { return new Locker ( refPathMutex , transactionLockTimeOut , MILLISECONDS ) ; } catch ( Exception e ) { throw new IOException ( "Failed to create lock in ZK" , e ) ; } } @Override public boolean compareAndPut ( String projectName , Ref oldRef , Ref newRef ) throws IOException { EnforcePolicy enforcementPolicy = refEnforcement . getPolicy (
} catch ( Exception e ) { throw new IOException ( "Failed to check if path exists in Zookeeper" , e ) ; } } public Locker lockRef ( String projectName , Ref ref ) throws IOException { InterProcessMutex refPathMutex = new InterProcessMutex ( client , " / locks" + pathFor ( projectName , ref . getName ( ) ) ) ; try { return new Locker ( refPathMutex , transactionLockTimeOut , MILLISECONDS ) ; } catch ( Exception e ) { < |startfocus| > throw new IOException ( "Failed to create lock in ZK" , e ) ; < |endfocus| > } } @Override public boolean compareAndPut ( String projectName , Ref oldRef , Ref newRef ) throws IOException { EnforcePolicy enforcementPolicy = refEnforcement . getPolicy ( projectName , MoreObjects . firstNonNull ( oldRef . getName ( ) , newRef . getName ( ) ) ) ; if ( enforcementPolicy == EnforcePolicy . IGNORED ) { return true ; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue ( client , pathFor ( projectName , oldRef , newRef ) , retryPolicy ) ; try { if ( oldRef == NULL_REF ) { return distributedRefValue . initialize ( writeObjectId ( newRef . getObjectId ( ) ) ) ; }
import org . eclipse . jgit . lib . ProgressMonitor ; import org . eclipse . jgit . lib . RefDatabase ; import org . eclipse . jgit . revwalk . RevWalk ; import org . eclipse . jgit . transport . PushCertificate ; import org . eclipse . jgit . transport . ReceiveCommand ; import org . eclipse . jgit . util . time . ProposedTimestamp ; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { private final BatchRefUpdate batchRefUpdate ; private final String projectName ; private final RefUpdateValidator . Factory batchRefValidatorFactory ; private final RefDatabase refDb ; public static interface Factory { < |startfocus| > MultiSiteBatchRefUpdate create ( String projectName , RefDatabase refDb ) ; < |endfocus| > } @Inject public MultiSiteBatchRefUpdate ( RefUpdateValidator . Factory batchRefValidatorFactory , @Assisted String projectName , @Assisted RefDatabase refDb ) { super ( refDb ) ; this . refDb = refDb ; this . projectName = projectName ; this . batchRefUpdate = refDb . newBatchUpdate ( ) ; this . batchRefValidatorFactory = batchRefValidatorFactory ; } @Override public int hashCode ( ) { return batchRefUpdate . hashCode ( ) ; } @Override public boolean equals ( Object obj ) { return batchRefUpdate . equals ( obj ) ; } @Override public void setRefLogIdent ( PersonIdent ident ) { batchRefUpdate . setRefLogIdent ( ident ) ; } @Override public void setRefLogMessage ( String msg , boolean append ) { batchRefUpdate . setRefLogMessage ( msg , append ) ; } @Override public void setPushCertificate ( PushCertificate cert ) { batchRefUpdate . setPushCertificate ( cert ) ; } @Override public void setForceUpdate ( boolean force ) { batchRefUpdate . setForceUpdate ( force ) ; } @Override public void setRefLogIncludeResult ( boolean includeResult ) { batchRefUpdate . setRefLogIncludeResult ( includeResult ) ; } @Override public void setRefLogExpire ( boolean expire ) { batchRefUpdate . setRefLogExpire ( expire ) ; } @Override public void setRefLogExpirePreReceive ( boolean expire ) { batchRefUpdate . setRefLogExpirePreReceive ( expire ) ; } @Override public void setRefLogExpireRecurse ( boolean expire ) { batchRefUpdate . setRefLogExpireRecurse ( expire ) ; } @Override public void setRefLogExpireRecurseSubmodules ( boolean expire ) { batchRefUpdate . setRefLogExpireRecurseSubmodules ( expire ) ; } @Override public void setRefLogRecords ( boolean records ) { batchRefUpdate . setRefLogRecords ( records ) ; } @Override public void setRefLogRecordsSubmodules ( boolean records ) { batchRefUpdate . setRefLogRecordsSubmodules ( records ) ; } @Override public void setRefLogRecordsFrom ( boolean records ) { batchRefUpdate . setRefLogRecordsFrom ( records ) ; } @Override public void setRefLogRecordsTo ( boolean records ) { batchRefUpdate . setRefLogRecordsTo ( records ) ; } @Override public void setRefLogRecordsFromTo ( boolean records ) { batchRefUpdate . setRefLogRecordsFromTo ( records ) ; } @Override public void setRefLogRecordsFromToSubmodules ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToSubmodules ( records ) ; } @Override public void setRefLogRecordsFromToCommits ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommits ( records ) ; } @Override public void setRefLogRecordsFromToCommitsSubmodules ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsSubmodules ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommits ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommits ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsSubmodules ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommitsSubmodules ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsCommits ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommitsCommits ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsCommitsSubmodules ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommitsCommitsSubmodules ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsCommitsCommits ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommitsCommitsCommits ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsCommitsCommitsSubmodules ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommitsCommitsCommitsSubmodules ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommits ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommits ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsSubmodules ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsSubmodules ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommits ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommits ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommitsSubmodules ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommitsSubmodules ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommitsCommits ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommitsCommits ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommitsCommitsSubmodules ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommitsCommitsSubmodules ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommitsCommitsCommits ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommitsCommitsCommits ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommitsCommitsCommitsSubmodules ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommitsCommitsCommitsSubmodules ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommitsCommitsCommitsCommits ( boolean records ) { batchRefUpdate . setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommitsCommitsCommitsCommits ( records ) ; } @Override public void setRefLogRecordsFromToCommitsCommitsCommitsCommitsCommitsCommitsCommitsCommitsCommitsSubmodules ( boolean records ) { batchRefUpdate
} @Override public List < ProposedTimestamp > getProposedTimestamps ( ) { return batchRefUpdate . getProposedTimestamps ( ) ; } @Override public BatchRefUpdate addProposedTimestamp ( ProposedTimestamp ts ) { return batchRefUpdate . addProposedTimestamp ( ts ) ; } @Override public void execute ( RevWalk walk , ProgressMonitor monitor , List < String > options ) throws IOException { batchRefValidatorFactory . create ( projectName , refDb ) . executeBatchUpdateWithValidation ( < |startfocus| > batchRefUpdate , ( ) - > { batchRefUpdate . execute ( walk , monitor , options ) ; } ) ; < |endfocus| > } @Override public void execute ( RevWalk walk , ProgressMonitor monitor ) throws IOException { batchRefValidatorFactory . create ( projectName , refDb ) . executeBatchUpdateWithValidation ( batchRefUpdate , ( ) - > { batchRefUpdate . execute ( walk , monitor ) ; } ) ; } @Override public String toString ( ) { return batchRefUpdate . toString ( ) ; } }
throws IOException { batchRefValidatorFactory . create ( projectName , refDb ) . executeBatchUpdateWithValidation ( batchRefUpdate , ( ) - > { batchRefUpdate . execute ( walk , monitor , options ) ; return null ; } ) ; } @Override public void execute ( RevWalk walk , ProgressMonitor monitor ) throws IOException { batchRefValidatorFactory . create ( projectName , refDb ) . executeBatchUpdateWithValidation ( < |startfocus| > batchRefUpdate , ( ) - > { batchRefUpdate . execute ( walk , monitor ) ; return null ; } ) ; < |endfocus| > } @Override public String toString ( ) { return batchRefUpdate . toString ( ) ; } }
public RefUpdateValidator ( SharedRefDatabase sharedRefDb , ValidationMetrics validationMetrics , SharedRefEnforcement refEnforcement , @Assisted String projectName , < |startfocus| > @Assisted RefDatabase refDb ) { < |endfocus| > this . sharedRefDb = sharedRefDb ; this . validationMetrics = validationMetrics ; this . refDb = refDb ; this . projectName = projectName ; this . refEnforcement = refEnforcement ;
} public String getName ( ) { return MoreObjects . firstNonNull ( oldRef == null ? null : oldRef . getName ( ) , newRef == null ? null : newRef . getName ( ) ) ; } public boolean hasFailed ( ) { return exception != null ; } } protected void executeBatchUpdateWithPolicy ( String errorMessage , BatchValidationWrapper delegateValidation , BatchRefUpdate batchRefUpdate , NoParameterVoidFunction gitUpdateFun ) throws IOException { < |startfocus| > if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . IGNORED ) { gitUpdateFun . apply ( ) ; return ; } < |endfocus| > try { delegateValidation . apply ( batchRefUpdate , gitUpdateFun ) ; } catch ( IOException e ) { logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . REQUIRED ) { throw e ; } } } protected RefUpdate . Result executeRefUpdateWithPolicy ( String errorMessage , RefValidationWrapper delegateValidation , RefUpdate refUpdate , NoParameterFunction < RefUpdate . Result > gitUpdateFun ) throws IOException {
String errorMessage , BatchValidationWrapper delegateValidation , BatchRefUpdate batchRefUpdate , NoParameterVoidFunction gitUpdateFun ) throws IOException { // If ignored we just do the GIT update if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . IGNORED ) { gitUpdateFun . apply ( ) ; return ; } try { < |startfocus| > delegateValidation . apply ( batchRefUpdate , gitUpdateFun ) ; } catch ( IOException e ) { logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . REQUIRED ) { throw e ; } } } protected RefUpdate . Result executeRefUpdateWithPolicy ( String errorMessage , RefValidationWrapper delegateValidation , RefUpdate refUpdate , NoParameterFunction < RefUpdate . Result > gitUpdateFun ) throws IOException { // If ignored we just do the GIT update if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . IGNORED ) { return gitUpdateFun . apply ( ) ; } try { return delegateValidation . apply ( gitUpdateFun , refUpdate ) ; } catch ( IOException e ) { if ( e . getClass ( ) == SharedDbSplitBrainException . class ) {
return ; } try { delegateValidation . apply ( batchRefUpdate , gitUpdateFun ) ; } catch ( IOException e ) { logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . REQUIRED ) { throw e ; } } } protected RefUpdate . Result executeRefUpdateWithPolicy ( String errorMessage , RefValidationWrapper delegateValidation , RefUpdate refUpdate , NoParameterFunction < RefUpdate . Result > gitUpdateFun ) throws IOException { < |startfocus| > if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . IGNORED ) { return gitUpdateFun . apply ( ) ; } < |endfocus| > try { return delegateValidation . apply ( gitUpdateFun , refUpdate ) ; } catch ( IOException e ) { if ( e . getClass ( ) == SharedDbSplitBrainException . class ) { validationMetrics . incrementSplitBrain ( ) ; } logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . REQUIRED ) { throw e ; } } return null ; }
List < RefPair > refsToUpdate = getRefsPairs ( commands ) . sorted ( comparing ( RefPair : : hasFailed ) . reversed ( ) ) . collect ( Collectors . toList ( ) ) ; if ( refsToUpdate . isEmpty ( ) ) { return ; } if ( refsToUpdate . get ( 0 ) . hasFailed ( ) ) { RefPair failedRef = refsToUpdate . get ( 0 ) ; logger . atWarning ( ) . withCause ( failedRef . exception ) . log ( "Failed to fetch ref entries" ) ; throw new IOException ( "Failed to fetch ref entries" + failedRef . newRef . getName ( ) , failedRef . exception ) ; < |startfocus| > } < |endfocus| > Map < ObjectId , Ref > oldRefsMap = refsToUpdate . stream ( ) . collect ( Collectors . toMap ( refPair - > refPair . newRef . getObjectId ( ) , refPair - > refPair . oldRef ) ) ; try ( CloseableSet < AutoCloseable > locks = new CloseableSet ( ) ) { assertRefPairsAreInSyncWithSharedDb ( refsToUpdate , locks ) ; delegateUpdate . apply ( ) ; updateSharedRefDbForSuccessfulCommands ( batchRefUpdate . getCommands ( ) . stream ( ) , oldRefsMap ) ; } } private void updateSharedRefDbForSuccessfulCommands ( Stream < ReceiveCommand > commands , Map < ObjectId , Ref > oldRefsMap ) { commands . filter ( command - > ! command . getResult ( ) . equals ( Result . REJECTED ) ) . forEach ( command - > updateSharedRefDb ( command , oldRefsMap ) ) ; } private void updateSharedRefDb ( ReceiveCommand command , Map < ObjectId , Ref > oldRefsMap ) {
< |startfocus| > protected RefPair newRefPairFrom ( RefUpdate refUpdate ) { return new RefPair ( refDb . getRef ( refUpdate . getName ( ) ) , sharedRefDb . newRef ( refUpdate . getName ( ) , refUpdate . getNewObjectId ( ) ) ) ; < |endfocus| >
< |startfocus| > protected RefPair newRefPairFrom ( RefUpdate refUpdate ) { return new RefPair ( refUpdate . getRef ( ) , refUpdate . getRef ( ) ) ; < |endfocus| >
public BatchRefUpdateValidator ( SharedRefDatabase sharedRefDb , ValidationMetrics validationMetrics , SharedRefEnforcement refEnforcement , @Assisted String projectName , < |startfocus| > @Assisted RefDatabase refDb ) { < |endfocus| > super ( sharedRefDb , validationMetrics , refEnforcement , projectName , refDb ) ;
public RefUpdateValidator ( SharedRefDatabase sharedRefDb , ValidationMetrics validationMetrics , SharedRefEnforcement refEnforcement , @Assisted String projectName , < |startfocus| > @Assisted RefDatabase refDb ) { < |endfocus| > this . sharedRefDb = sharedRefDb ; this . validationMetrics = validationMetrics ; this . refDb = refDb ; this . projectName = projectName ; this . refEnforcement = refEnforcement ;
protected final SharedRefEnforcement refEnforcement ; public static interface Factory { RefUpdateValidator create ( String projectName , RefDatabase refDb ) ; } @Inject public RefUpdateValidator ( SharedRefDatabase sharedRefDb , ValidationMetrics validationMetrics , SharedRefEnforcement refEnforcement , @Assisted String projectName , @Nullable @Assisted RefDatabase refDb ) { this . sharedRefDb = sharedRefDb ; this . validationMetrics = validationMetrics ; this . refDb = refDb ; this . projectName = projectName ; this . refEnforcement = refEnforcement ; } < |startfocus| > protected void executeBatchUpdateWithPolicy ( String errorMessage , BatchValidationWrapper delegateValidation , BatchRefUpdate batchRefUpdate , NoParameterVoidFunction gitUpdateFun ) < |endfocus| > throws IOException { if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . IGNORED ) { gitUpdateFun . apply ( ) ; return ; } try { delegateValidation . apply ( batchRefUpdate , gitUpdateFun ) ; } catch ( IOException e ) { logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . REQUIRED ) { throw e ; } } }
RefUpdateValidator create ( String projectName , RefDatabase refDb ) ; } @Inject public RefUpdateValidator ( SharedRefDatabase sharedRefDb , ValidationMetrics validationMetrics , SharedRefEnforcement refEnforcement , @Assisted String projectName , @Nullable @Assisted RefDatabase refDb ) { this . sharedRefDb = sharedRefDb ; this . validationMetrics = validationMetrics ; this . refDb = refDb ; this . projectName = projectName ; this . refEnforcement = refEnforcement ; } < |startfocus| > protected void executeBatchUpdateWithPolicy ( String errorMessage , BatchValidationWrapper delegateValidation , BatchRefUpdate batchRefUpdate ) < |endfocus| > throws IOException { if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . IGNORED ) { batchRefUpdate . execute ( ) ; return ; } try { delegateValidation . apply ( batchRefUpdate , batchRefUpdate : : execute ) ; } catch ( IOException e ) { logger . atWarning ( ) . withCause ( e ) . log ( errorMessage ) ; if ( refEnforcement . getPolicy ( projectName ) == EnforcePolicy . REQUIRED ) { throw e ; } } } protected RefUpdate . Result executeRefUpdateWithPolicy ( String errorMessage , RefValidationWrapper delegateValidation ,
try { locks . addResourceIfNotExist ( resourceLockKey , ( ) - > sharedRefDb . lockRef ( projectName , nonNullRef ) ) ; } catch ( Exception e ) { throw new IOException ( String . format ( "Unable to prepare locks for project % s and reference % s" , projectName , nonNullRef . getName ( ) ) , e ) ; } boolean isInSync ; < |startfocus| > if ( refPair . oldRef != sharedRefDb . NULL_REF && refPair . oldRef != null ) { isInSync = sharedRefDb . isUpToDate ( projectName , refPair . oldRef ) ; < |endfocus| > } else { isInSync = ! sharedRefDb . exists ( projectName , refPair . getName ( ) ) ; } if ( ! isInSync ) { failWith ( new IOException ( String . format ( "Ref ' % s' for project ' % s' not in sync with shared Ref - Db . " + "Trying to change the Ref - Db from oldRefId ' % s'" + " to newRefId ' % s' . Aborting batch update . " , refPair . getName ( ) , projectName , refPair . oldRef . getObjectId ( ) , refPair . getNewObjectId ( ) ) ,
import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . zookeeper . RefUpdateStub ; import java . io . IOException ; import org . eclipse . jgit . lib . ObjectIdRef ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . RefDatabase ; import org . eclipse . jgit . lib . RefUpdate ; import org . eclipse . jgit . lib . RefUpdate . Result ; import org . junit . Before ; import org . junit . Rule ; import org . junit . Test ; import org . junit . rules . TestName ; import org . junit . runner . RunWith ; import org . mockito . Mock ; import org . mockito . junit . MockitoJUnitRunner ; < |startfocus| > @RunWith ( MockitoJUnitRunner . class ) < |endfocus| > public class MultiSiteRefUpdateTest implements RefFixture { @Mock SharedRefDatabase sharedRefDb ; @Mock ValidationMetrics validationMetrics ; private final Ref oldRef = new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , A_TEST_REF_NAME , AN_OBJECT_ID_1 ) ; private final Ref newRef = new ObjectIdRef . Unpeeled ( Ref . Storage . NETWORK , A_TEST_REF_NAME , AN_OBJECT_ID_2 ) ; @Rule public TestName nameRule = new TestName ( ) ; @Override public String testBranch ( ) { return "branch_" + nameRule . getMethodName ( ) ; } @Before
if ( policy == EnforcePolicy . REQUIRED ) { throw e ; } } protected RefUpdate . Result doExecuteRefUpdate ( RefUpdate refUpdate , NoParameterFunction < RefUpdate . Result > refUpdateFunction ) throws IOException { try ( CloseableSet < AutoCloseable > locks = new CloseableSet < > ( ) ) { RefPair refPair = newRefPairFrom ( refUpdate ) ; checkIfLocalRefIsUpToDateWithSharedRefDb ( refPair . getName ( ) , locks ) ; RefUpdate . Result result = refUpdateFunction . invoke ( ) ; if ( isSuccessful ( result ) ) { < |startfocus| > updateSharedDbOrThrowExceptionFor ( refPair ) ; < |endfocus| > } return result ; } } protected void updateSharedDbOrThrowExceptionFor ( RefPair refPair ) throws IOException { // We are not checking refs that should be ignored final EnforcePolicy refEnforcementPolicy = refEnforcement . getPolicy ( projectName , refPair . getName ( ) ) ; if ( refEnforcementPolicy == EnforcePolicy . IGNORED ) return ; String errorMessage = String . format ( "Not able to persist the data in Zookeeper for project ' % s' and ref ' % s' , " + "the cluster is now in Split Brain since the commit has been "
assertThat ( created . ref ) . isEqualTo ( branch . branch ( ) ) ; } private void assertCreateFails ( BranchNameKey branch , Class < ? extends RestApiException > errType , String errMsg ) throws Exception { assertCreateFails ( branch , null , errType , errMsg ) ; } private void assertCreateFails ( BranchNameKey branch , String revision , Class < ? extends RestApiException > errType , String errMsg ) throws Exception { BranchInput in = new BranchInput ( ) ; in . revision = revision ; < |startfocus| > if ( errMsg != null ) { assertThrows ( errType , ( ) - > branch ( branch ) . create ( in ) ) ; } < |endfocus| > } private void assertCreateFails ( BranchNameKey branch , Class < ? extends RestApiException > errType ) throws Exception { assertCreateFails ( branch , errType , null ) ; } }
} @Test public void customLabel_DisallowPostSubmit ( ) throws Exception { label . setFunction ( NO_OP ) ; label . setAllowPostSubmit ( false ) ; P . setFunction ( NO_OP ) ; saveLabelConfig ( ) ; PushOneCommit . Result r = createChange ( ) ; revision ( r ) . review ( ReviewInput . approve ( ) ) ; revision ( r ) . submit ( ) ; ChangeInfo info = getWithLabels ( r ) ; assertPermitted ( info , "Code - Review" , 2 ) ; assertPermitted ( info , P . getName ( ) , 0 , 1 ) ; assertPermitted ( info , label . getName ( ) ) ; < |startfocus| > ReviewInput preSubmitReview = new ReviewInput ( ) ; preSubmitReview . label ( P . getName ( ) , P . getMax ( ) . getValue ( ) ) ; revision ( r ) . review ( preSubmitReview ) ; ReviewInput postSubmitReview = new ReviewInput ( ) ; postSubmitReview . label ( label . getName ( ) , label . getMax ( ) . getValue ( ) ) ; ResourceConflictException thrown = assertThrows ( ResourceConflictException . class , ( ) - > revision ( r ) . review ( postSubmitReview ) ) ; assertThat ( thrown ) . hasMessageThat ( ) . contains ( "Voting on labels disallowed after submit : " + label . getName ( ) ) ; < |endfocus| > } @Test public void customLabelWithUserPermissionChange ( ) throws Exception {
staticPath = cdnPath ; } else if ( canonicalPath != null ) { staticPath = canonicalPath ; } // The resource path must be typed as safe for use in a script src . // TODO ( wyatta ) : Upgrade this to use an appropriate safe URL type . SanitizedContent sanitizedStaticPath = UnsafeSanitizedContentOrdainer . ordainAsSafe ( staticPath , SanitizedContent . ContentKind . TRUSTED_RESOURCE_URI ) ; Map data = new HashMap < > ( ) ; data . put ( "canonicalPath" , canonicalPath ) ; < |startfocus| > data . put ( "staticResourcePath" , sanitizedStaticPath ) ; < |endfocus| > data . put ( "faviconPath" , faviconPath ) ; return data ; } }
String staticPath = "" ; if ( cdnPath != null ) { staticPath = cdnPath ; } else if ( canonicalPath != null ) { staticPath = canonicalPath ; } // The resource path must be typed as safe for use in a script src . // TODO ( wyatta ) : Upgrade this to use an appropriate safe URL type . SanitizedContent sanitizedStaticPath = UnsafeSanitizedContentOrdainer . ordainAsSafe ( staticPath , SanitizedContent . ContentKind . TRUSTED_RESOURCE_URI ) ; < |startfocus| > Map < String , Object > data = new HashMap < > ( ) ; < |endfocus| > data . put ( "canonicalPath" , canonicalPath ) ; data . put ( "staticResourcePath" , sanitizedStaticPath ) ; data . put ( "faviconPath" , faviconPath ) ; return data ; } }
// implied . // See the License for the specific language governing permissions and // limitations under the License . package com . vmware . gerrit . owners . common ; import static org . junit . Assert . assertEquals ; import com . google . gerrit . acceptance . LightweightPluginDaemonTest ; import com . google . gerrit . acceptance . Sandboxed ; import com . google . gerrit . acceptance . TestPlugin ; import com . google . gerrit . extensions . events . GitReferenceUpdatedListener ; import com . google . gerrit . reviewdb . client . RefNames ; import com . google . inject . AbstractModule ; import org . eclipse . jgit . transport . ReceiveCommand . Type ; import org . junit . Test ; < |startfocus| > @Sandboxed < |endfocus| > @TestPlugin ( name = "owners - autoassign" , sysModule = "com . vmware . gerrit . owners . common . GitRefListenerIT$TestModule" ) public class GitRefListenerIT extends LightweightPluginDaemonTest { public static class TestModule extends AbstractModule { @Override protected void configure ( ) { bind ( GitReferenceUpdatedListener . class ) . to ( TestGitRefListener . class ) ; } } @Test public void shouldNotProcessNoteDbOnlyRefs ( ) { TestGitRefListener gitRefListener = getPluginInstance ( TestGitRefListener . class ) ; String aRefChange = RefNames . REFS_CHANGES + "01 / 01" + RefNames . META_SUFFIX ; < |startfocus| > gitRefListener . onGitReferenceUpdated ( aRefChange , Type . UPDATE , null , null , null ) ; < |endfocus| > assertEquals ( 1 , gitRefListener . getRefs ( ) . size ( ) ) ; assertEquals ( aRefChange , gitRefListener . getRefs ( ) . get ( 0 ) ) ; } }
builder . setGroups ( PatchSet . joinGroups ( groups ) ) ; } patchSet . getPushCertificate ( ) . ifPresent ( builder : : setPushCertificate ) ; patchSet . getDescription ( ) . ifPresent ( builder : : setDescription ) ; return builder . build ( ) ; } @Override public PatchSet fromProto ( Entities . PatchSet proto ) { < |startfocus| > PatchSet . Builder builder = PatchSet . builder ( ) . id ( patchSetIdConverter . fromProto ( proto . getId ( ) ) ) ; builder . groups ( proto . hasGroups ( ) ? PatchSet . splitGroups ( proto . getGroups ( ) ) : ImmutableList . of ( ) ) ; < |endfocus| > if ( proto . hasPushCertificate ( ) ) { builder . pushCertificate ( proto . getPushCertificate ( ) ) ; } if ( proto . hasDescription ( ) ) { builder . description ( proto . getDescription ( ) ) ; } // The following fields used to theoretically be nullable in PatchSet , but in practice no // production codepath should have ever serialized an instance that was missing one of these // fields . // // However , since some protos may theoretically be missing these fields , we need to support // them . Populate specific sentinel values for each field as documented in the PatchSet javadoc .
// distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . manager ; import static com . google . common . truth . Truth . assertThat ; import static com . googlesource . gerrit . plugins . manager . GerritVersionBranch . getBranch ; import org . junit . Test ; public class GerritVersionBranchTest { @Test < |startfocus| > public void getBranchReturnsCorrectBranchForVersion ( ) throws Exception { < |endfocus| > // Regular 2 . x versions assertBranch ( "2 . 13" , "stable - 2 . 13" ) ; assertBranch ( "2 . 14" , "stable - 2 . 14" ) ; assertBranch ( "2 . 15" , "stable - 2 . 15" ) ; assertBranch ( "2 . 16" , "stable - 2 . 16" ) ; } @Test public void getBranchReturnsCorrectBranchForVersion2 ( ) throws Exception { // 2 . x . y version assertBranch ( "2 . 16 . 10" , "stable - 2 . 16" ) ; } @Test public void getBranchReturnsCorrectBranchForVersion3 ( ) throws Exception { // 2 . x - rcx version assertBranch ( "2 . 16 - rc1" , "stable - 2 . 16" ) ; } @Test public void getBranchReturnsCorrectBranchForVersion4 ( ) throws Exception { // 3 . 0 . 0 version assertBranch ( "3 . 0 . 0" , "stable - 3 . 0" ) ; } private void assertBranch ( String version , String branch ) { assertThat ( getBranch ( version ) ) . isEqualTo ( branch ) ; } }
* } * * public int getHttpStatusCode ( ) { * return httpStatusCode ; * } * } * * public class MyErrorHandlingFilter extends AbstractHttpFilter { * private static final DefaultErrorHandlingFilter delegate = * new DefaultErrorHandlingFilter ( ) ; * * { @literal @ } Override * public void doFilter ( HttpServletRequest req , HttpServletResponse res , FilterChain chain ) * throws IOException , ServletException { * try { < |startfocus| > * delegate . doFilter ( req , res , chain ) ; < |endfocus| > * } catch ( MyRequestFailureException e ) { * res . setHeader ( DefaultErrorHandlingFilter . GITILES_ERROR , e . getReason ( ) . toString ( ) ) ; * res . sendError ( e . getReason ( ) . getHttpStatusCode ( ) ) ; * } * } * } * </ code > </ pre > * * < p > { @code RepositoryResolver } can throw { @code MyRequestFailureException } and { @code * MyErrorHandlingFilter } will handle that . You can control how the error should be surfaced . */ public final class GitilesRequestFailureException extends RuntimeException {
BLAME_REGION_NOT_FOUND ( SC_NOT_FOUND ) , /* * Cannot parse URL as a Gitiles URL . */ CANNOT_PARSE_GITILES_VIEW ( SC_NOT_FOUND ) , /* * URL parameters are not valid . */ INCORECT_PARAMETER ( SC_BAD_REQUEST ) , /* * * The object specified by the URL is not suitable for the view ( e . g . trying to show a blob as a * tree ) . */ < |startfocus| > INCORRECT_OBJECT_TYPE ( SC_BAD_REQUEST ) , < |endfocus| > /* * Markdown rendering is not enabled . */ MARKDOWN_NOT_ENABLED ( SC_NOT_FOUND ) , /* * Request is not authorized . */ NOT_AUTHORIZED ( SC_UNAUTHORIZED ) , /* * Object is not found . */ OBJECT_NOT_FOUND ( SC_NOT_FOUND ) , /* * Object is too large to show . */ OBJECT_TOO_LARGE ( SC_INTERNAL_SERVER_ERROR ) , /* * Repository is not found . */ REPOSITORY_NOT_FOUND ( SC_NOT_FOUND ) , /* * Gitiles is not enabled for the repository . */ SERVICE_NOT_ENABLED ( SC_FORBIDDEN ) , /* * GitWeb URL cannot be converted to Gitiles URL . */ UNSUPPORTED_GITWEB_URL ( SC_GONE ) ,
// you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // https :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gitiles ; < |startfocus| > < |endfocus| > public class MoreAssert { private MoreAssert ( ) { } /* * Simple version of assertThrows that will be introduced in JUnit 4 . 13 . */ public static < T extends Throwable > T assertThrows ( Class < T > expected , ThrowingRunnable r ) { try { r . run ( ) ; throw new AssertionError ( "Expected " + expected . getSimpleName ( ) + " to be thrown" ) ; } catch ( Throwable actual ) { if ( expected . isAssignableFrom ( actual . getClass ( ) ) ) { return ( T ) actual ; } throw new AssertionError ( actual ) ; } } /* * Functional interface for code that may throw an exception . */ @FunctionalInterface public interface ThrowingRunnable { void run ( ) throws Exception ; } }
factory ( MultiSiteBatchRefUpdate . Factory . class ) ; factory ( RefUpdateValidator . Factory . class ) ; factory ( BatchRefUpdateValidator . Factory . class ) ; if ( ! disableGitRepositoryValidation ) { bind ( GitRepositoryManager . class ) . to ( MultiSiteGitRepositoryManager . class ) ; } if ( cfg . getZookeeperConfig ( ) . getEnforcementRules ( ) . isEmpty ( ) ) { bind ( SharedRefEnforcement . class ) . to ( DefaultSharedRefEnforcement . class ) . in ( Scopes . SINGLETON ) ; } else { bind ( SharedRefEnforcement . class ) < |startfocus| > . to ( CustomSharedRefEnforcementByProject . class ) . in ( Scopes . SINGLETON ) ; < |endfocus| > } install ( new ZkValidationModule ( cfg ) ) ;
// and then query the secondary index for each user but this way is less // efficient . queryPredicate = Predicate . or ( AccountPredicates . isActive ( ) , AccountPredicates . isNotActive ( ) ) ; } for ( AccountState accountState : accountQueryProvider . get ( ) . query ( queryPredicate ) ) { Account account = accountState . getAccount ( ) ; String out = new StringBuilder ( ) . append ( account . getId ( ) . toString ( ) ) . append ( " |" ) . append ( < |startfocus| > accountState . getUserName ( ) . isPresent ( ) < |endfocus| > ? "" : " " + accountState . getUserName ( ) . get ( ) ) . append ( " |" ) . append ( Strings . isNullOrEmpty ( account . getFullName ( ) ) ? "" : " " + account . getFullName ( ) ) . append ( " |" ) . append ( Strings . isNullOrEmpty ( account . getPreferredEmail ( ) ) ? "" : " " + account . getPreferredEmail ( ) ) . append ( " |" ) . append ( account . isActive ( ) ? " active" : " inactive" ) . toString ( ) ;
if ( args . getSchema ( ) . hasField ( ChangeField . EXTENSION ) ) { FileExtensionPredicate extensionPredicate = new FileExtensionPredicate ( ext ) ; if ( ext . isEmpty ( ) ) { RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate ( " ^ . { 0 } $" ) ; // RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate ( " ^ ( ) $" ) ; // cf . https :/ / www . brics . dk / automaton / doc / index . html ? dk / brics / automaton / RegExp . html return emptyExtPredicate ; // return Predicate . or ( extensionPredicate , emptyExtPredicate ) ; } < |startfocus| > return extensionPredicate ; < |endfocus| > } throw new QueryParseException ( "'extension' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > onlyexts ( String extList ) throws QueryParseException { return onlyextensions ( extList ) ; } @Operator public Predicate < ChangeData > onlyextensions ( String extList ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . ONLY_EXTENSIONS ) ) { return new FileExtensionListPredicate ( extList ) ; } throw new QueryParseException ( "'onlyextensions' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > path ( String path ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . PATH ) ) { return new PathPredicate ( path ) ; } throw new QueryParseException ( "'path' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > project ( String project ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . PROJECT ) ) { return new ProjectPredicate ( project ) ; } throw new QueryParseException ( "'project' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > ref ( String ref ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . REF ) ) { return new RefPredicate ( ref ) ; } throw new QueryParseException ( "'ref' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > refexact ( String ref ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . REF ) ) { return new RefPredicate ( ref , true ) ; } throw new QueryParseException ( "'refexact' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > refprefix ( String ref ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . REF ) ) { return new RefPredicate ( ref , false ) ; } throw new QueryParseException ( "'refprefix' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > refregex ( String ref ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . REF ) ) { return new RefRegexPredicate ( ref ) ; } throw new QueryParseException ( "'refregex' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > reviewer ( String reviewer ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . REVIEWER ) ) { return new ReviewerPredicate ( reviewer ) ; } throw new QueryParseException ( "'reviewer' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > reviewerbyemail ( String reviewer ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . REVIEWER_BY_EMAIL ) ) { return new ReviewerByEmailPredicate ( reviewer ) ; } throw new QueryParseException ( "'reviewerbyemail' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > reviewerfile ( String reviewer ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . REVIEWER_UUID ) ) { return new ReviewerFilePredicate ( reviewer ) ; } throw new QueryParseException ( "'reviewerfile' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > reviewerin ( String reviewer ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . REVIEWER ) ) { return new ReviewerPredicate ( reviewer , true ) ; } throw new QueryParseException ( "'reviewerin' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > reviewerinfile ( String reviewer ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . REVIEWER_UUID ) ) { return new ReviewerFilePredicate ( reviewer , true ) ; } throw new QueryParseException ( "'reviewerinfile' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > reviewerbyemailin ( String reviewer ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . REVIEWER_BY_EMAIL ) ) { return new ReviewerByEmailPredicate ( reviewer , true ) ; } throw new QueryParseException ( "'reviewerbyemailin' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > status ( String status ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . STATUS ) ) { return new StatusPredicate ( status ) ; } throw new QueryParseException ( "'status' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > topic ( String topic ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . TOPIC ) ) { return new TopicPredicate ( topic ) ; } throw new QueryParseException ( "'topic' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > tr ( String tr ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . TR ) ) { return new TrackingIdPredicate ( tr ) ; } throw new QueryParseException ( "'tr' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > trin ( String tr ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . TR ) ) { return new TrackingIdPredicate ( tr , true ) ; } throw new QueryParseException ( "'trin' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > trany ( String tr ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . TR ) ) { return new TrackingIdPredicate ( tr , false ) ; } throw new QueryParseException ( "'trany' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > trregex ( String tr ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . TR ) ) { return new TrackingIdRegexPredicate ( tr ) ; } throw new QueryParseException ( "'trregex' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > trregexin ( String tr ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . TR ) ) { return new TrackingIdRegexPredicate ( tr , true ) ; } throw new QueryParseException ( "'trregexin' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > trregexany ( String
public void disablePlugins ( Set < String > names ) { if ( ! isRemoteAdminEnabled ( ) ) { logger . atWarning ( ) . log ( "Remote plugin administration is disabled , ignoring disablePlugins ( % s ) " , names ) ; return ; } synchronized ( this ) { for ( String name : names ) { Plugin active = running . get ( name ) ; if ( active == null ) { continue ; } < |startfocus| > if ( mandatoryPlugins . contains ( name ) ) { logger . atInfo ( ) . log ( "Mandatory plugin % s cannot be disabled" , name ) ; continue ; } < |endfocus| > logger . atInfo ( ) . log ( "Disabling plugin % s" , active . getName ( ) ) ; Path off = active . getSrcFile ( ) . resolveSibling ( active . getSrcFile ( ) . getFileName ( ) + " . disabled" ) ; try { Files . move ( active . getSrcFile ( ) , off ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Failed to disable plugin" ) ; // In theory we could still unload the plugin even if the rename // failed . However , it would be reloaded on the next server startup , so // we don't bother .
. state ( CheckState . FAILED ) . upsert ( ) ; assertThat ( getChangeCheckInfo ( changeId ) ) . hasValue ( new ChangeCheckInfo ( "checks" , CombinedCheckState . FAILED ) ) ; } @Test public void combinedCheckStateViaQuery ( ) throws Exception { CacheStats start = cloneStats ( cache . getStats ( ) ) ; long startReloadsFalse = cache . getReloadCount ( false ) ; long startReloadsTrue = cache . getReloadCount ( true ) ; assertThat ( queryChangeCheckInfo ( changeId ) ) . hasValue ( new ChangeCheckInfo ( "checks" , CombinedCheckState . NOT_RELEVANT ) ) ; < |startfocus| > // Cache hasn't yet populated during update . < |endfocus| > assertThat ( cache . getStats ( ) ) . since ( start ) . hasHitCount ( 0 ) ; assertThat ( cache . getStats ( ) ) . since ( start ) . hasMissCount ( 1 ) ; assertThat ( cache . getReloadCount ( false ) - startReloadsFalse ) . isEqualTo ( 0 ) ; assertThat ( cache . getReloadCount ( true ) - startReloadsTrue ) . isEqualTo ( 0 ) ; assertThat ( queryChangeCheckInfo ( changeId ) ) . hasValue ( new ChangeCheckInfo ( "checks" , CombinedCheckState . NOT_RELEVANT ) ) ; assertThat ( cache . getStats ( ) ) . since ( start ) . hasHitCount ( 1 ) ; assertThat ( cache . getStats ( ) ) . since ( start ) . hasMissCount ( 1 ) ; assertThat ( cache . getReloadCount ( false ) - startReloadsFalse ) . isEqualTo ( 0 ) ; assertThat ( cache . getReloadCount ( true ) - startReloadsTrue ) . isEqualTo ( 0 ) ;
} return EqualsFilePredicate . create ( args , file ) ; } @Operator public Predicate < ChangeData > path ( String path ) { if ( path . startsWith ( " ^ " ) ) { return new RegexPathPredicate ( path ) ; } return new EqualsPathPredicate ( FIELD_PATH , path ) ; } @Operator public Predicate < ChangeData > ext ( String ext ) throws QueryParseException { return extension ( ext ) ; } @Operator public Predicate < ChangeData > extension ( String ext ) throws QueryParseException { < |startfocus| > if ( args . getSchema ( ) . hasField ( ChangeField . EXTENSION ) ) { < |endfocus| > return new FileExtensionPredicate ( ext ) ; } throw new QueryParseException ( "'extension' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > onlyexts ( String extList ) throws QueryParseException { return onlyextensions ( extList ) ; } @Operator public Predicate < ChangeData > onlyextensions ( String extList ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . ONLY_EXTENSIONS ) ) { return new FileExtensionListPredicate ( extList ) ; } throw new QueryParseException ( "'onlyextensions' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > is ( String value ) throws QueryParseException { return is ( value , false ) ; } @Operator public Predicate < ChangeData > is ( String value , boolean caseInsensitive ) throws QueryParseException { if ( value . equals ( "starred" ) ) { return new StarredPredicate ( args . getAccountId ( ) ) ; } if ( value . equals ( "watched" ) ) { return new WatchedPredicate ( args . getAccountId ( ) ) ; } if ( value . equals ( "draft" ) ) { return new DraftPredicate ( args . getAccountId ( ) ) ; } if ( value . equals ( "mergeable" ) ) { return new MergeablePredicate ( ) ; } if ( value . equals ( "reviewed" ) ) { return new ReviewedPredicate ( args . getAccountId ( ) ) ; } if ( value . equals ( "owner" ) ) { return new OwnerPredicate ( args . getAccountId ( ) ) ; } if ( value . equals ( "reviewer" ) ) { return new ReviewerPredicate ( args . getAccountId ( ) ) ; } if ( value . equals ( "commit" ) ) { return new CommitPredicate ( ) ; } if ( value . equals ( "submittable" ) ) { return new SubmittablePredicate ( ) ; } if ( value . equals ( "private" ) ) { return new PrivatePredicate ( ) ; } if ( value . equals ( "visibleto : self" ) ) { return new VisibleToPredicate ( args . getAccountId ( ) ) ; } if ( value . startsWith ( "visibleto : " ) ) { return new VisibleToPredicate ( args . getAccountId ( ) , value . substring ( "visibleto : " . length ( ) ) ) ; } if ( value . equals ( "limit : 0" ) ) { return new LimitPredicate ( 0 ) ; } if ( value . startsWith ( "limit : " ) ) { try { return new LimitPredicate ( Integer . parseInt ( value . substring ( "limit : " . length ( ) ) ) ) ; } catch ( NumberFormatException e ) { throw new QueryParseException ( "invalid limit : " + value ) ; } } if ( value . equals ( "conflicts" ) ) { return new ConflictsPredicate ( ) ; } if ( value . equals ( "has : draft" ) ) { return new HasDraftPredicate ( args . getAccountId ( ) ) ; } if ( value . equals ( "has : edit" ) ) { return new HasEditPredicate ( args . getAccountId ( ) ) ; } if ( value . equals ( "has : star" ) ) { return new HasStarPredicate ( args . getAccountId ( ) ) ; } if ( value . equals ( "has : label" ) ) { return new HasLabelPredicate ( ) ; } if ( value . equals ( "has : comment" ) ) { return new HasCommentPredicate ( ) ; } if ( value . equals ( "has : attachment" ) ) { return new HasAttachmentPredicate ( ) ; } if ( value . equals ( "has : change" ) ) { return new HasChangePredicate ( ) ; } if ( value . equals ( "has : patchset" ) ) { return new HasPatchSetPredicate ( ) ; } if ( value . equals ( "has : revision" ) ) { return new HasRevisionPredicate ( ) ; } if ( value . equals ( "has : message" ) ) { return new HasMessagePredicate ( ) ; } if ( value . equals ( "has : submit" ) ) { return new HasSubmitRecordPredicate ( ) ; } if ( value . equals ( "has : abandon" ) ) { return new HasAbandonRecordPredicate ( ) ; } if ( value . equals ( "has : restore" ) ) { return new HasRestoreRecordPredicate ( ) ; } if ( value . equals ( "has : wip" ) ) { return new HasWorkInProgressPredicate ( ) ; } if ( value . equals ( "has : ready" ) ) { return new HasReadyPredicate ( ) ; } if ( value . equals ( "has : workflow" ) ) { return new HasWorkflowPredicate ( ) ; } if ( value . equals ( "has : action" ) ) { return new HasActionPredicate ( ) ; } if ( value . equals ( "has : submit_action" ) ) { return new HasSubmitActionPredicate ( ) ; } if ( value . equals ( "has : rebase" ) ) { return new HasRebasePredicate ( ) ; } if ( value . equals ( "has : cherrypick" ) ) { return new HasCherryPickPredicate ( ) ; } if ( value . equals ( "has : trivial_rebase" ) ) { return new HasTrivialRebasePredicate ( ) ; } if ( value . equals ( "has : mergeable" ) ) { return new HasMergeablePredicate ( ) ; } if ( value . equals ( "has : revert" ) ) { return new HasRevertPredicate ( ) ; } if ( value . equals ( "has : work_in_progress_by_user" ) ) { return new HasWorkInProgressByUserPredicate ( ) ; } if ( value . equals ( "has : work_in_progress_by_admin" ) ) { return new HasWorkInProgressByAdminPredicate ( ) ; } if ( value . equals ( "has : work_in_progress_by_others" ) ) { return new HasWorkInProgressByOthersPredicate ( ) ; } if ( value . equals ( "has : work_in_progress" ) ) { return new HasWorkInProgressPredicate ( ) ; } if ( value . equals ( "has : ready_by_user" ) ) { return new HasReadyByUserPredicate ( ) ; } if ( value . equals ( "has : ready_by_admin" ) ) { return new HasReadyByAdminPredicate ( ) ; } if ( value . equals ( "has : ready_by_others" ) ) { return new HasReadyByOthersPredicate ( ) ; } if ( value . equals ( "has : ready" ) ) { return new HasReadyPredicate ( ) ; } if ( value . equals ( "has : workflow" ) ) { return new HasWorkflowPredicate ( ) ; } if ( value . equals ( "has : action" ) ) { return new HasActionPredicate ( ) ; } if ( value . equals ( "has : submit_action" ) ) { return new HasSubmitActionPredicate ( ) ; } if ( value . equals ( "has : rebase" ) ) { return new HasRebasePredicate ( ) ; } if ( value . equals ( "has : cherrypick" ) ) { return new HasCherryPickPredicate ( ) ; } if ( value . equals ( "has : trivial_rebase" ) ) { return new HasTrivialRebasePredicate ( ) ; } if ( value . equals ( "has : mergeable" ) ) { return new HasMergeablePredicate ( ) ; } if ( value . equals ( "has : revert" ) ) { return new HasRevertPredicate ( ) ; } if ( value . equals ( "has : work_in_progress_by_user" ) ) { return new HasWorkInProgressByUserPredicate ( ) ; } if ( value . equals ( "has : work_in_progress_by_admin" ) ) { return new HasWorkInProgressByAdminPredicate ( ) ; } if ( value . equals ( "has : work
< |startfocus| > public MissingMandatoryPluginsException ( Collection < String > pluginNames ) { < |endfocus| > super ( getMessage ( pluginNames ) ) ;
// See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . plugins ; import java . util . Set ; /* * Raised when one or more mandatory plugins are missing . */ public class MissingMandatoryPluginsException extends RuntimeException { private static final long serialVersionUID = 1L ; public MissingMandatoryPluginsException ( Set < String > pluginNames ) { super ( getMessage ( pluginNames ) ) ; } < |startfocus| > public MissingMandatoryPluginsException ( Set < String > pluginNames , Throwable why ) { super ( getMessage ( pluginNames ) , why ) ; } private static String getMessage ( Set < String > pluginNames ) { < |endfocus| > return String . format ( "Cannot find or load the following mandatory plugins : % s" , pluginNames ) ; } }
" % s plugin % s , version % s" , active == null ? "Loaded" : "Reloaded" , loadedPlugin . getName ( ) , loadedPlugin . getVersion ( ) ) ; } } catch ( PluginInstallException e ) { logger . atWarning ( ) . withCause ( e . getCause ( ) ) . log ( "Cannot load plugin % s" , name ) ; } } } Set < String > missingMandatory = Sets . difference ( mandatoryPlugins , loadedPlugins ) ; if ( ! missingMandatory . isEmpty ( ) ) { < |startfocus| > throw new ProvisionException ( "Failed to load mandatory plugins : " + missingMandatory ) ; < |endfocus| > } cleanInBackground ( ) ; } private void addAllEntries ( Map < String , Path > from , TreeSet < Map . Entry < String , Path > > to ) { Iterator < Map . Entry < String , Path > > it = from . entrySet ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { Map . Entry < String , Path > entry = it . next ( ) ; to . add ( new AbstractMap . SimpleImmutableEntry < > ( entry . getKey ( ) , entry . getValue ( ) ) ) ; } } private TreeSet < Map . Entry < String , Path > > jarsFirstSortedPluginsSet ( Map < String , Path > activePlugins ) {
* should use the batch instead of abandoning one by one . * * < p > It's the caller's responsibility to ensure that all jobs inside the same batch have the * matching project from its ChangeData . Violations will result in a ResourceConflictException . */ public void batchAbandon ( BatchUpdate . Factory updateFactory , Project . NameKey project , CurrentUser user , Collection < ChangeData > changes , String msgTxt , < |startfocus| > NotifyResolver . Result notify ) throws RestApiException , UpdateException { if ( changes . isEmpty ( ) ) { return ; } AccountState accountState = user . isIdentifiedUser ( ) ? user . asIdentifiedUser ( ) . state ( ) : null ; try ( BatchUpdate u = updateFactory . create ( project , user , TimeUtil . nowTs ( ) ) ) { u . setNotify ( notify ) ; for ( ChangeData change : changes ) { if ( ! project . equals ( change . project ( ) ) ) { throw new ResourceConflictException ( String . format ( "Project name \" % s\" doesn't match \" % s\"" ,
public static IndexType getIndexType ( Injector injector ) { < |startfocus| > return getIndexType ( injector . getInstance ( Key . get ( Config . class , GerritServerConfig . class ) ) ) ; < |endfocus| >
public static IndexType getIndexType ( @Nullable Config cfg ) { < |startfocus| > if ( cfg == null ) { return IndexType . LUCENE ; } return cfg . getEnum ( "index" , null , "type" , IndexType . LUCENE ) ; < |endfocus| >
} } CurrentUser getUser ( ) throws QueryRequiresAuthException { try { return self . get ( ) ; } catch ( ProvisionException e ) { throw new QueryRequiresAuthException ( NotSignedInException . MESSAGE , e ) ; } } Schema < ChangeData > getSchema ( ) { return index != null ? index . getSchema ( ) : null ; } } private final Arguments args ; @Inject ChangeQueryBuilder ( Arguments args ) { super ( mydef ) ; this . args = args ; setupDynamicOperators ( ) ; } @VisibleForTesting < |startfocus| > protected ChangeQueryBuilder ( Definition < ChangeData , ? extends QueryBuilder < ChangeData > > def , Arguments args ) { super ( def ) ; < |endfocus| > this . args = args ; } private void setupDynamicOperators ( ) { for ( Extension < ChangeOperatorFactory > e : args . opFactories ) { String name = e . getExportName ( ) + "_" + e . getPluginName ( ) ; opFactories . put ( name , e . getProvider ( ) . get ( ) ) ; } } public Arguments getArgs ( ) { return args ; } public ChangeQueryBuilder asUser ( CurrentUser user ) {
return new RegexPathPredicate ( path ) ; } return new EqualsPathPredicate ( FIELD_PATH , path ) ; } @Operator public Predicate < ChangeData > ext ( String ext ) throws QueryParseException { return extension ( ext ) ; } @Operator public Predicate < ChangeData > extension ( String ext ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . EXTENSION ) ) { < |startfocus| > if ( ext . isEmpty ( ) ) { IndexType indexType = config != null ? config . getEnum ( "index" , null , "type" , IndexType . LUCENE ) : IndexType . LUCENE ; if ( indexType == IndexType . ELASTICSEARCH ) { return new FileWithNoExtensionPredicate ( ) ; } < |endfocus| > } return new FileExtensionPredicate ( ext ) ; } throw new QueryParseException ( "'extension' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > onlyexts ( String extList ) throws QueryParseException { return onlyextensions ( extList ) ; } @Operator public Predicate < ChangeData > onlyextensions ( String extList ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . ONLY_EXTENSIONS ) ) { return new FileExtensionListPredicate ( extList ) ; } throw new QueryParseException (
private final DynamicItem < UrlFormatter > urlFormatter ; private final Optional < Schedule > schedule ; private final long abandonAfter ; private final boolean abandonIfMergeable ; private final String abandonMessage ; @Inject ChangeCleanupConfig ( @GerritServerConfig Config cfg , DynamicItem < UrlFormatter > urlFormatter ) { this . urlFormatter = urlFormatter ; schedule = ScheduleConfig . createSchedule ( cfg , SECTION ) ; abandonAfter = readAbandonAfter ( cfg ) ; < |startfocus| > abandonIfMergeable = cfg . getBoolean ( SECTION , null , KEY_ABANDON_IF_MERGEABLE , false ) ; < |endfocus| > abandonMessage = readAbandonMessage ( cfg ) ; } private long readAbandonAfter ( Config cfg ) { long abandonAfter = ConfigUtil . getTimeUnit ( cfg , SECTION , null , KEY_ABANDON_AFTER , 0 , TimeUnit . MILLISECONDS ) ; return abandonAfter >= 0 ? abandonAfter : 0 ; } private String readAbandonMessage ( Config cfg ) { String abandonMessage = cfg . getString ( SECTION , null , KEY_ABANDON_MESSAGE ) ; return Strings . isNullOrEmpty ( abandonMessage ) ? DEFAULT_ABANDON_MESSAGE : abandonMessage ; } public Optional < Schedule > getSchedule ( ) { return schedule ; } public long getAbandonAfter ( ) { return abandonAfter ; }
Project . NameKey key = projectOperations . newProject ( ) . create ( ) ; ProjectConfig projectConfig = projectOperations . project ( key ) . getProjectConfig ( ) ; ProjectState cachedProjectState1 = projectCache . checkedGet ( key ) ; assertThat ( cachedProjectState1 ) . isNotNull ( ) ; assertThat ( cachedProjectState1 . getProject ( ) . getDescription ( ) ) . isEmpty ( ) ; assertThat ( projectConfig . getProject ( ) . getDescription ( ) ) . isEmpty ( ) ; projectConfig . getProject ( ) . setDescription ( "my fancy project" ) ; < |startfocus| > ProjectState cachedProjectState2 = projectCache . checkedGet ( key ) ; assertThat ( cachedProjectState2 ) . isNotNull ( ) ; assertThat ( cachedProjectState2 . getProject ( ) . getDescription ( ) ) . isEmpty ( ) ; < |endfocus| > } @Test public void getProjectConfigNoRefsMetaConfig ( ) throws Exception { Project . NameKey key = projectOperations . newProject ( ) . create ( ) ; deleteRefsMetaConfig ( key ) ; ProjectConfig projectConfig = projectOperations . project ( key ) . getProjectConfig ( ) ; assertThat ( projectConfig . getName ( ) ) . isEqualTo ( key ) ; assertThat ( projectConfig . getRevision ( ) ) . isNull ( ) ; } @Test public void getConfig ( ) throws Exception { Project . NameKey key = projectOperations . newProject ( ) . create ( ) ;
public IterableSubject sections ( ) { isNotNull ( ) ; < |startfocus| > return check ( "getSections ( ) " ) . that ( config . getSections ( ) ) ; < |endfocus| >
// See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . common ; import static java . lang . annotation . ElementType . FIELD ; import static java . lang . annotation . ElementType . METHOD ; import static java . lang . annotation . ElementType . TYPE ; import static java . lang . annotation . RetentionPolicy . RUNTIME ; import java . lang . annotation . Retention ; import java . lang . annotation . Target ; /* * < |startfocus| > * A marker to say a method / type / field is added or public solely because it is called from inside a * project or an organisation using Gerrit . < |endfocus| > */ @Target ( { METHOD , TYPE , FIELD } ) @Retention ( RUNTIME ) public @interface UsedAt { /* * Enumeration of projects that call a method / type / field . */ enum Project { GOOGLE , PLUGIN_CHECKS , PLUGIN_DELETE_PROJECT , PLUGIN_SERVICEUSER , PLUGINS_ALL , // Use this project if a method / type is generally made available to all plugins . } /* * Reference to the project that uses the method annotated with this annotation . */ Project value ( ) ; }
? NON_EXISTING : REJECTED_OTHER_REASON ; postReplicationFailedEvent ( pushOp , status ) ; if ( pushOp . setToRetry ( ) ) { postReplicationScheduledEvent ( pushOp ) ; pool . schedule ( pushOp , config . getRetryDelay ( ) , TimeUnit . MINUTES ) ; } else { pushOp . canceledByReplication ( ) ; pending . remove ( uri ) ; stateLog . error ( "Push to " + pushOp . getURI ( ) + " cancelled after maximum number of retries" , pushOp . getStatesAsArray ( ) ) ; } break ; } } } } < |startfocus| > boolean requestRunway ( PushOne op ) { < |endfocus| > synchronized ( stateLock ) { if ( op . wasCanceled ( ) ) { return false ; } pending . remove ( op . getURI ( ) ) ; if ( inFlight . containsKey ( op . getURI ( ) ) ) { return false ; } inFlight . put ( op . getURI ( ) , op ) ; } return true ; } void notifyFinished ( PushOne op ) { synchronized ( stateLock ) { inFlight . remove ( op . getURI ( ) ) ; } } boolean wouldPushProject ( Project . NameKey project ) { if ( ! shouldReplicate ( project ) ) {
public class DeleteGpgKey implements RestModifyView < GpgKey , Input > { private static final Logger log = LoggerFactory . getLogger ( DeleteGpgKey . class ) ; public static class Input { } private final Provider < PersonIdent > serverIdent ; private final Provider < PublicKeyStore > storeProvider ; private final ExternalIdsUpdate . User externalIdsUpdateFactory ; private final DeleteKeySender . Factory deleteKeySenderFactory ; @Inject DeleteGpgKey ( @GerritPersonIdent Provider < PersonIdent > serverIdent , Provider < PublicKeyStore > storeProvider , ExternalIdsUpdate . User externalIdsUpdateFactory , < |startfocus| > DeleteKeySender . Factory deleteKeySenderFactory ) { < |endfocus| > this . serverIdent = serverIdent ; this . storeProvider = storeProvider ; this . externalIdsUpdateFactory = externalIdsUpdateFactory ; this . deleteKeySenderFactory = deleteKeySenderFactory ; } @Override public Response < ? > apply ( GpgKey rsrc , Input input ) throws ResourceConflictException , PGPException , OrmException , IOException , ConfigInvalidException { PGPPublicKey key = rsrc . getKeyRing ( ) . getPublicKey ( ) ; externalIdsUpdateFactory . create ( ) . delete ( rsrc . getUser ( ) . getAccountId ( ) , ExternalId . Key . create ( SCHEME_GPGKEY , BaseEncoding . base16 ( ) . encode ( key . getFingerprint ( ) ) ) ) ;
import org . slf4j . LoggerFactory ; @Singleton public class PostGpgKeys implements RestModifyView < AccountResource , Input > { public static class Input { public List < String > add ; public List < String > delete ; } private final Logger log = LoggerFactory . getLogger ( getClass ( ) ) ; private final Provider < PersonIdent > serverIdent ; private final Provider < CurrentUser > self ; private final Provider < PublicKeyStore > storeProvider ; private final GerritPublicKeyChecker . Factory checkerFactory ; private final AddKeySender . Factory addKeyFactory ; < |startfocus| > private final DeleteKeySender . Factory deleteKeySenderFactory ; < |endfocus| > private final Provider < InternalAccountQuery > accountQueryProvider ; private final ExternalIds externalIds ; private final ExternalIdsUpdate . User externalIdsUpdateFactory ; @Inject PostGpgKeys ( @GerritPersonIdent Provider < PersonIdent > serverIdent , Provider < CurrentUser > self , Provider < PublicKeyStore > storeProvider , GerritPublicKeyChecker . Factory checkerFactory , AddKeySender . Factory addKeyFactory , DeleteKeySender . Factory deleteKeySenderFactory , Provider < InternalAccountQuery > accountQueryProvider , ExternalIds externalIds , ExternalIdsUpdate . User externalIdsUpdateFactory ) { this . serverIdent = serverIdent ; this . self = self ;
case NEW : case FAST_FORWARD : case FORCED : if ( ! addedKeys . isEmpty ( ) ) { try { addKeyFactory . create ( user , addedKeys ) . send ( ) ; } catch ( EmailException e ) { log . error ( "Cannot send GPG key added message to " + user . getAccount ( ) . getPreferredEmail ( ) , e ) ; } } if ( ! toRemove . isEmpty ( ) ) { try { < |startfocus| > deleteKeyFactory . create ( user , toRemove . stream ( ) . map ( Fingerprint : : toString ) . collect ( toList ( ) ) ) < |endfocus| > . send ( ) ; } catch ( EmailException e ) { log . error ( "Cannot send GPG key deleted message to " + user . getAccount ( ) . getPreferredEmail ( ) , e ) ; } } break ; case NO_CHANGE : break ; case IO_FAILURE : case LOCK_FAILURE : case NOT_ATTEMPTED : case REJECTED : case REJECTED_CURRENT_BRANCH : case RENAMED : case REJECTED_MISSING_OBJECT : case REJECTED_OTHER_REASON : default : // TODO ( dborowitz ) : Backoff and retry on LOCK_FAILURE .
import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . errors . RepositoryNotFoundException ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; @Singleton public class DeleteSshKey implements RestModifyView < AccountResource . SshKey , Input > { private static final Logger log = LoggerFactory . getLogger ( DeleteSshKey . class ) ; public static class Input { } private final Provider < CurrentUser > self ; private final PermissionBackend permissionBackend ; private final VersionedAuthorizedKeys . Accessor authorizedKeys ; private final SshKeyCache sshKeyCache ; < |startfocus| > private final DeleteKeySender . Factory deleteKeySenderFactory ; < |endfocus| > @Inject DeleteSshKey ( Provider < CurrentUser > self , PermissionBackend permissionBackend , VersionedAuthorizedKeys . Accessor authorizedKeys , SshKeyCache sshKeyCache , DeleteKeySender . Factory deleteKeySenderFactory ) { this . self = self ; this . permissionBackend = permissionBackend ; this . authorizedKeys = authorizedKeys ; this . sshKeyCache = sshKeyCache ; this . deleteKeySenderFactory = deleteKeySenderFactory ; } @Override public Response < ? > apply ( AccountResource . SshKey rsrc , Input input ) throws AuthException , OrmException , RepositoryNotFoundException , IOException , ConfigInvalidException , PermissionBackendException {
import com . google . gerrit . extensions . restapi . AuthException ; import com . google . gerrit . reviewdb . client . AccountSshKey ; import com . google . gerrit . server . IdentifiedUser ; import com . google . gerrit . server . mail . Address ; import com . google . gerrit . server . permissions . GlobalPermission ; import com . google . gerrit . server . permissions . PermissionBackend ; import com . google . gerrit . server . permissions . PermissionBackendException ; import com . google . inject . assistedinject . Assisted ; import com . google . inject . assistedinject . AssistedInject ; import java . util . List ; public class DeleteKeySender extends OutgoingEmail { public interface Factory { DeleteKeySender create ( IdentifiedUser user , AccountSshKey sshKey ) ; < |startfocus| > DeleteKeySender create ( IdentifiedUser user , List < String > gpgKeys ) ; < |endfocus| > } private final PermissionBackend permissionBackend ; private final IdentifiedUser callingUser ; private final IdentifiedUser user ; private final AccountSshKey sshKey ; private final List < String > gpgKeys ; @AssistedInject public DeleteKeySender ( EmailArguments ea , PermissionBackend permissionBackend , IdentifiedUser callingUser , @Assisted IdentifiedUser user , @Assisted AccountSshKey sshKey ) { super ( ea , "deletekey" ) ; this . permissionBackend = permissionBackend ; this . callingUser = callingUser ; this . user = user ; this . sshKey = sshKey ; } @AssistedInject public DeleteKeySender ( EmailArguments ea , PermissionBackend permissionBackend , IdentifiedUser callingUser , @Assisted IdentifiedUser user , @Assisted List < String > gpgKeys ) { super ( ea , "deletekey" ) ; this . permissionBackend = permissionBackend ; this . callingUser = callingUser ; this . user = user ; this . gpgKeys = gpgKeys ; } @Override protected void init ( ) throws EmailException { super . init ( ) ; if ( sshKey != null ) { setHeader ( "Subject" , "SSH key " + sshKey . getSshPublicKey ( ) . getKey ( ) . substring ( 0 , 16 ) + " . . . " + " deleted" ) ; } else { setHeader ( "Subject" , "GPG keys deleted" ) ; } setHeader ( "X - Gerrit - Change - Number" , "n / a" ) ; setHeader ( "X - Gerrit - PatchSet" , "n / a" ) ; setHeader ( "X - Gerrit - Project" , "n / a" ) ; setHeader ( "X - Gerrit - Branch" , "n / a" ) ; setHeader ( "X - Gerrit - MessageType" , "deletekey" ) ; add ( callingUser . getAccount ( ) . getId ( ) ) ; add ( user . getAccount ( ) . getId ( ) ) ; format ( "User % s has deleted the following SSH keys for % s : " , callingUser . getNameEmail ( ) , user . getNameEmail ( ) ) ; if ( sshKey != null ) { format ( " % s" , sshKey . getSshPublicKey ( ) . getKey ( ) ) ; } else { for ( String gpgKey : gpgKeys ) { format ( " % s" , gpgKey ) ; } } } @Override protected void setupSoyContext ( ) { super . setupSoyContext ( ) ; soyContextEmailData . put ( "sshKey" , sshKey ) ; soyContextEmailData . put ( "gpgKeys" , gpgKeys ) ; } @Override protected boolean supportsHtml ( ) { return false ; } @Override protected void populate ( ) throws EmailException { } }
import com . google . gerrit . server . IdentifiedUser ; import com . google . gerrit . server . mail . Address ; import com . google . gerrit . server . permissions . GlobalPermission ; import com . google . gerrit . server . permissions . PermissionBackend ; import com . google . gerrit . server . permissions . PermissionBackendException ; import com . google . inject . assistedinject . Assisted ; import com . google . inject . assistedinject . AssistedInject ; import java . util . List ; public class DeleteKeySender extends OutgoingEmail { public interface Factory { DeleteKeySender create ( IdentifiedUser user , AccountSshKey sshKey ) ; < |startfocus| > DeleteKeySender create ( IdentifiedUser user , List < String > gpgKeyFingeprints ) ; < |endfocus| > } private final PermissionBackend permissionBackend ; private final IdentifiedUser callingUser ; private final IdentifiedUser user ; private final AccountSshKey sshKey ; private final List < String > gpgKeys ; @AssistedInject public DeleteKeySender ( EmailArguments ea , PermissionBackend permissionBackend , IdentifiedUser callingUser , @Assisted IdentifiedUser user , @Assisted AccountSshKey sshKey ) { super ( ea , "deletekey" ) ; this . permissionBackend = permissionBackend ; this . callingUser = callingUser ; this . user = user ; this . gpgKeys = null ; this . sshKey = sshKey ; } @AssistedInject
public DeleteKeySender ( EmailArguments ea , PermissionBackend permissionBackend , IdentifiedUser callingUser , @Assisted IdentifiedUser user , @Assisted AccountSshKey sshKey ) { super ( ea , "deletekey" ) ; this . permissionBackend = permissionBackend ; this . callingUser = callingUser ; this . user = user ; < |startfocus| > this . gpgKeys = Collections . emptyList ( ) ; < |endfocus| > this . sshKey = sshKey ;
public DeleteKeySender ( EmailArguments ea , PermissionBackend permissionBackend , IdentifiedUser callingUser , @Assisted IdentifiedUser user , < |startfocus| > @Assisted List < String > gpgKeys ) { < |endfocus| > super ( ea , "deletekey" ) ; this . permissionBackend = permissionBackend ; this . callingUser = callingUser ; this . user = user ; this . gpgKeys = gpgKeys ; this . sshKey = null ;
public DeleteKeySender ( EmailArguments ea , PermissionBackend permissionBackend , IdentifiedUser callingUser , @Assisted IdentifiedUser user , @Assisted List < String > gpgKey ) { super ( ea , "deletekey" ) ; this . permissionBackend = permissionBackend ; this . callingUser = callingUser ; this . user = user ; < |startfocus| > this . gpgKeys = gpgKey ; < |endfocus| > this . sshKey = null ;
public String getKeyType ( ) { if ( sshKey != null ) { return "SSH" ; } else if ( gpgKeys != null ) { return "GPG" ; } < |startfocus| > throw new IllegalStateException ( "Unknown key type" ) ; < |endfocus| >
< |startfocus| > public String getGpgKeys ( ) { if ( gpgKeyFingeprints != null ) { return Joiner . on ( "\n" ) . join ( gpgKeyFingeprints ) ; < |endfocus| > } return null ;
return TestPermission . builder ( ) . name ( name ) . action ( PermissionRule . Action . ALLOW ) ; } /* * Start a builder for denying a permission . */ public static TestPermission . Builder deny ( String name ) { return TestPermission . builder ( ) . name ( name ) . action ( PermissionRule . Action . DENY ) ; } /* * Start a builder for blocking a permission . */ public static TestPermission . Builder block ( String name ) { return TestPermission . builder ( ) . name ( name ) . action ( PermissionRule . Action . BLOCK ) ; } /* * < |startfocus| > * Records a permission to be updated . < |endfocus| > * * < p > Not used for permissions that have ranges ( label permissions ) or global capabilities . */ @AutoValue public abstract static class TestPermission { private static Builder builder ( ) { return new AutoValue_TestProjectUpdate_TestPermission . Builder ( ) . force ( false ) ; } abstract String name ( ) ; abstract String ref ( ) ; abstract AccountGroup . UUID group ( ) ; abstract PermissionRule . Action action ( ) ; abstract boolean force ( ) ; /* * Builder for { @link TestPermission } . */ @AutoValue . Builder public abstract static class Builder {
*/ @AutoValue public abstract static class TestPermission { private static Builder builder ( ) { return new AutoValue_TestProjectUpdate_TestPermission . Builder ( ) . force ( false ) ; } abstract String name ( ) ; abstract String ref ( ) ; abstract AccountGroup . UUID group ( ) ; abstract PermissionRule . Action action ( ) ; abstract boolean force ( ) ; /* * Builder for { @link TestPermission } . */ @AutoValue . Builder public abstract static class Builder { < |startfocus| > /* * Sets the name of the permission . */ abstract Builder name ( String name ) ; < |endfocus| > /* * Sets the ref pattern used on the permission . */ public abstract Builder ref ( String ref ) ; /* * Sets the group to which the permission applies . */ public abstract Builder group ( AccountGroup . UUID groupUuid ) ; abstract Builder action ( PermissionRule . Action action ) ; /* * Sets whether the permission is a force permission . */ public abstract Builder force ( boolean force ) ; /* * Builds the { @link TestPermission } . */ public abstract TestPermission build ( ) ; } }
public void deleteUserBranch_Conflict ( ) throws Exception { projectOperations . project ( allUsers ) . forUpdate ( ) . add ( TestProjectUpdate . allow ( Permission . CREATE ) . ref ( RefNames . REFS_USERS + " * " ) . group ( REGISTERED_USERS ) ) . add ( TestProjectUpdate . allow ( Permission . PUSH ) . ref ( RefNames . REFS_USERS + " * " ) . group ( REGISTERED_USERS ) ) . update ( ) ; < |startfocus| > allow ( allUsers , RefNames . REFS_USERS + " * " , Permission . CREATE , REGISTERED_USERS ) ; allow ( allUsers , RefNames . REFS_USERS + " * " , Permission . PUSH , REGISTERED_USERS ) ; < |endfocus| > ResourceConflictException thrown = assertThrows ( ResourceConflictException . class , ( ) - > branch ( BranchNameKey . create ( allUsers , RefNames . refsUsers ( admin . id ( ) ) ) ) . delete ( ) ) ; assertThat ( thrown ) . hasMessageThat ( ) . contains ( "Not allowed to delete user branch . " ) ; } @Test public void deleteGroupBranch_Conflict ( ) throws Exception { allow ( allUsers , RefNames . REFS_GROUPS + " * " , Permission . CREATE , REGISTERED_USERS ) ; allow ( allUsers , RefNames . REFS_GROUPS + " * " , Permission . PUSH , REGISTERED_USERS ) ; ResourceConflictException thrown = assertThrows ( ResourceConflictException . class , ( ) - > branch ( BranchNameKey . create ( allUsers , RefNames . refsGroups ( adminGroupUuid ) ) ) . delete ( ) ) ; assertThat ( thrown ) . hasMessageThat ( ) . contains ( "Not allowed to delete group branch . " ) ; }
@NoHttpd public class PluginLoaderIT extends AbstractDaemonTest { Description testDescription ; @Override protected void beforeTest ( Description description ) throws Exception { this . testDescription = description ; } @Override protected void afterTest ( ) throws Exception { } @Test ( expected = MissingMandatoryPluginsException . class ) @GerritConfig ( name = "plugins . mandatory" , value = "my - mandatory - plugin" ) public void shouldFailToStartGerritWhenMandatoryPluginsAreMissing ( ) throws Exception { < |startfocus| > super . beforeTest ( testDescription ) ; < |endfocus| > } }
public void disablePlugins ( Set < String > names ) { if ( ! isRemoteAdminEnabled ( ) ) { logger . atWarning ( ) . log ( "Remote plugin administration is disabled , ignoring disablePlugins ( % s ) " , names ) ; return ; } synchronized ( this ) { for ( String name : names ) { Plugin active = running . get ( name ) ; if ( active == null ) { continue ; } < |startfocus| > if ( mandatoryPlugins . contains ( name ) ) { logger . atWarning ( ) . log ( "Mandatory plugin % s cannot be disabled" , name ) ; continue ; } < |endfocus| > logger . atInfo ( ) . log ( "Disabling plugin % s" , active . getName ( ) ) ; Path off = active . getSrcFile ( ) . resolveSibling ( active . getSrcFile ( ) . getFileName ( ) + " . disabled" ) ; try { Files . move ( active . getSrcFile ( ) , off ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Failed to disable plugin" ) ; // In theory we could still unload the plugin even if the rename // failed . However , it would be reloaded on the next server startup ,
public void disablePlugins ( Set < String > names ) { if ( ! isRemoteAdminEnabled ( ) ) { logger . atWarning ( ) . log ( "Remote plugin administration is disabled , ignoring disablePlugins ( % s ) " , names ) ; return ; } synchronized ( this ) { for ( String name : names ) { Plugin active = running . get ( name ) ; if ( active == null ) { continue ; } < |startfocus| > if ( mandatoryPlugins . contains ( name ) ) { logger . atInfo ( ) . log ( "Mandatory plugin % s cannot be disabled" , name ) ; continue ; } logger . atInfo ( ) . log ( "Disabling plugin % s" , active . getName ( ) ) ; Path off = active . getSrcFile ( ) . resolveSibling ( active . getSrcFile ( ) . getFileName ( ) + " . disabled" ) ; try { Files . move ( active . getSrcFile ( ) , off ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Failed to disable plugin" ) ; // In theory we could still unload the plugin even if the rename // failed . However , it would be reloaded on the next server startup ,
public void setUp ( ) { globalPluginConfig = new Config ( ) ; replicationConfig = new Config ( ) ; } private Configuration getConfiguration ( ) { return new Configuration ( globalPluginConfig , replicationConfig ) ; } @Test public void testGetIndexThreadPoolSize ( ) throws Exception { assertThat ( getConfiguration ( ) . index ( ) . threadPoolSize ( ) ) . isEqualTo ( DEFAULT_THREAD_POOL_SIZE ) ; globalPluginConfig . setInt ( INDEX_SECTION , null , THREAD_POOL_SIZE_KEY , THREAD_POOL_SIZE ) ; assertThat ( getConfiguration ( ) . index ( ) . threadPoolSize ( ) ) . isEqualTo ( THREAD_POOL_SIZE ) ; } < |startfocus| > < |endfocus| > @Test public void testGetIndexSynchronize ( ) throws Exception { assertThat ( getConfiguration ( ) . index ( ) . synchronize ( ) ) . isEqualTo ( DEFAULT_SYNCHRONIZE ) ; globalPluginConfig . setBoolean ( INDEX_SECTION , null , SYNCHRONIZE_KEY , false ) ; assertThat ( getConfiguration ( ) . index ( ) . synchronize ( ) ) . isFalse ( ) ; globalPluginConfig . setBoolean ( INDEX_SECTION , null , SYNCHRONIZE_KEY , true ) ; assertThat ( getConfiguration ( ) . index ( ) . synchronize ( ) ) . isTrue ( ) ; } @Test public void testGetCacheThreadPoolSize ( ) throws Exception { assertThat ( getConfiguration ( ) . cache ( ) . threadPoolSize ( ) ) . isEqualTo ( DEFAULT_THREAD_POOL_SIZE ) ; globalPluginConfig . setInt ( CACHE_SECTION , null , THREAD_POOL_SIZE_KEY , THREAD_POOL_SIZE ) ; assertThat ( getConfiguration ( ) . cache ( ) . threadPoolSize ( ) ) . isEqualTo ( THREAD_POOL_SIZE ) ; }
drainQueue ( droppedEventsQueue ) ; ChangeData change = createChange ( ) . getChange ( ) ; String project = change . project ( ) . get ( ) ; int changeNum = change . getId ( ) . get ( ) ; String changeNotesRef = change . notes ( ) . getRefName ( ) ; int patchsetNum = change . currentPatchSet ( ) . getPatchSetId ( ) ; String patchsetRevision = change . currentPatchSet ( ) . getRevision ( ) . get ( ) ; String patchsetRef = change . currentPatchSet ( ) . getRefName ( ) ; < |startfocus| > Map < String , List < Event > > eventsByType = receiveEventsByType ( droppedEventsQueue ) ; < |endfocus| > assertThat ( eventsByType . get ( "change - index" ) ) . containsExactly ( createChangeIndexEvent ( project , changeNum , getParentCommit ( change ) ) ) ; assertThat ( eventsByType . get ( "ref - updated" ) . stream ( ) . map ( e - > ( ( RefUpdatedEvent ) e ) . getRefName ( ) ) . collect ( toSet ( ) ) ) . containsAllOf ( changeNotesRef , patchsetRef ) ; // 'refs / sequences / changes' not always updated thus not checked List < Event > patchSetCreatedEvents = eventsByType . get ( "patchset - created" ) ; assertThat ( patchSetCreatedEvents ) . hasSize ( 1 ) ; assertPatchSetAttributes ( patchSetCreatedEvents . get ( 0 ) , project , changeNum , patchsetNum , patchsetRevision ) ;
import java . util . Arrays ; import java . util . Collections ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; import java . util . Properties ; import java . util . UUID ; import org . apache . commons . lang . StringUtils ; import org . apache . curator . RetryPolicy ; import org . apache . curator . framework . CuratorFramework ; import org . apache . curator . framework . CuratorFrameworkFactory ; import org . apache . curator . retry . BoundedExponentialBackoffRetry ; import org . apache . kafka . common . serialization . StringSerializer ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . storage . file . FileBasedConfig ; < |startfocus| > import org . eclipse . jgit . util . FS ; < |endfocus| > import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; @Singleton public class Configuration { private static final Logger log = LoggerFactory . getLogger ( Configuration . class ) ; public static final String PLUGIN_NAME = "multi - site" ; static final String INSTANCE_ID_FILE = "instanceId . data" ; // common parameters to cache and index sections static final String THREAD_POOL_SIZE_KEY = "threadPoolSize" ; static final int DEFAULT_INDEX_MAX_TRIES = 2 ; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000 ; static final int DEFAULT_THREAD_POOL_SIZE = 10 ;
< |startfocus| > Copyright ( C ) 2015 The Android Open Source Project < |endfocus| > // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite ; import static com . google . common . base . Suppliers . memoize ; import static com . googlesource . gerrit . plugins . multisite . ConfigurationHelper . getString ; import com . google . common . annotations . VisibleForTesting ; import com . google . common . base . CaseFormat ; import com . google . common . base . Supplier ; import com . google . common . collect . ImmutableMap ; import com . google . gerrit . server . config . SitePaths ; import com . google . inject . Inject ; import com . googlesource . gerrit . plugins . multisite . forwarder . events . EventFamily ; import java . util . HashMap ; import java . util . Map ; import java . util . concurrent . TimeUnit ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . eclipse . jgit . util . FS ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ;
< |startfocus| > Copyright ( C ) 2015 The Android Open Source Project < |endfocus| > // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite ; import static com . google . common . truth . Truth . assertThat ; import static com . googlesource . gerrit . plugins . multisite . Configuration . ENABLE_KEY ; import static com . googlesource . gerrit . plugins . multisite . KafkaConfiguration . KAFKA_PROPERTY_PREFIX ; import static com . googlesource . gerrit . plugins . multisite . KafkaConfiguration . KAFKA_SECTION ; import static com . googlesource . gerrit . plugins . multisite . KafkaConfiguration . KafkaPublisher . KAFKA_PUBLISHER_SUBSECTION ; import static com . googlesource . gerrit . plugins . multisite . KafkaConfiguration . KafkaSubscriber . KAFKA_SUBSCRIBER_SUBSECTION ; import org . eclipse . jgit . lib . Config ; import org . junit . Test ;
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . acceptance . testsuite . project ; import com . google . auto . value . AutoValue ; import com . google . common . collect . ImmutableList ; import com . google . gerrit . acceptance . testsuite . ThrowingConsumer ; import com . google . gerrit . common . data . PermissionRule ; import com . google . gerrit . reviewdb . client . AccountGroup ; @AutoValue public abstract class TestProjectUpdate { < |startfocus| > /* * Starts a builder for allowing a permission . */ < |endfocus| > public static TestPermission . Builder allow ( String name ) { return TestPermission . builder ( ) . name ( name ) . action ( PermissionRule . Action . ALLOW ) ; } /* * Starts a builder for denying a permission . */ public static TestPermission . Builder deny ( String name ) { return TestPermission . builder ( ) . name ( name ) . action ( PermissionRule . Action . DENY ) ; } /* * Starts a builder for blocking a permission . */ public static TestPermission . Builder block ( String name ) { return TestPermission . builder ( ) . name ( name ) . action ( PermissionRule . Action . BLOCK ) ; } /* *
* request , implementations should not deduct tokens from a bucket , yet . */ QuotaResponse requestNoDeduction ( String quotaGroup , QuotaRequestContext ctx , long numTokens ) ; /* * * A previously requested and deducted quota has to be refilled ( if possible ) because the request * failed other quota checks . Implementations can choose to leave this a no - op in case they are * the first line of defence ( e . g . always deduct HTTP quota even if the request failed for other < |startfocus| > * quota issues so that the user gets throttled ) . < |endfocus| > */ void refill ( String quotaGroup , QuotaRequestContext ctx , long numTokens ) ; }
import com . google . gerrit . reviewdb . client . RefNames ; import com . google . gerrit . reviewdb . server . ReviewDb ; import com . google . gerrit . server . GerritPersonIdent ; import com . google . gerrit . server . config . AllUsersName ; import com . google . gerrit . server . git . GitRepositoryManager ; import com . google . gwtorm . server . OrmException ; import com . google . inject . Inject ; import com . google . inject . Provider ; import java . io . IOException ; import java . sql . ResultSet ; import java . sql . SQLException ; import java . sql . Statement ; import java . sql . Timestamp ; import java . util . HashMap ; import java . util . Map ; < |startfocus| > import java . util . logging . Logger ; < |endfocus| > import org . eclipse . jgit . lib . CommitBuilder ; import org . eclipse . jgit . lib . Constants ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . ObjectInserter ; import org . eclipse . jgit . lib . PersonIdent ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . RefUpdate ; import org . eclipse . jgit . lib . RefUpdate . Result ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . revwalk . RevCommit ; import org . eclipse . jgit . revwalk . RevSort ; import org . eclipse . jgit . revwalk . RevWalk ; /* *
String refName = RefNames . refsUsers ( e . getKey ( ) ) ; Ref ref = repo . exactRef ( refName ) ; if ( ref != null ) { rewriteUserBranch ( repo , rw , oi , emptyTree , ref , e . getValue ( ) ) ; } else { createUserBranch ( repo , oi , emptyTree , e . getKey ( ) , e . getValue ( ) ) ; } i ++ ; if ( i % 100 == 0 ) { < |startfocus| > LOG . info ( String . format ( "Migrated % d users to schema 146" , i ) ) ; < |endfocus| > } } } catch ( IOException e ) { throw new OrmException ( "Failed to rewrite user branches . " , e ) ; } } private void rewriteUserBranch ( Repository repo , RevWalk rw , ObjectInserter oi , ObjectId emptyTree , Ref ref , Timestamp registeredOn ) throws IOException { ObjectId current = createInitialEmptyCommit ( oi , emptyTree , registeredOn ) ; rw . reset ( ) ; rw . sort ( RevSort . TOPO ) ; rw . sort ( RevSort . REVERSE , true ) ; rw . markStart ( rw . parseCommit ( ref . getObjectId ( ) ) ) ; RevCommit c ; < |startfocus| > while ( ( c = rw . next ( ) ) != null ) { if ( c . getParentCount ( ) == 0 ) { break ; } if ( c . getParentCount ( ) == 1 ) { current = createCommit ( repo , rw , oi , current , c ) ; } else { current = createMergeCommit ( repo , rw , oi , current , c ) ; } } < |endfocus| >
// and the start ( ) methods of each such listener are executed in the // order they are declared . // Makes sure that PluginLoader . start ( ) is executed before the // LuceneIndexModule . start ( ) so that plugins get loaded and the respective // Guice modules installed so that the on - line reindexing will happen // with the proper classes ( e . g . group backends , custom Prolog // predicates ) and the associated rules ready to be evaluated . modules . add ( new PluginModule ( ) ) ; < |startfocus| > < |endfocus| > modules . add ( new RestApiModule ( ) ) ; modules . add ( new GpgModule ( config ) ) ; modules . add ( new StartupChecks . Module ( ) ) ; // Index module shutdown must happen before work queue shutdown , otherwise // work queue can get stuck waiting on index futures that will never return . modules . add ( createIndexModule ( ) ) ; modules . add ( new WorkQueue . Module ( ) ) ; modules . add ( new GerritInstanceNameModule ( ) ) ; modules . add ( new CanonicalWebUrlModule ( ) { @Override protected Class < ? extends Provider < String > > provider ( ) { return HttpCanonicalWebUrlProvider . class ; } } ) ;
try { u = new URL ( p . substring ( 0 , p . indexOf ( ' ! ' ) ) ) ; } catch ( MalformedURLException e ) { FileNotFoundException fnfe = new FileNotFoundException ( "Not a valid jar file : " + u ) ; fnfe . initCause ( e ) ; throw fnfe ; } } if ( ! "file" . equals ( u . getProtocol ( ) ) ) { throw new FileNotFoundException ( "Cannot extract path from " + u ) ; } < |startfocus| > // Pop up to the top - level source folder by looking for WORKSPACE . < |endfocus| > dir = Paths . get ( u . getPath ( ) ) ; while ( ! Files . isRegularFile ( dir . resolve ( "WORKSPACE" ) ) ) { Path parent = dir . getParent ( ) ; if ( parent == null ) { throw new FileNotFoundException ( "Cannot find source root from " + u ) ; } dir = parent ; } } Path ret = dir . resolve ( name ) ; if ( ! Files . exists ( ret ) ) { throw new FileNotFoundException ( name + " not found in source root " + dir ) ; } return ret ; }
< |startfocus| > protected String getDeleteActions ( Id c ) { if ( ! client . adapter ( ) . useType ( ) ) { return delete ( client . adapter ( ) . getType ( "" ) , c ) ; } return delete ( OPEN_CHANGES , c ) + delete ( CLOSED_CHANGES , c ) ; } < |endfocus| >
private final boolean useV6Type ; private final boolean omitTypeFromSearch ; < |startfocus| > private final String searchFilteringName ; private final String indicesExistParam ; private final String exactFieldType ; private final String stringFieldType ; private final String indexProperty ; private final String versionDiscoveryUrl ; private final String includeTypeNameParam ; ElasticQueryAdapter ( ElasticVersion version ) { this . ignoreUnmapped = false ; this . useType = ! version . isV6OrLater ( ) ; this . useV6Type = version . isV6 ( ) ; this . omitTypeFromSearch = version . isV7OrLater ( ) ; this . versionDiscoveryUrl = version . isV6OrLater ( ) ? " / % s * " : " / % s */ _aliases" ; this . searchFilteringName = "_source" ; this . indicesExistParam = " ? allow_no_indices = false" ; this . exactFieldType = "keyword" ; this . stringFieldType = "text" ; this . indexProperty = "true" ; this . includeTypeNameParam = version . isV6 ( ) ? " ? include_type_name = true" : "" ;
} public static String supportedVersions ( ) { return Joiner . on ( " , " ) . join ( ElasticVersion . values ( ) ) ; } public boolean isV6 ( ) { return isVersion ( 6 ) ; } public boolean isV6OrLater ( ) { return isAtLeastVersion ( 6 ) ; } public boolean isV7OrLater ( ) { return isAtLeastVersion ( 7 ) ; } private boolean isAtLeastVersion ( int v ) { return Integer . valueOf ( version . split ( "\\ . " ) [ 0 ] ) >= v ; } < |startfocus| > private boolean isVersion ( int v ) { return Integer . valueOf ( version . split ( "\\ . " ) [ 0 ] ) == v ; } @Override public String toString ( ) { return version ; } }
RawInputUtil . create ( HTML_PLUGIN . getBytes ( UTF_8 ) ) ; private static final ImmutableList < String > PLUGINS = ImmutableList . of ( "plugin - a . js" , "plugin - b . html" , "plugin - c . js" , "plugin - d . html" , "plugin_e . js" ) ; @Inject private RequestScopeOperations requestScopeOperations ; @Inject private MandatoryPluginsCollection mandatoryPluginsCollection ; @Test @GerritConfig ( name = "plugins . allowRemoteAdmin" , value = "true" ) < |startfocus| > // @GerritConfig ( name = "plugins . mandatory" , value = "plugin_e . js" ) < |endfocus| > public void pluginManagement ( ) throws Exception { // No plugins are loaded assertThat ( list ( ) . get ( ) ) . isEmpty ( ) ; assertThat ( list ( ) . all ( ) . get ( ) ) . isEmpty ( ) ; PluginApi api ; // Install all the plugins InstallPluginInput input = new InstallPluginInput ( ) ; for ( String plugin : PLUGINS ) { input . raw = plugin . endsWith ( " . js" ) ? JS_PLUGIN_CONTENT : HTML_PLUGIN_CONTENT ; api = gApi . plugins ( ) . install ( plugin , input ) ; assertThat ( api ) . isNotNull ( ) ; PluginInfo info = api . get ( ) ;
public TestLabelPermission build ( ) { TestLabelPermission result = autoBuild ( ) ; < |startfocus| > LabelType . checkName ( result . name ( ) ) ; < |endfocus| > return result ;
"queryLimit" , " + 0 . .+ " + DEFAULT_MAX_QUERY_LIMIT + " group global : Registered - Users" ) ; } @Test public void removePermission ( ) throws Exception { Project . NameKey key = projectOperations . newProject ( ) . create ( ) ; projectOperations . project ( key ) . forUpdate ( ) . add ( TestProjectUpdate . allow ( Permission . ABANDON ) . ref ( "refs / foo" ) . group ( REGISTERED_USERS ) ) . update ( ) ; assertThat ( projectOperations . project ( key ) . getConfig ( ) ) . subsectionValues ( "access" , "refs / foo" ) < |startfocus| > . containsKey ( "abandon" ) ; < |endfocus| > projectOperations . project ( key ) . forUpdate ( ) . remove ( TestProjectUpdate . permissionKey ( Permission . ABANDON ) . ref ( "refs / foo" ) . group ( REGISTERED_USERS ) ) . update ( ) ; assertThat ( projectOperations . project ( key ) . getConfig ( ) ) . subsectionValues ( "access" , "refs / foo" ) . doesNotContainKey ( "abandon" ) ; } @Test public void removeLabelPermission ( ) throws Exception { Project . NameKey key = projectOperations . newProject ( ) . create ( ) ; projectOperations . project ( key ) . forUpdate ( ) . add ( TestProjectUpdate . allowLabel ( "Code - Review" )
private void rcpt ( @Nullable RecipientType type , String email , boolean expected ) { if ( recipients . get ( type ) . contains ( email ) != expected ) { failWithoutActual ( fact ( < |startfocus| > expected ? "should notify" : "shouldn't notify" , type + " : " + users . emailToName ( email ) ) ) ; < |endfocus| > } if ( expected ) { accountedFor . add ( email ) ; } }
assertThat ( projectDir . exists ( ) ) . isFalse ( ) ; } @Test @UseLocalDisk public void testSshDeleteProjectWithoutOptions ( ) throws Exception { createChange ( ) ; String cmd = Joiner . on ( " " ) . join ( PLUGIN , "delete" , project . get ( ) ) ; String expected = String . format ( "Really delete ' % s' ? \n" + "This is an operation which permanently deletes data . This cannot be undone ! \n" < |startfocus| > + "If you are sure you wish to delete this project , re - run with the" + " -- yes - really - delete flag . \n\n" , < |endfocus| > project . get ( ) ) ; adminSshSession . exec ( cmd ) ; assertThat ( projectDir . exists ( ) ) . isTrue ( ) ; assertThat ( adminSshSession . getError ( ) ) . isEqualTo ( expected ) ; } @Test @UseLocalDisk public void testSshDeleteProjYesReallyDelete ( ) throws Exception { createChange ( ) ; String cmd = createDeleteCommand ( project . get ( ) ) ; String expected = String . format ( "Project ' % s' has open changes . - To really delete ' % s' , re - run with the -- force"
// // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . schema ; import com . google . common . collect . Iterables ; import com . google . common . collect . Sets ; import com . google . gerrit . reviewdb . client . Account ; < |startfocus| > import com . google . gerrit . reviewdb . client . Account ; < |endfocus| > import com . google . gerrit . reviewdb . client . RefNames ; import com . google . gerrit . reviewdb . server . ReviewDb ; import com . google . gerrit . server . GerritPersonIdent ; import com . google . gerrit . server . config . AllUsersName ; import com . google . gerrit . server . git . GitRepositoryManager ; import com . google . gwtorm . server . OrmException ; import com . google . inject . Inject ; import com . google . inject . Provider ; import java . io . IOException ; import java . sql . ResultSet ; import java . sql . SQLException ; import java . sql . Statement ; import java . sql . Timestamp ; import java . time . Duration ; import java . time . Instant ; import java . util . Date ; import java . util . HashMap ; import java . util . List ;
assertThat ( accountState . getAccount ( ) . getFullName ( ) ) . isEqualTo ( fullName ) ; AccountInfo info = gApi . accounts ( ) . id ( accountId . get ( ) ) . get ( ) ; assertThat ( info . name ) . isEqualTo ( fullName ) ; List < EmailInfo > emails = gApi . accounts ( ) . id ( accountId . get ( ) ) . getEmails ( ) ; assertThat ( emails . stream ( ) . map ( e - > e . email ) . collect ( toSet ( ) ) ) . containsExactly ( extId . email ( ) ) ; RevCommit commitUserBranch = < |startfocus| > projectOperations . project ( allUsers ) . getHead ( RefNames . refsUsers ( accountId ) ) ; < |endfocus| > RevCommit commitRefsMetaExternalIds = projectOperations . project ( allUsers ) . getHead ( RefNames . REFS_EXTERNAL_IDS ) ; assertThat ( commitUserBranch . getCommitTime ( ) ) . isEqualTo ( commitRefsMetaExternalIds . getCommitTime ( ) ) ; } finally { TestTimeUtil . useSystemTime ( ) ; } } @Test public void updateNonExistingAccount ( ) throws Exception { Account . Id nonExistingAccountId = Account . id ( 999999 ) ; AtomicBoolean consumerCalled = new AtomicBoolean ( ) ; Optional < AccountState > accountState = accountsUpdateProvider . get ( ) . update (
projectOperations . project ( allUsers ) . forUpdate ( ) . add ( allow ( Permission . CREATE ) . ref ( RefNames . REFS_USERS + " * " ) . group ( REGISTERED_USERS ) ) . add ( allow ( Permission . PUSH ) . ref ( RefNames . REFS_USERS + " * " ) . group ( REGISTERED_USERS ) ) . update ( ) ; < |startfocus| > projectOperations . project ( allUsers ) . forUpdate ( ) . add ( allow ( Permission . CREATE ) . ref ( RefNames . REFS_USERS + " * " ) . group ( REGISTERED_USERS ) ) . add ( allow ( Permission . PUSH ) . ref ( RefNames . REFS_USERS + " * " ) . group ( REGISTERED_USERS ) ) . update ( ) ; < |endfocus| > ResourceConflictException thrown = assertThrows ( ResourceConflictException . class , ( ) - > branch ( BranchNameKey . create ( allUsers , RefNames . refsUsers ( admin . id ( ) ) ) ) . delete ( ) ) ; assertThat ( thrown ) . hasMessageThat ( ) . contains ( "Not allowed to delete user branch . " ) ; } @Test public void deleteGroupBranch_Conflict ( ) throws Exception { projectOperations . project ( allUsers ) . forUpdate ( ) . add ( allow ( Permission . CREATE ) . ref ( RefNames . REFS_GROUPS + " * " ) . group ( REGISTERED_USERS ) ) . add ( allow ( Permission . PUSH ) . ref ( RefNames . REFS_GROUPS + " * " ) . group ( REGISTERED_USERS ) ) . update ( ) ;
assertThat ( gApi . accounts ( ) . id ( user . username ( ) ) . get ( ) . name ) . isEqualTo ( "User McUserface" ) ; } @Test public void userCannotSetNameOfOtherUser ( ) throws Exception { requestScopeOperations . setApiUser ( user . id ( ) ) ; assertThrows ( AuthException . class , ( ) - > gApi . accounts ( ) . id ( admin . username ( ) ) . setName ( "Admin McAdminface" ) ) ; } @Test @Sandboxed public void userCanSetNameOfOtherUserWithModifyAccountPermission ( ) throws Exception { < |startfocus| > AccountIT . this . projectOperations < |endfocus| > . project ( allProjects ) . forUpdate ( ) . add ( allowCapability ( GlobalCapability . MODIFY_ACCOUNT ) . group ( REGISTERED_USERS ) ) . update ( ) ; gApi . accounts ( ) . id ( admin . username ( ) ) . setName ( "Admin McAdminface" ) ; assertThat ( gApi . accounts ( ) . id ( admin . username ( ) ) . get ( ) . name ) . isEqualTo ( "Admin McAdminface" ) ; } @Test public void fetchUserBranch ( ) throws Exception { requestScopeOperations . setApiUser ( user . id ( ) ) ; TestRepository < InMemoryRepository > allUsersRepo = cloneProject ( allUsers , user ) ; String userRefName = RefNames . refsUsers ( user . id ( ) ) ; // remove default READ permissions < |startfocus| > ReviewDb db = ReviewDbUtil . unwrapDb ( schemaFactory ) ; try ( RepoContext ctx = repoManager . openRepo ( allUsers ) ) { RefUpdate ru = ctx . getRepository ( ) . updateRef ( userRefName ) ; ru . setForceUpdate ( true ) ; assertThat ( ru . delete ( ) ) . isEqualTo ( RefUpdate . Result . FORCED ) ; } < |endfocus| >
metaRef3 , "refs / heads / master" , "refs / tags / master - tag" , "refs / users / 00 / 1000000 / edit - " + cd3 . getId ( ) + " / 1" , "refs / users / 01 / 1000001 / edit - " + cd3 . getId ( ) + " / 1" ) ; } @Test public void uploadPackSubsetOfRefsVisibleWithAccessDatabase ( ) throws Exception { projectOperations . project ( allProjects ) . forUpdate ( ) < |startfocus| > . add ( allowCapability ( GlobalCapability . ACCESS_DATABASE ) . group ( REGISTERED_USERS ) ) < |endfocus| > . add ( deny ( Permission . READ ) . ref ( "refs / heads / master" ) . group ( REGISTERED_USERS ) ) . add ( allow ( Permission . READ ) . ref ( "refs / heads / branch" ) . group ( REGISTERED_USERS ) ) . update ( ) ; requestScopeOperations . setApiUser ( admin . id ( ) ) ; gApi . changes ( ) . id ( cd3 . getId ( ) . get ( ) ) . edit ( ) . create ( ) ; requestScopeOperations . setApiUser ( user . id ( ) ) ; assertUploadPackRefs ( // Change 1 is visible due to accessDatabase capability , even though // refs / heads / master is not . psRef1 , metaRef1 , psRef2 , metaRef2 , psRef3 , metaRef3 , psRef4 , metaRef4 , "refs / users / 00 / 1000000 / edit - " + cd3 . getId ( ) + " / 1" , "refs / users / 01 / 1000001 / edit - " + cd3 . getId ( ) + " / 1" ) ; } @Test public void uploadPackSubsetOfRefsVisibleWithAccessDatabase ( ) throws Exception { projectOperations . project ( allProjects ) . forUpdate ( ) < |startfocus| > . add ( allowCapability ( GlobalCapability . ACCESS_DATABASE ) . group ( REGISTERED_USERS ) ) < |endfocus| > . add ( deny ( Permission . READ ) . ref ( "refs / heads / master" ) . group ( REGISTERED_USERS ) ) . add ( allow ( Permission . READ ) . ref ( "refs / heads / branch" ) . group ( REGISTERED_USERS ) ) . update ( ) ; requestScopeOperations . setApiUser ( admin . id ( ) ) ; gApi . changes ( ) . id ( cd3 . getId ( ) . get ( ) ) . edit ( ) . create ( ) ; requestScopeOperations . setApiUser ( user . id ( ) ) ; assertUploadPackRefs ( // Change 1 is visible due to accessDatabase capability , even though // refs / heads / master is not . psRef1 , metaRef1 , psRef2 , metaRef2 , psRef3 , metaRef3 , psRef4 , metaRef4 ,
ProjectConfig allProjectsConfig = projectConfigFactory . create ( allProjectsName ) ; allProjectsConfig . load ( md ) ; LabelType cr = Util . codeReview ( ) ; allProjectsConfig . getLabelSections ( ) . put ( cr . getName ( ) , cr ) ; allProjectsConfig . commit ( md ) ; } } repoManager . createRepository ( parentKey ) . close ( ) ; repoManager . createRepository ( localKey ) . close ( ) ; try ( MetaDataUpdate md = metaDataUpdateFactory . create ( localKey ) ) { < |startfocus| > ProjectConfig newLocal = projectConfigFactory . create ( localKey ) ; < |endfocus| > newLocal . load ( md ) ; newLocal . getProject ( ) . setParentName ( parentKey ) ; newLocal . commit ( md ) ; } requestContext . setContext ( ( ) - > null ) ; } @After public void tearDown ( ) throws Exception { requestContext . setContext ( null ) ; } @Test public void ownerProject ( ) throws Exception { projectOperations . project ( localKey ) . forUpdate ( ) . add ( allow ( OWNER ) . ref ( "refs /* " ) . group ( ADMIN ) ) . update ( ) ; assertAdminsAreOwnersAndDevsAreNot ( ) ; } @Test public void denyOwnerProject ( ) throws Exception { projectOperations . project ( localKey ) . forUpdate ( )
projectOperations . project ( localKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( "refs / heads /* " ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( "refs / heads / master" , u ) ; } @Test public void unblockMoreSpecificRefInLocal_Fails ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) < |startfocus| > . add ( block ( PUSH ) . ref ( "refs / heads /* " ) . group ( ANONYMOUS_USERS ) ) < |endfocus| > . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( "refs / heads / master" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlag ( ) throws Exception { projectOperations . project ( localKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( "refs / heads /* " ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( "refs / heads / master" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCanUpdate ( "refs / heads / master" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( "refs / heads /* " ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( "refs / heads / master" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( "refs / heads / master" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails2 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( "refs / heads /* " ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( "refs / heads / master" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( "refs / heads / master" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails3 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( "refs / heads /* " ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( "refs / heads / master" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( "refs / heads / master" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails4 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( "refs / heads /* " ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( "refs / heads / master" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( "refs / heads / master" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails5 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( "refs / heads /* " ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( "refs / heads / master" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( "refs / heads / master" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails6 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( "refs / heads /* " ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( "refs / heads / master" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( "refs / heads / master" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails7 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( "refs / heads /* " ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( "refs / heads / master" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( "refs / heads / master" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails8 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( "refs / heads /* " ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( "refs / heads / master" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( "refs / heads / master" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails9 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( "refs / heads /* " ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( "refs / heads / master" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( "refs / heads / master" , u ) ; } @Test public void unblockMoreSpecificRefWithExclusiveFlagInParent_Fails10 ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( "refs / heads /* " ) . group ( ANONYMOUS_USERS ) ) . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( "refs / heads / master" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( "refs / heads / master" , u
assertCanVote ( - 2 , range ) ; } @Test public void unblockFromParentDoesNotAffectChild ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . update ( ) ; projectOperations . project ( localKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) < |startfocus| > . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( "refs / heads / master" ) , true ) < |endfocus| > . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ; assertCannotUpdate ( "refs / heads / master" , u ) ; } @Test public void unblockFromParentDoesNotAffectChildDifferentGroups ( ) throws Exception { projectOperations . project ( parentKey ) . forUpdate ( ) . add ( allow ( PUSH ) . ref ( "refs / heads / master" ) . group ( DEVS ) ) . update ( ) ; projectOperations . project ( localKey ) . forUpdate ( ) . add ( block ( PUSH ) . ref ( "refs / heads / master" ) . group ( ANONYMOUS_USERS ) ) . setExclusiveGroup ( permissionKey ( PUSH ) . ref ( "refs / heads / master" ) , true ) . update ( ) ; ProjectControl u = user ( localKey , DEVS ) ;
package com . google . gerrit . index . query ; import static com . google . common . base . Preconditions . checkNotNull ; import com . google . common . collect . ImmutableList ; import java . util . Iterator ; import java . util . function . Supplier ; /* * * Result set that allows for asynchronous execution of the actual query . Callers should dispatch * the query and call the constructor of this class with a supplier that fetches the result and * blocks on it if necessary . * < |startfocus| > * < p > If the execution is synchronous or the results are know a - priori , consider using { @link < |endfocus| > * ListResultSet } . */ public class LazyResultSet < T > implements ResultSet < T > { private final Supplier < ImmutableList < T > > resultsCallback ; private boolean resultsReturned = false ; public LazyResultSet ( Supplier < ImmutableList < T > > r ) { resultsCallback = checkNotNull ( r , "results can't be null" ) ; } @Override public Iterator < T > iterator ( ) { return toList ( ) . iterator ( ) ; } @Override public ImmutableList < T > toList ( ) { if ( resultsReturned ) { throw new IllegalStateException ( "Results already obtained" ) ; } resultsReturned = true ; return resultsCallback . get ( ) ; } }
public LazyResultSet ( Supplier < ImmutableList < T > > r ) { < |startfocus| > resultsCallback = requireNonNull ( r , "results can't be null" ) ; < |endfocus| >
public ListResultSet ( List < T > r ) { < |startfocus| > results = ImmutableList . copyOf ( requireNonNull ( r , "results can't be null" ) ) ; < |endfocus| >
} @Test public void testCapabilityAllowsZeroRangeOnCapabilityThatHasRange ( ) throws Exception { TestCapability c = allowCapability ( QUERY_LIMIT ) . group ( REGISTERED_USERS ) . range ( 0 , 0 ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 0 ) ; assertThat ( c . max ( ) ) . isEqualTo ( 0 ) ; } @Test public void testCapabilityDisallowsInvertedRange ( ) throws Exception { assertThrows ( RuntimeException . class , < |startfocus| > ( ) - > allowCapability ( ADMINISTRATE_SERVER ) . group ( REGISTERED_USERS ) . range ( 1 , 0 ) . build ( ) ) ; < |endfocus| > } @Test public void testCapabilityDisallowsRangeIfCapabilityDoesNotSupportRange ( ) throws Exception { assertThrows ( RuntimeException . class , ( ) - > allowCapability ( ADMINISTRATE_SERVER ) . group ( REGISTERED_USERS ) . range ( - 1 , 1 ) . build ( ) ) ; } @Test public void testCapabilityRangeIsZeroIfCapabilityDoesNotSupportRange ( ) throws Exception { TestCapability c = allowCapability ( ADMINISTRATE_SERVER ) . group ( REGISTERED_USERS ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 0 ) ; assertThat ( c . max ( ) ) . isEqualTo ( 0 ) ; } @Test public void testCapabilityUsesDefaultRangeIfUnspecified ( ) throws Exception { TestCapability c = allowCapability ( QUERY_LIMIT ) . group ( REGISTERED_USERS ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 0 ) ; assertThat ( c . max ( ) ) . isEqualTo ( Integer . MAX_VALUE ) ; } @Test public void testCapabilityUsesDefaultRangeIfUnspecifiedAndCapabilityDoesNotSupportRange ( ) throws Exception { TestCapability c = allowCapability ( ADMINISTRATE_SERVER ) . group ( REGISTERED_USERS ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 0 ) ; assertThat ( c . max ( ) ) . isEqualTo ( 0 ) ; } @Test public void testCapabilityAllowsRangeIfCapabilitySupportsRange ( ) throws Exception { TestCapability c = allowCapability ( QUERY_LIMIT ) . group ( REGISTERED_USERS ) . range ( 1 , 2 ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 1 ) ; assertThat ( c . max ( ) ) . isEqualTo ( 2 ) ; } @Test public void testCapabilityAllowsRangeIfCapabilitySupportsRangeAndRangeIsZero ( ) throws Exception { TestCapability c = allowCapability ( QUERY_LIMIT ) . group ( REGISTERED_USERS ) . range ( 0 , 0 ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 0 ) ; assertThat ( c . max ( ) ) . isEqualTo ( 0 ) ; } @Test public void testCapabilityAllowsRangeIfCapabilitySupportsRangeAndRangeIsUnbounded ( ) throws Exception { TestCapability c = allowCapability ( QUERY_LIMIT ) . group ( REGISTERED_USERS ) . range ( 0 , Integer . MAX_VALUE ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 0 ) ; assertThat ( c . max ( ) ) . isEqualTo ( Integer . MAX_VALUE ) ; } @Test public void testCapabilityAllowsRangeIfCapabilitySupportsRangeAndRangeIsUnboundedOnBothSides ( ) throws Exception { TestCapability c = allowCapability ( QUERY_LIMIT ) . group ( REGISTERED_USERS ) . range ( Integer . MIN_VALUE , Integer . MAX_VALUE ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( Integer . MIN_VALUE ) ; assertThat ( c . max ( ) ) . isEqualTo ( Integer . MAX_VALUE ) ; } @Test public void testCapabilityAllowsRangeIfCapabilitySupportsRangeAndRangeIsUnboundedOnBothSidesAndRangeIsZero ( ) throws Exception { TestCapability c = allowCapability ( QUERY_LIMIT ) . group ( REGISTERED_USERS ) . range ( 0 , 0 ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 0 ) ; assertThat ( c . max ( ) ) . isEqualTo ( 0 ) ; } @Test public void testCapabilityAllowsRangeIfCapabilitySupportsRangeAndRangeIsUnboundedOnBothSidesAndRangeIsUnbounded ( ) throws Exception { TestCapability c = allowCapability ( QUERY_LIMIT ) . group ( REGISTERED_USERS ) . range ( 0 , Integer . MAX_VALUE ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 0 ) ; assertThat ( c . max ( ) ) . isEqualTo ( Integer . MAX_VALUE ) ; } @Test public void testCapabilityAllowsRangeIfCapabilitySupportsRangeAndRangeIsUnboundedOnBothSidesAndRangeIsUnboundedAndRangeIsZero ( ) throws Exception { TestCapability c = allowCapability ( QUERY_LIMIT ) . group ( REGISTERED_USERS ) . range ( 0 , 0 ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 0 ) ; assertThat ( c . max ( ) ) . isEqualTo ( 0 ) ; } @Test public void testCapabilityAllowsRangeIfCapabilitySupportsRangeAndRangeIsUnboundedOnBothSidesAndRangeIsUnboundedAndRangeIsUnbounded ( ) throws Exception { TestCapability c = allowCapability ( QUERY_LIMIT ) . group ( REGISTERED_USERS ) . range ( 0 , Integer . MAX_VALUE ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 0 ) ; assertThat ( c . max ( ) ) . isEqualTo ( Integer . MAX_VALUE ) ; } @Test public void testCapabilityAllowsRangeIfCapabilitySupportsRangeAndRangeIsUnboundedOnBothSidesAndRangeIsUnboundedAndRangeIsUnboundedAndRangeIsZero ( ) throws Exception { TestCapability c = allowCapability ( QUERY_LIMIT ) . group ( REGISTERED_USERS ) . range ( 0 , 0 ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 0 ) ; assertThat ( c . max ( ) ) . isEqualTo ( 0 ) ; } @Test public void testCapabilityAllowsRangeIfCapabilitySupportsRangeAndRangeIsUnboundedOnBothSidesAndRangeIsUnboundedAndRangeIsUnboundedAndRangeIsUnbounded ( ) throws Exception { TestCapability c = allowCapability ( QUERY_LIMIT ) . group ( REGISTERED_USERS ) . range ( 0 , Integer . MAX_VALUE ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 0 ) ; assertThat ( c . max ( ) ) . isEqualTo ( Integer . MAX_VALUE ) ; } @Test public void testCapabilityAllowsRangeIfCapabilitySupportsRangeAndRangeIsUnboundedOnBothSidesAndRangeIsUnboundedAndRangeIsUnboundedAndRangeIsUnboundedAndRangeIsZero ( ) throws Exception { TestCapability c = allowCapability ( QUERY_LIMIT ) . group ( REGISTERED_USERS ) . range ( 0 , 0 ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 0 ) ; assertThat ( c . max ( ) ) . isEqualTo ( 0 ) ; } @Test public void testCapabilityAllowsRangeIfCapabilitySupportsRangeAndRangeIsUnboundedOnBothSidesAndRangeIsUnboundedAndRangeIsUnboundedAndRangeIsUnboundedAndRangeIsUnbounded ( ) throws Exception { TestCapability c = allowCapability ( QUERY_LIMIT ) . group ( REGISTERED_USERS ) . range ( 0 , Integer . MAX_VALUE ) . build ( ) ; assertThat ( c . min ( ) ) . isEqualTo ( 0 ) ; assertThat ( c . max ( ) ) . isEqualTo (
// limitations under the License . package com . ericsson . gerrit . plugins . highavailability . forwarder . rest ; import com . ericsson . gerrit . plugins . highavailability . cache . Constants ; import com . google . common . base . Strings ; import com . google . common . base . Supplier ; import com . google . gerrit . reviewdb . client . Account ; import com . google . gerrit . reviewdb . client . AccountGroup ; import com . google . gerrit . server . events . Event ; import com . google . gerrit . server . events . EventDeserializer ; import com . google . gerrit . server . events . SupplierDeserializer ; import com . google . gson . Gson ; import com . google . gson . GsonBuilder ; import com . google . inject . Singleton ; @Singleton < |startfocus| > final class GsonParser { private final Gson gson = new GsonBuilder ( ) . registerTypeAdapter ( Event . class , new EventDeserializer ( ) ) . registerTypeAdapter ( Supplier . class , new SupplierDeserializer ( ) ) . create ( ) ; < |endfocus| > public Gson gson ( ) { return gson ; } Object fromJson ( String cacheName , String json ) { Object key ; // Need to add a case for 'adv_bases' switch ( cacheName ) { case Constants . ACCOUNTS : key = gson . fromJson ( Strings . nullToEmpty ( json ) . trim ( ) , Account . Id . class ) ; break ; case Constants . GROUPS : key = gson . fromJson ( Strings . nullToEmpty ( json ) . trim ( ) , AccountGroup . UUID . class ) ; break ; default : key = json ; } return key ; } }
public class BranchCommitValidator { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; private final CommitValidators . Factory commitValidatorsFactory ; private final IdentifiedUser user ; private final PermissionBackend . ForProject permissions ; private final Project project ; private final BranchNameKey branch ; private final SshInfo sshInfo ; interface Factory { BranchCommitValidator create ( ProjectState projectState , BranchNameKey branch , IdentifiedUser user ) ; } /* * A boolean validation status and a list of additional messages . */ @AutoValue < |startfocus| > public static abstract class Result { static Result create ( boolean isValid , List < CommitValidationMessage > messages ) { < |endfocus| > return new AutoValue_BranchCommitValidator_Result ( isValid , messages ) ; } /* * Whether the commit is valid . */ abstract boolean isValid ( ) ; /* * * A list of messages related to the validation . Messages may be present regardless of the * { @link #isValid ( ) } status . */ abstract List < CommitValidationMessage > messages ( ) ; } @Inject BranchCommitValidator ( CommitValidators . Factory commitValidatorsFactory , PermissionBackend permissionBackend , SshInfo sshInfo ,
< |startfocus| > static Result create ( boolean isValid , ImmutableList < CommitValidationMessage > messages ) { < |endfocus| > return new AutoValue_BranchCommitValidator_Result ( isValid , messages ) ;
@AutoValue public static abstract class Result { static Result create ( boolean isValid , List < CommitValidationMessage > messages ) { return new AutoValue_BranchCommitValidator_Result ( isValid , messages ) ; } /* * Whether the commit is valid . */ abstract boolean isValid ( ) ; /* * * A list of messages related to the validation . Messages may be present regardless of the * { @link #isValid ( ) } status . */ < |startfocus| > abstract ImmutableList < CommitValidationMessage > messages ( ) ; < |endfocus| > } @Inject BranchCommitValidator ( CommitValidators . Factory commitValidatorsFactory , PermissionBackend permissionBackend , SshInfo sshInfo , @Assisted ProjectState projectState , @Assisted BranchNameKey branch , @Assisted IdentifiedUser user ) { this . sshInfo = sshInfo ; this . user = user ; this . branch = branch ; this . commitValidatorsFactory = commitValidatorsFactory ; project = projectState . getProject ( ) ; permissions = permissionBackend . user ( user ) . project ( project . getNameKey ( ) ) ; } /* * * Validates a single commit . If the commit does not validate , the command is rejected . *
if ( args . getSchema ( ) . hasField ( ChangeField . EXTENSION ) ) { FileExtensionPredicate extensionPredicate = new FileExtensionPredicate ( ext ) ; if ( ext . isEmpty ( ) ) { RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate ( " ^ . { 0 } $" ) ; // RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate ( " ^ ( ) $" ) ; // cf . https :/ / www . brics . dk / automaton / doc / index . html ? dk / brics / automaton / RegExp . html return emptyExtPredicate ; // return Predicate . or ( extensionPredicate , emptyExtPredicate ) ; } < |startfocus| > return extensionPredicate ; < |endfocus| > } throw new QueryParseException ( "'extension' operator is not supported by change index version" ) ; } @Operator public Predicate < ChangeData > onlyexts ( String extList ) throws QueryParseException { return onlyextensions ( extList ) ; } @Operator public Predicate < ChangeData > onlyextensions ( String extList ) throws QueryParseException { if ( args . getSchema ( ) . hasField ( ChangeField . ONLY_EXTENSIONS ) ) { return new FileExtensionListPredicate ( extList ) ; } throw new QueryParseException ( "'onlyextensions' operator is not supported by change index version" ) ; } @Operator
ChecksCollection ( Checks checks , DynamicMap < RestView < CheckResource > > views , ListChecks listChecks ) { this . checks = checks ; this . views = views ; this . listChecks = listChecks ; } @Override public RestReadView < RevisionResource > list ( ) throws RestApiException { return listChecks ; } @Override public CheckResource parse ( RevisionResource parent , IdString id ) throws RestApiException , PermissionBackendException , IOException , StorageException { if ( parent . getEdit ( ) . isPresent ( ) ) { < |startfocus| > throw new ResourceConflictException ( "checks are not supported on an edit" ) ; < |endfocus| > } CheckerUuid checkerUuid = CheckerUuid . tryParse ( id . get ( ) ) . orElseThrow ( ( ) - > new BadRequestException ( String . format ( "invalid checker UUID : % s" , id . get ( ) ) ) ) ; CheckKey checkKey = CheckKey . create ( parent . getProject ( ) , parent . getPatchSet ( ) . id ( ) , checkerUuid ) ; Optional < Check > check = checks . getCheck ( checkKey , GetCheckOptions . withBackfilling ( ) ) ; return new CheckResource ( parent , check . orElseThrow ( ( ) - > new ResourceNotFoundException ( String . format (
@Inject Schema_146 ( Provider < Schema_145 > prior , GitRepositoryManager repoManager , AllUsersName allUsersName , @GerritPersonIdent PersonIdent serverIdent ) { super ( prior ) ; this . repoManager = repoManager ; this . allUsersName = allUsersName ; this . serverIdent = serverIdent ; } @Override protected void migrateData ( ReviewDb db , UpdateUI ui ) throws OrmException , SQLException { ui . message ( "Migrating accounts" ) ; < |startfocus| > Set < Entry < Account . Id , Timestamp > > accounts = scanAccounts ( db , ui ) . entrySet ( ) ; < |endfocus| > gc ( ui ) ; Set < List < Entry < Account . Id , Timestamp > > > batches = Sets . newHashSet ( Iterables . partition ( accounts , 500 ) ) ; ExecutorService pool = createExecutor ( ui ) ; try { batches . stream ( ) . forEach ( batch - > pool . submit ( ( ) - > processBatch ( batch , ui ) ) ) ; pool . shutdown ( ) ; pool . awaitTermination ( Long . MAX_VALUE , TimeUnit . DAYS ) ; } catch ( InterruptedException e ) { throw new RuntimeException ( e ) ; } ui . message ( String . format ( " . . . ( % . 3f s ) Migrated all % d accounts to schema 146" , elapsed ( ) , i . get ( ) ) ) ; }
return CacheBuilder . newBuilder ( ) . maximumSize ( 1 < < 10 ) . expireAfterWrite ( 30 , TimeUnit . MINUTES ) ; } public VisibilityCache ( boolean topoSort ) { this ( topoSort , defaultBuilder ( ) ) ; } public VisibilityCache ( boolean topoSort , CacheBuilder < Object , Object > builder ) { this ( new VisibilityChecker ( topoSort ) , builder ) ; } /* * * Use the constructors with a boolean parameter ( e . g . { @link #VisibilityCache ( boolean ) } ) . The < |startfocus| > * default visibility checker should cover all common use cases . < |endfocus| > * * < p > This constructor is useful to set e . g . an instrumented checker . */ public VisibilityCache ( VisibilityChecker checker ) { this ( checker , defaultBuilder ( ) ) ; } /* * * Use the constructors with a boolean parameter ( e . g . { @link #VisibilityCache ( boolean ) } ) . The * default visibility checker should cover all common use cases . * * < p > This constructor is useful to set e . g . an instrumented checker . */ public VisibilityCache ( VisibilityChecker checker , CacheBuilder < Object , Object > builder ) { this . cache = builder . build ( ) ;
import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . RefDatabase ; import org . eclipse . jgit . revwalk . RevCommit ; import org . eclipse . jgit . revwalk . RevSort ; import org . eclipse . jgit . revwalk . RevWalk ; /* * * Checks for object visibility * * < p > Objects are visible if they are reachable from any of the references visible to the user . */ public class VisibilityChecker { private boolean topoSort ; < |startfocus| > /* * @param topoSort whether to use a more thorough reachability check * by sorting in topological order */ < |endfocus| > public VisibilityChecker ( boolean topoSort ) { this . topoSort = topoSort ; } /* * * Check if any of the refs in { @code refDb } points to the object { @code id } . * * @param refDb a reference database * @param id object we are looking for * @return true if the any of the references in the db points directly to the id * @throws IOException the reference space cannot be accessed */
import org . junit . Before ; import org . junit . Test ; import org . junit . runner . RunWith ; import org . junit . runners . JUnit4 ; @RunWith ( JUnit4 . class ) public class VisibilityCacheTest { private InMemoryRepository repo ; private GitilesAccess access = new FakeGitilesAccess ( ) ; private RevCommit baseCommit ; private RevCommit commit1 ; private RevCommit commit2 ; private RevCommit commitA ; private RevCommit commitB ; private RevCommit commitC ; private VisibilityCache visibilityCache ; private RevWalk walk ; @Before < |startfocus| > public void setUp ( ) throws Exception { < |endfocus| > repo = new InMemoryRepository ( new DfsRepositoryDescription ( ) ) ; TestRepository < InMemoryRepository > git = new TestRepository < > ( repo ) ; baseCommit = git . commit ( ) . message ( "baseCommit" ) . create ( ) ; commit1 = git . commit ( ) . parent ( baseCommit ) . message ( "commit1" ) . create ( ) ; commit2 = git . commit ( ) . parent ( commit1 ) . message ( "commit2" ) . create ( ) ; commitA = git . commit ( ) . parent ( baseCommit ) . message ( "commitA" ) . create ( ) ; commitB = git . commit ( ) . parent ( commitA ) . message ( "commitB" ) . create ( ) ; commitC = git . commit ( ) . parent ( commitB ) . message ( "commitC" ) . create ( ) ;
public void diffOfNonExistentFileIsAnEmptyDiffResult ( ) throws Exception { addModifiedPatchSet ( changeId , FILE_NAME , content - > content . replace ( "Line 2\n" , "Line two\n" ) ) ; DiffInfo diffInfo = getDiffRequest ( changeId , CURRENT , "a_non - existent_file . txt" ) . withBase ( initialPatchSetId ) . withContext ( DiffPreferencesInfo . WHOLE_FILE_CONTEXT ) . get ( ) ; assertThat ( diffInfo ) . content ( ) . isEmpty ( ) ; } < |startfocus| > // This behavior is likely a bug . A fix might not be easy as it might break syntax highlighting . < |endfocus| > @Test public void contextParameterIsIgnored ( ) throws Exception { addModifiedPatchSet ( changeId , FILE_NAME , content - > content . replace ( "Line 20\n" , "Line twenty\n" ) ) ; DiffInfo diffInfo = getDiffRequest ( changeId , CURRENT , FILE_NAME ) . withBase ( initialPatchSetId ) . withContext ( 5 ) . get ( ) ; assertThat ( diffInfo ) . content ( ) . element ( 0 ) . commonLines ( ) . hasSize ( 19 ) ; assertThat ( diffInfo ) . content ( ) . element ( 1 ) . linesOfA ( ) . containsExactly ( "Line 20" ) ; < |startfocus| > // TODO : Add "TODO" in these comments ? < |endfocus| >
package com . ericsson . gerrit . plugins . highavailability . forwarder . rest ; import com . ericsson . gerrit . plugins . highavailability . cache . Constants ; import com . google . common . base . Strings ; import com . google . gerrit . reviewdb . client . Account ; import com . google . gerrit . reviewdb . client . AccountGroup ; import com . google . gson . Gson ; import com . google . gson . JsonElement ; import com . google . gson . JsonObject ; import com . google . inject . Inject ; import com . google . inject . Singleton ; @Singleton class GsonParser { private final Gson gson ; @Inject < |startfocus| > GsonParser ( GsonProvider gson ) { this . gson = gson . get ( ) ; < |endfocus| > } public Object fromJson ( String cacheName , String jsonString ) { JsonElement json = gson . fromJson ( Strings . nullToEmpty ( jsonString ) , JsonElement . class ) ; Object key ; // Need to add a case for 'adv_bases' if ( ! json . isJsonObject ( ) ) { return json . getAsString ( ) ; } JsonObject asJsonObject = json . getAsJsonObject ( ) ; switch ( cacheName ) { case Constants . ACCOUNTS : key = asJsonObject . has ( "id" ) ? Account . id ( asJsonObject . get ( "id" ) . getAsInt ( ) ) : null ; break ;
* file constructed to trigger excessive backtracking . */ public class CheckConfig { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; public static final String toolName = "check_new_config" ; private static final String ACCESS = "access" ; private static final String LABEL = "label" ; private static final String PLUGIN = "plugin" ; private static final int BUFFER_SIZE = 2048 ; < |startfocus| > private static final char [ ] BUFFER = new char [ BUFFER_SIZE ] ; < |endfocus| > private String pluginName ; private Config configProject ; ScannerConfig scannerConfig ; public CheckConfig ( String pluginName , String projectConfigContents ) throws ConfigInvalidException { this . pluginName = pluginName ; configProject = new Config ( ) ; configProject . fromText ( projectConfigContents ) ; Config config = new Config ( ) ; for ( String name : configProject . getNames ( PLUGIN , pluginName ) ) { config . setStringList ( PLUGIN , pluginName , name , Arrays . asList ( configProject . getStringList ( PLUGIN , pluginName , name ) ) ) ; } PluginConfig pluginConfig = new PluginConfig ( pluginName , config ) ;
* file constructed to trigger excessive backtracking . */ public class CheckConfig { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; public static final String toolName = "check_new_config" ; private static final String ACCESS = "access" ; private static final String LABEL = "label" ; private static final String PLUGIN = "plugin" ; private static final int BUFFER_SIZE = 2048 ; private static final char [ ] BUFFER = new char [ BUFFER_SIZE ] ; < |startfocus| > private String pluginName ; < |endfocus| > private Config configProject ; ScannerConfig scannerConfig ; public CheckConfig ( String pluginName , String projectConfigContents ) throws ConfigInvalidException { this . pluginName = pluginName ; configProject = new Config ( ) ; configProject . fromText ( projectConfigContents ) ; Config config = new Config ( ) ; for ( String name : configProject . getNames ( PLUGIN , pluginName ) ) { config . setStringList ( PLUGIN , pluginName , name , Arrays . asList ( configProject . getStringList ( PLUGIN , pluginName , name ) ) ) ; } PluginConfig pluginConfig = new PluginConfig ( pluginName , config ) ;
* * < p > When a new commit alters the configured scanner patterns , the push will fail with a message * to download the plugin source , to run a shell script that runs { @code main } below , and to copy * the output on success into the commit message . * * < p > This method scans the commit message to find the copied text . If the text was created for < |startfocus| > * the same pattern signagure , this method returns a single valid finding with the number of < |endfocus| > * microseconds it took to scan a large file , which can be used to block patterns that cause * excessive backtracking . * * < p > If the commit message contains one or more copied texts for other pattern signatures , this * method retuns an invalid finding for each . * * < p > If the commit message contains no copied texts , this method returns an empty list of * findings , which { @link com . googlesource . gerrit . plugins . copyright . CopyrightConfig } uses as a
import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Constants ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . ObjectLoader ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . revwalk . RevTree ; import org . eclipse . jgit . revwalk . RevWalk ; import org . eclipse . jgit . treewalk . TreeWalk ; /* * Listener to manage configuration for enforcing review of copyright declarations and licenses . */ @Singleton class CopyrightConfig implements CommitValidationListener , RevisionCreatedListener , GitReferenceUpdatedListener { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; < |startfocus| > < |endfocus| > private final long DEFAULT_MAX_ELAPSED_SECONDS = 8 ; private final Metrics metrics ; private final AllProjectsName allProjectsName ; private final String pluginName ; private final GitRepositoryManager repoManager ; private final ProjectCache projectCache ; private final PluginConfigFactory pluginConfigFactory ; private final CopyrightReviewApi reviewApi ; private PluginConfig gerritConfig ; private CheckConfig checkConfig ; static AbstractModule module ( ) { return new AbstractModule ( ) { @Override protected void configure ( ) { DynamicSet . bind ( binder ( ) , CommitValidationListener . class ) . to ( CopyrightConfig . class ) ; < |startfocus| > < |endfocus| >
if ( ! event . getRefName ( ) . equals ( RefNames . REFS_CONFIG ) ) { return ; } if ( ! event . getProjectName ( ) . equals ( allProjectsName . get ( ) ) ) { return ; } long nanoStart = System . nanoTime ( ) ; try { clearConfig ( ) ; checkConfig = readConfig ( event . getNewObjectId ( ) ) ; } catch ( IOException | ConfigInvalidException e ) { logger . atSevere ( ) . withCause ( e ) . log ( " % s plugin unable to load configuration" , pluginName ) ; checkConfig = null ; return ; } finally { long elapsedMicros = ( System . nanoTime ( ) - nanoStart ) / 1000 ; metrics . readConfigTimer . record ( elapsedMicros , TimeUnit . MICROSECONDS ) ; }
" % s plugin revision % s : error posting review : % s" , pluginName , event . getChange ( ) . currentRevision , result . error ) ; } for ( Map . Entry < String , AddReviewerResult > entry : result . reviewers . entrySet ( ) ) { AddReviewerResult arr = entry . getValue ( ) ; if ( ! Strings . isNullOrEmpty ( arr . error ) ) { logger . atSevere ( ) . log ( " % s plugin revision % s : error adding reviewer % s : % s" , pluginName , event . getChange ( ) . currentRevision , entry . getKey ( ) , arr . error ) ; } }
* * @throws RestApiException if an error occurs updating the review thread */ private ReviewResult review ( ChangeResource change , ReviewInput ri ) throws RestApiException { try { PatchSet ps = psUtil . current ( change . getNotes ( ) ) ; if ( ps == null ) { throw new ResourceNotFoundException ( IdString . fromDecoded ( "current" ) ) ; } RevisionResource revision = RevisionResource . createNonCacheable ( change , ps ) ; return postReview . apply ( revision , ri ) . value ( ) ; } catch ( Exception e ) { Throwables . throwIfUnchecked ( e ) ; throw e instanceof RestApiException < |startfocus| > ? ( RestApiException ) e : new RestApiException ( "Cannot post review" , e ) ; < |endfocus| > } } /* * Returns true if { @code priorComments } already includes a comment identical to { @code ci } . */ @VisibleForTesting boolean containsComment ( Iterable < ? extends Comment > priorComments , CommentInput ci ) { if ( priorComments == null ) { return false ; } for ( Comment prior : priorComments ) { if ( Objects . equals ( prior . line , ci . line ) {
* @param event describes the newly created revision triggering the scan * @throws IOException if an error occurred reading the repository * @throws RestApiException if an error occured reporting findings to the review thread */ private void scanRevision ( String project , String branch , RevisionCreatedListener . Event event ) throws IOException , RestApiException { Map < String , ImmutableList < Match > > findings = new HashMap < > ( ) ; ArrayList < String > containedPaths = new ArrayList < > ( ) ; long scanStart = System . nanoTime ( ) ; < |startfocus| > metrics . scanCountByProject . increment ( project ) ; < |endfocus| > metrics . scanCountByBranch . increment ( branch ) ; try ( Repository repo = repoManager . openRepository ( Project . nameKey ( project ) ) ; RevWalk revWalk = new RevWalk ( repo ) ; TreeWalk tw = new TreeWalk ( revWalk . getObjectReader ( ) ) ) { RevCommit commit = repo . parseCommit ( ObjectId . fromString ( event . getRevision ( ) . commit . commit ) ) ; tw . setRecursive ( true ) ; tw . setFilter ( TreeFilter . ANY_DIFF ) ; tw . addTree ( commit . getTree ( ) ) ; if ( commit . getParentCount ( ) > 0 ) {
import com . google . gerrit . server . git . validators . ValidationMessage ; import com . google . gerrit . server . project . ProjectConfig ; import com . googlesource . gerrit . plugins . copyright . lib . CopyrightPatterns ; import com . googlesource . gerrit . plugins . copyright . lib . CopyrightPatterns . UnknownPatternName ; import com . googlesource . gerrit . plugins . copyright . lib . CopyrightScanner ; import java . util . ArrayList ; import java . util . Collection ; import java . util . LinkedHashSet ; import java . util . Objects ; import java . util . function . Consumer ; import java . util . regex . Pattern ; import java . util . regex . PatternSyntaxException ; < |startfocus| > /* * Configuration state for { @link CopyrightValidator } . */ < |endfocus| > class ScannerConfig { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; public static final String KEY_ENABLE = "enable" ; static final String KEY_TIME_TEST_MAX = "timeTestMax" ; static final String DEFAULT_REVIEW_LABEL = "Copyright - Review" ; static final String KEY_REVIEWER = "reviewer" ; static final String KEY_CC = "cc" ; static final String KEY_FROM = "fromAccountId" ; static final String KEY_REVIEW_LABEL = "reviewLabel" ; static final String KEY_EXCLUDE = "exclude" ; < |startfocus| > /* * * The state of the scanner . */ < |endfocus| > enum State { /* * * The scanner is disabled . */ DISABLED , /* * * The scanner is enabled . */ ENABLED , /* * * The scanner is enabled , but the configuration is invalid . */ INVALID }
public boolean isV6 ( ) { return isVersion ( 6 ) ; } public boolean isV6OrLater ( ) { return isAtLeastVersion ( 6 ) ; } public boolean isV7OrLater ( ) { return isAtLeastVersion ( 7 ) ; } private boolean isAtLeastVersion ( int v ) { return Integer . valueOf ( version . split ( "\\ . " ) [ 0 ] ) >= v ; } < |startfocus| > private boolean isVersion ( int v ) { return Integer . valueOf ( version . split ( "\\ . " ) [ 0 ] ) == v ; < |endfocus| > } @Override public String toString ( ) { return version ; } }
boolean oldForceLogging = loggingCtx . isLoggingForced ( ) ; boolean oldPerformanceLogging = loggingCtx . isPerformanceLogging ( ) ; ImmutableList < PerformanceLogRecord > oldPerformanceLogRecords = loggingCtx . getPerformanceLogEntries ( ) ; loggingCtx . setTags ( tags ) ; loggingCtx . forceLogging ( forceLogging ) ; loggingCtx . performanceLogging ( performanceLogging ) ; loggingCtx . setPerformanceLogEntries ( performanceLogRecords ) ; try { runnable . run ( ) ; } finally { loggingCtx . setTags ( oldTags ) ; loggingCtx . forceLogging ( oldForceLogging ) ; loggingCtx . performanceLogging ( oldPerformanceLogging ) ; < |startfocus| > loggingCtx . setPerformanceLogEntries ( oldPerformanceLogRecords ) ; < |endfocus| > } } }
public void close ( ) { if ( LoggingContext . getInstance ( ) . isPerformanceLogging ( ) ) { runEach ( performanceLoggers , LoggingContext . getInstance ( ) . getPerformanceLogEntries ( ) ) ; } // Restore old state . LoggingContext . getInstance ( ) . performanceLogging ( oldPerformanceLogging ) ; < |startfocus| > LoggingContext . getInstance ( ) . setPerformanceLogEntries ( oldPerformanceLogRecords ) ; < |endfocus| >
. forUpdate ( ) . add ( allow ( Permission . READ ) . ref ( "refs /* " ) . group ( REGISTERED_USERS ) ) . add ( allow ( Permission . READ ) . ref ( RefNames . REFS_CONFIG ) . group ( REGISTERED_USERS ) ) . update ( ) ; assertUploadPackRefs ( "HEAD" , psRef1 , metaRef1 , psRef2 , metaRef2 , psRef3 , metaRef3 , psRef4 , metaRef4 , "refs / heads / branch" , "refs / heads / master" , RefNames . REFS_CONFIG , "refs / tags / branch - tag" , < |startfocus| > "refs / tags / master - tag" ) ; < |endfocus| > } @Test public void uploadPackSubsetOfBranchesVisibleIncludingHead ( ) throws Exception { projectOperations . project ( project ) . forUpdate ( ) . add ( allow ( Permission . READ ) . ref ( "refs / heads / master" ) . group ( REGISTERED_USERS ) ) . add ( deny ( Permission . READ ) . ref ( "refs / heads / branch" ) . group ( REGISTERED_USERS ) ) . update ( ) ; requestScopeOperations . setApiUser ( user . id ( ) ) ; assertUploadPackRefs ( "HEAD" , psRef1 , metaRef1 , psRef3 , metaRef3 , "refs / heads / master" , "refs / tags / master - tag" ) ; } @Test
metaRef4 , "refs / heads / branch" , "refs / heads / master" , RefNames . REFS_CONFIG , "refs / tags / branch - tag" , "refs / tags / master - tag" ) ; } @Test public void uploadPackSubsetOfBranchesVisibleIncludingHead ( ) throws Exception { projectOperations . project ( project ) . forUpdate ( ) . add ( allow ( Permission . READ ) . ref ( "refs / heads / master" ) . group ( REGISTERED_USERS ) ) . add ( deny ( Permission . READ ) . ref ( "refs / heads / branch" ) . group ( REGISTERED_USERS ) ) . update ( ) ; requestScopeOperations . setApiUser ( user . id ( ) ) ; assertUploadPackRefs ( < |startfocus| > "HEAD" , psRef1 , metaRef1 , psRef3 , metaRef3 , "refs / heads / master" , "refs / tags / master - tag" ) ; < |endfocus| > } @Test public void uploadPackSubsetOfBranchesVisibleNotIncludingHead ( ) throws Exception { projectOperations . project ( project ) . forUpdate ( ) . add ( deny ( Permission . READ ) . ref ( "refs / heads / master" ) . group ( REGISTERED_USERS ) ) . add ( allow ( Permission . READ ) . ref ( "refs / heads / branch" ) . group ( REGISTERED_USERS ) ) . update ( ) ; requestScopeOperations . setApiUser ( user . id ( ) ) ; assertUploadPackRefs ( psRef2 , metaRef2 ,
// // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . readonly ; import static com . google . common . truth . Truth . assertThat ; import com . google . gerrit . acceptance . RestResponse ; import com . google . gerrit . server . config . GerritServerConfig ; < |startfocus| > import com . google . gerrit . testing . ConfigSuite ; < |endfocus| > import com . google . inject . Inject ; import org . eclipse . jgit . lib . Config ; public class ReadOnlyByHttpIT extends AbstractReadOnlyTest { @ConfigSuite . Default public static Config withPluginNamePrefix ( ) { Config cfg = new Config ( ) ; cfg . setString ( "readonly" , "test" , "endpoint" , "readonly~readonly" ) ; return cfg ; } @ConfigSuite . Config public static Config withoutPluginNamePrefix ( ) { Config cfg = new Config ( ) ; cfg . setString ( "readonly" , "test" , "endpoint" , "readonly" ) ; return cfg ; }
} else if ( input . httpPassword == null ) { newPassword = null ; } else { // Only administrators can explicitly set the password . permissionBackend . currentUser ( ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; newPassword = input . httpPassword ; } return apply ( rsrc . getUser ( ) , newPassword ) ; } // Used by the admin console plugin // TODO ( dpursehouse ) : Replace comment with @UsedAt public Response < String > apply ( IdentifiedUser user , String newPassword ) < |startfocus| > throws ResourceNotFoundException , ResourceConflictException , OrmException , IOException , < |endfocus| > ConfigInvalidException { String userName = user . getUserName ( ) . orElseThrow ( ( ) - > new ResourceConflictException ( "username must be set" ) ) ; Optional < ExternalId > optionalExtId = externalIds . get ( ExternalId . Key . create ( SCHEME_USERNAME , userName ) ) ; ExternalId extId = optionalExtId . orElseThrow ( ResourceNotFoundException : : new ) ; accountsUpdateProvider . get ( ) . update ( "Set HTTP Password via API" , extId . accountId ( ) , u - > u . updateExternalId ( ExternalId . createWithPassword (
// included : pA : d2 / OWNERS , pA : d2 / . ./ f1 , pA : d1 / f1 // inherited : pA : OWNERS String owners = "owners : [ " + concat ( ownerJson ( "pAd1f1@g" ) , " , " ) + concat ( ownerJson ( "pAd2@g" ) , " , " ) + concat ( ownerJson ( "pAf1@g" ) , " , " ) < |startfocus| > + concat ( ownerJson ( "pA@g" , 0 , 1 , 0 ) , " ] " ) ; < |endfocus| > assertThat ( getOwnersResponse ( c1 ) ) . contains ( owners ) ; } }
private void handleGitReferenceUpdatedAsUser ( Event event , Account . Id updaterAccountId ) { try ( ManualRequestContext ctx = oneOffReqCtx . openAs ( updaterAccountId ) ) { handleGitReferenceUpdated ( event ) ; } catch ( OrmException e ) { < |startfocus| > logger . warn ( "Unable to process event { } on project { } " , event , event . getProjectName ( ) , e ) ; < |endfocus| > }
public void onGitReferenceUpdated ( Event event ) { AccountInfo updaterAccountInfo = event . getUpdater ( ) ; CurrentUser currentUser = currentUserProvider . get ( ) ; if ( currentUser . isIdentifiedUser ( ) ) { handleGitReferenceUpdated ( event ) ; } else if ( updaterAccountInfo != null ) { < |startfocus| > handleGitReferenceUpdatedAsUser ( event , new Account . Id ( updaterAccountInfo . _accountId ) ) ; } else { handleGitReferenceUpdatedAsAnonymous ( event ) ; < |endfocus| > }
// For the performance log records use the list instance from the logging context of the calling // thread in the logging context of the new thread . This way performance log records that are // created from the new thread are available from the logging context of the calling thread . // This is important since performance log records are processed only at the end of the request // and performance log records that are created in another thread should not get lost . < |startfocus| > loggingCtx . setMutablePerformanceLogRecordList ( mutablePerformanceLogRecords ) ; < |endfocus| > try { return callable . call ( ) ; } finally { loggingCtx . setTags ( oldTags ) ; loggingCtx . forceLogging ( oldForceLogging ) ; loggingCtx . performanceLogging ( oldPerformanceLogging ) ; loggingCtx . setPerformanceLogRecords ( oldPerformanceLogRecords ) ; } } }
. setRate ( ) . setUnit ( "errors" ) , project ) ; errors = metricMaker . newCounter ( "error_count" , new Description ( "Number of errors of any kind" ) . setRate ( ) . setUnit ( "errors" ) ) ; } } @Inject CopyrightConfig ( Metrics metrics , AllProjectsName allProjectsName , @PluginName String pluginName , GitRepositoryManager repoManager , ProjectCache projectCache , PluginConfigFactory pluginConfigFactory , < |startfocus| > CopyrightReviewApi reviewApi ) throws IOException , ConfigInvalidException { < |endfocus| > this . metrics = metrics ; this . allProjectsName = allProjectsName ; this . pluginName = pluginName ; this . repoManager = repoManager ; this . projectCache = projectCache ; this . pluginConfigFactory = pluginConfigFactory ; this . reviewApi = reviewApi ; long nanoStart = System . nanoTime ( ) ; try { checkConfig = readConfig ( projectCache . getAllProjects ( ) . getProject ( ) . getConfigRefState ( ) ) ; } finally { long elapsedMicros = ( System . nanoTime ( ) - nanoStart ) / 1000 ; metrics . readConfigTimer . record ( elapsedMicros , TimeUnit . MICROSECONDS ) ; } } private CopyrightConfig ( Metrics metrics , AllProjectsName allProjectsName , String pluginName , GitRepositoryManager repoManager , ProjectCache projectCache , PluginConfigFactory pluginConfigFactory , CopyrightReviewApi reviewApi ) throws IOException , ConfigInvalidException { this . metrics = metrics ; this . allProjectsName = allProjectsName ; this . pluginName = pluginName ; this . repoManager = repoManager ; this . projectCache = projectCache ; this . pluginConfigFactory = pluginConfigFactory ; this . reviewApi = reviewApi ; long nanoStart = System . nanoTime ( ) ; try { checkConfig = readConfig ( projectCache . getAllProjects ( ) . getProject ( ) . getConfigRefState ( ) ) ; } finally { long elapsedMicros = ( System . nanoTime ( ) - nanoStart ) / 1000 ; metrics . readConfigTimer . record ( elapsedMicros , TimeUnit . MICROSECONDS ) ; } } private CopyrightConfig (
throws ConfigInvalidException { metrics = new Metrics ( metricMaker ) ; allProjectsName = new AllProjectsName ( "All - Projects" ) ; pluginName = "copyright" ; repoManager = null ; projectCache = null ; pluginConfigFactory = null ; this . reviewApi = reviewApi ; checkConfig = new CheckConfig ( pluginName , projectConfigContents ) ; } @VisibleForTesting static CopyrightConfig createTestInstance ( MetricMaker metricMaker , CopyrightReviewApi reviewApi , String projectConfigContents ) throws ConfigInvalidException { return new CopyrightConfig ( metricMaker , reviewApi , projectConfigContents ) ; } < |startfocus| > ScannerConfig getScannerConfig ( ) { return checkConfig . scannerConfig ; } < |endfocus| > /* * Listens for merges to / refs / meta / config on All - Projects to reload plugin configuration . */ @Override public void onGitReferenceUpdated ( GitReferenceUpdatedListener . Event event ) { if ( ! event . getRefName ( ) . equals ( RefNames . REFS_CONFIG ) ) { return ; } if ( ! event . getProjectName ( ) . equals ( allProjectsName . get ( ) ) ) { return ; } long nanoStart = System . nanoTime ( ) ; try {
public void onGitReferenceUpdated ( GitReferenceUpdatedListener . Event event ) { if ( ! event . getRefName ( ) . equals ( RefNames . REFS_CONFIG ) ) { return ; } if ( ! event . getProjectName ( ) . equals ( allProjectsName . get ( ) ) ) { return ; } long nanoStart = System . nanoTime ( ) ; try { logger . atSevere ( ) . log ( "\n\nonGitRefUpdated\n\n" ) ; checkConfig = readConfig ( event . getNewObjectId ( ) ) ; < |startfocus| > logger . atSevere ( ) . log ( "\n\nonGitRefUpdated : ' % s'\n\n" , checkConfig ) ; < |endfocus| > } catch ( IOException | ConfigInvalidException e ) { logger . atSevere ( ) . withCause ( e ) . log ( " % s plugin unable to load configuration" , pluginName ) ; metrics . configurationErrors . increment ( allProjectsName . get ( ) ) ; metrics . errors . increment ( ) ; return ; } finally { long elapsedMicros = ( System . nanoTime ( ) - nanoStart ) / 1000 ; metrics . readConfigTimer . record ( elapsedMicros , TimeUnit . MICROSECONDS ) ; }
public void onGitReferenceUpdated ( GitReferenceUpdatedListener . Event event ) { if ( ! event . getRefName ( ) . equals ( RefNames . REFS_CONFIG ) ) { return ; } if ( ! event . getProjectName ( ) . equals ( allProjectsName . get ( ) ) ) { return ; } long nanoStart = System . nanoTime ( ) ; try { logger . atSevere ( ) . log ( "onGitRefUpdated" ) ; checkConfig = readConfig ( event . getNewObjectId ( ) ) ; < |startfocus| > logger . atSevere ( ) . log ( "onGitRefUpdated : ' % s'" , checkConfig ) ; < |endfocus| > } catch ( IOException | ConfigInvalidException e ) { logger . atSevere ( ) . withCause ( e ) . log ( " % s plugin unable to load configuration" , pluginName ) ; metrics . configurationErrors . increment ( allProjectsName . get ( ) ) ; metrics . errors . increment ( ) ; return ; } finally { long elapsedMicros = ( System . nanoTime ( ) - nanoStart ) / 1000 ; metrics . readConfigTimer . record ( elapsedMicros , TimeUnit . MICROSECONDS ) ; }
public void onGitReferenceUpdated ( GitReferenceUpdatedListener . Event event ) { if ( ! event . getRefName ( ) . equals ( RefNames . REFS_CONFIG ) ) { return ; } if ( ! event . getProjectName ( ) . equals ( allProjectsName . get ( ) ) ) { return ; } long nanoStart = System . nanoTime ( ) ; try { checkConfig = readConfig ( event . getNewObjectId ( ) ) ; < |startfocus| > logger . atSevere ( ) . log ( "\n\nonGitRefUpdated : ' % s'\n\n" , checkConfig ) ; < |endfocus| > } catch ( IOException | ConfigInvalidException e ) { logger . atSevere ( ) . withCause ( e ) . log ( " % s plugin unable to load configuration" , pluginName ) ; metrics . configurationErrors . increment ( allProjectsName . get ( ) ) ; metrics . errors . increment ( ) ; return ; } finally { long elapsedMicros = ( System . nanoTime ( ) - nanoStart ) / 1000 ; metrics . readConfigTimer . record ( elapsedMicros , TimeUnit . MICROSECONDS ) ; }
CommentInfo draftInfo = Iterables . getOnlyElement ( drafts . get ( draft . path ) ) ; ReviewInput reviewInput = new ReviewInput ( ) ; reviewInput . drafts = DraftHandling . KEEP ; reviewInput . message = "foo" ; CommentInput comment = newComment ( file , Side . REVISION , 0 , "comment" , false ) ; // Replace the existing draft . comment . id = draftInfo . id ; reviewInput . comments = new HashMap < > ( ) ; reviewInput . comments . put ( comment . path , ImmutableList . of ( comment ) ) ; revision ( r ) . review ( reviewInput ) ; < |startfocus| > // The draft was deleted despite DraftHandling . KEEP . < |endfocus| > drafts = getDraftComments ( changeId , revId ) ; assertThat ( drafts ) . isEmpty ( ) ; } @Test public void listComments ( ) throws Exception { String file = "file" ; PushOneCommit push = pushFactory . create ( admin . newIdent ( ) , testRepo , "first subject" , file , "contents" ) ; PushOneCommit . Result r = push . to ( "refs / for / master" ) ; String changeId = r . getChangeId ( ) ; String revId = r . getCommit ( ) . getName ( ) ; assertThat ( getPublishedComments ( changeId , revId ) ) . isEmpty ( ) ;
( metadata , value ) - > elementAssertThatFunction . apply ( value ) ; return assertThat ( optional , valueSubjectFactory ) ; } public static < S extends Subject , T > OptionalSubject < S , T > assertThat ( Optional < T > optional , Subject . Factory < S , T > valueSubjectFactory ) { return assertAbout ( optionals ( ) ) . thatCustom ( optional , valueSubjectFactory ) ; } public static OptionalSubject < Subject , ? > assertThat ( Optional < ? > optional ) { < |startfocus| > return assertAbout ( optionals ( ) ) . that ( optional , StandardSubjectBuilder : : that ) ; < |endfocus| > } public static CustomSubjectBuilder . Factory < OptionalSubjectBuilder > optionals ( ) { return OptionalSubjectBuilder : : new ; } private OptionalSubject ( FailureMetadata failureMetadata , Optional < T > optional , BiFunction < StandardSubjectBuilder , ? super T , ? extends S > valueSubjectCreator ) { super ( failureMetadata , optional ) ; this . optional = optional ; this . valueSubjectCreator = valueSubjectCreator ; } public void isPresent ( ) { isNotNull ( ) ; if ( ! optional . isPresent ( ) ) { failWithoutActual ( fact ( "expected to have" , "value" ) ) ; } } public void isAbsent ( ) {
} public static class OptionalSubjectBuilder extends CustomSubjectBuilder { OptionalSubjectBuilder ( FailureMetadata failureMetadata ) { super ( failureMetadata ) ; } public < S extends Subject , T > OptionalSubject < S , T > thatCustom ( Optional < T > optional , Subject . Factory < S , T > valueSubjectFactory ) { return that ( optional , ( builder , value ) - > builder . about ( valueSubjectFactory ) . that ( value ) ) ; } public OptionalSubject < Subject , ? > that ( Optional < ? > optional ) { < |startfocus| > return that ( optional , ( builder , value ) - > ( DefaultSubject ) builder . that ( value ) ) ; < |endfocus| > } public < S extends Subject , T > OptionalSubject < S , T > that ( Optional < T > optional , BiFunction < StandardSubjectBuilder , ? super T , ? extends S > valueSubjectCreator ) { return new OptionalSubject < > ( metadata ( ) , optional , valueSubjectCreator ) ; } } }
GitReferenceUpdatedListener , LifecycleListener { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; /* * Default value of timeTestMax configuration parameter for avoiding excessive backtracking . */ private final long DEFAULT_MAX_ELAPSED_SECONDS = 8 ; private final Metrics metrics ; private final AllProjectsName allProjectsName ; private final String pluginName ; private final GitRepositoryManager repoManager ; private final ProjectCache projectCache ; private final PluginConfigFactory pluginConfigFactory ; private final CopyrightReviewApi reviewApi ; < |startfocus| > private PluginConfig gerritConfig ; private CheckConfig checkConfig ; < |endfocus| > static AbstractModule module ( ) { return new AbstractModule ( ) { @Override protected void configure ( ) { DynamicSet . bind ( binder ( ) , CommitValidationListener . class ) . to ( CopyrightConfig . class ) ; DynamicSet . bind ( binder ( ) , LifecycleListener . class ) . to ( CopyrightConfig . class ) ; DynamicSet . bind ( binder ( ) , RevisionCreatedListener . class ) . to ( CopyrightConfig . class ) ; DynamicSet . bind ( binder ( ) , GitReferenceUpdatedListener . class ) . to ( CopyrightConfig . class ) ; } } ; } @Inject CopyrightConfig ( Metrics metrics , AllProjectsName allProjectsName , @PluginName String pluginName , < |startfocus| > @Nullable @GerritServerConfig PluginConfig gerritConfig , @Nullable @PluginConfig PluginConfig pluginConfig , < |endfocus| >
} } boolean pluginEnabled = gerritConfig != null && gerritConfig . getBoolean ( ScannerConfig . KEY_ENABLE , false ) ; CheckConfig . checkProjectConfig ( reviewApi , pluginEnabled , trialConfig ) ; return trialConfig == null || trialConfig . scannerConfig == null ? Collections . emptyList ( ) : trialConfig . scannerConfig . messages ; } } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "failed to read new project . config" ) ; < |startfocus| > throw new CommitValidationException ( "failed to read new project . config" , e ) ; < |endfocus| > } catch ( ConfigInvalidException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "unable to parse plugin config" ) ; if ( trialConfig != null && trialConfig . scannerConfig != null ) { trialConfig . scannerConfig . messages . add ( ScannerConfig . errorMessage ( e . getMessage ( ) ) ) ; metrics . configurationErrors . increment ( allProjectsName . get ( ) ) ; metrics . errors . increment ( ) ; return trialConfig . scannerConfig . messages ; } else { throw new CommitValidationException ( "unable to parse new project . config" , e ) ; } } finally { if ( trialConfig != null && trialConfig . scannerConfig != null
return scannerConfig . defaultEnable ; } return pluginConfig . getBoolean ( ScannerConfig . KEY_ENABLE , scannerConfig . defaultEnable ) ; } /* * * Loads and compiles configured patterns from { @code ref / meta / All - Projects / project . config } and * { @code gerrit . config } . * * @param projectConfigObjectId identifies the version of project . config to load and to compile * @return the new scanner configuration to check * @throws IOException if accessing the repository fails < |startfocus| > */ < |endfocus| > private CheckConfig readConfig ( String projectConfigObjectId ) throws IOException , ConfigInvalidException { CheckConfig checkConfig = null ; // new All - Projects project . config not yet in cache -- read from repository ObjectId id = ObjectId . fromString ( projectConfigObjectId ) ; if ( ObjectId . zeroId ( ) . equals ( id ) ) { return checkConfig ; } try ( Repository repo = repoManager . openRepository ( allProjectsName ) ) { checkConfig = new CheckConfig ( pluginName , readFileContents ( repo , id , ProjectConfig . PROJECT_CONFIG ) ) ; } gerritConfig = pluginConfigFactory . getFromGerritConfig ( pluginName , true ) ;
// new All - Projects project . config not yet in cache -- read from repository ObjectId id = ObjectId . fromString ( projectConfigObjectId ) ; if ( ObjectId . zeroId ( ) . equals ( id ) ) { return checkConfig ; } try ( Repository repo = repoManager . openRepository ( allProjectsName ) ) { checkConfig = new CheckConfig ( pluginName , readFileContents ( repo , id , ProjectConfig . PROJECT_CONFIG ) ) ; } gerritConfig = pluginConfigFactory . getFromGerritConfig ( pluginName , true ) ; if ( gerritConfig == null ) { < |startfocus| > // throw IllegalStateException ? RestApiException ? < |endfocus| > checkConfig . scannerConfig . messages . add ( ScannerConfig . hintMessage ( "missing [ plugin \"" + pluginName + "\" ] section in gerrit . config" ) ) ; } else { checkConfig . scannerConfig . defaultEnable = gerritConfig . getBoolean ( ScannerConfig . KEY_ENABLE , false ) ; } return checkConfig ; } private void logReviewResultErrors ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( ! Strings . isNullOrEmpty ( result . error ) ) { logger . atSevere ( ) . log ( "error while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . error ) ; } } private void logReviewResultWarnings ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( ! result . warnings . isEmpty ( ) ) { logger . atWarning ( ) . log ( "warnings while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . warnings ) ; } } private void logReviewResultMessages ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( ! result . messages . isEmpty ( ) ) { logger . atInfo ( ) . log ( "messages while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . messages ) ; } } private void logReviewResultHints ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( ! result . hints . isEmpty ( ) ) { logger . atInfo ( ) . log ( "hints while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . hints ) ; } } private void logReviewResultScannerConfig ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( result . scannerConfig != null ) { logger . atInfo ( ) . log ( "scanner config while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . scannerConfig ) ; } } private void logReviewResultScannerConfigMessages ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( result . scannerConfig != null && ! result . scannerConfig . messages . isEmpty ( ) ) { logger . atInfo ( ) . log ( "scanner config messages while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . scannerConfig . messages ) ; } } private void logReviewResultScannerConfigHints ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( result . scannerConfig != null && ! result . scannerConfig . hints . isEmpty ( ) ) { logger . atInfo ( ) . log ( "scanner config hints while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . scannerConfig . hints ) ; } } private void logReviewResultScannerConfigWarnings ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( result . scannerConfig != null && ! result . scannerConfig . warnings . isEmpty ( ) ) { logger . atInfo ( ) . log ( "scanner config warnings while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . scannerConfig . warnings ) ; } } private void logReviewResultScannerConfigErrors ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( result . scannerConfig != null && ! result . scannerConfig . errors . isEmpty ( ) ) { logger . atInfo ( ) . log ( "scanner config errors while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . scannerConfig . errors ) ; } } private void logReviewResultScannerConfigChecks ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( result . scannerConfig != null && ! result . scannerConfig . checks . isEmpty ( ) ) { logger . atInfo ( ) . log ( "scanner config checks while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . scannerConfig . checks ) ; } } private void logReviewResultScannerConfigCheckMessages ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( result . scannerConfig != null && ! result . scannerConfig . checkMessages . isEmpty ( ) ) { logger . atInfo ( ) . log ( "scanner config check messages while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . scannerConfig . checkMessages ) ; } } private void logReviewResultScannerConfigCheckHints ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( result . scannerConfig != null && ! result . scannerConfig . checkHints . isEmpty ( ) ) { logger . atInfo ( ) . log ( "scanner config check hints while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . scannerConfig . checkHints ) ; } } private void logReviewResultScannerConfigCheckWarnings ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( result . scannerConfig != null && ! result . scannerConfig . checkWarnings . isEmpty ( ) ) { logger . atInfo ( ) . log ( "scanner config check warnings while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . scannerConfig . checkWarnings ) ; } } private void logReviewResultScannerConfigCheckErrors ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( result . scannerConfig != null && ! result . scannerConfig . checkErrors . isEmpty ( ) ) { logger . atInfo ( ) . log ( "scanner config check errors while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . scannerConfig . checkErrors ) ; } } private void logReviewResultScannerConfigCheckFiles ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( result . scannerConfig != null && ! result . scannerConfig . checkFiles . isEmpty ( ) ) { logger . atInfo ( ) . log ( "scanner config check files while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . scannerConfig . checkFiles ) ; } } private void logReviewResultScannerConfigCheckFileMessages ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( result . scannerConfig != null && ! result . scannerConfig . checkFileMessages . isEmpty ( ) ) { logger . atInfo ( ) . log ( "scanner config check file messages while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . scannerConfig . checkFileMessages ) ; } } private void logReviewResultScannerConfigCheckFileHints ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( result . scannerConfig != null && ! result . scannerConfig . checkFileHints . isEmpty ( ) ) { logger . atInfo ( ) . log ( "scanner config check file hints while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . scannerConfig . checkFileHints ) ; } } private void logReviewResultScannerConfigCheckFileWarnings ( RevisionCreatedListener . Event event , ReviewResult result ) { if ( result . scannerConfig != null && ! result . scannerConfig . checkFileWarnings . isEmpty ( ) ) { logger . atInfo ( ) . log ( "scanner config check file warnings while checking % s : % s" , event . getPatchSet ( ) . getId ( ) , result . scannerConfig . checkFileWarnings ) ; } } private void logReviewResultScannerConfigCheckFileEr
AddReviewerResult arr = entry . getValue ( ) ; if ( ! Strings . isNullOrEmpty ( arr . error ) ) { logger . atSevere ( ) . log ( "revision % s : error adding reviewer % s : % s" , event . getChange ( ) . currentRevision , entry . getKey ( ) , arr . error ) ; metrics . addReviewerErrors . increment ( event . getChange ( ) . project ) ; metrics . errors . increment ( ) ; } } } private String readFileContents ( Repository repo , ObjectId objectId , String filename ) throws IOException { < |startfocus| > RevWalk rw = new RevWalk ( repo ) ; try { RevTree tree = rw . parseTree ( objectId ) ; try ( TreeWalk tw = TreeWalk . forPath ( rw . getObjectReader ( ) , filename , tree ) ) { < |endfocus| > ObjectLoader loader = repo . open ( tw . getObjectId ( 0 ) , Constants . OBJ_BLOB ) ; return new String ( loader . getCachedBytes ( ) , UTF_8 ) ; } } finally { rw . close ( ) ; } } }
"revision % s : error adding reviewer % s : % s" , event . getChange ( ) . currentRevision , entry . getKey ( ) , arr . error ) ; metrics . addReviewerErrors . increment ( event . getChange ( ) . project ) ; metrics . errors . increment ( ) ; } } } private String readFileContents ( Repository repo , ObjectId objectId , String filename ) throws IOException { RevWalk rw = new RevWalk ( repo ) ; RevTree tree = rw . parseTree ( objectId ) ; try ( TreeWalk tw = TreeWalk . forPath ( rw . getObjectReader ( ) , filename , tree ) ) { if ( tw == null ) { return null ; } ObjectLoader loader = repo . open ( tw . getObjectId ( 0 ) , Constants . OBJ_BLOB ) ; return new String ( loader . getCachedBytes ( ) , UTF_8 ) ; } } }
import com . googlesource . gerrit . plugins . multisite . validation . dfsrefdb . zookeeper . ZkValidationModule ; import java . io . BufferedReader ; import java . io . BufferedWriter ; import java . io . IOException ; import java . nio . file . Files ; import java . nio . file . Path ; import java . nio . file . Paths ; import java . util . Collection ; import java . util . UUID ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; public class Module extends LifecycleModule { private static final Logger log = LoggerFactory . getLogger ( Module . class ) ; private Configuration config ; private NoteDbStatus noteDb ; private final boolean disableGitRepositoryValidation ; @Inject public Module ( Configuration config , NoteDbStatus noteDb ) { this ( config , noteDb , false ) ; } // TODO : It is not possible to properly test the libModules in Gerrit . // Disable the Git repository validation during integration test and then build the necessary // support // in Gerrit for it . @VisibleForTesting public Module ( Configuration config , NoteDbStatus noteDb , boolean disableGitRepositoryValidation ) {
install ( new IndexModule ( ) ) ; } if ( config . kafkaSubscriber ( ) . enabled ( ) ) { install ( new KafkaConsumerModule ( config . kafkaSubscriber ( ) ) ) ; install ( new ForwardedEventRouterModule ( ) ) ; } if ( config . kafkaPublisher ( ) . enabled ( ) ) { install ( new BrokerForwarderModule ( config . kafkaPublisher ( ) ) ) ; } install ( new MultiSiteValidationModule ( config , disableGitRepositoryValidation || ! config . getSharedRefDb ( ) . isEnabled ( ) ) ) ; < |startfocus| > if ( config . getSharedRefDb ( ) . isEnabled ( ) ) { install ( new ZkValidationModule ( config ) ) ; } < |endfocus| > bind ( Gson . class ) . annotatedWith ( BrokerGson . class ) . toProvider ( GsonProvider . class ) . in ( Singleton . class ) ;
import org . apache . curator . retry . BoundedExponentialBackoffRetry ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . eclipse . jgit . util . FS ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; public class ZookeeperConfig { private static final Logger log = LoggerFactory . getLogger ( ZookeeperConfig . class ) ; < |startfocus| > // TODO Read from different config file when moving it into a plugin public static final String ZOOKEEPER_MS_CONFIG = "multi - site . config" ; < |endfocus| > public static final int defaultSessionTimeoutMs ; public static final int defaultConnectionTimeoutMs ; public static final String DEFAULT_ZK_CONNECT = "localhost : 2181" ; private final int DEFAULT_RETRY_POLICY_BASE_SLEEP_TIME_MS = 1000 ; private final int DEFAULT_RETRY_POLICY_MAX_SLEEP_TIME_MS = 3000 ; private final int DEFAULT_RETRY_POLICY_MAX_RETRIES = 3 ; private final int DEFAULT_CAS_RETRY_POLICY_BASE_SLEEP_TIME_MS = 100 ; private final int DEFAULT_CAS_RETRY_POLICY_MAX_SLEEP_TIME_MS = 300 ; private final int DEFAULT_CAS_RETRY_POLICY_MAX_RETRIES = 3 ; private final int DEFAULT_CAS_RETRY_POLICY_MAX_RETRIES = 3 ;
< |startfocus| > public ZkValidationModule ( ZookeeperConfig cfg ) { this . cfg = cfg ; < |endfocus| >
static { System . setProperty ( "gerrit . notedb" , "ON" ) ; } public static class KafkaTestContainerModule extends LifecycleModule { public static class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka ; public KafkaStopAtShutdown ( KafkaContainer kafka ) { this . kafka = kafka ; } @Override public void stop ( ) { kafka . stop ( ) ; } @Override public void start ( ) { // Do nothing } } < |startfocus| > private final FileBasedConfig multiSiteConfig ; < |endfocus| > private final FileBasedConfig sharedRefConfig ; private final Module multiSiteModule ; @Inject public KafkaTestContainerModule ( SitePaths sitePaths , NoteDbStatus noteDb ) { this . multiSiteConfig = new FileBasedConfig ( sitePaths . etc_dir . resolve ( Configuration . MULTI_SITE_CONFIG ) . toFile ( ) , FS . DETECTED ) ; this . sharedRefConfig = new FileBasedConfig ( sitePaths . etc_dir . resolve ( ZookeeperConfig . ZOOKEEPER_MS_CONFIG ) . toFile ( ) , FS . DETECTED ) ; this . multiSiteModule = new Module ( new Configuration ( multiSiteConfig , new Config ( ) ) , new ZookeeperConfig ( sharedRefConfig ) ,
import com . google . gerrit . server . change . ChangeResource ; import com . google . gerrit . server . change . RevisionResource ; import com . google . gerrit . server . update . CommentsRejectedException ; import com . google . gerrit . server . update . UpdateException ; import com . google . inject . Inject ; import com . google . inject . Module ; import com . google . inject . Provider ; import java . sql . Timestamp ; import org . junit . Before ; import org . junit . Test ; /* * Tests for comment validation in { @link PostReview } . */ @NoHttpd public class PostReviewIT extends AbstractDaemonTest { < |startfocus| > @Inject private Provider < ChangesCollection > changes ; @Inject private Provider < PostReview > postReview ; @Inject private RequestScopeOperations requestScopeOperations ; < |endfocus| > @Override public Module createModule ( ) { return new FactoryModule ( ) { @Override public void configure ( ) { bind ( CommentValidationListener . class ) . annotatedWith ( Exports . named ( "TestCommentValidationListener" ) ) . to ( TestCommentValidationListener . class ) . asEagerSingleton ( ) ; } } ; } @Before public void setUp ( ) { requestScopeOperations . setApiUser ( admin . id ( ) ) ; getValidationCalls ( ) . clear ( ) ; } @Test public void validateCommentsInInput_commentOK ( ) throws Exception { ChangeResource change = gApi . changes ( ) . id ( changeId ) . get ( ) ;
public void configure ( ) { < |startfocus| > bind ( CommentValidationListener . class ) . annotatedWith ( Exports . named ( "TestCommentValidationListener" ) ) . to ( TestCommentValidationListener . class ) . asEagerSingleton ( ) ; < |endfocus| > }
} } ; } @Before public void setUp ( ) { requestScopeOperations . setApiUser ( admin . id ( ) ) ; getValidationCalls ( ) . clear ( ) ; } @Test public void validateCommentsInInput_commentOK ( ) throws Exception { String file = "file" ; PushOneCommit push = pushFactory . create ( admin . newIdent ( ) , testRepo , "first subject" , file , "contents" ) ; PushOneCommit . Result r = push . to ( "refs / for / master" ) ; String changeId = r . getChangeId ( ) ; String revId = r . getCommit ( ) . getName ( ) ; < |startfocus| > < |endfocus| > ReviewInput input = new ReviewInput ( ) ; String commentText = "this comment is OK" ; CommentInput comment = newComment ( file , commentText ) ; comment . updated = new Timestamp ( 0 ) ; input . comments = ImmutableMap . of ( comment . path , Lists . newArrayList ( comment ) ) ; ChangeResource changeResource = changes . get ( ) . parse ( TopLevelResource . INSTANCE , IdString . fromDecoded ( changeId ) ) ; RevisionResource revisionResource = revisions . parse ( changeResource , IdString . fromDecoded ( revId ) ) ; assertThat ( getPublishedComments ( changeId ) ) . isEmpty ( ) ;
private UUID tryToLoadSavedInstanceId ( String serverIdFile ) { if ( Files . exists ( Paths . get ( serverIdFile ) ) ) { try ( BufferedReader br = new BufferedReader ( new FileReader ( serverIdFile ) ) ) { return UUID . fromString ( br . readLine ( ) ) ; } catch ( IOException e ) { < |startfocus| > multisiteLog . warn ( < |endfocus| > String . format ( "Cannot read instance ID from path ' % s' , deleting the old file and generating a new ID : ( % s ) " , serverIdFile , e . getMessage ( ) ) ) ; try { Files . delete ( Paths . get ( serverIdFile ) ) ; } catch ( IOException e1 ) { multisiteLog . warn ( String . format ( "Cannot delete old instance ID file at path ' % s' with instance ID while generating a new one : ( % s ) " , serverIdFile , e1 . getMessage ( ) ) ) ; } } } return null ;
protected void configure ( ) { < |startfocus| > < |endfocus| > bind ( SharedRefDatabase . class ) . to ( ZkSharedRefDatabase . class ) ; bind ( CuratorFramework . class ) . toInstance ( cfg . getZookeeperConfig ( ) . buildCurator ( ) ) ; bind ( ZkConnectionConfig . class ) . toInstance ( new ZkConnectionConfig ( cfg . getZookeeperConfig ( ) . buildCasRetryPolicy ( ) , cfg . getZookeeperConfig ( ) . getZkInterProcessLockTimeOut ( ) ) ) ; DynamicSet . bind ( binder ( ) , ProjectDeletedListener . class ) . to ( ProjectDeletedSharedDbCleanup . class ) ;
Throwable t = e . getCause ( ) ; if ( t instanceof LockFailureException ) { logger . atSevere ( ) . withCause ( t ) . log ( "Error in % s % s" , req . getMethod ( ) , uriForLogging ( req ) ) ; responseBytes = replyError ( req , res , status = SC_SERVICE_UNAVAILABLE , messageOr ( t , "Lock failure" ) , e ) ; < |startfocus| > } else if ( t instanceof CommentsRejectedException ) { responseBytes = replyError ( req , res , status = SC_BAD_REQUEST , messageOr ( t , "Comments rejected" ) , e ) ; < |endfocus| > } else { status = SC_INTERNAL_SERVER_ERROR ; responseBytes = handleException ( e , req , res ) ; } } catch ( QuotaException e ) { responseBytes = replyError ( req , res , status = 429 , messageOr ( e , "Quota limit reached" ) , e . caching ( ) , e ) ; } catch ( Exception e ) { status = SC_INTERNAL_SERVER_ERROR ; responseBytes = handleException ( e , req , res ) ; } finally { String metric = viewData != null && viewData . view != null ? globals . metrics . view ( viewData ) : "_unknown" ;
< |startfocus| > public static List < CommentValidationFailure > findInvalidComments ( < |endfocus| > PluginSetContext < CommentValidator > commentValidators , ImmutableList < CommentForValidation > commentsForValidation ) { List < CommentValidationFailure > commentValidationFailures = new ArrayList < > ( ) ; commentValidators . runEach ( listener - > commentValidationFailures . addAll ( listener . validateComments ( commentsForValidation ) ) ) ; return ImmutableList . copyOf ( commentValidationFailures ) ;
comments . addAll ( toPublish ) ; return ! toPublish . isEmpty ( ) ; } private boolean insertRobotComments ( ChangeContext ctx ) throws OrmException , PatchListNotAvailableException { if ( in . robotComments == null ) { return false ; } List < RobotComment > newRobotComments = getNewRobotComments ( ctx ) ; commentsUtil . putRobotComments ( ctx . getUpdate ( psId ) , newRobotComments ) ; comments . addAll ( newRobotComments ) ; return ! newRobotComments . isEmpty ( ) ; } private List < RobotComment > getNewRobotComments ( ChangeContext ctx ) < |startfocus| > throws OrmException , PatchListNotAvailableException { < |endfocus| > List < RobotComment > toAdd = new ArrayList < > ( in . robotComments . size ( ) ) ; Set < CommentSetEntry > existingIds = in . omitDuplicateComments ? readExistingRobotComments ( ctx ) : Collections . emptySet ( ) ; for ( Map . Entry < String , List < RobotCommentInput > > ent : in . robotComments . entrySet ( ) ) { String path = ent . getKey ( ) ; for ( RobotCommentInput c : ent . getValue ( ) ) { RobotComment e = createRobotCommentFromInput ( ctx , path , c ) ; if ( existingIds . contains ( CommentSetEntry . create ( e ) ) ) { continue ;
name ) ; this . refName = RefNames . REFS_SEQUENCES + name ; this . seed = requireNonNull ( seed , "seed" ) ; this . floor = floor ; checkArgument ( batchSize > 0 , "expected batchSize > 0 , got : % s" , batchSize ) ; this . batchSize = batchSize ; this . afterReadRef = requireNonNull ( afterReadRef , "afterReadRef" ) ; this . retryer = requireNonNull ( retryer , "retryer" ) ; counterLock = new ReentrantLock ( true ) ; } < |startfocus| > /* * * Thread safe . */ < |endfocus| > public int next ( ) { return Iterables . getOnlyElement ( next ( 1 ) ) ; } public ImmutableList < Integer > next ( int count ) { if ( count == 0 ) { return ImmutableList . of ( ) ; } checkArgument ( count > 0 , "count is negative : % s" , count ) ; try { return retryer . call ( ( ) - > { counterLock . lock ( ) ; try { if ( count == 1 ) { if ( counter >= limit ) { acquire ( batchSize ) ; } return ImmutableList . of ( counter ++ ) ; } List < Integer > ids = new ArrayList < > ( count ) ; while ( counter < limit ) {
// from the sequence . Creating an ID requires the RepoSequence . counterLock , if it's not free // ( because we forgot to release it before blocking ) the call in the other thread would hang and // the test would time out . // We can set the runnable that consumes the ID from another thread only after RepoSequence was // created , because we need the RepoSequence instance to get the next ID . BlockStrategyThatTriggersRunnable blockStrategy = new BlockStrategyThatTriggersRunnable ( ) ; < |startfocus| > < |endfocus| > // Use batch size = 1 to make each call go to NoteDb . RepoSequence s = newSequence ( "id" , 1 , 1 , bgUpdate , RepoSequence . retryerBuilder ( ) . withBlockStrategy ( blockStrategy ) . build ( ) ) ; blockStrategy . runOnBlock = ( ) - > { try { Executors . newFixedThreadPool ( 1 ) . submit ( ( ) - > { // This call hangs if we don't release the RepoSequence . counterLock while we // are blocking until the next try . If this happens we block until the test // times // out .
assertThat ( getEmails ( ) ) . containsExactly ( previous ) ; assertThat ( gApi . accounts ( ) . self ( ) . get ( ) . email ) . isNull ( ) ; } @Test @Sandboxed public void deleteAllEmails ( ) throws Exception { EmailInput input = new EmailInput ( ) ; input . email = "foo . bar@example . com" ; input . noConfirmation = true ; gApi . accounts ( ) . self ( ) . addEmail ( input ) ; accountIndexedCounter . assertReindexOf ( admin ) ; resetCurrentApiUser ( ) ; Set < String > allEmails = getEmails ( ) ; assertThat ( allEmails ) . hasSize ( 2 ) ; < |startfocus| > accountIndexedCounter . clear ( ) ; < |endfocus| > for ( String email : allEmails ) { gApi . accounts ( ) . self ( ) . deleteEmail ( email ) ; } resetCurrentApiUser ( ) ; assertThat ( getEmails ( ) ) . isEmpty ( ) ; assertThat ( gApi . accounts ( ) . self ( ) . get ( ) . email ) . isNull ( ) ; } @Test public void deleteEmailFromCustomExternalIdSchemes ( ) throws Exception { String email = "foo . bar@example . com" ; String extId1 = "foo : bar" ; String extId2 = "foo : baz" ; List < ExternalId > extIds = ImmutableList . of ( ExternalId . create (
multisiteLog . warn ( String . format ( "Cannot read instance ID from path ' % s' , deleting the old file and generating a new ID : ( % s ) " , serverIdFile , e . getMessage ( ) ) ) ; try { Files . delete ( Paths . get ( serverIdFile ) ) ; } catch ( IOException e1 ) { multisiteLog . warn ( String . format ( "Cannot delete old instance ID file at path ' % s' with instance ID while generating a new one : ( % s ) " , serverIdFile , e1 . getMessage ( ) ) ) ; } } } return null ;
* and executing the callable do not apply . * * < p > See { @link LoggingContextAwareRunnable } for an example . * * @see LoggingContextAwareRunnable */ class LoggingContextAwareCallable < T > implements Callable < T > { private final Callable < T > callable ; private final Thread callingThread ; private final ImmutableSetMultimap < String , String > tags ; private final boolean forceLogging ; private final boolean performanceLogging ; private final MutablePerformanceLogRecords mutablePerformanceLogRecords ; /* * * @param callable Callable that should be wrapped . * @param mutablePerformanceLogRecords instance of { @link MutablePerformanceLogRecords } to which * performance log records that are created from the runnable are added */ LoggingContextAwareCallable ( Callable < T > callable , MutablePerformanceLogRecords mutablePerformanceLogRecords ) { this . callable = callable ; this . callingThread = Thread . currentThread ( ) ; this . tags = LoggingContext . getInstance ( ) . getTagsAsMap ( ) ; this . forceLogging = LoggingContext . getInstance ( ) . isLoggingForced ( ) ; this . performanceLogging = LoggingContext . getInstance ( ) . isPerformanceLogging ( ) ; this . mutablePerformanceLogRecords = mutablePerformanceLogRecords ; } @Override
. andReturn ( ImmutableList . of ( commentForValidation . failValidation ( "Oh no ! " ) ) ) ; EasyMock . replay ( mockCommentValidator ) ; PushOneCommit . Result r = createChange ( ) ; ReviewInput input = new ReviewInput ( ) ; CommentInput comment = newComment ( r . getChange ( ) . currentFilePaths ( ) . get ( 0 ) ) ; comment . updated = new Timestamp ( 0 ) ; input . comments = ImmutableMap . of ( comment . path , ImmutableList . of ( comment ) ) ; < |startfocus| > assertThat ( testCommentUtil . getPublishedComments ( r . getChangeId ( ) ) ) . isEmpty ( ) ; BadRequestException badRequestException = < |endfocus| > assertThrows ( BadRequestException . class , ( ) - > gApi . changes ( ) . id ( r . getChangeId ( ) ) . current ( ) . review ( input ) ) ; assertThat ( badRequestException . getCause ( ) ) . isInstanceOf ( CommentsRejectedException . class ) ; assertThat ( Iterables . getOnlyElement ( ( ( CommentsRejectedException ) badRequestException . getCause ( ) ) . getCommentValidationFailures ( ) ) . getComment ( ) . getText ( ) ) . isEqualTo ( COMMENT_TEXT ) ; assertThat ( badRequestException . getCause ( ) ) . hasMessageThat ( ) . contains ( "Oh no ! " ) ; assertThat ( testCommentUtil . getPublishedComments ( r . getChangeId ( ) ) ) . isEmpty ( ) ; } @Test
public OrmException convertError ( String op , SQLException err ) { < |startfocus| > switch ( getSQLStateInt ( err ) ) { case 23000 : // ER_DUP_KEY , ER_DUP_ENTRY , ER_DUP_ENTRY_WITH_KEY_NAME , ER_DUP_KEY_WITH_CHILD_INFO , ER_DUP_UNIQUE , ER_DUP_UNIQUE_PRIMARY_KEY , ER_DUP_UNIQUE_KEY , ER_DUP_UNIQUE_KEY_WITH_CHILD_INFO , ER_DUP_UNIQUE_KEY_WITH_CHILD_INFO_AND_DUP_ENTRY , ER_DUP_UNIQUE_KEY_WITH_DUP_ENTRY , ER_DUP_UNIQUE_KEY_WITH_DUP_ENTRY_AND_CHILD_INFO , ER_DUP_UNIQUE_KEY_WITH_DUP_ENTRY_AND_CHILD_INFO_AND_DUP_ENTRY , ER_DUP_UNIQUE_KEY_WITH_DUP_ENTRY_AND_DUP_ENTRY , ER_DUP_UNIQUE_KEY_WITH_DUP_ENTRY_AND_DUP_ENTRY_AND_CHILD_INFO < |endfocus| > return new OrmDuplicateKeyException ( "ACCOUNT_PATCH_REVIEWS" , err ) ; default : if ( err . getCause ( ) == null && err . getNextException ( ) != null ) { err . initCause ( err . getNextException ( ) ) ; } return new OrmException ( op + " failure on ACCOUNT_PATCH_REVIEWS" , err ) ; }
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite ; import static com . google . common . base . Preconditions . checkArgument ; import static com . google . common . base . Suppliers . memoize ; import static com . google . common . base . Suppliers . ofInstance ; import com . google . common . annotations . VisibleForTesting ; import com . google . common . base . CaseFormat ; import com . google . common . base . Strings ; < |startfocus| > import com . google . common . base . Supplier ; import com . google . common . collect . ImmutableList ; < |endfocus| > import com . google . common . collect . ImmutableMap ; import com . google . gerrit . server . config . SitePaths ; import com . google . inject . Inject ; import com . google . inject . Singleton ; import com . google . inject . spi . Message ; import com . googlesource . gerrit . plugins . multisite . forwarder . events . EventFamily ; import java . io . IOException ; import java . util . Arrays ; import java . util . Collection ; import java . util . Collections ; import java . util . HashMap ; import java . util . List ; import java . util . Map ; import java . util . Properties ; import java . util . UUID ; import org . apache . commons . lang . StringUtils ; import org . apache . curator . RetryPolicy ;
private final boolean enabled ; private final Map < EventFamily , Boolean > eventsEnabled ; private KafkaPublisher ( Supplier < Config > cfg ) { enabled = < |startfocus| > cfg . get ( ) . getBoolean ( KAFKA_SECTION , KAFKA_PUBLISHER_SUBSECTION , ENABLE_KEY , DEFAULT_BROKER_ENABLED ) ; < |endfocus| > eventsEnabled = eventsEnabled ( cfg , KAFKA_PUBLISHER_SUBSECTION ) ; if ( enabled ) { setDefaults ( ) ; applyKafkaConfig ( cfg , KAFKA_PUBLISHER_SUBSECTION , this ) ; }
import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import com . google . common . base . CaseFormat ; import com . google . common . base . Strings ; import com . google . common . base . Supplier ; import com . google . common . collect . ImmutableMap ; import com . googlesource . gerrit . plugins . multisite . forwarder . events . EventFamily ; public class KafkaConfiguration { private static final Logger log = LoggerFactory . getLogger ( KafkaConfiguration . class ) ; < |startfocus| > public static final String KAFKA_CONFIG = "multi - site . config" ; public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp - " ; < |endfocus| > static final String KAFKA_SECTION = "kafka" ; static final String ENABLE_KEY = "enabled" ; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost : 9092" ; static final boolean DEFAULT_ENABLE_PROCESSING = true ; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000 ; private final Supplier < KafkaSubscriber > subscriber ; private final Supplier < Kafka > kafka ; private final Supplier < KafkaPublisher > publisher ; public KafkaConfiguration ( Config kafkaConfig ) { Supplier < Config > lazyCfg = lazyLoad ( kafkaConfig ) ; < |startfocus| > private static Supplier < Config > lazyLoad ( Config kafkaConfig ) { return new Supplier < Config > ( ) { @Override public Config get ( ) { return kafkaConfig ; } } ; } < |endfocus| >
ProvisionException pe = new ProvisionException ( "error opening ReviewDb" ) ; pe . initCause ( e ) ; throw pe ; } dbRef . set ( db ) ; } return db ; } @Override public CurrentUser getUser ( ) { throw new OutOfScopeException ( "No user during ChangeIndexer" ) ; } } ; RequestContext oldCtx = context . setContext ( newCtx ) ; try { < |startfocus| > if ( this instanceof IndexTask ) { queuedIndexTasks . remove ( this ) ; } else if ( this instanceof ReindexIfStaleTask ) { queuedReindexIfStaleTasks . remove ( this ) ; } < |endfocus| > return callImpl ( newCtx . getReviewDbProvider ( ) ) ; } finally { context . setContext ( oldCtx ) ; Provider < ReviewDb > db = dbRef . get ( ) ; if ( db != null ) { db . get ( ) . close ( ) ; } } } catch ( Exception e ) { log . error ( "Failed to execute " + this , e ) ; throw e ; }
pe . initCause ( e ) ; throw pe ; } dbRef . set ( db ) ; } return db ; } @Override public CurrentUser getUser ( ) { throw new OutOfScopeException ( "No user during ChangeIndexer" ) ; } } ; RequestContext oldCtx = context . setContext ( newCtx ) ; try { < |startfocus| > queuedIndexTasks . remove ( this ) ; queuedReindexIfStaleTasks . remove ( this ) ; < |endfocus| > return callImpl ( newCtx . getReviewDbProvider ( ) ) ; } finally { context . setContext ( oldCtx ) ; Provider < ReviewDb > db = dbRef . get ( ) ; if ( db != null ) { db . get ( ) . close ( ) ; } } } catch ( Exception e ) { log . error ( "Failed to execute " + this , e ) ; throw e ; }
} } @Override public void onFailure ( Throwable ignored ) { // Logged by { @link GetChanges#call ( ) } . } } , directExecutor ( ) ) ; } private abstract class Task < V > implements Callable < V > { protected Event event ; protected Task ( Event event ) { this . event = event ; } @Override public final V call ( ) throws Exception { try ( ManualRequestContext ctx = requestContext . open ( ) ) { < |startfocus| > if ( this instanceof Index ) { queuedIndexTasks . remove ( this ) ; } < |endfocus| > return impl ( ctx ) ; } catch ( Exception e ) { log . error ( "Failed to reindex changes after " + event , e ) ; throw e ; } } protected abstract V impl ( RequestContext ctx ) throws Exception ; } private class GetChanges extends Task < List < Change > > { private GetChanges ( Event event ) { super ( event ) ; } @Override protected List < Change > impl ( RequestContext ctx ) throws OrmException { String ref = event . getRefName ( ) ; Project . NameKey project = new Project . NameKey ( event . getProjectName ( ) ) ; List < Change > changes = new ArrayList < > ( ) ;
import com . googlesource . gerrit . plugins . multisite . forwarder . events . EventFamily ; import java . util . HashMap ; import java . util . Map ; import java . util . Properties ; import java . util . UUID ; import org . apache . kafka . common . serialization . StringSerializer ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . eclipse . jgit . util . FS ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; public class KafkaConfiguration { private static final Logger log = LoggerFactory . getLogger ( KafkaConfiguration . class ) ; public static final String PLUGIN_NAME = "kafka" ; public static final String KAFKA_CONFIG = PLUGIN_NAME + " . config" ; public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp - " ; static final String KAFKA_SECTION = "kafka" ; static final String ENABLE_KEY = "enabled" ; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost : 9092" ; static final boolean DEFAULT_ENABLE_PROCESSING = true ; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000 ; private final Supplier < KafkaSubscriber > subscriber ; private final Supplier < Kafka > kafka ; private final Supplier < KafkaPublisher > publisher ; @Inject
import java . util . Map ; import java . util . Properties ; import java . util . UUID ; import org . apache . kafka . common . serialization . StringSerializer ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . eclipse . jgit . util . FS ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; public class KafkaConfiguration { private static final Logger log = LoggerFactory . getLogger ( KafkaConfiguration . class ) ; < |startfocus| > public static final String PLUGIN_NAME = "kafka" ; public static final String KAFKA_CONFIG = PLUGIN_NAME + " . config" ; < |endfocus| > public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp - " ; static final String KAFKA_SECTION = "kafka" ; static final String ENABLE_KEY = "enabled" ; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost : 9092" ; static final boolean DEFAULT_ENABLE_PROCESSING = true ; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000 ; private final Supplier < KafkaSubscriber > subscriber ; private final Supplier < Kafka > kafka ; private final Supplier < KafkaPublisher > publisher ; @Inject KafkaConfiguration ( SitePaths sitePaths ) { this ( getConfigFile ( sitePaths , KAFKA_CONFIG ) ) ; } @Singleton public static class Module extends LifecycleModule { @Override protected void configure ( ) { listener ( ) . to ( KafkaSubscriber . class ) ; listener ( ) . to ( KafkaPublisher . class ) ; bind ( Kafka . class ) . toProvider ( KafkaProvider . class ) ; } }
import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . eclipse . jgit . util . FS ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; public class KafkaConfiguration { private static final Logger log = LoggerFactory . getLogger ( KafkaConfiguration . class ) ; < |startfocus| > public static final String PLUGIN_NAME = "kafka" ; public static final String KAFKA_CONFIG = PLUGIN_NAME + " . config" ; < |endfocus| > public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp - " ; static final String KAFKA_SECTION = "kafka" ; static final String ENABLE_KEY = "enabled" ; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost : 9092" ; static final boolean DEFAULT_ENABLE_PROCESSING = true ; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000 ; private final Supplier < KafkaSubscriber > subscriber ; private final Supplier < Kafka > kafka ; private final Supplier < KafkaPublisher > publisher ; @Inject KafkaConfiguration ( SitePaths sitePaths ) { this ( getConfigFile ( sitePaths , < |startfocus| > MultiSiteConfiguration . MULTI_SITE_CONFIG < |endfocus| > ) ) ; } @VisibleForTesting public KafkaConfiguration ( Config kafkaConfig ) { Supplier < Config > lazyCfg = ConfigurationHelper . lazyLoad ( kafkaConfig ) ;
import org . apache . kafka . clients . producer . ProducerRecord ; import org . apache . kafka . clients . producer . RecordMetadata ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; import com . google . inject . Inject ; import com . googlesource . gerrit . plugins . multisite . InstanceId ; import com . googlesource . gerrit . plugins . multisite . KafkaConfiguration ; import com . googlesource . gerrit . plugins . multisite . broker . BrokerSession ; import com . googlesource . gerrit . plugins . multisite . forwarder . events . EventFamily ; public class KafkaSession implements BrokerSession { private static final Logger LOGGER = LoggerFactory . getLogger ( KafkaSession . class ) ; < |startfocus| > private KafkaConfiguration kafkaConfig ; < |endfocus| > private final UUID instanceId ; private volatile Producer < String , String > producer ; @Inject public KafkaSession ( KafkaConfiguration kafkaConfig , @InstanceId UUID instanceId ) { this . kafkaConfig = kafkaConfig ; this . instanceId = instanceId ; } @Override public boolean isOpen ( ) { if ( producer != null ) { return true ; } return false ; } @Override public void connect ( ) { if ( isOpen ( ) ) { LOGGER . debug ( "Already connected . " ) ; return ; }
// // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . kafka . consumer ; < |startfocus| > import com . google . gerrit . extensions . registration . DynamicSet ; import com . google . gerrit . lifecycle . LifecycleModule ; import com . google . inject . TypeLiteral ; import com . googlesource . gerrit . plugins . multisite . KafkaConfiguration . KafkaSubscriber ; import com . googlesource . gerrit . plugins . multisite . forwarder . events . EventFamily ; import com . googlesource . gerrit . plugins . multisite . forwarder . events . MultiSiteEvent ; < |endfocus| > import java . util . concurrent . Executor ; import java . util . concurrent . Executors ; import org . apache . kafka . common . serialization . ByteArrayDeserializer ; import org . apache . kafka . common . serialization . Deserializer ; public class KafkaConsumerModule extends LifecycleModule { private final KafkaSubscriber kafkaSubscriber ; public KafkaConsumerModule ( KafkaSubscriber kafkaSubscriber ) { this . kafkaSubscriber = kafkaSubscriber ; } @Override protected void configure ( ) { MultiSiteEvent . registerEventTypes ( ) ;
// // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite ; import static com . google . common . truth . Truth . assertThat ; import static com . googlesource . gerrit . plugins . multisite . Configuration . Cache . CACHE_SECTION ; import static com . googlesource . gerrit . plugins . multisite . Configuration . Cache . PATTERN_KEY ; import static com . googlesource . gerrit . plugins . multisite . Configuration . Event . EVENT_SECTION ; import static com . googlesource . gerrit . plugins . multisite . Configuration . Forwarding . DEFAULT_SYNCHRONIZE ; import static com . googlesource . gerrit . plugins . multisite . Configuration . Forwarding . SYNCHRONIZE_KEY ; import static com . googlesource . gerrit . plugins . multisite . Configuration . Index . INDEX_SECTION ; < |startfocus| > import static com . googlesource . gerrit . plugins . multisite . Configuration . DEFAULT_THREAD_POOL_SIZE ; import static com . googlesource . gerrit . plugins . multisite . Configuration . THREAD_POOL_SIZE_KEY ; < |endfocus| > import org . eclipse . jgit . lib . Config ; import org . junit . Before ; import org . junit . Test ; import org . junit . runner . RunWith ; import org . mockito . junit . MockitoJUnitRunner ;
static final int DEFAULT_INDEX_MAX_TRIES = 2 ; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000 ; static final int DEFAULT_THREAD_POOL_SIZE = 4 ; static final String NUM_STRIPED_LOCKS = "numStripedLocks" ; static final int DEFAULT_NUM_STRIPED_LOCKS = 10 ; static final String ENABLE_KEY = "enabled" ; private final Supplier < Cache > cache ; private final Supplier < Event > event ; private final Supplier < Index > index ; < |startfocus| > private final Supplier < Collection < Message > > replicationConfigValidation ; < |endfocus| > @Inject Configuration ( SitePaths sitePaths ) { this ( getConfigFile ( sitePaths , MULTI_SITE_CONFIG ) , getConfigFile ( sitePaths , REPLICATION_CONFIG ) ) ; } @VisibleForTesting public Configuration ( Config multiSiteConfig , Config replicationConfig ) { Supplier < Config > lazyMultiSiteCfg = lazyLoad ( multiSiteConfig ) ; replicationConfigValidation = lazyValidateReplicatioConfig ( replicationConfig ) ; cache = memoize ( ( ) - > new Cache ( lazyMultiSiteCfg ) ) ; event = memoize ( ( ) - > new Event ( lazyMultiSiteCfg ) ) ; index = memoize ( ( ) - > new Index ( lazyMultiSiteCfg ) ) ; } public Cache cache ( ) { return cache . get ( ) ; } public Event event ( ) { return event . get ( ) ; }
private final int threadPoolSize ; private final List < String > patterns ; private Cache ( Supplier < Config > cfg ) { super ( cfg , CACHE_SECTION ) ; threadPoolSize = getInt ( cfg , CACHE_SECTION , null , THREAD_POOL_SIZE_KEY , DEFAULT_THREAD_POOL_SIZE ) ; patterns = getList ( cfg , CACHE_SECTION , null , PATTERN_KEY ) ; < |startfocus| >
import com . google . common . base . Strings ; import com . google . common . base . Supplier ; import com . google . common . collect . ImmutableMap ; import com . google . gerrit . server . config . SitePaths ; import com . google . inject . Inject ; import com . googlesource . gerrit . plugins . multisite . forwarder . events . EventFamily ; public class KafkaConfiguration { private static final Logger log = LoggerFactory . getLogger ( KafkaConfiguration . class ) ; static final String KAFKA_PROPERTY_PREFIX = "KafkaProp - " ; static final String KAFKA_SECTION = "kafka" ; < |startfocus| > private static final String KAFKA_CONFIG = "multi - site . config" ; private static final String ENABLE_KEY = "enabled" ; private static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost : 9092" ; private static final boolean DEFAULT_ENABLE_PROCESSING = true ; < |endfocus| > private static final int DEFAULT_POLLING_INTERVAL_MS = 1000 ; private final Supplier < KafkaSubscriber > subscriber ; private final Supplier < Kafka > kafka ; private final Supplier < KafkaPublisher > publisher ; @Inject KafkaConfiguration ( SitePaths sitePaths ) { this ( getConfigFile ( sitePaths , Configuration . MULTI_SITE_CONFIG ) ) ; } @VisibleForTesting KafkaConfiguration ( Config kafkaConfig ) { Supplier < Config > lazyCfg = lazyLoad ( kafkaConfig ) ;
projectOperations . allProjectsForUpdate ( ) . add ( allow ( Permission . READ ) . ref ( "refs /* " ) . group ( admins ) ) . update ( ) ; // Remove all read permissions on All - Users . try ( ProjectConfigUpdate u = updateProject ( allUsers ) ) { for ( AccessSection sec : u . getConfig ( ) . getAccessSections ( ) ) { sec . removePermission ( Permission . READ ) ; } u . save ( ) ; } } < |startfocus| > < |endfocus| > private void setUpChanges ( ) throws Exception { gApi . projects ( ) . name ( project . get ( ) ) . branch ( "branch" ) . create ( new BranchInput ( ) ) ; // First 2 changes are merged , which means the tags pointing to them are // visible . projectOperations . project ( project ) . forUpdate ( ) . add ( allow ( Permission . SUBMIT ) . ref ( "refs / for / refs / heads /* " ) . group ( admins ) ) . update ( ) ; PushOneCommit . Result mr = pushFactory . create ( admin . newIdent ( ) , testRepo ) . to ( "refs / for / master % submit" ) ; mr . assertOkStatus ( ) ; cd1 = mr . getChange ( ) ; rc1 = mr . getCommit ( ) ; psRef1 = cd1 . currentPatchSet ( ) . id ( ) . toRefName ( ) ;
// Remove all read permissions on All - Users . try ( ProjectConfigUpdate u = updateProject ( allUsers ) ) { for ( AccessSection sec : u . getConfig ( ) . getAccessSections ( ) ) { sec . removePermission ( Permission . READ ) ; } u . save ( ) ; } } private void setUpChanges ( ) throws Exception { gApi . projects ( ) . name ( project . get ( ) ) . branch ( "branch" ) . create ( new BranchInput ( ) ) ; // First 2 changes are merged , which means the tags pointing to them are // visible . projectOperations . project ( project ) . forUpdate ( ) . add ( allow ( Permission . SUBMIT ) . ref ( "refs / for / refs / heads /* " ) . group ( admins ) ) < |startfocus| > . update ( ) ; < |endfocus| > PushOneCommit . Result mr = pushFactory . create ( admin . newIdent ( ) , testRepo ) . to ( "refs / for / master % submit" ) ; mr . assertOkStatus ( ) ; cd1 = mr . getChange ( ) ; rc1 = mr . getCommit ( ) ; psRef1 = cd1 . currentPatchSet ( ) . id ( ) . toRefName ( ) ; metaRef1 = RefNames . changeMetaRef ( cd1 . getId ( ) ) ; PushOneCommit . Result br = pushFactory . create ( admin . newIdent ( ) , testRepo ) . to ( "refs / for / branch % submit" ) ; br . assertOkStatus ( ) ; cd2 = br . getChange ( ) ; rc2 = br . getCommit ( ) ; psRef2 = cd2 . currentPatchSet ( ) . id ( ) . toRefName ( ) ; metaRef2 = RefNames . changeMetaRef ( cd2 . getId ( ) ) ;
Project . NameKey projectName ) { return create ( allRefsWatcher , perm , queryProvider , projectName , false ) ; } /* * * Returns a single { @link AdvertiseRefsHook } that encompasses a chain of { @link * AdvertiseRefsHook } to be used for advertising when processing a Git push . Omits { @link * HackPushNegotiateHook } as that does not advertise refs on it's own but adds { @code . have } based * on history which is not relevant for the tests we have . < |startfocus| > */ < |endfocus| > public static AdvertiseRefsHook createForTest ( PermissionBackend . ForProject perm , Provider < InternalChangeQuery > queryProvider , Project . NameKey projectName ) { return create ( new AllRefsWatcher ( ) , perm , queryProvider , projectName , true ) ; } private static AdvertiseRefsHook create ( AllRefsWatcher allRefsWatcher , PermissionBackend . ForProject perm , Provider < InternalChangeQuery > queryProvider , Project . NameKey projectName , boolean skipHackPushNegotiateHook ) { List < AdvertiseRefsHook > advHooks = new ArrayList < > ( ) ; advHooks . add ( allRefsWatcher ) ; advHooks . add ( new
} /* * Returns the URL for viewing a comment in a file in a given patch set of a change . */ default Optional < String > getInlineCommentView ( Change change , int patchsetId , String filename , short side , int startLine ) { return getPatchFileView ( change , patchsetId , filename ) . map ( url - > url + String . format ( "@ % s % d" , side == 0 ? "a" : "" , startLine ) ) ; } < |startfocus| > /* * Returns a URL pointing to the settings page . */ < |endfocus| > default Optional < String > getSettingsUrl ( @Nullable String section ) { return getWebUrl ( ) . map ( url - > url + "settings" + ( Strings . isNullOrEmpty ( section ) ? "" : "#" + section ) ) ; } /* * Returns a URL pointing to a documentation page , at a given named anchor . */ default Optional < String > getDocUrl ( String page , String anchor ) { return getWebUrl ( ) . map ( url - > url + "Documentation / " + page + "#" + anchor ) ; } /* * Returns the URL for viewing a comment in a file in a given patch set of a change . */ default Optional < String > getInlineCommentView ( Change change , int patchsetId , String filename , short side , int startLine ) { return getPatchFileView ( change , patchsetId , filename ) . map ( url - > url + String . format ( "@ % s % d" , side == 0 ? "a" : "" , startLine ) ) ; }
public void connect ( ) { if ( isOpen ( ) ) { multisiteLog . debug ( "Already connected . " ) ; return ; } multisiteLog . info ( "Connect to { } . . . " , properties . getKafka ( ) . getBootstrapServers ( ) ) ; /* Need to make sure that the thread of the running connection uses * the correct class loader otherwize you can endup with hard to debug * ClassNotFoundExceptions */ setConnectionClassLoader ( ) ; < |startfocus| > producer = new KafkaProducer < > ( properties . kafkaPublisher ( ) ) ; multisiteLog . info ( "Connection established . " ) ; < |endfocus| >
public void connect ( ) { if ( isOpen ( ) ) { LOGGER . debug ( "Already connected . " ) ; return ; } /* Need to make sure that the thread of the running connection uses * the correct class loader otherwize you can endup with hard to debug * ClassNotFoundExceptions */ setConnectionClassLoader ( ) ; < |startfocus| > producer = producerProvider . get ( ) ; < |endfocus| > LOGGER . info ( "Connection established . " ) ; }
COMMIT_FOOTERS ( 17 ) , /* * Include push certificate information along with any patch sets . */ PUSH_CERTIFICATES ( 18 ) , /* * Include change's reviewer updates . */ REVIEWER_UPDATES ( 19 ) , /* * Set the submittable boolean . */ SUBMITTABLE ( 20 ) , /* * If tracking Ids are included , include detailed tracking Ids info . */ TRACKING_IDS ( 21 ) , /* * Skip mergeability data */ SKIP_MERGEABLE ( 22 ) , < |startfocus| > /* * Skip unnecessary insertions and deletions calculations */ SKIP_INSERT_DELETE ( 23 ) ; < |endfocus| > private final int value ; ListChangesOption ( int v ) { this . value = v ; } @Override public int getValue ( ) { return value ; } }
out . hashtags = cd . hashtags ( ) ; out . changeId = in . getKey ( ) . get ( ) ; if ( in . isNew ( ) ) { SubmitTypeRecord str = cd . submitTypeRecord ( ) ; if ( str . isOk ( ) ) { out . submitType = str . type ; } if ( ! excludeMergeableInChangeInfo && ! has ( SKIP_MERGEABLE ) ) { out . mergeable = cd . isMergeable ( ) ; } if ( has ( SUBMITTABLE ) ) { out . submittable = submittable ( cd ) ; } } < |startfocus| > if ( ! has ( SKIP_INSERT_DELETE ) ) { < |endfocus| > Optional < ChangedLines > changedLines = cd . changedLines ( ) ; if ( changedLines . isPresent ( ) ) { out . insertions = changedLines . get ( ) . insertions ; out . deletions = changedLines . get ( ) . deletions ; } } out . isPrivate = in . isPrivate ( ) ? true : null ; out . workInProgress = in . isWorkInProgress ( ) ? true : null ; out . hasReviewStarted = in . hasReviewStarted ( ) ; out . subject = in . getSubject ( ) ; out . status = in . getStatus ( ) . asChangeStatus ( ) ; out . owner = accountLoader . get ( in . getOwner ( ) ) ;
if ( pr . getAction ( ) == PermissionRule . Action . ALLOW && projectControl . match ( pr , isChangeOwner ) ) { // For votes , contrary to normal permissions , we aggregate all applicable rules . voteMin = Math . min ( voteMin , pr . getMin ( ) ) ; voteMax = Math . max ( voteMax , pr . getMax ( ) ) ; } } < |startfocus| > voteMin = Math . max ( voteMin , blockAllowMin ) ; voteMax = Math . min ( voteMax , blockAllowMax ) ; if ( voteMin > voteMax ) { voteMin = 0 ; voteMax = 0 ; } return new PermissionRange ( permissionName , voteMin , voteMax ) ; < |endfocus| >
public TestRefValidator ( ReceiveCommand . Type rejectType ) { this . rejectType = rejectType ; this . rejectRef = TEST_REF ; < |startfocus| > this . handle = validators . add ( this ) ; < |endfocus| >
if ( valueType == String . class ) { return s - > ( String ) s ; } else if ( valueType == Integer . class || valueType == Boolean . class ) { return Object : : toString ; } else if ( Enum . class . isAssignableFrom ( valueType ) ) { return in - > ( ( Enum < ? > ) in ) . name ( ) ; } throw new IllegalStateException ( "unsupported type " + valueType . getName ( ) ) ; } @AutoValue . Builder public abstract static class Builder < T > { abstract Builder < T > name ( String name ) ; abstract Builder < T > valueType ( Class < T > type ) ; < |startfocus| > < |endfocus| > public abstract Builder < T > description ( String description ) ; abstract Field < T > autoBuild ( ) ; public Field < T > build ( ) { Field < T > field = autoBuild ( ) ; checkArgument ( field . name ( ) . matches ( " ^ [ a - z_ ] + $" ) , "name must match [ a - z_ ] " ) ; return field ; } } }
} private Function < T , String > formatter ; /* * @return name of this field within the metric . */ public abstract String name ( ) ; /* * @return type of value used within the field . */ public abstract Class < T > valueType ( ) ; /* * @return description text for the field explaining its range of values . */ public abstract Optional < String > description ( ) ; < |startfocus| > @Memoized public Function < T , String > formatter ( ) { return initFormatter ( valueType ( ) ) ; } < |endfocus| > private static < T > Function < T , String > initFormatter ( Class < T > valueType ) { if ( valueType == String . class ) { return s - > ( String ) s ; } else if ( valueType == Integer . class || valueType == Boolean . class ) { return Object : : toString ; } else if ( Enum . class . isAssignableFrom ( valueType ) ) { return in - > ( ( Enum < ? > ) in ) . name ( ) ; } throw new IllegalStateException ( "unsupported type " + valueType . getName ( ) ) ; } @AutoValue . Builder
reject ( cmd , "not valid ref" ) ; return ; } if ( RefNames . isNoteDbMetaRef ( cmd . getRefName ( ) ) ) { // Reject pushes to NoteDb refs without a special option and permission . Note that this // prohibition doesn't depend on NoteDb being enabled in any way , since all sites will // migrate to NoteDb eventually , and we don't want garbage data waiting there when the // migration finishes . < |startfocus| > logger . atFine ( ) . log ( < |endfocus| > " % s NoteDb ref % s with % s = % s" , cmd . getType ( ) , cmd . getRefName ( ) , NoteDbPushOption . OPTION_NAME , noteDbPushOption ) ; if ( ! Optional . of ( NoteDbPushOption . ALLOW ) . equals ( noteDbPushOption ) ) { // Only reject this command , not the whole push . This supports the use case of "git clone // -- mirror" followed by "git push -- mirror" , when the user doesn't really intend to clone // or mirror the NoteDb data ; there is no single refspec that describes all refs * except * // NoteDb refs . reject ( cmd , "not allowed to push NoteDb refs" ) ; return ; } }
< |startfocus| > public Context start ( F1 field1 ) { return new Context ( this , field1 ) ; } < |endfocus| >
. valueType ( Boolean . class ) . formatter ( Object : : toString ) . name ( name ) ; } /* * * Break down metrics by cases of an enum . * * @param enumType type of enum * @param name field name * @return builder for the enum field */ public static < E extends Enum < E > > Field . Builder < E > ofEnum ( Class < E > enumType , String name ) { < |startfocus| > return new AutoValue_Field . Builder < E > ( ) . valueType ( enumType ) . formatter ( Enum : : name ) . name ( name ) ; < |endfocus| > } /* * * Break down metrics by integer . * * < p > Each unique integer will allocate a new submetric . < b > Do not use user content as a field * value </ b > as field values are never reclaimed . * * @param name field name * @return builder for the integer field */ public static Field . Builder < Integer > ofInteger ( String name ) { return new AutoValue_Field . Builder < Integer > ( ) . valueType ( Integer . class ) . formatter ( Object : : toString )
public RequestMetrics ( MetricMaker metricMaker ) { Field < Integer > statusCodeField = < |startfocus| > Field . ofInteger ( "status" , Metadata . Builder : : httpStatus ) < |endfocus| > . description ( "HTTP status code" ) . build ( ) ; errors = metricMaker . newCounter ( "http / server / error_count" , new Description ( "Rate of REST API error responses" ) . setRate ( ) . setUnit ( "errors" ) , statusCodeField ) ; successes = metricMaker . newCounter ( "http / server / success_count" , new Description ( "Rate of REST API success responses" ) . setRate ( ) . setUnit ( "successes" ) , statusCodeField ) ;
package com . google . gerrit . metrics ; import static com . google . common . base . Preconditions . checkArgument ; import com . google . auto . value . AutoValue ; import java . util . Optional ; import java . util . function . BiConsumer ; import java . util . function . Function ; /* * * Describes a bucketing field used by a metric . * * @param < T > type of field */ @AutoValue public abstract class Field < T > { /* * * Break down metrics by boolean true / false . * * @param name field name * @return builder for the boolean field */ < |startfocus| > public static Field . Builder < Boolean > ofBoolean ( String name ) { < |endfocus| > return new AutoValue_Field . Builder < Boolean > ( ) . valueType ( Boolean . class ) . formatter ( Object : : toString ) . name ( name ) ; } /* * * Break down metrics by cases of an enum . * * @param enumType type of enum * @param name field name * @return builder for the enum field */ public static < E extends Enum < E > > Field . Builder < E > ofEnum ( Class < E > enumType , String name ) {
public abstract Class < T > valueType ( ) ; /* * @return description text for the field explaining its range of values . */ public abstract Optional < String > description ( ) ; /* * @return formatter to format field values . */ public abstract Function < T , String > formatter ( ) ; @AutoValue . Builder public abstract static class Builder < T > { abstract Builder < T > name ( String name ) ; abstract Builder < T > valueType ( Class < T > type ) ; abstract Builder < T > formatter ( Function < T , String > formatter ) ; /* * @return description text for the field explaining its range of values . */ public abstract Builder < T > description ( String description ) ; abstract Field < T > autoBuild ( ) ; public Field < T > build ( ) { Field < T > field = autoBuild ( ) ; checkArgument ( field . name ( ) . matches ( " ^ [ a - z_ ] + $" ) , "name must match [ a - z_ ] " ) ; return field ; } } }
@Singleton public class UploadPackMetricsHook implements PostUploadHook { enum Operation { CLONE , FETCH ; } private final Counter1 < Operation > requestCount ; private final Timer1 < Operation > counting ; private final Timer1 < Operation > compressing ; private final Timer1 < Operation > writing ; private final Histogram1 < Operation > packBytes ; @Inject UploadPackMetricsHook ( MetricMaker metricMaker ) { Field < Operation > operationField = < |startfocus| > Field . ofEnum ( Operation . class , "operation" , ( metadataBuilder , fieldValue ) - > metadataBuilder . gitOperation ( fieldValue . toString ( ) ) ) . build ( ) ; < |endfocus| > requestCount = metricMaker . newCounter ( "git / upload - pack / request_count" , new Description ( "Total number of git - upload - pack requests" ) . setRate ( ) . setUnit ( "requests" ) , operationField ) ; counting = metricMaker . newTimer ( "git / upload - pack / phase_counting" , new Description ( "Time spent in the 'Counting . . . ' phase" ) . setCumulative ( ) . setUnit ( Units . MILLISECONDS ) , operationField ) ; compressing = metricMaker . newTimer ( "git / upload - pack / phase_compressing" , new Description ( "Time spent in the 'Compressing . . . ' phase" )
// The name of a branch . public abstract Optional < String > branchName ( ) ; // Key of an entity in a cache . public abstract Optional < String > cacheKey ( ) ; // The name of a cache . public abstract Optional < String > cacheName ( ) ; // The name of the implementation class . public abstract Optional < String > className ( ) ; // The numeric ID of a change . public abstract Optional < Integer > changeId ( ) ; // The type of change ID ( e . g . numeric ID , triplet etc . ) . public abstract Optional < String > changeIdType ( ) ; // The type of an event . public abstract Optional < String > eventType ( ) ; // The name under which a plugin extension was registered . public abstract Optional < String > exportName ( ) ; // Garbage collector name . public abstract Optional < String > garbageCollectorName ( ) ; // Git operation ( CLONE , FETCH ) . public abstract Optional < String > gitOperation ( ) ; // The numeric ID of an internal group . public abstract Optional < Integer > groupId ( ) ; // The name of a group . public abstract Optional < String > groupName ( ) ;
public abstract Optional < String > cacheName ( ) ; // The name of the implementation class . public abstract Optional < String > className ( ) ; // The numeric ID of a change . public abstract Optional < Integer > changeId ( ) ; // The type of change ID ( e . g . numeric ID , triplet etc . ) . public abstract Optional < String > changeIdType ( ) ; // The type of an event . public abstract Optional < String > eventType ( ) ; // The name under which a plugin extension was registered . public abstract Optional < String > exportName ( ) ; // Garbage collector name . public abstract Optional < String > garbageCollectorName ( ) ; // Git operation ( CLONE , FETCH ) . public abstract Optional < String > gitOperation ( ) ; // The numeric ID of an internal group . public abstract Optional < Integer > groupId ( ) ; // The name of a group . public abstract Optional < String > groupName ( ) ; // The UUID of a group . public abstract Optional < String > groupUuid ( ) ; // HTTP status response code . public abstract Optional < Integer > httpStatus ( ) ; // The name of a secondary index .
public abstract Optional < Integer > groupId ( ) ; // The name of a group . public abstract Optional < String > groupName ( ) ; // The UUID of a group . public abstract Optional < String > groupUuid ( ) ; // HTTP status response code . public abstract Optional < Integer > httpStatus ( ) ; // The name of a secondary index . public abstract Optional < String > indexName ( ) ; // The version of a secondary index . public abstract Optional < Integer > indexVersion ( ) ; < |startfocus| > // An LDAP domain name . public abstract Optional < String > authDomainName ( ) ; < |endfocus| > // The name of the implementation method . public abstract Optional < String > methodName ( ) ; // Boolean : one or more public abstract Optional < Boolean > multiple ( ) ; // Name of a metadata file in NoteDb . public abstract Optional < String > noteDbFileName ( ) ; // Name of a metadata ref in NoteDb . public abstract Optional < String > noteDbRefName ( ) ; // Type of a sequence in NoteDb ( ACCOUNTS , CHANGES , GROUPS ) . public abstract Optional < String > noteDbSequenceType ( ) ;
public abstract Optional < String > restViewName ( ) ; // The SHA1 of Git commit . public abstract Optional < String > revision ( ) ; // The username of an account . public abstract Optional < String > username ( ) ; public static Metadata . Builder builder ( ) { return new AutoValue_Metadata . Builder ( ) ; } public static Metadata empty ( ) { return builder ( ) . build ( ) ; } @AutoValue . Builder public abstract static class Builder { public abstract Builder accountId ( int accountId ) ; public abstract Builder actionType ( @Nullable String actionType ) ; public abstract Builder branchName ( @Nullable String branchName ) ; public abstract Builder cacheKey ( @Nullable String cacheKey ) ; public abstract Builder cacheName ( @Nullable String cacheName ) ; public abstract Builder className ( @Nullable String className ) ; public abstract Builder changeId ( int changeId ) ; public abstract Builder changeIdType ( @Nullable String changeIdType ) ; public abstract Builder eventType ( @Nullable String eventType ) ; public abstract Builder exportName ( @Nullable String exportName ) ; public abstract Builder garbageCollectorName ( @Nullable String garbageCollectorName ) ; public abstract Builder gitOperation ( @Nullable String gitOperation ) ; < |startfocus| > < |endfocus| > public abstract Builder groupId ( int groupId ) ; public abstract Builder groupName ( @Nullable String groupName ) ; public abstract Builder httpMethod ( @Nullable String httpMethod ) ; public abstract Builder httpStatus ( int httpStatus ) ; public abstract Builder httpUrl ( @Nullable String httpUrl ) ; public abstract Builder indexName ( @Nullable String indexName ) ; public abstract Builder indexType ( @Nullable String indexType ) ; public abstract Builder indexUuid ( @Nullable String indexUuid ) ; public abstract Builder ipAddress ( @Nullable String ipAddress ) ; public abstract Builder labelId ( int labelId ) ; public abstract Builder labelName ( @Nullable String labelName ) ; public abstract Builder labelValue ( int labelValue ) ; public abstract Builder mergeResult ( @Nullable String mergeResult ) ; public abstract Builder mergeStrategy ( @Nullable String mergeStrategy ) ; public abstract Builder newBranchName ( @Nullable String newBranchName ) ; public abstract Builder newChangeId ( int newChangeId ) ; public abstract Builder newChangeIdType ( @Nullable String newChangeIdType ) ; public abstract Builder newGroupId ( int newGroupId ) ; public abstract Builder newGroupName ( @Nullable String newGroupName ) ; public abstract Builder newProjectName ( @Nullable String newProjectName ) ; public abstract Builder newRefName ( @Nullable String newRefName ) ; public abstract Builder newRevision ( @Nullable String newRevision ) ; public abstract Builder newTopic ( @Nullable String newTopic ) ; public abstract Builder oldBranchName ( @Nullable String oldBranchName ) ; public abstract Builder oldChangeId ( int oldChangeId ) ; public abstract Builder oldChangeIdType ( @Nullable String oldChangeIdType ) ; public abstract Builder oldGroupId ( int oldGroupId ) ; public abstract Builder oldGroupName ( @Nullable String oldGroupName ) ; public abstract Builder oldProjectName ( @Nullable String oldProjectName ) ; public abstract Builder oldRefName ( @Nullable String oldRefName ) ; public abstract Builder oldRevision ( @Nullable String oldRevision ) ; public abstract Builder oldTopic ( @Nullable String oldTopic ) ; public abstract Builder operation ( @Nullable String operation ) ; public abstract Builder pluginName ( @Nullable String pluginName ) ; public abstract Builder projectName ( @Nullable String projectName ) ; public abstract Builder refName ( @Nullable String refName ) ; public abstract Builder refOperation ( @Nullable String refOperation ) ; public abstract Builder refUpdate ( @Nullable String refUpdate ) ; public abstract Builder remoteHostname ( @Nullable String remoteHostname ) ; public abstract Builder remoteName ( @Nullable String remoteName ) ; public abstract Builder remoteUrl ( @Nullable String remoteUrl ) ; public abstract Builder requestId ( @Nullable String requestId ) ; public abstract Builder requestMethod ( @Nullable String requestMethod ) ; public abstract Builder requestUri ( @Nullable String requestUri ) ; public abstract Builder revision ( @Nullable String revision ) ; public abstract Builder serverId ( @Nullable String serverId ) ; public abstract Builder sessionId ( @Nullable String sessionId ) ; public abstract Builder shard ( int shard ) ; public abstract Builder source ( @Nullable String source ) ; public abstract Builder status ( @Nullable String status ) ; public abstract Builder tagName ( @Nullable String tagName ) ; public abstract Builder target ( @Nullable String target ) ; public abstract Builder threadName ( @Nullable String threadName ) ; public abstract Builder topic ( @Nullable String topic ) ; public abstract Builder userAgent ( @Nullable String userAgent ) ; public abstract Builder username ( @Nullable String username ) ; public abstract Builder uuid ( @Nullable String uuid ) ; public abstract Metadata build ( ) ; } }
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . logging ; import static java . util . Objects . requireNonNull ; import com . google . auto . value . AutoValue ; import com . google . gerrit . common . Nullable ; /* * * The record of an operation for which the execution time was measured . * < |startfocus| > * < p > Meta data is stored in separate key / value fields to avoid expensive instantiations of Map * objects . < |endfocus| > */ @AutoValue public abstract class PerformanceLogRecord { /* * * Creates a performance log record without meta data . * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @return the performance log record */ public static PerformanceLogRecord create ( String operation , long durationMs ) { return new AutoValue_PerformanceLogRecord ( operation , durationMs , null ) ; } /* * * Creates a performance log record with meta data . *
} /* * * Creates a performance log record with meta data . * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @param metadata metadata * @return the performance log record */ public static PerformanceLogRecord create ( String operation , long durationMs , Metadata metadata ) { return new AutoValue_PerformanceLogRecord ( operation , durationMs , requireNonNull ( metadata ) ) ; } public abstract String operation ( ) ; public abstract long durationMs ( ) ; < |startfocus| > public abstract Optional < Metadata > metadata ( ) ; < |endfocus| > void writeTo ( PerformanceLogger performanceLogger ) { if ( metadata ( ) . isPresent ( ) ) { performanceLogger . log ( operation ( ) , durationMs ( ) , metadata ( ) . get ( ) ) ; } else { performanceLogger . log ( operation ( ) , durationMs ( ) ) ; } } }
if ( refEnforcementPolicy == EnforcePolicy . IGNORED ) return ; String errorMessage = String . format ( "Not able to persist the data in Zookeeper for project ' % s' and ref ' % s' , " + "the cluster is now in Split Brain since the commit has been " + "persisted locally but not in SharedRef the value % s" , projectName , refPair . getName ( ) , refPair . putValue ) ; boolean succeeded ; try { < |startfocus| > succeeded = sharedRefDb . compareAndPut ( projectName , refPair . getValue ( ) , refPair . putValue ) ; < |endfocus| > } catch ( IOException e ) { throw new SharedDbSplitBrainException ( errorMessage , e ) ; } if ( ! succeeded ) { throw new SharedDbSplitBrainException ( errorMessage ) ; } } protected void checkIfLocalRefIsUpToDateWithSharedRefDb ( RefPair refPair , CloseableSet < AutoCloseable > locks ) throws SharedLockException , OutOfSyncException , IOException { String refName = refPair . getName ( ) ; EnforcePolicy refEnforcementPolicy = refEnforcement . getPolicy ( projectName , refName ) ; if ( refEnforcementPolicy == EnforcePolicy . IGNORED ) { return ; }
} } private void updateSharedRefDb ( Stream < ReceiveCommand > commandStream , List < RefPair > refsToUpdate ) throws IOException { if ( commandStream . filter ( cmd - > cmd . getResult ( ) != ReceiveCommand . Result . OK ) . findFirst ( ) . isPresent ( ) ) { return ; } List < RefPair > updatedRefPairs = refsToUpdate . stream ( ) . filter ( distinctByKey ( BatchRefUpdateValidator : : getName ) ) . map ( p - > { try { Ref current = getLatestLocalRef ( p ) ; return new RefPair ( p . compareRef , current . getObjectId ( ) ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } ) . collect ( Collectors . toList ( ) ) ; for ( RefPair refPair : updatedRefPairs ) { updateSharedDbOrThrowExceptionFor ( refPair ) ; } } public static String getName ( RefPair p ) { return p . compareRef . getName ( ) ; } public static < T > Predicate < T > distinctByKey ( Function < ? super T , ? > keyExtractor ) { Set < Object > seen = ConcurrentHashMap . newKeySet ( ) ;
return get ( Arrays . asList ( options ) ) ; } /* * * { @link #get ( ListChangesOption . . . ) } with all options included , except for the following . * * < ul > * < li > { @code CHECK } is omitted , to skip consistency checks . * < li > { @code SKIP_MERGEABLE } is omitted , so the { @code mergeable } bit < em > is </ em > set . < |startfocus| > * < li > { @code SKIP_DIFFSTAT } is omitted to ensure diffstat calculations . < |endfocus| > * </ ul > */ default ChangeInfo get ( ) throws RestApiException { return get ( EnumSet . complementOf ( EnumSet . of ( ListChangesOption . CHECK , ListChangesOption . SKIP_MERGEABLE , ListChangesOption . SKIP_DIFFSTAT ) ) ) ; } /* * { @link #get ( ListChangesOption . . . ) } with no options included . */ default ChangeInfo info ( ) throws RestApiException { return get ( EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( ) throws RestApiException { return edit ( EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( EnumSet ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( EnumSet < ListChangesOption > options ) throws RestApiException { return edit ( options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( ListChangesOption . . . options ) throws RestApiException { return edit ( Arrays . asList ( options ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( List ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( List < ListChangesOption > options ) throws RestApiException { return edit ( options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base ) throws RestApiException { return edit ( base , EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , EnumSet ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , EnumSet < ListChangesOption > options ) throws RestApiException { return edit ( base , options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , ListChangesOption . . . options ) throws RestApiException { return edit ( base , Arrays . asList ( options ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , List ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , List < ListChangesOption > options ) throws RestApiException { return edit ( base , options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path ) throws RestApiException { return edit ( base , path , EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String , EnumSet ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path , EnumSet < ListChangesOption > options ) throws RestApiException { return edit ( base , path , options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String , ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path , ListChangesOption . . . options ) throws RestApiException { return edit ( base , path , Arrays . asList ( options ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String , List ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path , List < ListChangesOption > options ) throws RestApiException { return edit ( base , path , options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String , String ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path , String revision ) throws RestApiException { return edit ( base , path , revision , EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String , String , EnumSet ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path , String revision , EnumSet < ListChangesOption > options ) throws RestApiException { return edit ( base , path , revision , options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String , String , ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path , String revision , ListChangesOption . . . options ) throws RestApiException { return edit ( base , path , revision , Arrays . asList ( options ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( String , String , String , List ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String base , String path , String revision , List < ListChangesOption > options ) throws RestApiException { return edit ( base , path , revision , options . toArray ( new ListChangesOption [
case DELETE : return new RefPair ( getCurrentRef ( command . getRefName ( ) ) , ObjectId . zeroId ( ) ) ; default : return new RefPair ( command . getRef ( ) , new IllegalArgumentException ( "Unsupported command type " + command . getType ( ) ) ) ; } } catch ( IOException e ) { return new RefPair ( command . getRef ( ) , e ) ; } } private ObjectId getNewRef ( ReceiveCommand command ) { return command . getNewId ( ) ; } < |startfocus| > private List < RefPair > getRefPairsToUpdate ( < |endfocus| > List < RefPair > refsToUpdate , CloseableSet < AutoCloseable > locks ) throws IOException { List < RefPair > latestRefsToUpdate = new ArrayList < > ( ) ; for ( RefPair refPair : refsToUpdate ) { latestRefsToUpdate . add ( checkIfLocalRefIsUpToDateWithSharedRefDb ( refPair , locks ) ) ; } return latestRefsToUpdate ; } }
+ "persisted locally but not in SharedRef the value % s" , projectName , refPair . getName ( ) , refPair . putValue ) ; boolean succeeded ; try { succeeded = sharedRefDb . compareAndPut ( projectName , refPair . compareRef , refPair . putValue ) ; } catch ( IOException e ) { throw new SharedDbSplitBrainException ( errorMessage , e ) ; } if ( ! succeeded ) { throw new SharedDbSplitBrainException ( errorMessage ) ; } } < |startfocus| > protected RefPair getRefPairToUpdate ( < |endfocus| > RefPair refPair , CloseableSet < AutoCloseable > locks ) throws SharedLockException , OutOfSyncException , IOException { String refName = refPair . getName ( ) ; EnforcePolicy refEnforcementPolicy = refEnforcement . getPolicy ( projectName , refName ) ; if ( refEnforcementPolicy == EnforcePolicy . IGNORED ) { return refPair ; } locks . addResourceIfNotExist ( String . format ( " % s - % s" , projectName , refName ) , ( ) - > sharedRefDb . lockRef ( projectName , refName ) ) ; RefPair latestRefPair = getLatestLocalRef ( refPair ) ; boolean isInSync =
info = getPatchSetInfo ( ctx ) ; ChangeUpdate update = ctx . getUpdate ( psId ) ; Change . Status status = change . getStatus ( ) ; if ( status == Change . Status . MERGED ) { return true ; } change . setCurrentPatchSet ( info ) ; change . setStatus ( Change . Status . MERGED ) ; // we cannot reconstruct the submit records for when this change was // submitted , this is why we must fix the status update . fixStatus ( Change . Status . MERGED ) ; update . setCurrentPatchSet ( ) ; if ( change . isWorkInProgress ( ) ) { < |startfocus| > change . setWorkInProgress ( false ) ; update . setWorkInProgress ( false ) ; < |endfocus| > } StringBuilder msgBuf = new StringBuilder ( ) ; msgBuf . append ( "Change has been successfully pushed" ) ; if ( ! refName . equals ( change . getDest ( ) . get ( ) ) ) { msgBuf . append ( " into " ) ; if ( refName . startsWith ( Constants . R_HEADS ) ) { msgBuf . append ( "branch " ) ; msgBuf . append ( Repository . shortenRefName ( refName ) ) ; } else { msgBuf . append ( refName ) ; } } msgBuf . append ( " . " ) ; ChangeMessage msg = ChangeMessagesUtil . newMessage (
fields = config . getBoolean ( "logFormat" , pretty , "verbose" , false ) ? VERBOSE_FIELDS : FIELDS ; variant = firstNonNull ( config . getString ( "logFormat" , pretty , "variant" ) , pretty ) ; } public void renderStreaming ( Paginator paginator , @Nullable String revision , Renderer renderer , Writer out , DateFormatter df , FooterBehavior footerBehavior ) throws IOException { out . write ( renderer . newRenderer ( "gitiles . logEntriesHeader" ) . setData ( toHeaderSoyData ( paginator , revision ) ) < |startfocus| > . render ( ) . get ( ) ) ; < |endfocus| > SoySauce . Renderer entryRenderer = renderer . newRenderer ( "gitiles . logEntryWrapper" ) ; boolean renderedEntries = false ; for ( RevCommit c : paginator ) { out . write ( entryRenderer . setData ( toEntrySoyData ( paginator , c , df ) ) . render ( ) . get ( ) ) ; out . flush ( ) ; renderedEntries = true ; } if ( ! renderedEntries ) { renderer . newRenderer ( "gitiles . emptyLog" ) . render ( ) . get ( ) ; } out . write ( renderer . newRenderer ( "gitiles . logEntriesFooter" ) . setData ( toFooterSoyData ( paginator , revision , footerBehavior ) ) . render ( ) . get ( ) ) ; } private Map < String , Object > toHeaderSoyData ( Paginator paginator , @Nullable String revision ) { Map < String , Object > data = Maps . newHashMapWithExpectedSize ( 2 ) ; data . put ( "paginator" , paginator ) ; data . put ( "revision" , revision ) ; return data ; } private Map < String , Object > toEntrySoyData ( Paginator paginator , RevCommit c , DateFormatter df ) { Map < String , Object > data = Maps . newHashMapWithExpectedSize ( 3 ) ; data . put ( "paginator" , paginator ) ; data . put ( "commit" , c ) ; data . put ( "dateFormatter" , df ) ; return data ; } private Map < String , Object > toFooterSoyData ( Paginator paginator , @Nullable String revision , FooterBehavior footerBehavior ) { Map < String , Object > data = Maps . newHashMapWithExpectedSize ( 3 ) ; data . put ( "paginator" , paginator ) ; data . put ( "revision" , revision ) ; data . put ( "footerBehavior" , footerBehavior ) ; return data ; } }
private boolean isInternalRef ( String refName ) { < |startfocus| > return RefNames . isGerritRef ( refName ) || RefNames . isNoteDbMetaRef ( refName ) ; < |endfocus| >
private boolean isInternalRef ( String refName ) { < |startfocus| > return RefNames . isGerritRef ( refName ) ; < |endfocus| >
EnforcePolicy refEnforcementPolicy = refEnforcement . getPolicy ( projectName , refName ) ; if ( refEnforcementPolicy == EnforcePolicy . IGNORED ) { return refPair ; } locks . addResourceIfNotExist ( String . format ( " % s - % s" , projectName , refName ) , ( ) - > sharedRefDb . lockRef ( projectName , refName ) ) ; Ref localRef = getLatestLocalRef ( refPair ) ; boolean isInSync = < |startfocus| > ( localRef != null ) ? sharedRefDb . isUpToDate ( projectName , localRef ) : ! sharedRefDb . exists ( projectName , refName ) ; < |endfocus| > if ( ! isInSync ) { validationMetrics . incrementSplitBrainPrevention ( ) ; softFailBasedOnEnforcement ( new OutOfSyncException ( projectName , localRef ) , refEnforcementPolicy ) ; } return new RefPair ( localRef == null ? nullRef ( refName ) : localRef , refPair . putValue ) ; } private Ref getLatestLocalRef ( RefPair refPair ) throws IOException { return refDb . exactRef ( refPair . getName ( ) ) ; } protected boolean isSuccessful ( RefUpdate . Result result ) { switch ( result ) { case NEW : case FORCED : case FAST_FORWARD : case NO_CHANGE :
HttpServletResponse res , int statusCode , String msg , CacheControl c , @Nullable Throwable err ) throws IOException { if ( err != null ) { RequestUtil . setErrorTraceAttribute ( req , err ) ; } configureCaching ( req , res , null , null , c ) ; checkArgument ( statusCode >= 400 , "non - error status : % s" , statusCode ) ; res . setStatus ( statusCode ) ; < |startfocus| > logger . atWarning ( ) . withCause ( err ) . log ( "REST call failed : % d" , statusCode ) ; < |endfocus| > return replyText ( req , res , true , msg ) ; } /* * * Sets a text reply on the given HTTP servlet response . * * @param req the HTTP servlet request * @param res the HTTP servlet response on which the reply should be set * @param allowTracing whether it is allowed to log the reply if tracing is enabled , must not be * set to { @code true } if the reply may contain sensitive data * @param text the text reply
} return Optional . empty ( ) ; } private Optional < Project . NameKey > getProjectNameForChangeId ( String changeId ) { Optional < Project . NameKey > projectName = extractProjectNameFromChangeId ( changeId ) ; if ( projectName . isPresent ( ) ) { return projectName ; } try { List < ChangeData > changeData = globals . queryProvider . get ( ) . setRequestedFields ( ChangeField . PROJECT ) . setLimit ( 2 ) . query ( globals . changeQueryBuilder . change ( changeId ) ) ; < |startfocus| > if ( changeData . isEmpty ( ) ) { < |endfocus| > return Optional . empty ( ) ; } return Optional . of ( changeData . get ( 0 ) . project ( ) ) ; } catch ( QueryParseException e ) { return Optional . empty ( ) ; } } @VisibleForTesting static Optional < Project . NameKey > extractProjectNameFromChangeId ( String changeId ) { int projectEndPosition = changeId . indexOf ( '~' ) ; if ( projectEndPosition <= 0 ) { return Optional . empty ( ) ; } return Optional . of ( Project . nameKey ( IdString . fromUrl ( changeId . substring ( 0 , projectEndPosition ) ) . get ( ) ) ) ; } private boolean isDelete ( HttpServletRequest req ) {
package com . google . gerrit . server ; import com . google . auto . value . AutoValue ; import com . google . gerrit . reviewdb . client . Project ; import com . google . gerrit . server . logging . TraceContext ; import java . util . Optional ; /* * Information about a request that was received from a user . */ @AutoValue public abstract class RequestInfo { public enum RequestType { GIT_RECEIVE , GIT_UPLOAD , REST , SSH } /* * < |startfocus| > * Type of the request , telling through which channel the request was coming in ( REST , Git * receive , git upload , SSH ) . < |endfocus| > */ public abstract RequestType requestType ( ) ; /* * The user that has sent the request . */ public abstract CurrentUser callingUser ( ) ; /* * The trace context of the request . */ public abstract TraceContext traceContext ( ) ; /* * * The name of the project for which the request is being done . Only available if the request is * tied to a project or change . If a project is available it's not guaranteed that it actually
import com . google . common . hash . Hashing ; import com . google . gerrit . common . data . GroupReference ; import com . google . gerrit . extensions . annotations . PluginCanonicalWebUrl ; import com . google . gerrit . extensions . annotations . PluginName ; import com . google . gerrit . extensions . api . groups . Groups ; import com . google . gerrit . extensions . common . GroupInfo ; import com . google . gerrit . extensions . restapi . AuthException ; import com . google . gerrit . extensions . restapi . ResourceConflictException ; import com . google . gerrit . extensions . restapi . RestApiException ; import com . google . gerrit . reviewdb . client . AccountGroup ; import com . google . gerrit . reviewdb . client . Project ; import com . google . gerrit . server . CurrentUser ; import com . google . gerrit . server . account . GroupMembership ; import com . google . gerrit . server . config . AllProjectsNameProvider ; import com . google . gerrit . server . config . PluginConfigFactory ; import com . google . gerrit . server . permissions . GlobalPermission ; import com . google . gerrit . server . permissions . PermissionBackend ; import com . google . gerrit . server . permissions . PermissionBackendException ; import com . google . gerrit . server . permissions . ProjectPermission ; import com . google . gerrit . server . project . CreateProjectArgs ; import com . google . gerrit . server . project . NoSuchProjectException ; import com . google . gerrit . server . validators . ProjectCreationValidationListener ; import com . google . gerrit . server . validators . ValidationException ;
< |startfocus| > private boolean isOwner ( Project . NameKey project ) { < |endfocus| > try { permissionBackend . user ( self . get ( ) ) . project ( project ) . check ( ProjectPermission . WRITE_CONFIG ) ; } catch ( AuthException | PermissionBackendException noWriter ) { try { permissionBackend . user ( self . get ( ) ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; } catch ( AuthException | PermissionBackendException noAdmin ) { return false ; } } return true ;
return get ( Arrays . asList ( options ) ) ; } /* * * { @link #get ( ListChangesOption . . . ) } with all options included , except for the following . * * < ul > * < li > { @code CHECK } is omitted , to skip consistency checks . * < li > { @code SKIP_MERGEABLE } is omitted , so the { @code mergeable } bit < em > is </ em > set . < |startfocus| > * < li > { @code SKIP_DIFFSTAT } is omitted to skip diffstat calculations . < |endfocus| > * </ ul > */ default ChangeInfo get ( ) throws RestApiException { return get ( EnumSet . complementOf ( EnumSet . of ( ListChangesOption . CHECK , ListChangesOption . SKIP_MERGEABLE , ListChangesOption . SKIP_DIFFSTAT ) ) ) ; } /* * { @link #get ( ListChangesOption . . . ) } with no options included . */ default ChangeInfo info ( ) throws RestApiException { return get ( EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( ) throws RestApiException { return edit ( EnumSet . noneOf ( ListChangesOption . class ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( EnumSet ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( EnumSet < ListChangesOption > options ) throws RestApiException { return edit ( options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( ListChangesOption . . . options ) throws RestApiException { return edit ( Arrays . asList ( options ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( List < ListChangesOption > options ) throws RestApiException { return edit ( options . toArray ( new ListChangesOption [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String . . . options ) throws RestApiException { return edit ( Arrays . asList ( options ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( List < String > options ) throws RestApiException { return edit ( options . toArray ( new String [ options . size ( ) ] ) ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( EnumSet < ListChangesOption > options , String . . . paths ) throws RestApiException { return edit ( options . toArray ( new ListChangesOption [ options . size ( ) ] ) , paths ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( ListChangesOption [ ] options , String . . . paths ) throws RestApiException { return edit ( Arrays . asList ( options ) , paths ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( List < ListChangesOption > options , String . . . paths ) throws RestApiException { return edit ( options . toArray ( new ListChangesOption [ options . size ( ) ] ) , paths ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String [ ] options , String . . . paths ) throws RestApiException { return edit ( Arrays . asList ( options ) , paths ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( List < String > options , String . . . paths ) throws RestApiException { return edit ( options . toArray ( new String [ options . size ( ) ] ) , paths ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( EnumSet < ListChangesOption > options , List < String > paths ) throws RestApiException { return edit ( options . toArray ( new ListChangesOption [ options . size ( ) ] ) , paths ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( ListChangesOption [ ] options , List < String > paths ) throws RestApiException { return edit ( Arrays . asList ( options ) , paths ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( List < ListChangesOption > options , List < String > paths ) throws RestApiException { return edit ( options . toArray ( new ListChangesOption [ options . size ( ) ] ) , paths ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( String [ ] options , List < String > paths ) throws RestApiException { return edit ( Arrays . asList ( options ) , paths ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( List < String > options , List < String > paths ) throws RestApiException { return edit ( options . toArray ( new String [ options . size ( ) ] ) , paths ) ; } /* * * Retrieve change edit when exists . * * @deprecated Replaced by { @link ChangeApi#edit ( ) } in combination with { @link ChangeEditApi#get ( ListChangesOption . . . ) } . */ @Deprecated default Optional < ChangeEditInfo > edit ( EnumSet < ListChangesOption > options , List < String > paths , String base ) throws RestApiException { return
/* * Include a copy of commit messages including review footers . */ COMMIT_FOOTERS ( 17 ) , /* * Include push certificate information along with any patch sets . */ PUSH_CERTIFICATES ( 18 ) , /* * Include change's reviewer updates . */ REVIEWER_UPDATES ( 19 ) , /* * Set the submittable boolean . */ SUBMITTABLE ( 20 ) , /* * If tracking Ids are included , include detailed tracking Ids info . */ TRACKING_IDS ( 21 ) , /* * Skip mergeability data */ SKIP_MERGEABLE ( 22 ) , /* * Skip diffstat computation */ SKIP_DIFFSTAT ( 23 ) ; private final int value ; ListChangesOption ( int v ) { this . value = v ; } @Override public int getValue ( ) { return value ; } }
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . extensions . api . changes ; import java . util . List ; /* * Detailed information about who should be notified about an update . */ public class NotifyInfo { public List < String > accounts ; /* * < |startfocus| > * @param accounts may be either just a list of : account IDs , Full names , or usernames . Also could * be list of those : "Full name < email@example . com > " or "Full name ( < ID > ) " < |endfocus| > */ public NotifyInfo ( List < String > accounts ) { this . accounts = accounts ; } }
// See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . extensions . api . changes ; import java . util . List ; /* * Detailed information about who should be notified about an update . */ public class NotifyInfo { public List < String > accounts ; /* * < |startfocus| > * @param accounts may be either just a list of : account IDs , Full names , or usernames . Also could * be a list of those : "Full name < email@example . com > " or "Full name ( < ID > ) " < |endfocus| > */ public NotifyInfo ( List < String > accounts ) { this . accounts = accounts ; } }
addDraft ( changeId , revId , comment ) ; assertThat ( gApi . changes ( ) . query ( "change : " + changeId + " has : draft" ) . get ( ) ) . hasSize ( 1 ) ; } } @Test public void publishCommentsAllRevisions ( ) throws Exception { PushOneCommit . Result result = createChange ( ) ; String changeId = result . getChangeId ( ) ; pushFactory < |startfocus| > . create ( db , admin . getIdent ( ) , testRepo , SUBJECT , FILE_NAME , "initial content\n" , changeId ) < |endfocus| > . to ( "refs / heads / master" ) ; PushOneCommit . Result r1 = pushFactory . create ( admin . newIdent ( ) , testRepo , SUBJECT , FILE_NAME , "old boring content\n" ) . to ( "refs / for / master" ) ; PushOneCommit . Result r2 = pushFactory . create ( admin . newIdent ( ) , testRepo , SUBJECT , FILE_NAME , "new interesting\ncntent\n" , r1 . getChangeId ( ) ) . to ( "refs / for / master" ) ; addDraft ( r1 . getChangeId ( ) , r1 . getCommit ( ) . getName ( ) , "comment on old boring content\n" ) ; addDraft ( r2 . getChangeId ( ) , r2 . getCommit ( ) . getName ( ) , "comment on new interesting content\n" ) ; assertThat ( gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 1 ) ; assertThat ( gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 1 ) ; gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . current ( ) . review ( ReviewInput . approve ( ) ) ; gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . current ( ) . submit ( ) ; assertThat ( gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 2 ) ; assertThat ( gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 1 ) ; gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . current ( ) . review ( ReviewInput . approve ( ) ) ; gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . current ( ) . submit ( ) ; assertThat ( gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 2 ) ; assertThat ( gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 2 ) ; } @Test public void publishCommentsOnCurrentRevision ( ) throws Exception { PushOneCommit . Result result = createChange ( ) ; String changeId = result . getChangeId ( ) ; pushFactory . create ( db , admin . getIdent ( ) , testRepo , SUBJECT , FILE_NAME , "initial content\n" , changeId ) . to ( "refs / heads / master" ) ; PushOneCommit . Result r1 = pushFactory . create ( admin . newIdent ( ) , testRepo , SUBJECT , FILE_NAME , "old boring content\n" ) . to ( "refs / for / master" ) ; PushOneCommit . Result r2 = pushFactory . create ( admin . newIdent ( ) , testRepo , SUBJECT , FILE_NAME , "new interesting\ncntent\n" , r1 . getChangeId ( ) ) . to ( "refs / for / master" ) ; addDraft ( r1 . getChangeId ( ) , r1 . getCommit ( ) . getName ( ) , "comment on old boring content\n" ) ; addDraft ( r2 . getChangeId ( ) , r2 . getCommit ( ) . getName ( ) , "comment on new interesting content\n" ) ; assertThat ( gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 1 ) ; assertThat ( gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 1 ) ; gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . current ( ) . review ( ReviewInput . approve ( ) ) ; gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . current ( ) . submit ( ) ; assertThat ( gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 2 ) ; assertThat ( gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 1 ) ; gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . current ( ) . review ( ReviewInput . approve ( ) ) ; gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . current ( ) . submit ( ) ; assertThat ( gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 2 ) ; assertThat ( gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 2 ) ; } }
addDraft ( changeId , revId , comment ) ; assertThat ( gApi . changes ( ) . query ( "change : " + changeId + " has : draft" ) . get ( ) ) . hasSize ( 1 ) ; } } @Test public void publishCommentsAllRevisions ( ) throws Exception { PushOneCommit . Result result = createChange ( ) ; String changeId = result . getChangeId ( ) ; pushFactory < |startfocus| > . create ( db , admin . getIdent ( ) , testRepo , SUBJECT , FILE_NAME , "initial content\n" , changeId ) < |endfocus| > . to ( "refs / heads / master" ) ; PushOneCommit . Result r1 = pushFactory . create ( admin . newIdent ( ) , testRepo , SUBJECT , FILE_NAME , "old boring content\n" ) . to ( "refs / for / master" ) ; PushOneCommit . Result r2 = pushFactory . create ( admin . newIdent ( ) , testRepo , SUBJECT , FILE_NAME , "new interesting\ncntent\n" , r1 . getChangeId ( ) ) . to ( "refs / for / master" ) ; addDraft ( r1 . getChangeId ( ) , r1 . getCommit ( ) . getName ( ) , "comment on old boring content\n" ) ; addDraft ( r2 . getChangeId ( ) , r2 . getCommit ( ) . getName ( ) , "comment on new interesting content\n" ) ; assertThat ( gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 1 ) ; assertThat ( gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 1 ) ; gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . current ( ) . review ( ReviewInput . approve ( ) ) ; gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . current ( ) . submit ( ) ; assertThat ( gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 2 ) ; assertThat ( gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 1 ) ; gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . current ( ) . review ( ReviewInput . approve ( ) ) ; gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . current ( ) . submit ( ) ; assertThat ( gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 2 ) ; assertThat ( gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 2 ) ; } @Test public void publishCommentsOnCurrentRevision ( ) throws Exception { PushOneCommit . Result result = createChange ( ) ; String changeId = result . getChangeId ( ) ; pushFactory . create ( db , admin . getIdent ( ) , testRepo , SUBJECT , FILE_NAME , "initial content\n" , changeId ) . to ( "refs / heads / master" ) ; PushOneCommit . Result r1 = pushFactory . create ( admin . newIdent ( ) , testRepo , SUBJECT , FILE_NAME , "old boring content\n" ) . to ( "refs / for / master" ) ; PushOneCommit . Result r2 = pushFactory . create ( admin . newIdent ( ) , testRepo , SUBJECT , FILE_NAME , "new interesting\ncntent\n" , r1 . getChangeId ( ) ) . to ( "refs / for / master" ) ; addDraft ( r1 . getChangeId ( ) , r1 . getCommit ( ) . getName ( ) , "comment on old boring content\n" ) ; addDraft ( r2 . getChangeId ( ) , r2 . getCommit ( ) . getName ( ) , "comment on new interesting content\n" ) ; assertThat ( gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 1 ) ; assertThat ( gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 1 ) ; gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . current ( ) . review ( ReviewInput . approve ( ) ) ; gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . current ( ) . submit ( ) ; assertThat ( gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 2 ) ; assertThat ( gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 1 ) ; gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . current ( ) . review ( ReviewInput . approve ( ) ) ; gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . current ( ) . submit ( ) ; assertThat ( gApi . changes ( ) . id ( r1 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 2 ) ; assertThat ( gApi . changes ( ) . id ( r2 . getChangeId ( ) ) . get ( ) . messages ) . hasSize ( 2 ) ; } }
protected void configure ( ) { if ( ! noteDb . enabled ( ) ) { throw new ProvisionException ( "Gerrit is still running on ReviewDb : please migrate to NoteDb " + "and then reload the multi - site plugin . " ) ; } Collection < Message > validationErrors = config . validate ( ) ; if ( ! validationErrors . isEmpty ( ) ) { throw new CreationException ( validationErrors ) ; } listener ( ) . to ( Log4jMessageLogger . class ) ; bind ( MessageLogger . class ) . to ( Log4jMessageLogger . class ) ; < |startfocus| > < |endfocus| > DynamicItem . itemOf ( binder ( ) , BrokerSession . class ) ; DynamicItem . bind ( binder ( ) , BrokerSession . class ) . to ( BrokerSessionNoOp . class ) ; install ( new ForwarderModule ( ) ) ; if ( config . cache ( ) . synchronize ( ) ) { install ( new CacheModule ( ) ) ; } if ( config . event ( ) . synchronize ( ) ) { install ( new EventModule ( ) ) ; } if ( config . index ( ) . synchronize ( ) ) { install ( new IndexModule ( ) ) ; } install ( kafkaForwardedEventRouterModule ) ; install ( kafkaBrokerForwarderModule ) ; install ( new ValidationModule ( config , disableGitRepositoryValidation || ! config . getSharedRefDb ( ) . isEnabled ( ) ) ) ;
"Kafka consumer subscribing to topic [ % s ] for event family [ % s ] " , topic , getEventFamily ( ) ) ; consumer . subscribe ( Collections . singleton ( topic ) ) ; while ( ! closed . get ( ) ) { ConsumerRecords < byte [ ] , byte [ ] > consumerRecords = consumer . poll ( Duration . ofMillis ( configuration . kafkaSubscriber ( ) . getPollingInterval ( ) ) ) ; consumerRecords . forEach ( this : : processRecord ) ; } } catch ( WakeupException e ) { // Ignore exception if closing if ( ! closed . get ( ) ) throw e ; < |startfocus| > } catch ( KafkaException e ) { < |endfocus| > subscriberMetrics . incrementSubscriberFailedToPollMessages ( ) ; throw e ; } catch ( Exception e ) { subscriberMetrics . incrementSubscriberFailedToPollMessages ( ) ; throw e ; } finally { consumer . close ( ) ; }
subscriberMetrics . incrementSubscriberConsumedMessage ( ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Malformed event ' % s' : [ Exception : % s ] " , event . getHeader ( ) . getEventType ( ) ) ; subscriberMetrics . incrementSubscriberFailedToConsumeMessage ( ) ; } catch ( PermissionBackendException | OrmException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Cannot handle message % s : [ Exception : % s ] " , event . getHeader ( ) . getEventType ( ) ) ; subscriberMetrics . incrementSubscriberFailedToConsumeMessage ( ) ; } } } catch ( Exception e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Malformed event ' % s' : [ Exception : % s ] " , new String ( consumerRecord . value ( ) , UTF_8 ) ) ; subscriberMetrics . incrementSubscriberFailedToConsumeMessage ( ) ; }
for ( String src : delta ) { Ref r = local . get ( src ) ; if ( r != null ) { n . put ( src , r ) ; } } local = n ; } local = forProject . filter ( local , git , RefFilterOptions . builder ( ) . setFilterMeta ( true ) . build ( ) ) ; } List < RemoteRefUpdate > remoteUpdatesList = pushAllRefs ? doPushAll ( tn , local ) : doPushDelta ( local ) ; ReplicationPushFilter pushFilter = replicationPushFilter . get ( ) ; < |startfocus| > if ( pushFilter == null ) { return remoteUpdatesList ; } < |endfocus| > return pushFilter . filter ( projectName . get ( ) , remoteUpdatesList ) ; } private List < RemoteRefUpdate > doPushAll ( Transport tn , Map < String , Ref > local ) throws NotSupportedException , TransportException , IOException { List < RemoteRefUpdate > cmds = new ArrayList < > ( ) ; boolean noPerms = ! pool . isReplicatePermissions ( ) ; Map < String , Ref > remote = listRemote ( tn ) ; for ( Ref src : local . values ( ) ) { if ( ! canPushRef ( src . getName ( ) , noPerms ) ) { continue ; } remoteUpdatesList = pushFilter == null ? remoteUpdateList : pushFilter . filter ( projectName . get ( ) , remoteUpdatesList ) ; return remoteUpdatesList ;
protected void configure ( ) { < |startfocus| > DynamicItem . itemOf ( binder ( ) , BeforeReplicationPushFilter . class ) ; DynamicItem . bind ( binder ( ) , BeforeReplicationPushFilter . class ) . to ( BeforeReplicationPushFilterNoOP . class ) ; < |endfocus| >
return java . nio . file . Files . createTempDirectory ( prefix ) ; } @Test public void shouldLoadNotEmptyInitialReplicationConfig ( ) throws Exception { FileBasedConfig replicationConfig = newReplicationConfig ( ) ; replicationConfig . setString ( "remote" , "foo" , "url" , "ssh :/ / git@git . somewhere . com / $ { name } " ) ; replicationConfig . save ( ) ; autoReloadConfig = new AutoReloadConfigDecorator ( sitePaths , destinationFactoryMock , Providers . of ( replicationQueueMock ) , pluginDataPath , "replication" , workQueueMock ) ; < |startfocus| > assertThat ( autoReloadConfig . getDestinations ( FilterType . ALL ) ) . hasSize ( 1 ) ; < |endfocus| > } @Test public void shouldAutoReloadReplicationConfig ( ) throws Exception { FileBasedConfig replicationConfig = newReplicationConfig ( ) ; replicationConfig . setBoolean ( "gerrit" , null , "autoReload" , true ) ; replicationConfig . setString ( "remote" , "foo" , "url" , "ssh :/ / git@git . foo . com / $ { name } " ) ; replicationConfig . save ( ) ; autoReloadConfig = new AutoReloadConfigDecorator ( sitePaths , destinationFactoryMock , Providers . of ( replicationQueueMock ) , pluginDataPath , "replication" , workQueueMock ) ; autoReloadConfig . startup ( workQueueMock ) ;
< |startfocus| > Copyright ( C ) 2010 The Android Open Source Project < |endfocus| > // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . index ; import java . util . Optional ; public class OnlineReindexMode { private static ThreadLocal < Boolean > isOnlineReindex = new ThreadLocal < > ( ) ; public static boolean get ( ) { return Optional . ofNullable ( isOnlineReindex . get ( ) ) . orElse ( Boolean . FALSE ) ; } public static void begin ( ) { isOnlineReindex . set ( Boolean . TRUE ) ; } public static void end ( ) { isOnlineReindex . set ( Boolean . FALSE ) ; } }
< |startfocus| > public static boolean isActive ( ) { < |endfocus| > return Optional . ofNullable ( isOnlineReindex . get ( ) ) . orElse ( Boolean . FALSE ) ;
import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; public class JgitWrapper { private static final Logger log = LoggerFactory . getLogger ( JgitWrapper . class ) ; public static Optional < byte [ ] > getBlobAsBytes ( Repository repository , String revision , String path ) throws IOException { ObjectId objectId = repository . resolve ( revision ) ; if ( objectId == null ) { return Optional . empty ( ) ; } try ( final TreeWalk w = TreeWalk . forPath ( < |startfocus| > repository , path , parseCommit ( repository , objectId ) . getTree ( ) ) ) { < |endfocus| > return Optional . ofNullable ( w ) . filter ( walk - > ( walk . getRawMode ( 0 ) & TYPE_MASK ) == TYPE_FILE ) . map ( walk - > walk . getObjectId ( 0 ) ) . flatMap ( id - > readBlob ( repository , id ) ) ; } } private static RevCommit parseCommit ( Repository repository , ObjectId commit ) throws IOException { try ( final RevWalk walk = new RevWalk ( repository ) ) { walk . setRetainBody ( true ) ; return walk . parseCommit ( commit ) ; } } private static Optional < byte [ ] > readBlob ( Repository repository , ObjectId id ) {
// You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . quota ; < |startfocus| > /* * * Defines the quota groups . */ public class QuotaGroupDefinitions { < |endfocus| > public static final String REPOSITORY_SIZE_GROUP = " / repository : size" ; private QuotaGroupDefinitions ( ) { } }
private static boolean isContentTooLargeForDisplay ( String content ) { int lines = 0 ; int nl = - 1 ; while ( true ) { nl = nextLineBreak ( content , nl + 1 , content . length ( ) ) ; if ( nl < 0 ) { return false ; } else if ( ++ lines == MAX_LINE_COUNT ) { return true ; } } < |startfocus| > < |endfocus| >
private static boolean isContentTooLargeForDisplay ( String content ) { < |startfocus| > Matcher m = Pattern . compile ( "\r\n|\r|\n" ) . matcher ( content ) ; < |endfocus| > int lines = 0 ; while ( m . find ( ) && lines < MAX_LINE_COUNT ) { lines ++ ; } if ( lines < MAX_LINE_COUNT ) { return false ; } return true ;
at , Duration . ofMillis ( cfg . getTimeUnit ( "retry" , at . name ( ) , "timeout" , SECONDS . toMillis ( defaultTimeout . getSeconds ( ) ) , MILLISECONDS ) ) ) ) ; this . waitStrategy = WaitStrategies . join ( WaitStrategies . exponentialWait ( cfg . getTimeUnit ( "retry" , null , "maxWait" , SECONDS . toMillis ( 5 ) , MILLISECONDS ) , MILLISECONDS ) , WaitStrategies . randomWait ( 50 , MILLISECONDS ) ) ; this . overwriteDefaultRetryerStrategySetup = overwriteDefaultRetryerStrategySetup ; < |startfocus| > this . retryWithTraceOnFailure = cfg . getBoolean ( "retry" , "retryWithTraceOnFailure" , false ) ; < |endfocus| >
// distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . server . logging ; import com . google . auto . value . AutoValue ; import java . util . Optional ; /* * * The record of an operation for which the execution time was measured . * < |startfocus| > * < p > Metadata to provide additional context can be included by provided a { @link Metadata } < |endfocus| > * instance . */ @AutoValue public abstract class PerformanceLogRecord { /* * * Creates a performance log record without meta data . * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @return the performance log record */ public static PerformanceLogRecord create ( String operation , long durationMs ) { return new AutoValue_PerformanceLogRecord ( operation , durationMs , Optional . empty ( ) ) ; } /* * * Creates a performance log record with meta data . *
public abstract static class Builder { public abstract Builder listener ( RetryListener listener ) ; public abstract Builder timeout ( Duration timeout ) ; public abstract Options build ( ) ; } } @VisibleForTesting @Singleton public static class Metrics { final Counter1 < ActionType > attemptCounts ; final Counter1 < ActionType > timeoutCount ; @Inject Metrics ( MetricMaker metricMaker ) { Field < ActionType > actionTypeField = < |startfocus| > Field . ofEnum ( ActionType . class , "action_type" , ( metadataBuilder , fieldValue ) - > metadataBuilder . actionType ( fieldValue ) ) . build ( ) ; < |endfocus| > attemptCounts = metricMaker . newCounter ( "action / retry_attempt_count" , new Description ( "Number of retry attempts made by RetryHelper to execute an action" + " ( 0 == single attempt , no retry ) " ) . setCumulative ( ) . setUnit ( "attempts" ) , actionTypeField ) ; timeoutCount = metricMaker . newCounter ( "action / retry_timeout_count" , new Description ( "Number of action executions of RetryHelper that ultimately timed out" ) . setCumulative ( )
public void setup ( ) { projectCreationListener = new TraceValidatingProjectCreationValidationListener ( ) ; projectCreationListenerRegistrationHandle = projectCreationValidationListeners . add ( "gerrit" , projectCreationListener ) ; commitValidationListener = new TraceValidatingCommitValidationListener ( ) ; commitValidationRegistrationHandle = commitValidationListeners . add ( "gerrit" , commitValidationListener ) ; < |startfocus| > testPerformanceLogger = new TestPerformanceLogger ( ) ; performanceLoggerRegistrationHandle = performanceLoggers . add ( "gerrit" , testPerformanceLogger ) ; < |endfocus| >
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . google . gerrit . util . cli ; import java . util . Optional ; /* * * Classes that define command - line options by using the { @link org . kohsuke . args4j . Option } * annotation can implement this class to accept and handle unknown options . * < |startfocus| > * < p > If a user specifies an unknown option and this unknown options doesn't get accepted , the < |endfocus| > * parsing of the command - line options fails and the user gets an error ( this is the default * behavior if classes do not implement this interface ) . */ public interface UnknownOptionHandler { /* * * Whether an unknown option should be accepted . * * < p > If an unknown option is not accepted , the parsing of the command - line options fails and the * user gets an error . * * < p > This method can be used to ignore unknown options ( without failure for the user ) or to
* user gets an error . * * < p > This method can be used to ignore unknown options ( without failure for the user ) or to * handle them . * * @param name the name of an unknown option that was provided by the user * @param value the value of the unknown option that was provided by the user * @return whether this unknown options is accepted */ < |startfocus| > boolean accept ( String name , Optional < String > value ) ; < |endfocus| > }
. buildRepeatable ( a - > { if ( a . getAccount ( ) . getMetaId ( ) == null ) { return ImmutableList . of ( ) ; } return ImmutableList . of ( RefState . create ( RefNames . refsUsers ( a . getAccount ( ) . getId ( ) ) , ObjectId . fromString ( a . getAccount ( ) . getMetaId ( ) ) ) // We use the default AllUsers name to avoid having to pass around that // variable just for indexing . < |startfocus| > // This field is only used for staleness detection which will discover the < |endfocus| > // default name and replace it with the actually configured name . . toByteArray ( new AllUsersName ( AllUsersNameProvider . DEFAULT ) ) ) ; } ) ; /* * * All note values of all external IDs that were used in the course of indexing this document . * * < p > Emitted as UTF - 8 encoded strings of the form { @code [ hex sha of external ID ] : [ hex sha of * note blob ] } , or with other words { @code [ note ID ] : [ note data ID ] } . */
// Custom All - Users repository names are not indexed . Instead , the default name is used . < |startfocus| > // Therefore , // defer to the currently configured All - Users name . < |endfocus| > Project . NameKey repoName = e . getKey ( ) . get ( ) . equals ( AllUsersNameProvider . DEFAULT ) ? allUsersName : e . getKey ( ) ; try ( Repository repo = repoManager . openRepository ( repoName ) ) { if ( ! e . getValue ( ) . match ( repo ) ) { // Ref was modified since the account was indexed . return true ; } } } Set < ExternalId > extIds = externalIds . byAccount ( id ) ; ListMultimap < ObjectId , ObjectId > extIdStates = parseExternalIdStates ( result . get ( ) . getValue ( AccountField . EXTERNAL_ID_STATE ) ) ; if ( extIdStates . size ( ) != extIds . size ( ) ) {
stateLog . error ( String . format ( "source project % s not available" , project ) , err , state ) ; return ; } } } synchronized ( stateLock ) { PushOne e = pending . get ( uri ) ; if ( e == null ) { e = opFactory . create ( project , uri ) ; addRef ( e , ref ) ; e . addState ( ref , state ) ; pool . schedule ( e , now ? 0 : config . getDelay ( ) , TimeUnit . SECONDS ) ; pending . put ( uri , e ) ; < |startfocus| > < |endfocus| > } else if ( ! e . getRefs ( ) . contains ( ref ) ) { addRef ( e , ref ) ; e . addState ( ref , state ) ; } state . increasePushTaskCount ( project . get ( ) , ref ) ; repLog . info ( "scheduled { } : { } = > { } to run after { } s" , project , ref , e , config . getDelay ( ) ) ; }
< |startfocus| > public String persist ( String project , String ref , URIish uri ) { String json = getEventJson ( project , ref , uri ) ; < |endfocus| > String eventKey = getEventKey ( json ) ; Path file = refUpdates ( ) . resolve ( eventKey ) ; if ( Files . exists ( file ) ) { return eventKey ; } try { logger . atFiner ( ) . log ( " ** CREATE ** % s : % s = > % s" , project , ref , uri ) ; Files . write ( file , json . getBytes ( UTF_8 ) ) ; } catch ( IOException e ) { logger . atWarning ( ) . log ( "Couldn't persist event % s" , json ) ; } return eventKey ; }
< |startfocus| > public void delete ( String project , String ref , URIish uri ) { String eventKey = getEventKey ( getEventJson ( project , ref , uri ) ) ; < |endfocus| > try { logger . atFiner ( ) . log ( " ** DELETE ** % s : % s = > % s" , project , ref , uri ) ; Files . delete ( refUpdates ( ) . resolve ( eventKey ) ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Error while deleting event % s" , eventKey ) ; }
if ( watchedTypes . contains ( type ) ) { matching . bcc . accounts . add ( accountId ) ; } logger . atFine ( ) . log ( "Added account % s as watcher" , accountId ) ; return true ; } logger . atFine ( ) . log ( "The filter did not match for account % s ; skip notification" , accountId ) ; } catch ( QueryParseException e ) { // Ignore broken filter expressions . < |startfocus| > logger . atWarning ( ) . withCause ( e ) . log ( "Account % s has invalid filter in project watch % s : % s" , accountId , key , e . getMessage ( ) ) ; < |endfocus| > } return false ;
private ImmutableList < RefUpdatedEvent > getRefUpdatedEvents ( String project , String refName , int expectedSize ) { String key = refEventKey ( RefUpdatedEvent . TYPE , project , refName ) ; if ( expectedSize == 0 ) { assertThat ( recordedEvents ) . doesNotContainKey ( key ) ; return ImmutableList . of ( ) ; } assertThat ( recordedEvents ) . containsKey ( key ) ; ImmutableList < RefUpdatedEvent > events = FluentIterable . from ( recordedEvents . get ( key ) ) . transform ( RefUpdatedEvent . class : : cast ) . toList ( ) ; assertThat ( events ) . hasSize ( expectedSize ) ; return events ; } < |startfocus| > < |endfocus| > public ImmutableList < ChangeMergedEvent > getChangeMergedEvents ( String project , String branch , int expectedSize ) { String key = refEventKey ( ChangeMergedEvent . TYPE , project , branch ) ; if ( expectedSize == 0 ) { assertThat ( recordedEvents ) . doesNotContainKey ( key ) ; return ImmutableList . of ( ) ; } assertThat ( recordedEvents ) . containsKey ( key ) ; ImmutableList < ChangeMergedEvent > events = FluentIterable . from ( recordedEvents . get ( key ) ) . transform ( ChangeMergedEvent . class : : cast ) . toList ( ) ; assertThat ( events ) . hasSize ( expectedSize ) ; return events ; } @VisibleForTesting
assertThat ( cd . change ( ) . getStatus ( ) ) . isEqualTo ( Change . Status . MERGED ) ; assertSubmitApproval ( psId ) ; assertThat ( cd . patchSets ( ) ) . hasSize ( 1 ) ; assertThat ( cd . patchSet ( psId ) . getRevision ( ) . get ( ) ) . isEqualTo ( c . name ( ) ) ; } @Test public void correctNewRevOnMergeByPushToBranch ( ) throws Exception { grant ( project , "refs / heads / master" , Permission . PUSH ) ; < |startfocus| > PushOneCommit . Result r1 = push ( "refs / for / master" , PushOneCommit . SUBJECT , "one . txt" , "One" ) ; PushOneCommit . Result r2 = push ( "refs / for / master" , PushOneCommit . SUBJECT , "two . txt" , "Two" ) ; < |endfocus| > startEventRecorder ( ) ; git ( ) . push ( ) . setRefSpecs ( new RefSpec ( r2 . getCommit ( ) . name ( ) + " : refs / heads / master" ) ) . call ( ) ; List < ChangeMergedEvent > changeMergedEvents = eventRecorder . getChangeMergedEvents ( project . get ( ) , "refs / heads / master" , 2 ) ; assertThat ( changeMergedEvents . get ( 0 ) . newRev ) . isEqualTo ( r2 . getPatchSet ( ) . getRevision ( ) . get ( ) ) ;
uri ) ; } } else { if ( canceledWhileRunning . get ( ) ) { logCanceledWhileRunningException ( e ) ; } else { repLog . error ( "Cannot replicate to { } " , uri , e ) ; // The remote push operation should be retried . pool . reschedule ( this , Destination . RetryReason . TRANSPORT_ERROR ) ; } } } catch ( IOException e ) { stateLog . error ( "Cannot replicate to " + uri , e , getStatesAsArray ( ) ) ; } catch ( PermissionBackendException | RuntimeException | Error e ) { stateLog . error ( "Unexpected error during replication to " + uri , e , getStatesAsArray ( ) ) ; } finally { pool . notifyFinished ( this ) ; if ( git != null ) { git . close ( ) ; } }
// distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . replication ; import com . google . gerrit . extensions . annotations . ExtensionPoint ; import java . util . List ; import org . eclipse . jgit . transport . RemoteRefUpdate ; /* * * < |startfocus| > * Filter that is invoked before list of remote ref updates is pushed to remote instance . It can be * used to filter out unwanted updates . * < |endfocus| > */ @ExtensionPoint public interface ReplicationPushFilter { public List < RemoteRefUpdate > filter ( String projectName , List < RemoteRefUpdate > remoteUpdatesList ) ; }
private final DestinationFactory destinationFactory ; private final Path pluginDataDir ; private final Provider < ReplicationQueue > replicationQueue ; @Inject public AutoReloadConfigDecorator ( SitePaths site , DestinationFactory destinationFactory , Provider < ReplicationQueue > replicationQueue , @PluginData Path pluginDataDir ) throws ConfigInvalidException , IOException { this . site = site ; this . destinationFactory = destinationFactory ; this . pluginDataDir = pluginDataDir ; this . currentConfig = loadConfig ( ) ; this . currentConfigTs = getLastModified ( currentConfig ) ; < |startfocus| > this . replicationQueue = replicationQueue ; < |endfocus| > } private static long getLastModified ( ReplicationFileBasedConfig cfg ) { return FileUtil . lastModified ( cfg . getCfgPath ( ) ) ; } private ReplicationFileBasedConfig loadConfig ( ) throws ConfigInvalidException , IOException { return new ReplicationFileBasedConfig ( site , destinationFactory , pluginDataDir ) ; } private boolean isAutoReload ( ) { return currentConfig . getConfig ( ) . getBoolean ( "gerrit" , "autoReload" , false ) ; } @Override public synchronized List < Destination > getDestinations ( FilterType filterType ) { reloadIfNeeded ( ) ; return currentConfig . getDestinations ( filterType ) ; } private void reloadIfNeeded ( ) {
< |startfocus| > private Renderer renderer ( String templateName ) { < |endfocus| > return args . soySauce . renderTemplate ( "com . google . gerrit . server . mail . template . " + templateName ) . setData ( soyContext ) ;
// limitations under the License . package com . googlesource . gerrit . plugins . multisite ; import com . google . gerrit . server . util . SystemLog ; import com . google . inject . Inject ; import com . google . inject . Singleton ; import org . apache . log4j . PatternLayout ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . Ref ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; @Singleton public class Log4jSharedRefLogger extends LibModuleLogFile implements SharedRefLogger { < |startfocus| > private static final String LOG_NAME = "sharedref_log" ; < |endfocus| > private final Logger sharedRefDBLog ; @Inject public Log4jSharedRefLogger ( SystemLog systemLog ) { super ( systemLog , LOG_NAME , new PatternLayout ( " [ % d { ISO8601 } ] [ % t ] %- 5p : % m % n" ) ) ; sharedRefDBLog = LoggerFactory . getLogger ( LOG_NAME ) ; } @Override public void log ( String project , Ref currRef , ObjectId newRefValue ) { sharedRefDBLog . info ( "project : { } |ref : { } |oldId : { } |newId : { } " , project , currRef . getName ( ) , currRef . getObjectId ( ) . getName ( ) , newRefValue . getName ( ) ) ; }
< |startfocus| > public void log ( String project , Ref currRef , ObjectId newRefValue ) { < |endfocus| > sharedRefDBLog . info ( "project : { } |ref : { } |oldId : { } |newId : { } " , project , currRef . getName ( ) , currRef . getObjectId ( ) . getName ( ) , newRefValue . getName ( ) ) ;
public void logDeletion ( String project ) { sharedRefDBLog . info ( "project : { } |DELETED" , project ) ;
public void onProjectDeleted ( Event event ) { String projectName = event . getProjectName ( ) ; logger . atInfo ( ) . log ( "Deleting project ' % s' . Will perform a cleanup in Shared - Ref database . " , projectName ) ; try { sharedDb . removeProject ( projectName ) ; < |startfocus| > sharedRefLogger . logDeletion ( projectName ) ; < |endfocus| > } catch ( IOException e ) { validationMetrics . incrementSplitBrain ( ) ; logger . atSevere ( ) . withCause ( e ) . log ( "Project ' % s' deleted from GIT but it was not able to cleanup" + " from Shared - Ref database" , projectName ) ; } }
String errorMessage = String . format ( "Not able to persist the data in Zookeeper for project ' % s' and ref ' % s' , " + "the cluster is now in Split Brain since the commit has been " + "persisted locally but not in SharedRef the value % s" , projectName , refPair . getName ( ) , refPair . putValue ) ; boolean succeeded ; try { < |startfocus| > succeeded = sharedRefDb . compareAndPut ( projectName , refPair . compareRef , refPair . putValue ) ; sharedRefLogger . log ( projectName , refPair . compareRef , refPair . putValue ) ; < |endfocus| > } catch ( IOException e ) { throw new SharedDbSplitBrainException ( errorMessage , e ) ; } if ( ! succeeded ) { throw new SharedDbSplitBrainException ( errorMessage ) ; } } protected RefPair compareAndGetLatestLocalRef ( RefPair refPair , CloseableSet < AutoCloseable > locks ) throws SharedLockException , OutOfSyncException , IOException { String refName = refPair . getName ( ) ; EnforcePolicy refEnforcementPolicy = refEnforcement . getPolicy ( projectName , refName ) ; if ( refEnforcementPolicy == EnforcePolicy . IGNORED ) { return refPair ; } locks . addResourceIfNotExist ( sharedRefDb . getLock ( projectName , refName ) ) ;
private String replaceInUrl ( String placeholder , String url , String replacement , boolean lowerCase ) { if ( url == null || replacement == null || ! url . contains ( placeholder ) ) { return url ; } < |startfocus| > if ( lowerCase ) { < |endfocus| > replacement = replacement . toLowerCase ( ) ; } // as we can't assume anything of 'replacement' , we're URL encoding it return url . replace ( placeholder , Url . encode ( replacement ) ) ;
public void cancel ( ) { < |startfocus| > repLog . info ( "Replication [ { } ] to { } was canceled" , HexFormat . fromInt ( id ) , getURI ( ) ) ; < |endfocus| > canceledByReplication ( ) ; pool . pushWasCanceled ( this ) ;
public void setCanceledWhileRunning ( ) { < |startfocus| > repLog . info ( "Replication [ { } ] to { } was canceled while being executed" , HexFormat . fromInt ( id ) , getURI ( ) ) ; < |endfocus| > canceledWhileRunning . set ( true ) ;
public void logRefUpdate ( String project , Ref currRef , ObjectId newRefValue ) { < |startfocus| > if ( ! ObjectId . zeroId ( ) . equals ( newRefValue ) ) { try ( Repository repository = gitRepositoryManager . openRepository ( new Project . NameKey ( project ) ) ; RevWalk walk = new RevWalk ( repository ) ) { < |endfocus| > RevCommit commit = walk . parseCommit ( newRefValue ) ; sharedRefDBLog . info ( gson . toJson ( new SharedRefLogEntry . UpdateRef ( project , currRef . getName ( ) , currRef . getObjectId ( ) . getName ( ) , newRefValue . getName ( ) , CommonConverters . toGitPerson ( commit . getCommitterIdent ( ) ) , commit . getFullMessage ( ) ) ) ) ; } } else { sharedRefDBLog . info ( gson . toJson ( new SharedRefLogEntry . DeleteRef ( project , currRef . getName ( ) , currRef . getObjectId ( ) . getName ( ) ) ) ) ; } } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Cannot log sharedRefDB interaction for ref % s on project % s" , currRef . getName ( ) , project ) ; }
String refName , String oldId , String newId , GitPerson committer , String comment ) { this . type = Type . UPDATE_REF ; this . projectName = projectName ; this . refName = refName ; this . oldId = oldId ; this . newId = newId ; this . committer = committer ; this . comment = comment ; } } public static class DeleteProject extends SharedRefLogEntry { public String refName ; public String oldId ; DeleteProject ( String projectName ) { < |startfocus| > this . type = Type . DELETE_PROJECT ; < |endfocus| > this . projectName = projectName ; } } public static class DeleteRef extends SharedRefLogEntry { public String refName ; public String oldId ; DeleteRef ( String projectName , String refName , String oldId ) { this . type = Type . DELETE_REF ; this . projectName = projectName ; this . refName = refName ; this . oldId = oldId ; } } }
} replicateAllOnPluginStart = config . getBoolean ( "gerrit" , "replicateOnStartup" , true ) ; defaultForceUpdate = config . getBoolean ( "gerrit" , "defaultForceUpdate" , false ) ; sshCommandTimeout = ( int ) ConfigUtil . getTimeUnit ( config , "gerrit" , null , "sshCommandTimeout" , 30 , SECONDS ) ; sshConnectionTimeout = ( int ) SECONDS . toMillis ( < |startfocus| > ConfigUtil . getTimeUnit ( config , "gerrit" , null , "sshConnectionTimeout" , 120 , SECONDS ) ) ; < |endfocus| > ImmutableList . Builder < Destination > dest = ImmutableList . builder ( ) ; for ( RemoteConfig c : allRemotes ( config ) ) { if ( c . getURIs ( ) . isEmpty ( ) ) { continue ; } // If destination for push is not set assume equal to source . for ( RefSpec ref : c . getPushRefSpecs ( ) ) { if ( ref . getDestination ( ) == null ) { ref . setDestination ( ref . getSource ( ) ) ; } } if ( c . getPushRefSpecs ( ) . isEmpty ( ) ) { c . addPushRefSpec ( new RefSpec ( ) . setSourceDestination ( "refs /* " , "refs /* " ) . setForceUpdate ( defaultForceUpdate ) ) ; }
private ImmutableSet < String > parseRequestTypes ( String traceId ) { return ImmutableSet . copyOf ( cfg . getStringList ( "tracing" , traceId , "requestType" ) ) ; } private ImmutableSet < Account . Id > parseAccounts ( String traceId ) { ImmutableSet . Builder < Account . Id > accountIds = ImmutableSet . builder ( ) ; String [ ] accounts = cfg . getStringList ( "tracing" , traceId , "account" ) ; for ( String account : accounts ) { Optional < Account . Id > accountId = Account . Id . tryParse ( account ) ; if ( ! accountId . isPresent ( ) ) { < |startfocus| > throw new ConfigInvalidException ( < |endfocus| > String . format ( "Invalid tracing config ( 'tracing . % s . account = % s' ) : invalid account ID" , traceId , account ) ) ; } accountIds . add ( accountId . get ( ) ) ; } return accountIds . build ( ) ; } private ImmutableSet < Pattern > parseProjectPatterns ( String traceId ) { ImmutableSet . Builder < Pattern > projectPatterns = ImmutableSet . builder ( ) ; String [ ] projectPatternRegExs = cfg . getStringList ( "tracing" , traceId , "projectPattern" ) ; for ( String projectPatternRegEx : projectPatternRegExs ) { try {
boolean matches ( RequestInfo requestInfo ) { if ( ! requestTypes ( ) . isEmpty ( ) < |startfocus| > && requestTypes ( ) . stream ( ) . noneMatch ( type - > type . equalsIgnoreCase ( requestInfo . requestType ( ) ) ) ) { < |endfocus| > return false ; } if ( ! accountIds ( ) . isEmpty ( ) ) { try { if ( accountIds ( ) . stream ( ) . noneMatch ( id - > id . equals ( requestInfo . callingUser ( ) . getAccountId ( ) ) ) ) { return false ; } } catch ( UnsupportedOperationException e ) { // calling user is not logged in return false ; } } if ( ! projectPatterns ( ) . isEmpty ( ) ) { if ( ! requestInfo . project ( ) . isPresent ( ) ) { // request is not for a project return false ; } if ( projectPatterns ( ) . stream ( ) . noneMatch ( p - > p . matcher ( requestInfo . project ( ) . get ( ) . get ( ) ) . matches ( ) ) ) { return false ; } } return true ;
/* * Java API to interact with single { @code Check } s . */ public interface CheckApi { /* * Returns a { @link CheckInfo } for the scoped resource with the given options . */ CheckInfo get ( ListChecksOption . . . options ) throws RestApiException ; /* * Updates a check and returns the { @link CheckInfo } for the updated resource . */ CheckInfo update ( CheckInput input ) throws RestApiException ; < |startfocus| > /* * reruns the check and returns the { @link CheckInfo } for the updated check . Input ignores "state" . */ CheckInfo rerun ( CheckInput input ) throws RestApiException ; < |endfocus| > /* * * A default implementation which allows source compatibility when adding new methods to the * interface . */ class NotImplemented implements CheckApi { @Override public CheckInfo get ( ListChecksOption . . . options ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override public CheckInfo update ( CheckInput input ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override public CheckInfo rerun ( CheckInput input ) throws RestApiException { throw new NotImplementedException ( ) ; } } }
/* * Java API to interact with single { @code Check } s . */ public interface CheckApi { /* * Returns a { @link CheckInfo } for the scoped resource with the given options . */ CheckInfo get ( ListChecksOption . . . options ) throws RestApiException ; /* * Updates a check and returns the { @link CheckInfo } for the updated resource . */ CheckInfo update ( CheckInput input ) throws RestApiException ; < |startfocus| > /* * Reruns the check and returns the CheckInfo for the updated check . Input ignores "state" . */ CheckInfo rerun ( CheckInput input ) throws RestApiException ; < |endfocus| > /* * * A default implementation which allows source compatibility when adding new methods to the * interface . */ class NotImplemented implements CheckApi { @Override public CheckInfo get ( ListChecksOption . . . options ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override public CheckInfo update ( CheckInput input ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override public CheckInfo rerun ( CheckInput input ) throws RestApiException { throw new NotImplementedException ( ) ; } } }
import com . google . gerrit . extensions . restapi . RestApiException ; import com . google . gerrit . extensions . restapi . RestModifyView ; import com . google . gerrit . server . permissions . PermissionBackendException ; import com . google . inject . Inject ; import com . google . inject . Singleton ; import java . io . IOException ; import org . eclipse . jgit . errors . ConfigInvalidException ; @Singleton public class RerunCheck implements RestModifyView < CheckResource , CheckInput > { private final PostCheck postCheck ; @Inject RerunCheck ( PostCheck postCheck ) { this . postCheck = postCheck ; } < |startfocus| > @Override < |endfocus| > public CheckInfo apply ( CheckResource checkResource , CheckInput input ) throws RestApiException , IOException , StorageException , PermissionBackendException , ConfigInvalidException { if ( input == null ) { input = new CheckInput ( ) ; } if ( input . checkerUuid == null ) { input . checkerUuid = checkResource . getCheckerUuid ( ) . get ( ) ; } return postCheck . apply ( checkResource . getRevisionResource ( ) , input ) ; } }
import com . google . gerrit . plugins . checks . api . CheckInfo ; import com . google . gerrit . plugins . checks . api . CheckInput ; import com . google . gerrit . plugins . checks . api . CheckState ; import com . google . gerrit . reviewdb . client . PatchSet ; import com . google . gerrit . testing . TestTimeUtil ; import com . google . inject . Inject ; import java . sql . Timestamp ; import java . time . Instant ; import java . util . concurrent . TimeUnit ; import org . junit . After ; import org . junit . Before ; import org . junit . Test ; public class RerunCheckIT extends AbstractCheckersTest { < |startfocus| > @Inject private RequestScopeOperations requestScopeOperations ; < |endfocus| > private PatchSet . Id patchSetId ; @Before public void setUp ( ) throws Exception { TestTimeUtil . resetWithClockStep ( 1 , TimeUnit . SECONDS ) ; TestTimeUtil . setClock ( Timestamp . from ( Instant . EPOCH ) ) ; patchSetId = createChange ( ) . getPatchSetId ( ) ; CheckerUuid checkerUuid = checkerOperations . newChecker ( ) . repository ( project ) . create ( ) ; checkOperations . newCheck ( CheckKey . create ( project , patchSetId , checkerUuid ) ) . upsert ( ) ; } @After public void resetTime ( ) { TestTimeUtil . useSystemTime ( ) ; } @Test
import com . google . gerrit . testing . TestTimeUtil ; import com . google . inject . Inject ; import java . sql . Timestamp ; import java . time . Instant ; import java . util . concurrent . TimeUnit ; import org . junit . After ; import org . junit . Before ; import org . junit . Test ; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations ; private PatchSet . Id patchSetId ; private CheckKey checkKey ; @Before public void setUp ( ) throws Exception { < |startfocus| > TestTimeUtil . resetWithClockStep ( 1 , TimeUnit . SECONDS ) ; TestTimeUtil . setClock ( Timestamp . from ( Instant . EPOCH ) ) ; < |endfocus| > patchSetId = createChange ( ) . getPatchSetId ( ) ; CheckerUuid checkerUuid = checkerOperations . newChecker ( ) . repository ( project ) . create ( ) ; checkKey = CheckKey . create ( project , patchSetId , checkerUuid ) ; checkOperations . newCheck ( checkKey ) . upsert ( ) ; } @After public void resetTime ( ) { TestTimeUtil . useSystemTime ( ) ; } @Test public void RerunCheck ( ) throws Exception { CheckInput input = new CheckInput ( ) ; input . state = CheckState . RUNNING ;
public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations ; private PatchSet . Id patchSetId ; private CheckKey checkKey ; @Before public void setUp ( ) throws Exception { TestTimeUtil . resetWithClockStep ( 1 , TimeUnit . SECONDS ) ; TestTimeUtil . setClock ( Timestamp . from ( Instant . EPOCH ) ) ; patchSetId = createChange ( ) . getPatchSetId ( ) ; CheckerUuid checkerUuid = checkerOperations . newChecker ( ) . repository ( project ) . create ( ) ; checkKey = CheckKey . create ( project , patchSetId , checkerUuid ) ; } @After public void resetTime ( ) { TestTimeUtil . useSystemTime ( ) ; } @Test public void RerunCheck ( ) throws Exception { CheckInput input = new CheckInput ( ) ; input . state = CheckState . RUNNING ; CheckInfo info = checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( input ) ; assertThat ( info . state ) . isEqualTo ( CheckState . NOT_STARTED ) ; } }
@Before public void setUp ( ) throws Exception { TestTimeUtil . resetWithClockStep ( 1 , TimeUnit . SECONDS ) ; TestTimeUtil . setClock ( Timestamp . from ( Instant . EPOCH ) ) ; patchSetId = createChange ( ) . getPatchSetId ( ) ; CheckerUuid checkerUuid = checkerOperations . newChecker ( ) . repository ( project ) . create ( ) ; checkKey = CheckKey . create ( project , patchSetId , checkerUuid ) ; checkOperations . newCheck ( checkKey ) . upsert ( ) ; } @After public void resetTime ( ) { TestTimeUtil . useSystemTime ( ) ; } @Test < |startfocus| > public void rerunCheck ( ) throws Exception { CheckInput input = new CheckInput ( ) ; input . state = CheckState . RUNNING ; < |endfocus| > CheckInfo info = checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( input ) ; assertThat ( info . state ) . isEqualTo ( CheckState . NOT_STARTED ) ; } }
CheckerUuid checkerUuid = checkerOperations . newChecker ( ) . repository ( project ) . create ( ) ; checkKey = CheckKey . create ( project , patchSetId , checkerUuid ) ; checkOperations . newCheck ( checkKey ) . upsert ( ) ; } @After public void resetTime ( ) { TestTimeUtil . useSystemTime ( ) ; } @Test public void RerunCheck ( ) throws Exception { CheckInput input = new CheckInput ( ) ; input . state = CheckState . RUNNING ; < |startfocus| > CheckInfo info = checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( input ) ; < |endfocus| > assertThat ( info . state ) . isEqualTo ( CheckState . NOT_STARTED ) ; } }
PermissionBackend permissionBackend , ExternalIds externalIds , @ServerInitiated Provider < AccountsUpdate > accountsUpdateProvider , SshKeyCache sshKeyCache , Realm realm ) { this . self = self ; this . permissionBackend = permissionBackend ; this . externalIds = externalIds ; this . accountsUpdateProvider = accountsUpdateProvider ; this . sshKeyCache = sshKeyCache ; this . realm = realm ; } @Override public String apply ( AccountResource rsrc , UsernameInput input ) < |startfocus| > throws AuthException , BadRequestException , MethodNotAllowedException , UnprocessableEntityException , ResourceConflictException , IOException , ConfigInvalidException , PermissionBackendException { < |endfocus| > if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) { permissionBackend . currentUser ( ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; } if ( ! realm . allowsEdit ( AccountFieldName . USER_NAME ) ) { throw new MethodNotAllowedException ( "realm does not allow editing username" ) ; } Account . Id accountId = rsrc . getUser ( ) . getAccountId ( ) ; if ( ! externalIds . byAccount ( accountId , SCHEME_USERNAME ) . isEmpty ( ) ) { throw new MethodNotAllowedException ( "Username cannot be changed . " ) ; }
} @Override public String apply ( AccountResource rsrc , UsernameInput input ) throws AuthException , MethodNotAllowedException , UnprocessableEntityException , ResourceConflictException , IOException , ConfigInvalidException , PermissionBackendException { if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) { permissionBackend . currentUser ( ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; } if ( ! realm . allowsEdit ( AccountFieldName . USER_NAME ) ) { throw new MethodNotAllowedException ( "realm does not allow editing username" ) ; } < |startfocus| > Account . Id accountId = rsrc . getUser ( ) . getAccountId ( ) ; if ( ! externalIds . byAccount ( accountId , SCHEME_USERNAME ) . isEmpty ( ) ) { throw new MethodNotAllowedException ( "Username cannot be changed . " ) ; } if ( input == null || Strings . isNullOrEmpty ( input . username ) ) { // A username is not set yet and in the input no username was specified . Hence there is // nothing to do . return input . username ; } if ( ! ExternalId . isValidUsername ( input . username ) ) { < |endfocus| >
@Nullable public Timestamp finished ; /* * Timestamp of when this check was created . */ public Timestamp created ; /* * Timestamp of when this check was last updated . */ public Timestamp updated ; /* * Name of the checker that produced this check . */ public String checkerName ; /* * Status of the checker that produced this check . */ public CheckerStatus checkerStatus ; /* * Blocking conditions that apply to this check . */ public Set < BlockingCondition > blocking ; < |startfocus| > /* * Description of the checker that produced this check */ public String description ; < |endfocus| > @Override public boolean equals ( Object o ) { if ( ! ( o instanceof CheckInfo ) ) { return false ; } CheckInfo other = ( CheckInfo ) o ; return Objects . equals ( other . repository , repository ) && Objects . equals ( other . changeNumber , changeNumber ) && Objects . equals ( other . patchSetId , patchSetId ) && Objects . equals ( other . checkerUuid , checkerUuid ) && Objects . equals ( other . state , state ) && Objects . equals ( other . message , message ) && Objects . equals ( other . url , url ) && Objects . equals ( other . started , started )
/* * Timestamp of when this check was created . */ public Timestamp created ; /* * Timestamp of when this check was last updated . */ public Timestamp updated ; /* * Name of the checker that produced this check . */ public String checkerName ; /* * Status of the checker that produced this check . */ public CheckerStatus checkerStatus ; < |startfocus| > /* * Description of the checker for this check */ public String checkerDescription ; < |endfocus| > /* * Blocking conditions that apply to this check . */ public Set < BlockingCondition > blocking ; @Override public boolean equals ( Object o ) { if ( ! ( o instanceof CheckInfo ) ) { return false ; } CheckInfo other = ( CheckInfo ) o ; return Objects . equals ( other . repository , repository ) && Objects . equals ( other . changeNumber , changeNumber ) && Objects . equals ( other . patchSetId , patchSetId ) && Objects . equals ( other . checkerUuid , checkerUuid ) && Objects . equals ( other . state , state ) && Objects . equals ( other . message , message ) && Objects . equals ( other . url , url ) && Objects . equals ( other . started , started ) && Objects . equals ( other . finished , finished )
} if ( options . contains ( FillOptions . STATUS ) ) { info . status = account . getStatus ( ) ; } if ( options . contains ( FillOptions . AVATARS ) ) { AvatarProvider ap = avatar . get ( ) ; if ( ap != null ) { info . avatars = new ArrayList < > ( ) ; IdentifiedUser user = userFactory . create ( account . getId ( ) ) ; // PolyGerrit UI uses the following sizes for avatars : < |startfocus| > // - 32px for avatars on next to names e . g . on the dashboard . This is also Gerrit's default . < |endfocus| > // - 56px for the user's own avatar in the menu // - 100ox for other user's avatars on dashboards // - 120px for the user's own profile settings page addAvatar ( ap , info , user , AvatarInfo . DEFAULT_SIZE ) ; if ( ! info . avatars . isEmpty ( ) ) { addAvatar ( ap , info , user , 56 ) ; addAvatar ( ap , info , user , 100 ) ; addAvatar ( ap , info , user , 120 ) ; } } } if ( options . contains ( FillOptions . DIFF_PREFERENCES ) ) { info . diffPrefs = diffPrefsFactory . create ( account . getId ( ) ) ; }
< |startfocus| > Copyright ( C ) 2013 The Android Open Source Project < |endfocus| > // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . replication ; import org . eclipse . jgit . errors . NotSupportedException ; import org . eclipse . jgit . errors . TransportException ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . transport . Transport ; import org . eclipse . jgit . transport . URIish ; public interface TransportFactory { Transport open ( Repository local , URIish uri ) throws NotSupportedException , TransportException ; }
< |startfocus| > Copyright ( C ) 2013 The Android Open Source Project < |endfocus| > // // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; // you may not use this file except in compliance with the License . // You may obtain a copy of the License at // // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . replication ; import org . eclipse . jgit . errors . NotSupportedException ; import org . eclipse . jgit . errors . TransportException ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . transport . Transport ; import org . eclipse . jgit . transport . URIish ; public class TransportFactoryImpl implements TransportFactory { @Override public Transport open ( Repository git , URIish uri ) throws NotSupportedException , TransportException { return Transport . open ( git , uri ) ; } }
import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . eclipse . jgit . transport . FetchConnection ; import org . eclipse . jgit . transport . PushConnection ; import org . eclipse . jgit . transport . PushResult ; import org . eclipse . jgit . transport . RefSpec ; import org . eclipse . jgit . transport . RemoteConfig ; import org . eclipse . jgit . transport . RemoteRefUpdate ; import org . eclipse . jgit . transport . Transport ; import org . eclipse . jgit . transport . URIish ; import org . eclipse . jgit . util . FS ; import org . junit . Before ; import org . junit . Test ; public class PushOneTest { < |startfocus| > private GitRepositoryManager gitRepositoryManagerMock ; private Repository repositoryMock ; private PermissionBackend permissionBackendMock ; private PermissionBackend . WithUser withUserMock ; private PermissionBackend . ForProject forProjectMock ; < |endfocus| > private Destination destinationMock ; private RemoteConfig remoteConfigMock ; private RefSpec refSpecMock ; private CredentialsFactory credentialsFactory ; private PerThreadRequestScope . Scoper threadRequestScoperMock ; private ReplicationQueue replicationQueueMock ; private IdGenerator idGeneratorMock ; private ReplicationStateListeners replicationStateListenersMock ; private ReplicationMetrics replicationMetricsMock ; private Timer1 . Context timerContextMock ; private ProjectCache projectCacheMock ; private RunwayStatus statusMock ; private TransportFactory transportFactoryMock ; private Transport transportMock ; private FetchConnection fetchConnection ; private PushConnection pushConnection ; private ProjectState projectStateMock ;
verify ( transportMock ) ; } private PushOne createPushOne ( DynamicItem < ReplicationPushFilter > replicationPushFilter ) { PushOne push = new PushOne ( gitRepositoryManagerMock , permissionBackendMock , destinationMock , remoteConfigMock , credentialsFactory , threadRequestScoperMock , replicationQueueMock , idGeneratorMock , replicationStateListenersMock , replicationMetricsMock , projectCacheMock , transportFactoryMock , projectNameKey , urish ) ; push . setReplicationPushFilter ( replicationPushFilter ) ; return push ; } private void waitUntilFinished ( ) throws InterruptedException { < |startfocus| > while ( ! isCallFinished . get ( ) ) { < |endfocus| > Thread . sleep ( 100 ) ; } } private void setupProjectCacheMock ( ) throws IOException { projectCacheMock = createNiceMock ( ProjectCache . class ) ; expect ( projectCacheMock . checkedGet ( projectNameKey ) ) . andReturn ( projectStateMock ) ; } private void setupTransportMock ( ) throws NotSupportedException , TransportException { transportMock = createNiceMock ( Transport . class ) ; expect ( transportMock . openFetch ( ) ) . andReturn ( fetchConnection ) ; transportFactoryMock = createNiceMock ( TransportFactory . class ) ; expect ( transportFactoryMock . open ( repositoryMock , urish ) ) . andReturn ( transportMock ) . anyTimes ( ) ; } private void setupReplicationMetricsMock ( ) {
private void setupDestinationMock ( ) { destinationMock = createNiceMock ( Destination . class ) ; expect ( destinationMock . requestRunway ( anyObject ( ) ) ) . andReturn ( RunwayStatus . allowed ( ) ) ; } private void setupPermissionBackedMock ( ) { permissionBackendMock = createNiceMock ( PermissionBackend . class ) ; expect ( permissionBackendMock . currentUser ( ) ) . andReturn ( withUserMock ) ; } private void setupWithUserMock ( ) { withUserMock = createNiceMock ( WithUser . class ) ; expect ( withUserMock . project ( projectNameKey ) ) . andReturn ( forProjectMock ) ; } < |startfocus| > private void setupGitRepoManagerMock ( ) throws IOException { < |endfocus| > gitRepositoryManagerMock = createNiceMock ( GitRepositoryManager . class ) ; expect ( gitRepositoryManagerMock . openRepository ( projectNameKey ) ) . andReturn ( repositoryMock ) ; } private void setupRepositoryMock ( FileBasedConfig config ) throws IOException { repositoryMock = createNiceMock ( Repository . class ) ; expect ( repositoryMock . getConfig ( ) ) . andReturn ( config ) . anyTimes ( ) ; expect ( repositoryMock . getAllRefs ( ) ) . andReturn ( localRefs ) ; expect ( repositoryMock . updateRef ( "fooProject" ) ) . andReturn ( refUpdateMock ) ; } private void setupRefUpdateMock ( ) { refUpdateMock = createNiceMock ( RefUpdate . class ) ;
&& compareField ( ref . getStatus ( ) , expectedRef . getStatus ( ) ) && compareField ( ref . getExpectedOldObjectId ( ) , expectedRef . getExpectedOldObjectId ( ) ) && compareField ( ref . getNewObjectId ( ) , expectedRef . getNewObjectId ( ) ) && compareField ( ref . isFastForward ( ) , expectedRef . isFastForward ( ) ) && compareField ( ref . getSrcRef ( ) , expectedRef . getSrcRef ( ) ) && compareField ( ref . isForceUpdate ( ) , expectedRef . isForceUpdate ( ) ) && compareField ( ref . getMessage ( ) , expectedRef . getMessage ( ) ) ; } < |startfocus| > private boolean compareField ( Object obj , Object expectedObj ) { return obj != null ? obj . equals ( expectedObj ) : expectedObj == null ; } < |endfocus| > } }
public GitPerson committer ; public String comment ; UpdateRef ( String projectName , String refName , String oldId , String newId , GitPerson committer , String comment ) { this . type = Type . UPDATE_REF ; this . projectName = projectName ; this . refName = refName ; this . oldId = oldId ; this . newId = newId ; this . committer = committer ; this . comment = comment ; } } public static class DeleteProject extends SharedRefLogEntry { public String refName ; public String oldId ; DeleteProject ( String projectName ) { this . type = Type . DELETE_PROJECT ; this . projectName = projectName ; } } public static class DeleteRef extends SharedRefLogEntry { public String refName ; public String oldId ; DeleteRef ( String projectName , String refName , String oldId ) { this . type = Type . DELETE_REF ; this . projectName = projectName ; this . refName = refName ; this . oldId = oldId ; } } }
public String comment ; UpdateRef ( String projectName , String refName , String oldId , String newId , GitPerson committer , String comment ) { this . type = Type . UPDATE_REF ; this . projectName = projectName ; this . refName = refName ; this . oldId = oldId ; this . newId = newId ; this . committer = committer ; this . comment = comment ; } } public static class DeleteProject extends SharedRefLogEntry { public String refName ; public String oldId ; DeleteProject ( String projectName ) { this . type = Type . DELETE_PROJECT ; this . projectName = projectName ; } } public static class DeleteRef extends SharedRefLogEntry { public String refName ; public String oldId ; DeleteRef ( String projectName , String refName , String oldId ) { this . type = Type . DELETE_REF ; this . projectName = projectName ; this . refName = refName ; this . oldId = oldId ; } } }
// limitations under the License . package com . google . gerrit . plugins . checks . api ; import com . google . gerrit . exceptions . StorageException ; import com . google . gerrit . extensions . restapi . BadRequestException ; import com . google . gerrit . extensions . restapi . RestApiException ; import com . google . gerrit . extensions . restapi . RestModifyView ; import com . google . gerrit . server . permissions . PermissionBackendException ; import com . google . inject . Inject ; import com . google . inject . Singleton ; import java . io . IOException ; import org . eclipse . jgit . errors . ConfigInvalidException ; @Singleton public class RerunCheck implements RestModifyView < CheckResource , CheckInput > { < |startfocus| > private final PostCheck postCheck ; < |endfocus| > @Inject RerunCheck ( PostCheck postCheck ) { this . postCheck = postCheck ; } @Override public CheckInfo apply ( CheckResource checkResource , CheckInput input ) throws RestApiException , IOException , StorageException , PermissionBackendException , ConfigInvalidException { if ( input == null ) { input = new CheckInput ( ) ; } if ( input . checkerUuid == null ) { input . checkerUuid = checkResource . getCheckerUuid ( ) . get ( ) ; } else if ( ! checkResource . getCheckerUuid ( ) . get ( ) . equals ( input . checkerUuid ) ) { throw new BadRequestException (
import com . google . common . cache . CacheLoader ; import com . google . common . flogger . FluentLogger ; import com . google . gerrit . server . cache . proto . Cache . AllExternalIds ; import com . google . gerrit . server . cache . proto . Cache . ExternalIdCacheEntry ; import com . google . gerrit . server . cache . serialize . CacheSerializer ; import com . google . gerrit . server . cache . serialize . ObjectIdCacheSerializer ; import com . google . gerrit . server . cache . serialize . ObjectIdSerializer ; import com . google . gerrit . server . config . GerritServerConfig ; import com . google . gerrit . server . git . GitRepositoryManager ; import com . google . gerrit . server . git . meta . MetaDataUpdate ; import com . google . gerrit . server . logging . TraceContext ; import com . google . gerrit . server . logging . TraceContext . TraceTimer ; import com . google . gerrit . server . notedb . ChangeNotes ; import com . google . gerrit . server . notedb . ChangeUpdate ; import com . google . gerrit . server . notedb . NotesMigration ; import com . google . gerrit . server . notedb . Sequences ; import com . google . gerrit . server . notedb . rebuild . ChangeRebuilder ; import com . google . gerrit . server . project . ProjectCache ; import com . google . gerrit . server . project . ProjectState ; import com . google . gerrit . server . query . change . ChangeData ; import com . google . gerrit . server . query . change . InternalChangeQuery ; import com . google . inject . Inject ; import com . google . inject . Provider ; import com . google . inject . Singleton ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Collection ; import java . util . List ; import java . util . Optional ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . lib . ObjectId ; import org . eclipse . jgit . lib . ObjectReader ; import org . eclipse . jgit . lib . Ref ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . revwalk . RevCommit ; import org . eclipse . jgit . revwalk . RevWalk ; import org . eclipse . jgit . util . io . DisabledOutputStream ; < |startfocus| > /* * Loads cache values for the external ID cache using either a full or a partial reload . */ < |endfocus| > public class ExternalIdCacheLoader extends CacheLoader < ObjectId , AllExternalIds > { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; // Maximum number of prior states we inspect to find a base for differential . If no cached state // is found within this number of parents , , we fall back to reading everything from scratch . private static final int MAX_HISTORY_LOOKBACK = 10 ; // Maximum number of changes we perform using the differential approach . If more updates need to
import org . eclipse . jgit . revwalk . RevWalk ; import org . eclipse . jgit . util . io . DisabledOutputStream ; /* * Loads cache values for the external ID cache using either a full or a partial reload . */ public class ExternalIdCacheLoader extends CacheLoader < ObjectId , AllExternalIds > { private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; // Maximum number of prior states we inspect to find a base for differential . If no cached state < |startfocus| > // is found within this number of parents , we fall back to reading everything from scratch . < |endfocus| > private static final int MAX_HISTORY_LOOKBACK = 10 ; // Maximum number of changes we perform using the differential approach . If more updates need to // be applied , we fall back to reading everything from scratch . private static final int MAX_DIFF_UPDATES = 50 ; private final ExternalIdReader externalIdReader ; private final Provider < Cache < ObjectId , AllExternalIds > > externalIdCache ; private final GitRepositoryManager gitRepositoryManager ; private final AllUsersName allUsersName ; private final Counter1 < Boolean > reloadCounter ; private final Timer0 reloadDifferential ;
new Description ( "Total number of external ID cache reloads from Git . " ) . setRate ( ) . setUnit ( "updates" ) , Field . ofBoolean ( "partial" , Metadata . Builder : : partial ) . build ( ) ) ; this . reloadDifferential = metricMaker . newTimer ( "notedb / external_id_partial_read_latency" , new Description ( "Latency for generating a new external ID cache state from a prior state . " ) . setCumulative ( ) . setUnit ( Units . MILLISECONDS ) ) ; this . enablePartialReloads = < |startfocus| > config . getBoolean ( "cache" , ExternalIdCacheImpl . CACHE_NAME , "enablePartialReloads" , false ) ; < |endfocus| > } @Override public AllExternalIds load ( ObjectId notesRev ) throws IOException , ConfigInvalidException { if ( ! enablePartialReloads ) { logger . atInfo ( ) . log ( "Partial reloads of " + ExternalIdCacheImpl . CACHE_NAME + " disabled . Falling back to full reload . " ) ; return reloadAllExternalIdsAndCachePersistently ( notesRev ) ; } // We failed to load the requested value from both the in - memory cache ( hence , this loader was
import com . googlesource . gerrit . plugins . renameproject . monitor . ProgressMonitor ; import java . io . BufferedReader ; import java . io . IOException ; import java . io . InputStreamReader ; import java . util . List ; import org . kohsuke . args4j . Argument ; import org . slf4j . Logger ; import org . slf4j . LoggerFactory ; @CommandMetaData ( name = "rename" , description = "Rename project" ) public final class RenameCommand extends SshCommand { @Argument ( index = 0 , required = true , metaVar = "OLDPROJECT" , usage = "project to rename" ) < |startfocus| > private String existingProjectName ; < |endfocus| > @Argument ( index = 1 , required = true , metaVar = "NEWNAME" , usage = "new name for the project" ) private String newProjectName ; private static final Logger log = LoggerFactory . getLogger ( RenameCommand . class ) ; private final RenameProject renameProject ; private final ProjectCache projectCache ; private final Provider < CurrentUser > self ; @Inject protected RenameCommand ( RenameProject renameProject , ProjectCache projectCache , Provider < CurrentUser > self ) { this . renameProject = renameProject ; this . projectCache = projectCache ; this . self = self ; } @Override
public abstract Optional < Timestamp > finished ( ) ; public abstract Builder toBuilder ( ) ; public static Builder builder ( ) { return new AutoValue_CheckUpdate . Builder ( ) ; } @AutoValue . Builder public abstract static class Builder { public abstract Builder setState ( CheckState state ) ; public abstract Builder setMessage ( String message ) ; public abstract Builder setUrl ( String url ) ; /* * < |startfocus| > * @param started - set the time the check started . Time can be reset to "null" if passed new * Timestamp ( 0 ) . < |endfocus| > */ public abstract Builder setStarted ( @Nullable Timestamp started ) ; /* * * @param finished - set the time the check finished . Time can be reset to "null" if passed new * Timestamp ( 0 ) . */ public abstract Builder setFinished ( @Nullable Timestamp finished ) ; public abstract CheckUpdate build ( ) ; } }
private static final FluentLogger logger = FluentLogger . forEnclosingClass ( ) ; // Maximum number of prior states we inspect to find a base for differential . If no cached state < |startfocus| > // is found within this number of parents , , we fall back to reading everything from scratch . < |endfocus| > private static final int MAX_HISTORY_LOOKBACK = 10 ; // Maximum number of changes we perform using the differential approach . If more updates need to // be applied , we fall back to reading everything from scratch . private static final int MAX_DIFF_UPDATES = 50 ; private final ExternalIdReader externalIdReader ; private final Provider < Cache < ObjectId , AllExternalIds > > externalIdCache ; private final GitRepositoryManager gitRepositoryManager ; private final AllUsersName allUsersName ; private final Counter1 < Boolean > reloadCounter ; private final Timer0 reloadDifferential ; private final boolean enablePartialReloads ; @Inject ExternalIdCacheLoader ( GitRepositoryManager gitRepositoryManager , AllUsersName allUsersName , ExternalIdReader externalIdReader , @Named ( ExternalIdCacheImpl . CACHE_NAME ) Provider < Cache < ObjectId , AllExternalIds > > externalIdCache , MetricMaker metricMaker , Config cfg ,
// state . try ( Repository repo = gitRepositoryManager . openRepository ( allUsersName ) ) { long start = System . nanoTime ( ) ; Ref extId = repo . exactRef ( RefNames . REFS_EXTERNAL_IDS ) ; if ( extId == null ) { logger . atInfo ( ) . log ( RefNames . REFS_EXTERNAL_IDS + " not initialized , falling back to full reload . " ) ; return reloadAllExternalIdsAndCachePersistently ( notesRev ) ; } < |startfocus| > RevWalk rw = new RevWalk ( repo ) ; RevCommit currentCommit = rw . parseCommit ( extId . getObjectId ( ) ) ; rw . markStart ( currentCommit ) ; RevCommit parentWithCacheValue = null ; AllExternalIds oldExternalIds = null ; for ( int i = 0 ; i < MAX_HISTORY_LOOKBACK ; i ++ ) { parentWithCacheValue = rw . next ( ) ; oldExternalIds = externalIdCache . get ( ) . getIfPresent ( parentWithCacheValue . getId ( ) ) ; if ( oldExternalIds != null ) { break ; } if ( parentWithCacheValue . getParentCount ( ) != 1 ) { logger . atWarning ( ) . log (
logger . atInfo ( ) . log ( RefNames . REFS_EXTERNAL_IDS + " not initialized , falling back to full reload . " ) ; return reloadAllExternalIdsAndCachePersistently ( notesRev ) ; } RevWalk rw = new RevWalk ( repo ) ; RevCommit currentCommit = rw . parseCommit ( extId . getObjectId ( ) ) ; rw . markStart ( currentCommit ) ; RevCommit parentWithCacheValue = null ; AllExternalIds oldExternalIds = null ; < |startfocus| > for ( int i = 0 ; i < MAX_HISTORY_LOOKBACK ; i ++ ) { parentWithCacheValue = rw . next ( ) ; < |endfocus| > oldExternalIds = externalIdCache . get ( ) . getIfPresent ( parentWithCacheValue . getId ( ) ) ; if ( oldExternalIds != null ) { break ; } if ( parentWithCacheValue . getParentCount ( ) != 1 ) { logger . atWarning ( ) . log ( "Unable to find an old ExternalId cache state because % s doesn't have exactly " + "one parent , falling back to full reload" , parentWithCacheValue ) ; return reloadAllExternalIdsAndCachePersistently ( notesRev ) ; } } if ( oldExternalIds == null ) { logger . atWarning ( ) . log ( "Unable to find an old ExternalId cache state , falling back to full reload" ) ; return reloadAllExternalIdsAndCachePersistently ( notesRev ) ; }
nameToBlob . getValue ( ) ) ; } catch ( ConfigInvalidException | RuntimeException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Ignoring invalid external ID note % s" , nameToBlob . getKey ( ) . name ( ) ) ; continue ; } byAccount . put ( parsedExternalId . accountId ( ) , parsedExternalId ) ; if ( parsedExternalId . email ( ) != null ) { byEmail . put ( parsedExternalId . email ( ) , parsedExternalId ) ; } } < |startfocus| > reloadCounter . increment ( true ) ; try ( Timer1 . Context ignored = reloadDifferential . start ( ) ) { return new AutoValue_AllExternalIds ( byAccount . build ( ) , byEmail . build ( ) ) ; } } } private static ObjectId fileNameToObjectId ( String path ) { int lastSlash = path . lastIndexOf ( ' / ' ) ; return ObjectId . fromString ( lastSlash > 0 ? path . substring ( lastSlash ) : path ) ; } private AllExternalIds reloadAllExternalIdsAndCachePersistently ( ObjectId notesRev ) throws IOException , ConfigInvalidException { try ( TraceTimer ignored = TraceContext . newTimer ( "Loading external IDs from scratch" ,
private static ObjectId fileNameToObjectId ( String path ) { < |startfocus| > return ObjectId . fromString ( path . replace ( ' / ' , ' ' ) ) ; < |endfocus| >
} private AllExternalIds reloadAllExternalIdsAndCachePersistently ( ObjectId notesRev ) throws IOException , ConfigInvalidException { try ( TraceTimer ignored = TraceContext . newTimer ( "Loading external IDs from scratch" , Metadata . builder ( ) . revision ( notesRev . name ( ) ) . build ( ) ) ) { ImmutableSet < ExternalId > externalIds = externalIdReader . all ( notesRev ) ; externalIds . forEach ( ExternalId : : checkThatBlobIdIsSet ) ; AllExternalIds allExternalIds = AllExternalIds . create ( externalIds ) ; < |startfocus| > externalIdCache . get ( ) . put ( notesRev , allExternalIds ) ; < |endfocus| > reloadCounter . increment ( false ) ; return allExternalIds ; } } }
// The UUID of a group . public abstract Optional < String > groupUuid ( ) ; // HTTP status response code . public abstract Optional < Integer > httpStatus ( ) ; // The name of a secondary index . public abstract Optional < String > indexName ( ) ; // The version of a secondary index . public abstract Optional < Integer > indexVersion ( ) ; // The name of the implementation method . public abstract Optional < String > methodName ( ) ; // Boolean : one or more public abstract Optional < Boolean > multiple ( ) ; < |startfocus| > // Boolean : partial or full public abstract Optional < Boolean > partial ( ) ; // Path of a metadata file in NoteDb . public abstract Optional < String > noteDbFilePath ( ) ; // Name of a metadata ref in NoteDb . public abstract Optional < String > noteDbRefName ( ) ; // Type of a sequence in NoteDb ( ACCOUNTS , CHANGES , GROUPS ) . public abstract Optional < String > noteDbSequenceType ( ) ; // Name of a "table" in NoteDb ( if set , always CHANGES ) . public abstract Optional < String > noteDbTable ( ) ; // The ID of a patch set . < |endfocus| >
package com . google . gerrit . server . config ; import com . google . inject . Inject ; import com . google . inject . Singleton ; import org . eclipse . jgit . lib . Config ; @Singleton public class ThreadSettingsConfig { private final int sshdThreads ; private final int httpdMaxThreads ; private final int sshdBatchThreads ; private final int databasePoolLimit ; @Inject ThreadSettingsConfig ( @GerritServerConfig Config cfg ) { int cores = Runtime . getRuntime ( ) . availableProcessors ( ) ; < |startfocus| > sshdThreads = cfg . getInt ( "sshd" , "threads" , Math . max ( 4 , 2 * cores ) ) ; < |endfocus| > httpdMaxThreads = cfg . getInt ( "httpd" , "maxThreads" , 25 ) ; int defaultDatabasePoolLimit = sshdThreads + httpdMaxThreads + 2 ; databasePoolLimit = cfg . getInt ( "database" , "poolLimit" , defaultDatabasePoolLimit ) ; sshdBatchThreads = cores == 1 ? 1 : 2 ; } public int getDatabasePoolLimit ( ) { return databasePoolLimit ; } public int getHttpdMaxThreads ( ) { return httpdMaxThreads ; } public int getSshdThreads ( ) { return sshdThreads ; } public int getSshdBatchTreads ( ) { return sshdBatchThreads ; } }
import org . eclipse . jgit . lib . RefUpdate . Result ; import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . lib . RepositoryCache . FileKey ; import org . eclipse . jgit . util . FS ; public class AccountsOnInit { private final InitFlags flags ; private final SitePaths site ; private final String allUsers ; @Inject public AccountsOnInit ( InitFlags flags , SitePaths site , AllUsersNameOnInitProvider allUsers ) { this . flags = flags ; this . site = site ; this . allUsers = allUsers . get ( ) ; } < |startfocus| > public Account insert ( Account . Builder account ) throws IOException { < |endfocus| > File path = getPath ( ) ; if ( path != null ) { try ( Repository repo = new FileRepository ( path ) ; ObjectInserter oi = repo . newObjectInserter ( ) ) { PersonIdent ident = new PersonIdent ( new GerritPersonIdentProvider ( flags . cfg ) . get ( ) , account . registeredOn ( ) ) ; Config accountConfig = new Config ( ) ; AccountProperties . writeToAccountConfig ( InternalAccountUpdate . builder ( ) . setActive ( account . isActive ( ) ) . setFullName ( account . fullName ( ) ) . setPreferredEmail ( account . preferredEmail ( ) ) . setStatus ( account . status ( ) ) . build ( ) ,
AllUsersName allUsersName = new AllUsersName ( AllUsersNameProvider . DEFAULT ) ; Account . Builder account = Account . builder ( Account . id ( 1 ) , TimeUtil . nowTs ( ) ) ; String metaId = "0e39795bb25dc914118224995c53c5c36923a461" ; account . setMetaId ( metaId ) ; List < String > values = toStrings ( AccountField . REF_STATE . get ( AccountState . forAccount ( account . build ( ) ) ) ) ; assertThat ( values ) . hasSize ( 1 ) ; String expectedValue = < |startfocus| > allUsersName . get ( ) + " : " + RefNames . refsUsers ( account . getId ( ) ) + " : " + metaId ; < |endfocus| > assertThat ( Iterables . getOnlyElement ( values ) ) . isEqualTo ( expectedValue ) ; } @Test public void externalIdStateFieldValues ( ) throws Exception { Account . Id id = Account . id ( 1 ) ; Account account = Account . create ( id , TimeUtil . nowTs ( ) ) ; ExternalId extId1 = ExternalId . create ( ExternalId . Key . create ( ExternalId . SCHEME_MAILTO , "foo . bar@example . com" ) , id , "foo . bar@example . com" , null , ObjectId . fromString ( "1b9a0cf038ea38a0ab08617c39aa8e28413a27ca" ) ) ; ExternalId extId2 =
@CommandMetaData ( name = "rename" , description = "Rename project" ) public final class RenameCommand extends SshCommand { @Argument ( index = 0 , required = true , metaVar = "OLDPROJECT" , usage = "project to rename" ) private String projectControl ; @Argument ( index = 1 , required = true , metaVar = "NEWNAME" , usage = "new name for the project" ) private String newProjectName ; private static final Logger log = LoggerFactory . getLogger ( RenameCommand . class ) ; private final RenameProject renameProject ; < |startfocus| > private final Provider < ProjectCache > projectCache ; < |endfocus| > private final Provider < CurrentUser > self ; @Inject protected RenameCommand ( RenameProject renameProject , Provider < ProjectCache > projectCache , Provider < CurrentUser > self ) { this . renameProject = renameProject ; this . projectCache = projectCache ; this . self = self ; } @Override public void run ( ) throws Exception { try { RenameProject . Input input = new RenameProject . Input ( ) ; input . name = newProjectName ; ProjectResource rsrc = new ProjectResource ( projectCache . get ( ) . get ( new Project . NameKey ( projectControl ) ) , self . get ( ) ) ;
&& Objects . equals ( other . checkerUuid , checkerUuid ) && Objects . equals ( other . state , state ) && Objects . equals ( other . message , message ) && Objects . equals ( other . url , url ) && Objects . equals ( other . started , started ) && Objects . equals ( other . finished , finished ) && Objects . equals ( other . created , created ) && Objects . equals ( other . updated , updated ) && Objects . equals ( other . checkerName , checkerName ) && Objects . equals ( other . checkerStatus , checkerStatus ) && Objects . equals ( other . blocking , blocking ) < |startfocus| > && Objects . equals ( other . description , description ) ; < |endfocus| >
public abstract Optional < Timestamp > started ( ) ; public abstract Optional < Timestamp > finished ( ) ; public abstract Builder toBuilder ( ) ; public static Builder builder ( ) { return new AutoValue_CheckUpdate . Builder ( ) ; } @AutoValue . Builder public abstract static class Builder { public abstract Builder setState ( CheckState state ) ; public abstract Builder setMessage ( String message ) ; public abstract Builder setUrl ( String url ) ; /* * < |startfocus| > * @param started - set the time the check started . Time can be reset to "null" if passed new * Timestamp ( 0 ) . < |endfocus| > */ public abstract Builder setStarted ( Timestamp started ) ; /* * * @param finished - set the time the check finished . Time can be reset to "null" if passed new * Timestamp ( 0 ) . */ public abstract Builder setFinished ( Timestamp finished ) ; public abstract CheckUpdate build ( ) ; } }
public abstract Optional < Timestamp > finished ( ) ; public abstract Builder toBuilder ( ) ; public static Builder builder ( ) { return new AutoValue_CheckUpdate . Builder ( ) ; } @AutoValue . Builder public abstract static class Builder { public abstract Builder setState ( CheckState state ) ; public abstract Builder setMessage ( String message ) ; public abstract Builder setUrl ( String url ) ; /* * < |startfocus| > * @param started - set the time the check started . Time can be reset to "null" if passed { @code new * Timestamp ( 0 ) } . < |endfocus| > */ public abstract Builder setStarted ( Timestamp started ) ; /* * * @param finished - set the time the check finished . Time can be reset to "null" if passed { @code new * Timestamp ( 0 ) } . */ public abstract Builder setFinished ( Timestamp finished ) ; public abstract CheckUpdate build ( ) ; } }
public abstract Optional < Timestamp > finished ( ) ; public abstract Builder toBuilder ( ) ; public static Builder builder ( ) { return new AutoValue_CheckUpdate . Builder ( ) ; } @AutoValue . Builder public abstract static class Builder { public abstract Builder setState ( CheckState state ) ; public abstract Builder setMessage ( String message ) ; public abstract Builder setUrl ( String url ) ; /* * < |startfocus| > * @param started Set the time the check started . Time can be reset to "null" if passed { @code * new Timestamp ( 0 ) } < |endfocus| > */ public abstract Builder setStarted ( Timestamp started ) ; /* * * @param finished Set the time the check finished . Time can be reset to "null" if passed { @code * new Timestamp ( 0 ) } */ public abstract Builder setFinished ( Timestamp finished ) ; public abstract CheckUpdate build ( ) ; } }
String email = readEmail ( sshKey ) ; List < ExternalId > extIds = new ArrayList < > ( 2 ) ; extIds . add ( ExternalId . createUsername ( username , id , httpPassword ) ) ; if ( email != null ) { extIds . add ( ExternalId . createEmail ( id , email ) ) ; } externalIds . insert ( "Add external IDs for initial admin user" , extIds ) ; < |startfocus| > Account persistedAccount = accounts . insert ( Account . builder ( id , TimeUtil . nowTs ( ) ) . setFullName ( name ) . setPreferredEmail ( email ) ) ; < |endfocus| > // Only two groups should exist at this point in time and hence iterating over all of them // is cheap . Optional < GroupReference > adminGroupReference = groupsOnInit . getAllGroupReferences ( ) . filter ( group - > group . getName ( ) . equals ( "Administrators" ) ) . findAny ( ) ; if ( ! adminGroupReference . isPresent ( ) ) { throw new NoSuchGroupException ( "Administrators" ) ; } GroupReference adminGroup = adminGroupReference . get ( ) ; groupsOnInit . addGroupMember ( adminGroup . getUUID ( ) , persistedAccount ) ; if ( sshKey != null ) {
CommitMessageUtil . checkAndSanitizeCommitMessage ( revCommit . getShortMessage ( ) ) ; List < String > changeIdFooters = revCommit . getFooterLines ( FooterConstants . CHANGE_ID ) ; if ( ! changeIdFooters . isEmpty ( ) && ! changeIdFooters . get ( 0 ) . equals ( currentChangeId ) ) { throw new ResourceConflictException ( "wrong Change - Id footer" ) ; } if ( revCommit . getFooterLines ( ) . isEmpty ( ) ) { // sanitization always adds '\n' at the end . newCommitMessage += "\n" ; } if ( requireChangeId && changeIdFooters . isEmpty ( ) ) { newCommitMessage += FooterConstants . CHANGE_ID . getName ( ) + " : " + currentChangeId + "\n" ; } else if ( changeIdFooters . size ( ) > 1 ) { throw new ResourceConflictException ( "multiple Change - Id footers" ) ; } return newCommitMessage ; } }
/* * Java API to interact with single { @code Check } s . */ public interface CheckApi { /* * Returns a { @link CheckInfo } for the scoped resource with the given options . */ CheckInfo get ( ListChecksOption . . . options ) throws RestApiException ; /* * Updates a check and returns the { @link CheckInfo } for the updated resource . */ CheckInfo update ( CheckInput input ) throws RestApiException ; < |startfocus| > /* * * Reruns the check and returns the { @link CheckInfo } for the updated check . */ < |endfocus| > CheckInfo rerun ( ) throws RestApiException ; /* * * A default implementation which allows source compatibility when adding new methods to the * interface . */ class NotImplemented implements CheckApi { @Override public CheckInfo get ( ListChecksOption . . . options ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override public CheckInfo update ( CheckInput input ) throws RestApiException { throw new NotImplementedException ( ) ; } @Override public CheckInfo rerun ( ) throws RestApiException { throw new NotImplementedException ( ) ;
private final Checks checks ; private final Provider < ChecksUpdate > checksUpdate ; private final CheckJson . Factory checkJsonFactory ; @Inject RerunCheck ( Provider < CurrentUser > self , PermissionBackend permissionBackend , AdministrateCheckersPermission permission , Checks checks , @UserInitiated Provider < ChecksUpdate > checksUpdate , CheckJson . Factory checkJsonFactory ) { this . self = self ; this . permissionBackend = permissionBackend ; this . permission = permission ; this . checks = checks ; this . checksUpdate = checksUpdate ; this . checkJsonFactory = checkJsonFactory ; } < |startfocus| > < |endfocus| > @Override public CheckInfo apply ( CheckResource checkResource , Input input ) throws RestApiException , IOException , StorageException , PermissionBackendException , ConfigInvalidException { if ( ! self . get ( ) . isIdentifiedUser ( ) ) { throw new AuthException ( "Authentication required" ) ; } permissionBackend . currentUser ( ) . check ( permission ) ; if ( checkResource . getRevisionResource ( ) . getEdit ( ) . isPresent ( ) ) { throw new ResourceConflictException ( "checks are not supported on a change edit" ) ; } CheckKey key = CheckKey . create ( checkResource . getRevisionResource ( ) . getProject ( ) ,
import com . google . gerrit . extensions . restapi . AuthException ; import com . google . gerrit . extensions . restapi . UnprocessableEntityException ; import com . google . gerrit . plugins . checks . CheckKey ; import com . google . gerrit . plugins . checks . CheckerUuid ; import com . google . gerrit . plugins . checks . acceptance . AbstractCheckersTest ; import com . google . gerrit . plugins . checks . api . CheckInfo ; import com . google . gerrit . plugins . checks . api . CheckState ; import com . google . gerrit . reviewdb . client . PatchSet ; import com . google . inject . Inject ; import org . junit . Before ; import org . junit . Test ; public class RerunCheckIT extends AbstractCheckersTest { < |startfocus| > @Inject private RequestScopeOperations requestScopeOperations ; < |endfocus| > private PatchSet . Id patchSetId ; private CheckKey checkKey ; @Before public void setUp ( ) throws Exception { patchSetId = createChange ( ) . getPatchSetId ( ) ; CheckerUuid checkerUuid = checkerOperations . newChecker ( ) . repository ( project ) . create ( ) ; checkKey = CheckKey . create ( project , patchSetId , checkerUuid ) ; } @Test public void rerunNotStartedCheck ( ) throws Exception { checkOperations . newCheck ( checkKey ) . upsert ( ) ; CheckInfo info = checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( ) ; assertThat ( info . started ) . isNull ( ) ; assertThat ( info . finished ) . isNull ( ) ; } }
import org . junit . Test ; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations ; private PatchSet . Id patchSetId ; private CheckKey checkKey ; @Before public void setUp ( ) throws Exception { patchSetId = createChange ( ) . getPatchSetId ( ) ; CheckerUuid checkerUuid = checkerOperations . newChecker ( ) . repository ( project ) . create ( ) ; checkKey = CheckKey . create ( project , patchSetId , checkerUuid ) ; } @Test public void rerunNotStartedCheck ( ) throws Exception { checkOperations . newCheck ( checkKey ) . state ( CheckState . NOT_STARTED ) . upsert ( ) ; CheckInfo info = checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( ) ; assertThat ( info . state ) . isEqualTo ( CheckState . NOT_STARTED ) ; } @Test public void rerunFinishedCheck ( ) throws Exception { checkOperations . newCheck ( checkKey ) . state ( CheckState . SUCCESSFUL ) . upsert ( ) ; CheckInfo info = checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( ) ; assertThat ( info . state ) . isEqualTo ( CheckState . NOT_STARTED ) ; } @Test public void rerunNotExistingCheckThrowsError ( ) throws Exception { assertThrows (
CheckInfo info = checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( ) ; assertThat ( info . state ) . isEqualTo ( CheckState . NOT_STARTED ) ; } @Test public void rerunFinishedCheck ( ) throws Exception { checkOperations . newCheck ( checkKey ) . state ( CheckState . SUCCESSFUL ) . upsert ( ) ; CheckInfo info = checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( ) ; assertThat ( info . state ) . isEqualTo ( CheckState . NOT_STARTED ) ; } @Test < |startfocus| > public void rerunNotExistingCheckThrowsError ( ) throws Exception { < |endfocus| > assertThrows ( UnprocessableEntityException . class , ( ) - > checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( ) ) ; } @Test public void cannotUpdateCheckWithoutAdministrateCheckers ( ) throws Exception { requestScopeOperations . setApiUser ( user . id ( ) ) ; checkOperations . newCheck ( checkKey ) . state ( CheckState . SUCCESSFUL ) . upsert ( ) ; AuthException thrown = assertThrows ( AuthException . class , ( ) - > checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( ) ) ; assertThat ( thrown ) . hasMessageThat ( ) . contains ( "not permitted" ) ; } @Test
. add ( "repository" , repository ) . add ( "changeNumber" , changeNumber ) . add ( "patchSetId" , patchSetId ) . add ( "checkerUuid" , checkerUuid ) . add ( "state" , state ) . add ( "message" , message ) . add ( "url" , url ) . add ( "started" , started ) . add ( "finished" , finished ) . add ( "created" , created ) . add ( "updated" , updated ) . add ( "checkerName" , checkerName ) . add ( "checkerStatus" , checkerStatus ) . add ( "blocking" , blocking ) < |startfocus| > . add ( "description" , description ) < |endfocus| > . toString ( ) ;
public abstract Optional < Timestamp > finished ( ) ; public abstract Builder toBuilder ( ) ; public static Builder builder ( ) { return new AutoValue_CheckUpdate . Builder ( ) ; } @AutoValue . Builder public abstract static class Builder { public abstract Builder setState ( CheckState state ) ; public abstract Builder setMessage ( String message ) ; public abstract Builder setUrl ( String url ) ; /* * * @param started Set the time the check started . Time can be reset to "null" if passed { @code * new Timestamp ( 0 ) } */ public abstract Builder setStarted ( Timestamp started ) ; /* * * @param finished Set the time the check finished . Time can be reset to "null" if passed { @code * new Timestamp ( 0 ) } */ public abstract Builder setFinished ( Timestamp finished ) ; public abstract CheckUpdate build ( ) ; } }
assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verify ( externalIdReaderSpy , times ( 1 ) ) . all ( head ) ; } @Test public void fallsBackToFullReloadOnManyUpdatesOnBranch ( ) throws Exception { insertExternalId ( 1 , 1 ) ; ObjectId head = null ; for ( int i = 2 ; i < 20 ; i ++ ) { head = insertExternalId ( i , i ) ; } assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verify ( externalIdReaderSpy , times ( 1 ) ) . all ( head ) ; } @Test public void handlesDeletionInPartialReload ( ) throws Exception { ObjectId firstState = insertExternalId ( 1 , 1 ) ; ObjectId head = deleteExternalId ( 1 , 1 ) ; assertThat ( allFromGit ( head ) . byAccount ( ) . size ( ) ) . isEqualTo ( 0 ) ; when ( externalIdCache . getIfPresent ( firstState ) ) . thenReturn ( allFromGit ( firstState ) ) ; assertThat ( loader . load ( head ) ) . isEqualTo ( allFromGit ( head ) ) ; verifyZeroInteractions ( externalIdReaderSpy ) ; } < |startfocus| > @Test < |endfocus| > public void handlesModifyInPartialReload ( ) throws Exception { ObjectId firstState = insertExternalId ( 1 , 1 ) ;
public void emptyStringIsDeserializedToMagicTimestamp ( ) { Timestamp timestamp = deserializer . deserialize ( new JsonPrimitive ( "" ) , Timestamp . class , null ) ; < |startfocus| > Truth . assertThat ( timestamp ) . isEqualTo ( TimeUtil . never ( ) ) ; < |endfocus| > }
. add ( allow ( Permission . PUSH ) . ref ( other ) . group ( adminGroupUuid ( ) ) ) . update ( ) ; RevCommit masterRev = projectOperations . project ( project ) . getHead ( "master" ) ; pushCommitTo ( masterRev , other ) ; PushOneCommit . Result r = createChange ( ) ; r . assertOkStatus ( ) ; RevCommit commit = r . getCommit ( ) ; pushCommitTo ( commit , master ) ; assertCommit ( project , master ) ; ChangeData cd = < |startfocus| > Iterables . getOnlyElement ( queryProvider . get ( ) . byKey ( Change . key ( r . getChangeId ( ) ) ) ) ; assertThat ( cd . change ( ) . isMerged ( ) ) . isTrue ( ) ; < |endfocus| > RemoteRefUpdate . Status status = pushCommitTo ( commit , "refs / for / other" ) ; assertThat ( status ) . isEqualTo ( RemoteRefUpdate . Status . OK ) ; pushCommitTo ( commit , other ) ; assertCommit ( project , other ) ; for ( ChangeData c : queryProvider . get ( ) . byKey ( Change . key ( r . getChangeId ( ) ) ) ) { if ( c . change ( ) . getDest ( ) . branch ( ) . equals ( other ) ) { assertThat ( c . change ( ) . isMerged ( ) ) . isTrue ( ) ; } } } private RemoteRefUpdate . Status pushCommitTo ( RevCommit commit , String ref ) throws Exception {
// from the cache . Extend the cache size by 1 to cover this case , but expire the extra // object after a short period of time , since it may be a potentially large amount of // memory . // When loading a new value because the primary data advanced , we want to leverage the old // cache state to recompute only what changed . This doesn't affect cache size though as // Guava calls the loader first and evicts later on . < |startfocus| > // memory . < |endfocus| > . maximumWeight ( 2 ) . expireFromMemoryAfterAccess ( Duration . ofMinutes ( 5 ) ) . loader ( ExternalIdCacheLoader . class ) . diskLimit ( - 1 ) . version ( 1 ) . keySerializer ( ObjectIdCacheSerializer . INSTANCE ) . valueSerializer ( AllExternalIds . Serializer . INSTANCE ) ; bind ( ExternalIdCacheImpl . class ) ; bind ( ExternalIdCache . class ) . to ( ExternalIdCacheImpl . class ) ;
public HashtagsInput ( Set < String > add , Set < String > remove ) { < |startfocus| > this ( add ) ; < |endfocus| > this . remove = remove ;
CheckerUuid checkerUuid = checkerOperations . newChecker ( ) . repository ( project ) . create ( ) ; checkKey = CheckKey . create ( project , patchSetId , checkerUuid ) ; } @After public void resetTime ( ) { TestTimeUtil . useSystemTime ( ) ; } @Test public void rerunNotStartedCheck ( ) throws Exception { checkOperations . newCheck ( checkKey ) . state ( CheckState . NOT_STARTED ) . upsert ( ) ; CheckInfo info = checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( ) ; < |startfocus| > assertSuccessfulRerun ( info ) ; assertThat ( info . updated ) . isGreaterThan ( info . created ) ; < |endfocus| > } @Test public void rerunFinishedCheck ( ) throws Exception { checkOperations . newCheck ( checkKey ) . state ( CheckState . SUCCESSFUL ) . upsert ( ) ; CheckInfo info = checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( ) ; assertSuccessfulRerun ( info ) ; assertThat ( info . updated ) . isGreaterThan ( info . created ) ; } @Test public void rerunCheckNotExistingButBackfilled ( ) throws Exception { CheckInfo info = checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( ) ; assertSuccessfulRerun ( info ) ; } @Test
private final String variant ; private CommitSoyData csd ; public LogSoyData ( HttpServletRequest req , GitilesAccess access , String pretty ) throws IOException { this . req = checkNotNull ( req ) ; this . view = checkNotNull ( ViewFilter . getView ( req ) ) ; checkNotNull ( pretty ) ; Config config = access . getConfig ( ) ; fields = config . getBoolean ( "logFormat" , pretty , "verbose" , false ) ? VERBOSE_FIELDS : FIELDS ; variant = firstNonNull ( config . getString ( "logFormat" , pretty , "variant" ) , pretty ) ; } < |startfocus| > < |endfocus| > private static class LogSoyDataAppendable implements AdvisingAppendable { private final Writer writer ; LogSoyDataAppendable ( Writer writer ) { this . writer = writer ; } @Override public AdvisingAppendable append ( CharSequence csq ) throws IOException { writer . append ( csq ) ; return this ; } @Override public AdvisingAppendable append ( CharSequence csq , int start , int end ) throws IOException { writer . append ( csq , start , end ) ; return this ; } @Override public AdvisingAppendable append ( char c ) throws IOException { writer . append ( c ) ; return this ; } @Override public void close ( ) throws IOException { writer . close ( ) ; } }
// don't do something with the result , so just wrap it in a dummy method . } public void renderStreaming ( Paginator paginator , @Nullable String revision , Renderer renderer , Writer writer , DateFormatter df , FooterBehavior footerBehavior ) throws IOException { LogSoyDataAppendable out = new LogSoyDataAppendable ( writer ) ; swallowResult ( renderer . newRenderer ( "gitiles . logEntriesHeader" ) < |startfocus| > . setData ( toHeaderSoyData ( paginator , revision ) ) . renderHtml ( out ) ) ; < |endfocus| > SoySauce . Renderer entryRenderer = renderer . newRenderer ( "gitiles . logEntryWrapper" ) ; boolean renderedEntries = false ; for ( RevCommit c : paginator ) { swallowResult ( entryRenderer . setData ( toEntrySoyData ( paginator , c , df ) ) . renderHtml ( out ) ) ; out . flush ( ) ; renderedEntries = true ; } if ( ! renderedEntries ) { swallowResult ( renderer . newRenderer ( "gitiles . emptyLog" ) . renderHtml ( out ) ) ; } swallowResult ( renderer . newRenderer ( "gitiles . logEntriesFooter" ) . setData ( toFooterSoyData ( paginator , revision , footerBehavior ) ) . renderHtml ( out ) ) ; }
checkState ( u != null , "Missing Soy template % s" , soyFile ) ; Hasher h = Hashing . murmur3_128 ( ) . newHasher ( ) ; try ( InputStream is = u . openStream ( ) ; OutputStream os = Funnels . asOutputStream ( h ) ) { ByteStreams . copy ( is , os ) ; } catch ( IOException e ) { throw new IllegalStateException ( "Missing Soy template " + soyFile , e ) ; } return h . hash ( ) ; } < |startfocus| > public String renderHtml ( String templateName , Map < String , ? > soyData ) { < |endfocus| > return newRenderer ( templateName ) . setData ( soyData ) . renderHtml ( ) . get ( ) . toString ( ) ; } void render ( HttpServletRequest req , HttpServletResponse res , String templateName , Map < String , ? > soyData ) throws IOException { res . setContentType ( "text / html" ) ; res . setCharacterEncoding ( "UTF - 8" ) ; byte [ ] data = newRenderer ( templateName ) . setData ( soyData ) . renderHtml ( ) . get ( ) . toString ( ) . getBytes ( UTF_8 ) ; if ( BaseServlet . acceptsGzipEncoding ( req ) ) { res . addHeader ( HttpHeaders . VARY , HttpHeaders . ACCEPT_ENCODING ) ;
o . write ( tail ) ; } } } ; } SoySauce . Renderer newRenderer ( String templateName ) { ImmutableMap . Builder < String , Object > staticUrls = ImmutableMap . builder ( ) ; for ( String key : STATIC_URL_GLOBALS . keySet ( ) ) { staticUrls . put ( key . replaceFirst ( " ^ gitiles\\ . " , "" ) , LegacyConversions . riskilyAssumeTrustedResourceUrl ( globals . get ( key ) ) ) ; } return getSauce ( ) . renderTemplate ( templateName ) < |startfocus| > . setIj ( ImmutableMap . of ( "staticUrls" , staticUrls . build ( ) ) ) ; < |endfocus| > } protected abstract SoySauce getSauce ( ) ; }
config . getBoolean ( "cache" , ExternalIdCacheImpl . CACHE_NAME , "enablePartialReloads" , false ) ; } @Override public AllExternalIds load ( ObjectId notesRev ) throws IOException , ConfigInvalidException { if ( ! enablePartialReloads ) { logger . atInfo ( ) . log ( "Partial reloads of " + ExternalIdCacheImpl . CACHE_NAME + " disabled . Falling back to full reload . " ) ; return reloadAllExternalIds ( notesRev ) ; } < |startfocus| > // We failed to load the requested value from the cache ( hence , this loader was invoked ) . // Therefore , try to create this entry from a past value using the minimal amount of Git // operations possible to reduce latency . < |endfocus| > // // First , try to find the most recent state we have in the persistent cache . Most of the time , // this will be the state before the last update happened , but it can also date further back . We // try a best effort approach and check the last 10 states . If nothing is found , we default to // loading the value from scratch . //
config . getBoolean ( "cache" , ExternalIdCacheImpl . CACHE_NAME , "enablePartialReloads" , false ) ; } @Override public AllExternalIds load ( ObjectId notesRev ) throws IOException , ConfigInvalidException { if ( ! enablePartialReloads ) { logger . atInfo ( ) . log ( "Partial reloads of " + ExternalIdCacheImpl . CACHE_NAME + " disabled . Falling back to full reload . " ) ; return reloadAllExternalIds ( notesRev ) ; } < |startfocus| > // We failed to load the requested value from the cache ( hence , this loader was invoked ) . // Therefore , try to create this entry from a past value using the minimal amount of Git // operations possible to reduce latency . < |endfocus| > // // First , try to find the most recent state we have in the persistent cache . Most of the time , // this will be the state before the last update happened , but it can also date further back . We // try a best effort approach and check the last 10 states . If nothing is found , we default to // loading the value from scratch . //
* were performed since then . * * < p > Removals are applied before additions . * * @param repo open repository * @param oldExternalIds prior state that is used as base * @param additions map of name to blob ID for each external ID that should be added * @param removals set of name { @link ObjectId } s that should be removed */ < |startfocus| > private static AllExternalIds buildAllExternalIds ( < |endfocus| > Repository repo , AllExternalIds oldExternalIds , Map < ObjectId , ObjectId > additions , Set < ObjectId > removals ) throws IOException { ImmutableSetMultimap . Builder < Account . Id , ExternalId > byAccount = ImmutableSetMultimap . builder ( ) ; ImmutableSetMultimap . Builder < String , ExternalId > byEmail = ImmutableSetMultimap . builder ( ) ; // Copy over old ExternalIds but exclude deleted ones for ( ExternalId externalId : oldExternalIds . byAccount ( ) . values ( ) ) { if ( removals . contains ( externalId . blobId ( ) ) ) { continue ; } byAccount . put ( externalId . accountId ( ) , externalId ) ; if ( externalId . email ( ) != null ) {
private final TypeAdapter < T > defaultEnumAdapter ; public EnumTypeAdapter ( TypeAdapter < T > defaultEnumAdapter ) { this . defaultEnumAdapter = defaultEnumAdapter ; } @Override public T read ( JsonReader in ) throws IOException { // Still handle null values . - > Check them first . if ( in . peek ( ) == JsonToken . NULL ) { in . nextNull ( ) ; return null ; } T enumValue = defaultEnumAdapter . read ( in ) ; if ( enumValue == null ) { < |startfocus| > throw new JsonSyntaxException ( "Expected an existing enum value . " ) ; < |endfocus| > } return enumValue ; } @Override public void write ( JsonWriter out , T value ) throws IOException { defaultEnumAdapter . write ( out , value ) ; } } }
< |startfocus| > public void emptyEnumValueIsRejectedOnParse ( ) { assertThrows ( JsonSyntaxException . class , ( ) - > gson . fromJson ( " { \"value\" : \"\" } " , TestData . class ) ) ; < |endfocus| >
} private PushOne createPushOne ( DynamicItem < ReplicationPushFilter > replicationPushFilter ) { PushOne push = new PushOne ( gitRepositoryManagerMock , permissionBackendMock , destinationMock , remoteConfigMock , credentialsFactory , threadRequestScoperMock , replicationQueueMock , idGeneratorMock , replicationStateListenersMock , replicationMetricsMock , projectCacheMock , transportFactoryMock , projectNameKey , urish ) ; push . setReplicationPushFilter ( replicationPushFilter ) ; return push ; } private void waitUntilFinished ( ) throws InterruptedException { while ( ! isCallFinished . get ( ) ) { < |startfocus| > Thread . sleep ( 100 ) ; < |endfocus| > } } private void setupProjectCacheMock ( ) throws IOException { projectCacheMock = createNiceMock ( ProjectCache . class ) ; expect ( projectCacheMock . checkedGet ( projectNameKey ) ) . andReturn ( projectStateMock ) ; } private void setupTransportMock ( ) throws NotSupportedException , TransportException { transportMock = createNiceMock ( Transport . class ) ; expect ( transportMock . openFetch ( ) ) . andReturn ( fetchConnection ) ; transportFactoryMock = createNiceMock ( TransportFactory . class ) ; expect ( transportFactoryMock . open ( repositoryMock , urish ) ) . andReturn ( transportMock ) . anyTimes ( ) ; } private void setupReplicationMetricsMock ( ) {
* Found } for a redirect ) . * * < p > The returned response usually does not have any value ( status code { code 204 No Content } ) . * If a value in the returned response is set it is automatically converted to JSON unless it is a * { @link BinaryResult } . * < |startfocus| > * < p > Further properties like caching behavior ( see { @link CacheControl } ) can be optionally set on * the returned response . * < |endfocus| > * < p > Throwing a subclass of { @link RestApiException } results in a 4XX response to the client . For * any other exception the client will get a { @code 500 Internal Server Error } response . * * @param parentResource parent resource of the resource that should be deleted * @param id the ID of the child resource that should be deleted * @param input input after parsing from request * @return response to return to the client * @throws RestApiException if the resource creation is rejected * @throws IOException if an I / O exception occurs
* RestCollectionModifyViews this is usually { code 200 OK } , but other 2XX or 3XX status codes are * also possible ( e . g . { code 201 Created } if a resource was created , { code 202 Accepted } if a * background task was scheduled , { @code 204 No Content } if no content is returned , { @code 302 * Found } for a redirect ) . * < p > Further properties like caching behavior ( see { @link CacheControl } ) can be optionally set on * the returned response . * < p > Throwing a subclass of { @link RestApiException } results in a 4XX response to the client . For * any other exception the client will get a { @code 500 Internal Server Error } response . * * @param parentResource the collection resource on which the modification is done * @return response to return to the client * @throws Exception the implementation of the view failed . The exception will be logged and HTTP * 500 Internal Server Error will be returned to the client .
throws RestApiException , IOException , ConfigInvalidException , PermissionBackendException { if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) { permissionBackend . currentUser ( ) . check ( GlobalPermission . ADMINISTRATE_SERVER ) ; } Map < ProjectWatchKey , Set < NotifyType > > projectWatches = asMap ( input ) ; accountsUpdateProvider . get ( ) . update ( "Update Project Watches via API" , rsrc . getUser ( ) . getAccountId ( ) , u - > u . updateProjectWatches ( projectWatches ) ) ; < |startfocus| > return Response . ok ( getWatchedProjects . apply ( rsrc ) . value ( ) ) ; < |endfocus| > } private Map < ProjectWatchKey , Set < NotifyType > > asMap ( List < ProjectWatchInfo > input ) throws RestApiException , IOException , PermissionBackendException { Map < ProjectWatchKey , Set < NotifyType > > m = new HashMap < > ( ) ; for ( ProjectWatchInfo info : input ) { if ( info . project == null ) { throw new BadRequestException ( "project name must be specified" ) ; } ProjectWatchKey key = ProjectWatchKey . create ( projectsCollection . parse ( info . project ) . getNameKey ( ) , info . filter ) ; if ( m . containsKey ( key ) ) { throw new BadRequestException ( "duplicate project watch for " + info . project ) ; } m . put ( key , info . notify_types ) ; } return m ; } }
this . self = self ; this . changes = changes ; } @Override @SuppressWarnings ( "unchecked" ) public Response < List < ChangeInfo > > apply ( AccountResource rsrc ) throws BadRequestException , AuthException , PermissionBackendException { if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) { throw new AuthException ( "not allowed to list stars of another account" ) ; } QueryChanges query = changes . list ( ) ; query . addQuery ( "has : stars" ) ; < |startfocus| > return Response . ok ( query . apply ( TopLevelResource . INSTANCE ) . value ( ) ) ; < |endfocus| > } } @Singleton public static class Get implements RestReadView < AccountResource . Star > { private final Provider < CurrentUser > self ; private final StarredChangesUtil starredChangesUtil ; @Inject Get ( Provider < CurrentUser > self , StarredChangesUtil starredChangesUtil ) { this . self = self ; this . starredChangesUtil = starredChangesUtil ; } @Override public Response < SortedSet < String > > apply ( AccountResource . Star rsrc ) throws AuthException { if ( ! self . get ( ) . hasSameAccountId ( rsrc . getUser ( ) ) ) {
< |startfocus| > public Response < Object > apply ( ProjectResource rsrc , Input input ) { < |endfocus| > Project . NameKey project = rsrc . getNameKey ( ) ; if ( input . async ) { return applyAsync ( project , input ) ; } return Response . ok ( applySync ( project , input ) ) ; }
: String . format ( "Changed default dashboard to % s . \n" , input . id ) ) ; if ( ! msg . endsWith ( "\n" ) ) { msg += "\n" ; } md . setAuthor ( rsrc . getUser ( ) . asIdentifiedUser ( ) ) ; md . setMessage ( msg ) ; config . commit ( md ) ; cache . evict ( rsrc . getProjectState ( ) . getProject ( ) ) ; if ( target != null ) { < |startfocus| > DashboardInfo info = get . get ( ) . apply ( target ) . value ( ) ; info . isDefault = true ; return Response . ok ( info ) ; < |endfocus| > } return Response . none ( ) ; } catch ( RepositoryNotFoundException notFound ) { throw new ResourceNotFoundException ( rsrc . getProjectState ( ) . getProject ( ) . getName ( ) ) ; } catch ( ConfigInvalidException e ) { throw new ResourceConflictException ( String . format ( "invalid project . config : % s" , e . getMessage ( ) ) ) ; } } }
private final Configuration cfg ; private final HideProject hideProject ; @Inject DeleteProject ( FilesystemDeleteHandler fsHandler , CacheDeleteHandler cacheHandler , Provider < CurrentUser > userProvider , DeleteLog deleteLog , DeletePreconditions preConditions , Configuration cfg , HideProject hideProject ) { this . fsHandler = fsHandler ; this . cacheHandler = cacheHandler ; this . userProvider = userProvider ; this . deleteLog = deleteLog ; this . preConditions = preConditions ; this . cfg = cfg ; this . hideProject = hideProject ; } @Override < |startfocus| > public Response < ? > apply ( ProjectResource rsrc , Input input ) throws OrmException , IOException , RestApiException { < |endfocus| > preConditions . assertDeletePermission ( rsrc ) ; preConditions . assertCanBeDeleted ( rsrc , input ) ; doDelete ( rsrc , input ) ; return Response . none ( ) ; } public void doDelete ( ProjectResource rsrc , Input input ) throws IOException , RestApiException { Project project = rsrc . getProjectState ( ) . getProject ( ) ; boolean preserve = input != null && input . preserve ; Exception ex = null ; try { if ( ! preserve || ! cfg . projectOnPreserveHidden ( ) ) { try {
private void savePluginSections ( Config rc , Set < AccountGroup . UUID > keepGroups ) { unsetSection ( rc , PLUGIN ) ; < |startfocus| > for ( Map . Entry < String , Config > e : pluginConfigs . entrySet ( ) ) { String plugin = e . getKey ( ) ; Config pluginConfig = e . getValue ( ) ; for ( String name : pluginConfig . getNames ( PLUGIN , plugin ) ) { String value = pluginConfig . getString ( PLUGIN , plugin , name ) ; String groupName = GroupReference . extractGroupName ( value ) ; if ( groupName != null ) { GroupReference ref = groupsByName . get ( groupName ) ; if ( ref != null && ref . getUUID ( ) != null ) { keepGroups . add ( ref . getUUID ( ) ) ; pluginConfig . setString ( PLUGIN , plugin , name , "group " + ref . getName ( ) ) ; } } rc . setStringList ( PLUGIN , plugin , name , Arrays . asList ( pluginConfig . getStringList ( PLUGIN , plugin , name ) ) ) ; } } < |endfocus| >
this . accountInfoFactory = infoFactory ; this . projectCache = projectCache ; this . prologRule = prologRule ; } @Override public Response < List < TestSubmitRuleInfo > > apply ( RevisionResource rsrc , TestSubmitRuleInput input ) throws AuthException , PermissionBackendException , BadRequestException { if ( input == null ) { input = new TestSubmitRuleInput ( ) ; } if ( input . rule == null ) { throw new BadRequestException ( "rule is required" ) ; } < |startfocus| > if ( input . rule == null ) { throw new BadRequestException ( "rule is required" ) ; } < |endfocus| > if ( ! rules . isProjectRulesEnabled ( ) ) { throw new AuthException ( "project rules are disabled" ) ; } input . filters = MoreObjects . firstNonNull ( input . filters , filters ) ; SubmitRuleOptions opts = SubmitRuleOptions . builder ( ) . skipFilters ( input . filters == Filters . SKIP ) . rule ( input . rule ) . logErrors ( false ) . build ( ) ; ProjectState projectState = projectCache . get ( rsrc . getProject ( ) ) ; if ( projectState == null ) { throw new BadRequestException ( "project not found" ) ; }
// // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . replication ; import com . google . gerrit . extensions . registration . DynamicItem ; import com . google . inject . AbstractModule ; /* * * Module to register the { @link ReplicationPushFilter } extension point . */ public class ReplicationExtensionPointModule extends AbstractModule { @Override protected void configure ( ) { DynamicItem . itemOf ( binder ( ) , ReplicationPushFilter . class ) ; } }
throw new RuntimeException ( e ) ; } } ) . collect ( Collectors . toList ( ) ) ; PushResult pushResult = new PushResult ( ) ; expect ( transportMock . push ( anyObject ( ) , compareRemoteRef ( expectedUpdates ) ) ) . andReturn ( pushResult ) . once ( ) ; replay ( transportMock ) ; PushOne pushOne = createPushOne ( replicationPushFilter ) ; pushOne . addRef ( PushOne . ALL_REFS ) ; pushOne . run ( ) ; isCallFinished . await ( 10 , TimeUnit . SECONDS ) ; verify ( transportMock ) ; } @Test < |startfocus| > public void shouldPushAllRefsWhenNoFiltersSetup ( ) throws InterruptedException , IOException { < |endfocus| > List < RemoteRefUpdate > expectedUpdates = localRefs . values ( ) . stream ( ) . map ( ref - > { try { return new RemoteRefUpdate ( repositoryMock , ref . getName ( ) , ref . getObjectId ( ) , "fooProject" , false , "fooProject" , null ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } ) . collect ( Collectors . toList ( ) ) ; PushResult pushResult = new PushResult ( ) ; expect ( transportMock . push ( anyObject ( ) , compareRemoteRef ( expectedUpdates ) ) ) . andReturn ( pushResult ) . once ( ) ; replay ( transportMock ) ; PushOne pushOne = createPushOne ( replicationPushFilter ) ; pushOne . addRef ( PushOne . ALL_REFS ) ; pushOne . run ( ) ; isCallFinished . await ( 10 , TimeUnit . SECONDS ) ; verify ( transportMock ) ; } @Test < |startfocus| > public void shouldPushAllRefsWhenNoFiltersSetup ( ) throws InterruptedException , IOException { < |endfocus| > List < RemoteRefUpdate > expectedUpdates = localRefs . values ( ) . stream ( ) . map ( ref - > { try { return new RemoteRefUpdate ( repositoryMock , ref . getName ( ) , ref . getObjectId ( ) , "fooProject" , false , "fooProject" , null ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } ) . collect ( Collectors . toList ( ) ) ; PushResult pushResult = new PushResult ( ) ; expect ( transportMock . push ( anyObject ( ) , compareRemoteRef ( expectedUpdates ) ) ) . andReturn ( pushResult ) . once ( ) ; replay ( transportMock ) ; PushOne pushOne = createPushOne ( replicationPushFilter ) ; pushOne . addRef ( PushOne . ALL_REFS ) ; pushOne . run ( ) ; isCallFinished . await ( 10 , TimeUnit . SECONDS ) ; verify ( transportMock ) ; } @Test < |startfocus| > public void shouldPushAllRefsWhenNoFiltersSetup ( ) throws InterruptedException , IOException { < |endfocus| > List < RemoteRefUpdate > expectedUpdates = localRefs . values ( ) . stream ( ) . map ( ref - > { try { return new RemoteRefUpdate ( repositoryMock , ref . getName ( ) , ref . getObjectId ( ) , "fooProject" , false , "fooProject" , null ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } ) . collect ( Collectors . toList ( ) ) ; PushResult pushResult = new PushResult ( ) ; expect ( transportMock . push ( anyObject ( ) , compareRemoteRef ( expectedUpdates ) ) ) . andReturn ( pushResult ) . once ( ) ; replay ( transportMock ) ; PushOne pushOne = createPushOne ( replicationPushFilter ) ; pushOne . addRef ( PushOne . ALL_REFS ) ; pushOne . run ( ) ; isCallFinished . await ( 10 , TimeUnit . SECONDS ) ; verify ( transportMock ) ; } @Test < |startfocus| > public void shouldPushAllRefsWhenNoFiltersSetup ( ) throws InterruptedException , IOException { < |endfocus| > List < RemoteRefUpdate > expectedUpdates = localRefs . values ( ) . stream ( ) . map ( ref - > { try { return new RemoteRefUpdate ( repositoryMock , ref . getName ( ) , ref . getObjectId ( ) , "fooProject" , false , "fooProject" , null ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } ) . collect ( Collectors . toList ( ) ) ; PushResult pushResult = new PushResult ( ) ; expect ( transportMock . push ( anyObject ( ) , compareRemoteRef ( expectedUpdates ) ) ) . andReturn ( pushResult ) . once ( ) ; replay ( transportMock ) ; PushOne pushOne = createPushOne ( replicationPushFilter ) ; pushOne . addRef ( PushOne . ALL_REFS ) ; pushOne . run ( ) ; isCallFinished . await ( 10 , TimeUnit . SECONDS ) ; verify ( transportMock ) ; } @Test < |startfocus| > public void shouldPushAllRefsWhenNoFiltersSetup ( ) throws InterruptedException , IOException { < |endfocus| > List < RemoteRefUpdate > expectedUpdates = localRefs . values ( ) . stream ( ) . map ( ref - > { try { return new RemoteRefUpdate ( repositoryMock , ref . getName ( ) , ref . getObjectId ( ) , "fooProject" , false , "fooProject" , null ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } ) . collect ( Collectors . toList ( ) ) ; PushResult pushResult = new PushResult ( ) ; expect ( transportMock . push ( anyObject ( ) , compareRemoteRef ( expectedUpdates ) ) ) . andReturn ( pushResult ) . once ( ) ; replay ( transportMock ) ; PushOne pushOne = createPushOne ( replicationPushFilter ) ; pushOne . addRef ( PushOne . ALL_REFS ) ; pushOne . run ( ) ; isCallFinished . await ( 10 , TimeUnit . SECONDS ) ; verify ( transportMock ) ; } @Test < |startfocus| > public void shouldPushAllRefsWhenNoFiltersSetup ( ) throws InterruptedException , IOException { < |endfocus| > List < RemoteRefUpdate > expectedUpdates = localRefs . values ( ) . stream ( ) . map ( ref - > { try { return new RemoteRefUpdate ( repositoryMock , ref . getName ( ) , ref . getObjectId ( ) , "fooProject" , false , "fooProject" , null ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } ) . collect ( Collectors . toList ( ) ) ; PushResult pushResult = new PushResult ( ) ; expect ( transportMock . push ( anyObject ( ) , compareRemoteRef ( expectedUpdates ) ) ) . andReturn ( pushResult ) . once ( ) ; replay ( transportMock ) ; PushOne pushOne = createPushOne ( replicationPushFilter ) ; pushOne . addRef ( PushOne . ALL_REFS ) ; pushOne . run ( ) ; isCallFinished . await ( 10 , TimeUnit . SECONDS ) ; verify ( transportMock ) ; } @Test < |startfocus| > public void shouldPushAllRefsWhenNoFiltersSetup ( ) throws InterruptedException , IOException { < |endfocus| > List < RemoteRefUpdate > expectedUpdates = localRefs . values ( ) . stream ( ) . map ( ref - > { try { return new RemoteRefUpdate ( repositoryMock , ref . getName ( ) , ref . getObjectId ( ) , "fooProject" , false , "fooProject" , null ) ; } catch ( IOException e ) { throw new RuntimeException ( e ) ; } } ) . collect ( Collectors . toList ( ) ) ; PushResult pushResult = new PushResult ( ) ; expect ( transportMock . push ( anyObject ( ) , compareRemoteRef ( expectedUpdates ) ) ) . andReturn ( pushResult ) . once ( ) ; replay ( transportMock ) ; PushOne pushOne = createPushOne ( replicationPushFilter ) ; pushOne . addRef ( PushOne . ALL_REFS ) ; pushOne . run ( ) ; isCallFinished . await ( 10 , TimeUnit . SECONDS ) ; verify ( transportMock ) ; } @Test < |startfocus| > public void shouldPushAllRefsWhenNoFiltersSetup ( ) throws InterruptedException , IOException { < |endfocus| > List < RemoteRefUpdate > expectedUpdates = localRefs . values ( ) . stream ( ) . map ( ref - > { try { return new RemoteRefUpdate ( repositoryMock , ref . getName ( ) , ref
throw new RuntimeException ( e ) ; } } ) . collect ( Collectors . toList ( ) ) ; PushResult pushResult = new PushResult ( ) ; expect ( transportMock . push ( anyObject ( ) , compareRemoteRef ( expectedUpdates ) ) ) . andReturn ( pushResult ) . once ( ) ; replay ( transportMock ) ; PushOne pushOne = createPushOne ( null ) ; pushOne . addRef ( PushOne . ALL_REFS ) ; pushOne . run ( ) ; isCallFinished . await ( 10 , TimeUnit . SECONDS ) ; verify ( transportMock ) ; } @Test < |startfocus| > public void shouldApplyReplicationPushFilter ( ) throws InterruptedException , IOException { < |endfocus| > DynamicItem < ReplicationPushFilter > replicationPushFilter = DynamicItem . itemOf ( ReplicationPushFilter . class , new ReplicationPushFilter ( ) { @Override public List < RemoteRefUpdate > filter ( String projectName , List < RemoteRefUpdate > remoteUpdatesList ) { remoteUpdatesList . remove ( 0 ) ; return remoteUpdatesList ; } } ) ; // easymock way to check if method was never called expect ( transportMock . push ( anyObject ( ) , anyObject ( ) ) ) . andThrow ( new AssertionFailedError ( ) ) . anyTimes ( ) ; replay ( transportMock ) ; PushOne pushOne = createPushOne ( replicationPushFilter ) ; pushOne . addRef ( PushOne . ALL_REFS ) ; pushOne . run ( ) ; isCallFinished . await ( 10 , TimeUnit . SECONDS ) ; verify ( transportMock ) ; } @Test public void shouldNotReplicateIfNoRefs ( ) throws InterruptedException , IOException {
public List < RemoteRefUpdate > filter ( String projectName , List < RemoteRefUpdate > remoteUpdatesList ) { < |startfocus| > return Collections . emptyList ( ) ; < |endfocus| >
throw new AuthException ( "Authentication required" ) ; } return commentJson . get ( ) . setFillAccounts ( includeAuthorInfo ( ) ) . setFillPatchSet ( true ) . newCommentFormatter ( ) . format ( listComments ( rsrc ) ) ; } public List < CommentInfo > getComments ( ChangeResource rsrc ) throws AuthException , OrmException { if ( requireAuthentication ( ) && ! rsrc . getUser ( ) . isIdentifiedUser ( ) ) { throw new AuthException ( "Authentication required" ) ; } return commentJson . get ( ) . setFillAccounts ( includeAuthorInfo ( ) ) . setFillPatchSet ( true ) < |startfocus| > . newCommentFormatter ( ) . formatAsList ( listComments ( rsrc ) ) ; < |endfocus| > } }
static final String MAX_CACHE_AGE = "maxCacheAge" ; // seconds to stay in cache static final String MAX_CACHE_SIZE = "maxCacheSize" ; // number of OwnersDb in cache static final String MIN_OWNER_VOTE_LEVEL = "minOwnerVoteLevel" ; // default + 1 static final String REPORT_SYNTAX_ERROR = "reportSyntaxError" ; // only for tests // "alwaysShowButton" is obsolete , new UI design always shows the [ Find Owners ] button < |startfocus| > // Name of config parameters that can be defined in project . config or gerrit . confg : < |endfocus| > static final String OWNERS_FILE_NAME = "ownersFileName" ; // config key for file name static final String REJECT_ERROR_IN_OWNERS = "rejectErrorInOwners" ; // enable upload validator static final String OWNERS = "OWNERS" ; // default OWNERS file name // Name of plugin and namespace . static final String PLUGIN_NAME = "find - owners" ; static final String PROLOG_NAMESPACE = "find_owners" ; private final PluginConfigFactory configFactory ; // Each call to API entry point creates one new Config and parses gerrit . config . < |startfocus| > private final ReviewDb reviewDb ; // ReviewDb is used to get the project name . < |endfocus| >
String getOwnersFileName ( Project project ) { String defaultName = getDefaultOwnersFileName ( ) ; try { String name = getProjectConfig ( project ) . getString ( OWNERS_FILE_NAME , defaultName ) ; if ( name . trim ( ) . isEmpty ( ) ) { < |startfocus| > logger . atSevere ( ) . log ( "Project % s has empty % s" , project , OWNERS_FILE_NAME ) ; < |endfocus| > return defaultName ; } return name ; } catch ( NoSuchProjectException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Exception in getOwnersFileName for % s" , project . getName ( ) ) ; return defaultName ; }
* * < p > In addition accounts are included that have the given email as preferred email even if they * have no external ID for the preferred email . Having accounts with a preferred email that does * not exist as external ID is an inconsistency , but existing functionality relies on still * getting those accounts , which is why they are included . Accounts by preferred email are fetched * from the account index as a fallback for email addresses that could not be resolved using < |startfocus| > * { @link ExternalIds } < |endfocus| > . * * @see #getAccountsFor ( String . . . ) */ public ImmutableSet < Account . Id > getAccountFor ( String email ) throws IOException { ImmutableSet < Account . Id > accounts = externalIds . byEmail ( email ) . stream ( ) . map ( ExternalId : : accountId ) . collect ( toImmutableSet ( ) ) ; if ( ! accounts . isEmpty ( ) ) { return accounts ; } return executeIndexQuery ( ( ) - > queryProvider . get ( ) . byPreferredEmail ( email ) . stream ( ) ) . map ( a - > a . getAccount ( ) . id ( ) ) . collect ( toImmutableSet ( ) ) ; } /* *
// limitations under the License . package com . google . gerrit . server . account ; import static com . google . common . collect . ImmutableList . toImmutableList ; import static com . google . common . collect . ImmutableSet . toImmutableSet ; import com . google . common . base . Throwables ; import com . google . common . collect . ImmutableSet ; import com . google . common . collect . ImmutableSetMultimap ; import com . google . common . collect . MultimapBuilder ; import com . google . common . collect . SetMultimap ; import com . google . gerrit . exceptions . StorageException ; import com . google . gerrit . reviewdb . client . Account ; < |startfocus| > import com . google . gerrit . reviewdb . client . Account ; < |endfocus| > import com . google . gerrit . server . account . externalids . ExternalId ; import com . google . gerrit . server . account . externalids . ExternalIds ; import com . google . gerrit . server . query . account . InternalAccountQuery ; import com . google . gerrit . server . update . RetryHelper ; import com . google . gerrit . server . update . RetryHelper . Action ; import com . google . gerrit . server . update . RetryHelper . ActionType ; import com . google . inject . Inject ; import com . google . inject . Provider ; import com . google . inject . Singleton ; import java . io . IOException ; import java . util . Arrays ; import java . util . List ; /* * Class to access accounts by email . */ @Singleton public class Emails { private final ExternalIds externalIds ;
// // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite ; import com . google . gerrit . extensions . common . GitPerson ; public class SharedRefLogEntry { public enum Type { < |startfocus| > UPDATE_REF , < |endfocus| > DELETE_REF , DELETE_PROJECT } public String projectName ; public Type type ; public static class UpdateRef extends SharedRefLogEntry { public String refName ; public String oldId ; public String newId ; public GitPerson committer ; public String comment ; UpdateRef ( String projectName , String refName , String oldId , String newId , GitPerson committer , String comment ) { this . type = Type . UPDATE_REF ; this . projectName = projectName ; this . refName = refName ;
public SharedRefDatabaseWrapper ( < |startfocus| > DynamicItem < SharedRefDatabase > sharedRefDatabase , SharedRefLogger sharedRefLogger ) { this . sharedRefDb = sharedRefDatabase . get ( ) ; this . sharedRefLogger = sharedRefLogger ; < |endfocus| >
public SharedRefDatabaseWrapper ( < |startfocus| > DynamicItem < SharedRefDatabase > sharedRefDatabase , SharedRefLogger sharedRefLogger ) { this . sharedRefDb = sharedRefDatabase ; < |endfocus| > this . sharedRefLogger = sharedRefLogger ;
logger . atFiner ( ) . log ( "Create new OwnersDb , key = % s" , key ) ; return new OwnersDb ( permissionBackend , projectState , accountCache , emails , key , repoManager , config , changeData , branch , files ) ; } try { logger . atFiner ( ) . log ( "Get from cache % s , key = % s , cache size = % d" , dbCache , key , dbCache . size ( ) ) ; < |startfocus| > logger . atFine ( ) . log ( "FindOwnersCacheStats : % s" , dbCache . stats ( ) ) ; < |endfocus| > return dbCache . get ( key , new Callable < OwnersDb > ( ) { @Override public OwnersDb call ( ) { logger . atFiner ( ) . log ( "Create new OwnersDb , key = % s" , key ) ; return new OwnersDb ( permissionBackend , projectState , accountCache , emails , key , repoManager , config , changeData , branch , files ) ; } } ) ; } catch ( ExecutionException e ) { logger . atSevere ( ) . withCause ( e ) . log (
. create ( ) ; update ( rev ) ; ProjectConfig cfg = read ( rev ) ; cfg . getAccountsSection ( ) . setSameGroupVisibility ( ImmutableList . of ( ) ) ; rev = commit ( cfg ) ; assertThat ( text ( rev , "project . config" ) ) . isEqualTo ( " [ commentlink \"bugzilla\" ] \n\tmatch = \" ( bug\\\\s + # ? ) ( \\\\d + ) \"\n\tlink = http :/ / bugs . example . com / show_bug . cgi ? id = $2\n" ) ; } @Test < |startfocus| > public void contributorSectionIsUnsetIfNoPermissionsAreSet ( ) throws Exception { < |endfocus| > RevCommit rev = tr . commit ( ) . add ( "project . config" , " [ commentlink \"bugzilla\" ] \n" + "\tmatch = \" ( bug\\\\s + # ? ) ( \\\\d + ) \"\n" + "\tlink = http :/ / bugs . example . com / show_bug . cgi ? id = $2\n" + " [ contributor - agreement \"Individual\" ] \n" + " accepted = group Developers\n" + " accepted = group Staff\n" ) . create ( ) ; update ( rev ) ; ProjectConfig cfg = read ( rev ) ; ContributorAgreement section = cfg . getContributorAgreement ( "Individual" ) ; section . setAccepted ( ImmutableList . of ( ) ) ; rev = commit ( cfg ) ; assertThat ( text ( rev , "project . config" ) ) . isEqualTo ( " [ commentlink \"bugzilla\" ] \n\tmatch = \" ( bug\\\\s + # ? ) ( \\\\d + ) \"\n\tlink = http :/ / bugs . example . com / show_bug . cgi ? id = $2\n" ) ; } @Test public void contributorSectionIsUnsetIfNoPermissionsAreSet ( ) throws Exception { RevCommit rev = tr . commit ( ) . add ( "project . config" , " [ commentlink \"bugzilla\" ] \n" + "\tmatch = \" ( bug\\\\s + # ? ) ( \\\\d + ) \"\n" + "\tlink = http :/ / bugs . example . com / show_bug . cgi ? id = $2\n" + " [ contributor - agreement \"Individual\" ] \n" + " accepted = group Developers\n" + " accepted = group Staff\n" ) . create ( ) ; update ( rev ) ; ProjectConfig cfg = read ( rev ) ; ContributorAgreement section = cfg . getContributorAgreement ( "Individual" ) ;
. create ( ) ; update ( rev ) ; ProjectConfig cfg = read ( rev ) ; ContributorAgreement section = cfg . getContributorAgreement ( "Individual" ) ; section . setAccepted ( ImmutableList . of ( ) ) ; rev = commit ( cfg ) ; assertThat ( text ( rev , "project . config" ) ) . isEqualTo ( " [ commentlink \"bugzilla\" ] \n\tmatch = \" ( bug\\\\s + # ? ) ( \\\\d + ) \"\n\tlink = http :/ / bugs . example . com / show_bug . cgi ? id = $2\n" ) ; } @Test < |startfocus| > public void notifySectionIsUnsetIfNoPermissionsAreSet ( ) throws Exception { < |endfocus| > RevCommit rev = tr . commit ( ) . add ( "project . config" , " [ commentlink \"bugzilla\" ] \n" + "\tmatch = \" ( bug\\\\s + # ? ) ( \\\\d + ) \"\n" + "\tlink = http :/ / bugs . example . com / show_bug . cgi ? id = $2\n" + " [ notify \"name\" ] \n" + " email = example@example . com\n" ) . create ( ) ; update ( rev ) ; ProjectConfig cfg = read ( rev ) ; cfg . getNotifyConfigs ( ) . clear ( ) ; rev = commit ( cfg ) ; assertThat ( text ( rev , "project . config" ) ) . isEqualTo ( " [ commentlink \"bugzilla\" ] \n\tmatch = \" ( bug\\\\s + # ? ) ( \\\\d + ) \"\n\tlink = http :/ / bugs . example . com / show_bug . cgi ? id = $2\n" ) ; } @Test public void notificationsAreSet ( ) throws Exception { RevCommit rev = tr . commit ( ) . add ( "project . config" , " [ commentlink \"bugzilla\" ] \n" + "\tmatch = \" ( bug\\\\s + # ? ) ( \\\\d + ) \"\n" + "\tlink = http :/ / bugs . example . com / show_bug . cgi ? id = $2\n" + " [ notify \"name\" ] \n" + " email = example@example . com\n" ) . create ( ) ; update ( rev ) ; ProjectConfig cfg = read ( rev ) ; NotifyConfig n = cfg . getNotifyConfig ( "name" ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header" ) , new HeaderValue ( "value" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header2" ) , new HeaderValue ( "value2" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header3" ) , new HeaderValue ( "value3" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header4" ) , new HeaderValue ( "value4" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header5" ) , new HeaderValue ( "value5" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header6" ) , new HeaderValue ( "value6" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header7" ) , new HeaderValue ( "value7" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header8" ) , new HeaderValue ( "value8" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header9" ) , new HeaderValue ( "value9" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header10" ) , new HeaderValue ( "value10" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header11" ) , new HeaderValue ( "value11" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header12" ) , new HeaderValue ( "value12" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header13" ) , new HeaderValue ( "value13" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header14" ) , new HeaderValue ( "value14" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header15" ) , new HeaderValue ( "value15" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header16" ) , new HeaderValue ( "value16" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header17" ) , new HeaderValue ( "value17" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header18" ) , new HeaderValue ( "value18" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header19" ) , new HeaderValue ( "value19" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header20" ) , new HeaderValue ( "value20" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header21" ) , new HeaderValue ( "value21" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header22" ) , new HeaderValue ( "value22" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header23" ) , new HeaderValue ( "value23" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header24" ) , new HeaderValue ( "value24" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header25" ) , new HeaderValue ( "value25" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header26" ) , new HeaderValue ( "value26" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header27" ) , new HeaderValue ( "value27" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header28" ) , new HeaderValue ( "value28" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header29" ) , new HeaderValue ( "value29" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header30" ) , new HeaderValue ( "value30" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header31" ) , new HeaderValue ( "value31" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header32" ) , new HeaderValue ( "value32" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header33" ) , new HeaderValue ( "value33" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header34" ) , new HeaderValue ( "value34" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header35" ) , new HeaderValue ( "value35" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header36" ) , new HeaderValue ( "value36" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header37" ) , new HeaderValue ( "value37" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header38" ) , new HeaderValue ( "value38" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header39" ) , new HeaderValue ( "value39" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header40" ) , new HeaderValue ( "value40" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header41" ) , new HeaderValue ( "value41" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header42" ) , new HeaderValue ( "value42" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header43" ) , new HeaderValue ( "value43" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header44" ) , new HeaderValue ( "value44" ) ) ) ; n . setHeader ( new Header ( new HeaderKey ( "X - Gerrit - Header45" ) , new HeaderValue ( "value45" ) ) ) ; n
+ " email = example@example . com\n" ) . create ( ) ; update ( rev ) ; ProjectConfig cfg = read ( rev ) ; cfg . getNotifyConfigs ( ) . clear ( ) ; rev = commit ( cfg ) ; assertThat ( text ( rev , "project . config" ) ) . isEqualTo ( " [ commentlink \"bugzilla\" ] \n\tmatch = \" ( bug\\\\s + # ? ) ( \\\\d + ) \"\n\tlink = http :/ / bugs . example . com / show_bug . cgi ? id = $2\n" ) ; } @Test < |startfocus| > public void commentLinkSectionIsUnsetIfNoPermissionsAreSet ( ) throws Exception { < |endfocus| > RevCommit rev = tr . commit ( ) . add ( "project . config" , " [ commentlink \"bugzilla\" ] \n" + "\tmatch = \" ( bug\\\\s + # ? ) ( \\\\d + ) \"\n" + "\tlink = http :/ / bugs . example . com / show_bug . cgi ? id = $2\n" + " [ notify \"name\" ] \n" + " email = example@example . com\n" ) . create ( ) ; update ( rev ) ; ProjectConfig cfg = read ( rev ) ; cfg . getCommentLinkSections ( ) . clear ( ) ; rev = commit ( cfg ) ; assertThat ( text ( rev , "project . config" ) ) . isEqualTo ( " [ notify \"name\" ] \n" + " email = example@example . com\n" ) ; } @Test public void commentLinkSectionIsUnsetIfNoPermissionsAreSet ( ) throws Exception { RevCommit rev = tr . commit ( ) . add ( "project . config" , " [ commentlink \"bugzilla\" ] \n" + "\tmatch = \" ( bug\\\\s + # ? ) ( \\\\d + ) \"\n" + "\tlink = http :/ / bugs . example . com / show_bug . cgi ? id = $2\n" + " [ notify \"name\" ] \n" + " email = example@example . com\n" ) . create ( ) ; update ( rev ) ; ProjectConfig cfg = read ( rev ) ; cfg . getCommentLinkSections ( ) . clear ( ) ; rev = commit ( cfg ) ;
@NoHttpd public class NoUnresolvedCommentsRuleIT extends LightweightPluginDaemonTest { private static final String FILENAME = "my . file" ; @Before public void enableRuleBeforeTest ( ) throws Exception { enableRule ( true ) ; } @Test public void blocksWithUnresolvedComments ( ) throws Exception { ReviewInput . CommentInput comment = newFileComment ( ) ; comment . unresolved = true ; PushOneCommit . Result r = createChangeWithComment ( comment ) ; Optional < SubmitRecord > submitRecords = evaluate ( r . getChange ( ) ) ; < |startfocus| > assertThat ( submitRecords ) . isPresent ( ) ; < |endfocus| > SubmitRecord result = submitRecords . get ( ) ; assertThat ( result . status ) . isEqualTo ( SubmitRecord . Status . NOT_READY ) ; assertThat ( result . labels ) . isNull ( ) ; assertThat ( result . requirements ) . hasSize ( 1 ) ; } @Test public void doesNotBlockWithNoComments ( ) throws Exception { ReviewInput . CommentInput comment = newFileComment ( ) ; comment . unresolved = false ; PushOneCommit . Result r = createChangeWithComment ( comment ) ; Optional < SubmitRecord > submitRecords = evaluate ( r . getChange ( ) ) ; assertThat ( submitRecords ) . isPresent ( ) ; SubmitRecord result = submitRecords . get ( ) ;
package com . google . gerrit . server . rules ; import com . google . gerrit . common . data . SubmitRecord ; import com . google . gerrit . extensions . annotations . ExtensionPoint ; import com . google . gerrit . server . query . change . ChangeData ; import java . util . Optional ; /* * * Allows plugins to decide whether a change is ready to be submitted or not . * * < p > For a given { @link ChangeData } , each plugin is called and returns a { @link Optional } of { @link < |startfocus| > * SubmitRecord } . This collection can be empty , or contain one or several values . < |endfocus| > * * < p > A Change can only be submitted if all the plugins give their consent . * * < p > Each { @link SubmitRecord } represents a decision made by the plugin . If the plugin rejects a * change , it should hold valuable informations to help the end user understand and correct the * blocking points . * * < p > It should be noted that each plugin can handle rules inheritance . * * < p > This interface should be used to write pre - submit validation rules . This includes both simple
import java . util . Map ; import java . util . Optional ; import org . eclipse . jgit . internal . storage . dfs . InMemoryRepository ; import org . eclipse . jgit . junit . TestRepository ; import org . junit . Test ; @NoHttpd public class IgnoreSelfApprovalRuleIT extends AbstractDaemonTest { @Inject private IgnoreSelfApprovalRule rule ; @Test public void blocksWhenUploaderIsOnlyApprover ( ) throws Exception { enableRule ( "Code - Review" , true ) ; PushOneCommit . Result r = createChange ( ) ; approve ( r . getChangeId ( ) ) ; < |startfocus| > Optional < SubmitRecord > submitRecord = rule . evaluate ( r . getChange ( ) ) ; < |endfocus| > assertThat ( submitRecord . isPresent ( ) ) . isTrue ( ) ; SubmitRecord result = submitRecord . get ( ) ; assertThat ( result . status ) . isEqualTo ( SubmitRecord . Status . NOT_READY ) ; assertThat ( result . labels ) . isNotEmpty ( ) ; assertThat ( result . requirements ) . containsExactly ( SubmitRequirement . builder ( ) . setFallbackText ( "Approval from non - uploader required" ) . setType ( "non_uploader_approval" ) . build ( ) ) ; } @Test public void allowsSubmissionWhenChangeHasNonUploaderApproval ( ) throws Exception { enableRule ( "Code - Review" , true ) ; // Create change as user
} @Test public void allowsSubmissionWhenChangeHasNonUploaderApproval ( ) throws Exception { enableRule ( "Code - Review" , true ) ; // Create change as user TestRepository < InMemoryRepository > userTestRepo = cloneProject ( project , user ) ; PushOneCommit push = pushFactory . create ( user . newIdent ( ) , userTestRepo ) ; PushOneCommit . Result r = push . to ( "refs / for / master" ) ; // Approve as admin approve ( r . getChangeId ( ) ) ; < |startfocus| > Optional < SubmitRecord > submitRecords = rule . evaluate ( r . getChange ( ) ) ; assertThat ( submitRecords ) . isEmpty ( ) ; < |endfocus| > } @Test public void doesNothingByDefault ( ) throws Exception { enableRule ( "Code - Review" , false ) ; PushOneCommit . Result r = createChange ( ) ; approve ( r . getChangeId ( ) ) ; Optional < SubmitRecord > submitRecords = rule . evaluate ( r . getChange ( ) ) ; assertThat ( submitRecords ) . isEmpty ( ) ; } private void enableRule ( String labelName , boolean newState ) throws Exception { try ( ProjectConfigUpdate u = updateProject ( project ) ) { Map < String , LabelType > localLabelSections = u . getConfig ( ) . getLabelSections ( ) ;
public void convertsPrologToSubmitRecord ( ) { PrologRuleEvaluator evaluator = makeEvaluator ( ) ; StructureTerm verifiedLabel = makeLabel ( "Verified" , "may" ) ; StructureTerm labels = new StructureTerm ( "label" , verifiedLabel ) ; List < Term > terms = ImmutableList . of ( makeTerm ( "ok" , labels ) ) ; Optional < SubmitRecord > record = evaluator . resultsToSubmitRecord ( null , terms ) ; < |startfocus| > assertThat ( record ) . isPresent ( ) ; < |endfocus| >
terms . add ( makeTerm ( "ok" , makeLabels ( label2 ) ) ) ; terms . add ( makeTerm ( "not_ready" , makeLabels ( label3 ) ) ) ; // When Optional < SubmitRecord > record = evaluator . resultsToSubmitRecord ( null , terms ) ; // assert that SubmitRecord expectedRecord = new SubmitRecord ( ) ; expectedRecord . status = SubmitRecord . Status . OK ; expectedRecord . labels = new ArrayList < > ( ) ; expectedRecord . labels . add ( submitRecordLabel2 ) ; expectedRecord . labels . add ( submitRecordLabel3 ) ; < |startfocus| > assertThat ( record ) . isPresent ( ) ; assertThat ( record . get ( ) ) . isEqualTo ( expectedRecord ) ; < |endfocus| >
terms . add ( makeTerm ( "ok" , makeLabels ( label2 ) ) ) ; terms . add ( makeTerm ( "not_ready" , makeLabels ( label3 ) ) ) ; // When Optional < SubmitRecord > record = evaluator . resultsToSubmitRecord ( null , terms ) ; // assert that SubmitRecord expectedRecord = new SubmitRecord ( ) ; expectedRecord . status = SubmitRecord . Status . OK ; expectedRecord . labels = new ArrayList < > ( ) ; expectedRecord . labels . add ( submitRecordLabel2 ) ; expectedRecord . labels . add ( submitRecordLabel3 ) ; < |startfocus| > assertThat ( record ) . hasValue ( expectedRecord ) ; < |endfocus| >
protected void configure ( ) { if ( config . getSharedRefDb ( ) . isEnabled ( ) ) { < |startfocus| > DynamicSet . bind ( binder ( ) , ProjectDeletedListener . class ) . to ( ProjectDeletedSharedDbCleanup . class ) ; < |endfocus| > install ( new ValidationModule ( config ) ) ; } }
protected void configure ( ) { < |startfocus| > < |endfocus| > bind ( SharedRefDatabase . class ) . to ( ZkSharedRefDatabase . class ) ; bind ( CuratorFramework . class ) . toInstance ( cfg . getZookeeperConfig ( ) . buildCurator ( ) ) ; bind ( ZkConnectionConfig . class ) . toInstance ( new ZkConnectionConfig ( cfg . getZookeeperConfig ( ) . buildCasRetryPolicy ( ) , cfg . getZookeeperConfig ( ) . getZkInterProcessLockTimeOut ( ) ) ) ; DynamicSet . bind ( binder ( ) , ProjectDeletedListener . class ) . to ( ProjectDeletedSharedDbCleanup . class ) ;
metadataBuilder . addPluginMetadata ( PluginMetadata . create ( PUBLISHER_SUCCESS_COUNTER , fieldValue ) ) ) . description ( "Broker message published count" ) . build ( ) ) ; this . brokerPublisherFailureCounter = metricMaker . newCounter ( "multi_site / broker / broker_message_publisher_failure_counter" , new Description ( "Number of messages failed to publish by the broker publisher" ) . setRate ( ) . setUnit ( "errors" ) , < |startfocus| > Field . ofString ( PUBLISHER_FAILURE_COUNTER , ( metadataBuilder , fieldValue ) - > metadataBuilder . addPluginMetadata ( PluginMetadata . create ( PUBLISHER_FAILURE_COUNTER , fieldValue ) ) ) < |endfocus| > . description ( "Broker failed to publish message count" ) . build ( ) ) ; this . brokerPublisherFailureCounter = metricMaker . newCounter ( "multi_site / broker / broker_message_publisher_failure_counter" , new Description ( "Number of messages failed to publish by the broker publisher" ) . setRate ( ) . setUnit ( "errors" ) , < |startfocus| > Field . ofString ( PUBLISHER_FAILURE_COUNTER , ( metadataBuilder , fieldValue ) - > metadataBuilder . addPluginMetadata ( PluginMetadata . create ( PUBLISHER_FAILURE_COUNTER , fieldValue ) ) ) < |endfocus| > . description ( "Broker failed to publish message count" ) . build ( ) ) ;
new Description ( "Number of messages failed to publish by the broker publisher" ) . setRate ( ) . setUnit ( "errors" ) , Field . ofString ( PUBLISHER_FAILURE_COUNTER , metadataMapper ( PUBLISHER_FAILURE_COUNTER ) ) . description ( "Broker failed to publish message count" ) . build ( ) ) ; } public void incrementBrokerPublishedMessage ( ) { brokerPublisherSuccessCounter . increment ( PUBLISHER_SUCCESS_COUNTER ) ; } public void incrementBrokerFailedToPublishMessage ( ) { brokerPublisherFailureCounter . increment ( PUBLISHER_FAILURE_COUNTER ) ; } < |startfocus| > private BiConsumer < Metadata . Builder , String > metadataMapper ( String metadataKey ) { return ( metadataBuilder , fieldValue ) - > metadataBuilder . addPluginMetadata ( PluginMetadata . create ( metadataKey , fieldValue ) ) ; } }
"Kafka consumer subscribing to topic [ % s ] for event family [ % s ] " , topic , getEventFamily ( ) ) ; consumer . subscribe ( Collections . singleton ( topic ) ) ; while ( ! closed . get ( ) ) { ConsumerRecords < byte [ ] , byte [ ] > consumerRecords = consumer . poll ( Duration . ofMillis ( configuration . kafkaSubscriber ( ) . getPollingInterval ( ) ) ) ; consumerRecords . forEach ( this : : processRecord ) ; } } catch ( WakeupException e ) { // Ignore exception if closing if ( ! closed . get ( ) ) throw e ; < |startfocus| > } catch ( Exception e ) { < |endfocus| > subscriberMetrics . incrementSubscriberFailedToPollMessages ( ) ; throw e ; } finally { consumer . close ( ) ; }
eventRouter . route ( event . getEventBody ( gson ) ) ; subscriberMetrics . incrementSubscriberConsumedMessage ( ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Malformed event ' % s' : [ Exception : % s ] " , event . getHeader ( ) . getEventType ( ) ) ; subscriberMetrics . incrementSubscriberFailedToConsumeMessage ( ) ; } catch ( PermissionBackendException | OrmException e ) { logger . atSevere ( ) . withCause ( e ) . log ( < |startfocus| > "Cannot handle message % s : [ Exception : % s ] " , event . getHeader ( ) . getEventType ( ) ) ; subscriberMetrics . incrementSubscriberFailedToConsumeMessage ( ) ; < |endfocus| > } } } catch ( Exception e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Malformed event ' % s' : [ Exception : % s ] " , new String ( consumerRecord . value ( ) , UTF_8 ) ) ; subscriberMetrics . incrementSubscriberFailedToConsumeMessage ( ) ; }
public IndexEventSubscriber ( KafkaConfiguration configuration , KafkaConsumerFactory consumerFactory , Deserializer < byte [ ] > keyDeserializer , Deserializer < SourceAwareEventWrapper > valueDeserializer , IndexEventRouter eventRouter , DynamicSet < DroppedEventListener > droppedEventListeners , @BrokerGson Gson gsonProvider , @InstanceId UUID instanceId , OneOffRequestContext oneOffCtx , MessageLogger msgLog , < |startfocus| > SubscriberMetrics subscriberMetrics ) { < |endfocus| > super ( configuration , consumerFactory , keyDeserializer , valueDeserializer , eventRouter , droppedEventListeners , gsonProvider , instanceId , oneOffCtx , msgLog , subscriberMetrics ) ;
public KafkaCacheEvictionEventSubscriber ( KafkaConfiguration configuration , KafkaConsumerFactory consumerFactory , Deserializer < byte [ ] > keyDeserializer , Deserializer < SourceAwareEventWrapper > valueDeserializer , StreamEventRouter eventRouter , DynamicSet < DroppedEventListener > droppedEventListeners , @BrokerGson Gson gsonProvider , @InstanceId UUID instanceId , OneOffRequestContext oneOffCtx , MessageLogger msgLog , < |startfocus| > SubscriberMetrics subscriberMetrics ) { < |endfocus| > super ( configuration , consumerFactory , keyDeserializer , valueDeserializer , eventRouter , droppedEventListeners , gsonProvider , instanceId , oneOffCtx , msgLog , subscriberMetrics ) ;
public ProjectUpdateEventSubscriber ( KafkaConfiguration configuration , KafkaConsumerFactory consumerFactory , Deserializer < byte [ ] > keyDeserializer , Deserializer < SourceAwareEventWrapper > valueDeserializer , ProjectListUpdateRouter eventRouter , DynamicSet < DroppedEventListener > droppedEventListeners , @BrokerGson Gson gson , @InstanceId UUID instanceId , OneOffRequestContext oneOffCtx , MessageLogger msgLog , < |startfocus| > SubscriberMetrics subscriberMetrics ) { < |endfocus| > super ( configuration , consumerFactory , keyDeserializer , valueDeserializer , eventRouter , droppedEventListeners , gson , instanceId , oneOffCtx , msgLog , subscriberMetrics ) ;
public StreamEventSubscriber ( KafkaConfiguration configuration , KafkaConsumerFactory consumerFactory , Deserializer < byte [ ] > keyDeserializer , Deserializer < SourceAwareEventWrapper > valueDeserializer , StreamEventRouter eventRouter , DynamicSet < DroppedEventListener > droppedEventListeners , @BrokerGson Gson gson , @InstanceId UUID instanceId , OneOffRequestContext oneOffCtx , MessageLogger msgLog , < |startfocus| > SubscriberMetrics subscriberMetrics ) { < |endfocus| > super ( configuration , consumerFactory , keyDeserializer , valueDeserializer , eventRouter , droppedEventListeners , gson , instanceId , oneOffCtx , msgLog , subscriberMetrics ) ;
private String replaceInUrl ( String placeholder , String url , < |startfocus| > String replacement , boolean lowerCase ) { < |endfocus| > if ( url == null || replacement == null || ! url . contains ( placeholder ) ) { return url ; } if ( lowerCase ) { replacement = replacement . toLowerCase ( ) ; } // as we can't assume anything of 'replacement' , we're URL encoding it return url . replace ( placeholder , Url . encode ( replacement ) ) ;
// distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . multisite . broker ; import com . googlesource . gerrit . plugins . multisite . forwarder . events . EventFamily ; public interface BrokerSession { boolean isOpen ( ) ; void connect ( ) ; void disconnect ( ) ; < |startfocus| > boolean publishEvent ( EventFamily eventFamily , String payload ) ; boolean publishEventToTopic ( String topic , String payload ) ; < |endfocus| > }
CheckUpdate . Builder builder = CheckUpdate . builder ( ) ; builder . setState ( CheckState . NOT_STARTED ) . unsetFinished ( ) . unsetStarted ( ) . setMessage ( "" ) . setUrl ( "" ) ; Check updatedCheck ; if ( ! check . isPresent ( ) ) { Checker checker = checkers . getChecker ( checkerUuid ) . orElseThrow ( ( ) - > new ResourceNotFoundException ( String . format ( "checker % s not found" , checkerUuid ) ) ) ; < |startfocus| > // Also return a backfilled check for checkers that are do not apply to the change . < |endfocus| > updatedCheck = Check . newBackfilledCheck ( checkResource . getRevisionResource ( ) . getProject ( ) , checkResource . getRevisionResource ( ) . getPatchSet ( ) , checker ) ; } else { updatedCheck = checksUpdate . get ( ) . updateCheck ( key , builder . build ( ) ) ; } return checkJsonFactory . noOptions ( ) . format ( updatedCheck ) ; } }
CheckUpdate . Builder builder = CheckUpdate . builder ( ) ; builder . setState ( CheckState . NOT_STARTED ) . unsetFinished ( ) . unsetStarted ( ) . setMessage ( "" ) . setUrl ( "" ) ; Check updatedCheck ; if ( ! check . isPresent ( ) ) { Checker checker = checkers . getChecker ( checkerUuid ) . orElseThrow ( ( ) - > new ResourceNotFoundException ( String . format ( "checker % s not found" , checkerUuid ) ) ) ; < |startfocus| > // Also return a backfilled check for checkers that do not apply to the change . < |endfocus| > updatedCheck = Check . newBackfilledCheck ( checkResource . getRevisionResource ( ) . getProject ( ) , checkResource . getRevisionResource ( ) . getPatchSet ( ) , checker ) ; } else { updatedCheck = checksUpdate . get ( ) . updateCheck ( key , builder . build ( ) ) ; } return checkJsonFactory . noOptions ( ) . format ( updatedCheck ) ; } }
assertThat ( info . state ) . isEqualTo ( CheckState . NOT_STARTED ) ; assertThat ( info . updated ) . isGreaterThan ( info . created ) ; } @Test public void rerunCheckNotExistingButBackfilled ( ) throws Exception { CheckInfo info = checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( ) ; assertThat ( info . state ) . isEqualTo ( CheckState . NOT_STARTED ) ; } @Test public void rerunExistingCheckWithCheckerNotAppliedToChange ( ) throws Exception { < |startfocus| > Project . NameKey otherProject = projectOperations . newProject ( ) . name ( "other" ) . create ( ) ; < |endfocus| > checkerOperations . checker ( checkKey . checkerUuid ( ) ) . forUpdate ( ) . repository ( otherProject ) . update ( ) ; checkOperations . newCheck ( checkKey ) . upsert ( ) ; CheckInfo info = checksApiFactory . revision ( patchSetId ) . id ( checkKey . checkerUuid ( ) ) . rerun ( ) ; assertThat ( info . state ) . isEqualTo ( CheckState . NOT_STARTED ) ; } @Test public void rerunNonExistingCheckWithCheckerNotAppliedToChange ( ) throws Exception { Project . NameKey otherProject = projectOperations . newProject ( ) . name ( "other" ) . create ( ) ; checkerOperations . checker ( checkKey . checkerUuid ( ) ) . forUpdate ( ) . repository ( otherProject ) . update ( ) ; assertThrows ( ResourceNotFoundException . class ,
// // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 // // Unless required by applicable law or agreed to in writing , software // distributed under the License is distributed on an "AS IS" BASIS , // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . // See the License for the specific language governing permissions and // limitations under the License . package com . googlesource . gerrit . plugins . replication ; import com . google . inject . Inject ; import com . google . inject . Singleton ; import java . util . Optional ; import org . eclipse . jgit . transport . URIish ; < |startfocus| > < |endfocus| > public interface AdminApiFactory { Optional < AdminApi > create ( URIish uri ) ; @Singleton static class DefaultAdminApiFactory implements AdminApiFactory { protected final SshHelper sshHelper ; @Inject public DefaultAdminApiFactory ( SshHelper sshHelper ) { this . sshHelper = sshHelper ; } @Override public Optional < AdminApi > create ( URIish uri ) { if ( isGerrit ( uri ) ) { return Optional . of ( new GerritSshApi ( sshHelper , uri ) ) ; } else if ( ! uri . isRemote ( ) ) { return Optional . of ( new LocalFS ( uri ) ) ; } else { return Optional . empty ( ) ; } } private boolean isGerrit ( URIish uri ) { return uri . getPath ( ) . endsWith ( " / a" ) ; } } }
if ( destRef == null ) { throw new ResourceConflictException ( "can't rebase onto tip of branch " + destRefKey . get ( ) + " ; branch doesn't exist" ) ; } return destRef . getObjectId ( ) ; } Base base = rebaseUtil . parseBase ( rsrc , str ) ; if ( base == null ) { < |startfocus| > throw new ResourceConflictException ( "Base revision is missing from the destination branch : " + str ) ; < |endfocus| > } PatchSet . Id baseId = base . patchSet ( ) . getId ( ) ; if ( change . getId ( ) . equals ( baseId . getParentKey ( ) ) ) { throw new ResourceConflictException ( "Cannot rebase change onto itself" ) ; } permissionBackend . user ( rsrc . getUser ( ) ) . database ( dbProvider ) . change ( base . notes ( ) ) . check ( ChangePermission . READ ) ; Change baseChange = base . notes ( ) . getChange ( ) ; if ( ! baseChange . getProject ( ) . equals ( change . getProject ( ) ) ) { throw new ResourceConflictException ( "Base change is in wrong project : " + baseChange . getProject ( ) ) ; } else if ( ! baseChange . getDest ( ) . equals ( change . getDest ( ) ) ) {
package com . googlesource . gerrit . plugins . multisite . kafka ; import com . google . gerrit . server . events . Event ; import com . google . inject . Inject ; import com . googlesource . gerrit . plugins . multisite . broker . BrokerApi ; import com . googlesource . gerrit . plugins . multisite . broker . kafka . BrokerPublisher ; import com . googlesource . gerrit . plugins . multisite . consumer . SourceAwareEventWrapper ; import com . googlesource . gerrit . plugins . multisite . forwarder . events . EventTopic ; import com . googlesource . gerrit . plugins . multisite . kafka . consumer . KafkaEventSubscriber ; import java . util . function . Consumer ; public class KafkaBrokerApi implements BrokerApi { private final BrokerPublisher publisher ; private final KafkaEventSubscriber subscriber ; @Inject public KafkaBrokerApi ( BrokerPublisher publisher , KafkaEventSubscriber subscriber ) { this . publisher = publisher ; this . subscriber = subscriber ; } @Override public boolean send ( String topic , Event event ) { return publisher . publish ( topic , event ) ; } @Override public void receiveAync ( String topic , Consumer < SourceAwareEventWrapper > eventConsumer ) { subscriber . subscribe ( EventTopic . of ( topic ) , eventConsumer ) ; } }
< |startfocus| > public void receiveAync ( String topic , Consumer < SourceAwareEventWrapper > eventConsumer ) { < |endfocus| > subscriber . subscribe ( EventTopic . of ( topic ) , eventConsumer ) ;
} listener ( ) . to ( Log4jMessageLogger . class ) ; bind ( MessageLogger . class ) . to ( Log4jMessageLogger . class ) ; install ( new ForwarderModule ( ) ) ; if ( config . cache ( ) . synchronize ( ) ) { install ( new CacheModule ( ) ) ; } if ( config . event ( ) . synchronize ( ) ) { install ( new EventModule ( ) ) ; } if ( config . index ( ) . synchronize ( ) ) { install ( new IndexModule ( ) ) ; } install ( new BrokerModule ( ) ) ; DynamicItem . bind ( binder ( ) , BrokerApi . class ) . to ( KafkaBrokerApi . class ) ; < |startfocus| > install ( kafkaForwardedEventRouterModule ) ; < |endfocus| > install ( kafkaBrokerForwarderModule ) ; install ( new ValidationModule ( config , disableGitRepositoryValidation || ! config . getSharedRefDb ( ) . isEnabled ( ) ) ) ; bind ( Gson . class ) . annotatedWith ( BrokerGson . class ) . toProvider ( GsonProvider . class ) . in ( SINGLETON . class ) ;
< |startfocus| > public void receiveAsync ( String topic , Consumer < SourceAwareEventWrapper > eventConsumer ) { apiDelegate . get ( ) . receiveAsync ( topic , eventConsumer ) ; } < |endfocus| >
public void receiveAync ( String topic , Consumer < SourceAwareEventWrapper > eventConsumer ) { KafkaEventSubscriber subscriber = subscriberProvider . get ( ) ; < |startfocus| > synchronized ( subscribers ) { subscribers . add ( subscriber ) ; } < |endfocus| > subscriber . subscribe ( EventTopic . of ( topic ) , eventConsumer ) ;
import com . google . gerrit . reviewdb . client . Account ; import com . google . gerrit . reviewdb . server . ReviewDb ; import com . google . gerrit . server . CurrentUser ; import com . google . gerrit . server . config . SitePaths ; import com . google . gerrit . server . util . ManualRequestContext ; import com . google . gerrit . server . util . OneOffRequestContext ; import com . google . gerrit . server . util . RequestContext ; import com . google . gerrit . testing . ConfigSuite ; import com . google . inject . Injector ; import com . google . inject . Module ; import com . google . inject . Provider ; import java . io . File ; import java . io . IOException ; import java . util . Arrays ; import java . util . Collections ; import org . eclipse . jgit . errors . ConfigInvalidException ; import org . eclipse . jgit . lib . Config ; import org . eclipse . jgit . lib . StoredConfig ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . eclipse . jgit . util . FS ; import org . eclipse . jgit . util . SystemReader ; import org . junit . Rule ; import org . junit . rules . RuleChain ; import org . junit . rules . TemporaryFolder ; import org . junit . rules . TestRule ; import org . junit . runner . Description ; import org . junit . runner . RunWith ; import org . junit . runners . model . Statement ; @RunWith ( ConfigSuite . class ) @UseLocalDisk public abstract class StandaloneSiteTest {
return new FileBasedConfig ( parent , new File ( tempDir , "user . config" ) , FS . detect ( ) ) ; } @Override public FileBasedConfig openSystemConfig ( Config parent , FS fs ) { return new FileBasedConfig ( parent , new File ( tempDir , "system . config" ) , FS . detect ( ) ) ; } @Override public long getCurrentTime ( ) { return oldSystemReader . getCurrentTime ( ) ; } @Override public int getTimezone ( long when ) { return oldSystemReader . getTimezone ( when ) ; } < |startfocus| > @Override public StoredConfig getUserConfig ( ) throws IOException , ConfigInvalidException { return oldSystemReader . getUserConfig ( ) ; } < |endfocus| > @Override public StoredConfig getSystemConfig ( ) throws IOException , ConfigInvalidException { return oldSystemReader . getSystemConfig ( ) ; }
private final Map < URIish , PushOne > pending = new HashMap < > ( ) ; private final Map < URIish , PushOne > inFlight = new HashMap < > ( ) ; private final PushOne . Factory opFactory ; private final GitRepositoryManager gitManager ; private final PermissionBackend permissionBackend ; private final Provider < CurrentUser > userProvider ; private final ProjectCache projectCache ; private volatile ScheduledExecutorService pool ; private final PerThreadRequestScope . Scoper threadScoper ; private final DestinationConfiguration config ; private final DynamicItem < EventDispatcher > eventDispatcher ; < |startfocus| > private final ReplicationTasksStorage replicationTaskStorage ; < |endfocus| > protected enum RetryReason { TRANSPORT_ERROR , COLLISION , REPOSITORY_MISSING ; } public static class QueueInfo { public final Map < URIish , PushOne > pending ; public final Map < URIish , PushOne > inFlight ; public QueueInfo ( Map < URIish , PushOne > pending , Map < URIish , PushOne > inFlight ) { this . pending = ImmutableMap . copyOf ( pending ) ; this . inFlight = ImmutableMap . copyOf ( inFlight ) ; } } @Inject protected Destination ( Injector injector , PluginUser pluginUser , GitRepositoryManager gitRepositoryManager , PermissionBackend permissionBackend ,
protected Destination ( Injector injector , PluginUser pluginUser , GitRepositoryManager gitRepositoryManager , PermissionBackend permissionBackend , Provider < CurrentUser > userProvider , ProjectCache projectCache , GroupBackend groupBackend , ReplicationStateListeners stateLog , GroupIncludeCache groupIncludeCache , DynamicItem < EventDispatcher > eventDispatcher , < |startfocus| > ReplicationTasksStorage rts , < |endfocus| > @Assisted DestinationConfiguration cfg ) { this . eventDispatcher = eventDispatcher ; gitManager = gitRepositoryManager ; this . permissionBackend = permissionBackend ; this . userProvider = userProvider ; this . projectCache = projectCache ; this . stateLog = stateLog ; this . eventsStorage = rts ; config = cfg ; CurrentUser remoteUser ; if ( ! cfg . getAuthGroupNames ( ) . isEmpty ( ) ) { ImmutableSet . Builder < AccountGroup . UUID > builder = ImmutableSet . builder ( ) ; for ( String name : cfg . getAuthGroupNames ( ) ) { GroupReference g = GroupBackends . findExactSuggestion ( groupBackend , name ) ; if ( g != null ) { builder . add ( g . getUUID ( ) ) ; addRecursiveParents ( g . getUUID ( ) , builder , groupIncludeCache ) ; } else {
return ; } } } synchronized ( stateLock ) { PushOne e = getPendingPush ( uri ) ; if ( e == null ) { e = opFactory . create ( project , uri ) ; addRef ( e , ref ) ; e . addState ( ref , state ) ; @SuppressWarnings ( "unused" ) ScheduledFuture < ? > ignored = pool . schedule ( e , now ? 0 : config . getDelay ( ) , TimeUnit . SECONDS ) ; pending . put ( uri , e ) ; < |startfocus| > eventsStorage . persist ( e ) ; < |endfocus| > } else if ( ! e . getRefs ( ) . contains ( ref ) ) { addRef ( e , ref ) ; e . addState ( ref , state ) ; } state . increasePushTaskCount ( project . get ( ) , ref ) ; repLog . info ( "scheduled { } : { } = > { } to run after { } s" , project , ref , e , config . getDelay ( ) ) ; }
void notifyFinished ( PushOne op ) { synchronized ( stateLock ) { inFlight . remove ( op . getURI ( ) ) ; if ( ! op . wasCanceled ( ) ) { for ( String ref : op . getRefs ( ) ) { if ( ! refHasPendingPush ( op . getURI ( ) , ref ) ) { < |startfocus| > eventsStorage . delete ( < |endfocus| > op . getProjectNameKey ( ) . get ( ) , ref , op . getURI ( ) , getRemoteConfigName ( ) ) ; } } } } }
String key = "$ { name } " ; int n = in . indexOf ( key ) ; if ( 0 <= n ) { return in . substring ( 0 , n ) + name + in . substring ( n + key . length ( ) ) ; } if ( keyIsOptional ) { return in ; } return null ; } private final WorkQueue workQueue ; private final DynamicItem < EventDispatcher > dispatcher ; private final ReplicationConfig config ; private final AdminApiFactory adminApiFactory ; private final ReplicationState . Factory replicationStateFactory ; < |startfocus| > private final ReplicationTasksStorage taskStorage ; < |endfocus| > private volatile boolean running ; private volatile boolean replaying ; @Inject ReplicationQueue ( WorkQueue wq , AdminApiFactory aaf , ReplicationConfig rc , DynamicItem < EventDispatcher > dis , ReplicationStateListeners sl , ReplicationState . Factory rsf , ReplicationTasksStorage es ) { workQueue = wq ; dispatcher = dis ; config = rc ; stateLog = sl ; adminApiFactory = aaf ; replicationStateFactory = rsf ; taskStorage = es ; } @Override public void start ( ) { if ( ! running ) { config . startup ( workQueue ) ;
return in ; } return null ; } private final WorkQueue workQueue ; private final DynamicItem < EventDispatcher > dispatcher ; private final ReplicationConfig config ; private final AdminApiFactory adminApiFactory ; private final ReplicationState . Factory replicationStateFactory ; private final ReplicationTasksStorage eventsStorage ; private volatile boolean running ; private volatile boolean replaying ; @Inject ReplicationQueue ( WorkQueue wq , AdminApiFactory aaf , ReplicationConfig rc , DynamicItem < EventDispatcher > dis , ReplicationStateListeners sl , ReplicationState . Factory rsf , < |startfocus| > ReplicationTasksStorage es ) { < |endfocus| > workQueue = wq ; dispatcher = dis ; config = rc ; stateLog = sl ; adminApiFactory = aaf ; replicationStateFactory = rsf ; eventsStorage = es ; } @Override public void start ( ) { if ( ! running ) { config . startup ( workQueue ) ; running = true ; firePendingEvents ( ) ; } } @Override public void stop ( ) { running = false ; int discarded = config . shutdown ( ) ; if ( discarded > 0 ) {
private void firePendingEvents ( ) { try { < |startfocus| > Set < String > tasksReplayed = new HashSet < > ( ) ; < |endfocus| > replaying = true ; for ( ReplicationTasksStorage . ReplicateRefUpdate e : eventsStorage . list ( ) ) { String eventKey = String . format ( " % s : % s" , e . project , e . ref ) ; if ( ! tasksReplayed . contains ( eventKey ) ) { repLog . info ( "Firing pending event { } " , eventKey ) ; onGitReferenceUpdated ( e . project , e . ref ) ; tasksReplayed . add ( eventKey ) ; } } } finally { replaying = false ; }
&& head . isSymbolic ( ) && RefNames . REFS_CONFIG . equals ( head . getLeaf ( ) . getName ( ) ) ) { return ; } } catch ( IOException err ) { stateLog . error ( String . format ( "cannot check type of project % s" , project ) , err , state ) ; return ; } } catch ( IOException err ) { stateLog . error ( String . format ( "source project % s not available" , project ) , err , state ) ; return ; } } } synchronized ( stateLock ) { < |startfocus| > PushOne t = getPendingPush ( uri ) ; if ( t == null ) { t = opFactory . create ( project , uri ) ; addRef ( t , ref ) ; t . addState ( ref , state ) ; < |endfocus| > @SuppressWarnings ( "unused" ) ScheduledFuture < ? > ignored = pool . schedule ( t , now ? 0 : config . getDelay ( ) , TimeUnit . SECONDS ) ; pending . put ( uri , t ) ; replicationTasksStorage . persist ( project . get ( ) , ref , t . getURI ( ) , getRemoteConfigName ( ) ) ; } else if ( ! t . getRefs ( ) . contains ( ref ) ) { addRef ( t , ref ) ; t . addState ( ref , state ) ; }
< |startfocus| > void notifyFinished ( PushOne op ) { < |endfocus| > synchronized ( stateLock ) { inFlight . remove ( op . getURI ( ) ) ; if ( ! op . wasCanceled ( ) ) { for ( String ref : op . getRefs ( ) ) { if ( ! refHasPendingPush ( op . getURI ( ) , ref ) ) { replicationTasksStorage . delete ( op . getProjectNameKey ( ) . get ( ) , ref , op . getURI ( ) , getRemoteConfigName ( ) ) ; } } } } }
public void delete ( String project , String ref , URIish uri , String remote ) { ReplicateRefUpdate r = new ReplicateRefUpdate ( ) ; r . project = project ; r . ref = ref ; r . uri = uri . toASCIIString ( ) ; r . remote = remote ; < |startfocus| > String taskJson = GSON . toJson ( r ) + "\n" ; String taskKey = sha1 ( taskJson ) . name ( ) ; < |endfocus| > try { logger . atFiner ( ) . log ( "DELETE % s : % s = > % s" , project , ref , uri ) ; Files . delete ( refUpdates ( ) . resolve ( taskKey ) ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Error while deleting event % s" , taskKey ) ; }
public void delete ( String project , String ref , URIish uri , String remote ) { ReplicateRefUpdate r = new ReplicateRefUpdate ( ) ; r . project = project ; r . ref = ref ; r . uri = uri . toASCIIString ( ) ; r . remote = remote ; < |startfocus| > String eventJson = GSON . toJson ( r ) + "\n" ; String taskKey = sha1 ( eventJson ) . name ( ) ; < |endfocus| > try { logger . atFiner ( ) . log ( "DELETE % s : % s = > % s" , project , ref , uri ) ; Files . delete ( refUpdates ( ) . resolve ( taskKey ) ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Error while deleting event % s" , taskKey ) ; }
if ( ! running ) { stateLog . warn ( "Replication plugin did not finish startup before event" , state ) ; return ; } Project . NameKey project = new Project . NameKey ( projectName ) ; for ( Destination cfg : config . getDestinations ( FilterType . ALL ) ) { if ( cfg . wouldPushProject ( project ) && cfg . wouldPushRef ( refName ) ) { for ( URIish uri : cfg . getURIs ( project , null ) ) { < |startfocus| > cfg . schedule ( project , refName , uri , state ) ; < |endfocus| > } } } state . markAllPushTasksScheduled ( ) ;
< |startfocus| > private void firePendingEvents ( ) { < |endfocus| > try { Set < String > tasksReplayed = new HashSet < > ( ) ; replaying = true ; for ( ReplicationTasksStorage . ReplicateRefUpdate t : replicationTasksStorage . list ( ) ) { String taskKey = String . format ( " % s : % s" , t . project , t . ref ) ; if ( ! tasksReplayed . contains ( taskKey ) ) { repLog . info ( "Firing pending task { } " , taskKey ) ; onGitReferenceUpdated ( t . project , t . ref ) ; tasksReplayed . add ( taskKey ) ; } } } finally { replaying = false ; } }
private void firePendingEvents ( ) { try { Set < String > tasksReplayed = new HashSet < > ( ) ; replaying = true ; for ( ReplicationTasksStorage . ReplicateRefUpdate t : replicationTasksStorage . list ( ) ) { < |startfocus| > String taskKey = String . format ( " % s : % s" , t . project , t . ref ) ; if ( ! tasksReplayed . contains ( taskKey ) ) { repLog . info ( "Firing pending task { } " , taskKey ) ; onGitReferenceUpdated ( t . project , t . ref ) ; tasksReplayed . add ( taskKey ) ; } } } finally { replaying = false ; }
< |startfocus| > public String persist ( ReplicateRefUpdate r ) { < |endfocus| > String json = GSON . toJson ( r ) + "\n" ; String eventKey = sha1 ( json ) . name ( ) ; Path file = refUpdates ( ) . resolve ( eventKey ) ; if ( Files . exists ( file ) ) { return eventKey ; } try { logger . atFine ( ) . log ( "CREATE % s : % s = > % s" , project , ref , uri ) ; Files . write ( file , json . getBytes ( UTF_8 ) ) ; } catch ( IOException e ) { logger . atWarning ( ) . log ( "Couldn't persist event % s" , json , e ) ; } return eventKey ;
String json = GSON . toJson ( r ) + "\n" ; String eventKey = sha1 ( json ) . name ( ) ; Path file = refUpdates ( ) . resolve ( eventKey ) ; if ( Files . exists ( file ) ) { return eventKey ; } try { logger . atFine ( ) . log ( "CREATE % s : % s = > % s" , project , ref , uri ) ; Files . write ( file , json . getBytes ( UTF_8 ) ) ; } catch ( IOException e ) { < |startfocus| > logger . atWarning ( ) . withCause ( e ) . log ( "Couldn't persist event % s" , json ) ; < |endfocus| > } return eventKey ;
public List < ReplicateRefUpdate > list ( ) { ArrayList < ReplicateRefUpdate > result = new ArrayList < > ( ) ; try ( DirectoryStream < Path > events = Files . newDirectoryStream ( refUpdates ( ) ) ) { for ( Path e : events ) { if ( Files . isRegularFile ( e ) ) { String json = new String ( Files . readAllBytes ( e ) , UTF_8 ) ; result . add ( GSON . fromJson ( json , ReplicateRefUpdate . class ) ) ; } } } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Error when firing pending events" ) ; } return result ;
import org . eclipse . jgit . lib . Repository ; import org . eclipse . jgit . revwalk . RevCommit ; import org . eclipse . jgit . storage . file . FileBasedConfig ; import org . eclipse . jgit . util . FS ; import org . junit . Test ; @UseLocalDisk @TestPlugin ( name = "replication" , sysModule = "com . googlesource . gerrit . plugins . replication . ReplicationModule" ) public class ReplicationIT extends LightweightPluginDaemonTest { private static final int TEST_REPLICATION_DELAY = 2 ; private static final Duration TEST_TIMEMOUT = Duration . ofSeconds ( TEST_REPLICATION_DELAY * 10 ) ; @Inject private SitePaths sitePaths ; < |startfocus| > private Path pluginDataDir ; < |endfocus| > private Path gitPath ; private Path storagePath ; private FileBasedConfig config ; @Override public void setUpTestPlugin ( ) throws Exception { config = new FileBasedConfig ( sitePaths . etc_dir . resolve ( "replication . config" ) . toFile ( ) , FS . DETECTED ) ; config . save ( ) ; gitPath = sitePaths . site_path . resolve ( "git" ) ; super . setUpTestPlugin ( ) ; pluginDataDir = plugin . getSysInjector ( ) . getInstance ( Key . get ( Path . class , PluginData . class ) ) ; storagePath = pluginDataDir . resolve ( "ref - updates" ) ; } @Test
e . printStackTrace ( ) ; return null ; } } private void setReplicationDestination ( String remoteName , String replicaSuffix , int replicationDelay ) throws IOException { setReplicationDestination ( remoteName , Arrays . asList ( replicaSuffix ) , replicationDelay ) ; } private void setReplicationDestination ( String remoteName , List < String > replicaSuffixes , int replicationDelay ) throws IOException { List < String > replicaUrls = replicaSuffixes . stream ( ) . map ( suffix - > gitPath . resolve ( "$ { name } " + suffix + " . git" ) . toString ( ) ) < |startfocus| > . collect ( toList ( ) ) ; < |endfocus| > config . setStringList ( "remote" , remoteName , "url" , replicaUrls ) ; config . setInt ( "remote" , remoteName , "replicationDelay" , replicationDelay ) ; config . save ( ) ; reloadConfig ( ) ; } private void waitUntil ( Supplier < Boolean > waitCondition ) throws InterruptedException { Stopwatch stopwatch = Stopwatch . createStarted ( ) ; while ( ! waitCondition . get ( ) && stopwatch . elapsed ( ) . compareTo ( TEST_TIMEMOUT ) < 0 ) { TimeUnit . SECONDS . sleep ( 1 ) ; } } private void reloadConfig ( ) { plugin . getSysInjector ( ) . getInstance ( AutoReloadConfigDecorator . class ) . forceReload ( ) ; } }
private static class RefReplicationStatus { private final String project ; private final String ref ; private int nodesToReplicateCount ; private int replicatedNodesCount ; RefReplicationStatus ( String project , String ref ) { this . project = project ; this . ref = ref ; } public boolean allDone ( ) { return replicatedNodesCount == nodesToReplicateCount ; } } private final Table < String , String , RefReplicationStatus > statusByProjectRef ; private int totalPushTasksCount ; private int finishedPushTasksCount ; < |startfocus| > @AssistedInject ReplicationState ( @Assisted PushResultProcessing processing ) { < |endfocus| > pushResultProcessing = processing ; statusByProjectRef = HashBasedTable . create ( ) ; } public void increasePushTaskCount ( String project , String ref ) { countingLock . lock ( ) ; try { getRefStatus ( project , ref ) . nodesToReplicateCount ++ ; totalPushTasksCount ++ ; } finally { countingLock . unlock ( ) ; } } public boolean hasPushTask ( ) { return totalPushTasksCount != 0 ; } public void notifyRefReplicated ( String project , String ref , URIish uri , RefPushResult status , String message ) { countingLock . lock ( ) ; try { RefReplicationStatus refStatus = getRefStatus ( project , ref ) ; refStatus . replicatedNodesCount ++ ; finishedPushTasksCount ++ ; pushResultProcessing . process ( project , ref , uri , status , message ) ; } finally { countingLock . unlock ( ) ; } } public boolean allDone ( ) { return finishedPushTasksCount == totalPushTasksCount ; } private RefReplicationStatus getRefStatus ( String project , String ref ) { RefReplicationStatus refStatus = statusByProjectRef . get ( project , ref ) ; if ( refStatus == null ) { refStatus = new RefReplicationStatus ( project , ref ) ; statusByProjectRef . put ( project , ref , refStatus ) ; } return refStatus ; } }
super ( retryHelper ) ; this . opFactory = opFactory ; this . editUtil = editUtil ; } @Override protected Response < Object > applyImpl ( BatchUpdate . Factory updateFactory , ChangeResource rsrc , Input input ) throws RestApiException , UpdateException , PermissionBackendException , IOException { if ( ! isChangeDeletable ( rsrc ) ) { throw new MethodNotAllowedException ( "delete not permitted" ) ; } rsrc . permissions ( ) . check ( ChangePermission . DELETE ) ; < |startfocus| > try ( BatchUpdate bu = updateFactory . create ( rsrc . getProject ( ) , rsrc . getUser ( ) , TimeUtil . nowTs ( ) ) ) { Change . Id id = rsrc . getChange ( ) . getId ( ) ; bu . addOp ( id , opFactory . create ( id ) ) ; bu . addOp ( id , new BatchUpdateOp ( ) { @Override public boolean updateChange ( ChangeContext ctx ) throws Exception { editUtil . deleteChangeEdits ( ctx . getChange ( ) . getId ( ) ) ; return true ; } } ) ; bu . execute ( ) ; } < |endfocus| > return Response . none ( ) ; } @Override
< |startfocus| > public Optional < Change > getUpdatedChange ( ) { return Optional . ofNullable ( updatedChange ) ; < |endfocus| >
Project . NameKey key = new Project . NameKey ( projectName ) ; // Remove from the jgit cache cleanCache ( key ) ; FileUtils . deleteDirectory ( gitDirectory ) ; projectCache . remove ( key ) ; sendProjectDeletedEvent ( projectName ) ; return true ; } catch ( IOException e ) { LOG . error ( "Cannot clean - up output Git directory " + gitDirectory ) ; return false ; } } private void cleanCache ( Project . NameKey key ) throws IOException { < |startfocus| > Repository repository = repoManager . openRepository ( key ) ; try { repository . close ( ) ; } finally { RepositoryCache . close ( repository ) ; } < |endfocus| > } private void sendProjectDeletedEvent ( String projectName ) { ProjectDeletedListener . Event event = new ProjectDeletedListener . Event ( ) { @Override public String getProjectName ( ) { return projectName ; } @Override public NotifyHandling getNotify ( ) { return NotifyHandling . NONE ; } } ; for ( ProjectDeletedListener l : deletedListeners ) { try { l . onProjectDeleted ( event ) ; } catch ( RuntimeException e ) { LOG . warn ( "Failure in ProjectDeletedListener" , e ) ; } } } }
public boolean rollback ( ) { File gitDirectory = destinationDirectory ; if ( ! gitDirectory . exists ( ) ) { return false ; } try { String projectName = organisation + " / " + repository ; Project . NameKey key = new Project . NameKey ( projectName ) ; < |startfocus| > cleanJGitCache ( key ) ; < |endfocus| > FileUtils . deleteDirectory ( gitDirectory ) ; projectCache . remove ( key ) ; sendProjectDeletedEvent ( projectName ) ; return true ; } catch ( IOException e ) { LOG . error ( "Cannot clean - up output Git directory " + gitDirectory ) ; return false ; }
this . currentConfig = loadConfig ( ) ; this . currentConfigTs = getLastModified ( currentConfig ) ; this . replicationQueue = replicationQueue ; } private static long getLastModified ( ReplicationFileBasedConfig cfg ) { return FileUtil . lastModified ( cfg . getCfgPath ( ) ) ; } private ReplicationFileBasedConfig loadConfig ( ) throws ConfigInvalidException , IOException { return new ReplicationFileBasedConfig ( site , destinationFactory , pluginDataDir ) ; } private synchronized boolean isAutoReload ( ) { < |startfocus| > boolean autoReload = currentConfig . getConfig ( ) . getBoolean ( "gerrit" , "autoReload" , false ) ; return autoReload ; < |endfocus| > } @Override public synchronized List < Destination > getDestinations ( FilterType filterType ) { reloadIfNeeded ( ) ; return currentConfig . getDestinations ( filterType ) ; } private void reloadIfNeeded ( ) { reload ( false ) ; } @VisibleForTesting public void forceReload ( ) { reload ( true ) ; } private void reload ( boolean force ) { if ( force || isAutoReload ( ) ) { ReplicationQueue queue = replicationQueue . get ( ) ; long lastModified = getLastModified ( currentConfig ) ; try { if ( force || ( lastModified > currentConfigTs )
public void configureServlets ( ) { for ( String p : POLYGERRIT_INDEX_PATHS ) { // Skip XsrfCookieFilter for / , since that is already done in the GWT UI // path ( UrlModule ) if it is enabled . < |startfocus| > if ( ! p . equals ( " / " ) || ! options . enableGwtUi ( ) ) { < |endfocus| > filter ( p ) . through ( XsrfCookieFilter . class ) ; } } filter ( " /* " ) . through ( PolyGerritFilter . class ) ;
< |startfocus| > public ReplicateRefUpdate ( String project , String ref , URIish uri , String remote ) { this . project = project ; this . ref = ref ; this . uri = uri . toASCIIString ( ) ; this . remote = remote ;
public String persist ( ReplicateRefUpdate r ) { String json = GSON . toJson ( r ) + "\n" ; String eventKey = sha1 ( json ) . name ( ) ; < |startfocus| > Path path = refUpdates ( ) . resolve ( eventKey ) ; < |endfocus| > if ( Files . exists ( path ) ) { return eventKey ; } try { logger . atFine ( ) . log ( "CREATE % s ( % s ) " , path , r ) ; Files . write ( path , json . getBytes ( UTF_8 ) ) ; } catch ( IOException e ) { logger . atWarning ( ) . withCause ( e ) . log ( "Couldn't persist event % s" , json ) ; } return eventKey ; }
public String persist ( ReplicateRefUpdate r ) { String json = GSON . toJson ( r ) + "\n" ; String eventKey = sha1 ( json ) . name ( ) ; Path path = refUpdates ( ) . resolve ( eventKey ) ; if ( Files . exists ( path ) ) { return eventKey ; } try { < |startfocus| > logger . atFine ( ) . log ( "CREATE % s ( % s ) " , path , json ) ; Files . write ( path , json . getBytes ( UTF_8 ) ) ; < |endfocus| > } catch ( IOException e ) { logger . atWarning ( ) . withCause ( e ) . log ( "Couldn't persist event % s" , json ) ; } return eventKey ;
public void delete ( ReplicateRefUpdate r ) { String taskJson = GSON . toJson ( r ) + "\n" ; String taskKey = sha1 ( taskJson ) . name ( ) ; < |startfocus| > Path file = refUpdates ( ) . resolve ( taskKey ) ; < |endfocus| > try { logger . atFine ( ) . log ( "DELETE % s ( % s ) " , file , r ) ; Files . delete ( refUpdates ( ) . resolve ( taskKey ) ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Error while deleting event % s" , taskKey ) ; }
public void delete ( ReplicateRefUpdate r ) { String taskJson = GSON . toJson ( r ) + "\n" ; String taskKey = sha1 ( taskJson ) . name ( ) ; < |startfocus| > Path path = refUpdates ( ) . resolve ( taskKey ) ; < |endfocus| > try { logger . atFine ( ) . log ( "DELETE % s ( % s ) " , path , r ) ; Files . delete ( refUpdates ( ) . resolve ( taskKey ) ) ; } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Error while deleting event % s" , taskKey ) ; }
public void delete ( ReplicateRefUpdate r ) { String taskJson = GSON . toJson ( r ) + "\n" ; String taskKey = sha1 ( taskJson ) . name ( ) ; Path path = refUpdates ( ) . resolve ( taskKey ) ; try { < |startfocus| > logger . atFine ( ) . log ( "DELETE % s ( % s ) " , path , r ) ; Files . delete ( path ) ; < |endfocus| > } catch ( IOException e ) { logger . atSevere ( ) . withCause ( e ) . log ( "Error while deleting event % s" , taskKey ) ; }
import static com . google . gerrit . gpg . testutil . TestKeys . validKeyWithExpiration ; import static com . google . gerrit . gpg . testutil . TestKeys . validKeyWithSecondUserId ; import static com . google . gerrit . gpg . testutil . TestKeys . validKeyWithoutExpiration ; import static com . google . gerrit . server . StarredChangesUtil . DEFAULT_LABEL ; import static com . google . gerrit . server . StarredChangesUtil . IGNORE_LABEL ; import static com . google . gerrit . server . account . externalids . ExternalId . SCHEME_GPGKEY ; import static com . google . gerrit . server . group . SystemGroupBackend . ANONYMOUS_USERS ; < |startfocus| > import static com . google . gerrit . server . group . SystemGroupBackend . REGISTERED_USERS ; < |endfocus| > import static java . nio . charset . StandardCharsets . UTF_8 ; import static java . util . stream . Collectors . toList ; import static java . util . stream . Collectors . toSet ; import static org . eclipse . jgit . lib . Constants . OBJ_BLOB ; import static org . junit . Assert . fail ; import com . google . common . collect . FluentIterable ; import com . google . common . collect . ImmutableList ; import com . google . common . collect . ImmutableMap ; import com . google . common . collect . ImmutableSet ; import com . google . common . collect . ImmutableSetMultimap ; import com . google . common . collect . Iterables ; import com . google . common . io . BaseEncoding ; import com . google . common . util . concurrent . AtomicLongMap ; import com . google . gerrit . acceptance . AbstractDaemonTest ; import static com . google . gerrit . gpg . testutil . TestKeys . validKeyWithExpiration ; import static com . google . gerrit . gpg . testutil . TestKeys . validKeyWithSecondUserId ; import static com . google . gerrit . gpg . testutil . TestKeys . validKeyWithoutExpiration ; import static com . google . gerrit . server . StarredChangesUtil . DEFAULT_LABEL ; import static com . google . gerrit . server . StarredChangesUtil . IGNORE_LABEL ; import static com . google . gerrit . server . account . externalids . ExternalId . SCHEME_GPGKEY ; import static com . google . gerrit . server . group . SystemGroupBackend . ANONYMOUS_USERS ; < |startfocus| > import static com . google . gerrit . server . group . SystemGroupBackend . REGISTERED_USERS ; < |endfocus| > import static java . nio . charset . StandardCharsets . UTF_8 ; import static java . util . stream . Collectors . toList ; import static java . util . stream . Collectors . toSet ; import static org . eclipse . jgit . lib . Constants . OBJ_BLOB ; import static org . junit . Assert . fail ; import com . google . common . collect . FluentIterable ; import com . google . common . collect . ImmutableList ; import com . google . common . collect . ImmutableMap ; import com . google . common . collect . ImmutableSet ; import com . google . common . collect . ImmutableSetMultimap ; import com . google . common . collect . Iterables ; import com . google . common . io . BaseEncoding ; import com . google . common . util . concurrent . AtomicLongMap ; import com . google . gerrit . acceptance . AbstractDaemonTest ;
} return fileConfig ; } ) ; } return ofInstance ( config ) ; } public static class Kafka { private final Map < EventTopic , String > eventTopics ; private final String bootstrapServers ; Kafka ( Supplier < Config > config ) { this . bootstrapServers = getString ( config , KAFKA_SECTION , null , "bootstrapServers" , DEFAULT_KAFKA_BOOTSTRAP_SERVERS ) ; this . eventTopics = new HashMap < > ( ) ; for ( EventTopic eventTopic : EventTopic . values ( ) ) { < |startfocus| > eventTopics . put ( eventTopic , getString ( config , KAFKA_SECTION , null , eventTopic . topicAliasKey ( ) , eventTopic . topic ( ) ) ) ; < |endfocus| > } } public String getTopicAlias ( EventTopic topic ) { return eventTopics . get ( topic ) ; } public String getBootstrapServers ( ) { return bootstrapServers ; } private static String getString ( Supplier < Config > cfg , String section , String subsection , String name , String defaultValue ) { String value = cfg . get ( ) . getString ( section , subsection , name ) ; if ( ! Strings . isNullOrEmpty ( value ) ) { return value ; }
reloadConfig ( ) ; waitForEmptyTasks ( ) ; Project . NameKey targetProject = createProject ( "projectreplica" ) ; String newBranch = "refs / heads / mybranch" ; String master = "refs / heads / master" ; BranchInput input = new BranchInput ( ) ; input . revision = master ; gApi . projects ( ) . name ( project . get ( ) ) . branch ( newBranch ) . create ( input ) ; assertThat ( listReplicationTasks ( "refs / heads / ( mybranch|master ) " ) ) . hasSize ( 2 ) ; try ( Repository repo = repoManager . openRepository ( targetProject ) ; < |startfocus| > Repository sourceRepo = repoManager . openRepository ( project ) ) { < |endfocus| > waitUntil ( ( ) - > checkedGetRef ( repo , newBranch ) != null ) ; Ref masterRef = getRef ( sourceRepo , master ) ; Ref targetBranchRef = getRef ( repo , newBranch ) ; assertThat ( targetBranchRef ) . isNotNull ( ) ; assertThat ( targetBranchRef . getObjectId ( ) ) . isEqualTo ( masterRef . getObjectId ( ) ) ; } } @Test public void shouldReplicateNewBranchToTwoRemotes ( ) throws Exception { Project . NameKey targetProject1 = createProject ( "projectreplica1" ) ; Project . NameKey targetProject2 = createProject ( "projectreplica2" ) ;
Change updatedChange = op . merge ( change , submitter , true , input , false ) ; if ( updatedChange . isMerged ( ) ) { return change ; } logger . atWarning ( ) . log ( "change % s of project % s unexpectedly had status % s after submit attempt" , updatedChange . getId ( ) , updatedChange . getProject ( ) , updatedChange . getStatus ( ) ) ; throw new RestApiException ( String . format ( < |startfocus| > "change % s unexpectedly had status % s after submit attempt" , updatedChange . getId ( ) , updatedChange . getStatus ( ) ) ) ; < |endfocus| > } } /* * * Returns a message describing what prevents the current change from being submitted - or null . * This method only considers parent changes , and changes in the same topic . The caller is * responsible for making sure the current change to be submitted can indeed be submitted * ( permissions , submit rules , is not a WIP . . . ) * * @param cd the change the user is currently looking at * @param cs set of changes to be submitted at once
config . save ( ) ; super . setUpTestPlugin ( ) ; pluginDataDir = plugin . getSysInjector ( ) . getInstance ( Key . get ( Path . class , PluginData . class ) ) ; storagePath = pluginDataDir . resolve ( "ref - updates" ) ; } @Test public void shouldReplicateNewProject ( ) throws Exception { setReplicationDestination ( "foo" , "replica" , ALL_PROJECTS ) ; reloadConfig ( ) ; waitForEmptyTasks ( ) ; Project . NameKey sourceProject = createProject ( "foo" ) ; assertThat ( listReplicationTasks ( "refs / meta / config" ) ) . hasSize ( 1 ) ; < |startfocus| > waitUntil ( ( ) - > gitPath . resolve ( sourceProject + "replica . git" ) . toFile ( ) . isDirectory ( ) ) ; < |endfocus| > ProjectInfo replicaProject = gApi . projects ( ) . name ( sourceProject + "replica" ) . get ( ) ; assertThat ( replicaProject ) . isNotNull ( ) ; } @Test public void shouldReplicateNewChangeRef ( ) throws Exception { Project . NameKey targetProject = createProject ( "projectreplica" ) ; setReplicationDestination ( "foo" , "replica" , ALL_PROJECTS ) ; reloadConfig ( ) ; waitForEmptyTasks ( ) ; Result pushResult = createChange ( ) ; RevCommit sourceCommit = pushResult . getCommit ( ) ;
} @Test public void shouldReplicateNewProject ( ) throws Exception { setReplicationDestination ( "foo" , "replica" , ALL_PROJECTS ) ; reloadConfig ( ) ; waitForEmptyTasks ( ) ; Project . NameKey sourceProject = createProject ( "foo" ) ; assertThat ( listReplicationTasks ( "refs / meta / config" ) ) . hasSize ( 1 ) ; < |startfocus| > waitUntil ( ( ) - > projectExists ( new Project . NameKey ( sourceProject + "replica . git" ) ) ) ; < |endfocus| > ProjectInfo replicaProject = gApi . projects ( ) . name ( sourceProject + "replica" ) . get ( ) ; assertThat ( replicaProject ) . isNotNull ( ) ; } @Test public void shouldReplicateNewChangeRef ( ) throws Exception { Project . NameKey targetProject = createProject ( "projectreplica" ) ; setReplicationDestination ( "foo" , "replica" , ALL_PROJECTS ) ; reloadConfig ( ) ; waitForEmptyTasks ( ) ; Result pushResult = createChange ( ) ; RevCommit sourceCommit = pushResult . getCommit ( ) ; String sourceRef = pushResult . getPatchSet ( ) . getRefName ( ) ; assertThat ( listReplicationTasks ( "refs / changes / \\d */ \\d */ \\d * " ) ) . hasSize ( 1 ) ; try ( Repository repo = repoManager . openRepository ( targetProject ) ) {
private static final String CONFIG_FILE_PATH = " / data / local / tmp / " ; private static final String CLOUD_PROPERTY_FILE = "cloud . properties" ; private static boolean mIsCbInvoked = CALLBACK_NOT_INVOKED ; private enum CloudAuth { SIGNUP , SIGNIN , SIGNOUT } ; private enum LogLevel { INFO , ERROR , DEBUG } ; private static Properties props ; private static String filePath ; private static String fileName ; private static File file ; public static CloudAuth mMethodName ; < |startfocus| > public static String s_cloudUid ; public static String s_cloudAccesstoken ; public static String authCode ; public static String mErrorMessage ; < |endfocus| > public static void init ( String fileDir ) { props = new Properties ( ) ; ReadConfigPropFile . readConfigFile ( CONFIG_FILE_PATH ) ; file = new File ( fileDir + CLOUD_PROPERTY_FILE ) ; if ( ! file . exists ( ) ) { getAuthCode ( ) ; } } private static void getAuthCode ( ) { Log . d ( TAG , "getAuthCode IN" ) ; GetAuthCode getContent = new GetAuthCode ( ) ; try {
private static final String CLOUD_PROPERTY_FILE = "cloud . properties" ; private static boolean mIsCbInvoked = CALLBACK_NOT_INVOKED ; private enum CloudAuth { SIGNUP , SIGNIN , SIGNOUT } ; private enum LogLevel { INFO , ERROR , DEBUG } ; private static Properties props ; private static String filePath ; private static String fileName ; private static File file ; public static CloudAuth mMethodName ; < |startfocus| > public static String s_CloudUid ; public static String s_CloudAccesstoken ; public static String authCode ; public static String mErrorMessage ; < |endfocus| > public static void init ( String fileDir ) { props = new Properties ( ) ; ReadConfigPropFile . readConfigFile ( CONFIG_FILE_PATH ) ; file = new File ( fileDir + CLOUD_PROPERTY_FILE ) ; if ( ! file . exists ( ) ) { getAuthCode ( ) ; } } private static void getAuthCode ( ) { Log . d ( TAG , "getAuthCode IN" ) ; GetAuthCode getContent = new GetAuthCode ( ) ; try { OcAccountManagerHelper . authCode = getContent . execute ( ) . get ( ) ;
+ JUSTWORKS_SERVER_UNOWNED_CBOR_02 + " 1" ; public static final String START_PRE_CONFIG_SERVER_01 = " ./ iotivity_pm_server " + PRECONFIG_SERVER_UNOWNED_CBOR_01 + " 3" ; public static final String START_RE_SERVER = " ./ iotivity_re_server" ; public static final String PROVISION_DB_FILE = " ./ Pdm . db" ; public static final String DEVICE_PROP_CBOR_FILE = " ./ device_properties . dat" ; < |startfocus| > TestBroadCast mTestBroadCast ; < |endfocus| > protected RIHelperCommon ( IoTivityTc iotivityTcObj ) { s_helperContext = iotivityTcObj . getInstrumentation ( ) . getTargetContext ( ) ; s_filePath = s_helperContext . getFilesDir ( ) . getPath ( ) ; s_sqLPath = s_helperContext . getFilesDir ( ) . getAbsolutePath ( ) . replace ( FILES , DATABASES ) + File . separator ; mTestBroadCast = new TestBroadCast ( s_helperContext ) ; } public boolean configClientServerPlatform ( ) { PlatformConfig cfg = new PlatformConfig ( s_helperContext , ServiceType . IN_PROC , ModeType . CLIENT_SERVER , "0 . 0 . 0 . 0" , 0 , QualityOfService . HIGH ) ; OcPlatform . Configure ( cfg ) ; }
* * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** / package org . iotivity . testcase ; import android . util . Log ; public class IoTivityLog { < |startfocus| > < |endfocus| > public static void v ( String tag , String format ) { Log . v ( tag , format ) ; } public static void d ( String tag , String format ) { Log . d ( tag , format ) ; } public static void i ( String tag , String format ) { Log . i ( tag , format ) ; } public static void w ( String tag , String format ) { Log . w ( tag , format ) ; } public static void e ( String tag , String format ) { Log . e ( tag , format ) ; } }
* * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** / package org . iotivity . testcase ; import java . util . logging . Logger ; public class IoTivityLog { < |startfocus| > < |endfocus| > public static void v ( String tag , String format ) { System . out . println ( tag + " : " + format ) ; } public static void d ( String tag , String format ) { System . out . println ( tag + " : " + format ) ; } public static void i ( String tag , String format ) { System . out . println ( tag + " : " + format ) ; } public static void w ( String tag , String format ) { System . out . println ( tag + " : " + format ) ; } public static void e ( String tag , String format ) { System . out . println ( tag + " : " + format ) ; } }
public void testConfigureServerInProc_SRC_P ( ) { try { < |startfocus| > PlatformConfig cfg = new PlatformConfig ( ServiceType . IN_PROC , < |endfocus| > ModeType . SERVER , "0 . 0 . 0 . 0" , 0 , QualityOfService . HIGH ) ; OcPlatform . Configure ( cfg ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; fail ( "Exception occured" ) ; }
import org . iotivity . base . QualityOfService ; import org . iotivity . base . RequestHandlerFlag ; import org . iotivity . base . RequestType ; import org . iotivity . base . ResourceProperty ; import org . iotivity . base . ServiceType ; import org . iotivity . base . OcRepresentation ; import org . iotivity . base . OcResource ; import org . iotivity . base . OcResource . OnObserveListener ; import org . iotivity . base . OcResourceHandle ; import org . iotivity . testcase . IoTivityLog ; import org . iotivity . testcase . IoTivityTc ; import org . iotivity . test . ri . common . RIHelperCommon ; public class RIHelper extends RIHelperCommon implements IRIConstants { < |startfocus| > private static RIHelper riHelperInstance = null ; < |endfocus| > private final String LOG_TAG = this . getClass ( ) . getSimpleName ( ) ; private OcResourceHandle m_resourceHandle = null ; public EnumSet < ResourceProperty > m_resourceProperty ; public static final String TEMPERATURE_RESOURCE_QUERY = OcPlatform . WELL_KNOWN_QUERY + " ? rt = " + RESOURCE_TYPE_TEMPERATURE ; private OcRepresentation m_representation = null ; // new OcRepresentation ( ) ; public int m_temp ; public int m_hour ; public static boolean s_isServerOk ; public static String s_errorMsg ; public static String s_errorMsg ;
* Map < String , String > queryParamsMap , * OnPostListener onPostListener , * QualityOfService qualityOfService ) * @test_data 1 . resourceUri " / test / ri / android / temperature" * 2 . resourceTypeName "oic . r . temperature" * 3 . resourceInterface DEFAULT_INTERFACE * 4 . entityHandler entity handler * 5 . resourcePropertySet indicates property of the resource * 6 . representation representation to set * 7 . queryParamsMap map with query paramter and value < |startfocus| > * 8 . onPostListener event handler < |endfocus| > * 9 . qualityOfService High * @pre_condition Configure platform for client server mode * @procedure 1 . Perform registerResource ( ) API * 2 . Perform findResource ( ) API with resource type in query * 3 . Check if callback is called * 4 . Check if temperature resource is found * 5 . Perform post ( ) API ( with qos ) on the found temperature resource * 6 . Check if server can get the post request and send response correctly
public void onReceive ( Context context , Intent intent ) { Log . d ( TAG , "BroadcastReceiver Invoked" ) ; Log . d ( TAG , "Recieved Braodcasted MSG : " + intent . getStringExtra ( "key" ) ) ; < |startfocus| > < |endfocus| > if ( mTcpClient != null ) { mTcpClient . sendMessage ( intent . getStringExtra ( "key" ) ) ; } else { Log . e ( TAG , "TCP Client is not initialized" ) ; }
( byte ) 0x66 , ( byte ) 0x11 , ( byte ) 0xa5 , ( byte ) 0x84 , ( byte ) 0x99 , ( byte ) 0x8d , ( byte ) 0x0d , ( byte ) 0xbd , ( byte ) 0xb1 , ( byte ) 0x54 , ( byte ) 0xbb , ( byte ) 0xc5 , ( byte ) 0x4f , ( byte ) 0xed , ( byte ) 0x86 , ( byte ) 0x9a , ( byte ) 0x66 , ( byte ) 0x11 } ; PMConstants . mErrorMessage = PMConstants . EMPTY_STRING ; < |startfocus| > mPMHelper . clearAll ( ) ; < |endfocus| > mPMHelper . stopServers ( ) ; mPMHelper . startSecuredServer ( mPMHelper . START_JUSTWORKS_SERVER_01 ) ; mPMHelper . startSecuredServer ( mPMHelper . START_JUSTWORKS_SERVER_02 ) ; PMHelper . delay ( 5 ) ; // create platform config mPMHelper . copyCborFromAsset ( PMConstants . OIC_CLIENT_CBOR_DB_FILE ) ; mPMHelper . configClientServerPlatform ( PMConstants . OIC_CLIENT_CBOR_DB_FILE ) ; mPMHelper . initOICStack ( PMHelper . s_sqLPath , PMConstants . OIC_SQL_DB_FILE ) ; } protected void tearDown ( ) throws Exception { mPMHelper . stopServers ( ) ; mPMHelper . clearAll ( ) ; super . tearDown ( ) ; } /* *
public static final String OIC_JWSERVER_CBOR_DB_FILE_2 = "oic_svr_db_server . dat" ; public static final String OIC_DP_CLIENT_CBOR_DB_FILE = "oic_svr_db_client_directpairing . dat" ; public static final String OIC_CLOUD_CLIENT = "cloud . dat" ; public static final String OIC_SQL_DB_FILE = "Pdm . db" ; public static final String OIC_MOT_SQL_DB_FILE = "MOT_Pdm . db" ; public static final String SERVER_SQL_DB_FILE = "ServerPdm . db" ; < |startfocus| > < |endfocus| > // Cloud Resource public static final String CERT_SERIAL_ONE = "1" ; // ACL Related Resource public static final String DEFAULT_ROWNER_ID = "61646d69 - 6e44 - 6576 - 6963 - 655555494430" ; public static final String DEFAULT_RESOURCES = " * " ; public static final String HREF_RESOURCES_1A = " / a / device1a" ; public static final String HREF_RESOURCES_1B = " / a / device1b" ; public static final String HREF_RESOURCES_2A = " / a / device2a" ; public static final String HREF_RESOURCES_2B = " / a / device2b" ;
try { m_resource . put ( m_rep , qpMap , onPut ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; fail ( "Exception occured" ) ; } } /* * * @objective Test put function with negative basic way using null representation * @target put ( OcRepresentation representation , * Map < String , String > queryParamsMap , * OnPutListener onPutListener ) * @test_data 1 . representation null < |startfocus| > * 2 . queryParamsMap map with query paramter and value * 3 . OnPutListener event handler < |endfocus| > * @pre_condition 1 . configure platform * 2 . construct resource object * @procedure Call put ( ) API using resource * @post_condition None * @expected OcException should occur * @see void Configure ( PlatformConfig platformConfig ) * @see OcResource constructResourceObject ( * String host , * String uri , * EnumSet < OcConnectivityType > connectivityTypeSet , * boolean isObservable , * List < String > resourceTypeList , * List < String > interfaceList ) * @since 2016 - 09 - 05 ** /
public void testConfigureServerNon_SRC_P ( ) { try { < |startfocus| > PlatformConfig cfg = new PlatformConfig ( ServiceType . IN_PROC , < |endfocus| > ModeType . SERVER , "0 . 0 . 0 . 0" , 0 , QualityOfService . LOW ) ; OcPlatform . Configure ( cfg ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; fail ( "Exception occured" ) ; }
String DEVICE_TYPE_AC = "AirCondition" ; String RESOURCE_URI_TEMPERATURE = " / test / ri / android / temperature" ; String RESOURCE_TYPE_TEMPERATURE = "oic . r . temperature" ; String RESOURCE_URI_LIGHT = " / a / light" ; String RESOURCE_TYPE_LIGHT = "core . light" ; String RESOURCE_URI_FAN = " / a / fan" ; String RESOURCE_TYPE_FAN = "core . fan" ; < |startfocus| > String HOST = "coap :/ / 192 . 168 . 1 . 2 : 5000" ; < |endfocus| > int INT_ZERO = 0 ; int INT_ONE = 1 ; int INT_TWO = 2 ; int INT_MINUS_ONE = - 1 ; int CALLBACK_WAIT_DEFAULT = 5 ; int CALLBACK_WAIT_MAX = 10 ; int CALLBACK_WAIT_MIN = 1 ; int SUCCESS_RESPONSE = 0 ; int COAP_RESPONSE_CODE_SUCCESS = 205 ; int COAP_RESPONSE_CODE_CREATED = 201 ; int COAP_RESPONSE_CODE_DELETED = 202 ;
public static RIHelper getInstance ( IoTivityTc iotivityTcObj ) { new OcRepresentation ( ) ; < |startfocus| > < |endfocus| > Lock mutex = new ReentrantLock ( ) ; if ( s_mRiHelperInstance == null ) { mutex . lock ( ) ; if ( s_mRiHelperInstance == null ) { IoTivityLog . i ( "RIHelper" , "Inside Helper" ) ; s_mRiHelperInstance = new RIHelper ( iotivityTcObj ) ; } mutex . unlock ( ) ; } return s_mRiHelperInstance ;
* // ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * // < |startfocus| > * // Copyright 2018 Intel Corporation All Rights Reserved . < |endfocus| > * // * // -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= * // * // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * // you may not use this file except in compliance with the License . * // You may obtain a copy of the License at * // * // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * // * // Unless required by applicable law or agreed to in writing , software * // distributed under the License is distributed on an "AS IS" BASIS , * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * // See the License for the specific language governing permissions and * // limitations under the License . * // * // -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= */ package org . iotivity . base . examples ; import org . iotivity . base . OcException ;
/* * Copyright ( c ) 2016 Intel Corporation * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package org . iotivity . base . examples ; import org . iotivity . base . OcException ; import org . iotivity . base . OcPlatform ; import org . iotivity . base . OcRepresentation ; import org . iotivity . base . OcResource ; import java . util . EnumSet ; /* * * Server * < p > * Server is a base class that provides common functionality for server * examples . */ public abstract class Server { protected static final String RESOURCE_URI = " / a / light" ; protected static final String RESOURCE_TYPE = "core . light" ; protected static final String RESOURCE_INTERFACE = OcPlatform . DEFAULT_INTERFACE ; protected static final String KEY_NAME = "name" ; protected static final String KEY_STATE = "state" ; protected static final String KEY_POWER = "power" ; protected static final String KEY_BRIGHTNESS = "brightness" ; protected OcResource mResource ; protected void createResource ( ) { try { mResource = OcPlatform . registerResource ( RESOURCE_URI , RESOURCE_TYPE , OcPlatform . DEFAULT_INTERFACE , ( OcResource . OnPutCallback ) this : : onPut , EnumSet . of ( ResourceProperty . DISCOVERABLE , ResourceProperty . OBSERVABLE ) ) ; } catch ( OcException e ) { Log . e ( TAG , e . toString ( ) ) ; Log . e ( TAG , "Failed to create resource" ) ; return ; } Log . i ( TAG , "Resource created" ) ; } protected void onPut ( OcResource ocResource , OcRepresentation ocRepresentation ) { Log . i ( TAG , "PUT request received" ) ; try { if ( ocRepresentation . hasAttribute ( KEY_NAME ) ) { mName = ocRepresentation . getValue ( KEY_NAME ) ; } if ( ocRepresentation . hasAttribute ( KEY_STATE ) ) { mState = ocRepresentation . getValue ( KEY_STATE ) ; } if ( ocRepresentation . hasAttribute ( KEY_POWER ) ) { mPower = ocRepresentation . getValue ( KEY_POWER ) ; } if ( ocRepresentation . hasAttribute ( KEY_BRIGHTNESS ) ) { mBrightness = ocRepresentation . getValue ( KEY_BRIGHTNESS ) ; } } catch ( OcException e ) { Log . e ( TAG , e . toString ( ) ) ; Log . e ( TAG , "Failed to read representation values" ) ; return ; } Log . i ( TAG , "Name : " + mName ) ; Log . i ( TAG , "State : " + mState ) ; Log . i ( TAG , "Power : " + mPower ) ; Log . i ( TAG , "Brightness : " + mBrightness ) ; } protected void start ( ) { try { OcPlatform . startPresence ( 0 ) ; } catch ( OcException e ) { Log . e ( TAG , e . toString ( ) ) ; Log . e ( TAG , "Failed to start presence" ) ; return ; } Log . i ( TAG , "Presence started" ) ; } protected void stop ( ) { try { OcPlatform . stopPresence ( ) ; } catch ( OcException e ) { Log . e ( TAG , e . toString ( ) ) ; Log . e ( TAG , "Failed to stop presence" ) ; return ; } Log . i ( TAG , "Presence stopped" ) ; } protected void unregisterResource ( ) { try { OcPlatform . unregisterResource ( mResource ) ; } catch ( OcException e ) { Log . e ( TAG , e . toString ( ) ) ; Log . e ( TAG , "Failed to unregister resource" ) ; return ; } Log . i ( TAG , "Resource unregistered" ) ; } }
/* * Copyright ( c ) 2016 Intel Corporation * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package org . iotivity . base . examples ; import android . graphics . Bitmap ; import android . graphics . BitmapFactory ; import android . os . Bundle ; import android . os . Handler ; import android . os . Message ; import android . util . Log ; import org . iotivity . base . OcException ; import org . iotivity . base . OcHeaderOption ; import org . iotivity . base . OcRepresentation ; import org . iotivity . base . OcResource ; import java . util . List ; /* * * GetRemoteRepresentationListener * < p / > * Listener for getting remote representation . */ public class GetRemoteRepresentationListener implements OcResource . OnGetListener { private static final String TAG = GetRemoteRepresentationListener . class . getSimpleName ( ) ; private Handler mHandler ; public GetRemoteRepresentationListener ( Handler handler ) { mHandler = handler ; } @Override public synchronized void onGetCompleted ( List < OcHeaderOption > list , OcRepresentation ocRepresentation ) { Log . d ( TAG , "GET request was successful" ) ; Log . d ( TAG , "Resource URI : " + ocRepresentation . getUri ( ) ) ; try { String uri = ocRepresentation . getUri ( ) ; if ( uri . equals ( Common . getLightUri ( ) ) ) { Common . setLightRepresentation ( ocRepresentation ) ; } else if ( uri . equals ( Common . getSwitchUri ( ) ) ) { Common . setSwitchRepresentation ( ocRepresentation ) ; } else if ( uri . equals ( Common . getImageUri ( ) ) ) { byte [ ] imageBytes = ocRepresentation . getValue ( "image" ) ; Bitmap bitmap = BitmapFactory . decodeByteArray ( imageBytes , 0 , imageBytes . length ) ; Common . setImageRepresentation ( bitmap ) ; } } catch ( OcException e ) { Log . e ( TAG , e . getMessage ( ) ) ; } Message msg = Message . obtain ( ) ; msg . what = Common . MSG_GET_SUCCESS ; Bundle data = new Bundle ( ) ; data . putString ( "URI" , ocRepresentation . getUri ( ) ) ; msg . setData ( data ) ; mHandler . sendMessage ( msg ) ; } @Override public synchronized void onGetFailed ( Throwable throwable ) { if ( throwable instanceof OcException ) { OcException ocEx = ( OcException ) throwable ; Log . e ( TAG , ocEx . toString ( ) ) ; ErrorCode errCode = Common . convertErrorCode ( ocEx . getErrorCode ( ) ) ; mHandler . sendEmptyMessage ( errCode . getValue ( ) ) ; } Log . e ( TAG , throwable . toString ( ) ) ; } }
/* * Copyright ( c ) 2016 Intel Corporation * * Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * you may not use this file except in compliance with the License . * You may obtain a copy of the License at * * http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * * Unless required by applicable law or agreed to in writing , software * distributed under the License is distributed on an "AS IS" BASIS , * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * See the License for the specific language governing permissions and * limitations under the License . */ package org . iotivity . base . examples ; import org . iotivity . base . OcException ; import org . iotivity . base . OcPlatform ; import org . iotivity . base . OcRepresentation ; import org . iotivity . base . OcResource ; import java . util . EnumSet ; /* * * Server * < p > * Server is a base class that provides common functionality for server * examples . */ public abstract class Server { protected static final String RESOURCE_URI = " / a / light" ; protected static final String RESOURCE_TYPE = "core . light" ; protected static final String RESOURCE_INTERFACE = OcPlatform . DEFAULT_INTERFACE ; protected static final String KEY_NAME = "name" ; protected static final String KEY_STATE = "state" ; protected static final String KEY_POWER = "power" ; protected static final String KEY_BRIGHTNESS = "brightness" ; protected OcResource mResource ; protected void createResource ( ) { try { mResource = OcPlatform . registerResource ( RESOURCE_URI , RESOURCE_TYPE , OcPlatform . DEFAULT_INTERFACE , ( OcResource . OnPutCallback ) this : : onPut , EnumSet . of ( ResourceProperty . DISCOVERABLE , ResourceProperty . OBSERVABLE ) ) ; } catch ( OcException e ) { Log . e ( TAG , e . toString ( ) ) ; Log . e ( TAG , "Failed to create resource" ) ; return ; } Log . i ( TAG , "Resource created" ) ; } protected void onPut ( OcResource ocResource , OcRepresentation ocRepresentation ) { Log . i ( TAG , "PUT request received" ) ; } protected void startServer ( ) { try { OcPlatform . startPresence ( 0 ) ; } catch ( OcException e ) { Log . e ( TAG , e . toString ( ) ) ; Log . e ( TAG , "Failed to start server" ) ; return ; } Log . i ( TAG , "Server started" ) ; } protected void stopServer ( ) { try { OcPlatform . stopPresence ( ) ; } catch ( OcException e ) { Log . e ( TAG , e . toString ( ) ) ; Log . e ( TAG , "Failed to stop server" ) ; return ; } Log . i ( TAG , "Server stopped" ) ; } protected void unregisterResource ( ) { try { OcPlatform . unregisterResource ( mResource ) ; } catch ( OcException e ) { Log . e ( TAG , e . toString ( ) ) ; Log . e ( TAG , "Failed to unregister resource" ) ; return ; } Log . i ( TAG , "Resource unregistered" ) ; } }
/* * * MediaControl * * This class is used by UpnpAvClientActivity to create an object representation of a remote media control resource * and update the values depending on the server response */ public class MediaControl extends Service { public static final String OIC_TYPE_MEDIA_CONTROL = "oic . r . media . control" ; < |startfocus| > public static final String OCF_OIC_URI_PREFIX_MEDIA_CONTROL = " / ocf / mediaControl / " ; public static final String UPNP_OIC_URI_PREFIX_MEDIA_CONTROL = " / upnp / mediaControl / " ; < |endfocus| > public static final String STATE_KEY = "playState" ; public static final boolean DEFAULT_STATE = false ; public static final String SPEED_KEY = "mediaSpeed" ; public static final double DEFAULT_SPEED = 1 . 0 ; public static final String LOCATION_KEY = "mediaLocation" ; public static final String DEFAULT_LOCATION = "0" ; public static final String LAST_ACTION_KEY = "lastAction" ; public static final String DEFAULT_LAST_ACTION = "stop" ; public static final String ACTIONS_KEY = "actions" ; private boolean mPlayState ;
* // ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * // < |startfocus| > * // Copyright 2016 Intel Corporation All Rights Reserved . < |endfocus| > * // * // -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= * // * // Licensed under the Apache License , Version 2 . 0 ( the "License" ) ; * // you may not use this file except in compliance with the License . * // You may obtain a copy of the License at * // * // http :/ / www . apache . org / licenses / LICENSE - 2 . 0 * // * // Unless required by applicable law or agreed to in writing , software * // distributed under the License is distributed on an "AS IS" BASIS , * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . * // See the License for the specific language governing permissions and * // limitations under the License . * // * // -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= -= */ package org . iotivity . base . examples ; import android . app . Activity ;
* limitations under the License . * *- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- =- = */ package org . iotivity . base . examples ; import org . iotivity . base . OcException ; import org . iotivity . base . OcPlatform ; import org . iotivity . base . PayloadType ; /* * * Light * * This class represents a light resource */ public class Light { < |startfocus| > static public final String RESOURCE_TYPE = "oic . d . light" ; static public final String DEVICE_RES_TYPE = "oic . wk . d" ; < |endfocus| > private Switch switchRes ; private Brightness brightnessRes ; private String deviceName ; public Light ( String name , String uuid , boolean powerOn , int brightness , LightControlPanel ui ) { deviceName = name ; switchRes = new Switch ( uuid ) ; switchRes . setValue ( powerOn ) ; switchRes . addObserver ( ui ) ; ui . addObserver ( switchRes ) ; OcfLightServer . msg ( "Created switch resource : " + switchRes ) ; brightnessRes = new Brightness ( uuid ) ; brightnessRes . setBrightness ( brightness ) ; brightnessRes . addObserver ( ui ) ; ui . addObserver ( brightnessRes ) ;
< |startfocus| > public void update ( boolean powerOn , int brightness ) { < |endfocus| > if ( powerOn ) { setBrightness ( brightness ) ; } else { setBrightness ( 0 ) ; } notifyObservers ( null ) ;
public void testUri ( ) { OCResource r = new OCResource ( ) ; assertNotNull ( r ) ; r . setUri ( " / foo / bar" ) ; assertEquals ( " / foo / bar" , r . getUri ( ) ) ; } @Test public void testTypes ( ) { OCResource r = new OCResource ( ) ; assertNotNull ( r ) ; // TODO properly encode / decode the OCResource oc_string_array_t types . // r . setTypes ( value ) ; // failure purposely done till the setTypes / getProperties methods are updated with non SWIG type values . fail ( "Not yet implemented" ) ; } < |startfocus| > < |endfocus| > @Test public void testInterfaces ( ) { OCResource r = new OCResource ( ) ; assertNotNull ( r ) ; r . setInterfaces ( OCInterfaceMask . RW ) ; assertEquals ( OCInterfaceMask . RW , r . getInterfaces ( ) ) ; } @Test public void testDefaultInterface ( ) { OCResource r = new OCResource ( ) ; assertNotNull ( r ) ; r . setDefaultInterface ( OCInterfaceMask . BASELINE ) ; assertEquals ( OCInterfaceMask . BASELINE , r . getDefaultInterface ( ) ) ; } @Test public void testProperties ( ) { OCResource r = new OCResource ( ) ; assertNotNull ( r ) ; r . setProperties ( OCResourceProperty . DISCOVERABLE ) ; assertEquals ( OCResourceProperty . DISCOVERABLE , r . getProperties ( ) ) ; }
} else if ( response . getCode ( ) == OCStatus . OC_STATUS_CREATED ) { System . out . println ( "\tPUT
private void eventLoop ( ) { while ( ! quit ) { long nextEvent = OCMain . mainPoll ( ) ; lock . lock ( ) ; try { if ( nextEvent == 0 ) { cv . await ( ) ; } else { long now = OCClock . clockTime ( ) ; < |startfocus| > cv . awaitNanos ( nextEvent - now ) ; < |endfocus| > } } catch ( InterruptedException e ) { Log . d ( TAG , e . getMessage ( ) ) ; } finally { lock . unlock ( ) ; } }
public int initialize ( ) { Log . d ( TAG , "inside MyInitHandler . initialize ( ) " ) ; < |startfocus| > int ret = OCMain . initPlatform ( "Android" ) ; ret | = OCMain . addDevice ( " / oic / d" , "oic . d . phone" , "Kishen's Android Phone" , "ocf . 1 . 0 . 0" , "ocf . res . 1 . 0 . 0" ) ; < |endfocus| > return ret ;
public void testValueObject ( ) { OCMain . repNewBuffer ( 1024 ) ; /* * { * "my_object" : { * "a" : 1 , * "b" : false , * "c" : "three" * } * } */ CborEncoder root = OCMain . repBeginRootObject ( ) ; assertEquals ( 0 , OCMain . repGetCborErrno ( ) ) ; < |startfocus| > CborEncoder myObject = OCMain . repOpenObject ( root , "my_object" ) ; < |endfocus| > assertEquals ( 0 , OCMain . repGetCborErrno ( ) ) ; OCMain . repSetInt ( myObject , "a" , 1 ) ; assertEquals ( 0 , OCMain . repGetCborErrno ( ) ) ; OCMain . repSetBoolean ( myObject , "b" , false ) ; assertEquals ( 0 , OCMain . repGetCborErrno ( ) ) ; OCMain . repSetTextString ( myObject , "c" , "three" ) ; assertEquals ( 0 , OCMain . repGetCborErrno ( ) ) ; OCMain . repCloseObject ( root , myObject ) ; OCMain . repEndRootObject ( ) ; assertEquals ( 0 , OCMain . repGetCborErrno ( ) ) ; OCMain . repSetPool ( new OCMemoryBuffer ( ) ) ; OCRepresentation rep = OCMain . repGetOCRepresentaionFromRootObject ( ) ; assertNotNull ( rep ) ; OCValue v = new OCValue ( ) ; assertNotNull ( v ) ;
public int initialize ( ) { < |startfocus| > System . out . println ( "inside ObtInitHandler . initialize ( ) " ) ; < |endfocus| > int ret = OCMain . initPlatform ( "OCF" ) ; ret | = OCMain . addDevice ( " / oic / d" , "oic . d . phone" , "OBT" , "ocf . 1 . 0 . 0" , "ocf . res . 1 . 0 . 0" ) ; return ret ;
System . out . println ( "################################################" ) ; System . out . println ( "\nSelect option : " ) ; } private static void discoverUnownedDevices ( ) { System . out . println ( "Discovering un - owned devices" ) ; appSyncLock . lock ( ) ; if ( 0 > OCObt . discoverUnownedDevices ( unownedDeviceHandler ) ) { System . err . println ( "ERROR discovering un - owned Devices . " ) ; } appSyncLock . unlock ( ) ; } private static void discoverOwnedDevices ( ) { appSyncLock . lock ( ) ; < |startfocus| > if ( 0 != OCObt . discoverOwnedDevices ( ownedDeviceHandler ) ) { < |endfocus| > System . err . println ( "ERROR discovering owned Devices . " ) ; } appSyncLock . unlock ( ) ; } public static void main ( String [ ] args ) { quit = false ; mainThread = Thread . currentThread ( ) ; Runtime . getRuntime ( ) . addShutdownHook ( shutdownHook ) ; String osName = System . getProperty ( "os . name" ) ; boolean isLinux = ( osName != null ) && osName . toLowerCase ( ) . contains ( "linux" ) ; System . out . println ( "OS Name = " + osName + " , isLinux = " + isLinux ) ; String creds_path = " ./ onboarding_tool_creds / " ;
break ; case 3 : OCObt . aceResourceSetWc ( res , OCAceWildcard . OC_ACE_WC_ALL_NON_DISCOVERABLE ) ; break ; default : break ; } } } System . out . print ( "Enter number of resource types [ 0 - None ] : " ) ; c = scanner . nextInt ( ) ; if ( c > 0 && c <= MAX_NUM_RT ) { OCObt . aceResoruceSetNumRt ( res , c ) ; int j = 0 ; while ( j < c ) { < |startfocus| > System . out . print ( "Enter resource type : " + ( j + 1 ) ) ; < |endfocus| > String rt = scanner . next ( ) ; if ( rt . length ( ) > 127 ) { rt = rt . substring ( 0 , 127 ) ; } OCObt . aceResoruceBindRt ( res , rt ) ; j ++ ; } } System . out . print ( "Enter number of interfaces [ 0 - None ] : " ) ; c = scanner . nextInt ( ) ; if ( c > 0 && c <= 7 ) { int j = 0 ; while ( j < c ) { int k ; System . out . println ( "\n [ 1 ] : oic . if . baseline" ) ;
public int initialize ( ) { < |startfocus| > System . out . println ( "inside ObtInitHandler . initialize ( ) " ) ; < |endfocus| > int ret = OCMain . initPlatform ( "OCF" ) ; ret | = OCMain . addDevice ( " / oic / d" , "oic . d . phone" , "OBT" , "ocf . 1 . 0 . 0" , "ocf . res . 1 . 0 . 0" ) ; return ret ;
public void handler ( OCUuid uuid , int status , Object userData ) { if ( status >= 0 ) { < |startfocus| > ObtMain . ownedDevices . remove ( uuid ) ; < |endfocus| > System . out . println ( "\nSuccessfully performed hard RESET to device " + OCUuidUtil . uuidToString ( uuid ) ) ; } else { System . out . println ( "\nERROR performing hard RESET to device " + OCUuidUtil . uuidToString ( uuid ) ) ; }
private void eventLoop ( ) { while ( ! quit ) { long nextEvent = OCMain . mainPoll ( ) ; lock . lock ( ) ; try { if ( nextEvent == 0 ) { cv . await ( ) ; } else { long now = OCClock . clockTime ( ) ; < |startfocus| > long timeToWait = ( NANOS_PER_SECOND / OCClock . clockSeconds ( ) ) * ( nextEvent - now ) ; < |endfocus| > cv . awaitNanos ( timeToWait ) ; } } catch ( InterruptedException e ) { Log . d ( TAG , e . getMessage ( ) ) ; } finally { lock . unlock ( ) ; } }
public void handler ( OCRequest request , int interfaces ) { Log . d ( TAG , "inside Put Light Request Handler" ) ; < |startfocus| > new PostLightRequestHandler ( activity ) . handler ( request , interfaces , userData ) ; < |endfocus| >
OCMain . resourceSetRequestHandler ( resource , OCMethod . OC_POST , new PostLightRequestHandler ( activity , light ) ) ; OCMain . addResource ( resource ) ; } @Override public void requestEntry ( ) { Log . d ( TAG , "inside MyInitHandler . requestEntry ( ) " ) ; } @Override public void signalEventLoop ( ) { Log . d ( TAG , "inside MyInitHandler . signalEventLoop ( ) " ) ; activity . lock . lock ( ) ; try { activity . cv . signalAll ( ) ; } finally { activity . lock . unlock ( ) ; } } < |startfocus| > private Light light ; < |endfocus| > }
String creds_path = " ./ simpleserver_creds / " ; java . io . File directory = new java . io . File ( creds_path ) ; if ( ! directory . exists ( ) ) { directory . mkdir ( ) ; } System . out . println ( "Storage Config PATH : " + directory . getPath ( ) ) ; if ( 0 != OCStorage . storageConfig ( directory . getPath ( ) ) ) { System . err . println ( "Failed to setup Storage Config . " ) ; } //
if ( ! directory . exists ( ) ) { directory . mkdir ( ) ; } System . out . println ( "Storage Config PATH : " + directory . getPath ( ) ) ; if ( 0 != OCStorage . storageConfig ( directory . getPath ( ) ) ) { System . err . println ( "Failed to setup Storage Config . " ) ; } //
public void handler ( OCClientResponse response ) { < |startfocus| > System . out . println ( "Get Owned Device Name Response Handler : " ) ; < |endfocus| > OCRepresentation rep = response . getPayload ( ) ; String n = null ; String di = null ; while ( rep != null ) { switch ( rep . getType ( ) ) { case OC_REP_STRING : if ( "n" . equals ( rep . getName ( ) ) ) { n = rep . getValue ( ) . getString ( ) ; } if ( "di" . equals ( rep . getName ( ) ) ) { di = rep . getValue ( ) . getString ( ) ; } break ; default : break ; } rep = rep . getNext ( ) ; } if ( di != null ) { ObtMain . ownedDevices . add ( new OCFDeviceInfo ( OCUuidUtil . stringToUuid ( di ) , n ) ) ; }
public void handler ( OCClientResponse response ) { < |startfocus| > System . out . println ( "Get Unowned Device Name Handler : " ) ; < |endfocus| > OCRepresentation rep = response . getPayload ( ) ; String n = null ; String di = null ; while ( rep != null ) { switch ( rep . getType ( ) ) { case OC_REP_STRING : if ( "n" . equals ( rep . getName ( ) ) ) { n = rep . getValue ( ) . getString ( ) ; } if ( "di" . equals ( rep . getName ( ) ) ) { di = rep . getValue ( ) . getString ( ) ; } break ; default : break ; } rep = rep . getNext ( ) ; } if ( di != null ) { ObtMain . unownedDevices . add ( new OCFDeviceInfo ( OCUuidUtil . stringToUuid ( di ) , n ) ) ; }
} // for unit testing only static public OcRepresentation createOcRepresentaionFromRoot ( ) throws OcCborException { OCRep . clearCborErrno ( ) ; OCRepresentation nativeRep = OCRep . getOCRepresentaionFromRootObject ( ) ; if ( ( nativeRep != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return new OcRepresentation ( nativeRep ) ; } throw new OcCborException ( "Failed to create OcRepresentation from root object" ) ; } public String getKey ( ) { OCRep . clearCborErrno ( ) ; return nativeRepresentation . getName ( ) ; } < |startfocus| > public boolean getBoolean ( ) throws OcCborException { < |endfocus| > Boolean returnValue = getValue ( ) . getBool ( ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( "Failed to get boolean" ) ; } public Long getLong ( ) throws OcCborException { Long returnValue = getValue ( ) . getInteger ( ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( "Failed to get long" ) ; } public Double getDouble ( ) throws OcCborException { Double returnValue = getValue ( ) . getDouble ( ) ;
return new OcRepresentation ( nativeRep ) ; } throw new OcCborException ( "Failed to create OcRepresentation from root object" ) ; } public String getKey ( ) { OCRep . clearCborErrno ( ) ; return nativeRepresentation . getName ( ) ; } public Boolean getBoolean ( ) throws OcCborException { Boolean returnValue = getValue ( ) . getBool ( ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( "Failed to get boolean" ) ; } < |startfocus| > public long getLong ( ) throws OcCborException { < |endfocus| > Long returnValue = getValue ( ) . getInteger ( ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( "Failed to get long" ) ; } public Double getDouble ( ) throws OcCborException { Double returnValue = getValue ( ) . getDouble ( ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( "Failed to get double" ) ; } public String getString ( ) throws OcCborException { String returnValue = getValue ( ) . getString ( ) ; if ( returnValue != null ) { return returnValue ; }
} public Boolean getBoolean ( ) throws OcCborException { Boolean returnValue = getValue ( ) . getBool ( ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( "Failed to get boolean" ) ; } public Long getLong ( ) throws OcCborException { Long returnValue = getValue ( ) . getInteger ( ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( "Failed to get long" ) ; } < |startfocus| > public double getDouble ( ) throws OcCborException { < |endfocus| > Double returnValue = getValue ( ) . getDouble ( ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( "Failed to get double" ) ; } public String getString ( ) throws OcCborException { String returnValue = getValue ( ) . getString ( ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( "Failed to get string" ) ; } public OCArray getArray ( ) throws OcCborException { OCArray returnValue = getValue ( ) . getArray ( ) ; if ( returnValue != null ) {
OCRepresentation nativeRep = getValue ( ) . getObject ( ) ; if ( nativeRep != null ) { return new OcRepresentation ( nativeRep ) ; } throw new OcCborException ( "Failed to get object" ) ; } public OcRepresentation getObjectArray ( ) throws OcCborException { OCRepresentation nativeRep = getValue ( ) . getObjectArray ( ) ; if ( nativeRep != null ) { return new OcRepresentation ( nativeRep ) ; } throw new OcCborException ( "Failed to get object array" ) ; } public OCValue getValue ( ) throws OcCborException { < |startfocus| > OCValue returnValue = nativeRepresentation . getValue ( ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( "Failed to get value" ) ; } public Boolean getBoolean ( String key ) throws OcCborException { Boolean returnValue = OCRep . getBoolean ( nativeRepresentation , key ) ; if ( returnValue != null ) { return returnValue ; } throw new OcCborException ( "Failed to get boolean for key " + key ) ;
if ( nativeRep != null ) { return new OcRepresentation ( nativeRep ) ; } throw new OcCborException ( "Failed to get object array" ) ; } public OCValue getValue ( ) throws OcCborException { OCRep . clearCborErrno ( ) ; OCValue returnValue = nativeRepresentation . getValue ( ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; } throw new OcCborException ( "Failed to get value" ) ; } < |startfocus| > public boolean getBoolean ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; < |endfocus| > Boolean returnValue = OCRep . getBoolean ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue . getBoolean ( ) ; } throw new OcCborException ( "Failed to get boolean for key " + key ) ; } public Long getLong ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; Long returnValue = OCRep . getLong ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; }
return returnValue ; } throw new OcCborException ( "Failed to get value" ) ; } public Boolean getBoolean ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; Boolean returnValue = OCRep . getBoolean ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; } throw new OcCborException ( "Failed to get boolean for key " + key ) ; } public long getLong ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; Long returnValue = OCRep . getLong ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; } throw new OcCborException ( "Failed to get long for key " + key ) ; } public Double getDouble ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; Double returnValue = OCRep . getDouble ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; }
return returnValue ; } throw new OcCborException ( "Failed to get boolean for key " + key ) ; } public Long getLong ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; Long returnValue = OCRep . getLong ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; } throw new OcCborException ( "Failed to get long for key " + key ) ; } public double getDouble ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; double returnValue = OCRep . getDouble ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; } throw new OcCborException ( "Failed to get double for key " + key ) ; } public String getString ( String key ) throws OcCborException { OCRep . clearCborErrno ( ) ; String returnValue = OCRep . getString ( nativeRepresentation , key ) ; if ( ( returnValue != null ) && ( OCRep . getCborErrno ( ) == 0 ) ) { return returnValue ; }
static public OcRepresentation createOcRepresentaionFromRoot ( ) throws OcCborException { OCRep . clearCborErrno ( ) ; OCRepresentation nativeRep = OCRep . getOCRepresentaionFromRootObject ( ) ; < |startfocus| > if ( nativeRep != null && OCRep . getCborErrno ( ) == 0 ) { < |endfocus| > return new OcRepresentation ( nativeRep ) ; } throw new OcCborException ( "Failed to create OcRepresentation from root object" ) ;
break ; case R . id . radio_recovery : mRebootMode = 2 ; Settings . System . putInt ( mContext . getContentResolver ( ) , Settings . System . STATUS_BAR_LAST_NOTIFICATION_STYLE , mRebootMode ) ; mTileMode = 2 ; break ; case R . id . radio_bootloader : mRebootMode = 3 ; Settings . System . putInt ( mContext . getContentResolver ( ) , Settings . System . STATUS_BAR_LAST_NOTIFICATION_STYLE , mRebootMode ) ; mTileMode = 2 ; break ; default : break ; < |startfocus| > } < |endfocus| > refreshState ( ) ;
public void update ( ) { int showNavBar = Settings . System . getIntForUser ( mContext . getContentResolver ( ) , Settings . System . NAVIGATION_BAR_SHOW , - 1 , mCurrentUserId ) ; < |startfocus| > int qsQuickPulldownValue = Settings . System . getIntForUser ( mContext . getContentResolver ( ) , Settings . System . STATUS_BAR_QUICK_QS_PULLDOWN , 0 , mCurrentUserId ) ; < |endfocus| > if ( showNavBar != - 1 ) { boolean showNavBarBool = showNavBar == 1 ; if ( showNavBarBool != mShowNavBar ) { updateNavigationBar ( ) ; } } mRecentsStyle = Settings . System . getIntForUser ( mContext . getContentResolver ( ) , Settings . System . NAVIGATION_BAR_RECENTS , 0 , mCurrentUserId ) ; mOmniSwitchRecents = mRecentsStyle == 1 ; mLongPressOnAppSwitchBehavior = Settings . System . getIntForUser ( mContext . getContentResolver ( ) , Settings . System . BUTTON_LONG_PRESS_RECENTS , 0 , mCurrentUserId ) ; if ( mStatusBarWindow != null ) { mStatusBarWindow . updateSettings ( ) ; } if ( mNavigationBar != null ) { mNavigationBar . setRecentsOptions ( mRecentsStyle , mLongPressOnAppSwitchBehavior ) ; } if ( mStatusBarWindowManager != null ) {
public void update ( ) { int showNavBar = Settings . System . getIntForUser ( mContext . getContentResolver ( ) , Settings . System . NAVIGATION_BAR_SHOW , - 1 , mCurrentUserId ) ; < |startfocus| > int qsQuickPulldownValue = Settings . System . getIntForUser ( mContext . getContentResolver ( ) , Settings . System . STATUS_BAR_QUICK_QS_PULLDOWN , 0 , UserHandle . USER_CURRENT ) ; < |endfocus| > if ( showNavBar != - 1 ) { boolean showNavBarBool = showNavBar == 1 ; if ( showNavBarBool != mShowNavBar ) { updateNavigationBar ( ) ; } } mRecentsStyle = Settings . System . getIntForUser ( mContext . getContentResolver ( ) , Settings . System . NAVIGATION_BAR_RECENTS , 0 , mCurrentUserId ) ; mOmniSwitchRecents = mRecentsStyle == 1 ; mLongPressOnAppSwitchBehavior = Settings . System . getIntForUser ( mContext . getContentResolver ( ) , Settings . System . BUTTON_LONG_PRESS_RECENTS , 0 , mCurrentUserId ) ; if ( mStatusBarWindow != null ) { mStatusBarWindow . updateSettings ( ) ; } if ( mNavigationBar != null ) { mNavigationBar . setRecentsOptions ( mRecentsStyle , mLongPressOnAppSwitchBehavior ) ; } }
public void onBindViewHolder ( PreferenceViewHolder holder ) { super . onBindViewHolder ( holder ) ; LinearLayout linearLayout = ( LinearLayout ) holder . findViewById ( R . id . selected_apps ) ; if ( linearLayout . getChildCount ( ) > 0 ) linearLayout . removeAllViews ( ) ; for ( String value : mValues ) { try { < |startfocus| > ImageView v = ( ImageView ) LayoutInflater . from ( mContext ) . inflate ( R . layout . app_grid_item , linearLayout , false ) ; < |endfocus| > ComponentName componentName = ComponentName . unflattenFromString ( value ) ; Drawable icon = mPm . getActivityIcon ( componentName ) ; v . setImageDrawable ( icon ) ; v . setPadding ( 0 , 0 , 15 , 0 ) ; v . setScaleType ( ImageView . ScaleType . CENTER_CROP ) ; linearLayout . addView ( v ) ; } catch ( PackageManager . NameNotFoundException e ) { Log . e ( TAG , "Set app icon" , e ) ; } }
public void onKeyguardShowingChanged ( ) { < |startfocus| > mShowIndicator = Settings . Secure . getIntForUser ( mContext . getContentResolver ( ) , Settings . Secure . LOCK_HIDE_INDICATOR_DISPLAY , 0 , UserHandle . USER_CURRENT ) == 0 ; < |endfocus| > updateLeftAffordance ( ) ; updateRightAffordance ( ) ; inflateCameraPreview ( ) ; mIndicationController . setVisibleOverwrite ( mShowIndicator ) ;
private void updateSettings ( ) { int mQsBackGroundAlpha = Settings . System . getIntForUser ( getContext ( ) . getContentResolver ( ) , < |startfocus| > Settings . System . QS_PANEL_BG_ALPHA , 255 , < |endfocus| > UserHandle . USER_CURRENT ) ; mQsBackGround . setAlpha ( mQsBackGroundAlpha ) ; setBackground ( mQsBackGround ) ;
mMusicActive . setOnPreferenceChangeListener ( this ) ; mAutorun = ( SwitchPreference ) findPreference ( EVENT_AUTORUN_SINGLE ) ; mAutorun . setChecked ( getPrefs ( ) . getBoolean ( EventServiceSettings . EVENT_AUTORUN_SINGLE , true ) ) ; mAutorun . setOnPreferenceChangeListener ( this ) ; mChooserTimeout = ( SeekBarPreference ) findPreference ( APP_CHOOSER_TIMEOUT ) ; mChooserTimeout . setValue ( getPrefs ( ) . getInt ( EventServiceSettings . APP_CHOOSER_TIMEOUT , 15 ) ) ; mChooserTimeout . setOnPreferenceChangeListener ( this ) ; < |startfocus| > boolean locationDisabled = Settings . Secure . getInt ( getActivity ( ) . getContentResolver ( ) , < |endfocus| > Settings . Secure . LOCATION_MODE , - 1 ) == 0 ; mDisableWifi = ( SeekBarPreference ) findPreference ( DISABLE_WIFI_THRESHOLD ) ; mDisableWifi . setValue ( getPrefs ( ) . getInt ( EventServiceSettings . DISABLE_WIFI_THRESHOLD , 0 ) ) ; mDisableWifi . setOnPreferenceChangeListener ( this ) ; mDisableWifi . setEnabled ( ! locationDisabled ) ; homeWifi = findPreference ( HOME_WIFI_PREFERENCE_SCREEN ) ; homeWifi . setEnabled ( ! locationDisabled ) ; workWifi = findPreference ( WORK_WIFI_PREFERENCE_SCREEN ) ; workWifi . setEnabled ( ! locationDisabled ) ; if ( locationDisabled ) { mDisableWifi . setSummary ( R . string . wifi_location_disabled ) ; homeWifi . setSummary ( R . string . wifi_location_disabled ) ;
public void onReceive ( Context context , Intent intent ) { String action = intent . getAction ( ) ; mWakeLock . acquire ( ) ; try { if ( DEBUG ) Log . d ( TAG , "onReceive " + action ) ; < |startfocus| > boolean disableIfMusicActive = getPrefs ( context ) . getBoolean ( EventServiceSettings . EVENT_MUSIC_ACTIVE , false ) ; < |endfocus| > boolean autoRun = getPrefs ( context ) . getBoolean ( EventServiceSettings . EVENT_AUTORUN_SINGLE , true ) ; boolean closeApp = getPrefs ( context ) . getBoolean ( EventServiceSettings . EVENT_DISCONNECT_HEADSET_OR_A2DP , false ) ; switch ( action ) { case BluetoothAdapter . ACTION_STATE_CHANGED : if ( intent . getIntExtra ( BluetoothAdapter . EXTRA_STATE , - 1 ) == BluetoothAdapter . STATE_OFF ) { mA2DPConnected = false ; } break ; case BluetoothA2dp . ACTION_CONNECTION_STATE_CHANGED : int state = intent . getIntExtra ( BluetoothProfile . EXTRA_STATE , BluetoothProfile . STATE_CONNECTED ) ; if ( state == BluetoothProfile . STATE_CONNECTED && ! mA2DPConnected ) { mA2DPConnected = true ; if ( DEBUG ) Log . d ( TAG , "BluetoothProfile . STATE_CONNECTED = true" ) ; if ( autoRun ) { if ( DEBUG ) Log . d ( TAG , "BluetoothProfile . STATE_CONNECTED = true" ) ;
private static final int KEY_MASK_BACK = 0x02 ; private static final int KEY_MASK_MENU = 0x04 ; private static final int KEY_MASK_ASSIST = 0x08 ; private static final int KEY_MASK_APP_SWITCH = 0x10 ; private CheckBoxPreference mVolumeWake ; // private CheckBoxPreference mVolumeMusicControl ; private CheckBoxPreference mSwapVolumeButtons ; // private ListPreference mVolumeKeyCursorControl ; private SwitchPreference mEnableCustomBindings ; private ListPreference mBackPressAction ; private ListPreference mBackLongPressAction ; private ListPreference mHomePressAction ; private ListPreference mHomeLongPressAction ; private ListPreference mHomeDoubleTapAction ; < |startfocus| > private CheckBoxPreference mHomeAnswerCall ; < |endfocus| > private ListPreference mMenuPressAction ; private ListPreference mMenuLongPressAction ; private ListPreference mAssistPressAction ; private ListPreference mAssistLongPressAction ; private ListPreference mAppSwitchPressAction ; private ListPreference mAppSwitchLongPressAction ; private Map < String , Integer > mKeySettings = new HashMap < String , Integer > ( ) ; // private ListPreference mVolumeDefault ; // private CheckBoxPreference mHeadsetHookLaunchVoice ; // private CheckBoxPreference mVirtualKeyHapticFeedback ; // private CheckBoxPreference mForceShowOverflowMenu ; // private CheckBoxPreference mCameraWakeScreen ; // private CheckBoxPreference mCameraSleepOnRelease ; // private CheckBoxPreference mCameraLaunch ; // private CheckBoxPreference mVolumeRockerWake ; // private CheckBoxPreference mVolumeRockerMusicControl ; // private CheckBoxPreference mVolumeRockerKeyboardControl ; // private CheckBoxPreference mPowerEndCall ; // private CheckBoxPreference mHomeWake ; // private CheckBoxPreference mBackWake ; // private CheckBoxPreference mMenuWake ; // private CheckBoxPreference mAssistWake ; // private CheckBoxPreference mAppSwitchWake ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDoubleTapPowerGesture ; // private CheckBoxPreference mCameraDouble
mGestureButtonHandler . sendEmptyMessageDelayed ( MSG_SEND_SWITCH_KEY , ( long ) GESTURE_KEY_DISTANCE_TIMEOUT ) ; } } mLastX = rawX ; mLastY = rawY ; break ; } else if ( mLongClick && mPreparedKeycode == 3 ) { mGestureButtonHandler . removeMessages ( MSG_SEND_SWITCH_KEY ) ; mGestureButtonHandler . sendEmptyMessageDelayed ( MSG_SEND_SWITCH_KEY , ( long ) GESTURE_KEY_DISTANCE_TIMEOUT ) ; mPreparedKeycode = 0 ; mLongClick = false ; } break ; < |startfocus| > case 3 : < |endfocus| > break ; default : break ; } // mSwipeStartFromEdge = false ; // mSwipeLongFireable = false ; } }
/* * * The animation property used for the icon when its isolation ends . * This animates the translation back to the right position . */ private static final AnimationProperties UNISOLATION_PROPERTY = new AnimationProperties ( ) { private AnimationFilter mAnimationFilter = new AnimationFilter ( ) . animateX ( ) ; @Override public AnimationFilter getAnimationFilter ( ) { return mAnimationFilter ; } } . setDuration ( CONTENT_FADE_DURATION ) ; < |startfocus| > private int MAX_VISIBLE_ICONS_WHEN_DARK = 5 ; private int MAX_STATIC_ICONS = 4 ; < |endfocus| > private static final int MAX_DOTS = 1 ; private boolean mIsStaticLayout = true ; private final HashMap < View , IconState > mIconStates = new HashMap < > ( ) ; private int mDotPadding ; private int mMaxVisibleIconsWhenDark ; private int mMaxStaticIcons ; private int mStaticDotRadius ; private int mStaticDotDiameter ; private int mOverflowWidth ; private int mActualLayoutWidth = NO_VALUE ; private float mActualPaddingEnd = NO_VALUE ; private float mActualPaddingStart = NO_VALUE ; private boolean mDark ;
* This animates the translation back to the right position . */ private static final AnimationProperties UNISOLATION_PROPERTY = new AnimationProperties ( ) { private AnimationFilter mAnimationFilter = new AnimationFilter ( ) . animateX ( ) ; @Override public AnimationFilter getAnimationFilter ( ) { return mAnimationFilter ; } } . setDuration ( CONTENT_FADE_DURATION ) ; < |startfocus| > public final int MAX_VISIBLE_ICONS_WHEN_DARK = getResources ( ) . getInteger ( R . integer . config_maxVisibleNotificationIconsWhenDark ) ; public final int MAX_STATIC_ICONS = getResources ( ) . getInteger ( R . integer . config_maxVisibleNotificationIcons ) ; < |endfocus| > private static final int MAX_DOTS = 1 ; private boolean mIsStaticLayout = true ; private final HashMap < View , IconState > mIconStates = new HashMap < > ( ) ; private int mDotPadding ; private int mStaticDotRadius ; private int mStaticDotDiameter ; private int mOverflowWidth ; private int mActualLayoutWidth = NO_VALUE ; private float mActualPaddingEnd = NO_VALUE ; private float mActualPaddingStart = NO_VALUE ; private boolean mDark ; private boolean mChangingViewPositions ; private int mAddAnimationStartIndex = - 1 ; private int mMaxVisibleIconsWhenDark ; private int mMaxVisibleIcons ;
< |startfocus| > private void initDimens ( ) { public final int MAX_VISIBLE_ICONS_WHEN_DARK = getResources ( ) . getInteger ( R . integer . config_maxVisibleNotificationIconsWhenDark ) ; public final int MAX_STATIC_ICONS = getResources ( ) . getInteger ( R . integer . config_maxVisibleNotificationIcons ) ; < |endfocus| > private static final int MAX_DOTS = 1 ; private static final int MAX_DOTS = 1 ;
toastText = com . android . internal . R . string . volume_dialog_ringer_guidance_silent_no_media ; break ; case VOLUME_HUSH_VIBRATE : effect = VibrationEffect . get ( VibrationEffect . EFFECT_HEAVY_CLICK ) ; ringerMode = AudioManager . RINGER_MODE_VIBRATE ; toastText = com . android . internal . R . string . volume_dialog_ringer_guidance_vibrate ; break ; } maybeVibrate ( effect ) ; setRingerModeInternal ( ringerMode , reason ) ; < |startfocus| > // Use the SystemUI context , so it gets themed properly . Context context = ActivityThread . currentActivityThread ( ) . getSystemUiContext ( ) ; Toast . makeText ( context , toastText , Toast . LENGTH_SHORT ) . show ( ) ; < |endfocus| >
boolean result = false ; try { logger . info ( "provisionONT begin" ) ; AddOntMessage request = AddOntMessage . newBuilder ( ) . setCLLI ( clli ) . setPortNumber ( portNumber ) . setSlotNumber ( slotNumber ) . setOntNumber ( ontNumber ) . setSerialNumber ( serialNumber ) . build ( ) ; AddOntReturn response = blockingStub . provisionOnt ( request ) ; result = response . getSuccess ( ) ; < |startfocus| > logger . info ( "provisionONT with device id : { } success : { } " , serialNumber , result ) ; < |endfocus| > } catch ( RuntimeException e ) { logger . log ( Level . WARNING , "provisionONT RPC failed" , e ) ; } return result ;
private static final Logger logger = Logger . getLogger ( AbstractOLTServer . class . getName ( ) ) ; @Override public void echo ( EchoMessage request , StreamObserver < EchoReplyMessage > responseObserver ) { } @Override public void createChassis ( AddChassisMessage request , StreamObserver < AddChassisReturn > responseObserver ) { AddChassisReturn response = AddChassisReturn . newBuilder ( ) . setDeviceID ( request . getCLLI ( ) ) . build ( ) ; responseObserver . onNext ( response ) ; responseObserver . onCompleted ( ) ; < |startfocus| > logger . info ( "createChassis with clli : { } " + request . getCLLI ( ) ) ; < |endfocus| > } @Override public void createOLTChassis ( AddOLTChassisMessage request , StreamObserver < AddOLTChassisReturn > responseObserver ) { AddOLTChassisReturn response = AddOLTChassisReturn . newBuilder ( ) . setDeviceID ( UUID . randomUUID ( ) . toString ( ) ) . setChassisDeviceID ( request . getCLLI ( ) ) . build ( ) ; responseObserver . onNext ( response ) ; responseObserver . onCompleted ( ) ; logger . info ( "createOLTChassis with clli : { } " + request . getCLLI ( ) ) ; } @Override public void provisionOnt ( AddOntMessage request , StreamObserver < AddOntReturn > responseObserver ) { AddOntReturn response = AddOntReturn . newBuilder ( ) . setSuccess ( true ) . build ( ) ;
public void removeSubscriber ( ConnectPoint port ) { AccessDeviceData olt = oltData . get ( port . deviceId ( ) ) ; if ( olt == null ) { log . warn ( "No data found for OLT device { } " , port . deviceId ( ) ) ; return ; } < |startfocus| > VlanId subscriberVlan = subscribers . remove ( port ) ; if ( subscriberVlan == null ) { log . warn ( "Unknown subscriber at location { } " , port ) ; < |endfocus| > return ; } if ( enableDhcpIgmpOnProvisioning ) { processDhcpFilteringObjectives ( olt . deviceId ( ) , port . port ( ) , false ) ; } unprovisionSubscriber ( olt . deviceId ( ) , olt . uplink ( ) , port . port ( ) , subscriberVlan , olt . vlan ( ) , olt . defaultVlan ( ) ) ; if ( enableDhcpIgmpOnProvisioning ) { processIgmpFilteringObjectives ( olt . deviceId ( ) , port . port ( ) , false ) ; }
for ( FunctionalExchange anExchange : getAvailableFunctionalExchangesToInsert ( functionView ) ) { AbstractFunction targetFunction = null ; if ( EcoreUtil . isAncestor ( function , anExchange . getSource ( ) ) && anExchange . getTarget ( ) . eContainer ( ) instanceof AbstractFunction ) { targetFunction = ( AbstractFunction ) anExchange . getTarget ( ) . eContainer ( ) ; } else if ( anExchange . getSource ( ) . eContainer ( ) instanceof AbstractFunction ) { targetFunction = ( AbstractFunction ) anExchange . getSource ( ) . eContainer ( ) ; } < |startfocus| > // TODO : add this function to the cache < |endfocus| > DNodeContainer visibleFunctionInDiagram = getDisplayedFunctionContainer ( targetFunction , functionContainersInDiagram ) ; if ( visibleFunctionInDiagram != null ) { if ( isValidCreationCategoryBetweenViews ( anExchange , functionView , visibleFunctionInDiagram ) ) { targetFunction = ( AbstractFunction ) visibleFunctionInDiagram . getTarget ( ) ; } else { targetFunction = null ; } } if ( targetFunction != null ) { for ( ExchangeCategory aCategory : anExchange . getCategories ( ) ) { returnedMap . put ( aCategory , targetFunction ) ; } } } return returnedMap ; }
import org . polarsys . capella . core . model . handler . command . CapellaResourceHelper ; /* * * An { @link ECrossReferenceAdapter } that only takes capella resources into account . */ public class CapellaECrossReferenceAdapter extends SiriusCrossReferenceAdapter { class CapellaInverseCrossReferencer extends InverseCrossReferencer { /* * * Generated serial UID . */ private static final long serialVersionUID = - 3473829340961544993L ; @Override protected void addProxy ( EObject proxy , EObject context ) { // Do nothing to avoid keeping EObjects turn into proxies during the whole application life . } < |startfocus| > /* * * { @inheritDoc } */ @Override protected boolean resolve ( ) { return CapellaECrossReferenceAdapter . this . resolve ( ) ; } < |endfocus| > } WeakReference < EditingDomain > _editingDomain ; public CapellaECrossReferenceAdapter ( EditingDomain editingDomain , Session session , ResourceSet set ) { super ( set , ( DAnalysisSessionImpl ) session ) ; _editingDomain = new WeakReference < EditingDomain > ( editingDomain ) ; } /* * * Adapt all references of specified object against the inverse cross referencer . < br > */ @Override protected void adapt ( EObject eObject ) { if ( eObject . eResource ( ) != null ) { if ( CapellaResourceHelper . isCapellaResource ( eObject . eResource ( ) ) ) { super . adapt ( eObject ) ; } } } /* * * { @inheritDoc } */ @Override protected InverseCrossReferencer createInverseCrossReferencer ( ) { return new CapellaInverseCrossReferencer ( ) ; } /* * * { @inheritDoc } */ @Override protected boolean resolve ( ) { EditingDomain editingDomain = _editingDomain . get ( ) ; if ( editingDomain != null ) { return super . resolve ( ) ; } return false ; } }
private static final String MIGRATED_FITLER_EXT = " . filter" ; private static final String FRAGMENT_SEPARATOR = "\\@" ; private static final String FILTER_SEPARATOR = "\\'" ; private static final String FRAGMENT_FILTER_KEY = "filters" ; private static final String PLUGIN_TYPE = "plugin" ; private static final String VALID_PLUGIN = "org . polarsys . capella . core . sirius . analysis" ; private static final String DESCRIPTION_TYPE = "description" ; private Map < DiagramDescription , Set < String > > validFilterNames ; < |startfocus| > private Map < String , String > filterNameExceptions ; < |endfocus| > public FilterMigrationContribution ( ) { validFilterNames = new HashMap < > ( ) ; filterNameExceptions = new HashMap < > ( ) ; filterNameExceptions . put ( "ShowEIExchangeContext" , "show . ei . exchange . context . filter" ) ; filterNameExceptions . put ( "CEParam" , "show . ce . param . filter" ) ; filterNameExceptions . put ( "CEEIParam" , "show . ce . ei . param . filter" ) ; filterNameExceptions . put ( "ShowFEExchangeContex" , "show . fe . exchange . context . filter" ) ; filterNameExceptions . put ( "ShowCEExchangeContext" , "show . ce . exchange . context . filter" ) ; } @Override
import org . polarsys . capella . core . model . helpers . BlockArchitectureExt ; import org . polarsys . capella . core . model . helpers . ComponentExt ; import org . polarsys . capella . core . ui . properties . fields . AbstractSemanticField ; import org . polarsys . capella . core . ui . properties . fields . MultipleSemanticField ; /* * * The Component section . */ public abstract class ComponentSection extends GeneralizableElementSection { private boolean showIsHuman ; private boolean showIsActor ; private boolean showImplementedInterfaces ; private boolean showUsedInterfaces ; private boolean showAllocatedFunctions ; < |startfocus| > protected HumanCheckbox isHumanCheckbox ; protected ActorCheckbox isActorCheckbox ; < |endfocus| > private MultipleSemanticField implementedInterfaces ; private MultipleSemanticField usedInterfaces ; protected MultipleSemanticField allocatedFunctions ; /* * * Default constructor . */ public ComponentSection ( ) { this ( true , true , true , true , true , true , true ) ; } /* * * Constructor . * @param showImplementedInterfaces * @param showUsedInterfaces * @param showAllocatedFunctions * @param showSuperTypes * @param showIsAbstract */
if ( null != propertiesCheckbox ) { propertiesCheckbox . setEnabled ( component . isActor ( ) ) ; } if ( null != isHumanCheckbox ) { isHumanCheckbox . loadData ( component ) ; // if the component is an OE , // if the component is a system , // if the component has children , boolean isOperationalEntity = block instanceof OperationalAnalysis && ! component . isActor ( ) ; boolean isSystem = component == block . getSystem ( ) ; boolean hasChildren = ComponentExt . isComposite ( component ) ; // then the IsHuman checkbox must be disabled < |startfocus| > if ( isHumanCheckbox . isEnabled ( ) && ( isOperationalEntity || isSystem || hasChildren ) ) { < |endfocus| > isHumanCheckbox . setEnabled ( false ) ; } } if ( null != isActorCheckbox ) { isActorCheckbox . loadData ( component ) ; // if the component is in SA level , // if the component is a system , // if the component is an actor and its container cannot have a component , // if the component is a component and its container cannot have an actor , boolean isSystemAnalysis = block instanceof SystemAnalysis ;
boolean condition1 = block instanceof SystemAnalysis ; boolean condition2 = component == block . getSystem ( ) ; boolean condition3 = component . isActor ( ) && ! ComponentExt . canCreateABComponent ( component . eContainer ( ) ) ; boolean condition4 = ! component . isActor ( ) && ! ComponentExt . canCreateABActor ( component . eContainer ( ) ) ; // then the IsActor checkbox must be disabled < |startfocus| > if ( isActorCheckbox . isEnabled ( ) && ( condition1 || condition2 || condition3 || condition4 ) ) { < |endfocus| > isActorCheckbox . setEnabled ( false ) ; } } if ( null != implementedInterfaces ) { implementedInterfaces . loadData ( component , CsPackage . Literals . COMPONENT__OWNED_INTERFACE_IMPLEMENTATIONS ) ; } if ( null != usedInterfaces ) { usedInterfaces . loadData ( component , CsPackage . Literals . COMPONENT__OWNED_INTERFACE_USES ) ; } if ( null != allocatedFunctions ) { allocatedFunctions . loadData ( component , FaPackage . Literals . ABSTRACT_FUNCTIONAL_BLOCK__OWNED_FUNCTIONAL_ALLOCATION ) ; }
/* ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * Copyright ( c ) 2006 , 2015 THALES GLOBAL SERVICES . * All rights reserved . This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1 . 0 * which accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html * * Contributors : * Thales - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . polarsys . capella . docgen . util . pattern . helper ; import java . util . ArrayList ; import java . util . Collection ; import org . polarsys . capella . core . data . fa . FunctionalExchange ; import org . polarsys . capella . core . data . oa . CommunicationMean ; import org . polarsys . capella . core . data . oa . Entity ; import org . polarsys . capella . common . data . modellingcore . AbstractInformationFlow ; import org . polarsys . capella . common . data . modellingcore . InformationsExchanger ; import org . polarsys . capella . docgen . util . CapellaServices ; import org . polarsys . capella . docgen . util . StringUtil ; public class CapellaEntityHelper { 	public static Collection < String > getIncomingCommunicationMeansLines ( Entity entity , String projectName , String outputFolder ) { 		Collection < String > ret = new ArrayList < String > ( ) ; 		for ( AbstractInformationFlow abstractInformationFlow : entity . getIncomingInformationFlows ( ) ) { 			if ( abstractInformationFlow instanceof CommunicationMean ) { 				CommunicationMean communicationMean = ( CommunicationMean ) abstractInformationFlow ; 				ret . add ( CapellaServices . getImageLinkFromElement ( communicationMean , projectName , outputFolder ) + StringUtil . escapeHTML ( communicationMean . getName ( ) ) ) ; 			 } 		 } 		return ret ; 	 } 	public static Collection < String > getOutgoingCommunicationMeansLines ( Entity entity , String projectName , String outputFolder ) { 		Collection < String > ret = new ArrayList < String > ( ) ; 		for ( AbstractInformationFlow abstractInformationFlow : entity . getOutgoingInformationFlows ( ) ) { 			if ( abstractInformationFlow instanceof CommunicationMean ) { 				CommunicationMean communicationMean = ( CommunicationMean ) abstractInformationFlow ; 				ret . add ( CapellaServices . getImageLinkFromElement ( communicationMean , projectName , outputFolder ) + StringUtil . escapeHTML ( communicationMean . getName ( ) ) ) ; 			 } 		 } 		return ret ; 	 } 	public static Collection < String > getIncomingFunctionalExchangesLines ( Entity entity , String projectName , String outputFolder ) { 		Collection < String > ret = new ArrayList < String > ( ) ; 		for ( InformationsExchanger informationsExchanger : entity . getIncomingInformationFlows ( ) ) { 			if ( informationsExchanger instanceof FunctionalExchange ) { 				FunctionalExchange functionalExchange = ( FunctionalExchange ) informationsExchanger ; 				ret . add ( CapellaServices . getImageLinkFromElement ( functionalExchange , projectName , outputFolder ) + StringUtil . escapeHTML ( functionalExchange . getName ( ) ) ) ; 			 } 		 } 		return ret ; 	 } 	public static Collection < String > getOutgoingFunctionalExchangesLines ( Entity entity , String projectName , String outputFolder ) { 		Collection < String > ret = new ArrayList < String > ( ) ; 		for ( InformationsExchanger informationsExchanger : entity . getOutgoingInformationFlows ( ) ) { 			if ( informationsExchanger instanceof FunctionalExchange ) { 				FunctionalExchange functionalExchange = ( FunctionalExchange ) informationsExchanger ; 				ret . add ( CapellaServices . getImageLinkFromElement ( functionalExchange , projectName , outputFolder ) + StringUtil . escapeHTML ( functionalExchange . getName ( ) ) ) ; 			 } 		 } 		return ret ; 	 } }
** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * < |startfocus| > * Copyright ( c ) 2006 , 2018 THALES GLOBAL SERVICES . < |endfocus| > * All rights reserved . This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1 . 0 * which accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html * * Contributors : * Thales - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** / package org . polarsys . capella . docgen . util ; import java . util . ArrayList ; import java . util . Collection ; import java . util . HashSet ; import java . util . Iterator ; import java . util . List ; import java . util . Set ; import org . eclipse . emf . common . util . EList ; import org . eclipse . emf . ecore . EObject ; import org . polarsys . capella . core . data . cs . Component ; import org . polarsys . capella . core . data . cs . Interface ; import org . polarsys . capella . core . data . fa . AbstractFunction ; import org . polarsys . capella . core . data . fa . ComponentExchange ; import org . polarsys . capella . core . data . fa . ComponentExchangeEnd ; import org . polarsys . capella . core . data . fa . ComponentExchangeKind ; import org . polarsys . capella . core . data . fa . ComponentPort ; import org . polarsys . capella . core . data . fa . FunctionalExchange ;
/* ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** * Copyright ( c ) 2006 , 2017 THALES GLOBAL SERVICES . * All rights reserved . This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1 . 0 * which accompanies this distribution , and is available at * http :/ / www . eclipse . org / legal / epl - v10 . html * * Contributors : * Thales - initial API and implementation ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** */ package org . polarsys . capella . docgen . util . pattern . helper ; import java . util . ArrayList ; import java . util . Collection ; import java . util . HashMap ; import java . util . Map ; import org . polarsys . capella . common . data . modellingcore . ModelElement ; import org . polarsys . capella . core . data . cs . Interface ; import org . polarsys . capella . core . data . fa . ComponentExchange ; import org . polarsys . capella . core . data . fa . ComponentExchangeKind ; import org . polarsys . capella . core . data . fa . ComponentPort ; import org . polarsys . capella . core . data . information . ExchangeItem ; import org . polarsys . capella . docgen . util . CapellaServices ; import org . polarsys . capella . docgen . util . StringUtil ; public class CapellaComponentPortHelper { 	 /* * 	 * Get the provided interfaces of a ComponentPort as html 	 * 	 * @param componentPort 	 * @return 	 */ 	public static String getProvidedInterfaces ( ComponentPort componentPort ) { 		StringBuffer buffer = new StringBuffer ( ) ; 		Collection < Interface > providedInterfaces = componentPort . getProvidedInterfaces ( ) ; 		if ( providedInterfaces . size ( ) > 0 ) { 			buffer . append ( " < ul > " ) ; 			for ( Interface providedInterface : providedInterfaces ) { 				buffer . append ( " < li > " ) ; 				buffer . append ( CapellaServices . getImageLinkFromElement ( providedInterface ) ) ; 				buffer . append ( CapellaServices . getHyperlinkFromElement ( providedInterface ) ) ; 				buffer . append ( " </ li > " ) ; 			 } 			buffer . append ( " </ ul > " ) ; 		 } 		return buffer . toString ( ) ; 	 } 	 /* * 	 * Get the required interfaces of a ComponentPort as html 	 * 	 * @param componentPort 	 * @return 	 */ 	public static String getRequiredInterfaces ( ComponentPort componentPort ) { 		StringBuffer buffer = new StringBuffer ( ) ; 		Collection < Interface > requiredInterfaces = componentPort . getRequiredInterfaces ( ) ; 		if ( requiredInterfaces . size ( ) > 0 ) { 			buffer . append ( " < ul > " ) ; 			for ( Interface requiredInterface : requiredInterfaces ) { 				buffer . append ( " < li > " ) ; 				buffer . append ( CapellaServices . getImageLinkFromElement ( requiredInterface ) ) ; 				buffer . append ( CapellaServices . getHyperlinkFromElement ( requiredInterface ) ) ; 				buffer . append ( " </ li > " ) ; 			 } 			buffer . append ( " </ ul > " ) ; 		 } 		return buffer . toString ( ) ; 	 } 	 /* * 	 * Get the provided exchange items of a ComponentPort as html 	 * 	 * @param componentPort 	 * @return 	 */ 	public static String getProvidedExchangeItems ( ComponentPort componentPort ) { 		StringBuffer buffer = new StringBuffer ( ) ; 		Collection < ExchangeItem > providedExchangeItems = componentPort . getProvidedExchangeItems ( ) ; 		if ( providedExchangeItems . size ( ) > 0 ) { 			buffer . append ( " < ul > " ) ; 			for ( ExchangeItem providedExchangeItem : providedExchangeItems ) { 				buffer . append ( " < li > " ) ; 				buffer . append ( CapellaServices . getImageLinkFromElement ( providedExchangeItem ) ) ; 				buffer . append ( CapellaServices . getHyperlinkFromElement ( providedExchangeItem ) ) ; 				buffer . append ( " </ li > " ) ; 			 } 			buffer . append ( " </ ul > " ) ; 		 } 		return buffer . toString ( ) ; 	 } 	 /* * 	 * Get the required exchange items of a ComponentPort as html 	 * 	 * @param componentPort 	 * @return 	 */ 	public static String getRequiredExchangeItems ( ComponentPort componentPort ) { 		StringBuffer buffer = new StringBuffer ( ) ; 		Collection < ExchangeItem > requiredExchangeItems = componentPort . getRequiredExchangeItems ( ) ; 		if ( requiredExchangeItems . size ( ) > 0 ) { 			buffer . append ( " < ul > " ) ; 			for ( ExchangeItem requiredExchangeItem : requiredExchangeItems ) { 				buffer . append ( " < li > " ) ; 				buffer . append ( CapellaServices . getImageLinkFromElement ( requiredExchangeItem ) ) ; 				buffer . append ( CapellaServices . getHyperlinkFromElement ( requiredExchangeItem ) ) ; 				buffer . append ( " </ li > " ) ; 			 } 			buffer . append ( " </ ul > " ) ; 		 } 		return buffer . toString ( ) ; 	 } }
EList < EObject > objects = new BasicEList < EObject > ( ) ; objects . add ( repTarget ) ; if ( repTarget instanceof Part ) { objects . addAll ( resolveReferencedElements ( ( ( Part ) repTarget ) . getAbstractType ( ) ) ) ; } if ( repTarget instanceof InstanceRole ) { objects . addAll ( resolveReferencedElements ( ( ( InstanceRole ) repTarget ) . getRepresentedInstance ( ) ) ) ; } if ( repTarget instanceof StateFragment ) { objects . addAll ( resolveReferencedElements ( ( ( StateFragment ) repTarget ) . getRelatedAbstractFunction ( ) ) ) ; } return objects ; } /* * < |startfocus| > < < < < < < < HEAD < |endfocus| > * Scrutinize all EOI ( element of interest : See * { @link org . polarsys . capella . core . diagram . helpers . naming . DAnnotationSourceConstants . CAPELLA_ELEMENT_OF_INTEREST } ) * annotation of all representation descriptors to find all representations * which are interested by the semantic element * * @param semanticElement * to find all representation interested by it * @return a collection of representations interested by semantic element . If * there are no representation , empty collection is returned */ public static Collection < DDiagram > getAllInterestedRepresentationsFor ( EObject semanticElement ) {

<|startcomment|> it would probably be a good idea to define this as a static, then use that anywhere you need to return -1. <|endcomment|>  import java.util.ArrayList; /** * This class provides helper functions for Wifi connectivity related modules to * access WifiNative. It starts with firmware roaming. TODO(b/34819513): Move operations * such as connection to network and legacy framework roaming here. */ public class WifiConnectivityHelper { private static final String TAG = "WifiConnectivityHelper"; private final WifiNative mWifiNative; private boolean mFirmwareRoamingSupported = false; <|startfocus|> private int mMaxNumBlacklistBssid = -1; private int mMaxNumWhitelistSsid = -1; <|endfocus|> WifiConnectivityHelper(WifiNative wifiNative) { mWifiNative = wifiNative; } /** * Query firmware if it supports * {@link android.net.wifi.WifiManager#WIFI_FEATURE_CONTROL_ROAMING}. If yes, get the firmware * roaming capabilities. */ public void getFirmwareRoamingInfo() { int fwFeatureSet = mWifiNative.getSupportedFeatureSet(); Log.d(TAG, "Firmware supported feature set: " + Integer.toHexString(fwFeatureSet)); mFirmwareRoamingSupported = (fwFeatureSet & WIFI_FEATURE_CONTROL_ROAMING) > 0;
<|startcomment|> there is no way for the caller to know if this failed. What should the proper operation be? What could cause the getRoamingCapabilities to fail? Should this then report that firmware roaming is not supported so the framework code can do the roams instead of relying on faulty firmware? or is this a sign that something major happened? Do we need to restart anything? <|endcomment|>  mMaxNumWhitelistSsid = -1; if (mFirmwareRoamingSupported) { WifiNative.RoamingCapabilities roamingCap = new WifiNative.RoamingCapabilities(); if (mWifiNative.getRoamingCapabilities(roamingCap)) { mMaxNumBlacklistBssid = roamingCap.maxBlacklistSize; mMaxNumWhitelistSsid = roamingCap.maxWhitelistSize; Log.d(TAG, "Firmware roaming capabilities: max num blacklist bssid=" + mMaxNumBlacklistBssid + " max num whitelist ssid=" + mMaxNumWhitelistSsid); } else { Log.e(TAG, "Failed to get firmware roaming capabilities"); <|startfocus|> } <|endfocus|> }
<|startcomment|> would be good to document the return value. <|endcomment|>  mMaxNumWhitelistSsid = roamingCap.maxWhitelistSize; Log.d(TAG, "Firmware roaming capabilities: max num blacklist bssid=" + mMaxNumBlacklistBssid + " max num whitelist ssid=" + mMaxNumWhitelistSsid); } else { Log.e(TAG, "Failed to get firmware roaming capabilities"); } } } /** * Return if firmware roaming is supported. */ public boolean isFirmwareRoamingSupported() { return mFirmwareRoamingSupported; } /** <|startfocus|> * Return the maximum size of BSSID blacklist. <|endfocus|> */ public int getMaxNumBlacklistBssid() { if (mFirmwareRoamingSupported) { return mMaxNumBlacklistBssid; } else { Log.e(TAG, "Firmware roaming is not supported"); return -1; } } /** * Return the maximum size of SSID whitelist. */ public int getMaxNumWhitelistSsid() { if (mFirmwareRoamingSupported) { return mMaxNumWhitelistSsid; } else { Log.e(TAG, "Firmware roaming is not supported"); return -1; } } /**
<|startcomment|> else not needed here. the normal case will return <|endcomment|>  public int getMaxNumBlacklistBssid() { if (mFirmwareRoamingSupported) { return mMaxNumBlacklistBssid; } else { <|startfocus|> Log.e(TAG, "Firmware roaming is not supported"); return -1; <|endfocus|> }
<|startcomment|> maybe add something like "MaxNumBlacklistBssid invalid: "... then what you have here. <|endcomment|>  public int getMaxNumBlacklistBssid() { if (mFirmwareRoamingSupported) { return mMaxNumBlacklistBssid; } else { <|startfocus|> Log.e(TAG, "Firmware roaming is not supported"); return -1; <|endfocus|> }
<|startcomment|> else not needed since the normal case will return the value <|endcomment|>  public int getMaxNumWhitelistSsid() { if (mFirmwareRoamingSupported) { return mMaxNumWhitelistSsid; } else { <|startfocus|> Log.e(TAG, "Firmware roaming is not supported"); return -1; <|endfocus|> }
<|startcomment|> WifiConnectivityHelperTest <|endcomment|>  /** Sets up test. */ @Before public void setUp() throws Exception { MockitoAnnotations.initMocks(this); setupWifiNative(); mWifiConnectivityHelper = new WifiConnectivityHelper(mWifiNative); } /** Cleans up test. */ @After public void cleanup() { validateMockitoUsage(); } private WifiConnectivityHelper mWifiConnectivityHelper; @Mock private WifiNative mWifiNative; @Captor ArgumentCaptor<WifiNative.RoamingConfig> mRoamingConfigCaptor; private int mFeatureSetValue; <|startfocus|> private static final String TAG = "WifiConnectivityHelper Unit Test"; <|endfocus|> private static final int MAX_BSSID_BLACKLIST_SIZE = 16; private static final int MAX_SSID_WHITELIST_SIZE = 8; private void setupWifiNative() { // Return firmware roaming feature as supported by default. when(mWifiNative.getSupportedFeatureSet()).thenReturn(WIFI_FEATURE_CONTROL_ROAMING); doAnswer(new AnswerWithArguments() { public boolean answer(WifiNative.RoamingCapabilities roamCap) throws Exception { roamCap.maxBlacklistSize = MAX_BSSID_BLACKLIST_SIZE; roamCap.maxWhitelistSize = MAX_SSID_WHITELIST_SIZE; return true;
<|startcomment|> you shouldn't need to set this, correct? the false should prevent you from attempting to read the values. <|endcomment|>  public void verifyFirmwareRoamingCapabilityWithFailureNativeCall() { doAnswer(new AnswerWithArguments() { public boolean answer(WifiNative.RoamingCapabilities roamCap) throws Exception { roamCap.maxBlacklistSize = -1; roamCap.maxWhitelistSize = -1; return false; }}).when(mWifiNative).getRoamingCapabilities(anyObject()); <|startfocus|> mWifiConnectivityHelper.getFirmwareRoamingInfo(); assertEquals(-1, mWifiConnectivityHelper.getMaxNumBlacklistBssid()); assertEquals(-1, mWifiConnectivityHelper.getMaxNumWhitelistSsid()); <|endfocus|>
<|startcomment|> can you also please verify that sizes below the max are written? <|endcomment|>  public void verifySetFirmwareRoamingConfigurationWithGoodInput() { <|startfocus|> mWifiConnectivityHelper.getFirmwareRoamingInfo(); <|endfocus|> ArrayList<String> blacklist = buildBssidBlacklist(MAX_BSSID_BLACKLIST_SIZE); ArrayList<String> whitelist = buildSsidWhitelist(MAX_SSID_WHITELIST_SIZE); assertTrue(mWifiConnectivityHelper.setFirmwareRoamingConfiguration(blacklist, whitelist));
<|startcomment|> Consider dropping the else, and just moving the remainder of the function up one level. (Functionally equivalent; I just find less nesting easier to read.) <|endcomment|>  * [or other varieties of that API]. * * * @hide */ public String createNetworkSpecifierPassphrase(@Nullable PeerHandle peerHandle, @NonNull String passphrase) { if (passphrase == null || passphrase.length() == 0) { throw new IllegalArgumentException("Passphrase must not be null or empty"); } if (mTerminated) { Log.w(TAG, "createNetworkSpecifierPassphrase: called on terminated session"); return null; <|startfocus|> } else { WifiAwareManager mgr = mMgr.get(); if (mgr == null) { Log.w(TAG, "createNetworkSpecifierPassphrase: called post GC on WifiAwareManager"); return null; } <|endfocus|> int role = this instanceof SubscribeDiscoverySession ? WifiAwareManager.WIFI_AWARE_DATA_PATH_ROLE_INITIATOR : WifiAwareManager.WIFI_AWARE_DATA_PATH_ROLE_RESPONDER; return mgr.createNetworkSpecifier(mClientId, role, mSessionId, peerHandle, null, passphrase); } } /** * Create a {@link android.net.NetworkRequest.Builder#setNetworkSpecifier(String)} for an
<|startcomment|> 2017 <|endcomment|> <|startfocus|> * Copyright (C) 2016 The Android Open Source Project <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ import java.lang.reflect.Method; public class Main { // Workaround for b/18051191. class InnerClass {} public static void main(String[] args) throws Exception { Class<?> c = Class.forName("IrreducibleLoop"); Method m = c.getMethod("simpleLoop", int.class); Object[] arguments = { 42 }; System.out.println(m.invoke(null, arguments)); } } 
<|startcomment|> Maybe use ArrayDeque<>.remove(), instead? (Just a little bit shorter.) <|endcomment|>  boolean waitForCallback(int callback) { synchronized (mLocalLock) { <|startfocus|> Iterator<Integer> it = mCallbackQueue.iterator(); while (it.hasNext()) { if (it.next() == callback) { it.remove(); return true; } <|endfocus|> } mCurrentWaitForCallback = callback; mBlocker = new CountDownLatch(1); } try { return mBlocker.await(WAIT_FOR_AWARE_CHANGE_SECS, TimeUnit.SECONDS); } catch (InterruptedException e) { return false; }
<|startcomment|> Maybe use ArrayDeque<>.contains(), instead? <|endcomment|>  boolean hasCallbackAlreadyHappened(int callback) { synchronized (mLocalLock) { <|startfocus|> Iterator<Integer> it = mCallbackQueue.iterator(); while (it.hasNext()) { if (it.next() == callback) { return true; } } <|endfocus|> } return false;
<|startcomment|> Maybe "subscribe"? <|endcomment|>  public void testSubscribeDiscoverySuccess() { if (!TestUtils.shouldTestWifiAware(getContext())) { return; } final String serviceName = "ValidName"; WifiAwareSession session = attachAndGetSession(); SubscribeConfig subscribeConfig = new SubscribeConfig.Builder().setServiceName( serviceName).build(); DiscoverySessionCallbackTest discoveryCb = new DiscoverySessionCallbackTest(); <|startfocus|> // 1. publish <|endfocus|> session.subscribe(subscribeConfig, discoveryCb, null); assertTrue("Subscribe started", discoveryCb.waitForCallback(DiscoverySessionCallbackTest.ON_SUBSCRIBE_STARTED)); SubscribeDiscoverySession discoverySession = discoveryCb.getSubscribeDiscoverySession(); assertNotNull("Subscribe session", discoverySession); // 2. update-subscribe subscribeConfig = new SubscribeConfig.Builder().setServiceName( serviceName).setServiceSpecificInfo("extras".getBytes()).build(); discoverySession.updateSubscribe(subscribeConfig); assertTrue("Subscribe update", discoveryCb.waitForCallback( DiscoverySessionCallbackTest.ON_SESSION_CONFIG_UPDATED)); // 3. destroy assertFalse("Subscribe not terminated", discoveryCb.hasCallbackAlreadyHappened( DiscoverySessionCallbackTest.ON_SESSION_TERMINATED)); discoverySession.destroy(); 
<|startcomment|> Should we call mMediaRecorder.setCamera(mCamera) here? I mean it looks more strait forward to set the camera for MediaRecorder after we query/setup the resolution. <|endcomment|>  assertTrue("Incorrect longitude: " + longitude, Math.abs(longitude - LONGITUDE) <= TOLERANCE); retriever.release(); return true; } private void checkOutputExist() { assertTrue(mOutFile.exists()); assertTrue(mOutFile.length() > 0); assertTrue(mOutFile.delete()); } public void testRecorderVideo() throws Exception { if (!hasCamera()) { return; } mCamera = Camera.open(0); setSupportedResolution(mCamera); <|startfocus|> mCamera.release(); mCamera = null; <|endfocus|> mMediaRecorder.setVideoSource(MediaRecorder.VideoSource.CAMERA); mMediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.DEFAULT); mMediaRecorder.setOutputFile(OUTPUT_PATH2); mMediaRecorder.setVideoEncoder(MediaRecorder.VideoEncoder.DEFAULT); mMediaRecorder.setPreviewDisplay(mActivity.getSurfaceHolder().getSurface()); mMediaRecorder.setVideoSize(mVideoWidth, mVideoHeight); FileOutputStream fos = new FileOutputStream(OUTPUT_PATH2); FileDescriptor fd = fos.getFD(); mMediaRecorder.setOutputFile(fd); long maxFileSize = MAX_FILE_SIZE * 10; recordMedia(maxFileSize, mOutFile2);
<|startcomment|> ditto. <|endcomment|>  assertNotNull(durationStr); return Integer.parseInt(durationStr); } public void testSetMaxFileSize() throws Exception { testSetMaxFileSize(512 * 1024, 50 * 1024); } private void testSetMaxFileSize( long fileSize, long tolerance) throws Exception { if (!hasMicrophone() || !hasCamera() || !hasAmrNb() || !hasH264()) { MediaUtils.skipTest("no microphone, camera, or codecs"); return; } mCamera = Camera.open(0); setSupportedResolution(mCamera); <|startfocus|> mCamera.release(); mCamera = null; <|endfocus|> mMediaRecorder.setAudioSource(MediaRecorder.AudioSource.MIC); mMediaRecorder.setVideoSource(MediaRecorder.VideoSource.CAMERA); mMediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP); mMediaRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AMR_NB); mMediaRecorder.setVideoEncoder(MediaRecorder.VideoEncoder.H264); mMediaRecorder.setVideoSize(mVideoWidth, mVideoHeight); mMediaRecorder.setVideoEncodingBitRate(256000); mMediaRecorder.setPreviewDisplay(mActivity.getSurfaceHolder().getSurface()); mMediaRecorder.setMaxFileSize(fileSize); mMediaRecorder.prepare(); mMediaRecorder.start(); 
<|startcomment|> LGTM. Actually there are 2 instances of getPackageInfo in SMSDispatcher.java and 2 in SmsApplication.java as well, should we fix them as well? Also not sure if this change will fail unit test or not because there is 1 instance in TelephonyTest.java as well. <|endcomment|>  // Refuse to send SMS if we can't get the calling package name. Rlog.e(TAG, "Can't get calling app package name: refusing to send SMS"); tracker.onFailed(mContext, RESULT_ERROR_GENERIC_FAILURE, 0/*errorCode*/); return; } // Get package info via packagemanager PackageInfo appInfo; try { // XXX this is lossy- apps can share a UID appInfo = pm.getPackageInfoAsUser(packageNames[0], PackageManager.GET_SIGNATURES, <|startfocus|> mContext.getUserId()); <|endfocus|> } catch (PackageManager.NameNotFoundException e) { Rlog.e(TAG, "Can't get calling app package info: refusing to send SMS"); tracker.onFailed(mContext, RESULT_ERROR_GENERIC_FAILURE, 0/*errorCode*/); return; } // checkDestination() returns true if the destination is not a premium short code or the // sending app is approved to send to short codes. Otherwise, a message is sent to our // handler with the SmsTracker to request user confirmation before sending. if (checkDestination(tracker)) {
<|startcomment|> nit: no need, we will release the camera in tear down. <|endcomment|>  mMediaRecorder.setVideoEncoder(MediaRecorder.VideoEncoder.DEFAULT); mMediaRecorder.setPreviewDisplay(mActivity.getSurfaceHolder().getSurface()); mMediaRecorder.setVideoSize(mVideoWidth, mVideoHeight); FileOutputStream fos = new FileOutputStream(OUTPUT_PATH2); FileDescriptor fd = fos.getFD(); mMediaRecorder.setOutputFile(fd); long maxFileSize = MAX_FILE_SIZE * 10; recordMedia(maxFileSize, mOutFile2); assertFalse(checkLocationInFile(OUTPUT_PATH2)); fos.close(); <|startfocus|> mCamera.release(); mCamera = null; <|endfocus|> } public void testRecordingAudioInRawFormats() throws Exception { int testsRun = 0; if (hasAmrNb()) { testsRun += testRecordAudioInRawFormat( MediaRecorder.OutputFormat.AMR_NB, MediaRecorder.AudioEncoder.AMR_NB); } if (hasAmrWb()) { testsRun += testRecordAudioInRawFormat( MediaRecorder.OutputFormat.AMR_WB, MediaRecorder.AudioEncoder.AMR_WB); } if (hasAac()) { testsRun += testRecordAudioInRawFormat( MediaRecorder.OutputFormat.AAC_ADTS, MediaRecorder.AudioEncoder.AAC); }
<|startcomment|> ditto <|endcomment|>  mMediaRecorder.setPreviewDisplay(mActivity.getSurfaceHolder().getSurface()); mMediaRecorder.setMaxFileSize(fileSize); mMediaRecorder.prepare(); mMediaRecorder.start(); // Recording a scene with moving objects would greatly help reduce // the time for waiting. if (!mMaxFileSizeCond.block(MAX_FILE_SIZE_TIMEOUT_MS)) { fail("timed out waiting for MEDIA_RECORDER_INFO_MAX_FILESIZE_REACHED"); } mMediaRecorder.stop(); checkOutputFileSize(OUTPUT_PATH, fileSize, tolerance); <|startfocus|> mCamera.release(); mCamera = null; <|endfocus|> } private void checkOutputFileSize(final String fileName, long fileSize, long tolerance) { assertTrue(mOutFile.exists()); assertEquals(fileSize, mOutFile.length(), tolerance); assertTrue(mOutFile.delete()); } public void testOnErrorListener() throws Exception { if (!hasMicrophone() || !hasAmrNb()) { MediaUtils.skipTest("no audio codecs or microphone"); return; } mMediaRecorder.setAudioSource(MediaRecorder.AudioSource.DEFAULT); mMediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP);
<|startcomment|> Calling .setCamera significantly changes the codepath executed in the media service, so this substantially changes code coverage, etc; I don't think you want to change that. Without this, media service will instantiate its own camera client in the mediaserver process; otherwise, it will proxy through the app's camera client. Both routes need testing, so we don't want to switch from one to the other without making sure both routes are still covered sufficiently. <|endcomment|>  assertTrue("Incorrect longitude: " + longitude, Math.abs(longitude - LONGITUDE) <= TOLERANCE); retriever.release(); return true; } private void checkOutputExist() { assertTrue(mOutFile.exists()); assertTrue(mOutFile.length() > 0); assertTrue(mOutFile.delete()); } public void testRecorderVideo() throws Exception { if (!hasCamera()) { return; } mCamera = Camera.open(0); setSupportedResolution(mCamera); mCamera.unlock(); <|startfocus|> mMediaRecorder.setCamera(mCamera); <|endfocus|> mMediaRecorder.setVideoSource(MediaRecorder.VideoSource.CAMERA); mMediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.DEFAULT); mMediaRecorder.setOutputFile(OUTPUT_PATH2); mMediaRecorder.setVideoEncoder(MediaRecorder.VideoEncoder.DEFAULT); mMediaRecorder.setPreviewDisplay(mActivity.getSurfaceHolder().getSurface()); mMediaRecorder.setVideoSize(mVideoWidth, mVideoHeight); FileOutputStream fos = new FileOutputStream(OUTPUT_PATH2); FileDescriptor fd = fos.getFD(); mMediaRecorder.setOutputFile(fd); long maxFileSize = MAX_FILE_SIZE * 10; recordMedia(maxFileSize, mOutFile2);
<|startcomment|> Hal (not caps) <|endcomment|>  || regState == ServiceState.RIL_REG_STATE_DENIED) { rejectCode = Integer.parseInt(states[13]); } } if (states.length > 14) { if (states[14] != null && states[14].length() > 0) { psc = (int)Long.parseLong(states[14], 16); } } } catch (NumberFormatException ex) { loge("error parsing RegistrationState: " + ex); } } <|startfocus|> mGsmRoaming = regCodeIsRoaming(regState); mNewSS.setVoiceRegState(regCodeToServiceState(regState)); mNewSS.setRilVoiceRadioTechnology(type); mNewRejectCode = rejectCode; <|endfocus|> boolean isVoiceCapable = mPhone.getContext().getResources() .getBoolean(com.android.internal.R.bool.config_voice_capable); if ((regState == ServiceState.RIL_REG_STATE_DENIED_EMERGENCY_CALL_ENABLED || regState == ServiceState.RIL_REG_STATE_NOT_REG_EMERGENCY_CALL_ENABLED || regState == ServiceState.RIL_REG_STATE_SEARCHING_EMERGENCY_CALL_ENABLED
<|startcomment|> If the HalRegState is really constrained to Hal it should get translated before it leaves Ril.java. If it's not it should probably be just convertRegStateToServiceState Looking at this furtuer this appear to not be regState -> ServiceState but Hal -> AOSP. Does anybody above RIL.java need the RegState version? <|endcomment|> <|startfocus|> private int convertHalRegStateToServiceState(int regState) { <|endfocus|> switch (regState) { case RegState.NOT_REG_MT_NOT_SEARCHING_OP: return ServiceState.RIL_REG_STATE_NOT_REG; case RegState.REG_HOME: return ServiceState.RIL_REG_STATE_HOME; case RegState.NOT_REG_MT_SEARCHING_OP: return ServiceState.RIL_REG_STATE_SEARCHING; case RegState.REG_DENIED: return ServiceState.RIL_REG_STATE_DENIED; case RegState.UNKNOWN: return ServiceState.RIL_REG_STATE_UNKNOWN; case RegState.REG_ROAMING: return ServiceState.RIL_REG_STATE_ROAMING; case RegState.NOT_REG_MT_NOT_SEARCHING_OP_EM: return ServiceState.RIL_REG_STATE_NOT_REG_EMERGENCY_CALL_ENABLED; case RegState.NOT_REG_MT_SEARCHING_OP_EM: return ServiceState.RIL_REG_STATE_SEARCHING_EMERGENCY_CALL_ENABLED; case RegState.REG_DENIED_EM: return ServiceState.RIL_REG_STATE_DENIED_EMERGENCY_CALL_ENABLED; case RegState.UNKNOWN_EM: return ServiceState.RIL_REG_STATE_UNKNOWN_EMERGENCY_CALL_ENABLED; default: return ServiceState.REGISTRATION_STATE_NOT_REGISTERED_AND_NOT_SEARCHING; }
<|startcomment|> why did you move this if nobody else in-scope is using? Please put back to tightest scoping.. <|endcomment|>  if (DBG) { log("handlPollVoiceRegResultMessage: regState=" + registrationState + " radioTechnology=" + voiceRegStateResult.rat); } break; } case EVENT_POLL_STATE_GPRS: { DataRegStateResult dataRegStateResult = (DataRegStateResult) ar.result; int regState = convertHalRegStateToServiceState(dataRegStateResult.regState); int dataRegState = regCodeToServiceState(regState); int newDataRat = dataRegStateResult.rat; <|startfocus|> int oldDataRAT = mSS.getRilDataRadioTechnology(); <|endfocus|> mNewSS.setDataRegState(dataRegState); mNewSS.setRilDataRadioTechnology(newDataRat); if (mPhone.isPhoneTypeGsm()) { mNewReasonDataDenied = dataRegStateResult.reasonDataDenied; mNewMaxDataCalls = dataRegStateResult.maxDataCalls; mDataRoaming = regCodeIsRoaming(regState); if (DBG) { log("handlPollStateResultMessage: GsmSST setDataRegState=" + dataRegState + " regState=" + regState + " dataRadioTechnology=" + newDataRat); } } else if (mPhone.isPhoneTypeCdma()) { 
<|startcomment|> 26+? I suspect it's TBD, same as other lines in this change. <|endcomment|>  * <td>TLS_DHE_RSA_WITH_3DES_EDE_CBC_SHA</td> * <td>1&ndash;8</td> * <td>1&ndash;8</td> * </tr> * <tr class="deprecated"> * <td>TLS_DHE_RSA_WITH_AES_128_CBC_SHA</td> * <td>9&ndash;TBD</td> * <td>9&ndash;TBD</td> * </tr> * <tr class="deprecated"> * <td>TLS_DHE_RSA_WITH_AES_128_CBC_SHA256</td> <|startfocus|> * <td>20&ndash;26+</td> <|endfocus|> * <td></td> * </tr> * <tr class="deprecated"> * <td>TLS_DHE_RSA_WITH_AES_128_GCM_SHA256</td> * <td>20&ndash;TBD</td> * <td>20&ndash;TBD</td> * </tr> * <tr class="deprecated"> * <td>TLS_DHE_RSA_WITH_AES_256_CBC_SHA</td> * <td>9&ndash;TBD</td> * <td>20&ndash;TBD</td> * </tr> * <tr class="deprecated">
<|startcomment|> Nit: Could probably be called ReadTimeout again. <|endcomment|>  } } } @Test public void testSocketConnectTimeout() throws Exception { // #connect(SocketAddress endpoint, int timeout) checkOperationTimesOut(() -> new Socket(), s -> s.connect(UNREACHABLE_ADDRESS, TIMEOUT_MILLIS)); // Setting SO_TIMEOUT should not affect connect timeout. checkOperationTimesOut(() -> new Socket(), s -> { s.setSoTimeout(TIMEOUT_MILLIS / 2); s.connect(UNREACHABLE_ADDRESS, TIMEOUT_MILLIS); }); } @Test <|startfocus|> public void testSocketIOStreamTimeout() throws Exception { <|endfocus|> // #read() try (ServerSocket ss = new ServerSocket(0)) { // The server socket will accept the connection without explicitly calling accept() due // to TCP backlog. checkOperationTimesOut(() -> new Socket(), s -> { s.connect(ss.getLocalSocketAddress()); s.setSoTimeout(TIMEOUT_MILLIS); s.getInputStream().read(); }); } } @Test public void testSocketWriteNeverTimeouts() throws Exception {
<|startcomment|> We can wait a reasonable time here to be sure. I'd personally do an absolute of + 1000 for this. 100 millis doesn't seem like much to me, and we'd end up passing if we didn't actually wait long enough. <|endcomment|>  writeCompleted.countDown(); } catch (IOException ignored) { } finally { writeCompleted.countDown(); } }); thread.start(); // Wait for the thread to start. assertTrue(threadStarted.await(500, TimeUnit.MILLISECONDS)); // Wait for TIMEOUT_MILLIS + slop. If write does not complete by then, we assume it has // blocked. boolean blocked = <|startfocus|> !writeCompleted.await((long) (TIMEOUT_MILLIS * 1.2f), TimeUnit.MILLISECONDS); <|endfocus|> assertTrue(blocked); // Make sure the writing thread completes after the socket is closed. sock.close(); assertTrue(writeCompleted.await(5000, TimeUnit.MILLISECONDS)); } } @Test public void testServerSocketAcceptTimeout() throws Exception { // #accept() checkOperationTimesOut(() -> new ServerSocket(0), s -> { s.setSoTimeout(TIMEOUT_MILLIS); s.accept(); }); } @Test public void testServerSocketChannelAcceptTimeout() throws Exception { // #accept() checkOperationTimesOut(() -> ServerSocketChannel.open(), s -> {
<|startcomment|> could probably combine these into one log line: maybe something like "Firmware roaming supported with capabilities:..." <|endcomment|>  if (roamingCap.maxBlacklistSize < 0 || roamingCap.maxWhitelistSize < 0) { Log.e(TAG, "Invalid firmware roaming capabilities: max num blacklist bssid=" + roamingCap.maxBlacklistSize + " max num whitelist ssid=" + roamingCap.maxWhitelistSize); } else { mFirmwareRoamingSupported = true; mMaxNumBlacklistBssid = roamingCap.maxBlacklistSize; mMaxNumWhitelistSsid = roamingCap.maxWhitelistSize; <|startfocus|> Log.d(TAG, "Firmware roaming is supported"); Log.d(TAG, "Firmware roaming capabilities: max num blacklist bssid=" <|endfocus|> + mMaxNumBlacklistBssid + " max num whitelist ssid=" + mMaxNumWhitelistSsid); return true; } } else { Log.e(TAG, "Failed to get firmware roaming capabilities"); } return false;
<|startcomment|> indent here looks off, either 8 spaces in from the line start above or lined up with the A in ArrayList above. <|endcomment|>  public boolean setFirmwareRoamingConfiguration(ArrayList<String> blacklistBssids, <|startfocus|> ArrayList<String> whitelistSsids) { <|endfocus|> if (!mFirmwareRoamingSupported) { Log.e(TAG, "Firmware roaming is not supported"); return false; } if (blacklistBssids == null || whitelistSsids == null) { Log.e(TAG, "Invalid firmware roaming configuration settings"); return false; } int blacklistSize = blacklistBssids.size(); int whitelistSize = whitelistSsids.size(); if (blacklistSize > mMaxNumBlacklistBssid || whitelistSize > mMaxNumWhitelistSsid) { Log.e(TAG, "Invalid BSSID blacklist size " + blacklistSize + " SSID whitelist size " + whitelistSize + ". Max blacklist size: " + mMaxNumBlacklistBssid + ", max whitelist size: " + mMaxNumWhitelistSsid); return false; } WifiNative.RoamingConfig roamConfig = new WifiNative.RoamingConfig(); roamConfig.blacklistBssids = blacklistBssids; roamConfig.whitelistSsids = whitelistSsids; return mWifiNative.configureRoaming(roamConfig);
<|startcomment|> should have an error message <|endcomment|>  public boolean requestIcon(String bssid, String fileName) { <|startfocus|> if (bssid == null || fileName == null) return false; <|endfocus|> return mSupplicantStaIfaceHal.initiateHs20IconQuery(bssid, fileName);
<|startcomment|> startMonitoring <|endcomment|>  * limitations under the License. */ package com.android.server.wifi; import static org.junit.Assert.assertTrue; import static org.mockito.Mockito.mock; import android.os.Handler; import android.os.Message; import android.util.SparseArray; import java.util.HashMap; import java.util.Map; /** * Creates a mock WifiMonitor. * WARNING: This does not perfectly mock the behavior of WifiMonitor at the moment <|startfocus|> * ex. startMoniroting does nothing and will not send a connection/disconnection event <|endfocus|> */ public class MockWifiMonitor extends WifiMonitor { private final Map<String, SparseArray<Handler>> mHandlerMap = new HashMap<>(); public MockWifiMonitor() { super(mock(WifiInjector.class)); } @Override public void registerHandler(String iface, int what, Handler handler) { SparseArray<Handler> ifaceHandlers = mHandlerMap.get(iface); if (ifaceHandlers == null) { ifaceHandlers = new SparseArray<>(); mHandlerMap.put(iface, ifaceHandlers); } ifaceHandlers.put(what, handler); } @Override
<|startcomment|> This returns a string <|endcomment|>  result.setResult(mISupplicantP2pIface.startWpsPinKeypad(groupIfName, pin)); } catch (RemoteException e) { Log.e(TAG, "ISupplicantP2pIface exception: " + e); supplicantServiceDiedHandler(); } return result.isSuccess(); } } /** * Initiate WPS Pin Display setup. * * @param groupIfName Group interface name to use. * @param bssid BSSID of the AP. Use zero'ed bssid to indicate wildcard. <|startfocus|> * @return true, if operation was successful. <|endfocus|> */ public String startWpsPinDisplay(String groupIfName, String bssid) { if (TextUtils.isEmpty(groupIfName) || TextUtils.isEmpty(bssid)) return null; synchronized (mLock) { if (!checkSupplicantP2pIfaceAndLogFailure("startWpsPinDisplay")) return null; if (groupIfName == null) { Log.e(TAG, "Group name required when requesting WPS KEYPAD."); return null; } // Null values should be fine, since bssid can be empty. byte[] macAddress = null; if (bssid != null) {
<|startcomment|> This comment is not true anymore, is it? <|endcomment|>  public WifiNative(String interfaceName, WifiVendorHal vendorHal, SupplicantStaIfaceHal staIfaceHal, SupplicantP2pIfaceHal p2pIfaceHal, WificondControl condControl) { mTAG = "WifiNative-" + interfaceName; mInterfaceName = interfaceName; mWifiVendorHal = vendorHal; mSupplicantStaIfaceHal = staIfaceHal; mSupplicantP2pIfaceHal = p2pIfaceHal; mWificondControl = condControl; } public String getInterfaceName() { return mInterfaceName; } <|startfocus|> // Note this affects logging on for all interfaces <|endfocus|> public void enableVerboseLogging(int verbose) { mWificondControl.enableVerboseLogging(verbose > 0 ? true : false); mSupplicantStaIfaceHal.enableVerboseLogging(verbose > 0); mWifiVendorHal.enableVerboseLogging(verbose > 0); } /******************************************************** * Native Initialization/Deinitialization ********************************************************/ /** * Setup wifi native for Client mode operations. * * 1. Starts the Wifi HAL and configures it in client/STA mode. * 2. Setup Wificond to operate in client mode and retrieve the handle to use for client * operations. *
<|startcomment|> This should be a 'start' shouldn't it? <|endcomment|>  public boolean startFilteringMulticastV4Packets() { return mSupplicantStaIfaceHal.stopRxFilter() && mSupplicantStaIfaceHal.removeRxFilter( SupplicantStaIfaceHal.RX_FILTER_TYPE_V4_MULTICAST) <|startfocus|> && mSupplicantStaIfaceHal.stopRxFilter(); <|endfocus|>
<|startcomment|> Start? <|endcomment|>  public boolean stopFilteringMulticastV4Packets() { return mSupplicantStaIfaceHal.stopRxFilter() && mSupplicantStaIfaceHal.addRxFilter( SupplicantStaIfaceHal.RX_FILTER_TYPE_V4_MULTICAST) <|startfocus|> && mSupplicantStaIfaceHal.stopRxFilter(); <|endfocus|>
<|startcomment|> start <|endcomment|>  public boolean startFilteringMulticastV6Packets() { return mSupplicantStaIfaceHal.stopRxFilter() && mSupplicantStaIfaceHal.removeRxFilter( SupplicantStaIfaceHal.RX_FILTER_TYPE_V6_MULTICAST) <|startfocus|> && mSupplicantStaIfaceHal.stopRxFilter(); <|endfocus|>
<|startcomment|> start <|endcomment|>  public boolean stopFilteringMulticastV6Packets() { return mSupplicantStaIfaceHal.stopRxFilter() && mSupplicantStaIfaceHal.addRxFilter( SupplicantStaIfaceHal.RX_FILTER_TYPE_V6_MULTICAST) <|startfocus|> && mSupplicantStaIfaceHal.stopRxFilter(); <|endfocus|>
<|startcomment|> soon is now? <|endcomment|>  public boolean setSerialNumber(String value) { return mSupplicantStaIfaceHal.setWpsSerialNumber(value); } public void setPowerSave(boolean enabled) { mSupplicantStaIfaceHal.setPowerSave(enabled); } /** * "sta" prioritizes STA connection over P2P and "p2p" prioritizes * P2P connection over STA */ public boolean setConcurrencyPriority(boolean isStaHigherPriority) { return mSupplicantStaIfaceHal.setConcurrencyPriority(isStaHigherPriority); } <|startfocus|> /** WifiSupplicantControl methods. TODO: These should use HIDL soon. */ <|endfocus|> /** * Migrate all the configured networks from wpa_supplicant. * * @param configs Map of configuration key to configuration objects corresponding to all * the networks. * @param networkExtras Map of extra configuration parameters stored in wpa_supplicant.conf * @return Max priority of all the configs. */ public boolean migrateNetworksFromSupplicant(Map<String, WifiConfiguration> configs, SparseArray<Map<String, String>> networkExtras) { return mSupplicantStaIfaceHal.loadNetworks(configs, networkExtras); } /**
<|startcomment|> no longer necessary. <|endcomment|>  /** * Handler to notify the occurrence of various events during PNO scan. */ public interface PnoEventHandler { /** * Callback to notify when one of the shortlisted networks is found during PNO scan. * @param results List of Scan results received. */ void onPnoNetworkFound(ScanResult[] results); /** * Callback to notify when the PNO scan schedule fails. */ void onPnoScanFailed(); } <|startfocus|> /* scan status, keep these values in sync with gscan.h */ <|endfocus|> public static final int WIFI_SCAN_RESULTS_AVAILABLE = 0; public static final int WIFI_SCAN_THRESHOLD_NUM_SCANS = 1; public static final int WIFI_SCAN_THRESHOLD_PERCENT = 2; public static final int WIFI_SCAN_FAILED = 3; public boolean startScan(ScanSettings settings, ScanEventHandler eventHandler) { return mWifiVendorHal.startScan(settings, eventHandler); } public void stopScan() { mWifiVendorHal.stopScan(); } public void pauseScan() { mWifiVendorHal.pauseScan(); } 
<|startcomment|> Maybe add a TODO w/ a bugid to rm calling code. <|endcomment|>  public void setWifiLinkLayerStats(String iface, int enable) { <|startfocus|> // Nothing to do here. Link layer stats is enabled when the HAL is started. <|endfocus|>
<|startcomment|> If you add the missing space, will checkstyle punish you by requiring javadoc? :-) <|endcomment|> <|startfocus|> public boolean isGetChannelsForBandSupported(){ <|endfocus|> return mWifiVendorHal.isGetChannelsForBandSupported();
<|startcomment|> My comment on line 1151 belongs here. <|endcomment|>  void onWifiAlert(int errorCode, byte[] buffer); } public boolean setLoggingEventHandler(WifiLoggerEventHandler handler) { return mWifiVendorHal.setLoggingEventHandler(handler); } public boolean startLoggingRingBuffer(int verboseLevel, int flags, int maxInterval, int minDataSize, String ringName){ return mWifiVendorHal.startLoggingRingBuffer( verboseLevel, flags, maxInterval, minDataSize, ringName); } public int getSupportedLoggerFeatureSet() { return mWifiVendorHal.getSupportedLoggerFeatureSet(); } <|startfocus|> <|endfocus|> public boolean resetLogHandler() { return mWifiVendorHal.resetLogHandler(); } public String getDriverVersion() { return mWifiVendorHal.getDriverVersion(); } public String getFirmwareVersion() { return mWifiVendorHal.getFirmwareVersion(); } public static class RingBufferStatus{ String name; int flag; int ringBufferId; int ringBufferByteSize; int verboseLevel; int writtenBytes; int readBytes; int writtenRecords; // Bit masks for interpreting |flag| public static final int HAS_BINARY_ENTRIES = (1 << 0);
<|startcomment|> why call it earfcn then? Shouldn't it be freq? <|endcomment|>  * @hide */ public static final String KEY_NOTIFY_INTERNATIONAL_CALL_ON_WFC_BOOL = "notify_international_call_on_wfc_bool"; /** * Offset to be reduced from rsrp threshold while calculating signal strength level. * @hide */ public static final String KEY_SIGNAL_STRENGTH_OFFSET_INT = "signal_strength_offset_int"; /** * Threshold of EARFCN above which signal_strength_offset_int will be applied. <|startfocus|> * Unit of this value should be in MHz. <|endfocus|> * @hide */ public static final String KEY_SIGNAL_STRENGTH_EAFCN_THRESHOD_INT = "signal_strength_earfcn_threshold_int"; /** The default value for every variable. */ private final static PersistableBundle sDefaults; static { sDefaults = new PersistableBundle(); sDefaults.putBoolean(KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL, true); sDefaults.putBoolean(KEY_ADDITIONAL_CALL_SETTING_BOOL, true); sDefaults.putBoolean(KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL, false); sDefaults.putBoolean(KEY_ALLOW_LOCAL_DTMF_TONES_BOOL, true);
<|startcomment|> typo <|endcomment|>  "notify_international_call_on_wfc_bool"; /** * Offset to be reduced from rsrp threshold while calculating signal strength level. * @hide */ public static final String KEY_SIGNAL_STRENGTH_OFFSET_INT = "signal_strength_offset_int"; /** * Threshold of EARFCN above which signal_strength_offset_int will be applied. * Unit of this value should be in MHz. * @hide */ <|startfocus|> public static final String KEY_SIGNAL_STRENGTH_EAFCN_THRESHOD_INT = <|endfocus|> "signal_strength_earfcn_threshold_int"; /** The default value for every variable. */ private final static PersistableBundle sDefaults; static { sDefaults = new PersistableBundle(); sDefaults.putBoolean(KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL, true); sDefaults.putBoolean(KEY_ADDITIONAL_CALL_SETTING_BOOL, true); sDefaults.putBoolean(KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL, false); sDefaults.putBoolean(KEY_ALLOW_LOCAL_DTMF_TONES_BOOL, true); sDefaults.putBoolean(KEY_APN_EXPAND_BOOL, true); sDefaults.putBoolean(KEY_AUTO_RETRY_ENABLED_BOOL, false);
<|startcomment|> There are a number of apps that use this API. It should be deprecated and a new one added with p2. <|endcomment|>  * * <p>Requires Permission: * {@link android.Manifest.permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE} * Or the calling app has carrier privileges. @see #hasCarrierPrivileges * * @param AID Application id. See ETSI 102.221 and 101.220. * @param p2 P2 parameter (described in ISO 7816-4). Default value: 0x00 * @return an IccOpenLogicalChannelResponse object. */ <|startfocus|> public IccOpenLogicalChannelResponse iccOpenLogicalChannel(String AID, byte p2) { <|endfocus|> return iccOpenLogicalChannel(getSubId(), AID, p2); } /** * Opens a logical channel to the ICC card. * * Input parameters equivalent to TS 27.007 AT+CCHO command. * * <p>Requires Permission: * {@link android.Manifest.permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE} * Or the calling app has carrier privileges. @see #hasCarrierPrivileges * * @param subId The subscription to use. * @param AID Application id. See ETSI 102.221 and 101.220.
<|startcomment|> oneshot <|endcomment|>  * limitations under the License. */ package com.android.server.wifi.scanner; import android.content.Context; import android.net.wifi.WifiScanner; import android.os.Handler; import android.os.Looper; import android.os.Message; import android.util.Log; import com.android.server.wifi.Clock; import com.android.server.wifi.WifiNative; /** * WifiScanner implementation that takes advantage of the gscan HAL API <|startfocus|> * The gscan API is used to perform background scans and wificond is used for onehot scans. <|endfocus|> * @see com.android.server.wifi.scanner.WifiScannerImpl for more details on each method. */ public class HalWifiScannerImpl extends WifiScannerImpl implements Handler.Callback { private static final String TAG = "HalWifiScannerImpl"; private static final boolean DBG = false; private final WifiNative mWifiNative; private final ChannelHelper mChannelHelper; private final WificondScannerImpl mWificondScannerDelegate; private final boolean mHalBasedPnoSupported; public HalWifiScannerImpl(Context context, WifiNative wifiNative, Looper looper, Clock clock) { mWifiNative = wifiNative; mChannelHelper = new HalChannelHelper(wifiNative);
<|startcomment|> looks like this slipped back in <|endcomment|>  * limitations under the License. */ package com.android.server.wifi.scanner; import android.content.Context; import android.net.wifi.WifiScanner; import android.os.Handler; import android.os.Looper; import android.os.Message; import android.util.Log; import com.android.server.wifi.Clock; import com.android.server.wifi.WifiMonitor; import com.android.server.wifi.WifiNative; /** * WifiScanner implementation that takes advantage of the gscan HAL API <|startfocus|> * The gscan API is used to perform background scans and wificond is used for onehot scans. <|endfocus|> * @see com.android.server.wifi.scanner.WifiScannerImpl for more details on each method. */ public class HalWifiScannerImpl extends WifiScannerImpl implements Handler.Callback { private static final String TAG = "HalWifiScannerImpl"; private static final boolean DBG = false; private final WifiNative mWifiNative; private final ChannelHelper mChannelHelper; private final WificondScannerImpl mWificondScannerDelegate; private final boolean mHalBasedPnoSupported; public HalWifiScannerImpl(Context context, WifiNative wifiNative, WifiMonitor wifiMonitor, Looper looper, Clock clock) {
<|startcomment|> Nit: formatting. <|endcomment|>  public void describeTo(Description description) { <|startfocus|> description.appendText(toString()); <|endfocus|>
<|startcomment|> Just nits. Personal preference: The "see " is implicit. I personally prefer a leading http://b/ so I can click on it in an IDE (for sure) & gerrit (I think). The bug reference is probably superfluous in this case; not sure what people would gain from looking at the bug. Judgement call, though. Would apply to both. <|endcomment|>  String[] s; s = params.getCipherSuites(); if (s != null) { setEnabledCipherSuites(s); } s = params.getProtocols(); if (s != null) { setEnabledProtocols(s); } if (params.getNeedClientAuth()) { setNeedClientAuth(true); } else if (params.getWantClientAuth()) { setWantClientAuth(true); } else { setWantClientAuth(false); } } <|startfocus|> // Android-added: Make toString explicit that this is an SSLServerSocket (see b/6602228) <|endfocus|> @Override public String toString() { return "SSL" + super.toString(); } } 
<|startcomment|> Nit: extra white space. <|endcomment|>  */ public void receivedWnmFrame(WnmData data) { mHandler.notifyWnmFrameReceived(data); } /** * Request the specified icon file |fileName| from the specified AP |bssid|. * @return true if the request is sent successfully, false otherwise */ public boolean queryPasspointIcon(long bssid, String fileName) { return mHandler.requestIcon(bssid, fileName); } /** <|startfocus|> * Lookup the ANQP elements associated with the given AP from the cache. An empty map <|endfocus|> * will be returned if no match found in the cache. * * @param scanResult The scan result associated with the AP * @return Map of ANQP elements */ public Map<Constants.ANQPElementType, ANQPElement> getANQPElements(ScanResult scanResult) { // Retrieve the Hotspot 2.0 Vendor Specific IE. InformationElementUtil.Vsa vsa = InformationElementUtil.getHS2VendorSpecificIE(scanResult.informationElements); // Lookup ANQP data in the cache. long bssid = Utils.parseMac(scanResult.BSSID); ANQPData anqpEntry = mAnqpCache.getEntry(ANQPNetworkKey.buildKey(
<|startcomment|> Maybe move this to @return? <|endcomment|>  mHandler.notifyWnmFrameReceived(data); } /** * Request the specified icon file |fileName| from the specified AP |bssid|. * @return true if the request is sent successfully, false otherwise */ public boolean queryPasspointIcon(long bssid, String fileName) { return mHandler.requestIcon(bssid, fileName); } /** <|startfocus|> * Lookup the ANQP elements associated with the given AP from the cache. An empty map <|endfocus|> * will be returned if no match found in the cache. * * @param scanResult The scan result associated with the AP * @return Map of ANQP elements */ public Map<Constants.ANQPElementType, ANQPElement> getANQPElements(ScanResult scanResult) { // Retrieve the Hotspot 2.0 Vendor Specific IE. InformationElementUtil.Vsa vsa = InformationElementUtil.getHS2VendorSpecificIE(scanResult.informationElements); // Lookup ANQP data in the cache. long bssid = Utils.parseMac(scanResult.BSSID); ANQPData anqpEntry = mAnqpCache.getEntry(ANQPNetworkKey.buildKey( scanResult.SSID, bssid, scanResult.hessid, vsa.anqpDomainID));
<|startcomment|> no need to do this. At this stage setSpeakerphoneOn(true/false) should not be called as this only applies to in call state. Hall, Why was it called in the first place? Is it a way to reset speakerphone state before starting the call? <|endcomment|>  public void enter() { super.enter(); <|startfocus|> if (!mBluetoothRouteManager.isInbandRingingEnabled()) { setSpeakerphoneOn(false); } <|endfocus|> CallAudioState newState = new CallAudioState(mIsMuted, ROUTE_BLUETOOTH, mAvailableRoutes); setSystemAudioState(newState); updateInternalCallAudioState();
<|startcomment|> this is ok as long as the behavior is going to be the same as earlier when API didn't have p2 as a parameter. <|endcomment|>  * {@link android.Manifest.permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE} * Or the calling app has carrier privileges. @see #hasCarrierPrivileges * * @param AID Application id. See ETSI 102.221 and 101.220. * @return an IccOpenLogicalChannelResponse object. * @deprecated Replaced by {@link #iccOpenLogicalChannel(String, byte)} */ @Deprecated public IccOpenLogicalChannelResponse iccOpenLogicalChannel(String AID) { <|startfocus|> return iccOpenLogicalChannel(getSubId(), AID, (byte) 0x00); <|endfocus|> } /** * Opens a logical channel to the ICC card. * * Input parameters equivalent to TS 27.007 AT+CCHO command. * * <p>Requires Permission: * {@link android.Manifest.permission#MODIFY_PHONE_STATE MODIFY_PHONE_STATE} * Or the calling app has carrier privileges. @see #hasCarrierPrivileges * * @param AID Application id. See ETSI 102.221 and 101.220. * @param p2 P2 parameter (described in ISO 7816-4). Default value: 0x00
<|startcomment|> 16 bits might not be long enough to ensure no collisions. If we currently only support one downstream, then you could use 0 everywhere. If not, then perhaps this code should keep state? <|endcomment|>  private static LinkProperties getUniqueLocalConfig(byte[] ulp, String ifname) { LinkProperties lp = new LinkProperties(); lp.setInterfaceName(ifname); final IpPrefix local48 = getUniqueLocalPrefix(ulp, (short) 0, 48); lp.addRoute(new RouteInfo(local48, null, null)); <|startfocus|> // Use 16 bits of the hashCode of the interface name as the Subnet ID. final IpPrefix local64 = getUniqueLocalPrefix(ulp, (short) ifname.hashCode(), 64); <|endfocus|> lp.addLinkAddress(new LinkAddress(local64.getAddress(), 64)); return lp;
<|startcomment|> mLteRsrpOffset. Actually not too happy with Offset either - it doesn't give an indication of direction. If a positive number here is better would this be an mLteRsrpBoost? <|endcomment|>  private int mEvdoDbm; // This value is the EVDO RSSI value private int mEvdoEcio; // This value is the EVDO Ec/Io private int mEvdoSnr; // Valid values are 0-8. 8 is the highest signal to noise ratio private int mLteSignalStrength; private int mLteRsrp; private int mLteRsrq; private int mLteRssnr; private int mLteCqi; <|startfocus|> private int mLteOffset; // offset to be reduced from the rsrp threshold while calculating // signal strength level <|endfocus|> private int mTdScdmaRscp; private boolean isGsm; // This value is set by the ServiceStateTracker onSignalStrengthResult /** * Create a new SignalStrength from a intent notifier Bundle * * This method is used by PhoneStateIntentReceiver and maybe by * external applications. * * @param m Bundle from intent notifier * @return newly created SignalStrength * * @hide */ public static SignalStrength newFromBundle(Bundle m) { SignalStrength ret; ret = new SignalStrength(); ret.setFromNotifierBundle(m);
<|startcomment|> setLteRsrpOffset? <|endcomment|> <|startfocus|> public void setLteOffset(int lteOffset) { mLteOffset = lteOffset; <|endfocus|>
<|startcomment|> are you certain this is what's desired? It would be nice if the offset applied throughout the range, but you're still keeping the upper and lower ends fixed which makes this more complicated. <|endcomment|>  */ int rssiIconLevel = SIGNAL_STRENGTH_NONE_OR_UNKNOWN, rsrpIconLevel = -1, snrIconLevel = -1; int[] threshRsrp = Resources.getSystem().getIntArray( com.android.internal.R.array.config_lteDbmThresholds); if (threshRsrp.length != 6) { Log.wtf(LOG_TAG, "getLteLevel - config_lteDbmThresholds has invalid num of elements." + " Cannot evaluate RSRP signal."); } else { if (mLteRsrp > threshRsrp[5]) { rsrpIconLevel = -1; <|startfocus|> } else if (mLteRsrp >= (threshRsrp[4] - mLteOffset)) { <|endfocus|> rsrpIconLevel = SIGNAL_STRENGTH_GREAT; } else if (mLteRsrp >= (threshRsrp[3] - mLteOffset)) { rsrpIconLevel = SIGNAL_STRENGTH_GOOD; } else if (mLteRsrp >= (threshRsrp[2] - mLteOffset)) { rsrpIconLevel = SIGNAL_STRENGTH_MODERATE; } else if (mLteRsrp >= (threshRsrp[1] - mLteOffset)) { rsrpIconLevel = SIGNAL_STRENGTH_POOR; } else if (mLteRsrp >= threshRsrp[0]) {
<|startcomment|> I thought the format was going to be "start-end" for each string in the array. <|endcomment|>  "notify_international_call_on_wfc_bool"; /** * Offset to be reduced from rsrp threshold while calculating signal strength level. * @hide */ public static final String KEY_SIGNAL_STRENGTH_OFFSET_INT = "signal_strength_offset_int"; /** * List of EARFCN ranges on which signal_strength_offset_int will be applied. <|startfocus|> * Format of the String array is expected to be {"erafcn1_start", earfcn1_end", * "earfcn2_start", "earfcn2_end" ... } <|endfocus|> * @hide */ public static final String KEY_SIGNAL_STRENGTH_EARFCNS_LIST_STRING_ARRAY = "signal_strength_earfcn_threshold_int"; /** The default value for every variable. */ private final static PersistableBundle sDefaults; static { sDefaults = new PersistableBundle(); sDefaults.putBoolean(KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL, true); sDefaults.putBoolean(KEY_ADDITIONAL_CALL_SETTING_BOOL, true); sDefaults.putBoolean(KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL, false); sDefaults.putBoolean(KEY_ALLOW_LOCAL_DTMF_TONES_BOOL, true);
<|startcomment|> this is confusing... something like "to start the wifi hotspot" ? <|endcomment|>  * @return error a {@code TETHER_ERROR} value indicating success or failure type * * {@hide} */ public int setUsbTethering(boolean enable) { try { return mService.setUsbTethering(enable); } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } /** * Request that a local-only Wi-Fi hotspot be started. The supplied Wi-Fi <|startfocus|> * configuration will be used after switch to station mode (STA), and must * be non-null. <|endfocus|> * * Local-only Wi-Fi hotspot functionality is currently mutually exclusive * with other tethering functionality. * * @param cfg The {@link android.net.wifi.WifiConfiguration} to use. * @return error a {@code TETHER_ERROR} value indicating success or failure * * @hide */ public int startLocalOnlyWifiHotspot(WifiConfiguration cfg) { try { return mService.startLocalOnlyWifiHotspot(cfg); } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } /**
<|startcomment|> a more accurate name here would be helpful. verifyGetFirmwareRoamingInfoIsCalledWhenWifiEnabled() (it is long, but you get the point - otherwise this might be a helper of some sort) <|endcomment|>  public void getFirmwareRoamingInfo() { <|startfocus|> reset(mWifiConnectivityHelper); <|endfocus|> mWifiConnectivityManager.setWifiEnabled(true); verify(mWifiConnectivityHelper).getFirmwareRoamingInfo();
<|startcomment|> this can either fit on one line or, better yet, check the int and config. make sure you get the right values. <|endcomment|>  // SSID as the one to be selected. WifiConfiguration currentNetwork = generateWifiConfig( 0, CANDIDATE_NETWORK_ID, CANDIDATE_SSID, false, true, null, null); when(mWifiConfigManager.getConfiguredNetwork(anyInt())).thenReturn(currentNetwork); // Set WiFi to connected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_CONNECTED); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); <|startfocus|> verify(mWifiStateMachine).startRoamToNetwork( anyInt(), anyObject()); <|endfocus|>
<|startcomment|> does this actually check the right thing? you are connected.. but does it know the correct network? I am not as familiar with this test, but it seems like you might not call this anyway. <|endcomment|>  public void noFrameworkRoamingIfFirmwareControlRoaming() { // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set WiFi to connected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_CONNECTED); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); <|startfocus|> verify(mWifiStateMachine, times(0)).startRoamToNetwork( anyInt(), anyObject()); <|endfocus|>
<|startcomment|> Move to class's constants (private static final) <|endcomment|>  * 6. "San Francisco" location card opens. * 7. Select "San Francisco". * 8. Tap on the Drive icon. * Verify: * 1. Map points to San Francisco location. * 2. Navigation overview is displayed. * </pre> */ @Test @TestInfo(id = "145493594") public void testMapsApp() throws Exception { <|startfocus|> String QUERY_STRING = "San Francisco"; <|endfocus|> Instrumentation instrumentation = testFramework.getInstrumentation(); UiDevice mDevice = testFramework.getDevice(); AppLauncher.launch(instrumentation, "Maps"); UiObject acceptButton = mDevice.findObject(new UiSelector().textContains("ACCEPT & CONTINUE")); // "Accept & Continue" occurs only on first time Maps gets launched. if (acceptButton.exists()) { acceptButton.clickAndWaitForNewWindow(); } // SKIP button only exist's occurs only on first time Maps gets launched. UiObject skipText = mDevice.findObject(new UiSelector().textContains("SKIP")); if (skipText.exists()) {
<|startcomment|> nit: add a space <|endcomment|>  scrollView.scrollIntoView(new UiSelector().text(QUERY_STRING)); selectedLocation = scrollView.getChildByText(new UiSelector() .className(TextView.class.getName()), QUERY_STRING); Assert.assertTrue(selectedLocation.exists()); selectedLocation.clickAndWaitForNewWindow(); // Verify the Query String is present after completing search. UiObject searchTextView = searchUiObject.getChild(new UiSelector().className(TextView.class.getName())); Assert.assertTrue(searchTextView.getText().contains(QUERY_STRING)); <|startfocus|> } else{ <|endfocus|> searchEditText = mDevice.findObject(new UiSelector().className(EditText.class.getName())); searchEditText.setText(QUERY_STRING); UiScrollable listViewSelector = new UiScrollable(new UiSelector().className(ListView.class.getName())); selectedLocation = listViewSelector.getChildByText(new UiSelector() .className(TextView.class.getName()), QUERY_STRING); selectedLocation.clickAndWaitForNewWindow(); // Verify the Query String is present after completing search. Assert.assertTrue(searchEditText.getText().contains(QUERY_STRING)); } 
<|startcomment|> since we are moving from wear, should we also use the new namespace? <|endcomment|>  private static final String TAG = "CellBroadcastReceiver"; static final boolean DBG = false; // STOPSHIP: change to false before ship public static final String CELLBROADCAST_START_CONFIG_ACTION = "android.cellbroadcastreceiver.START_CONFIG"; // Key to access the stored reminder interval default value private static final String CURRENT_INTERVAL_DEFAULT = "current_interval_default"; public static final String ACTION_MARK_AS_READ = "com.google.android.clockwork.cmas.intent.action.MARK_AS_READ"; public static final String EXTRA_DELIVERY_TIME = <|startfocus|> "com.google.android.clockwork.cmas.intent.extra.ID"; <|endfocus|> @Override public void onReceive(Context context, Intent intent) { onReceiveWithPrivilege(context, intent, false); } protected void onReceiveWithPrivilege(Context context, Intent intent, boolean privileged) { if (DBG) log("onReceive " + intent); String action = intent.getAction(); final long deliveryTime = intent.getLongExtra(EXTRA_DELIVERY_TIME, -1); if (ACTION_MARK_AS_READ.equals(action)) { new CellBroadcastContentProvider.AsyncCellBroadcastTask(context.getContentResolver())
<|startcomment|> consider moving this down to the if block. <|endcomment|>  protected void onReceiveWithPrivilege(Context context, Intent intent, boolean privileged) { if (DBG) log("onReceive " + intent); String action = intent.getAction(); <|startfocus|> final long deliveryTime = intent.getLongExtra(EXTRA_DELIVERY_TIME, -1); <|endfocus|> if (ACTION_MARK_AS_READ.equals(action)) { new CellBroadcastContentProvider.AsyncCellBroadcastTask(context.getContentResolver()) .execute(new CellBroadcastContentProvider.CellBroadcastOperation() { @Override public boolean execute(CellBroadcastContentProvider provider) { return provider.markBroadcastRead(CellBroadcasts.DELIVERY_TIME, deliveryTime); } }); } else if (TelephonyIntents.ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED.equals(action) || CarrierConfigManager.ACTION_CARRIER_CONFIG_CHANGED.equals(action) || CELLBROADCAST_START_CONFIG_ACTION.equals(action)) { // Todo: Add the service state check once the new get service state API is done. // Do not rely on mServiceState as it gets reset to -1 time to time because // the process of CellBroadcastReceiver gets killed every time once the job is done.
<|startcomment|> do you need to register in the manifest? <|endcomment|>  protected void onReceiveWithPrivilege(Context context, Intent intent, boolean privileged) { if (DBG) log("onReceive " + intent); String action = intent.getAction(); final long deliveryTime = intent.getLongExtra(EXTRA_DELIVERY_TIME, -1); <|startfocus|> if (ACTION_MARK_AS_READ.equals(action)) { <|endfocus|> new CellBroadcastContentProvider.AsyncCellBroadcastTask(context.getContentResolver()) .execute(new CellBroadcastContentProvider.CellBroadcastOperation() { @Override public boolean execute(CellBroadcastContentProvider provider) { return provider.markBroadcastRead(CellBroadcasts.DELIVERY_TIME, deliveryTime); } }); } else if (TelephonyIntents.ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED.equals(action) || CarrierConfigManager.ACTION_CARRIER_CONFIG_CHANGED.equals(action) || CELLBROADCAST_START_CONFIG_ACTION.equals(action)) { // Todo: Add the service state check once the new get service state API is done. // Do not rely on mServiceState as it gets reset to -1 time to time because // the process of CellBroadcastReceiver gets killed every time once the job is done.
<|startcomment|> nit: probably one line since others above follow that format? Also, should probably add some description, e.g. something like: "Intent extra for passing an SmsCbMessage" <|endcomment|>  /** Intent action to display alert dialog/notification, after verifying the alert is new. */ static final String SHOW_NEW_ALERT_ACTION = "cellbroadcastreceiver.SHOW_NEW_ALERT"; /** Use the same notification ID for non-emergency alerts. */ static final int NOTIFICATION_ID = 1; /** Sticky broadcast for latest area info broadcast received. */ static final String CB_AREA_INFO_RECEIVED_ACTION = "android.cellbroadcastreceiver.CB_AREA_INFO_RECEIVED"; <|startfocus|> /** * Intent extra */ <|endfocus|> private static final String EXTRA_MESSAGE = "message"; /** * Container for service category, serial number, location, body hash code, and ETWS primary/ * secondary information for duplication detection. */ private static final class MessageServiceCategoryAndScope { private final int mServiceCategory; private final int mSerialNumber; private final SmsCbLocation mLocation; private final int mBodyHash; private final boolean mIsEtwsPrimary; MessageServiceCategoryAndScope(int serviceCategory, int serialNumber, SmsCbLocation location, int bodyHash, boolean isEtwsPrimary) { mServiceCategory = serviceCategory;
<|startcomment|> nit: Wear <|endcomment|>  ArrayList<CellBroadcastMessage> messageList, Context context, boolean fromSaveState) { int channelTitleId = CellBroadcastResources.getDialogTitleResource(context, message); CharSequence channelName = context.getText(channelTitleId); String messageBody = message.getMessageBody(); // Create intent to show the new messages when user selects the notification. Intent intent; if (context.getPackageManager().hasSystemFeature(PackageManager.FEATURE_WATCH)) { <|startfocus|> // For wear we want to mark as read intent = createWearDeleteIntent(context, message.getDeliveryTime()); <|endfocus|> } else { // For phone we handle it differently intent = createDisplayMessageIntent(context, CellBroadcastAlertDialog.class, messageList); } intent.putExtra(CellBroadcastAlertDialog.FROM_NOTIFICATION_EXTRA, true); intent.putExtra(CellBroadcastAlertDialog.FROM_SAVE_STATE_NOTIFICATION_EXTRA, fromSaveState); PendingIntent pi; if (context.getPackageManager().hasSystemFeature(PackageManager.FEATURE_WATCH)) { pi = PendingIntent.getBroadcast(context, 0, intent, 0); } else { pi = PendingIntent.getActivity(context, NOTIFICATION_ID, intent,
<|startcomment|> hmm, lets name createMarkAsReadIntent? Can probably leave Wear out since it could possibly be used in other contexts. <|endcomment|> <|startfocus|> static Intent createWearDeleteIntent(Context context, long deliveryTime) { <|endfocus|> Intent deleteIntent = new Intent(context, CellBroadcastReceiver.class); deleteIntent.setAction(CellBroadcastReceiver.ACTION_MARK_AS_READ); deleteIntent.putExtra(CellBroadcastReceiver.EXTRA_DELIVERY_TIME, deliveryTime); return deleteIntent;
<|startcomment|> comment that INetd should never be cached outside of this interface? <|endcomment|>  /** * @hide */ public class NetdService { private static final String TAG = NetdService.class.getSimpleName(); private static final String NETD_SERVICE_NAME = "netd"; private static final int BASE_TIMEOUT_MS = 100; private static final int MAX_TIMEOUT_MS = 1000; /** * It is the caller's responsibility to check for a null return value * and to handle RemoteException errors from invocations on the returned * interface if, for example, netd dies and is restarted. <|startfocus|> * <|endfocus|> * @return an INetd instance or null. */ public static INetd getInstance() { // NOTE: ServiceManager does no caching for the netd service, // because netd is not one of the defined common services. final INetd netdInstance = INetd.Stub.asInterface( ServiceManager.getService(NETD_SERVICE_NAME)); if (netdInstance == null) { Log.w(TAG, "WARNING: returning null INetd instance."); } return netdInstance; } /** * Blocks until an INetd instance is available. *
<|startcomment|> Can this actually happen ? It looks like the loop goes on until getInstance is not null. <|endcomment|>  if (netdInstance == null) { Log.w(TAG, "WARNING: returning null INetd instance."); } return netdInstance; } /** * Blocks until an INetd instance is available. * * It is the caller's responsibility to handle RemoteException errors * from invocations on the returned interface if, for example, netd * dies after this interface was returned. * * Returned instances of INetd should not be cached. * * @return an INetd instance or null. */ <|startfocus|> public static INetd get() { for (int i = 0; ; i++) { <|endfocus|> final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } // No netdInstance was received; sleep and retry. final int timeoutMs = (i < (MAX_TIMEOUT_MS / BASE_TIMEOUT_MS)) ? (i * BASE_TIMEOUT_MS) : MAX_TIMEOUT_MS; try { Thread.sleep(timeoutMs); } catch (InterruptedException e) {} } } 
<|startcomment|> Is the timeout arithmetics needed for doing linear backoff ? I would like to suggest the following alternative that does not include arithmetics per say, or at least less of it: timeoutMs = BASE_TIME_MS; while (true) { ... Thread.sleep(timeoutMs); timeoutMs = Math.min(timeoutMs + BASE_TIMEOUT_MS, MAX_TIMEOUT_MS); } <|endcomment|>  public static INetd get() { for (int i = 0; ; i++) { final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } // No netdInstance was received; sleep and retry. final int timeoutMs = (i < (MAX_TIMEOUT_MS / BASE_TIMEOUT_MS)) ? (i * BASE_TIMEOUT_MS) : MAX_TIMEOUT_MS; try { Thread.sleep(timeoutMs); <|startfocus|> } catch (InterruptedException e) {} <|endfocus|> }
<|startcomment|> ServiceSpecificException is a runtime exception, no need to declare it in the signature (it doesn't really have any effect because callers don't have to catch). <|endcomment|> <|startfocus|> void run(INetd netd) throws RemoteException, ServiceSpecificException; <|endfocus|> } /** * Blocks until an INetd instance is availabe, and retries until either * the command succeeds or a ServiceSpecificError is thrown. */
<|startcomment|> -> runtime <|endcomment|>  void run(INetd netd) throws RemoteException, ServiceSpecificException; } /** * Blocks until an INetd instance is availabe, and retries until either <|startfocus|> * the command succeeds or a ServiceSpecificError is thrown. <|endfocus|> */
<|startcomment|> Is this a good idea to pass in INed to cmd even if it is null ? With the current usage in IpManager, this immediately triggers an NPE that's not caught. That seemed to be the case before, but if I understand correctly this patch tries to correct this issue right ? I suggest: INetd netd = get(); if (netd == null) { continue; } cmd.run(netd) (this is assuming that get() can indeed returns null based on its doc) <|endcomment|>  public static void run(NetdCommand cmd) { while (true) { try { cmd.run(get()); return; <|startfocus|> } catch (RemoteException re) {} <|endfocus|> }
<|startcomment|> Shouldn't the error be logged ? <|endcomment|>  public static void run(NetdCommand cmd) { while (true) { try { cmd.run(get()); return; <|startfocus|> } catch (RemoteException re) {} <|endfocus|> }
<|startcomment|> let's reduce this to 3. A test taking over hour is not ok. <|endcomment|>  ResultUnit.BYTE); Stat.StatResult stat = Stat.getStat(mbps); getReportLog().printSummary("write throughput", stat.mAverage, ResultType.HIGHER_BETTER, ResultUnit.MBPS); } @TimeoutReq(minutes = 80) public void testSingleSequentialUpdate() throws Exception { final long fileSize = FileUtil.getFileSizeExceedingMemory(getContext(), BUFFER_SIZE); if (fileSize == 0) { // not enough space, give up return; } <|startfocus|> final int NUMBER_REPETITION = 6; <|endfocus|> FileUtil.doSequentialUpdateTest(getContext(), DIR_SEQ_UPDATE, getReportLog(), fileSize, BUFFER_SIZE, NUMBER_REPETITION); } @TimeoutReq(minutes = 30) public void testSingleSequentialRead() throws Exception { final long fileSize = FileUtil.getFileSizeExceedingMemory(getContext(), BUFFER_SIZE); if (fileSize == 0) { // not enough space, give up return; } long start = System.currentTimeMillis(); final File file = FileUtil.createNewFilledFile(getContext(), DIR_SEQ_RD, fileSize); long finish = System.currentTimeMillis();
<|startcomment|> Extra white space? <|endcomment|>  private void updateSavedNetworkSelectionStatus() { List<WifiConfiguration> savedNetworks = mWifiConfigManager.getSavedNetworks(); if (savedNetworks.size() == 0) { localLog("No saved networks."); return; } StringBuffer sbuf = new StringBuffer("Saved Networks List: \n"); for (WifiConfiguration network : savedNetworks) { /** <|startfocus|> * Ignore Passpoint networks. Passpoint networks are also considered as "saved" * network, but without being persisted to the storage. They are managed <|endfocus|> * by {@link PasspointNetworkEvaluator}. */ if (network.isPasspoint()) { continue; } WifiConfiguration.NetworkSelectionStatus status = network.getNetworkSelectionStatus(); // If a configuration is temporarily disabled, re-enable it before trying // to connect to it. mWifiConfigManager.tryEnableNetwork(network.networkId); //TODO(b/30928589): Enable "permanently" disabled networks if we are in DISCONNECTED // state. // Clear the cached candidate, score and seen. mWifiConfigManager.clearNetworkCandidateScanResult(network.networkId); 
<|startcomment|> Nit: extra white space? <|endcomment|>  List<WifiConfiguration> associatedConfigurations = null; WifiConfiguration associatedConfiguration = mWifiConfigManager.getSavedNetworkForScanDetailAndCache(scanDetail); if (associatedConfiguration == null) { continue; } else { associatedConfigurations = new ArrayList<>(Arrays.asList(associatedConfiguration)); } for (WifiConfiguration network : associatedConfigurations) { /** <|startfocus|> * Ignore Passpoint networks. Passpoint networks are also considered as "saved" * network, but without being persisted to the storage. They are being evaluated <|endfocus|> * by {@link PasspointNetworkEvaluator}. */ if (network.isPasspoint()) { continue; } WifiConfiguration.NetworkSelectionStatus status = network.getNetworkSelectionStatus(); status.setSeenInLastQualifiedNetworkSelection(true); if (!status.isNetworkEnabled()) { continue; } else if (network.BSSID != null && !network.BSSID.equals("any") && !network.BSSID.equals(scanResult.BSSID)) { // App has specified the only BSSID to connect for this // configuration. So only the matching ScanResult can be a candidate.
<|startcomment|> is this am command already supported in the aosp ? <|endcomment|>  "am stack move-top-activity-to-pinned-stack 1 0 0 500 500"; protected static final String LAUNCHING_ACTIVITY = "LaunchingActivity"; private static final String AM_RESIZE_DOCKED_STACK = "am stack resize-docked-stack "; private static final String AM_MOVE_TASK = "am stack movetask "; private static final String AM_SUPPORTS_SPLIT_SCREEN_MULTIWINDOW = "am supports-split-screen-multiwindow"; <|startfocus|> private static final String AM_NO_HOME_SCREEN = "am no-home-screen"; <|endfocus|> private static final String INPUT_KEYEVENT_HOME = "input keyevent 3"; /** A reference to the device under test. */ protected ITestDevice mDevice; private HashSet<String> mAvailableFeatures; protected static String getAmStartCmd(final String activityName) { return "am start -n " + getActivityComponentName(activityName); } protected static String getAmStartCmdOverHome(final String activityName) { return "am start --activity-task-on-home -n " + getActivityComponentName(activityName); } static String getActivityComponentName(final String activityName) {
<|startcomment|> We probably need to check for mode being TETHERING here. <|endcomment|>  public int startLocalOnlyWifiHotspot(WifiConfiguration cfg) { <|startfocus|> if (mMode == Mode.LOCAL_HOTSPOT) { <|endfocus|> if (VDBG) { Log.e(TAG, "Attempt to startLocalOnlyWifiHotspot absent corresponding stop."); } return ConnectivityManager.TETHER_ERROR_SERVICE_UNAVAIL; } mMode = Mode.LOCAL_HOTSPOT; return setWifiTethering(cfg, true);
<|startcomment|> Nit: "Local hotspot already started"? <|endcomment|>  public int startLocalOnlyWifiHotspot(WifiConfiguration cfg) { if (mMode == Mode.LOCAL_HOTSPOT) { if (VDBG) { <|startfocus|> Log.e(TAG, "Attempt to startLocalOnlyWifiHotspot absent corresponding stop."); <|endfocus|> } return ConnectivityManager.TETHER_ERROR_SERVICE_UNAVAIL; } mMode = Mode.LOCAL_HOTSPOT; return setWifiTethering(cfg, true);
<|startcomment|> "Local hotspot not running"? <|endcomment|>  public void stopLocalOnlyWifiHotspot() { if (mMode != Mode.LOCAL_HOTSPOT) { if (VDBG) { <|startfocus|> Log.e(TAG, "Attempt to stopLocalOnlyWifiHotspot absent corresponding start."); <|endfocus|> } return; } setWifiTethering(null, false);
<|startcomment|> I would say put it unconditionally after the if branch if this is a condition that needs to be ensured. <|endcomment|>  protected boolean turnOffMasterTetherSettings() { if (!stopIpServices()) { transitionTo(mStopTetheringErrorState); return false; } if (mMode == Mode.TETHERING) { try { mNMService.setIpForwardingEnabled(false); } catch (Exception e) { transitionTo(mSetIpForwardingDisabledErrorState); return false; } <|startfocus|> } else { // Reset to tethering mode (default mode). mMode = Mode.TETHERING; <|endfocus|> } transitionTo(mInitialState); return true;
<|startcomment|> Nit: "drop the State, it's cleaner"? <|endcomment|> import java.util.Random; /** * IPv6 tethering is rather different from IPv4 owing to the absence of NAT. * This coordinator is responsible for evaluating the dedicated prefixes * assigned to the device and deciding how to divvy them up among downstream * interfaces. * * @hide */ public class IPv6TetheringCoordinator { private static final String TAG = IPv6TetheringCoordinator.class.getSimpleName(); private static final boolean DBG = false; private static final boolean VDBG = false; <|startfocus|> private static class DownstreamState { <|endfocus|> public final TetherInterfaceStateMachine tism; public final short subnetId; DownstreamState(TetherInterfaceStateMachine tism, short subnetId) { this.tism = tism; this.subnetId = subnetId; } } private final ArrayList<TetherInterfaceStateMachine> mNotifyList; private final LinkedList<DownstreamState> mActiveDownstreams; private short mNextSubnetId; private byte[] mUniqueLocalPrefix; private NetworkState mUpstreamNetworkState; public IPv6TetheringCoordinator(ArrayList<TetherInterfaceStateMachine> notifyList) { mNotifyList = notifyList; mActiveDownstreams = new LinkedList<>();
<|startcomment|> Nit: could/should this be a Map from subnet ID to TetherInterfaceStateMachine? If so I think you would't need the DownstreamState class. Equivalently it could be a SparseArray keyed off subnet ID But this is fine too. <|endcomment|>  */ public class IPv6TetheringCoordinator { private static final String TAG = IPv6TetheringCoordinator.class.getSimpleName(); private static final boolean DBG = false; private static final boolean VDBG = false; private static class DownstreamState { public final TetherInterfaceStateMachine tism; public final short subnetId; DownstreamState(TetherInterfaceStateMachine tism, short subnetId) { this.tism = tism; this.subnetId = subnetId; } } private final ArrayList<TetherInterfaceStateMachine> mNotifyList; <|startfocus|> private final LinkedList<DownstreamState> mActiveDownstreams; <|endfocus|> private short mNextSubnetId; private byte[] mUniqueLocalPrefix; private NetworkState mUpstreamNetworkState; public IPv6TetheringCoordinator(ArrayList<TetherInterfaceStateMachine> notifyList) { mNotifyList = notifyList; mActiveDownstreams = new LinkedList<>(); mNextSubnetId = 0; } public void addActiveDownstream(TetherInterfaceStateMachine downstream) { if (findDownstream(downstream) == null) { // Adding a new downstream appends it to the list. Adding a // downstream a second time without first removing it has no effect.
<|startcomment|> Do you need to do something when mNextSubnetId goes from 32767 to -32768? <|endcomment|>  public void addActiveDownstream(TetherInterfaceStateMachine downstream) { if (findDownstream(downstream) == null) { // Adding a new downstream appends it to the list. Adding a // downstream a second time without first removing it has no effect. <|startfocus|> mActiveDownstreams.offer(new DownstreamState(downstream, mNextSubnetId++)); <|endfocus|> updateIPv6TetheringInterfaces(); }
<|startcomment|> I think it can be folded into: Arrays.copyOf(ulp, NetworkConstants.IPV6_ADDR_LEN) that would return an array of length NetworkConstants.IPV6_ADDR_LEN padded with 0s. <|endcomment|>  private static byte[] generateUniqueLocalPrefix() { final byte[] ulp = new byte[6]; // 6 = 48bits / 8bits/byte (new Random()).nextBytes(ulp); <|startfocus|> final byte[] in6addr = new byte[NetworkConstants.IPV6_ADDR_LEN]; System.arraycopy(ulp, 0, in6addr, 0, ulp.length); <|endfocus|> in6addr[0] = (byte) 0xfd; // fc00::/7 and L=1 return in6addr;
<|startcomment|> nit: whitespace <|endcomment|>  ActivityReceiverFilter appEndReceiver = new ActivityReceiverFilter(ACTIVITY_EXIT_ACTION); // The filter for the time event. ActivityReceiverFilter timeReceiver = new ActivityReceiverFilter(ACTIVITY_TIME_TRACK_INFO); // Run the activity. mContext.startActivity(intent, options.toBundle()); // Wait until it finishes and end the reciever then. assertEquals(RESULT_PASS, appEndReceiver.waitForActivity()); appEndReceiver.close(); if (!noHomeScreen()) { <|startfocus|> // At this time the timerReceiver should not fire, even though the activity has shut <|endfocus|> // down, because we are back to the home screen. assertEquals(RESULT_TIMEOUT, timeReceiver.waitForActivity()); assertTrue(timeReceiver.mTimeUsed == 0); } else { assertEquals(RESULT_PASS, timeReceiver.waitForActivity()); } // Issuing now another activity will trigger the timing information release. final Intent dummyIntent = new Intent(context, MockApplicationActivity.class); dummyIntent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK); final Activity activity = mInstrumentation.startActivitySync(dummyIntent); // Wait until it finishes and end the reciever then.
<|startcomment|> range. Also is it inclusive? Inclusiveness should also appear in the carrierconfig comments. <|endcomment|>  private CdmaSubscriptionSourceManager mCdmaSSM; public static final String INVALID_MCC = "000"; public static final String DEFAULT_MNC = "00"; private HbpcdUtils mHbpcdUtils = null; /* Used only for debugging purposes. */ private String mRegistrationDeniedReason; private String mCurrentCarrier = null; /* list of LTE EARFCNs (E-UTRA Absolute Radio Frequency Channel Number, * Reference: 3GPP TS 36.104 5.4.3) <|startfocus|> * pairs for which the lte rsrp boost is applied */ <|endfocus|> private ArrayList<Pair<Integer, Integer>> mEarfcnPairListForRsrpBoost = null; private int mLteRsrpBoost = 0; // offset which is reduced from the rsrp threshold // while calculating signal strength level. private final Object mLteRsrpBoostLock = new Object(); // mLteRsrpBoost lock public ServiceStateTracker(GsmCdmaPhone phone, CommandsInterface ci) { mPhone = phone; mCi = ci; mRatRatcheter = new RatRatcheter(mPhone); mVoiceCapable = mPhone.getContext().getResources().getBoolean( com.android.internal.R.bool.config_voice_capable);
<|startcomment|> don't need (it's the name..) <|endcomment|>  /* list of LTE EARFCNs (E-UTRA Absolute Radio Frequency Channel Number, * Reference: 3GPP TS 36.104 5.4.3) * pairs for which the lte rsrp boost is applied */ private ArrayList<Pair<Integer, Integer>> mEarfcnPairListForRsrpBoost = null; private int mLteRsrpBoost = 0; // offset which is reduced from the rsrp threshold // while calculating signal strength level. <|startfocus|> private final Object mLteRsrpBoostLock = new Object(); // mLteRsrpBoost lock <|endfocus|> public ServiceStateTracker(GsmCdmaPhone phone, CommandsInterface ci) { mPhone = phone; mCi = ci; mRatRatcheter = new RatRatcheter(mPhone); mVoiceCapable = mPhone.getContext().getResources().getBoolean( com.android.internal.R.bool.config_voice_capable); mUiccController = UiccController.getInstance(); mUiccController.registerForIccChanged(this, EVENT_ICC_CHANGED, null); mCi.setOnSignalStrengthUpdate(this, EVENT_SIGNAL_STRENGTH_UPDATE, null); mCi.registerForCellInfoList(this, EVENT_UNSOL_CELL_INFO_LIST, null); mSubscriptionController = SubscriptionController.getInstance();
<|startcomment|> pass in ServiceState so it's clear what's getting updated. The name doesn't suggested mNewSS is altered. <|endcomment|>  && ServiceState.isCdma(newDataRat))) { mCi.getSignalStrength(obtainMessage(EVENT_GET_SIGNAL_STRENGTH)); } // voice roaming state in done while handling EVENT_POLL_STATE_REGISTRATION_CDMA mNewSS.setDataRoaming(regCodeIsRoaming(regState)); if (DBG) { log("handlPollStateResultMessage: CdmaLteSST setDataRegState=" + dataRegState + " regState=" + regState + " dataRadioTechnology=" + newDataRat); } } <|startfocus|> updateLteEarfcnBoost(getLteEarfcn(dataRegStateResult)); <|endfocus|> break; } case EVENT_POLL_STATE_OPERATOR: { if (mPhone.isPhoneTypeGsm()) { String opNames[] = (String[]) ar.result; if (opNames != null && opNames.length >= 3) { // FIXME: Giving brandOverride higher precedence, is this desired? String brandOverride = mUiccController.getUiccCard(getPhoneId()) != null ? mUiccController.getUiccCard(getPhoneId()).getOperatorBrandOverride() : null; if (brandOverride != null) {
<|startcomment|> this should be a defined constant used here and in getLteEarfcn when not found. <|endcomment|>  private void updateLteEarfcnBoost(int lteEarfcn) { synchronized (mLteRsrpBoostLock) { if ((lteEarfcn != -1) && containsEarfcnInEarfcnRange(mEarfcnPairListForRsrpBoost, lteEarfcn)) { <|startfocus|> mNewSS.setLteEarfcnRsrpBoost(mLteRsrpBoost); <|endfocus|> } else { mNewSS.setLteEarfcnRsrpBoost(0); } }
<|startcomment|> Wrap to 100 chars. <|endcomment|>  && mRingingCall.getState() == ImsPhoneCall.State.IDLE) { mForegroundCall.detach(mPendingMO); removeConnection(mPendingMO); mPendingMO.finalize(); mPendingMO = null; mPhone.initiateSilentRedial(); return; } else { mPendingMO = null; int cause = getDisconnectCauseFromReasonInfo(reasonInfo); ImsPhoneConnection conn = findConnection(imsCall); if(conn != null) { <|startfocus|> conn.setPreciseDisconnectCause(getPreciseDisconnectCauseFromReasonInfo(reasonInfo)); <|endfocus|> } processCallStateChange(imsCall, ImsPhoneCall.State.DISCONNECTED, cause); } mMetrics.writeOnImsCallStartFailed(mPhone.getPhoneId(), imsCall.getCallSession(), reasonInfo); }
<|startcomment|> mPreciseDisconnectCause <|endcomment|>  * onFeatureCapabilityChanged(int, int[], int[])} callbacks, or values received via the * {@link ImsCallProfile#EXTRA_CALL_RAT_TYPE} extra. Util we receive a value via the extras, * we will use the wifi state based on the {@code onFeatureCapabilityChanged}. Once a value * is received via the extras, we will prefer those values going forward. */ private boolean mIsWifiStateFromExtras = false; <|startfocus|> private int mPreciseCause = 0; <|endfocus|> //***** Event Constants private static final int EVENT_DTMF_DONE = 1; private static final int EVENT_PAUSE_DONE = 2; private static final int EVENT_NEXT_POST_DIAL = 3; private static final int EVENT_WAKE_LOCK_TIMEOUT = 4; private static final int EVENT_DTMF_DELAY_DONE = 5; //***** Constants private static final int PAUSE_DELAY_MILLIS = 3 * 1000; private static final int WAKE_LOCK_TIMEOUT_MILLIS = 60*1000; //***** Inner Classes class MyHandler extends Handler {
<|startcomment|> ImsReasonInfo is CODE_LOCAL_ILLEGAL_ARGUMENT. Should we keep the LOCAL part? <|endcomment|>  /** Not a preempted call */ public static final int CDMA_PREEMPTED = 1007; /** Not an emergency call */ public static final int CDMA_NOT_EMERGENCY = 1008; /** Access Blocked by CDMA network */ public static final int CDMA_ACCESS_BLOCKED = 1009; /** Mapped from ImsReasonInfo */ /* The passed argument is an invalid */ public static final int ILLEGAL_ARGUMENT = 1200; // The operation is invoked in invalid call state <|startfocus|> public static final int ILLEGAL_STATE = 1201; <|endfocus|> // IMS service internal error public static final int INTERNAL_ERROR = 1202; // IMS service goes down (service connection is lost) public static final int IMS_SERVICE_DOWN = 1203; // No pending incoming call exists public static final int NO_PENDING_CALL = 1204; // Service unavailable; by power off public static final int POWER_OFF = 1205; // Service unavailable; by low battery public static final int LOW_BATTERY = 1206;
<|startcomment|> ImsReasonInfo is CODE_LOCAL_ILLEGAL_STATE. Should we keep the LOCAL part? <|endcomment|>  public static final int CDMA_PREEMPTED = 1007; /** Not an emergency call */ public static final int CDMA_NOT_EMERGENCY = 1008; /** Access Blocked by CDMA network */ public static final int CDMA_ACCESS_BLOCKED = 1009; /** Mapped from ImsReasonInfo */ /* The passed argument is an invalid */ public static final int ILLEGAL_ARGUMENT = 1200; // The operation is invoked in invalid call state public static final int ILLEGAL_STATE = 1201; // IMS service internal error <|startfocus|> public static final int INTERNAL_ERROR = 1202; <|endfocus|> // IMS service goes down (service connection is lost) public static final int IMS_SERVICE_DOWN = 1203; // No pending incoming call exists public static final int NO_PENDING_CALL = 1204; // Service unavailable; by power off public static final int POWER_OFF = 1205; // Service unavailable; by low battery public static final int LOW_BATTERY = 1206; // Service unavailable; by out of service (data service state)
<|startcomment|> Should we keep the LOCAL part (similar to ImsReasonInfo)? <|endcomment|>  /** Access Blocked by CDMA network */ public static final int CDMA_ACCESS_BLOCKED = 1009; /** Mapped from ImsReasonInfo */ /* The passed argument is an invalid */ public static final int ILLEGAL_ARGUMENT = 1200; // The operation is invoked in invalid call state public static final int ILLEGAL_STATE = 1201; // IMS service internal error public static final int INTERNAL_ERROR = 1202; // IMS service goes down (service connection is lost) <|startfocus|> public static final int IMS_SERVICE_DOWN = 1203; <|endfocus|> // No pending incoming call exists public static final int NO_PENDING_CALL = 1204; // Service unavailable; by power off public static final int POWER_OFF = 1205; // Service unavailable; by low battery public static final int LOW_BATTERY = 1206; // Service unavailable; by out of service (data service state) public static final int NETWORK_NO_SERVICE = 1207; /* Service unavailable; by no LTE coverage * (VoLTE is not supported even though IMS is registered)
<|startcomment|> Should we keep the "LOCAL" prefix similar to in ImsReasonInfo? <|endcomment|>  public static final int ILLEGAL_ARGUMENT = 1200; // The operation is invoked in invalid call state public static final int ILLEGAL_STATE = 1201; // IMS service internal error public static final int INTERNAL_ERROR = 1202; // IMS service goes down (service connection is lost) public static final int IMS_SERVICE_DOWN = 1203; // No pending incoming call exists public static final int NO_PENDING_CALL = 1204; // Service unavailable; by power off <|startfocus|> public static final int POWER_OFF = 1205; <|endfocus|> // Service unavailable; by low battery public static final int LOW_BATTERY = 1206; // Service unavailable; by out of service (data service state) public static final int NETWORK_NO_SERVICE = 1207; /* Service unavailable; by no LTE coverage * (VoLTE is not supported even though IMS is registered) */ public static final int NETWORK_NO_LTE_COVERAGE = 1208; /** Service unavailable; by located in roaming area */ public static final int NETWORK_ROAMING = 1209;
<|startcomment|> I'm curious, the ImsReasonInfo version of this (and some others) is LOCAL_CALL_EXCEEDED; does it make sense to call this one LOCAL_CALL_EXCEEDED as well? This is especially confusing when you consider MAXIMUM_NUMBER_OF_CALLS_REACHED, which is used for multi-endpoint. Suggest: MAX_LOCAL_CALLS_EXCEEDED for this one? <|endcomment|>  /** Service unavailable; by located in roaming area */ public static final int NETWORK_ROAMING = 1209; /** Service unavailable; by IP changed */ public static final int NETWORK_IP_CHANGED = 1210; /** Service unavailable; other */ public static final int SERVICE_UNAVAILABLE = 1211; /* Service unavailable; IMS connection is lost (IMS is not registered) */ public static final int NOT_REGISTERED = 1212; /** Max call exceeded */ <|startfocus|> public static final int CALL_EXCEEDED = 1213; <|endfocus|> /** Call decline */ public static final int LOCAL_CALL_DECLINE = 1214; /** SRVCC is in progress */ public static final int VCC_ON_PROGRESSING = 1215; /** Resource reservation is failed (QoS precondition) */ public static final int RESOURCE_RESERVATION_FAILED = 1216; /** Retry CS call; VoLTE service can't be provided by the network or remote end * Resolve the extra code(EXTRA_CODE_CALL_RETRY_*) if the below code is set */
<|startcomment|> shouldn't the first sleep be equal to BASE_TIMEOUT_MS ? With this ordering it looks like timeoutMs should start at 0. <|endcomment|>  public static INetd get(int maxTimeoutMs) { int timeoutMs = BASE_TIMEOUT_MS; while (true) { final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } if (maxTimeoutMs == 0) break; // No netdInstance was received; sleep and retry. timeoutMs = Math.min(timeoutMs + BASE_TIMEOUT_MS, MAX_TIMEOUT_MS); <|startfocus|> if (maxTimeoutMs > 0) timeoutMs = Math.min(timeoutMs, maxTimeoutMs); <|endfocus|> try { Thread.sleep(timeoutMs); } catch (InterruptedException e) { // If this occurs we can lose track of some time slept. } if (maxTimeoutMs > 0) maxTimeoutMs -= timeoutMs; } return null;
<|startcomment|> Shouldn't this maxTimeoutMs parameter apply to the total aggregated sleep time at the function level, not at the loop iteration level ? At the moment if a positive maxTimeoutMs is specified, the loop still runs until a non-null INetd returns. An alternative might be to manage maxTimeoutMs outside of the loop: if (maxTimeoutMs == 0) { return getInstance(); } long stop = SystemClock.elapsed() + maxTimeoutMs; (maxTimeoutMs < 0) { stop = Long.MAX_VALUE; } while(SystemClock.elapsed() < stop) { .. same as before but without maxTimeousMs management } <|endcomment|>  public static INetd get(int maxTimeoutMs) { int timeoutMs = BASE_TIMEOUT_MS; while (true) { final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } if (maxTimeoutMs == 0) break; // No netdInstance was received; sleep and retry. timeoutMs = Math.min(timeoutMs + BASE_TIMEOUT_MS, MAX_TIMEOUT_MS); <|startfocus|> if (maxTimeoutMs > 0) timeoutMs = Math.min(timeoutMs, maxTimeoutMs); <|endfocus|> try { Thread.sleep(timeoutMs); } catch (InterruptedException e) { // If this occurs we can lose track of some time slept. } if (maxTimeoutMs > 0) maxTimeoutMs -= timeoutMs; } return null;
<|startcomment|> i is unused now. consider: while (true) <|endcomment|>  public static INetd get(int maxTimeoutMs) { int timeoutMs = BASE_TIMEOUT_MS; <|startfocus|> for (int i = 0; i > -1; i++) { <|endfocus|> final INetd netdInstance = getInstance(); if (netdInstance != null) { return netdInstance; } if (maxTimeoutMs == 0) break; // No netdInstance was received; sleep and retry. timeoutMs = Math.min(timeoutMs + BASE_TIMEOUT_MS, MAX_TIMEOUT_MS); if (maxTimeoutMs > 0) timeoutMs = Math.min(timeoutMs, maxTimeoutMs); try { Thread.sleep(timeoutMs); } catch (InterruptedException e) { // If this occurs we can lose track of some time slept. } if (maxTimeoutMs > 0) maxTimeoutMs -= timeoutMs; } return null;
<|startcomment|> communicating? <|endcomment|>  public static void run(NetdCommand cmd) { while (true) { try { cmd.run(get()); return; } catch (RemoteException re) { <|startfocus|> Log.e(TAG, "error communicated with netd: " + re); <|endfocus|> } }
<|startcomment|> This isn't going to compile. <|endcomment|>  private AuthenticatorHelper mAuthenticatorHelper; private BluetoothAdapter mBtAdapter; private ConnectivityListener mConnectivityListener; private boolean mInputSettingNeeded; private Preference mDeveloperPref; private PreferenceGroup mAccessoriesGroup; private PreferenceGroup mAccountsGroup; private Preference mAddAccessory; private Preference mNetworkPref; private Preference mSoundsPref; private final BroadcastReceiver mBCMReceiver = new BroadcastReceiver() { @Override public void onReceive(Context context, Intent intent) { updateAccessories(); } }; <|startfocus|> private final BroadcastReceiver mBtConnectionReceiver = new BluetoothConnectionsManager(); <|endfocus|> public static MainFragment newInstance() { return new MainFragment(); } @Override public void onCreate(Bundle savedInstanceState) { mAuthenticatorHelper = new AuthenticatorHelper(getContext(), new UserHandle(UserHandle.myUserId()), new AuthenticatorHelper.OnAccountsUpdateListener() { @Override public void onAccountsUpdate(UserHandle userHandle) { updateAccounts(); } }); mBtAdapter = BluetoothAdapter.getDefaultAdapter(); mConnectivityListener = new ConnectivityListener(getContext(), new ConnectivityListener.Listener() { @Override
<|startcomment|> This doesn't look right. Is part of this CL missing? <|endcomment|>  public void onStart() { super.onStart(); mAuthenticatorHelper.listenToAccountUpdates(); IntentFilter btChangeFilter = new IntentFilter(); btChangeFilter.addAction(BluetoothDevice.ACTION_ACL_CONNECTED); btChangeFilter.addAction(BluetoothDevice.ACTION_ACL_DISCONNECTED); btChangeFilter.addAction(BluetoothAdapter.ACTION_STATE_CHANGED); <|startfocus|> getContext().registerReceiver(mBBCMReceiver, btChangeFilter); <|endfocus|>
<|startcomment|> May be too long. (and below) <|endcomment|>  List<X509Certificate> certPathList) throws GeneralSecurityException { if (debug != null) { debug.println("ForwardBuilder.verifyCert(SN: " + Debug.toHexString(cert.getSerialNumber()) + "\n Issuer: " + cert.getIssuerX500Principal() + ")" + "\n Subject: " + cert.getSubjectX500Principal() + ")"); } ForwardState currState = (ForwardState)currentState; <|startfocus|> // BEGIN Android-removed: Android doesn't use this mechanism for checking untrusted certificates. <|endfocus|> // // Don't bother to verify untrusted certificate more. // currState.untrustedChecker.check(cert, Collections.<String>emptySet()); // END Android-removed: Android doesn't use this mechanism for checking untrusted certificates. /* * check for looping - abort a loop if we encounter the same * certificate twice */ if (certPathList != null) { for (X509Certificate cpListCert : certPathList) { if (cert.equals(cpListCert)) { if (debug != null) { debug.println("loop detected!!"); }
<|startcomment|> no point in trying further so just teardown() and return here <|endcomment|>  } public void testScreenLayout() throws Exception { int expectedScreenLayout = computeScreenLayout(); int expectedSize = expectedScreenLayout & Configuration.SCREENLAYOUT_SIZE_MASK; int expectedLong = expectedScreenLayout & Configuration.SCREENLAYOUT_LONG_MASK; // Check that all four orientations report the same configuration value. for (int i = 0; i < ORIENTATIONS.length; i++) { Activity activity = startOrientationActivity(ORIENTATIONS[i]); if (activity.isInMultiWindowMode()) { // activity.setRequestedOrientation has no effect in multiwindow mode. <|startfocus|> continue; <|endfocus|> } Configuration mConfig = activity.getResources().getConfiguration(); int actualSize = mConfig.screenLayout & Configuration.SCREENLAYOUT_SIZE_MASK; int actualLong = mConfig.screenLayout & Configuration.SCREENLAYOUT_LONG_MASK; assertEquals("Expected screen size value of " + expectedSize + " but got " + actualSize + " for orientation " + ORIENTATIONS[i], expectedSize, actualSize); assertEquals("Expected screen long value of " + expectedLong + " but got " + actualLong
<|startcomment|> See PhoneNumberUtilsTest in frameworks/opt/telephony/tests/telephonytests/ There are some other cases there that might be good to cover; eg. assertTrue(PhoneNumberUtils.compare("+17005554141", "**31#+17005554141")); <|endcomment|>  public void testCompare() { assertTrue(PhoneNumberUtils.compare(null, null)); <|startfocus|> assertTrue(PhoneNumberUtils.compare("2023458246", "2023458246")); <|endfocus|> assertFalse(PhoneNumberUtils.compare("2023458246", "6503458246")); assertTrue(PhoneNumberUtils.compare("2023458246", "202-345-8246")); assertTrue(PhoneNumberUtils.compare("2023458246", "+12023458246")); assertTrue(PhoneNumberUtils.compare("2023458246", "+812023458246")); assertTrue(PhoneNumberUtils.compare("2023458246", "+1(202)345-8246"));
<|startcomment|> From the unit tests, might be good to also add: assertEquals("+18004664114", PhoneNumberUtils.formatNumberToE164("800-GOOG-114", "US") <|endcomment|>  public void testFormatNumberToE164() { assertNull(PhoneNumberUtils.formatNumber("invalid#", "US")); <|startfocus|> <|endfocus|> assertEquals("+12023458246", PhoneNumberUtils.formatNumberToE164("(202)345-8246", "US")); assertEquals("+812023458246", PhoneNumberUtils.formatNumberToE164("202-345-8246", "JP"));
<|startcomment|> This looks like new code, not formatting. <|endcomment|>  int connectionState = mStateMachine.getConnectionState(device); if (connectionState != BluetoothProfile.STATE_CONNECTED && connectionState != BluetoothProfile.STATE_CONNECTING) { return false; } mStateMachine.sendMessage(HeadsetStateMachine.DISCONNECT, device); return true; } public List<BluetoothDevice> getConnectedDevices() { enforceCallingOrSelfPermission(BLUETOOTH_PERM, "Need BLUETOOTH permission"); return mStateMachine.getConnectedDevices(); } <|startfocus|> public BluetoothDevice getCurrentDevice() { enforceCallingOrSelfPermission(BLUETOOTH_PERM, "Need BLUETOOTH permission"); return mStateMachine.getCurrentDevice(); } <|endfocus|> private List<BluetoothDevice> getDevicesMatchingConnectionStates(int[] states) { enforceCallingOrSelfPermission(BLUETOOTH_PERM, "Need BLUETOOTH permission"); return mStateMachine.getDevicesMatchingConnectionStates(states); } public int getConnectionState(BluetoothDevice device) { enforceCallingOrSelfPermission(BLUETOOTH_PERM, "Need BLUETOOTH permission"); return mStateMachine.getConnectionState(device); } public boolean setPriority(BluetoothDevice device, int priority) { enforceCallingOrSelfPermission(BLUETOOTH_ADMIN_PERM, "Need BLUETOOTH_ADMIN permission"); Settings.Global.putInt(getContentResolver(),
<|startcomment|> Seems like new code, not formatting. <|endcomment|> <|startfocus|> private void processSlcConnected(BluetoothDevice device) { <|endfocus|> if (mPhoneProxy != null) { try { mPhoneProxy.queryPhoneState(); } catch (RemoteException e) { Log.e(TAG, Log.getStackTraceString(new Throwable())); } } else { Log.e(TAG, "Handsfree phone proxy null for query phone state"); }
<|startcomment|> New code, not formatting. <|endcomment|>  } return BluetoothProfile.STATE_DISCONNECTED; } else { Log.e(TAG, "Bad currentState: " + currentState); return BluetoothProfile.STATE_DISCONNECTED; } } } List<BluetoothDevice> getConnectedDevices() { List<BluetoothDevice> devices = new ArrayList<BluetoothDevice>(); synchronized (this) { for (int i = 0; i < mConnectedDevicesList.size(); i++) devices.add(mConnectedDevicesList.get(i)); } return devices; } <|startfocus|> BluetoothDevice getCurrentDevice() { return mCurrentDevice; } <|endfocus|> boolean isAudioOn() { return (getCurrentState() == mAudioOn); } boolean isAudioConnected(BluetoothDevice device) { synchronized (this) { /* Additional check for audio state included for the case when PhoneApp queries Bluetooth Audio state, before we receive the close event from the stack for the sco disconnect issued in AudioOn state. This was causing a mismatch in the Incall screen UI. */ if (getCurrentState() == mAudioOn && mCurrentDevice.equals(device)
<|startcomment|> We enable this network and disable other networks here, right? Probably worth mentioning it. Otherwise, people would ask what if there is higher scored saved network around. <|endcomment|>  public void exit() { <|startfocus|> mWifiConfigManager.loadFromStore(); <|endfocus|>
<|startcomment|> add sth like "transition to". <|endcomment|>  public void exit() { <|startfocus|> mWifiConfigManager.loadFromStore(); <|endfocus|>
<|startcomment|> CDD <|endcomment|>  protected boolean hasLog(String str) throws DeviceNotAvailableException { String logs = getDevice().executeAdbCommand("logcat", "-v", "brief", "-d", mService + ":I", "*:S"); return logs.contains(str); } private void clearLogcat() throws DeviceNotAvailableException { getDevice().executeAdbCommand("logcat", "-c"); } protected boolean supportedHardware() throws DeviceNotAvailableException { // Customization by third-party tiles is only a requirement for devices <|startfocus|> // supporting Quick Settings UI component. <|endfocus|> // // As there is no public API to distinguish a device with Quick Settings // from others, the check below, as well as all the tests under // CtsSystemUiHostTestCases relying on the check may have false negatives. String features = getDevice().executeShellCommand("pm list features"); return !features.contains("android.hardware.type.television") && !features.contains("android.hardware.type.watch"); } } 
<|startcomment|> AdvertiserInfo <|endcomment|>  HandlerThread thread = new HandlerThread("BluetoothAdvertiseManager"); thread.start(); mHandler = new Handler(thread.getLooper()); } void cleanup() { logd("cleanup()"); cleanupNative(); mAdvertisers.clear(); sTempRegistrationId = -1; if (mHandler != null) { // Shut down the thread mHandler.removeCallbacksAndMessages(null); Looper looper = mHandler.getLooper(); if (looper != null) { looper.quit(); } mHandler = null; } } <|startfocus|> class AdvertiserBag { <|endfocus|> /* When id is negative, the registration is ongoing. When the registration finishes, id * becomes equal to advertiser_id */ public Integer id; public AdvertisingSetDeathRecipient deathRecipient; public IAdvertisingSetCallback callback; AdvertiserBag(Integer id, AdvertisingSetDeathRecipient deathRecipient, IAdvertisingSetCallback callback) { this.id = id; this.deathRecipient = deathRecipient; this.callback = callback; } } IBinder toBinder(IAdvertisingSetCallback e) { return ((IInterface) e).asBinder(); } class AdvertisingSetDeathRecipient implements IBinder.DeathRecipient {
<|startcomment|> unused? <|endcomment|> import android.os.ParcelFileDescriptor; import android.os.Process; import android.os.SystemClock; import android.telecom.PhoneAccount; import android.telecom.PhoneAccountHandle; import android.telecom.TelecomManager; import junit.framework.TestCase; import java.io.BufferedReader; import java.io.FileInputStream; import java.io.InputStream; import java.io.InputStreamReader; import java.nio.charset.StandardCharsets; import java.util.ArrayList; import java.util.Optional; import java.util.concurrent.CountDownLatch; import java.util.concurrent.TimeUnit; import java.util.function.Predicate; <|startfocus|> import java.util.stream.Collectors; <|endfocus|> public class TestUtils { static final String TAG = "TelecomCTSTests"; static final boolean HAS_TELECOM = Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP; static final long WAIT_FOR_STATE_CHANGE_TIMEOUT_MS = 10000; static final long WAIT_FOR_CALL_ADDED_TIMEOUT_S = 15; static final long WAIT_FOR_STATE_CHANGE_TIMEOUT_CALLBACK = 50; // Non-final to allow modification by tests not in this package (e.g. permission-related // tests in the Telecom2 test package.
<|startcomment|> If you do: import static android.net.util.NetworkConstants.RFC7421_PREFIX_LENGTH; you can keep this nice and short. <|endcomment|>  // Avoid unnecessary work on spurious updates. if (Objects.equals(mLastIPv6LinkProperties, v6only)) { return; } RaParams params = null; if (v6only != null) { params = new RaParams(); params.mtu = v6only.getMtu(); params.hasDefaultRoute = v6only.hasIPv6DefaultRoute(); for (LinkAddress linkAddr : v6only.getLinkAddresses()) { <|startfocus|> if (linkAddr.getPrefixLength() != NetworkConstants.RFC7421_IP_PREFIX_LENGTH) { continue; } <|endfocus|> final IpPrefix prefix = new IpPrefix( linkAddr.getAddress(), linkAddr.getPrefixLength()); params.prefixes.add(prefix); final Inet6Address dnsServer = getLocalDnsIpFor(prefix); if (dnsServer != null) { params.dnses.add(dnsServer); } } } // If v6only is null, we pass in null to setRaParams(), which handles // deprecation of any existing RA data. setRaParams(params); mLastIPv6LinkProperties = v6only;
<|startcomment|> You can just move this constant right up to below IPV6_ADDR_LEN. You can also s/_IP_/_/ out of its name. <|endcomment|>  */ public static final int IPV6_HEADER_LEN = 40; public static final int IPV6_PROTOCOL_OFFSET = 6; public static final int IPV6_SRC_ADDR_OFFSET = 8; public static final int IPV6_DST_ADDR_OFFSET = 24; public static final int IPV6_ADDR_LEN = 16; /** <|startfocus|> * IPv6 constants. * * See also: * - https://tools.ietf.org/html/rfc7421 */ public static final int RFC7421_IP_PREFIX_LENGTH = 64; /** <|endfocus|> * ICMPv6 constants. * * See also: * - https://tools.ietf.org/html/rfc4443 * - https://tools.ietf.org/html/rfc4861 */ public static final int ICMPV6_HEADER_MIN_LEN = 4; public static final int ICMPV6_ROUTER_SOLICITATION = 133; public static final int ICMPV6_ROUTER_ADVERTISEMENT = 134; public static final int ICMPV6_NEIGHBOR_SOLICITATION = 135; public static final int ICMPV6_NEIGHBOR_ADVERTISEMENT = 136; public static final int ICMPV6_ND_OPTION_MIN_LENGTH = 8;
<|startcomment|> [nit] If you felt ambitious, you could in this change: [1] airlift IPv6TetheringInterfaceServices' RFC7421_IP_PREFIX_LENGTH definition out of its file and into android.net.util.NetworkConstants (with s/IP/IPV6/ in the anem) [2] import and use NetworkConstants.RFC7421_IPV6_PREFIX_LENGTH here. <|endcomment|>  private boolean startIPv6() { try { enableInterfaceIpv6PrivacyExtensions(); setInterfaceIpv6RaRtInfoMaxPlen(ACCEPT_RA_RT_INFO_MAX_PLEN); mNwService.enableIpv6(mInterfaceName); <|startfocus|> } catch (IllegalStateException|RemoteException|ServiceSpecificException e) { logError("Unable to change interface settings: %s", e); <|endfocus|> return false; } return true;
<|startcomment|> Sorry, I failed to mention that "import static" lines seem to go between the "package" declaration and other regular lines (according to other files I've worked in), usually with a blank line surrounding the "import static" block (which in this is just a single line). <|endcomment|>  * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.server.connectivity.tethering; import android.net.INetd; import android.net.IpPrefix; import android.net.LinkAddress; import android.net.LinkProperties; import android.net.NetworkCapabilities; import android.net.NetworkState; import android.net.RouteInfo; import android.net.ip.RouterAdvertisementDaemon; import android.net.ip.RouterAdvertisementDaemon.RaParams; import android.net.util.NetdService; <|startfocus|> import static android.net.util.NetworkConstants.RFC7421_PREFIX_LENGTH; <|endfocus|> import android.os.INetworkManagementService; import android.os.ServiceSpecificException; import android.os.RemoteException; import android.util.Log; import android.util.Slog; import java.net.Inet6Address; import java.net.InetAddress; import java.net.NetworkInterface; import java.net.SocketException; import java.net.UnknownHostException; import java.util.ArrayList; import java.util.HashSet; import java.util.Objects; /** * @hide */ public class IPv6TetheringInterfaceServices { private static final String TAG = IPv6TetheringInterfaceServices.class.getSimpleName();
<|startcomment|> Same: this goes up before other imports. <|endcomment|> import android.net.apf.ApfFilter; import android.net.DhcpResults; import android.net.INetd; import android.net.InterfaceConfiguration; import android.net.LinkAddress; import android.net.LinkProperties; import android.net.LinkProperties.ProvisioningChange; import android.net.ProxyInfo; import android.net.RouteInfo; import android.net.StaticIpConfiguration; import android.net.dhcp.DhcpClient; import android.net.metrics.IpConnectivityLog; import android.net.metrics.IpManagerEvent; import android.net.util.MultinetworkPolicyTracker; <|startfocus|> import android.net.util.NetdService; import static android.net.util.NetworkConstants.RFC7421_PREFIX_LENGTH; <|endfocus|> import android.os.INetworkManagementService; import android.os.Message; import android.os.RemoteException; import android.os.ServiceManager; import android.os.ServiceSpecificException; import android.os.SystemClock; import android.system.OsConstants; import android.text.TextUtils; import android.util.LocalLog; import android.util.Log; import android.util.SparseArray; import com.android.internal.annotations.VisibleForTesting; import com.android.internal.util.IndentingPrintWriter; import com.android.internal.util.IState; import com.android.internal.util.State; import com.android.internal.util.StateMachine; import com.android.server.net.NetlinkTracker; import java.io.FileDescriptor;
<|startcomment|> Long line and Intent already has a convenience method you can use for this: final int dialogType = getIntent().getIntExtra(DIALOG_TYPE_KEY, INVALID_PICK); <|endcomment|>  protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); <|startfocus|> final Bundle extras = getIntent().getExtras(); final int dialogType = (extras == null ? INVALID_PICK : extras.getInt(DIALOG_TYPE_KEY, INVALID_PICK)); <|endfocus|> switch (dialogType) { case DATA_PICK: case CALLS_PICK: case SMS_PICK: createDialog(this, dialogType).show(); break; case PREFERRED_PICK: displayPreferredDialog(extras.getInt(PREFERRED_SIM)); break; default: throw new IllegalArgumentException("Invalid dialog type " + dialogType + " sent."); } 
<|startcomment|> Please include the test: {"12345*00000", "12346", "12345*00000"} I do not think this test will pass... <|endcomment|>  {"12345", "12345", "12345"}, {"12345", "67890", "67890"}, {"12345*00000", "12345", "12345*00000"}, {"12345*00000", "67890", "67890"}, {"12345*00000", "12345*00000", "12345*00000"}, {"12345;11111*00000", "12345", "12345"}, {"12345*00000;11111", "12345", "12345*00000"}, {"18412345*00000", "18412345", "18412345*00000"}, <|startfocus|> {"+8112345*00000", "+8112345", "+8112345*00000"}}; <|endfocus|> for (String[] testAddress : testAddressMappingSet) { mConnectionUT = new ImsPhoneConnection(mImsPhone, testAddress[0], mImsCT, mForeGroundCall, false); doReturn(testAddress[1]).when(mImsCallProfile) .getCallExtra(eq(ImsCallProfile.EXTRA_OI)); mConnectionUT.updateAddressDisplay(mImsCall); assertEquals(testAddress[2], mConnectionUT.getAddress()); }
<|startcomment|> Should you put "Set by the framework to indicate" here? <|endcomment|>  * @hide */ public static final int PROPERTY_IS_DOWNGRADED_CONFERENCE = 1<<6; /** * Set by the framework to indicate that the {@link Connection} originated from a self-managed * {@link ConnectionService}. * <p> * See {@link PhoneAccount#CAPABILITY_SELF_MANAGED}. */ public static final int PROPERTY_SELF_MANAGED = 1<<7; /** <|startfocus|> * When set, indicates that a connection has an active RTT session associated with it. <|endfocus|> * @hide */ @TestApi public static final int PROPERTY_IS_RTT = 1 << 8; //********************************************************************************************** // Next PROPERTY value: 1<<9 //********************************************************************************************** /** * Connection extra key used to store the last forwarded number associated with the current * connection. Used to communicate to the user interface that the connection was forwarded via * the specified number. */ public static final String EXTRA_LAST_FORWARDED_NUMBER = "android.telecom.extra.LAST_FORWARDED_NUMBER"; /**
<|startcomment|> don't do this, it's clear from the code. <|endcomment|>  private static final int STACK_EVENT = 101; private static final int DIALING_OUT_TIMEOUT = 102; private static final int START_VR_TIMEOUT = 103; private static final int CLCC_RSP_TIMEOUT = 104; private static final int CONNECT_TIMEOUT = 201; private static final int DIALING_OUT_TIMEOUT_VALUE = 10000; private static final int START_VR_TIMEOUT_VALUE = 5000; private static final int CLCC_RSP_TIMEOUT_VALUE = 5000; <|startfocus|> // Max number of HF connections at any time, default to 1 <|endfocus|> private int max_hf_connections = 1; private static final int NBS_CODEC = 1; private static final int WBS_CODEC = 2; // Keys are AT commands, and values are the company IDs. private static final Map<String, Integer> VENDOR_SPECIFIC_AT_COMMAND_COMPANY_ID; // Hash for storing the Audio Parameters like NREC for connected headsets private HashMap<BluetoothDevice, HashMap> mHeadsetAudioParam = new HashMap<BluetoothDevice, HashMap>(); // Hash for storing the Remotedevice BRSF private HashMap<BluetoothDevice, Integer> mHeadsetBrsf =
<|startcomment|> Can we also rename this to com.android.cellbroadcastreceiver.intent so all intents have the same domain? And maybe move this or the other two so all the intents definitions can stay together. Everything else LGTM. <|endcomment|> import android.preference.PreferenceManager; import android.provider.Telephony; import android.provider.Telephony.CellBroadcasts; import android.telephony.CarrierConfigManager; import android.telephony.cdma.CdmaSmsCbProgramData; import android.util.Log; import com.android.internal.telephony.TelephonyIntents; import com.android.internal.telephony.cdma.sms.SmsEnvelope; public class CellBroadcastReceiver extends BroadcastReceiver { private static final String TAG = "CellBroadcastReceiver"; static final boolean DBG = false; // STOPSHIP: change to false before ship <|startfocus|> public static final String CELLBROADCAST_START_CONFIG_ACTION = "android.cellbroadcastreceiver.START_CONFIG"; <|endfocus|> // Key to access the stored reminder interval default value private static final String CURRENT_INTERVAL_DEFAULT = "current_interval_default"; public static final String ACTION_MARK_AS_READ = "com.android.cellbroadcastreceiver.intent.action.MARK_AS_READ"; public static final String EXTRA_DELIVERY_TIME = "com.android.cellbroadcastreceiver.intent.extra.ID"; @Override public void onReceive(Context context, Intent intent) { onReceiveWithPrivilege(context, intent, false); } protected void onReceiveWithPrivilege(Context context, Intent intent, boolean privileged) {
<|startcomment|> will this happen anyway since we are going to the disconnected state? <|endcomment|>  public boolean processMessage(Message message) { logStateAndMessage(message, this); switch (message.what) { case WifiMonitor.WPS_SUCCESS_EVENT: // Ignore intermediate success, wait for full connection break; case WifiMonitor.NETWORK_CONNECTION_EVENT: if (loadNetworksFromSupplicantAfterWps()) { replyToMessage(mSourceMessage, WifiManager.WPS_COMPLETED); <|startfocus|> mWifiConnectivityManager.forceConnectivityScan(); <|endfocus|> } else { replyToMessage(mSourceMessage, WifiManager.WPS_FAILED, WifiManager.ERROR); } mSourceMessage.recycle(); mSourceMessage = null; deferMessage(message); transitionTo(mDisconnectedState); break; case WifiMonitor.WPS_OVERLAP_EVENT: replyToMessage(mSourceMessage, WifiManager.WPS_FAILED, WifiManager.WPS_OVERLAP_ERROR); mSourceMessage.recycle(); mSourceMessage = null; transitionTo(mDisconnectedState); break; case WifiMonitor.WPS_FAIL_EVENT: // Arg1 has the reason for the failure if ((message.arg1 != WifiManager.ERROR) || (message.arg2 != 0)) { replyToMessage(mSourceMessage, WifiManager.WPS_FAILED, message.arg1);
<|startcomment|> false? I think this method is supposed to return whether the connect succeeded <|endcomment|>  public boolean connect(Call call) { if (mIsConnected) { Log.addEvent(call, LogUtils.Events.INFO, "Already connected, ignoring request."); return true; } if (call.isSelfManaged() && !mInCallServiceInfo.isSelfManagedCallsSupported()) { <|startfocus|> return true; <|endfocus|> } Intent intent = new Intent(InCallService.SERVICE_INTERFACE); intent.setComponent(mInCallServiceInfo.getComponentName()); if (call != null && !call.isIncoming() && !call.isExternalCall()){ intent.putExtra(TelecomManager.EXTRA_OUTGOING_CALL_EXTRAS, call.getIntentExtras()); intent.putExtra(TelecomManager.EXTRA_PHONE_ACCOUNT_HANDLE, call.getTargetPhoneAccount()); } Log.i(this, "Attempting to bind to InCall %s, with %s", mInCallServiceInfo, intent); mIsConnected = true; if (!mContext.bindServiceAsUser(intent, mServiceConnection, Context.BIND_AUTO_CREATE | Context.BIND_FOREGROUND_SERVICE, UserHandle.CURRENT)) { Log.w(this, "Failed to connect."); mIsConnected = false; } 
<|startcomment|> nit: whitespace issues <|endcomment|>  public CallerInfoAsyncQuery startQuery(int token, Context context, <|startfocus|> String number, CallerInfoAsyncQuery.OnQueryCompleteListener listener, Object cookie) { <|endfocus|> Log.i(TelecomSystem.getInstance(), "CallerInfoAsyncQuery.startQuery number=%s cookie=%s", Log.pii(number), cookie); return CallerInfoAsyncQuery.startQuery( token, context, number, listener, cookie);
<|startcomment|> We're already using 1 for missed call notifier. <|endcomment|>  */ public class IncomingCallNotifier extends CallsManagerListenerBase { public interface IncomingCallNotifierFactory { IncomingCallNotifier make(Context context, CallsManagerProxy mCallsManagerProxy); } /** * Eliminates strict dependency between this class and CallsManager. */ public interface CallsManagerProxy { boolean hasCallsForOtherPhoneAccount(PhoneAccountHandle phoneAccountHandle); } // Notification for incoming calls. This is interruptive and will show up as a HUN. <|startfocus|> private static final int NOTIFICATION_INCOMING_CALL = 1; <|endfocus|> public final Call.ListenerBase mCallListener = new Call.ListenerBase() { @Override public void onCallerInfoChanged(Call call) { if (mIncomingCall != call) { return; } showIncomingCallNotification(mIncomingCall); } }; private final Context mContext; private final NotificationManager mNotificationManager; private final Set<Call> mCalls = new ArraySet<>(); private CallsManagerProxy mCallsManagerProxy; // The current incoming call we are displaying UX for. private Call mIncomingCall; public IncomingCallNotifier(Context context) { mContext = context; mNotificationManager =
<|startcomment|> No need for @hide here. <|endcomment|>  } public boolean isConnected() { return sc.isConnected(); } public boolean isBound() { return sc.localAddress() != null; } public boolean isClosed() { return !sc.isOpen(); } public boolean isInputShutdown() { return !sc.isInputOpen(); } public boolean isOutputShutdown() { return !sc.isOutputOpen(); } /** * Android-added: for testing and internal use. <|startfocus|> * * @hide internal use only <|endfocus|> */ @Override public FileDescriptor getFileDescriptor$() { return sc.getFD(); } } 
<|startcomment|> please add a comment that this works without actual files because it uses the their extensions to deduce mime type <|endcomment|> kage libcore.java.nio.file.spi; import org.junit.Test; import java.nio.file.Paths; import java.nio.file.spi.FileTypeDetector; import static org.junit.Assert.assertEquals; public class FileTypeDetectorTest { @Test public void test_probeFileType() throws Exception { <|startfocus|> FileTypeDetector defaultFileTypeDetector = sun.nio.fs.DefaultFileTypeDetector.create(); <|endfocus|> assertEquals("text/plain", defaultFileTypeDetector.probeContentType(Paths.get("file.txt"))); assertEquals("text/x-java", defaultFileTypeDetector.probeContentType(Paths.get("file.java"))); } } 
<|startcomment|> shouldn't this not be called default now? Just mCarrierConfigPackage. Same in the config name. <|endcomment|> import java.io.FileOutputStream; import java.io.FilenameFilter; import java.io.IOException; import java.io.PrintWriter; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; import java.util.List; /** * CarrierConfigLoader binds to privileged carrier apps to fetch carrier config overlays. */ public class CarrierConfigLoader extends ICarrierConfigLoader.Stub { private static final String LOG_TAG = "CarrierConfigLoader"; <|startfocus|> // Package name for default carrier config app, bundled with system image. private final String mDefaultCarrierConfigPackage; <|endfocus|> /** The singleton instance. */ private static CarrierConfigLoader sInstance; // The context for phone app, passed from PhoneGlobals. private Context mContext; // Carrier configs from default app, indexed by phoneID. private PersistableBundle[] mConfigFromDefaultApp; // Carrier configs from privileged carrier config app, indexed by phoneID. private PersistableBundle[] mConfigFromCarrierApp; // Service connection for binding to config app. private CarrierServiceConnection[] mServiceConnection; // Broadcast receiver for Boot intents, register intent filter in construtor.
<|startcomment|> Java style: rename to "adminUser" (the "is" prefix is used only in method names) <|endcomment|>  enforceTetherAccessPermission(); return mTethering.getTetheredIfaces(); } @Override public String[] getTetheringErroredIfaces() { enforceTetherAccessPermission(); return mTethering.getErroredIfaces(); } @Override public String[] getTetheredDhcpRanges() { enforceConnectivityInternalPermission(); return mTethering.getTetheredDhcpRanges(); } // if ro.tether.denied = true we default to no tethering // gservices could set the secure setting to 1 though to enable it on a build where it // had previously been turned off. @Override public boolean isTetheringSupported() { enforceTetherAccessPermission(); <|startfocus|> int defaultVal = (SystemProperties.get("ro.tether.denied").equals("true") ? 0 : 1); <|endfocus|> boolean tetherEnabledInSettings = (Settings.Global.getInt(mContext.getContentResolver(), Settings.Global.TETHER_SUPPORTED, defaultVal) != 0) && !mUserManager.hasUserRestriction(UserManager.DISALLOW_CONFIG_TETHERING); return tetherEnabledInSettings && mUserManager.isAdminUser() && mTethering.hasTetherableConfiguration(); } @Override public void startTethering(int type, ResultReceiver receiver, boolean showProvisioningUi) {
<|startcomment|> To make this a little more readable: The majority of the impl in this method has an extra indent because of the else. If this seems less readable, then maybe adding a comment above the if would alleviate that concern. Having the else makes it harder to read since you end up with deep indents near the end of the method. <|endcomment|>  private boolean updateBssidBlacklist(String bssid, boolean enable, int reasonCode) { if (enable) { return mBssidBlacklist.remove(bssid) != null; <|startfocus|> } else { BssidBlacklistStatus status = mBssidBlacklist.get(bssid); if (status == null) { // First time for this BSSID status = new BssidBlacklistStatus(); mBssidBlacklist.put(bssid, status); } <|endfocus|> status.blacklistedTimeStamp = mClock.getElapsedSinceBootMillis(); status.counter++; if (!status.isBlacklisted) { if (status.counter >= BSSID_BLACKLIST_THRESHOLD || reasonCode == REASON_CODE_AP_UNABLE_TO_HANDLE_NEW_STA) { status.isBlacklisted = true; return true; } } return false; }
<|startcomment|> spelling <|endcomment|>  when(mClock.getElapsedSinceBootMillis()).thenReturn(SystemClock.elapsedRealtime() + WifiConnectivityManager.BSSID_BLACKLIST_EXPIRE_TIME_MS); mWifiConnectivityManager.forceConnectivityScan(); assertFalse(mWifiConnectivityManager.isBssidDisabled(bssid)); } /** * When WifiConnectivityManager is on and Wifi client mode is enabled, framework * queries firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability. * * Expected behavior: WifiConnectivityManager#setWifiEnabled calls into <|startfocus|> * WifiConnectivityHelper#getFirmwareRoamingIinfo <|endfocus|> */ @Test public void verifyGetFirmwareRoamingInfoIsCalledWhenEnableWiFiAndWcmOn() { reset(mWifiConnectivityHelper); // WifiConnectivityManager is on by default mWifiConnectivityManager.setWifiEnabled(true); verify(mWifiConnectivityHelper).getFirmwareRoamingInfo(); } /** * When WifiConnectivityManager is off, verify that framework does not * query firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability when enabling Wifi client mode. * * Expected behavior: WifiConnectivityManager#setWifiEnabled does not call into * WifiConnectivityHelper#getFirmwareRoamingIinfo
<|startcomment|> spelling <|endcomment|>  reset(mWifiConnectivityHelper); // WifiConnectivityManager is on by default mWifiConnectivityManager.setWifiEnabled(true); verify(mWifiConnectivityHelper).getFirmwareRoamingInfo(); } /** * When WifiConnectivityManager is off, verify that framework does not * query firmware via WifiConnectivityHelper to check if firmware roaming is * supported and its capability when enabling Wifi client mode. * * Expected behavior: WifiConnectivityManager#setWifiEnabled does not call into <|startfocus|> * WifiConnectivityHelper#getFirmwareRoamingIinfo <|endfocus|> */ @Test public void verifyGetFirmwareRoamingInfoIsNotCalledWhenEnableWiFiAndWcmOff() { reset(mWifiConnectivityHelper); mWifiConnectivityManager.enable(false); mWifiConnectivityManager.setWifiEnabled(true); verify(mWifiConnectivityHelper, times(0)).getFirmwareRoamingInfo(); } /* * Firmware supports controlled roaming. * Connect to a network from the DISCONNECTED state. * * Expected behavior: WifiConnectivityManager calls * WifiStateMachine.startConnectToNetwork() with the * expected candidate network ID, and the BSSID value should be * 'any' since firmware controls the roaming. */ @Test
<|startcomment|> do you have a test for a specific Bssid + framework roam? <|endcomment|> <|startfocus|> public void useAnyBssidForConnectionIfFirmwareControlsRoaming() { <|endfocus|> // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork( CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY);
<|startcomment|> maybe change to noFrameworkRoamingIfConnectedAndFirmwareRoamingSupported <|endcomment|> <|startfocus|> public void noFrameworkRoamingIfFirmwareControlRoaming() { <|endfocus|> // Mock the currently connected network which has the same networkID and // SSID as the one to be selected. WifiConfiguration currentNetwork = generateWifiConfig( 0, CANDIDATE_NETWORK_ID, CANDIDATE_SSID, false, true, null, null); when(mWifiConfigManager.getConfiguredNetwork(anyInt())).thenReturn(currentNetwork); // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set WiFi to connected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_CONNECTED); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); verify(mWifiStateMachine, times(0)).startRoamToNetwork( anyInt(), anyObject());
<|startcomment|> you could add a check for an empty blacklist and return to avoid calling the code below. <|endcomment|>  private void refreshBssidBlacklist() { <|startfocus|> boolean updated = false; <|endfocus|> Iterator<BssidBlacklistStatus> iter = mBssidBlacklist.values().iterator(); Long currentTimeStamp = mClock.getElapsedSinceBootMillis(); while (iter.hasNext()) { BssidBlacklistStatus status = iter.next(); if (status.isBlacklisted && ((currentTimeStamp - status.blacklistedTimeStamp) >= BSSID_BLACKLIST_EXPIRE_TIME_MS)) { iter.remove(); updated = true; } } if (updated && mConnectivityHelper.isFirmwareRoamingSupported()) { updateFirmwareBssidBlacklist(); }
<|startcomment|> maybe "equivalent" since they aren't actually the same, but we are treating them as "equals" <|endcomment|>  // network(same SSID & security type) as the currently connected one. // This might save a disconnection triggered by network switch when // the score of the currently connected BSSID is lower than a network // with a different SSID, but within the currently connected network // there is a BSSID better than the currently connected BSSID. // This is under the assumption that firmware will roam the device // to that better BSSID. score += mSameBssidAward; <|startfocus|> sbuf.append(" Firmware roaming same BSSID bonus: ") <|endfocus|> .append(mSameBssidAward).append(","); } } // When firmware roaming is supported, the same BSSID award is already // applied above, skip it. if (!mConnectivityHelper.isFirmwareRoamingSupported()) { // Same BSSID award. if (currentBssid != null && currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Same BSSID as the current one bonus: ").append(mSameBssidAward) .append(","); } } // Security award.
<|startcomment|> add CAP_TO_INDEX and CAP_TO_MASK to OsConstants, like we did S_ISDIR and friends? https://cs.corp.google.com/android/libcore/luni/src/main/java/android/system/OsConstants.java?q=file:osconstants.java&sq=package:%5Eandroid$&l=29 <|endcomment|>  data[0] = new StructCapUserData(data[0].effective, data[0].permitted, data[0].permitted); data[1] = new StructCapUserData(data[1].effective, data[1].permitted, data[1].permitted); Os.capset(header, data); } for (int i = 0; i < 64; i++) { <|startfocus|> int dataIndex = i / 32; int bitShift = i % 32; if ((data[dataIndex].inheritable & (1 << bitShift)) != 0) { <|endfocus|> try { Os.prctl(OsConstants.PR_CAP_AMBIENT, OsConstants.PR_CAP_AMBIENT_RAISE, i, 0, 0); } catch (ErrnoException ex) { Slog.e(RuntimeInit.TAG, "RuntimeInit: Failed to raise ambient capability " + i, ex); } } } } catch (Exception e) { Slog.e(RuntimeInit.TAG, "RuntimeInit: Failed to preserve capabilities", e); }
<|startcomment|> spelling <|endcomment|>  * This is supposed to be from Telephony service. * otherwise we think it is from other applications. * @return Returns true if the country code passed in is acceptable. */ public synchronized boolean setCountryCode(String countryCode) { if (DBG) Log.d(TAG, "Receive set country code request: " + countryCode); // Empty country code. if (TextUtils.isEmpty(countryCode)) { <|startfocus|> if (DBG) Log.d(TAG, "Revceived empty country code, reset to default country code"); <|endfocus|> mTelephonyCountryCode = null; } else { mTelephonyCountryCode = countryCode.toUpperCase(); } // If wpa_supplicant is ready we set the country code now, otherwise it will be // set once wpa_supplicant is ready. if (mReady) { updateCountryCode(); } return true; } /** * Method to get the Country Code that was sent to wpa_supplicant. * * @return Returns the local copy of the Country Code that was sent to the driver upon * setReadyForChange(true).
<|startcomment|> Do we have to worry that "x" is an unsigned value in C code, whereas here it's a signed value? Shouldn't we be using ">>>" (bitwise shift) instead of ">>" (arithmetic shift)? <|endcomment|>  * See the License for the specific language governing permissions and * limitations under the License. */ package android.system; /** * Constants and helper functions for use with {@link Os}. */ public final class OsConstants { private OsConstants() { } /** * Returns the index of the element in the cap_user_data array that this capability is stored * in. * @hide */ <|startfocus|> public static int CAP_TO_INDEX(int x) { return x >> 5; } <|endfocus|> /** * Returns the mask for the given capability. This is relative to the capability's cap_user_data * element, the index of which can be retrieved with CAP_TO_INDEX. * @hide */ public static int CAP_TO_MASK(int x) { return 1 << (x & 31); } /** * Tests whether the given mode is a block device. */ public static boolean S_ISBLK(int mode) { return (mode & S_IFMT) == S_IFBLK; } /**
<|startcomment|> you could just put the buildBssidBlacklist call here (no real preference on this, just doesn't seem to be used after this) <|endcomment|>  refreshBssidBlacklist(); if (mStateMachine.isLinkDebouncing() || mStateMachine.isSupplicantTransientState()) { localLog(listenerName + " onResults: No network selection because linkDebouncing is " + mStateMachine.isLinkDebouncing() + " and supplicantTransient is " + mStateMachine.isSupplicantTransientState()); return false; } localLog(listenerName + " onResults: start network selection"); HashSet<String> blacklistedBssids = buildBssidBlacklist(); WifiConfiguration candidate = <|startfocus|> mNetworkSelector.selectNetwork(scanDetails, blacklistedBssids, mWifiInfo, <|endfocus|> mStateMachine.isConnected(), mStateMachine.isDisconnected(), mUntrustedConnectionAllowed); mWifiLastResortWatchdog.updateAvailableNetworks( mNetworkSelector.getFilteredScanDetails()); mWifiMetrics.countScanResults(scanDetails); if (candidate != null) { localLog(listenerName + ": WNS candidate-" + candidate.SSID); connectToNetwork(candidate); return true; } else { return false; }
<|startcomment|> Now I am a bit confused with this test. Shouldn't it have a setup like below and then confirm the selected BSSID is replaced with ANY? <|endcomment|> <|startfocus|> public void useAnyBssidForConnectionIfFirmwareControlsRoaming() { <|endfocus|> // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork( CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY);
<|startcomment|> is this possible? it is a final variable <|endcomment|>  private void localLog(String log) { <|startfocus|> if (mLocalLog != null) { mLocalLog.log(log); } <|endfocus|>
<|startcomment|> Please wrap this line. <|endcomment|>  private void updateEverything() { BatteryInfo info = BatteryInfo.getBatteryInfo(getContext(), mBatteryBroadcast, mStats, SystemClock.elapsedRealtime() * 1000); final View view = getView(); if (mShowCellSignal) { info.bindHistory((UsageView) view.findViewById(R.id.battery_usage), mChargingParser, <|startfocus|> mScreenOn, mGpsParser, mFlashlightParser, mCameraParser, mWifiParser, mCpuParser, mPhoneParser); <|endfocus|> } else { info.bindHistory((UsageView) view.findViewById(R.id.battery_usage), mChargingParser, mScreenOn, mGpsParser, mFlashlightParser, mCameraParser, mWifiParser, mCpuParser); } ((TextView) view.findViewById(R.id.charge)).setText(info.batteryPercentString); ((TextView) view.findViewById(R.id.estimation)).setText(info.remainingLabel); bindData(mChargingParser, R.string.battery_stats_charging_label, R.id.charging_group); bindData(mScreenOn, R.string.battery_stats_screen_on_label, R.id.screen_on_group); bindData(mGpsParser, R.string.battery_stats_gps_on_label, R.id.gps_group);
<|startcomment|> Also this line. <|endcomment|>  SystemClock.elapsedRealtime() * 1000); final View view = getView(); if (mShowCellSignal) { info.bindHistory((UsageView) view.findViewById(R.id.battery_usage), mChargingParser, mScreenOn, mGpsParser, mFlashlightParser, mCameraParser, mWifiParser, mCpuParser, mPhoneParser); } else { info.bindHistory((UsageView) view.findViewById(R.id.battery_usage), mChargingParser, <|startfocus|> mScreenOn, mGpsParser, mFlashlightParser, mCameraParser, mWifiParser, mCpuParser); <|endfocus|> } ((TextView) view.findViewById(R.id.charge)).setText(info.batteryPercentString); ((TextView) view.findViewById(R.id.estimation)).setText(info.remainingLabel); bindData(mChargingParser, R.string.battery_stats_charging_label, R.id.charging_group); bindData(mScreenOn, R.string.battery_stats_screen_on_label, R.id.screen_on_group); bindData(mGpsParser, R.string.battery_stats_gps_on_label, R.id.gps_group); bindData(mFlashlightParser, R.string.battery_stats_flashlight_on_label, R.id.flashlight_group);
<|startcomment|> And this :) <|endcomment|>  bindData(mFlashlightParser, R.string.battery_stats_flashlight_on_label, R.id.flashlight_group); bindData(mCameraParser, R.string.battery_stats_camera_on_label, R.id.camera_group); bindData(mWifiParser, R.string.battery_stats_wifi_running_label, R.id.wifi_group); bindData(mCpuParser, R.string.battery_stats_wake_lock_label, R.id.cpu_group); if (mShowCellSignal) { <|startfocus|> bindData(mPhoneParser, R.string.battery_stats_phone_signal_label, R.id.cell_network_group); <|endfocus|> } else { view.findViewById(R.id.cell_network_group).setVisibility(View.GONE); }
<|startcomment|> Please explain here and below how the lack of home screen was causing this test to fail. <|endcomment|>  // Wait until it finishes and end the reciever then. assertEquals(RESULT_PASS, appEndReceiver.waitForActivity()); appEndReceiver.close(); if (!noHomeScreen()) { // At this time the timerReceiver should not fire, even though the activity has shut // down, because we are back to the home screen. assertEquals(RESULT_TIMEOUT, timeReceiver.waitForActivity()); assertTrue(timeReceiver.mTimeUsed == 0); <|startfocus|> } else { <|endfocus|> assertEquals(RESULT_PASS, timeReceiver.waitForActivity()); } // Issuing now another activity will trigger the timing information release. final Intent dummyIntent = new Intent(context, MockApplicationActivity.class); dummyIntent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK); final Activity activity = mInstrumentation.startActivitySync(dummyIntent); // Wait until it finishes and end the reciever then. assertEquals(RESULT_PASS, timeReceiver.waitForActivity()); timeReceiver.close(); assertTrue(timeReceiver.mTimeUsed != 0); } /** * Verify that the TimeTrackingAPI works properly when switching away from the monitored task. */
<|startcomment|> rewrap line <|endcomment|>  * getPhoneId(DEFAULT_SUB_ID) will return the same as getPhoneId(getDefaultSubId()). * * Finally, any getters which perform the mapping between subscriptions, slots and phones will * return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID. All other getters <|startfocus|> * will fail and return the appropriate error value. Ie calling getSlotIndex(INVALID_SUBSCRIPTION_ID) * will return INVALID_SIM_SLOT_INDEX and calling getSubInfoForSubscriber(INVALID_SUBSCRIPTION_ID) * will return null. <|endfocus|> * */ public class SubscriptionController extends ISub.Stub { static final String LOG_TAG = "SubscriptionController"; static final boolean DBG = true; static final boolean VDBG = false; static final int MAX_LOCAL_LOG_LINES = 500; // TODO: Reduce to 100 when 17678050 is fixed private ScLocalLog mLocalLog = new ScLocalLog(MAX_LOCAL_LOG_LINES); /** * Copied from android.util.LocalLog with flush() adding flush and line number * TODO: Update LocalLog */ static class ScLocalLog { private LinkedList<String> mLog;
<|startcomment|> slotIndex? <|endcomment|> import java.io.PrintWriter; import java.util.ArrayList; import java.util.Collections; import java.util.Comparator; import java.util.Iterator; import java.util.LinkedList; import java.util.List; import java.util.Map; import java.util.Map.Entry; import java.util.Set; import java.util.concurrent.ConcurrentHashMap; /** * SubscriptionController to provide an inter-process communication to * access Sms in Icc. * <|startfocus|> * Any setters which take subId, slotId or phoneId as a parameter will throw an exception if the <|endfocus|> * parameter equals the corresponding INVALID_XXX_ID or DEFAULT_XXX_ID. * * All getters will lookup the corresponding default if the parameter is DEFAULT_XXX_ID. Ie calling * getPhoneId(DEFAULT_SUB_ID) will return the same as getPhoneId(getDefaultSubId()). * * Finally, any getters which perform the mapping between subscriptions, slots and phones will * return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID. All other getters * will fail and return the appropriate error value. Ie calling getSlotId(INVALID_SUBSCRIPTION_ID)
<|startcomment|> getSlotIndex <|endcomment|>  * * All getters will lookup the corresponding default if the parameter is DEFAULT_XXX_ID. Ie calling * getPhoneId(DEFAULT_SUB_ID) will return the same as getPhoneId(getDefaultSubId()). * * Finally, any getters which perform the mapping between subscriptions, slots and phones will * return the corresponding INVALID_XXX_ID if the parameter is INVALID_XXX_ID. All other getters <|startfocus|> * will fail and return the appropriate error value. Ie calling getSlotId(INVALID_SUBSCRIPTION_ID) <|endfocus|> * will return INVALID_SLOT_ID and calling getSubInfoForSubscriber(INVALID_SUBSCRIPTION_ID) * will return null. * */ public class SubscriptionController extends ISub.Stub { static final String LOG_TAG = "SubscriptionController"; static final boolean DBG = true; static final boolean VDBG = false; static final int MAX_LOCAL_LOG_LINES = 500; // TODO: Reduce to 100 when 17678050 is fixed private ScLocalLog mLocalLog = new ScLocalLog(MAX_LOCAL_LOG_LINES); /** * Copied from android.util.LocalLog with flush() adding flush and line number
<|startcomment|> slotIndex <|endcomment|>  } } /** * @return the maximum number of subscriptions this device will support at any one time. */ @Override public int getActiveSubInfoCountMax() { // FIXME: This valid now but change to use TelephonyDevController in the future return mTelephonyManager.getSimCount(); } /** * Add a new SubInfoRecord to subinfo database if needed * @param iccId the IccId of the SIM card <|startfocus|> * @param slotId the slot which the SIM is inserted <|endfocus|> * @return 0 if success, < 0 on error. */ @Override public int addSubInfoRecord(String iccId, int slotId) { if (DBG) logdl("[addSubInfoRecord]+ iccId:" + SubscriptionInfo.givePrintableIccid(iccId) + " slotId:" + slotId); enforceModifyPhoneState("addSubInfoRecord"); // Now that all security checks passes, perform the operation as ourselves. final long identity = Binder.clearCallingIdentity(); try { if (iccId == null) {
<|startcomment|> slotIndex <|endcomment|>  public int addSubInfoRecord(String iccId, int slotId) { if (DBG) logdl("[addSubInfoRecord]+ iccId:" + SubscriptionInfo.givePrintableIccid(iccId) + <|startfocus|> " slotId:" + slotId); <|endfocus|> enforceModifyPhoneState("addSubInfoRecord"); // Now that all security checks passes, perform the operation as ourselves. final long identity = Binder.clearCallingIdentity(); try { if (iccId == null) { if (DBG) logdl("[addSubInfoRecord]- null iccId"); return -1; } ContentResolver resolver = mContext.getContentResolver(); Cursor cursor = resolver.query(SubscriptionManager.CONTENT_URI, new String[]{SubscriptionManager.UNIQUE_KEY_SUBSCRIPTION_ID, SubscriptionManager.SIM_SLOT_INDEX, SubscriptionManager.NAME_SOURCE}, SubscriptionManager.ICC_ID + "=?", new String[]{iccId}, null); int color = getUnusedColor(mContext.getOpPackageName()); boolean setDisplayName = false; try { if (cursor == null || !cursor.moveToFirst()) { setDisplayName = true; ContentValues value = new ContentValues();
<|startcomment|> slotIndex - there may be more. Please do a search. I stopped looking here. <|endcomment|>  public int addSubInfoRecord(String iccId, int slotId) { if (DBG) logdl("[addSubInfoRecord]+ iccId:" + SubscriptionInfo.givePrintableIccid(iccId) + <|startfocus|> " slotId:" + slotId); <|endfocus|> enforceModifyPhoneState("addSubInfoRecord"); // Now that all security checks passes, perform the operation as ourselves. final long identity = Binder.clearCallingIdentity(); try { if (iccId == null) { if (DBG) logdl("[addSubInfoRecord]- null iccId"); return -1; } ContentResolver resolver = mContext.getContentResolver(); Cursor cursor = resolver.query(SubscriptionManager.CONTENT_URI, new String[]{SubscriptionManager.UNIQUE_KEY_SUBSCRIPTION_ID, SubscriptionManager.SIM_SLOT_INDEX, SubscriptionManager.NAME_SOURCE}, SubscriptionManager.ICC_ID + "=?", new String[]{iccId}, null); int color = getUnusedColor(mContext.getOpPackageName()); boolean setDisplayName = false; try { if (cursor == null || !cursor.moveToFirst()) { setDisplayName = true; ContentValues value = new ContentValues();
<|startcomment|> rename <|endcomment|> import com.android.internal.telephony.Phone; import com.android.internal.telephony.PhoneConstants; import com.android.internal.telephony.SubscriptionController; import com.android.internal.telephony.TelephonyIntents; import java.io.FileDescriptor; import java.io.PrintWriter; import java.util.concurrent.atomic.AtomicInteger; import java.util.List; // must extend SubscriptionController as some people use it directly within-process public class SubscriptionControllerMock extends SubscriptionController { final AtomicInteger mDefaultDataSubId = new AtomicInteger(INVALID_SUBSCRIPTION_ID); final ITelephonyRegistry.Stub mTelephonyRegistry; <|startfocus|> final int[][] mSlotIdxToSubId; <|endfocus|> public static SubscriptionController init(Phone phone) { throw new RuntimeException("not implemented"); } public static SubscriptionController init(Context c, CommandsInterface[] ci) { throw new RuntimeException("not implemented"); } public static SubscriptionController getInstance() { throw new RuntimeException("not implemented"); } public SubscriptionControllerMock(Context c, ITelephonyRegistry.Stub tr, int phoneCount) { super(c); mTelephonyRegistry = tr; mSlotIdxToSubId = new int[phoneCount][];
<|startcomment|> rename <|endcomment|> <|startfocus|> public SubscriptionInfo getActiveSubscriptionInfoForSimSlotIndex(int slotIdx, String cp){ <|endfocus|> throw new RuntimeException("not implemented");
<|startcomment|> rename <|endcomment|> <|startfocus|> private boolean isInvalidSlotId(int slotIdx) { if (slotIdx < 0 || slotIdx >= mSlotIdxToSubId.length) return true; <|endfocus|> return false;
<|startcomment|> rename <|endcomment|> <|startfocus|> public int[] getSubId(int slotIdx) { if (isInvalidSlotId(slotIdx)) { <|endfocus|> return null; } return mSlotIdxToSubId[slotIdx];
<|startcomment|> rename <|endcomment|> <|startfocus|> public void setSlotSubId(int slotIdx, int subId) { if (isInvalidSlotId(slotIdx)) { throw new RuntimeException("invalid slot specified" + slotIdx); <|endfocus|> } if (mSlotIdxToSubId[slotIdx][0] != subId) { mSlotIdxToSubId[slotIdx][0] = subId; try { mTelephonyRegistry.notifySubscriptionInfoChanged(); } catch (RemoteException ex) {} }
<|startcomment|> rename? <|endcomment|> <|startfocus|> public SubscriptionInfo getActiveSubscriptionInfoForSimSlotIndex(int slotIdx, <|endfocus|> String callingPackage) { if (!canReadPhoneState(callingPackage, "getActiveSubscriptionInfoForSimSlotIndex")) { return null; } // Now that all security checks passes, perform the operation as ourselves. final long identity = Binder.clearCallingIdentity(); try { List<SubscriptionInfo> subList = getActiveSubscriptionInfoList( mContext.getOpPackageName()); if (subList != null) { for (SubscriptionInfo si : subList) { if (si.getSimSlotIndex() == slotIdx) { if (DBG) { logd("[getActiveSubscriptionInfoForSimSlotIndex]+ slotIdx=" + slotIdx + " subId=" + si); } return si; } } if (DBG) { logd("[getActiveSubscriptionInfoForSimSlotIndex]+ slotIdx=" + slotIdx + " subId=null"); } } else { if (DBG) { logd("[getActiveSubscriptionInfoForSimSlotIndex]+ subList=null"); } } } finally { Binder.restoreCallingIdentity(identity); } 
<|startcomment|> this? <|endcomment|> <|startfocus|> public int[] getSubId(int slotIdx) { if (VDBG) printStackTrace("[getSubId]+ slotIdx=" + slotIdx); <|endfocus|> // Map default slotIdx to the current default subId. // TODO: Not used anywhere sp consider deleting as it's somewhat nebulous // as a slot maybe used for multiple different type of "connections" // such as: voice, data and sms. But we're doing the best we can and using // getDefaultSubId which makes a best guess. if (slotIdx == SubscriptionManager.DEFAULT_SIM_SLOT_INDEX) { slotIdx = getSlotId(getDefaultSubId()); if (VDBG) logd("[getSubId] map default slotIdx=" + slotIdx); } // Check that we have a valid SlotIdx if (!SubscriptionManager.isValidSlotId(slotIdx)) { if (DBG) logd("[getSubId]- invalid slotIdx=" + slotIdx); return null; } // Check if we've got any SubscriptionInfo records using slotIdToSubId as a surrogate. int size = sSlotIdxToSubId.size();
<|startcomment|> this? <|endcomment|> <|startfocus|> private int[] getDummySubIds(int slotIdx) { <|endfocus|> // FIXME: Remove notion of Dummy SUBSCRIPTION_ID. // I tested this returning null as no one appears to care, // but no connection came up on sprout with two sims. // We need to figure out why and hopefully remove DummySubsIds!!! int numSubs = getActiveSubInfoCountMax(); if (numSubs > 0) { int[] dummyValues = new int[numSubs]; for (int i = 0; i < numSubs; i++) { dummyValues[i] = SubscriptionManager.DUMMY_SUBSCRIPTION_ID_BASE - slotIdx; } if (VDBG) { logd("getDummySubIds: slotIdx=" + slotIdx + " return " + numSubs + " DummySubIds with each subId=" + dummyValues[0]); } return dummyValues; } else { return null; }
<|startcomment|> rename this as well? <|endcomment|>  pw.println(" defaultDataPhoneId=" + SubscriptionManager .from(mContext).getDefaultDataPhoneId()); pw.println(" defaultVoicePhoneId=" + SubscriptionManager.getDefaultVoicePhoneId()); pw.println(" defaultSmsPhoneId=" + SubscriptionManager .from(mContext).getDefaultSmsPhoneId()); pw.flush(); <|startfocus|> for (Entry<Integer, Integer> entry : sSlotIdxToSubId.entrySet()) { pw.println(" sSlotIdxToSubId[" + entry.getKey() + "]: subId=" + entry.getValue()); <|endfocus|> } pw.flush(); pw.println("++++++++++++++++++++++++++++++++"); List<SubscriptionInfo> sirl = getActiveSubscriptionInfoList( mContext.getOpPackageName()); if (sirl != null) { pw.println(" ActiveSubInfoList:"); for (SubscriptionInfo entry : sirl) { pw.println(" " + entry.toString()); } } else { pw.println(" ActiveSubInfoList: is null"); } pw.flush(); pw.println("++++++++++++++++++++++++++++++++"); sirl = getAllSubInfoList(mContext.getOpPackageName()); if (sirl != null) {
<|startcomment|> rename this? <|endcomment|> import com.android.internal.telephony.Phone; import com.android.internal.telephony.PhoneConstants; import com.android.internal.telephony.SubscriptionController; import com.android.internal.telephony.TelephonyIntents; import java.io.FileDescriptor; import java.io.PrintWriter; import java.util.concurrent.atomic.AtomicInteger; import java.util.List; // must extend SubscriptionController as some people use it directly within-process public class SubscriptionControllerMock extends SubscriptionController { final AtomicInteger mDefaultDataSubId = new AtomicInteger(INVALID_SUBSCRIPTION_ID); final ITelephonyRegistry.Stub mTelephonyRegistry; <|startfocus|> final int[][] mSlotIdxToSubId; <|endfocus|> public static SubscriptionController init(Phone phone) { throw new RuntimeException("not implemented"); } public static SubscriptionController init(Context c, CommandsInterface[] ci) { throw new RuntimeException("not implemented"); } public static SubscriptionController getInstance() { throw new RuntimeException("not implemented"); } public SubscriptionControllerMock(Context c, ITelephonyRegistry.Stub tr, int phoneCount) { super(c); mTelephonyRegistry = tr; mSlotIdxToSubId = new int[phoneCount][];
<|startcomment|> this <|endcomment|> <|startfocus|> public SubscriptionInfo getActiveSubscriptionInfoForSimSlotIndex(int slotIdx, String cp){ <|endfocus|> throw new RuntimeException("not implemented");
<|startcomment|> rename? <|endcomment|> <|startfocus|> private boolean isInvalidSlotId(int slotIdx) { if (slotIdx < 0 || slotIdx >= mSlotIdxToSubId.length) return true; <|endfocus|> return false;
<|startcomment|> Please search all 'idx' and see if they need to be renamed :) <|endcomment|> <|startfocus|> public void setSlotSubId(int slotIdx, int subId) { if (isInvalidSlotId(slotIdx)) { throw new RuntimeException("invalid slot specified" + slotIdx); <|endfocus|> } if (mSlotIdxToSubId[slotIdx][0] != subId) { mSlotIdxToSubId[slotIdx][0] = subId; try { mTelephonyRegistry.notifySubscriptionInfoChanged(); } catch (RemoteException ex) {} }
<|startcomment|> final <|endcomment|>  private static String getEtwsPrimaryMessage(Context context, int category) { <|startfocus|> Resources r = context.getResources(); <|endfocus|> switch (category) { case ETWS_WARNING_TYPE_EARTHQUAKE: return r.getString(R.string.etws_primary_default_message_earthquake); case ETWS_WARNING_TYPE_TSUNAMI: return r.getString(R.string.etws_primary_default_message_tsunami); case ETWS_WARNING_TYPE_EARTHQUAKE_AND_TSUNAMI: return r.getString(R.string.etws_primary_default_message_earthquake_and_tsunami); case ETWS_WARNING_TYPE_TEST_MESSAGE: return r.getString(R.string.etws_primary_default_message_test); case ETWS_WARNING_TYPE_OTHER_EMERGENCY: return r.getString(R.string.etws_primary_default_message_others); default: return ""; }
<|startcomment|> rename <|endcomment|>  * * @param subId The subscription ID * @return true if the network for the subscription is roaming, false otherwise */ public boolean isNetworkRoaming(int subId) { final int phoneId = getPhoneId(subId); if (phoneId < 0) { // What else can we do? return false; } return TelephonyManager.getDefault().isNetworkRoaming(subId); } /** <|startfocus|> * Returns a constant indicating the state of sim for the slot idx. <|endfocus|> * * @param slotIndex * * {@See TelephonyManager#SIM_STATE_UNKNOWN} * {@See TelephonyManager#SIM_STATE_ABSENT} * {@See TelephonyManager#SIM_STATE_PIN_REQUIRED} * {@See TelephonyManager#SIM_STATE_PUK_REQUIRED} * {@See TelephonyManager#SIM_STATE_NETWORK_LOCKED} * {@See TelephonyManager#SIM_STATE_READY} * {@See TelephonyManager#SIM_STATE_NOT_READY} * {@See TelephonyManager#SIM_STATE_PERM_DISABLED} * {@See TelephonyManager#SIM_STATE_CARD_IO_ERROR} * * {@hide} */
<|startcomment|> leave an empty line between functions <|endcomment|>  ServiceStateTable.DATA_OPERATOR_NUMERIC, ServiceStateTable.IS_MANUAL_NETWORK_SELECTION, ServiceStateTable.RIL_VOICE_RADIO_TECHNOLOGY, ServiceStateTable.RIL_DATA_RADIO_TECHNOLOGY, ServiceStateTable.CSS_INDICATOR, ServiceStateTable.NETWORK_ID, ServiceStateTable.SYSTEM_ID, ServiceStateTable.CDMA_ROAMING_INDICATOR, ServiceStateTable.CDMA_DEFAULT_ROAMING_INDICATOR, ServiceStateTable.CDMA_ERI_ICON_INDEX, ServiceStateTable.CDMA_ERI_ICON_MODE, ServiceStateTable.IS_EMERGENCY_ONLY, ServiceStateTable.IS_DATA_ROAMING_FROM_REGISTRATION, ServiceStateTable.IS_USING_CARRIER_AGGREGATION, }; @Override <|startfocus|> public boolean onCreate() { <|endfocus|> return true; } @Override public Uri insert(Uri uri, ContentValues values) { throw new RuntimeException("Not supported"); } @Override public int delete(Uri uri, String selection, String[] selectionArgs) { throw new RuntimeException("Not supported"); } @Override public int update(Uri uri, ContentValues values, String selection, String[] selectionArgs) { throw new RuntimeException("Not supported"); } @Override public String getType(Uri uri) { if (ServiceStateTable.CONTENT_URI.equals(uri)) {
<|startcomment|> negate the check above and throw this exception first. <|endcomment|>  voice_operator_numeric, data_operator_alpha_long, data_operator_alpha_short, data_operator_numeric, is_manual_network_selection, ril_voice_radio_technology, ril_data_radio_technology, css_indicator, network_id, system_id, cdma_roaming_indicator, cdma_default_roaming_indicator, cdma_eri_icon_index, cdma_eri_icon_mode, is_emergency_only, is_data_roaming_from_registration, is_using_carrier_aggregation, }); } <|startfocus|> throw new IllegalArgumentException("Invalid URI: " + uri); <|endfocus|>
<|startcomment|> leave a line <|endcomment|>  MESSAGE_FORMAT, MESSAGE_PRIORITY, ETWS_WARNING_TYPE, CMAS_MESSAGE_CLASS, CMAS_CATEGORY, CMAS_RESPONSE_TYPE, CMAS_SEVERITY, CMAS_URGENCY, CMAS_CERTAINTY }; } /** * Constants for interfacing with the ServiceStateProvider and the different fields of the * ServiceState class accessible through the provider */ public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri.parse("content://service-state/"); <|startfocus|> /** * The MIME-type of {@link #CONTENT_URI}. */ public static final String CONTENT_TYPE = "vnd.android.cursor.dir/service_state"; <|endfocus|> /** * Used to push and receive updates to a field in the ServiceState for a given subId * @param field the ServiceState field to receive updates on * @param subId the subId to receive updates on * @return the Uri that will be notified by ServiceStateTracker */ public static Uri getUriForSubId(String field, int subId) {
<|startcomment|> is this used? <|endcomment|>  CMAS_RESPONSE_TYPE, CMAS_SEVERITY, CMAS_URGENCY, CMAS_CERTAINTY }; } /** * Constants for interfacing with the ServiceStateProvider and the different fields of the * ServiceState class accessible through the provider */ public static final class ServiceStateTable { public static final Uri CONTENT_URI = Uri.parse("content://service-state/"); <|startfocus|> /** * The MIME-type of {@link #CONTENT_URI}. */ public static final String CONTENT_TYPE = "vnd.android.cursor.dir/service_state"; <|endfocus|> /** * Used to push and receive updates to a field in the ServiceState for a given subId * @param field the ServiceState field to receive updates on * @param subId the subId to receive updates on * @return the Uri that will be notified by ServiceStateTracker */ public static Uri getUriForSubId(String field, int subId) { return CONTENT_URI.buildUpon().appendEncodedPath(String.valueOf(subId)) .appendEncodedPath(field).build(); } 
<|startcomment|> this is for a specific field and subid? should there be one for just subId too? <|endcomment|> <|startfocus|> public static Uri getUriForSubId(String field, int subId) { <|endfocus|> return CONTENT_URI.buildUpon().appendEncodedPath(String.valueOf(subId)) .appendEncodedPath(field).build();
<|startcomment|> P <|endcomment|>  + something.getClass().getName() + " to byte array!"); } } public AdvertiseData buildAdvData(JSONObject params) throws Exception { AdvertiseData.Builder builder = new AdvertiseData.Builder(); Iterator<String> keys = params.keys(); while (keys.hasNext()) { String key = keys.next(); <|startfocus|> /** python don't have multi map, if advertise data should repeat use serviceUuid, * serviceUuid2, serviceUuid3... . For that use "startsWith" */ <|endfocus|> if (key.startsWith("manufacturerData")) { JSONArray manuf = params.getJSONArray(key); int manufId = manuf.getInt(0); byte[] data = somethingToByteArray(manuf.get(1)); builder.addManufacturerData(manufId, data); } else if (key.startsWith("serviceData")) { JSONArray serDat = params.getJSONArray(key); ParcelUuid uuid = ParcelUuid.fromString(serDat.getString(0)); byte[] data = somethingToByteArray(serDat.get(1)); builder.addServiceData(uuid, data); } else if (key.startsWith("serviceUuid")) {
<|startcomment|> doesn't <|endcomment|>  + something.getClass().getName() + " to byte array!"); } } public AdvertiseData buildAdvData(JSONObject params) throws Exception { AdvertiseData.Builder builder = new AdvertiseData.Builder(); Iterator<String> keys = params.keys(); while (keys.hasNext()) { String key = keys.next(); <|startfocus|> /** python don't have multi map, if advertise data should repeat use serviceUuid, * serviceUuid2, serviceUuid3... . For that use "startsWith" */ <|endfocus|> if (key.startsWith("manufacturerData")) { JSONArray manuf = params.getJSONArray(key); int manufId = manuf.getInt(0); byte[] data = somethingToByteArray(manuf.get(1)); builder.addManufacturerData(manufId, data); } else if (key.startsWith("serviceData")) { JSONArray serDat = params.getJSONArray(key); ParcelUuid uuid = ParcelUuid.fromString(serDat.getString(0)); byte[] data = somethingToByteArray(serDat.get(1)); builder.addServiceData(uuid, data); } else if (key.startsWith("serviceUuid")) {
<|startcomment|> same if statement <|endcomment|>  public PeriodicAdvertisingParameters buildPeriodicParameters(JSONObject params) throws Exception { PeriodicAdvertisingParameters.Builder builder = new PeriodicAdvertisingParameters.Builder(); Iterator<String> keys = params.keys(); while (keys.hasNext()) { String key = keys.next(); if (key.equals("enable")) { builder.setEnable(params.getBoolean(key)); } else if (key.equals("includeTxPower")) { builder.setIncludeTxPower(params.getBoolean(key)); <|startfocus|> } else if (key.equals("includeTxPower")) { <|endfocus|> builder.setInterval(params.getInt(key)); } else { throw new IllegalArgumentException( "Unknown PeriodicAdvertisingParameters field " + key); } } return builder.build(); } /** * Starts ble advertising * * @throws Exception */ @Rpc(description = "Starts ble advertisement") public void bleAdvSetStartAdvertisingSet( @RpcParameter(name = "params") JSONObject parametersJson, @RpcParameter(name = "data") JSONObject dataJson, @RpcParameter(name = "scanResponse") JSONObject scanResponseJson, @RpcParameter(name = "periodicParameters") JSONObject periodicParametersJson,
<|startcomment|> this test should have 2 flavors - with and without a bssid specified. One of the two should have failed with the next CL. <|endcomment|> <|startfocus|> public void useAnyBssidForConnectionIfFirmwareControlsRoaming() { <|endfocus|> // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork( CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY);
<|startcomment|> < 0 doesn't seem like a great overflow check, maybe be more explicit? <|endcomment|>  private int readHighTagNumber() throws BerDataValueFormatException { // Base-128 big-endian form, where each byte has the highest bit set, except for the last // byte int b; int result = 0; do { if (!mBuf.hasRemaining()) { throw new BerDataValueFormatException("Truncated tag number"); } b = mBuf.get(); result <<= 7; result += b & 0x7f; if (result < 0) { throw new BerDataValueFormatException("Tag number too large"); <|startfocus|> } <|endfocus|> } while ((b & 0x80) != 0); return result; } private int readShortFormLength(int firstLengthByte) throws BerDataValueFormatException { return firstLengthByte & 0x7f; } private int readLongFormLength(int firstLengthByte) throws BerDataValueFormatException { // The low 7 bits of the first byte represent the number of bytes (following the first // byte) in which the length is in big-endian base-256 form int byteCount = firstLengthByte & 0x7f;
<|startcomment|> Unneeded? <|endcomment|>  "Truncated indefinite-length contents: " + bytesRead + " bytes read"); } int b = mBuf.get(); bytesRead++; if (bytesRead < 0) { throw new BerDataValueFormatException("Indefinite-length contents too long"); } if (b == 0) { if (prevZeroByte) { // End of contents reached -- we've read the value and its terminator 0x00 0x00 return bytesRead - 2; } prevZeroByte = true; <|startfocus|> continue; <|endfocus|> } else { prevZeroByte = false; } } } } 
<|startcomment|> 2017 <|endcomment|> <|startfocus|> * Copyright (C) 2016 The Android Open Source Project <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.rs.rsov.test; import android.content.Context; import android.renderscript.Allocation; import android.renderscript.Element; import android.renderscript.RenderScript; import android.renderscript.Type; import android.util.Log; public class UT_global_query extends UnitTest { protected UT_global_query(RSoVTestCore rstc, Context ctx) { super(rstc, "global_query", ctx); } 
<|startcomment|> Consider filing a bug to rename this method. I took Lc to mean "lower-case", and Uc to mean "upper-case", and was worried that this meant we were up-casing all passphrases (which would reduce entropy). Examining the source, I don't actually see upcasing (good). But a clearer name (e.g. convertByteArrayToArrayList) would avoid the confusion altogether. <|endcomment|>  req.channelRequestType = channelRequestType; req.channel = channel; req.ifaceName = interfaceName; req.securityRequired = !((pmk == null || pmk.length == 0) && (passphrase == null || passphrase.length() == 0)); if (req.securityRequired) { req.cipherType = getStrongestCipherSuiteType(capabilities.supportedCipherSuites); if (pmk != null && pmk.length != 0) { convertLcByteToUcByteArray(pmk, req.pmk); } else { convertLcByteToUcByteArray(passphrase.getBytes(), req.passphrase); } <|startfocus|> } <|endfocus|> try { WifiStatus status = iface.initiateDataPathRequest(transactionId, req); if (status.code == WifiStatusCode.SUCCESS) { return true; } else { Log.e(TAG, "initiateDataPath: error: " + statusString(status)); return false; } } catch (RemoteException e) { Log.e(TAG, "initiateDataPath: exception: " + e); return false; }
<|startcomment|> Does this trigger some callback? Mention it here <|endcomment|>  public boolean setWfdEnable(boolean enable) { return mSupplicantP2pIfaceHal.enableWfd(enable); } /** * Set Wifi Display device info. * * @param hex WFD device info as described in section 5.1.2 of WFD technical * specification v1.0.0. * @return true, if operation was successful. */ public boolean setWfdDeviceInfo(String hex) { return mSupplicantP2pIfaceHal.setWfdDeviceInfo(hex); } /** <|startfocus|> * Initiate a P2P service discovery indefinitely. <|endfocus|> * * @return boolean value indicating whether operation was successful. */ public boolean p2pFind() { return p2pFind(0); } /** * Initiate a P2P service discovery with a (optional) timeout. * * @param timeout Max time to be spent is peforming discovery. * Set to 0 to indefinely continue discovery untill and explicit * |stopFind| is sent. * @return boolean value indicating whether operation was successful. */ public boolean p2pFind(int timeout) {
<|startcomment|> Consider using SparseArray instead. <|endcomment|>  import java.io.IOException; import java.util.Map; import java.util.concurrent.atomic.AtomicReference; public class ToyVpnService extends VpnService implements Handler.Callback, ToyVpnConnection.Listener { private static final String TAG = ToyVpnService.class.getSimpleName(); public static final String ACTION_CONNECT = "com.example.android.toyvpn.START"; public static final String ACTION_DISCONNECT = "com.example.android.toyvpn.STOP"; private Handler mHandler; <|startfocus|> private Map<Integer, Thread> mThreads = new ArrayMap<>(); private int mNextConnectionId = 1; <|endfocus|> private AtomicReference<ParcelFileDescriptor> mTunnelInterface = new AtomicReference<>(); private PendingIntent mConfigureIntent; @Override public void onCreate() { // The handler is only used to show messages. if (mHandler == null) { mHandler = new Handler(this); } // Create the intent to "configure" the connection (just start ToyVpnClient). mConfigureIntent = PendingIntent.getActivity(this, 0, new Intent(this, ToyVpnClient.class), PendingIntent.FLAG_UPDATE_CURRENT); } @Override
<|startcomment|> Are there going to be more type of actions in the future ? If yes consider using String switch: switch (intent.getAction()) { case ACTION_DISCONNECT: ... case ACTION_CONNECT: ... default: log.w("unknown action " + intent.getAction()); } <|endcomment|>  public int onStartCommand(Intent intent, int flags, int startId) { if (ACTION_DISCONNECT.equals(intent.getAction())) { disconnect(); } else { connect(); } <|startfocus|> return START_STICKY; <|endfocus|>
<|startcomment|> Shouldn't this use equals() instead of pointer equality ? Even if this works it is not super robust. <|endcomment|>  public boolean handleMessage(Message message) { <|startfocus|> if (message != null) { Toast.makeText(this, message.what, Toast.LENGTH_SHORT).show(); if (message.what != R.string.disconnected) { updateForegroundNotification(message.what); } <|endfocus|> } return true;
<|startcomment|> what needs to be synchronized in this method besides read/wrote of mNextConnectionId variable and the thread map ? If nothing, could you scope the synchronized block to mNextConnectionId increment and the map update ? <|endcomment|>  } final ParcelFileDescriptor oldInterface = mTunnelInterface.getAndSet(tunInterface); if (oldInterface != null) { try { Log.i(TAG, "Closing interface: " + oldInterface); oldInterface.close(); } catch (IOException e){ Log.e(TAG, "Closing interface failed", e); } } } @Override public synchronized void onDisconnect(int connectionId) { mThreads.remove(connectionId); } @Override public void onRevoke() { disconnect(); } <|startfocus|> private synchronized void connect() { <|endfocus|> // Become a foreground service. Background services can be VPN services too, but they can // be killed by background check before getting a chance to receive onRevoke(). updateForegroundNotification(R.string.connecting); mHandler.sendEmptyMessage(R.string.connecting); final SharedPreferences prefs = getSharedPreferences(ToyVpnClient.Prefs.NAME, MODE_PRIVATE); final ToyVpnConnection connection; try { // Extract information from the shared preferences. connection = new ToyVpnConnection(this, this, mNextConnectionId, prefs.getString(ToyVpnClient.Prefs.SERVER_ADDRESS, ""),
<|startcomment|> remove? <|endcomment|>  import org.junit.After; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.ArgumentCaptor; import org.mockito.Mock; import org.mockito.MockitoAnnotations; import static android.Manifest.permission.MODIFY_PHONE_STATE; import static android.Manifest.permission.READ_PHONE_STATE; import static com.android.internal.telephony.ims.ImsResolver.SERVICE_INTERFACE; import static junit.framework.Assert.assertEquals; import static junit.framework.Assert.assertNotNull; import static junit.framework.Assert.assertNull; import static junit.framework.Assert.fail; <|startfocus|> import static org.mockito.Matchers.any; <|endfocus|> import static org.mockito.Matchers.anyInt; import static org.mockito.Matchers.anyString; import static org.mockito.Matchers.eq; import static org.mockito.Matchers.nullable; import static org.mockito.Mockito.doThrow; import static org.mockito.Mockito.never; import static org.mockito.Mockito.times; import static org.mockito.Mockito.verify; import static org.mockito.Mockito.when; /** * Unit tests for ImsService */ @RunWith(AndroidJUnit4.class) public class ImsServiceTest { private static final int TEST_SLOT_0 = 0; private static final int TEST_SLOT_1 = 1;
<|startcomment|> Needs proper capitalization and/or word splitting. Same comment applies to the reset of the CL. <|endcomment|>  // Mock the HeadsetService when(mockServiceFactory.getHeadsetService()).thenReturn(mockHeadsetService); when(mockHeadsetService.getPriority(device)) .thenReturn(BluetoothProfile.PRIORITY_UNDEFINED); // Mock the A2DP service when(mockServiceFactory.getA2dpService()).thenReturn(mockA2dpService); when(mockA2dpService.getPriority(device)).thenReturn(BluetoothProfile.PRIORITY_UNDEFINED); // Mock the looper when(mockAdapterService.getMainLooper()).thenReturn(mHandlerThread.getLooper()); <|startfocus|> // Tell the adapterservice that it is a mock (see isMock documentation) <|endfocus|> when(mockAdapterService.isMock()).thenReturn(true); PhonePolicy phPol = new PhonePolicy(mockAdapterService, mockServiceFactory); // Get the broadcast receiver to inject events. BroadcastReceiver injector = phPol.getBroadcastReceiver(); // Inject an event for UUIDs updated for a remote device with only HFP enabled Intent intent = new Intent(BluetoothDevice.ACTION_UUID); intent.putExtra(BluetoothDevice.EXTRA_DEVICE, device); ParcelUuid[] uuids = new ParcelUuid[2]; uuids[0] = BluetoothUuid.Handsfree; uuids[1] = BluetoothUuid.AudioSink; 
<|startcomment|> can we remove this? <|endcomment|> import com.android.internal.telephony.MmiCode; import com.android.internal.telephony.Phone; import com.android.internal.telephony.PhoneConstants; import java.util.List; /** * Used to display a dialog from within the Telephony service when running an USSD code */ public class MMIDialogActivity extends Activity { private static final String TAG = MMIDialogActivity.class.getSimpleName(); private Dialog mMMIDialog; private Handler mHandler; private CallManager mCM = PhoneGlobals.getInstance().getCallManager(); <|startfocus|> private Phone mPhone = PhoneGlobals.getPhone(); <|endfocus|> @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); Intent intent = getIntent(); int subId = intent.getIntExtra(PhoneConstants.SUBSCRIPTION_KEY, SubscriptionManager.DEFAULT_SUBSCRIPTION_ID); mPhone = PhoneGlobals.getPhone(subId); mHandler = new Handler() { @Override public void handleMessage(Message msg) { switch (msg.what) { case PhoneGlobals.MMI_COMPLETE: onMMIComplete((MmiCode) ((AsyncResult) msg.obj).result); break; case PhoneGlobals.MMI_CANCEL: onMMICancel();
<|startcomment|> spacing different here (and the line below) <|endcomment|>  // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork( CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY); } /* <|startfocus|> * Firmware supports controlled roaming. * Connect to a network which has a config specified BSSID. <|endfocus|> * * Expected behavior: WifiConnectivityManager calls * WifiStateMachine.startConnectToNetwork() with the * expected candidate network ID, and the BSSID value should be * 'any' since firmware controls the roaming. */ @Test public void useAnyBssidToConnectWhenFirmwareRoamingOnAndConfigHasBssidSpecified() { // Firmware controls roaming when(mWifiConnectivityHelper.isFirmwareRoamingSupported()).thenReturn(true); // Set up the candidate configuration such that it has a BSSID specified. WifiConfiguration candidate = generateWifiConfig( 0, CANDIDATE_NETWORK_ID, CANDIDATE_SSID, false, true, null, null);
<|startcomment|> extra space again and below <|endcomment|>  anyBoolean(), anyBoolean())).thenReturn(candidate); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine).startConnectToNetwork( CANDIDATE_NETWORK_ID, WifiStateMachine.SUPPLICANT_BSSID_ANY); } /* <|startfocus|> * Firmware does not support controlled roaming. * Connect to a network which doesn't have a config specified BSSID. <|endfocus|> * * Expected behavior: WifiConnectivityManager calls * WifiStateMachine.startConnectToNetwork() with the expected candidate network ID, * and the BSSID value should be the candidate scan result specified. */ @Test public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified() { // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine, atLeastOnce()).startConnectToNetwork( CANDIDATE_NETWORK_ID, CANDIDATE_BSSID); } /*
<|startcomment|> shouldn't this just be once? <|endcomment|>  public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified() { // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); <|startfocus|> verify(mWifiStateMachine, atLeastOnce()).startConnectToNetwork( CANDIDATE_NETWORK_ID, CANDIDATE_BSSID); <|endfocus|>
<|startcomment|> space <|endcomment|>  */ @Test public void useScanResultBssidToConnectWhenFirmwareRoamingOffAndConfigHasNoBssidSpecified() { // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); verify(mWifiStateMachine, atLeastOnce()).startConnectToNetwork( CANDIDATE_NETWORK_ID, CANDIDATE_BSSID); } /* <|startfocus|> * Firmware does not support controlled roaming. * Connect to a network which has a config specified BSSID. <|endfocus|> * * Expected behavior: WifiConnectivityManager calls * WifiStateMachine.startConnectToNetwork() with the expected candidate network ID, * and the BSSID value should be the config specified one. */ @Test public void useConfigSpecifiedBssidToConnectionWhenFirmwareRoamingOff() { // Set up the candidate configuration such that it has a BSSID specified. WifiConfiguration candidate = generateWifiConfig( 0, CANDIDATE_NETWORK_ID, CANDIDATE_SSID, false, true, null, null); candidate.BSSID = CANDIDATE_BSSID; // config specified ScanResult candidateScanResult = new ScanResult();
<|startcomment|> does this fit on the line above? <|endcomment|>  candidateScanResult.SSID = CANDIDATE_SSID; candidateScanResult.BSSID = CANDIDATE_BSSID; candidate.getNetworkSelectionStatus().setCandidate(candidateScanResult); when(mWifiNS.selectNetwork(anyObject(), anyObject(), anyObject(), anyBoolean(), anyBoolean(), anyBoolean())).thenReturn(candidate); // Set screen to on mWifiConnectivityManager.handleScreenStateChanged(true); // Set WiFi to disconnected state mWifiConnectivityManager.handleConnectionStateChanged( WifiConnectivityManager.WIFI_STATE_DISCONNECTED); <|startfocus|> verify(mWifiStateMachine).startConnectToNetwork( CANDIDATE_NETWORK_ID, CANDIDATE_BSSID); <|endfocus|>
<|startcomment|> What about "setLockdown()", "Enabled" is kind of redundant with true/false parameter. i.e setLockdown(true), setLockdown(false), setLockdown(mIsLockdownEnabled) are self-documenting enough. <|endcomment|>  } updateAlwaysOnNotification(detailedState); } /** * Chooses whether to force all connections to go though VPN. * * Used to enable/disable legacy VPN lockdown. This uses the same rule-based mechanism as * {@link #setAlwaysOnPackage(String, boolean)}; previous settings from calling that function * will be replaced. * * @param lockdown whether to prevent all traffic outside of a VPN. */ <|startfocus|> public synchronized void setLockdownEnabled(boolean lockdown) { <|endfocus|> enforceControlPermissionOrInternalCaller(); // Explicitly disable previous settings from always-on app VPN if it was set up, to avoid // getting into a confusing state with both enabled at the same time. if (mAlwaysOn) { setAlwaysOnPackage(null, false); } // Apply the new lockdown rules. setVpnForcedLocked(lockdown); mLockdown = lockdown; } /** * Configures an always-on VPN connection through a specific application. * This connection is automatically granted and persisted after a reboot. *
<|startcomment|> Should this function tries to detect an edge transition and be idempotent, should it distinguish mLockdown transitions true -> false and false -> true. For instance it looks like the if(mAlwaysOn) path is relevant only when lockdown is true. Related question: are setAlwaysOnPackage and setVpnForcedLocked idempotent ? <|endcomment|>  * * @param lockdown whether to prevent all traffic outside of a VPN. */ public synchronized void setLockdownEnabled(boolean lockdown) { enforceControlPermissionOrInternalCaller(); // Explicitly disable previous settings from always-on app VPN if it was set up, to avoid // getting into a confusing state with both enabled at the same time. if (mAlwaysOn) { setAlwaysOnPackage(null, false); } // Apply the new lockdown rules. setVpnForcedLocked(lockdown); <|startfocus|> mLockdown = lockdown; <|endfocus|> } /** * Configures an always-on VPN connection through a specific application. * This connection is automatically granted and persisted after a reboot. * * <p>The designated package should exist and declare a {@link VpnService} in its * manifest guarded by {@link android.Manifest.permission.BIND_VPN_SERVICE}, * otherwise the call will fail. * * @param packageName the package to designate as always-on VPN supplier. * @param lockdown whether to prevent traffic outside of a VPN, for example while connecting.
<|startcomment|> Similarly to the change in setVpnForcedWithExemptionsLocked, can you have a single call to setVpnForcedWithExemptionsLocked with the isNullOrLegacyVpn(mPackage) conditional deciding on eemptedPackages ? <|endcomment|>  private void setVpnForcedLocked(boolean enforce) { <|startfocus|> if (isNullOrLegacyVpn(mPackage)) { setVpnForcedWithExemptionsLocked(enforce, null); } else { setVpnForcedWithExemptionsLocked(enforce, Collections.singletonList(mPackage)); } <|endfocus|>
<|startcomment|> If addedRanges is not modified below, I suggest using Collections.EMPTY_SET (probably with a type cast) as the default for addedRanges and removing the else branch. <|endcomment|>  private void setVpnForcedWithExemptionsLocked(boolean enforce, @Nullable List<String> exemptedPackages) { final Set<UidRange> removedRanges = new ArraySet<>(mBlockedUsers); final Set<UidRange> addedRanges; if (enforce) { addedRanges = createUserAndRestrictedProfilesRanges(mUserHandle, /* allowedApplications */ null, /* disallowedApplications */ exemptedPackages); removedRanges.removeAll(addedRanges); addedRanges.removeAll(mBlockedUsers); <|startfocus|> } else { addedRanges = Collections.<UidRange> emptySet(); <|endfocus|> } setAllowOnlyVpnForUids(false, removedRanges); setAllowOnlyVpnForUids(true, addedRanges);
<|startcomment|> type inference does not work without this ? <|endcomment|>  private void setVpnForcedWithExemptionsLocked(boolean enforce, @Nullable List<String> exemptedPackages) { final Set<UidRange> removedRanges = new ArraySet<>(mBlockedUsers); final Set<UidRange> addedRanges; if (enforce) { addedRanges = createUserAndRestrictedProfilesRanges(mUserHandle, /* allowedApplications */ null, /* disallowedApplications */ exemptedPackages); removedRanges.removeAll(addedRanges); addedRanges.removeAll(mBlockedUsers); <|startfocus|> } else { addedRanges = Collections.<UidRange> emptySet(); <|endfocus|> } setAllowOnlyVpnForUids(false, removedRanges); setAllowOnlyVpnForUids(true, addedRanges);
<|startcomment|> Seems inconsistent to document this removal here but document the removal of getAnnotatedBounds() below. Is there a reason? <|endcomment|>  * instances representing the type variable. However, all instances * representing a type variable must be equal() to each other. * As a consequence, users of type variables must not rely on the identity * of instances of classes implementing this interface. * * @param <D> the type of generic declaration that declared the * underlying type variable. * * @since 1.5 */ <|startfocus|> // Android-changed: Removed AnnotatedElement due to excluded support for runtime type annotations public interface TypeVariable<D extends GenericDeclaration> extends Type{ <|endfocus|> /** * Returns an array of {@code Type} objects representing the * upper bound(s) of this type variable. Note that if no upper bound is * explicitly declared, the upper bound is {@code Object}. * * <p>For each upper bound B: <ul> <li>if B is a parameterized * type or a type variable, it is created, (see {@link * java.lang.reflect.ParameterizedType ParameterizedType} for the
<|startcomment|> Please remove one of these words. (Your choice which one. ;-)) <|endcomment|>  * @param log WifiLog object to assign to the clientHandler */ @VisibleForTesting public void setWifiHandlerLogForTest(WifiLog log) { mClientHandler.setWifiLog(log); } /** * Check if we are ready to start wifi. * <|startfocus|> * First check if we will be restarting system services to decrypt the device. If the device is * not encrypted, check if Wi-Fi needs to be enabled and start if needed * * This function is used only at boot time. <|endfocus|> */ public void checkAndStartWifi() { // First check if we will end up restarting WifiService if (mFrameworkFacade.inStorageManagerCryptKeeperBounce()) { Log.d(TAG, "Device still encrypted. Need to restart SystemServer. Do not start wifi."); return; } // Check if wi-fi needs to be enabled boolean wifiEnabled = mSettingsStore.isWifiToggleEnabled(); Slog.i(TAG, "WifiService starting up with Wi-Fi " + (wifiEnabled ? "enabled" : "disabled")); registerForScanModeChange();
<|startcomment|> Consider "WifiControllerDoesNotStart", for greater contrast with the successful start test. <|endcomment|>  public void testWifiDoesNotStartWhenDeviceTriggerResetMainAtBoot() { <|startfocus|> when(mPropertyService.get(eq("vold.decrypt"), anyString())).thenReturn("trigger_reset_main"); <|endfocus|> when(mSettingsStore.isWifiToggleEnabled()).thenReturn(false); mWifiServiceImpl.checkAndStartWifi(); verify(mWifiController, never()).start();
<|startcomment|> Maybe "WifiControllerStarts", to make the test's aim more obvious? (It's surprising to read Wifistarts...WithWifiDisabled.) <|endcomment|>  public void testWifiStartsWhenDeviceIsDecryptedAtBootWithWifiDisabled() { <|startfocus|> when(mPropertyService.get(eq("vold.decrypt"), anyString())).thenReturn(""); <|endfocus|> when(mSettingsStore.isWifiToggleEnabled()).thenReturn(false); mWifiServiceImpl.checkAndStartWifi(); verify(mWifiController).start(); verify(mWifiController, never()).sendMessage(CMD_WIFI_TOGGLED);
<|startcomment|> Consider "WifiFullyStarts" or "WifiStartsFully", to make the contrast with the other cases more obvious? <|endcomment|>  public void testWifiStartsWhenDeviceIsDecryptedAtBootWithWifiEnabled() { <|startfocus|> when(mPropertyService.get(eq("vold.decrypt"), anyString())).thenReturn(""); <|endfocus|> when(mSettingsStore.handleWifiToggled(true)).thenReturn(true); when(mSettingsStore.isWifiToggleEnabled()).thenReturn(true); when(mWifiStateMachine.syncGetWifiState()).thenReturn(WIFI_STATE_DISABLED); mWifiServiceImpl.checkAndStartWifi(); verify(mWifiController).start(); verify(mWifiController).sendMessage(CMD_WIFI_TOGGLED);
<|startcomment|> Can this be added after SCAN_FAILED_EVENT? <|endcomment|>  public static final int SUP_DISCONNECTION_EVENT = BASE + 2; /* Network connection completed */ public static final int NETWORK_CONNECTION_EVENT = BASE + 3; /* Network disconnection completed */ public static final int NETWORK_DISCONNECTION_EVENT = BASE + 4; /* Scan results are available */ public static final int SCAN_RESULTS_EVENT = BASE + 5; /* Scheduled scan results are available */ public static final int SCHED_SCAN_RESULTS_EVENT = BASE + 6; /* Supplicate state changed */ <|startfocus|> public static final int SUPPLICANT_STATE_CHANGE_EVENT = BASE + 7; <|endfocus|> /* Password failure and EAP authentication failure */ public static final int AUTHENTICATION_FAILURE_EVENT = BASE + 8; /* WPS success detected */ public static final int WPS_SUCCESS_EVENT = BASE + 9; /* WPS failure detected */ public static final int WPS_FAIL_EVENT = BASE + 10; /* WPS overlap detected */ public static final int WPS_OVERLAP_EVENT = BASE + 11; /* WPS timeout detected */
<|startcomment|> Do we want to make it more specific so we know it is PNO scan results since there are other type of scheduled scans? <|endcomment|>  public void OnPnoNetworkFound() { Log.d(TAG, "Pno scan result event"); <|startfocus|> mWifiMonitor.broadcastSchedScanResultEvent(mClientInterfaceName); <|endfocus|>
<|startcomment|> This whole comment feels unnecessary to me since it's just stating what the code does (and the code is pretty readable). <|endcomment|>  android.provider.Settings.Global.SETUP_PREPAID_DATA_SERVICE_URL)); if (!isLteOnCdma || missingDataServiceUrl) { prefSet.removePreference(mLteDataServicePref); } else { android.util.Log.d(LOG_TAG, "keep ltePref"); } // Hide enhanced 4G LTE mode settings when either it is not supported by platform or // 'KEY_HIDE_ENHANCED_4G_LTE_BOOL' is true. if (!(ImsManager.isVolteEnabledByPlatform(getActivity()) && ImsManager.isVolteProvisionedOnDevice(getActivity())) <|startfocus|> || carrierConfig.getBoolean(CarrierConfigManager.KEY_HIDE_ENHANCED_4G_LTE_BOOL)) { <|endfocus|> Preference pref = prefSet.findPreference(BUTTON_4G_LTE_KEY); if (pref != null) { prefSet.removePreference(pref); } } ActionBar actionBar = getActivity().getActionBar(); if (actionBar != null) { // android.R.id.home will be triggered in onOptionsItemSelected() actionBar.setDisplayHomeAsUpEnabled(true); } // Enable link to CMAS app settings depending on the value in config.xml.
<|startcomment|> please fix indentation <|endcomment|>  if (!isLteOnCdma || missingDataServiceUrl) { prefSet.removePreference(mLteDataServicePref); } else { android.util.Log.d(LOG_TAG, "keep ltePref"); } // Hide enhanced 4G LTE mode settings when either it is not supported by platform or // 'KEY_HIDE_ENHANCED_4G_LTE_BOOL' is true. if (!(ImsManager.isVolteEnabledByPlatform(getActivity()) && ImsManager.isVolteProvisionedOnDevice(getActivity())) <|startfocus|> || carrierConfig.getBoolean(CarrierConfigManager.KEY_HIDE_ENHANCED_4G_LTE_BOOL)) { <|endfocus|> Preference pref = prefSet.findPreference(BUTTON_4G_LTE_KEY); if (pref != null) { prefSet.removePreference(pref); } } ActionBar actionBar = getActivity().getActionBar(); if (actionBar != null) { // android.R.id.home will be triggered in onOptionsItemSelected() actionBar.setDisplayHomeAsUpEnabled(true); } // Enable link to CMAS app settings depending on the value in config.xml. final boolean isCellBroadcastAppLinkEnabled = getActivity().getResources().getBoolean(
<|startcomment|> did you intend to leave this comment here? <|endcomment|>  assertFalse(nc.hasCapability(NET_CAPABILITY_INTERNET)); } @Test public void testNetworkCapabilitiesForTypeBluetooth() { verifyUnrestrictedNetworkCapabilities( ConnectivityManager.TYPE_BLUETOOTH, TRANSPORT_BLUETOOTH); } @Test public void testNetworkCapabilitiesForTypeEthernet() { verifyUnrestrictedNetworkCapabilities( ConnectivityManager.TYPE_ETHERNET, TRANSPORT_ETHERNET); } @Test public void testNoDoubleCallbackRegistration() throws Exception { ConnectivityManager manager = new ConnectivityManager(mCtx, mService); <|startfocus|> //NetworkRequest request = new NetworkRequest.Builder().clearCapabilities().build(); NetworkRequest request = makeRequest(1234); <|endfocus|> NetworkCallback callback = new ConnectivityManager.NetworkCallback(); ApplicationInfo info = new ApplicationInfo(); info.targetSdkVersion = VERSION_CODES.N_MR1 + 1; when(mCtx.getApplicationInfo()).thenReturn(info); when(mService.requestNetwork(any(), any(), anyInt(), any(), anyInt())).thenReturn(request); Handler handler = new Handler(Looper.getMainLooper()); manager.requestNetwork(request, callback, handler); // Callback is already registered, reregistration should fail. Class<IllegalArgumentException> wantException = IllegalArgumentException.class;
<|startcomment|> under what circumstances can sleep be replaced by waitForIdle()? Consider documenting the preconditions. <|endcomment|>  Handler handler = new Handler(Looper.getMainLooper()); manager.requestNetwork(request, callback, handler); // Callback is already registered, reregistration should fail. Class<IllegalArgumentException> wantException = IllegalArgumentException.class; expectThrowable(() -> manager.requestNetwork(request, callback), wantException); manager.unregisterNetworkCallback(callback); <|startfocus|> // Service release request and sends back notification Message releaseMsg = makeMessage(request, ConnectivityManager.CALLBACK_RELEASED); handler.sendMessage(releaseMsg); Thread.sleep(1000); // replace by waitForIdle() // Unregistering the callback should make it registrable again. <|endfocus|> manager.requestNetwork(request, callback); } static Message makeMessage(NetworkRequest req, int messageType) { Bundle bundle = new Bundle(); bundle.putParcelable(NetworkRequest.class.getSimpleName(), req); Message msg = Message.obtain(); msg.what = messageType; msg.setData(bundle); return msg; } static NetworkRequest makeRequest(int requestId) { NetworkRequest request = new NetworkRequest.Builder().clearCapabilities().build(); return new NetworkRequest(request.networkCapabilities, ConnectivityManager.TYPE_NONE, requestId, NetworkRequest.Type.NONE);
<|startcomment|> indent 8 <|endcomment|>  if (maxBlacklistSize <= 0) { Log.wtf(TAG, "Invalid max BSSID blacklist size: " + maxBlacklistSize); return; } ArrayList<String> blacklistedBssids = new ArrayList<String>(buildBssidBlacklist()); int blacklistSize = blacklistedBssids.size(); if (blacklistSize > maxBlacklistSize) { Log.wtf(TAG, "Attempt to write " + blacklistSize + " blacklisted BSSIDs, max size is " + maxBlacklistSize); blacklistedBssids = new ArrayList<String>(blacklistedBssids.subList(0, <|startfocus|> maxBlacklistSize)); <|endfocus|> localLog("Trim down BSSID blacklist size from " + blacklistSize + " to " + blacklistedBssids.size()); } if (!mConnectivityHelper.setFirmwareRoamingConfiguration(blacklistedBssids, new ArrayList<String>())) { // TODO(b/36488259): SSID whitelist management. localLog("Failed to set firmware roaming configuration."); }
<|startcomment|> if we crash, or just don't clear the roaming config, will it persist? Do we need to clear it out when we call start? <|endcomment|>  private void start() { <|startfocus|> mConnectivityHelper.getFirmwareRoamingInfo(); <|endfocus|> startConnectivityScan(SCAN_IMMEDIATELY);
<|startcomment|> it is confusing to have this check and the one below reversed... what about a little helper method that looks something like (the name needs work): private void checkRunningState() { if (mWifiEnabled && mWifiConnectivityManagerEnabled) { localLog("starting up WifiConnectivityManager"); start(); return; } localLog("stopping WifiConnectivitymanager"); stop(); } <|endcomment|>  public void setWifiEnabled(boolean enable) { localLog("Set WiFi " + (enable ? "enabled" : "disabled")); mWifiEnabled = enable; <|startfocus|> if (!mWifiEnabled) { stop(); } else if (mWifiConnectivityManagerEnabled) { start(); } <|endfocus|>
<|startcomment|> This check can also be removed - same reason <|endcomment|>  private void localLog(String log) { <|startfocus|> if (mLocalLog != null) { mLocalLog.log(log); } <|endfocus|>
<|startcomment|> indent 8 <|endcomment|>  sbuf.append(" Same network the current one bonus: ") .append(mSameNetworkAward).append(","); // When firmware roaming is supported, equivalent BSSIDs (the ones under the // same network as the currently connected one) get the same BSSID award. if (mConnectivityHelper.isFirmwareRoamingSupported() && currentBssid != null && !currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Firmware roaming equivalent BSSID bonus: ") <|startfocus|> .append(mSameBssidAward).append(","); <|endfocus|> } } // Same BSSID award. if (currentBssid != null && currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Same BSSID as the current one bonus: ").append(mSameBssidAward) .append(","); } // Security award. if (!WifiConfigurationUtil.isConfigForOpenNetwork(network)) { score += mSecurityAward; sbuf.append(" Secure network bonus: ").append(mSecurityAward).append(","); } // No internet penalty.
<|startcomment|> indent 8 <|endcomment|>  if (mConnectivityHelper.isFirmwareRoamingSupported() && currentBssid != null && !currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Firmware roaming equivalent BSSID bonus: ") .append(mSameBssidAward).append(","); } } // Same BSSID award. if (currentBssid != null && currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Same BSSID as the current one bonus: ").append(mSameBssidAward) <|startfocus|> .append(","); <|endfocus|> } // Security award. if (!WifiConfigurationUtil.isConfigForOpenNetwork(network)) { score += mSecurityAward; sbuf.append(" Secure network bonus: ").append(mSecurityAward).append(","); } // No internet penalty. if (network.numNoInternetAccessReports > 0 && !network.validatedInternetAccess) { score -= mNoInternetPenalty; sbuf.append(" No internet penalty: -").append(mNoInternetPenalty).append(","); } sbuf.append(" ## Total score: ").append(score).append("\n"); return score;
<|startcomment|> does this fit on the same line? <|endcomment|>  if (mConnectivityHelper.isFirmwareRoamingSupported() && currentBssid != null && !currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Firmware roaming equivalent BSSID bonus: ") .append(mSameBssidAward).append(","); } } // Same BSSID award. if (currentBssid != null && currentBssid.equals(scanResult.BSSID)) { score += mSameBssidAward; sbuf.append(" Same BSSID as the current one bonus: ").append(mSameBssidAward) <|startfocus|> .append(","); <|endfocus|> } // Security award. if (!WifiConfigurationUtil.isConfigForOpenNetwork(network)) { score += mSecurityAward; sbuf.append(" Secure network bonus: ").append(mSecurityAward).append(","); } // No internet penalty. if (network.numNoInternetAccessReports > 0 && !network.validatedInternetAccess) { score -= mNoInternetPenalty; sbuf.append(" No internet penalty: -").append(mNoInternetPenalty).append(","); } sbuf.append(" ## Total score: ").append(score).append("\n"); return score;
<|startcomment|> Do we have #defines available for these random numbers anywhere? <|endcomment|>  public void testCTSSyscallBlocked() { if (CpuFeatures.isArm64Cpu()) { <|startfocus|> testAllowed(98); testBlocked(99); testBlocked(100); <|endfocus|> } else if (CpuFeatures.isArmCpu()) { testBlocked(7); testAllowed(8); testBlocked(9); } else if (CpuFeatures.isX86_64Cpu()) { testBlocked(31); testAllowed(32); testBlocked(33); } else if (CpuFeatures.isX86Cpu()) { testBlocked(7); testAllowed(8); testBlocked(9); } else if (CpuFeatures.isMips64Cpu()) { testBlocked(5030); testAllowed(5031); testBlocked(5032); } else if (CpuFeatures.isMipsCpu()) { testBlocked(4032); testAllowed(4033); testBlocked(4034); } else { fail("Unsupported OS"); }
<|startcomment|> 2017 <|endcomment|> <|startfocus|> * Copyright (C) 2014 The Android Open Source Project <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.security.cts; import android.test.AndroidTestCase; import com.android.compatibility.common.util.CpuFeatures; import junit.framework.TestCase; /** * Verify that the seccomp policy is enforced */ public class SeccompTest extends AndroidTestCase { static { System.loadLibrary("ctssecurity_jni"); } public void testCTSSyscallBlocked() { if (CpuFeatures.isArm64Cpu()) {
<|startcomment|> I'd put it by the other clearing of mAutoAttachOnCreation state (4 lines down). <|endcomment|>  mPhone.notifyOtaspChanged(ServiceStateTracker.OTASP_SIM_UNPROVISIONED); // Tear down all metered apns cleanUpAllConnections(true, Phone.REASON_CARRIER_ACTION_DISABLE_METERED_APN); } else { teardownRestrictedMeteredConnections(); setupDataOnConnectableApns(Phone.REASON_DATA_ENABLED); } } } } private void onSimNotReady() { if (DBG) log("onSimNotReady"); <|startfocus|> // Clear auto attach as modem is expected to do a new attach once SIM is ready mAutoAttachOnCreation.set(false); <|endfocus|> cleanUpAllConnections(true, Phone.REASON_SIM_NOT_READY); mAllApnSettings = null; mAutoAttachOnCreationConfig = false; } private void onSetDependencyMet(String apnType, boolean met) { // don't allow users to tweak hipri to work around default dependency not met if (PhoneConstants.APN_TYPE_HIPRI.equals(apnType)) return; ApnContext apnContext = mApnContexts.get(apnType); if (apnContext == null) { loge("onSetDependencyMet: ApnContext not found in onSetDependencyMet(" + apnType + ", " + met + ")");
<|startcomment|> Please update the comment to reflect this new 'forceReconnect' parameter. <|endcomment|>  public void onChange(boolean selfChange) { <|startfocus|> mUserWantsSuspendOpt.set(Settings.Global.getInt(mContext.getContentResolver(), <|endfocus|> Settings.Global.WIFI_SUSPEND_OPTIMIZATIONS_ENABLED, 1) == 1);
<|startcomment|> cleanup the comments here and below? <|endcomment|>  mSapProxy = getSapProxy(); } /** * Notify SapServer that this class is ready for shutdown. */ void notifyShutdown() { if (DEBUG) Log.i(TAG, "notifyShutdown()"); // If we are already shutdown, don't bother sending a notification. synchronized (this) { if (mSapProxy != null) sendShutdownMessage(); } } /** <|startfocus|> * This will terminate the SapRilReceiver thread, by closing the RIL-BT in-/output * streams. <|endfocus|> */ public void shutdown() { if (DEBUG) Log.i(TAG, "shutdown()"); /* On Android you need to close the IOstreams using Socket.shutdown* * The IOstream close must not be used, as it some how decouples the * stream from the socket, and when the socket is closed, the pending * reads never return nor throw and exception. * Hence here we use the shutdown method: */ synchronized (this) { if (mSapProxy != null) { mSapProxy = null; } } } 
<|startcomment|> given this implementation, you should be able to break out once you have a match. will this leave holes in the networkId numbers? i am guessing that doesn't matter. just mentioning in case it does. <|endcomment|>  return null; } WifiConfiguration[] configs = new WifiConfiguration[ssids.length]; for (int index = 0; index < ssids.length; index++) { int networkId = index; for (int k = 0; k < index; k++) { // If two networks have the same SSID and security type, assign them // the same network Id. if (ssids[index].equals(ssids[k]) && (securities[index] == securities[k])) { networkId = k; } } <|startfocus|> configs[index] = generateWifiConfig(networkId, 0, ssids[index], false, true, null, null, securities[index]); <|endfocus|> } return configs;
<|startcomment|> this is pretty complicated to read - consider thinking about an alternate impl to make this a bit easier to read. <|endcomment|>  for (int index = 0; index < ssids.length; index++) { int networkId = index; for (int k = 0; k < index; k++) { // If two networks have the same SSID and security type, assign them // the same network Id. if (ssids[index].equals(ssids[k]) && (securities[index] == securities[k])) { networkId = k; } } <|startfocus|> configs[index] = generateWifiConfig(networkId, 0, ssids[index], false, true, null, null, securities[index]); <|endfocus|> } return configs;
<|startcomment|> AndroidJUnitRunner <|endcomment|>  public class MacroSubstitutionNamingStrategy implements TestCaseNamingStrategy { private static final String MACRO_PATTERN = "\\{[^\\}]{0,50}\\}"; // Pattern that keeps delimiters in split result private static final Pattern MACRO_SPLIT_PATTERN = Pattern.compile(String.format("(?=%s)|(?<=%s)", MACRO_PATTERN, MACRO_PATTERN)); private static final String MACRO_START = "{"; private static final String MACRO_END = "}"; <|startfocus|> // Android-changed: CTS and AJUR rely on specific format to test names, changing them // will prevent CTS and AJUR from working properly; see b/36541809 <|endfocus|> static final String DEFAULT_TEMPLATE = "{method}[{index}]"; private TestMethod method; public MacroSubstitutionNamingStrategy(TestMethod testMethod) { this.method = testMethod; } @Override public String getTestCaseName(int parametersIndex, Object parameters) { TestCaseName testCaseName = method.getAnnotation(TestCaseName.class); String template = getTemplate(testCaseName); String builtName = buildNameByTemplate(template, parametersIndex, parameters); 
<|startcomment|> Can you double-check the unit test results for this patch? When I pull in the current stack of patches, I see some error messages that look to be related to this change: 66) testRttTypeTranslation(com.android.server.wifi.WifiVendorHalTest) org.mockito.exceptions.base.MockitoException: Cannot mock/spy class android.os.Looper Mockito cannot mock/spy because : - final or anonymous class at com.android.server.wifi.WifiVendorHalTest.setUp(WifiVendorHalTest.java:122) <|endcomment|> import org.mockito.MockitoAnnotations; import org.mockito.stubbing.Answer; import java.net.InetAddress; import java.util.ArrayList; import java.util.Arrays; import java.util.List; import java.util.Random; /** * Unit tests for {@link com.android.server.wifi.WifiVendorHal}. */ public class WifiVendorHalTest { WifiVendorHal mWifiVendorHal; private WifiStatus mWifiStatusSuccess; private WifiStatus mWifiStatusFailure; WifiLog mWifiLog; @Mock private HalDeviceManager mHalDeviceManager; @Mock <|startfocus|> private Looper mLooper; <|endfocus|> @Mock private WifiVendorHal.HalDeviceManagerStatusListener mHalDeviceManagerStatusCallbacks; @Mock private IWifiApIface mIWifiApIface; @Mock private IWifiChip mIWifiChip; @Mock private IWifiStaIface mIWifiStaIface; @Mock private IWifiRttController mIWifiRttController; private IWifiStaIfaceEventCallback mIWifiStaIfaceEventCallback; private IWifiChipEventCallback mIWifiChipEventCallback; @Mock private WifiNative.VendorHalDeathEventHandler mVendorHalDeathHandler; /** * Identity function to supply a type to its argument, which is a lambda */
<|startcomment|> the wording here is a bit odd <|endcomment|>  break; case CMD_DIAGS_CONNECT_TIMEOUT: mWifiDiagnostics.reportConnectionEvent( (Long) message.obj, BaseWifiDiagnostics.CONNECTION_EVENT_FAILED); break; default: loge("Error! unhandled message" + message); break; } return HANDLED; } } class InitialState extends State { private void cleanup() { // Tearing down the client interfaces below is going to stop our supplicant. mWifiMonitor.stopAllMonitoring(); mDeathRecipient.unlinkToDeath(); mWifiNative.tearDownInterfaces(); mWifiNative.stopHal(); } <|startfocus|> <|endfocus|> @Override public void enter() { mWifiStateTracker.updateState(WifiStateTracker.INVALID); cleanup(); } @Override public boolean processMessage(Message message) { logStateAndMessage(message, this); switch (message.what) { case CMD_START_SUPPLICANT: mClientInterface = mWifiNative.setupDriverForClientMode(); if (mClientInterface == null || !mDeathRecipient.linkToDeath(mClientInterface.asBinder())) { setWifiState(WifiManager.WIFI_STATE_UNKNOWN); cleanup(); break; } try {
<|startcomment|> Add a bug to track the work? <|endcomment|>  sendMessage(CMD_DISCONNECT); } break; case WifiManager.CONNECT_NETWORK: /** * The connect message can contain a network id passed as arg1 on message or * or a config passed as obj on message. * For a new network, a config is passed to create and connect. * For an existing network, a network id is passed */ netId = message.arg1; config = (WifiConfiguration) message.obj; <|startfocus|> mWifiConnectionStatistics.numWifiManagerJoinAttempt++; <|endfocus|> // New network addition. if (config != null) { result = mWifiConfigManager.addOrUpdateNetwork(config, message.sendingUid); if (!result.isSuccess()) { loge("CONNECT_NETWORK adding/updating config=" + config + " failed"); messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL; replyToMessage(message, WifiManager.CONNECT_NETWORK_FAILED, WifiManager.ERROR); break; } netId = result.getNetworkId(); } if (!connectToUserSelectNetwork(netId, message.sendingUid)) {
<|startcomment|> Is it possible that both Ip and Proxy changed? <|endcomment|>  /** * The connect message can contain a network id passed as arg1 on message or * or a config passed as obj on message. * For a new network, a config is passed to create and connect. * For an existing network, a network id is passed */ netId = message.arg1; config = (WifiConfiguration) message.obj; <|startfocus|> mWifiConnectionStatistics.numWifiManagerJoinAttempt++; <|endfocus|> // New network addition. if (config != null) { result = mWifiConfigManager.addOrUpdateNetwork(config, message.sendingUid); if (!result.isSuccess()) { loge("CONNECT_NETWORK adding/updating config=" + config + " failed"); messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL; replyToMessage(message, WifiManager.CONNECT_NETWORK_FAILED, WifiManager.ERROR); break; } netId = result.getNetworkId(); } if (!connectToUserSelectNetwork(netId, message.sendingUid)) { messageHandlingStatus = MESSAGE_HANDLING_STATUS_FAIL; replyToMessage(message, WifiManager.CONNECT_NETWORK_FAILED,
<|startcomment|> it is a little odd to split the hasCredentialChanged here from where it is set above. <|endcomment|>  newNetwork || WifiConfigurationUtil.hasCredentialChanged( existingInternalConfig, newInternalConfig); // This is needed to inform IpManager about any IP configuration changes. boolean hasIpChanged = newNetwork || WifiConfigurationUtil.hasIpChanged( existingInternalConfig, newInternalConfig); boolean hasProxyChanged = newNetwork || WifiConfigurationUtil.hasProxyChanged( existingInternalConfig, newInternalConfig); <|startfocus|> // Reset the |hasEverConnected| flag if the credential parameters changed in this update. <|endfocus|> if (hasCredentialChanged) { newInternalConfig.getNetworkSelectionStatus().setHasEverConnected(false); } // Add it to our internal map. This will replace any existing network configuration for // updates. mConfiguredNetworks.put(newInternalConfig); if (mDeletedEphemeralSSIDs.remove(config.SSID)) { if (mVerboseLoggingEnabled) { Log.v(TAG, "Removed from ephemeral blacklist: " + config.SSID); } } // Stage the backup of the SettingsProvider package which backs this up. mBackupManagerProxy.notifyDataChanged(); NetworkUpdateResult result = new NetworkUpdateResult(hasIpChanged, hasProxyChanged, hasCredentialChanged); result.setIsNewNetwork(newNetwork);
<|startcomment|> If you're assuming it's locked here you should call this getSapProxyLocked <|endcomment|>  public ISap getSapProxy() { <|startfocus|> if (mSapProxy != null) { return mSapProxy; } try { mSapProxy = ISap.getService(SOCKET_NAME_RIL_BT); <|endfocus|> if (mSapProxy != null) { mSapProxy.linkToDeath(mSapProxyDeathRecipient, mSapProxyCookie.incrementAndGet()); mSapProxy.setCallback(mSapCallback); } else { Log.e(TAG, "getSapProxy: mSapProxy == null"); } } catch (RemoteException | RuntimeException e) { mSapProxy = null; Log.e(TAG, "getSapProxy: exception: " + e); } if (mSapProxy == null) { // if service is not up, treat it like death notification to try to get service again mSapServerMsgHandler.sendMessageDelayed( mSapServerMsgHandler.obtainMessage( SapServer.SAP_PROXY_DEAD, mSapProxyCookie.get()), SapServer.ISAP_GET_SERVICE_DELAY_MILLIS); } return mSapProxy;
<|startcomment|> Small o in onConn..., How about onConnectionParametersUpdated? <|endcomment|>  " mtu=" + mtu + " status=" + status); if (!address.equals(mDevice.getAddress())) { return; } try { mCallback.onMtuChanged(BluetoothGatt.this, mtu, status); } catch (Exception ex) { Log.w(TAG, "Unhandled exception in callback", ex); } } /** * Callback invoked when the given connection is updated * @hide */ <|startfocus|> public void OnConnectionUpdated(String address, int interval, int latency, <|endfocus|> int timeout, int status) { if (DBG) Log.d(TAG, "onConnectionUpdated() - Device=" + address + " interval=" + interval + " latency=" + latency + " timeout=" + timeout + " status=" + status); if (!address.equals(mDevice.getAddress())) { return; } try { mCallback.onConnectionUpdated(BluetoothGatt.this, interval, latency, timeout, status); } catch (Exception ex) { Log.w(TAG, "Unhandled exception in callback", ex); } } }; 
<|startcomment|> 2017 <|endcomment|> <|startfocus|> * Copyright (C) 2007 The Android Open Source Project <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.server; import static android.Manifest.permission.DUMP; import static android.Manifest.permission.SHUTDOWN; import android.content.Context; import android.net.IIpSecService; import android.net.INetd; import android.os.Binder; import android.os.Handler; import android.os.Process; import android.os.RemoteException; import android.os.ServiceManager; import android.util.Log; import java.io.FileDescriptor; import java.io.PrintWriter;
<|startcomment|> We don't need this since we're only going to be communicating to netd via binder. Use NetdService instead. <|endcomment|> import java.util.concurrent.CountDownLatch; /** @hide */ public class IpSecService extends IIpSecService.Stub implements Watchdog.Monitor { private static final String TAG = "IpSecService"; private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_TAG = "NetdConnector"; private static final String NETD_SERVICE_NAME = "netd"; /** Binder context for this service */ private final Context mContext; <|startfocus|> /** connector object for communicating with netd */ private final NativeDaemonConnector mConnector; private final Handler mFgHandler; <|endfocus|> private INetd mNetdService; private final Thread mThread; private CountDownLatch mConnectedSignal = new CountDownLatch(1); /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; // make sure this is on the same looper as our NativeDaemonConnector for sync purposes mFgHandler = new Handler(FgThread.get().getLooper()); mConnector =
<|startcomment|> Don't need this either. <|endcomment|>  private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_TAG = "NetdConnector"; private static final String NETD_SERVICE_NAME = "netd"; /** Binder context for this service */ private final Context mContext; /** connector object for communicating with netd */ private final NativeDaemonConnector mConnector; private final Handler mFgHandler; private INetd mNetdService; <|startfocus|> private final Thread mThread; private CountDownLatch mConnectedSignal = new CountDownLatch(1); <|endfocus|> /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; // make sure this is on the same looper as our NativeDaemonConnector for sync purposes mFgHandler = new Handler(FgThread.get().getLooper()); mConnector = new NativeDaemonConnector( new NetdCallbackReceiver(), socket, 10, NETD_TAG, 160, null /*wakelock*/, FgThread.get().getLooper());
<|startcomment|> Don't need this. <|endcomment|>  public void systemReady() { <|startfocus|> if (DBG) { final long start = System.currentTimeMillis(); prepareNativeDaemon(); final long delta = System.currentTimeMillis() - start; Log.d(TAG, "Prepared in " + delta + "ms"); return; <|endfocus|> } else { prepareNativeDaemon(); }
<|startcomment|> Look at NetdService.java. <|endcomment|>  private void connectNativeNetdService() { <|startfocus|> mNetdService = INetd.Stub.asInterface(ServiceManager.getService(NETD_SERVICE_NAME)); if (!isNetdAlive()) { Log.wtf(TAG, "Can't connect to NativeNetdService " + NETD_SERVICE_NAME); } <|endfocus|>
<|startcomment|> The time tracking is considered complete only when the user switches to another activity that is not part of the tracked flow. <|endcomment|>  assertEquals(RESULT_PASS, appEndReceiver.waitForActivity()); appEndReceiver.close(); if (!noHomeScreen()) { // At this time the timerReceiver should not fire, even though the activity has shut // down, because we are back to the home screen. Going to the home screen does not <|startfocus|> // qualify as the user leaving the activity's flow. Only when the The user switch to // another activity that is not part of the tracked flow that we consider the flow is // complete. <|endfocus|> assertEquals(RESULT_TIMEOUT, timeReceiver.waitForActivity()); assertTrue(timeReceiver.mTimeUsed == 0); } else { // With platforms that have no home screen, focus is returned to something else that is // considered a completion of the tracked activity flow, and hence time tracking is // triggered. assertEquals(RESULT_PASS, timeReceiver.waitForActivity()); } // Issuing now another activity will trigger the timing information release. final Intent dummyIntent = new Intent(context, MockApplicationActivity.class); dummyIntent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK);
<|startcomment|> Or, mNextSubnetId &= Short.MAX_VALUE; (i.e masking the sign byte). Branchless, but more obscure, so please don't do it :p Real suggestion though: consider having mNextSubmetId++ and this overflow check in the same statement: mActiveDownstreams.offer(new Downstream(downstream, mNextSubnetId)); mNextSubnetId = Math.max(0, mNextSubnetId + 1); // always positive <|endcomment|>  public void addActiveDownstream(TetherInterfaceStateMachine downstream) { if (findDownstream(downstream) == null) { // Adding a new downstream appends it to the list. Adding a // downstream a second time without first removing it has no effect. <|startfocus|> mActiveDownstreams.offer(new Downstream(downstream, mNextSubnetId++)); // Try to wrap cleanly after 2^15 downstreams added since boot. if (mNextSubnetId < 0) mNextSubnetId = 0; <|endfocus|> updateIPv6TetheringInterfaces(); }
<|startcomment|> Shouldn't this be StaticServiceFetcher? <|endcomment|>  // (which extends it). SYSTEM_SERVICE_NAMES.put(android.text.ClipboardManager.class, Context.CLIPBOARD_SERVICE); registerService(Context.CONNECTIVITY_SERVICE, ConnectivityManager.class, new StaticApplicationContextServiceFetcher<ConnectivityManager>() { @Override public ConnectivityManager createService(Context context) { IBinder b = ServiceManager.getService(Context.CONNECTIVITY_SERVICE); IConnectivityManager service = IConnectivityManager.Stub.asInterface(b); return new ConnectivityManager(context, service); }}); registerService(Context.IPSEC_SERVICE, IpSecManager.class, new StaticApplicationContextServiceFetcher<IpSecManager>() { @Override <|startfocus|> public IpSecManager createService(Context context) { <|endfocus|> IBinder b = ServiceManager.getService(Context.IPSEC_SERVICE); IIpSecService service = IIpSecService .Stub.asInterface(b); return new IpSecManager(context, service); }}); registerService(Context.COUNTRY_DETECTOR, CountryDetector.class, new StaticServiceFetcher<CountryDetector>() { @Override public CountryDetector createService() { IBinder b = ServiceManager.getService(Context.COUNTRY_DETECTOR); return new CountryDetector(ICountryDetector.Stub.asInterface(b)); }}); registerService(Context.DEVICE_POLICY_SERVICE, DevicePolicyManager.class,
<|startcomment|> Lose this space? <|endcomment|>  public IpSecManager createService(Context context) { IBinder b = ServiceManager.getService(Context.IPSEC_SERVICE); <|startfocus|> IIpSecService service = IIpSecService .Stub.asInterface(b); return new IpSecManager(context, service); <|endfocus|>
<|startcomment|> Also consider just using the class lock. <|endcomment|> import android.os.RemoteException; import android.util.Log; import android.util.Slog; import java.io.FileDescriptor; import java.io.PrintWriter; /** @hide */ public class IpSecService extends IIpSecService.Stub { private static final String TAG = "IpSecService"; private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_SERVICE_NAME = "netd"; /** Binder context for this service */ private final Context mContext; private Object mLock = new Object(); <|startfocus|> private static final int NETD_FETCH_TIMEOUT = 1000; //ms <|endfocus|> /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; } static IpSecService create(Context context, String socket) throws InterruptedException { final IpSecService service = new IpSecService(context, socket); service.connectNativeNetdService(); return service; } public static IpSecService create(Context context) throws InterruptedException {
<|startcomment|> This may not be enough. <|endcomment|> import android.util.Slog; import java.io.FileDescriptor; import java.io.PrintWriter; /** @hide */ public class IpSecService extends IIpSecService.Stub { private static final String TAG = "IpSecService"; private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_SERVICE_NAME = "netd"; /** Binder context for this service */ private final Context mContext; private Object mLock = new Object(); <|startfocus|> private static final int NETD_FETCH_TIMEOUT = 1000; //ms <|endfocus|> /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; } static IpSecService create(Context context, String socket) throws InterruptedException { final IpSecService service = new IpSecService(context, socket); service.connectNativeNetdService(); return service; } public static IpSecService create(Context context) throws InterruptedException { return create(context, NETD_SERVICE_NAME); } 
<|startcomment|> Just checking: in the previous code loadAlwaysOnPackage was called after the ctor had returned. Is this correct to call it at that point. Maybe it is more correct now :p <|endcomment|>  protected Vpn(Looper looper, Context context, INetworkManagementService netService, int userHandle, SystemServices systemServices) { mContext = context; mNetd = netService; mUserHandle = userHandle; mLooper = looper; mSystemServices = systemServices; mPackage = VpnConfig.LEGACY_VPN; mOwnerUID = getAppUid(mPackage, mUserHandle); <|startfocus|> loadAlwaysOnPackage(); <|endfocus|> try { netService.registerObserver(mObserver); } catch (RemoteException e) { Log.wtf(TAG, "Problem registering observer", e); } mNetworkInfo = new NetworkInfo(ConnectivityManager.TYPE_VPN, 0, NETWORKTYPE, ""); // TODO: Copy metered attribute and bandwidths from physical transport, b/16207332 mNetworkCapabilities = new NetworkCapabilities(); mNetworkCapabilities.addTransportType(NetworkCapabilities.TRANSPORT_VPN); mNetworkCapabilities.removeCapability(NetworkCapabilities.NET_CAPABILITY_NOT_VPN);
<|startcomment|> make this an interface, and you can drop all these "public static final"s. that's also the idiomatic way of doing things. <|endcomment|>  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.example.android.toyvpn; import android.app.Activity; import android.content.Intent; import android.content.SharedPreferences; import android.net.VpnService; import android.os.Bundle; import android.widget.TextView; public class ToyVpnClient extends Activity { <|startfocus|> public static class Prefs { public static final String NAME = "connection"; public static final String SERVER_ADDRESS = "server.address"; public static final String SERVER_PORT = "server.port"; public static final String SHARED_SECRET = "shared.secret"; <|endfocus|> } @Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.form); final TextView serverAddress = (TextView) findViewById(R.id.address); final TextView serverPort = (TextView) findViewById(R.id.port); final TextView sharedSecret = (TextView) findViewById(R.id.secret); 
<|startcomment|> indent is off <|endcomment|>  * * TODO: really don't do this; a blocking read on another thread is much cleaner. */ private static final long IDLE_INTERVAL_MS = TimeUnit.MILLISECONDS.toMillis(100); /** * Number of periods of length {@IDLE_INTERVAL_MS} to wait before declaring the handshake a * complete and abject failure. * * TODO: use a higher-level protocol; hand-rolling is a fun but pointless exercise. */ <|startfocus|> private static final int MAX_HANDSHAKE_ATTEMPTS = 50; <|endfocus|> private final VpnService mService; private final int mConnectionId; private final String mServerName; private final int mServerPort; private final byte[] mSharedSecret; private PendingIntent mConfigureIntent; private OnEstablishListener mOnEstablishListener; public ToyVpnConnection(final VpnService service, final int connectionId, final String serverName, final int serverPort, final byte[] sharedSecret) { mService = service; mConnectionId = connectionId; mServerName = serverName; mServerPort= serverPort; mSharedSecret = sharedSecret; } /**
<|startcomment|> for... ? <|endcomment|>  } catch (Exception e) { Log.e(getTag(), "Connection failed, exiting", e); } } private boolean run(SocketAddress server) throws Exception { ParcelFileDescriptor iface = null; boolean connected = false; // Create a DatagramChannel as the VPN tunnel. try (DatagramChannel tunnel = DatagramChannel.open()) { // Protect the tunnel before connecting to avoid loopback. if (!mService.protect(tunnel.socket())) { <|startfocus|> throw new IllegalStateException("Cannot protect the tunnel for"); <|endfocus|> } // Connect to the server. tunnel.connect(server); // For simplicity, we use the same thread for both reading and // writing. Here we put the tunnel into non-blocking mode. tunnel.configureBlocking(false); // Authenticate and configure the virtual network interface. iface = handshake(tunnel); // Now we are connected. Set the flag. connected = true; // Packets to be sent are queued in this input stream. FileInputStream in = new FileInputStream(iface.getFileDescriptor()); 
<|startcomment|> what's this check for ? also maybe document that for the sake of simplicity, you're using a fixed length buffer for the packet ? <|endcomment|>  packet.position(0); tunnel.write(packet); } packet.clear(); // Wait for the parameters within a limited time. for (int i = 0; i < MAX_HANDSHAKE_ATTEMPTS; ++i) { Thread.sleep(IDLE_INTERVAL_MS); // Normally we should not receive random packets. int length = tunnel.read(packet); if (length > 0 && packet.get(0) == 0) { <|startfocus|> return configure(new String(packet.array(), 1, length - 1).trim()); <|endfocus|> } } throw new IllegalStateException("Timed out"); } private ParcelFileDescriptor configure(String parameters) throws Exception { // Configure a builder while parsing the parameters. VpnService.Builder builder = mService.new Builder(); for (String parameter : parameters.split(" ")) { String[] fields = parameter.split(","); try { switch (fields[0].charAt(0)) { case 'm': builder.setMtu(Short.parseShort(fields[1])); break; case 'a': builder.addAddress(fields[1], Integer.parseInt(fields[2]));
<|startcomment|> this is considered bad practice : must always specify an encoding when constructing a string out of byte[] <|endcomment|>  packet.position(0); tunnel.write(packet); } packet.clear(); // Wait for the parameters within a limited time. for (int i = 0; i < MAX_HANDSHAKE_ATTEMPTS; ++i) { Thread.sleep(IDLE_INTERVAL_MS); // Normally we should not receive random packets. int length = tunnel.read(packet); if (length > 0 && packet.get(0) == 0) { <|startfocus|> return configure(new String(packet.array(), 1, length - 1).trim()); <|endfocus|> } } throw new IllegalStateException("Timed out"); } private ParcelFileDescriptor configure(String parameters) throws Exception { // Configure a builder while parsing the parameters. VpnService.Builder builder = mService.new Builder(); for (String parameter : parameters.split(" ")) { String[] fields = parameter.split(","); try { switch (fields[0].charAt(0)) { case 'm': builder.setMtu(Short.parseShort(fields[1])); break; case 'a': builder.addAddress(fields[1], Integer.parseInt(fields[2]));
<|startcomment|> what exception are you expecting ? catching "Exception" or "Throwable" is usually considered bad practice. <|endcomment|>  private void setConnectingThread(final Thread thread) { final Thread oldThread = mConnectingThread.getAndSet(thread); if (oldThread != null) { try { oldThread.interrupt(); <|startfocus|> } catch (Exception e) { <|endfocus|> Log.e(TAG, "Interrupting thread", e); } }
<|startcomment|> likewise <|endcomment|>  private void setConnection(final Connection connection) { final Connection oldConnection = mConnection.getAndSet(connection); if (oldConnection != null) { try { oldConnection.first.interrupt(); oldConnection.second.close(); } catch (Exception e) { <|startfocus|> Log.e(TAG, "Interrupting thread", e); <|endfocus|> } } 
<|startcomment|> tws <|endcomment|>  public static int inlineMonomorphic(Main a) { if (a == null) { return 42; } int i = 0; while (i < 100) { i += a.getValue(); } return i; } /// CHECK-START: int Main.inlinePolymorphic(Main) inliner (before) /// CHECK: InvokeVirtual method_name:Main.getValue /// CHECK-START: int Main.inlinePolymorphic(Main) inliner (after) /// CHECK-NOT: InvokeVirtual method_name:Main.getValue <|startfocus|> <|endfocus|> /// CHECK-START: int Main.inlineMonomorphic(Main) licm (before) /// CHECK: <<Deopt:l\d+>> Deoptimize /// CHECK: InstanceFieldGet [<<Deopt>>] field_name:Main.value /// CHECK-START: int Main.inlineMonomorphic(Main) licm (after) /// CHECK: <<Deopt:l\d+>> Deoptimize /// CHECK: InstanceFieldGet [<<Deopt>>] field_name:Main.value public static int inlinePolymorphic(Main a) { return a.getValue(); } public int getValue() { return value; } 
<|startcomment|> nit: Random newline <|endcomment|>  mNetworkFactory = new WifiNetworkFactory(getHandler().getLooper(), mContext, NETWORKTYPE, mNetworkCapabilitiesFilter); mNetworkFactory.setScoreFilter(60); mNetworkFactory.register(); // We can't filter untrusted network in the capabilities filter because a trusted // network would still satisfy a request that accepts untrusted ones. mUntrustedNetworkFactory = new UntrustedWifiNetworkFactory(getHandler().getLooper(), mContext, NETWORKTYPE_UNTRUSTED, mNetworkCapabilitiesFilter); mUntrustedNetworkFactory.setScoreFilter(Integer.MAX_VALUE); mUntrustedNetworkFactory.register(); } } } <|startfocus|> <|endfocus|> /** * WifiStateMachine needs to enable/disable other services when wifi is in client mode. This * method allows WifiStateMachine to get these additional system services. * * At this time, this method is used to setup variables for P2P service and Wifi Aware. */ private void getAdditionalWifiServiceInterfaces() { // First set up Wifi Direct if (mP2pSupported) { IBinder s1 = mFacade.getService(Context.WIFI_P2P_SERVICE); WifiP2pServiceImpl wifiP2pServiceImpl =
<|startcomment|> . http://b/36636576 [Since there's some additional information in there] <|endcomment|>  * and calls the <code>close</code> method of the underlying output * stream. * * @exception IOException if an I/O error occurs. * @since JCE1.2 */ public void close() throws IOException { if (closed) { return; } closed = true; try { obuffer = cipher.doFinal(); } catch (IllegalBlockSizeException | BadPaddingException e) { obuffer = null; <|startfocus|> // Android-added: Throw an exception when the underlying cipher does <|endfocus|> throw new IOException(e); } try { flush(); } catch (IOException ignored) {} out.close(); } } 
<|startcomment|> exceeds 100 chars <|endcomment|>  setAndBroadcastNetworkSetTime(mSavedTime + (currTime - mSavedAtTime)); } } private void revertToNitzTimeZone() { if (Settings.Global.getInt(mCr, Settings.Global.AUTO_TIME_ZONE, 0) == 0) { return; } String tmpLog = "Reverting to NITZ TimeZone: tz=" + mSavedTimeZone; if (DBG) log(tmpLog); mTimeZoneLog.log(tmpLog); if (mSavedTimeZone != null) { setAndBroadcastNetworkSetTimeZone(mSavedTimeZone); } } /** * Post a notification to NotificationManager for restricted state and * rejection cause for cs registration * <|startfocus|> * @param notifyType is one state of PS/CS_*_ENABLE/DISABLE <|endfocus|> */ @VisibleForTesting public void setNotification(int notifyType) { if (DBG) log("setNotification: create notification " + notifyType); // Needed because sprout RIL sends these when they shouldn't? boolean isSetNotification = mPhone.getContext().getResources().getBoolean( com.android.internal.R.bool.config_user_notification_of_restrictied_mobile_access);
<|startcomment|> exceeds 100 chars <|endcomment|> <|startfocus|> public void setNotification(int notifyType) { <|endfocus|> if (DBG) log("setNotification: create notification " + notifyType); // Needed because sprout RIL sends these when they shouldn't? boolean isSetNotification = mPhone.getContext().getResources().getBoolean( com.android.internal.R.bool.config_user_notification_of_restrictied_mobile_access); if (!isSetNotification) { if (DBG) log("Ignore all the notifications"); return; } Context context = mPhone.getContext(); CarrierConfigManager configManager = (CarrierConfigManager) context.getSystemService(Context.CARRIER_CONFIG_SERVICE); if (configManager != null) { PersistableBundle bundle = configManager.getConfig(); if (bundle != null) { boolean disableVoiceBarringNotification = bundle.getBoolean( CarrierConfigManager.KEY_DISABLE_VOICE_BARRING_NOTIFICATION_BOOL, false); if(disableVoiceBarringNotification && (notifyType == CS_ENABLED || notifyType == CS_NORMAL_ENABLED || notifyType == CS_EMERGENCY_ENABLED)) { if (DBG) log("Voice/emergency call barred notification disabled"); return; } } } CharSequence details = "";
<|startcomment|> the name for this seems like it could be a general case. maybe something like clearBlacklistForForcedConnection ? <|endcomment|> <|startfocus|> public void prepareForConnectionAttempt(int netId) { localLog("prepareForConnectionAttempt: netId=" + netId); <|endfocus|> clearConnectionAttemptTimeStamps(); clearBssidBlacklist();
<|startcomment|> spelling (sorry, i just happened to see it :) ) <|endcomment|>  long timeStamp = clock.getElapsedSinceBootMillis(); for (int index = 0; index < ssids.length; index++) { ScanDetail scanDetail = new ScanDetail(WifiSsid.createFromAsciiEncoded(ssids[index]), bssids[index], caps[index], levels[index], freqs[index], timeStamp, 0); scanDetailList.add(scanDetail); } return scanDetailList; } /** * Generate an array of {@link android.net.wifi.WifiConfiguration} based on the caller <|startfocus|> * supplied network SSID and sencurity information. <|endfocus|> * * @param ssids an array of SSIDs * @param securities an array of the network's security setting * @return the constructed array of {@link android.net.wifi.WifiConfiguration} */ public static WifiConfiguration[] generateWifiConfigurations(String[] ssids, int[] securities) { if (ssids == null || securities == null || ssids.length != securities.length || ssids.length == 0) { return null; } Map<String, Integer> netIdMap = new HashMap<>(); int netId = 0; 
<|startcomment|> This doesn't compile, UidDetail isn't imported. <|endcomment|>  MAXIMUM_POOL_SIZE, KEEP_ALIVE_SECONDS, TimeUnit.SECONDS, workQueue); for (int i = 1; i < mPackages.size(); i++) { final AppPrefLoader loader = new AppPrefLoader(); loader.executeOnExecutor(executor, mPackages.valueAt(i)); } } else { removePreference(KEY_APP_LIST); } } else { final Context context = getActivity(); <|startfocus|> UidDetail mUidDetail = new UidDetailProvider(context).getUidDetail(mAppItem.key, true); mIcon = mUidDetail.icon; mLabel = mUidDetail.label; <|endfocus|> mPackageName = context.getPackageName(); removePreference(KEY_UNRESTRICTED_DATA); removePreference(KEY_APP_SETTINGS); removePreference(KEY_RESTRICT_BACKGROUND); removePreference(KEY_APP_LIST); }
<|startcomment|> just uidDetail, it's not a member variable so calling it mUidDetail would be strange. <|endcomment|>  MAXIMUM_POOL_SIZE, KEEP_ALIVE_SECONDS, TimeUnit.SECONDS, workQueue); for (int i = 1; i < mPackages.size(); i++) { final AppPrefLoader loader = new AppPrefLoader(); loader.executeOnExecutor(executor, mPackages.valueAt(i)); } } else { removePreference(KEY_APP_LIST); } } else { final Context context = getActivity(); <|startfocus|> UidDetail mUidDetail = new UidDetailProvider(context).getUidDetail(mAppItem.key, true); mIcon = mUidDetail.icon; mLabel = mUidDetail.label; <|endfocus|> mPackageName = context.getPackageName(); removePreference(KEY_UNRESTRICTED_DATA); removePreference(KEY_APP_SETTINGS); removePreference(KEY_RESTRICT_BACKGROUND); removePreference(KEY_APP_LIST); }
<|startcomment|> this will never be thrown on Android (i should go modify the docs to stop claiming this happens) <|endcomment|>  private void setConnectingThread(final Thread thread) { final Thread oldThread = mConnectingThread.getAndSet(thread); if (oldThread != null) { <|startfocus|> try { oldThread.interrupt(); } catch (SecurityException e) { Log.e(TAG, "Interrupting thread", e); } <|endfocus|> }
<|startcomment|> Why not use a List and a ListCodec here? <|endcomment|>  */ @HasKeyId @Name("BoostLockedRegionPriorityFeature") @Description("Feature turning on BoostLockedRegionPriorityFeature") public final class BoostLockedRegionPriorityFeature implements Feature { @Nonnull public static final BooleanPropertyId ENABLE = BooleanPropertyId.create( "jack.transformations.boost-locked-region-priority", "Boost priority of threads acquiring certain locks") .addCategory(Private.class) .addDefaultValue(Boolean.FALSE) .addCategory(DumpInLibrary.class); @Nonnull <|startfocus|> public static final PropertyId<String> BOOST_LOCK_CLASSNAME = <|endfocus|> PropertyId.create( "jack.transformations.boost-locked-region-priority.classname", "The class signatures where acquiring it as a lock should boost a thread's prioirty", new ClassNameCodec()) .requiredIf(BoostLockedRegionPriorityFeature.ENABLE.getValue().isTrue()) .addCategory(Private.class) .addCategory(DumpInLibrary.class); @Nonnull public static final PropertyId<List<MethodNameValue>> BOOST_LOCK_REQUEST_METHOD = PropertyId.create( "jack.transformations.boost-locked-region-priority.request", "Static methods in the specified classes that can boost a thread's prioirty",
<|startcomment|> lockClass is @Nonnull. If you want to shortcut, use lockClass.lenth == 0 ... <|endcomment|>  Jack.getSession().getReporter().report(Severity.FATAL, new BadBoostLockedRegionPriorityConfigurationException(prop, e)); Jack.getSession().abortEventually(); return null; } } @Override public void run(@Nonnull JMethod method) { if (method.isNative() || method.isAbstract() || !filter.accept(this.getClass(), method)) { return; } <|startfocus|> if (lockClass == null || requestClass == null || resetClass == null || requestMethodId == null || resetMethodId == null) { <|endfocus|> return; } TransformationRequest tr = new TransformationRequest(method); Visitor visitor = new Visitor(method, tr); visitor.accept(method); tr.commit(); } private class Visitor extends JVisitor { @Nonnull private final JMethod method; @Nonnull private final TransformationRequest tr; public Visitor(@Nonnull JMethod method, @Nonnull TransformationRequest tr) { this.method = method; this.tr = tr; } @Override public void endVisit(@Nonnull JLock jLock) { assert lockClass != null; int lockIndex = -1;
<|startcomment|> we don't have these in HIDL anyway, so you would never get this? Also you seem to throw UnsupportedOperation on these <|endcomment|>  * Two objects of HIDL types are considered equal if: * 1. Both null * 2. Both non-null, and of the same class, and: * 2.1 Both are primitive arrays / enum arrays, elements are equal using == check * 2.2 Both are object arrays, elements are checked recursively * 2.3 Both are Lists, elements are checked recursively * 2.4 (If both are collections other than lists or maps, undefined behavior) <|startfocus|> * 2.5 .equals return true <|endfocus|> */ public static boolean deepEquals(Object lft, Object rgt) { if (lft == rgt) { return true; } if (lft == null || rgt == null) { return false; } Class<?> lftClazz = lft.getClass(); Class<?> rgtClazz = rgt.getClass(); if (lftClazz != rgtClazz) { return false; } if (lftClazz.isArray()) { Class<?> lftElementType = lftClazz.getComponentType(); if (lftElementType != rgtClazz.getComponentType()) { return false; } 
<|startcomment|> nit: returns <|endcomment|>  * Two objects of HIDL types are considered equal if: * 1. Both null * 2. Both non-null, and of the same class, and: * 2.1 Both are primitive arrays / enum arrays, elements are equal using == check * 2.2 Both are object arrays, elements are checked recursively * 2.3 Both are Lists, elements are checked recursively * 2.4 (If both are collections other than lists or maps, undefined behavior) <|startfocus|> * 2.5 .equals return true <|endfocus|> */ public static boolean deepEquals(Object lft, Object rgt) { if (lft == rgt) { return true; } if (lft == null || rgt == null) { return false; } Class<?> lftClazz = lft.getClass(); Class<?> rgtClazz = rgt.getClass(); if (lftClazz != rgtClazz) { return false; } if (lftClazz.isArray()) { Class<?> lftElementType = lftClazz.getComponentType(); if (lftElementType != rgtClazz.getComponentType()) { return false; } 
<|startcomment|> which equals? <|endcomment|>  * Two objects of HIDL types are considered equal if: * 1. Both null * 2. Both non-null, and of the same class, and: * 2.1 Both are primitive arrays / enum arrays, elements are equal using == check * 2.2 Both are object arrays, elements are checked recursively * 2.3 Both are Lists, elements are checked recursively * 2.4 (If both are collections other than lists or maps, undefined behavior) <|startfocus|> * 2.5 .equals return true <|endfocus|> */ public static boolean deepEquals(Object lft, Object rgt) { if (lft == rgt) { return true; } if (lft == null || rgt == null) { return false; } Class<?> lftClazz = lft.getClass(); Class<?> rgtClazz = rgt.getClass(); if (lftClazz != rgtClazz) { return false; } if (lftClazz.isArray()) { Class<?> lftElementType = lftClazz.getComponentType(); if (lftElementType != rgtClazz.getComponentType()) { return false; } 
<|startcomment|> inconsistent indent. <|endcomment|>  } String invokeWith = null; if ((app.info.flags & ApplicationInfo.FLAG_DEBUGGABLE) != 0) { // Debuggable apps may include a wrapper script with their library directory. String wrapperFileName = app.info.nativeLibraryDir + "/wrap.sh"; StrictMode.ThreadPolicy oldPolicy = StrictMode.allowThreadDiskReads(); try { if (new File(wrapperFileName).exists()) { invokeWith = "/system/bin/logwrapper " + wrapperFileName; } } finally { <|startfocus|> StrictMode.setThreadPolicy(oldPolicy); <|endfocus|> } } String requiredAbi = (abiOverride != null) ? abiOverride : app.info.primaryCpuAbi; if (requiredAbi == null) { requiredAbi = Build.SUPPORTED_ABIS[0]; } String instructionSet = null; if (app.info.primaryCpuAbi != null) { instructionSet = VMRuntime.getInstructionSet(app.info.primaryCpuAbi); } app.gids = gids; app.requiredAbi = requiredAbi; app.instructionSet = instructionSet; // Start the process. It will either succeed and return a result containing
<|startcomment|> and WFC Mode <|endcomment|>  loge("setWfcSetting(): ", e); } } } /** * Change persistent WFC enabled setting for slot. */ public void setWfcSettingForSlot(boolean enabled) { int value = enabled ? 1 : 0; android.provider.Settings.Global.putInt(mContext.getContentResolver(), android.provider.Settings.Global.WFC_IMS_ENABLED, value); setWfcSettingInternalForSlot(enabled, getWfcModeForSlot()); } /** <|startfocus|> * Non-persistently change WFC eanbled setting and WFC preference for slot <|endfocus|> * * @param wfcMode The WFC preference if WFC is enabled */ public void setWfcSettingInternalForSlot(boolean enabled, int wfcMode) { int imsFeatureValue = enabled ? ImsConfig.FeatureValueConstants.ON : ImsConfig.FeatureValueConstants.OFF; // Force IMS to register over LTE when turning off WFC int imsWfcModeFeatureValue = enabled ? wfcMode : ImsConfig.WfcModeFeatureValueConstants.CELLULAR_PREFERRED; try { ImsConfig config = getConfigInterface(); config.setFeatureValue(ImsConfig.FeatureConstants.FEATURE_TYPE_VOICE_OVER_WIFI, TelephonyManager.NETWORK_TYPE_IWLAN,
<|startcomment|> enabled <|endcomment|>  loge("setWfcSetting(): ", e); } } } /** * Change persistent WFC enabled setting for slot. */ public void setWfcSettingForSlot(boolean enabled) { int value = enabled ? 1 : 0; android.provider.Settings.Global.putInt(mContext.getContentResolver(), android.provider.Settings.Global.WFC_IMS_ENABLED, value); setWfcSettingInternalForSlot(enabled, getWfcModeForSlot()); } /** <|startfocus|> * Non-persistently change WFC eanbled setting and WFC preference for slot <|endfocus|> * * @param wfcMode The WFC preference if WFC is enabled */ public void setWfcSettingInternalForSlot(boolean enabled, int wfcMode) { int imsFeatureValue = enabled ? ImsConfig.FeatureValueConstants.ON : ImsConfig.FeatureValueConstants.OFF; // Force IMS to register over LTE when turning off WFC int imsWfcModeFeatureValue = enabled ? wfcMode : ImsConfig.WfcModeFeatureValueConstants.CELLULAR_PREFERRED; try { ImsConfig config = getConfigInterface(); config.setFeatureValue(ImsConfig.FeatureConstants.FEATURE_TYPE_VOICE_OVER_WIFI, TelephonyManager.NETWORK_TYPE_IWLAN,
<|startcomment|> Should this be public if it is "Internal"? <|endcomment|> <|startfocus|> public void setWfcSettingInternalForSlot(boolean enabled, int wfcMode) { <|endfocus|> int imsFeatureValue = enabled ? ImsConfig.FeatureValueConstants.ON : ImsConfig.FeatureValueConstants.OFF; // Force IMS to register over LTE when turning off WFC int imsWfcModeFeatureValue = enabled ? wfcMode : ImsConfig.WfcModeFeatureValueConstants.CELLULAR_PREFERRED; try { ImsConfig config = getConfigInterface(); config.setFeatureValue(ImsConfig.FeatureConstants.FEATURE_TYPE_VOICE_OVER_WIFI, TelephonyManager.NETWORK_TYPE_IWLAN, imsFeatureValue, mImsConfigListener); if (enabled) { log("setWfcSettingForSlot() : turnOnIms"); turnOnIms(); } else if (isTurnOffImsAllowedByPlatformForSlot() && (!isVolteEnabledByPlatformForSlot() || !isEnhanced4gLteModeSettingEnabledByUserForSlot())) { log("setWfcSettingForSlot() : imsServiceAllowTurnOff -> turnOffIms"); turnOffIms(); } setWfcModeInternalForSlot(imsWfcModeFeatureValue); } catch (ImsException e) { loge("setWfcSettingForSlot(): ", e); }
<|startcomment|> Intentional? <|endcomment|>  * <h3>Developer Guides</h3> * <p>For more information about using Bluetooth, read the * <a href="{@docRoot}guide/topics/connectivity/bluetooth.html">Bluetooth</a> developer guide.</p> * </div> * * {@see BluetoothServerSocket} * {@see java.io.InputStream} * {@see java.io.OutputStream} */ public final class BluetoothSocket implements Closeable { private static final String TAG = "BluetoothSocket"; <|startfocus|> private static final boolean DBG = true; <|endfocus|> private static final boolean VDBG = Log.isLoggable(TAG, Log.VERBOSE); /** @hide */ public static final int MAX_RFCOMM_CHANNEL = 30; /*package*/ static final int MAX_L2CAP_PACKAGE_SIZE = 0xFFFF; /** RFCOMM socket */ public static final int TYPE_RFCOMM = 1; /** SCO socket */ public static final int TYPE_SCO = 2; /** L2CAP socket */ public static final int TYPE_L2CAP = 3; /*package*/ static final int EBADFD = 77; /*package*/ static final int EADDRINUSE = 98; 
<|startcomment|> What was the purpose of this? This wasn't there in the original (pre-NS-as-object) code? This actually busted some existing Wi-Fi Aware code. It doesn't allow copying and modifying NetworkCapabilities. I don't see an issue with allowing an overwrite. <|endcomment|>  public NetworkCapabilities setNetworkSpecifier(NetworkSpecifier networkSpecifier) { if (networkSpecifier != null && Long.bitCount(mTransportTypes) != 1) { throw new IllegalStateException("Must have a single transport specified to use " + "setNetworkSpecifier"); } <|startfocus|> if (mNetworkSpecifier != null) { throw new IllegalStateException("Network specifier already set"); } <|endfocus|> if (networkSpecifier != null && !(networkSpecifier instanceof Parcelable)) { throw new IllegalArgumentException("Network specifier must be parcelable"); } mNetworkSpecifier = networkSpecifier; return this;
<|startcomment|> instanceof already contains an implicit null guard, i.e null cannot match anything with instanceof. <|endcomment|>  public boolean equals(Object o) { <|startfocus|> return o != null && o instanceof MatchAllNetworkSpecifier; <|endfocus|>
<|startcomment|> implicitly in the instanceof check. <|endcomment|>  public NetworkCapabilities setNetworkSpecifier(NetworkSpecifier networkSpecifier) { if (networkSpecifier != null && Long.bitCount(mTransportTypes) != 1) { throw new IllegalStateException("Must have a single transport specified to use " + "setNetworkSpecifier"); } <|startfocus|> if (networkSpecifier != null && !(networkSpecifier instanceof Parcelable)) { throw new IllegalArgumentException("Network specifier must be parcelable"); } <|endfocus|> mNetworkSpecifier = networkSpecifier; return this;
<|startcomment|> Just checking: isn't the normal java format style to put the "||" or "&&" at the beginning of the next line ? <|endcomment|>  private boolean satisfiedBySpecifier(NetworkCapabilities nc) { <|startfocus|> return mNetworkSpecifier == null || mNetworkSpecifier.satisfiedBy(nc.mNetworkSpecifier) || nc.mNetworkSpecifier instanceof MatchAllNetworkSpecifier; <|endfocus|>
<|startcomment|> Why the cast ? <|endcomment|>  (mLinkUpBandwidthKbps * 11) + (mLinkDownBandwidthKbps * 13) + Objects.hashCode(mNetworkSpecifier) * 17 + (mSignalStrength * 19)); } @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel dest, int flags) { dest.writeLong(mNetworkCapabilities); dest.writeLong(mTransportTypes); dest.writeInt(mLinkUpBandwidthKbps); dest.writeInt(mLinkDownBandwidthKbps); <|startfocus|> dest.writeParcelable((Parcelable) mNetworkSpecifier, 0); <|endfocus|> dest.writeInt(mSignalStrength); } public static final Creator<NetworkCapabilities> CREATOR = new Creator<NetworkCapabilities>() { @Override public NetworkCapabilities createFromParcel(Parcel in) { NetworkCapabilities netCap = new NetworkCapabilities(); netCap.mNetworkCapabilities = in.readLong(); netCap.mTransportTypes = in.readLong(); netCap.mLinkUpBandwidthKbps = in.readInt(); netCap.mLinkDownBandwidthKbps = in.readInt(); netCap.mNetworkSpecifier = in.readParcelable(null); netCap.mSignalStrength = in.readInt(); return netCap; } @Override
<|startcomment|> pass the flags variable in. <|endcomment|>  (mLinkUpBandwidthKbps * 11) + (mLinkDownBandwidthKbps * 13) + Objects.hashCode(mNetworkSpecifier) * 17 + (mSignalStrength * 19)); } @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel dest, int flags) { dest.writeLong(mNetworkCapabilities); dest.writeLong(mTransportTypes); dest.writeInt(mLinkUpBandwidthKbps); dest.writeInt(mLinkDownBandwidthKbps); <|startfocus|> dest.writeParcelable((Parcelable) mNetworkSpecifier, 0); <|endfocus|> dest.writeInt(mSignalStrength); } public static final Creator<NetworkCapabilities> CREATOR = new Creator<NetworkCapabilities>() { @Override public NetworkCapabilities createFromParcel(Parcel in) { NetworkCapabilities netCap = new NetworkCapabilities(); netCap.mNetworkCapabilities = in.readLong(); netCap.mTransportTypes = in.readLong(); netCap.mLinkUpBandwidthKbps = in.readInt(); netCap.mLinkDownBandwidthKbps = in.readInt(); netCap.mNetworkSpecifier = in.readParcelable(null); netCap.mSignalStrength = in.readInt(); return netCap; } @Override
<|startcomment|> Consider using Preconditions <|endcomment|>  public StringNetworkSpecifier(String specifier) { <|startfocus|> if (TextUtils.isEmpty(specifier)) { throw new IllegalArgumentException("Network specifier must not be empty"); } <|endfocus|> this.specifier = specifier;
<|startcomment|> Is there a way to reuse equals ? Besides the null check, logic looks identical. <|endcomment|>  public boolean satisfiedBy(NetworkSpecifier other) { <|startfocus|> if (other == null) return false; if (!(other instanceof StringNetworkSpecifier)) return false; return specifier.equals(((StringNetworkSpecifier) other).specifier); <|endfocus|>
<|startcomment|> 7 <|endcomment|> <|startfocus|> * Copyright (C) 2016 The Android Open Source Project <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net; import android.os.Parcel; import android.os.Parcelable; import android.text.TextUtils; import java.util.Objects; /** @hide */ public final class StringNetworkSpecifier extends NetworkSpecifier implements Parcelable { public final String specifier; public StringNetworkSpecifier(String specifier) { if (TextUtils.isEmpty(specifier)) { throw new IllegalArgumentException("Network specifier must not be empty"); }
<|startcomment|> "false"? <|endcomment|>  public boolean satisfiedBy(NetworkSpecifier other) { <|startfocus|> if (other == null) return true; <|endfocus|> if (!(other instanceof StringNetworkSpecifier)) return false; return specifier.equals(((StringNetworkSpecifier) other).specifier);
<|startcomment|> The socket is no longer necessary, right? Can you remove it? <|endcomment|> <|startfocus|> private IpSecService(Context context, String socket) { <|endfocus|> mContext = context;
<|startcomment|> Ditto. <|endcomment|>  /** Binder context for this service */ private final Context mContext; private Object mLock = new Object(); private static final int NETD_FETCH_TIMEOUT = 5000; //ms /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; } <|startfocus|> static IpSecService create(Context context, String socket) throws InterruptedException { final IpSecService service = new IpSecService(context, socket); <|endfocus|> service.connectNativeNetdService(); return service; } public static IpSecService create(Context context) throws InterruptedException { return create(context, NETD_SERVICE_NAME); } public void systemReady() { if (isNetdAlive()) { Slog.d(TAG, "IpSecService is ready"); } else { Slog.wtf(TAG, "IpSecService not ready: failed to connect to NetD Native Service!"); } } private void connectNativeNetdService() { // Avoid blocking the system server to do this Thread t =
<|startcomment|> Ditto. <|endcomment|>  /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context, String socket) { mContext = context; } static IpSecService create(Context context, String socket) throws InterruptedException { final IpSecService service = new IpSecService(context, socket); service.connectNativeNetdService(); return service; } <|startfocus|> public static IpSecService create(Context context) throws InterruptedException { return create(context, NETD_SERVICE_NAME); } <|endfocus|> public void systemReady() { if (isNetdAlive()) { Slog.d(TAG, "IpSecService is ready"); } else { Slog.wtf(TAG, "IpSecService not ready: failed to connect to NetD Native Service!"); } } private void connectNativeNetdService() { // Avoid blocking the system server to do this Thread t = new Thread( new Runnable() { @Override public void run() { synchronized (mLock) { NetdService.get(NETD_FETCH_TIMEOUT); } }
<|startcomment|> If keys are ints, consider using a SparseArray instead if the number of entries is small or bounded. <|endcomment|>  } void unlinkDeathRecipient() { if (mBinder != null) { mBinder.unlinkToDeath(this, 0); } } protected void releaseResources() {} protected void nullifyRecord() {} public void binderDied() { Log.w(TAG, "IpSecService.SpiRecord binderDied(" + mBinder + ")"); } } <|startfocus|> private final HashMap<Integer, SpiRecord> mSpiRecords = new HashMap<>(); private final HashMap<Integer, TransformRecord> mTransformRecords = new HashMap<>(); <|endfocus|> /** * Constructs a new IpSecService instance * * @param context Binder context for this service */ private IpSecService(Context context) { mContext = context; } static IpSecService create(Context context) throws InterruptedException { final IpSecService service = new IpSecService(context); service.connectNativeNetdService(); return service; } public void systemReady() { if (isNetdAlive()) { Slog.d(TAG, "IpSecService is ready"); } else {
<|startcomment|> ?? <|endcomment|>  } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } synchronized (mSpiRecords) { mSpiRecords.put( resourceId, new SpiRecord(resourceId, direction, localAddress, remoteAddress, spi, binder)); } Bundle retBundle = new Bundle(3); retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_STATUS, IpSecManager.Status.OK); retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_RESOURCE_ID, resourceId); retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_SPI, spi); <|startfocus|> return null; <|endfocus|>
<|startcomment|> Isn't there some minimal validation you should do here (same comment for other impl methods). For instance can c be null ? <|endcomment|> <|startfocus|> public Bundle createTransportModeTransform(IpSecConfig c, IBinder binder) { <|endfocus|> int resourceId = mNextTransformId.getAndIncrement(); for (int direction : new int[] {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}) { IpSecAlgorithm auth = c.getAuthentication(direction); IpSecAlgorithm crypt = c.getEncryption(direction); try { int result = getNetdInstance().ipSecAddSecurityAssociation( resourceId, c.getMode(), direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "", (c.getRemoteAddress() != null) ? c.getRemoteAddress().getHostAddress() : "", (c.getNetwork() != null) ? c.getNetwork().getNetworkHandle() : 0, c.getSpi(direction), (auth != null) ? auth.getName() : "", (auth != null) ? auth.getKey() : null, (auth != null) ? auth.getTruncationLengthBits() : 0, (crypt != null) ? crypt.getName() : "",
<|startcomment|> Consider declaring this as a package private static final int[] DIRECTIONS = { OUT, IN }; Otherwise consider putting the block below in a helper priv method createTransportModeTransform(IpSecConfig c, IBinder binder, int direction) and do createTransportModeTransform(c, binder, DIRECTION_OUT); createTransportModeTransform(c, binder, DIRECTION_IN); (alternative is probably not convenient for control flow though). <|endcomment|>  public Bundle createTransportModeTransform(IpSecConfig c, IBinder binder) { int resourceId = mNextTransformId.getAndIncrement(); <|startfocus|> for (int direction : new int[] {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}) { <|endfocus|> IpSecAlgorithm auth = c.getAuthentication(direction); IpSecAlgorithm crypt = c.getEncryption(direction); try { int result = getNetdInstance().ipSecAddSecurityAssociation( resourceId, c.getMode(), direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "", (c.getRemoteAddress() != null) ? c.getRemoteAddress().getHostAddress() : "", (c.getNetwork() != null) ? c.getNetwork().getNetworkHandle() : 0, c.getSpi(direction), (auth != null) ? auth.getName() : "", (auth != null) ? auth.getKey() : null, (auth != null) ? auth.getTruncationLengthBits() : 0,
<|startcomment|> It is a bit ugly and hard to read, but I am not sure how it could be improved really. Maybe you can define a "null" IpSecAlgorithm object that returns "", null and 0 for getName() getKey() getTruncationLengthBits. Then instead of doing three times (auth != null) xxx : yyy, you can simply do: IpSecAlgorithm auth = c.getAuthentication(direction); if (auth == null) { auth = IpSecAlgorithm.NULL; // or DEFAULT, or NONE, ... } <|endcomment|>  (auth != null) ? auth.getKey() : null, (auth != null) ? auth.getTruncationLengthBits() : 0, (crypt != null) ? crypt.getName() : "", (crypt != null) ? crypt.getKey() : null, (crypt != null) ? crypt.getTruncationLengthBits() : 0, c.getEncapType(), c.getEncapLocalPort(), c.getEncapRemotePort()); if (result != c.getSpi(direction)) { Bundle retBundle = new Bundle(2); retBundle.putInt( IpSecTransform.KEY_STATUS, IpSecManager.Status.SPI_UNAVAILABLE); <|startfocus|> retBundle.putInt(IpSecTransform.KEY_RESOURCE_ID, IpSecTransform.INVALID_SPI); <|endfocus|> return retBundle; } } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } synchronized (mTransformRecords) { mTransformRecords.put(resourceId, new TransformRecord(c, resourceId, binder)); } 
<|startcomment|> Could be a static final object with documentation: returned by xxx when yyy fails. <|endcomment|>  (crypt != null) ? crypt.getKey() : null, (crypt != null) ? crypt.getTruncationLengthBits() : 0, c.getEncapType(), c.getEncapLocalPort(), c.getEncapRemotePort()); if (result != c.getSpi(direction)) { Bundle retBundle = new Bundle(2); retBundle.putInt( IpSecTransform.KEY_STATUS, IpSecManager.Status.SPI_UNAVAILABLE); <|startfocus|> retBundle.putInt(IpSecTransform.KEY_RESOURCE_ID, IpSecTransform.INVALID_SPI); <|endfocus|> return retBundle; } } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } } synchronized (mTransformRecords) { mTransformRecords.put(resourceId, new TransformRecord(c, resourceId, binder)); } Bundle retBundle = new Bundle(2); retBundle.putInt(IpSecTransform.KEY_STATUS, IpSecManager.Status.OK); retBundle.putInt(IpSecTransform.KEY_RESOURCE_ID, resourceId); return retBundle;
<|startcomment|> should be in the sync block. <|endcomment|>  public void deleteTransportModeTransform(int resourceId) { TransformRecord record; <|startfocus|> synchronized (mTransformRecords) { <|endfocus|> // We want to non-destructively get so that we can check credentials before removing this record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } // remove from the DB because releasing might fail, but it won't ever succeed later mTransformRecords.remove(resourceId); record.releaseResources(); record.nullifyRecord(); }
<|startcomment|> Is this failure detectable here ? If yes I suggest adding a log so that it can be discovered if there is a real issue going on. <|endcomment|>  record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } <|startfocus|> // remove from the DB because releasing might fail, but it won't ever succeed later mTransformRecords.remove(resourceId); <|endfocus|> record.releaseResources(); record.nullifyRecord(); }
<|startcomment|> Should be in the sync block <|endcomment|>  public void applyTransportModeTransform(ParcelFileDescriptor socket, int resourceId) { <|startfocus|> TransformRecord info; <|endfocus|> synchronized (mTransformRecords) { // FIXME: this code should be factored out into a security check + getter info = mTransformRecords.get(resourceId); if (info == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not active"); } if (info.pid != getCallingPid() || info.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may apply it!"); } IpSecConfig c = info.getConfig(); try { for (int direction : new int[] {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}) { getNetdInstance().ipSecApplyTransportModeTransform( socket.getFileDescriptor(), resourceId, direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "", (c.getRemoteAddress() != null) ? c.getRemoteAddress().getHostAddress() : "",
<|startcomment|> It seems that this class is going to be dummy now. We might want to keep the class for future unit tests but at least we should remove unused imports. <|endcomment|> import static org.mockito.Mockito.atLeastOnce; import static org.mockito.Mockito.mock; import static org.mockito.Mockito.validateMockitoUsage; import static org.mockito.Mockito.verify; import static org.mockito.Mockito.when; import android.content.Context; import android.net.wifi.WifiScanner.BssidInfo; import android.os.Handler; import android.os.Message; import android.os.test.TestLooper; import android.test.suitebuilder.annotation.SmallTest; import com.android.internal.util.test.BidirectionalAsyncChannelServer; import org.junit.After; import org.junit.Before; <|startfocus|> import org.junit.Test; import org.mockito.ArgumentCaptor; <|endfocus|> import org.mockito.Mock; import org.mockito.MockitoAnnotations; /** * Unit tests for {@link android.net.wifi.WifiScanner}. */ @SmallTest public class WifiScannerTest { @Mock private Context mContext; @Mock private IWifiScanner mService; private WifiScanner mWifiScanner; private TestLooper mLooper; private Handler mHandler; /** * Setup before tests. */ @Before public void setUp() throws Exception { MockitoAnnotations.initMocks(this); mLooper = new TestLooper(); mHandler = mock(Handler.class);
<|startcomment|> Not sure why this is needed. <|endcomment|>  mImsRegistered = (responseArray[0] == 1) ? true : false; } break; //GSM case EVENT_RADIO_AVAILABLE: //this is unnecessary //setPowerStateToDesired(); break; case EVENT_SIM_READY: // Reset the mPreviousSubId so we treat a SIM power bounce // as a first boot. See b/19194287 mOnSubscriptionsChangedListener.mPreviousSubId.set(-1); pollState(); // Signal strength polling stops when radio is off queueNextSignalStrengthPoll(); <|startfocus|> setNotification(CS_ENABLED); <|endfocus|> break; case EVENT_RADIO_STATE_CHANGED: case EVENT_PHONE_TYPE_SWITCHED: if(!mPhone.isPhoneTypeGsm() && mCi.getRadioState() == CommandsInterface.RadioState.RADIO_ON) { handleCdmaSubscriptionSource(mCdmaSSM.getCdmaSubscriptionSource()); // Signal strength polling stops when radio is off. queueNextSignalStrengthPoll(); } // This will do nothing in the 'radio not available' case setPowerStateToDesired(); // These events are modem triggered, so pollState() needs to be forced modemTriggeredPollState(); break; 
<|startcomment|> nit: the user or users. <|endcomment|>  * Reference: 3GPP TS 36.104 5.4.3) inclusive ranges on which lte_rsrp_boost_int * will be applied. Format of the String array is expected to be {"erafcn1_start-earfcn1_end", * "earfcn2_start-earfcn2_end" ... } * @hide */ public static final String KEY_BOOSTED_LTE_EARFCNS_STRING_ARRAY = "boosted_lte_earfcns_string_array"; <|startfocus|> /** * Key identifying if voice call barring notification is required to be shown to user. * @hide */ public static final String KEY_DISABLE_VOICE_BARRING_NOTIFICATION_BOOL = "disable_voice_barring_notification_bool"; <|endfocus|> /** The default value for every variable. */ private final static PersistableBundle sDefaults; static { sDefaults = new PersistableBundle(); sDefaults.putBoolean(KEY_ALLOW_HOLD_IN_IMS_CALL_BOOL, true); sDefaults.putBoolean(KEY_ADDITIONAL_CALL_SETTING_BOOL, true); sDefaults.putBoolean(KEY_ALLOW_EMERGENCY_NUMBERS_IN_CALL_LOG_BOOL, false); sDefaults.putBoolean(KEY_ALLOW_LOCAL_DTMF_TONES_BOOL, true);
<|startcomment|> Now the comment doesn't match the new static variable name. <|endcomment|>  * perform operations that pertain to network connectivity at an abstract * level, use {@link android.net.ConnectivityManager}. */ public class WifiManager { private static final String TAG = "WifiManager"; // Supplicant error codes: /** * The error code if there was a problem authenticating. */ public static final int ERROR_AUTHENTICATING = 1; // Supplicant Authentication Failure reason codes: /** <|startfocus|> * Default reason code for error during authentication. <|endfocus|> * @hide */ public static final int ERROR_AUTH_FAILURE_NONE = 0; // Supplicant Authentication Failure reason codes: /** * The reason code if there was a timeout authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1; // Supplicant Authentication Failure reason codes: /** * The reason code if there was a wrong password while * authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2; // Supplicant Authentication Failure reason codes: /**
<|startcomment|> Remove this line. <|endcomment|>  */ public class WifiManager { private static final String TAG = "WifiManager"; // Supplicant error codes: /** * The error code if there was a problem authenticating. */ public static final int ERROR_AUTHENTICATING = 1; // Supplicant Authentication Failure reason codes: /** * Default reason code for error during authentication. * @hide */ public static final int ERROR_AUTH_FAILURE_NONE = 0; <|startfocus|> // Supplicant Authentication Failure reason codes: <|endfocus|> /** * The reason code if there was a timeout authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1; // Supplicant Authentication Failure reason codes: /** * The reason code if there was a wrong password while * authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2; // Supplicant Authentication Failure reason codes: /** * The reason code if there was EAP failure while * authenticating. * @hide */
<|startcomment|> Remove this line. <|endcomment|>  */ public static final int ERROR_AUTHENTICATING = 1; // Supplicant Authentication Failure reason codes: /** * Default reason code for error during authentication. * @hide */ public static final int ERROR_AUTH_FAILURE_NONE = 0; // Supplicant Authentication Failure reason codes: /** * The reason code if there was a timeout authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1; <|startfocus|> // Supplicant Authentication Failure reason codes: <|endfocus|> /** * The reason code if there was a wrong password while * authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2; // Supplicant Authentication Failure reason codes: /** * The reason code if there was EAP failure while * authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3; /** * Broadcast intent action indicating whether Wi-Fi scanning is allowed currently * @hide */
<|startcomment|> Remove this line. <|endcomment|>  // Supplicant Authentication Failure reason codes: /** * The reason code if there was a timeout authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_TIMEOUT = 1; // Supplicant Authentication Failure reason codes: /** * The reason code if there was a wrong password while * authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_WRONG_PSWD = 2; <|startfocus|> // Supplicant Authentication Failure reason codes: <|endfocus|> /** * The reason code if there was EAP failure while * authenticating. * @hide */ public static final int ERROR_AUTH_FAILURE_EAP_FAILURE = 3; /** * Broadcast intent action indicating whether Wi-Fi scanning is allowed currently * @hide */ public static final String WIFI_SCAN_AVAILABLE = "wifi_scan_available"; /** * Extra int indicating scan availability, WIFI_STATE_ENABLED and WIFI_STATE_DISABLED * @hide */ public static final String EXTRA_SCAN_AVAILABLE = "scan_enabled"; /**
<|startcomment|> As soon as there are more type of NetworkSpecifier, this will require a downcast to known types, or some kind of virtual dispatch. Similarly the createFromParcel will need some kind of switch. <|endcomment|>  (mLinkUpBandwidthKbps * 11) + (mLinkDownBandwidthKbps * 13) + Objects.hashCode(mNetworkSpecifier) * 17 + (mSignalStrength * 19)); } @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel dest, int flags) { dest.writeLong(mNetworkCapabilities); dest.writeLong(mTransportTypes); dest.writeInt(mLinkUpBandwidthKbps); dest.writeInt(mLinkDownBandwidthKbps); <|startfocus|> dest.writeParcelable((Parcelable) mNetworkSpecifier, 0); <|endfocus|> dest.writeInt(mSignalStrength); } public static final Creator<NetworkCapabilities> CREATOR = new Creator<NetworkCapabilities>() { @Override public NetworkCapabilities createFromParcel(Parcel in) { NetworkCapabilities netCap = new NetworkCapabilities(); netCap.mNetworkCapabilities = in.readLong(); netCap.mTransportTypes = in.readLong(); netCap.mLinkUpBandwidthKbps = in.readInt(); netCap.mLinkDownBandwidthKbps = in.readInt(); netCap.mNetworkSpecifier = in.readParcelable(null); netCap.mSignalStrength = in.readInt(); return netCap; } @Override
<|startcomment|> should not. As discussed it is possible to extend that class. To make it much harder to extend this by app, add a package private ctor. Apps won't be able to extend it outside of android.net, but because the class loaders are different, the things apps try to define will compile but will fail loading at run time. <|endcomment|>  * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net; /** * Describes specific properties of a network for use in a {@link NetworkRequest}. * * Applications cannot instantiate this class by themselves, but can obtain instances of this <|startfocus|> * class via other APIs. <|endfocus|> */ public abstract class NetworkSpecifier { /** * Returns true if a request with this {@link NetworkSpecifier} is satisfied by a network * with the given NetworkSpecifier. */ public abstract boolean satisfiedBy(NetworkSpecifier other); } 
<|startcomment|> Is this the correct order of precedence? <|endcomment|>  // STATE_DIALING, put it on hold before answering the call. if (foregroundCall != null && foregroundCall != call && (foregroundCall.isActive() || foregroundCall.getState() == CallState.DIALING || foregroundCall.getState() == CallState.PULLING)) { if (!foregroundCall.getTargetPhoneAccount().equals( call.getTargetPhoneAccount()) && <|startfocus|> (call.isSelfManaged() != foregroundCall.isSelfManaged() || <|endfocus|> call.isSelfManaged())) { // The foreground call is from another connection service, and either: // 1. FG call's managed state doesn't match that of the incoming call. // E.g. Incoming is self-managed and FG is managed, or incoming is managed // and foreground is self-managed. // 2. The incoming call is self-managed. // E.g. The incoming call is Log.i(this, "Answering call from %s CS; disconnecting calls from %s CS.", foregroundCall.isSelfManaged() ? "selfMg" : "mg",
<|startcomment|> remove <|endcomment|>  @Mock private Call mVideoCall; @Mock private Call mRingingCall; private IncomingCallNotifier mIncomingCallNotifier; private NotificationManager mNotificationManager; public void setUp() throws Exception { super.setUp(); mContext = mComponentContextFixture.getTestDouble().getApplicationContext(); ApplicationInfo info = new ApplicationInfo(); info.targetSdkVersion = Build.VERSION_CODES.N_MR1; doReturn(info).when(mContext).getApplicationInfo(); doReturn(null).when(mContext).getTheme(); <|startfocus|> //mContext.getApplicationInfo().targetSdkVersion <|endfocus|> mNotificationManager = (NotificationManager) mContext.getSystemService( Context.NOTIFICATION_SERVICE); mIncomingCallNotifier = new IncomingCallNotifier(mContext); mIncomingCallNotifier.setCallsManagerProxy(mCallsManagerProxy); when(mAudioCall.getVideoState()).thenReturn(VideoProfile.STATE_AUDIO_ONLY); when(mAudioCall.getTargetPhoneAccountLabel()).thenReturn("Bar"); when(mVideoCall.getVideoState()).thenReturn(VideoProfile.STATE_BIDIRECTIONAL); when(mVideoCall.getTargetPhoneAccountLabel()).thenReturn("Bar"); when(mRingingCall.isSelfManaged()).thenReturn(true); when(mRingingCall.isIncoming()).thenReturn(true);
<|startcomment|> Maybe remove this one as well? <|endcomment|>  @Mock WifiTrafficPoller mWifiTrafficPoller; @Mock WifiStateMachine mWifiStateMachine; @Mock HandlerThread mHandlerThread; TestLooper mLooper; @Mock AsyncChannel mAsyncChannel; @Mock Resources mResources; @Mock FrameworkFacade mFrameworkFacade; @Mock WifiLockManager mLockManager; @Mock WifiMulticastLockManager mWifiMulticastLockManager; @Mock WifiLastResortWatchdog mWifiLastResortWatchdog; @Mock WifiBackupRestore mWifiBackupRestore; @Mock WifiMetrics mWifiMetrics; @Spy FakeWifiLog mLog; @Mock WifiPermissionsUtil mWifiPermissionsUtil; <|startfocus|> @Mock PropertyService mPropertyService; <|endfocus|> @Mock WifiSettingsStore mSettingsStore; @Mock ContentResolver mContentResolver; PowerManager mPowerManager; private class WifiAsyncChannelTester { private static final String TAG = "WifiAsyncChannelTester"; public static final int CHANNEL_STATE_FAILURE = -1; public static final int CHANNEL_STATE_DISCONNECTED = 0; public static final int CHANNEL_STATE_HALF_CONNECTED = 1; public static final int CHANNEL_STATE_FULLY_CONNECTED = 2; private int mState = CHANNEL_STATE_DISCONNECTED; private WifiAsyncChannel mChannel; private WifiLog mAsyncTestLog; 
<|startcomment|> 2017 <|endcomment|> <|startfocus|> * Copyright (C) 2016 The Android Open Source Project <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License */ package benchmarks.regression; import com.google.caliper.Param; public class StringReplaceAllBenchmark { // NOTE: These estimates of MOVEABLE / NON_MOVEABLE are based on a knowledge of // ART implementation details. They make a difference here because JNI calls related // to strings took different paths depending on whether the String in question was // moveable or not. enum StringLengths { EMPTY(""),
<|startcomment|> added <|endcomment|>  } /** * Creates a new advertising set. If operation succeed, device will start advertising. This * method returns immediately, the operation status is delivered through * {@code callback.onAdvertisingSetStarted()}. * <p> * @param parameters advertising set parameters. * @param advertiseData Advertisement data to be broadcasted. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength}. If the <|startfocus|> * advertisement is connectable, three bytes will be appended with flags. <|endfocus|> * @param scanResponse Scan response associated with the advertisement data. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength} * @param periodicData Periodic advertising data. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength} * @param timeoutMillis Advertising time limit. May not exceed 180000 * @param callback Callback for advertising set. * @param handler thread upon which the callbacks will be invoked. */ public void startAdvertisingSet(AdvertisingSetParameters parameters, AdvertiseData advertiseData, AdvertiseData scanResponse, PeriodicAdvertisingParameters periodicParameters,
<|startcomment|> for <|endcomment|>  } /** * Creates a new advertising set. If operation succeed, device will start advertising. This * method returns immediately, the operation status is delivered through * {@code callback.onAdvertisingSetStarted()}. * <p> * @param parameters advertising set parameters. * @param advertiseData Advertisement data to be broadcasted. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength}. If the <|startfocus|> * advertisement is connectable, three bytes will be appended with flags. <|endfocus|> * @param scanResponse Scan response associated with the advertisement data. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength} * @param periodicData Periodic advertising data. Size must not exceed * {@link BluetoothAdapter#getLeMaximumAdvertisingDataLength} * @param timeoutMillis Advertising time limit. May not exceed 180000 * @param callback Callback for advertising set. * @param handler thread upon which the callbacks will be invoked. */ public void startAdvertisingSet(AdvertisingSetParameters parameters, AdvertiseData advertiseData, AdvertiseData scanResponse, PeriodicAdvertisingParameters periodicParameters,
<|startcomment|> { <|endcomment|>  * by the system. */ public static final String ACTION_SUBINFO_RECORD_UPDATED = "android.intent.action.ACTION_SUBINFO_RECORD_UPDATED"; /** * Broadcast Action: The default subscription has changed. This has the following * extra values:</p> * <ul> * <li><em>subscription</em> - A int, the current default subscription.</li> * </ul> <|startfocus|> * @deprecated Use (@link SubscriptionManager.ACTION_DEFAULT_SUBSCRIPTION_CHANGED} <|endfocus|> */ @Deprecated public static final String ACTION_DEFAULT_SUBSCRIPTION_CHANGED = SubscriptionManager.ACTION_DEFAULT_SUBSCRIPTION_CHANGED; /** * Broadcast Action: The default data subscription has changed. This has the following * extra values:</p> * <ul> * <li><em>subscription</em> - A int, the current data default subscription.</li> * </ul> */ public static final String ACTION_DEFAULT_DATA_SUBSCRIPTION_CHANGED = "android.intent.action.ACTION_DEFAULT_DATA_SUBSCRIPTION_CHANGED"; /** * Broadcast Action: The default voice subscription has changed. This has the following
<|startcomment|> { <|endcomment|>  * </ul> */ public static final String ACTION_DEFAULT_VOICE_SUBSCRIPTION_CHANGED = "android.intent.action.ACTION_DEFAULT_VOICE_SUBSCRIPTION_CHANGED"; /** * Broadcast Action: The default sms subscription has changed. This has the following * extra values:</p> * <ul> * <li><em>subscription</em> - A int, the current sms default subscription.</li> * </ul> <|startfocus|> * @deprecated Use (@link SubscriptionManager.ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED} <|endfocus|> */ @Deprecated public static final String ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED = SubscriptionManager.ACTION_DEFAULT_SMS_SUBSCRIPTION_CHANGED; /* * Broadcast Action: An attempt to set phone radio type and access technology has changed. * This has the following extra values: * <ul> * <li><em>phones radio access family </em> - A RadioAccessFamily * array, contain phone ID and new radio access family for each phone.</li> * </ul> * * <p class="note"> * Requires the READ_PHONE_STATE permission.
<|startcomment|> define a local variable for this and use here and below. <|endcomment|>  } public void testChangeFontScaleNoRelaunch() throws Exception { // Should receive onConfigurationChanged() and no relaunch testChangeFontScale(NO_RELAUNCH_ACTIVITY_NAME, false); } private void testRotation( String activityName, int rotationStep, int numRelaunch, int numConfigChange) throws Exception { executeShellCommand(getAmStartCmd(activityName)); final String[] waitForActivitiesVisible = new String[] {activityName}; mAmWmState.computeState(mDevice, waitForActivitiesVisible); <|startfocus|> setDeviceRotation(4 - rotationStep); <|endfocus|> mAmWmState.computeState(mDevice, waitForActivitiesVisible); final int actualStackId = mAmWmState.getAmState().getTaskByActivityName( activityName).mStackId; final int displayId = mAmWmState.getAmState().getStackById(actualStackId).mDisplayId; final int newDeviceRotation = getDeviceRotation(displayId); if (newDeviceRotation == INVALID_DEVICE_ROTATION) { CLog.logAndDisplay(LogLevel.WARN, "Got an invalid device rotation value. " + "Continuing the test despite of that, but it is likely to fail.");
<|startcomment|> Shouldn't this validation be in setNetworkSpecifier ? It is redundant with the Parcelable check, assuming all whitelisted subclasses are Parcelable. <|endcomment|>  Objects.hashCode(mNetworkSpecifier) * 17 + (mSignalStrength * 19)); } @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel dest, int flags) { dest.writeLong(mNetworkCapabilities); dest.writeLong(mTransportTypes); dest.writeInt(mLinkUpBandwidthKbps); dest.writeInt(mLinkDownBandwidthKbps); if (mNetworkSpecifier != null && !NetworkSpecifier.isWhitelistedNetworkSpecifier( mNetworkSpecifier)) { <|startfocus|> throw new IllegalStateException("Invalid network specifier"); <|endfocus|> } dest.writeParcelable((Parcelable) mNetworkSpecifier, flags); dest.writeInt(mSignalStrength); } public static final Creator<NetworkCapabilities> CREATOR = new Creator<NetworkCapabilities>() { @Override public NetworkCapabilities createFromParcel(Parcel in) { NetworkCapabilities netCap = new NetworkCapabilities(); netCap.mNetworkCapabilities = in.readLong(); netCap.mTransportTypes = in.readLong(); netCap.mLinkUpBandwidthKbps = in.readInt(); netCap.mLinkDownBandwidthKbps = in.readInt(); try { netCap.mNetworkSpecifier = in.readParcelable(null);
<|startcomment|> readParcelable() as a rhs to set mNetworkSpecifier which is of type NetworkSpecifier looks fishy. After checking readParcelable() has a parametric return type. i.e the Parcelable is cast to what needs to be on the lhs. This can also throws a ClassCastException. <|endcomment|>  new Creator<NetworkCapabilities>() { @Override public NetworkCapabilities createFromParcel(Parcel in) { NetworkCapabilities netCap = new NetworkCapabilities(); netCap.mNetworkCapabilities = in.readLong(); netCap.mTransportTypes = in.readLong(); netCap.mLinkUpBandwidthKbps = in.readInt(); netCap.mLinkDownBandwidthKbps = in.readInt(); try { netCap.mNetworkSpecifier = in.readParcelable(null); <|startfocus|> } catch (BadParcelableException e) { Log.e(TAG, "BadParcelableException: e=" + e); <|endfocus|> netCap.mNetworkSpecifier = null; } netCap.mSignalStrength = in.readInt(); return netCap; } @Override public NetworkCapabilities[] newArray(int size) { return new NetworkCapabilities[size]; } }; @Override public String toString() { int[] types = getTransportTypes(); String transports = (types.length > 0) ? " Transports: " + transportNamesOf(types) : ""; types = getCapabilities(); String capabilities = (types.length > 0 ? " Capabilities: " : "");
<|startcomment|> There is an existing method in this class, isImsConnection() which determines if this is an IMS connection. It looks based on the original connection's phone type; should be re-usable here. <|endcomment|>  */ @Override public void onPullExternalCall() { if ((getConnectionProperties() & Connection.PROPERTY_IS_EXTERNAL_CALL) != Connection.PROPERTY_IS_EXTERNAL_CALL) { Log.w(this, "onPullExternalCall - cannot pull non-external call"); return; } if (mOriginalConnection != null) { mOriginalConnection.pullExternalCall(); } } @Override public void onStartRtt(RttTextStream textStream) { <|startfocus|> Phone phone = getPhone(); if (phone instanceof ImsPhone) { ImsPhone imsPhone = (ImsPhone) phone; <|endfocus|> imsPhone.sendRttModifyRequest(textStream); } else { Log.w(this, "onStartRtt - not in IMS, so RTT cannot be enabled."); } } @Override public void onStopRtt() { // This is not supported by carriers/vendor yet. No-op for now. } @Override public void handleRttUpgradeResponse(RttTextStream textStream) { Phone phone = getPhone(); if (!(phone instanceof ImsPhone)) {
<|startcomment|> There is an existing method in this class, isImsConnection() which determines if this is an IMS connection. It looks based on the original connection's phone type; should be re-usable here. <|endcomment|>  if (phone instanceof ImsPhone) { ImsPhone imsPhone = (ImsPhone) phone; imsPhone.sendRttModifyRequest(textStream); } else { Log.w(this, "onStartRtt - not in IMS, so RTT cannot be enabled."); } } @Override public void onStopRtt() { // This is not supported by carriers/vendor yet. No-op for now. } @Override public void handleRttUpgradeResponse(RttTextStream textStream) { <|startfocus|> Phone phone = getPhone(); if (!(phone instanceof ImsPhone)) { <|endfocus|> Log.w(this, "handleRttUpgradeResponse - not in IMS, so RTT cannot be enabled."); return; } ImsPhone imsPhone = (ImsPhone) phone; imsPhone.sendRttModifyResponse(textStream); } public void performHold() { Log.v(this, "performHold"); // TODO: Can dialing calls be put on hold as well since they take up the // foreground call slot? if (Call.State.ACTIVE == mConnectionState) { Log.v(this, "Holding active call"); try {
<|startcomment|> 7 ? <|endcomment|> <|startfocus|> * Copyright (C) 2016 The Android Open Source Project <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net.wifi.aware; import android.net.NetworkSpecifier; import android.os.Parcel; import android.os.Parcelable; import java.util.Arrays; import java.util.Objects; /** * Network specifier object used to request a Wi-Fi Aware network. Apps do not create these objects * directly but obtain them using * {@link WifiAwareSession#createNetworkSpecifierOpen(int, byte[])} or
<|startcomment|> I suggest a more specific comment: MatchAllNetworkSpecifier taken care of in {@code xxx}. <|endcomment|>  public boolean satisfiedBy(NetworkSpecifier other) { <|startfocus|> return equals(other); // Match All is taken care of already <|endfocus|>
<|startcomment|> this seems like an API change, which is fine if intentional, just checking. <|endcomment|> <|startfocus|> public static List<TimeZone> getTimeZonesWithUniqueOffsets(String country) { <|endfocus|> synchronized(sLastUniqueLockObj) { if ((country != null) && country.equals(sLastUniqueCountry)) { if (DBG) { Log.d(TAG, "getTimeZonesWithUniqueOffsets(" + country + "): return cached version"); } return sLastUniqueZoneOffsets; } } Collection<TimeZone> zones = getTimeZones(country); ArrayList<TimeZone> uniqueTimeZones = new ArrayList<>(); for (TimeZone zone : zones) { // See if we already have this offset, // Using slow but space efficient and these are small. boolean found = false; for (int i = 0; i < uniqueTimeZones.size(); i++) { if (uniqueTimeZones.get(i).getRawOffset() == zone.getRawOffset()) { found = true; break; } } if (!found) { if (DBG) { Log.d(TAG, "getTimeZonesWithUniqueOffsets: add unique offset=" +
<|startcomment|> What about ON_RTT_REQUEST_RESPONSE and ON_STOP_RTT? <|endcomment|>  private static String getCounterLabel(int counterIndex) { switch (counterIndex) { case ON_POST_DIAL_WAIT: return "onPostDialWait"; case ON_CALL_EVENT: return "onCallEvent"; case ON_PULL_EXTERNAL_CALL: return "onPullExternalCall"; case ON_EXTRAS_CHANGED: return "onExtrasChanged"; case ON_START_RTT: <|startfocus|> return "onStartRtt"; <|endfocus|> default: return "Callback"; }
<|startcomment|> Who calls this? Does it need to be package-visible? <|endcomment|>  mKeepaliveCallback, mConfig.getLocalAddress(), mConfig.getEncapLocalPort(), mConfig.getRemoteAddress()); try { // FIXME: this is still a horrible way to fudge the synchronous callback mKeepaliveSyncLock.wait(2000); } catch (InterruptedException e) { } } if (mKeepaliveStatus != ConnectivityManager.PacketKeepalive.SUCCESS) { throw new UnsupportedOperationException("Packet Keepalive cannot be started"); } } /* Package */ <|startfocus|> void setResourceId(int resourceId) { mResourceId = resourceId; } /* Package */ <|endfocus|> int getResourceId() { return mResourceId; } /* Package */ void stopKeepalive() { if (mKeepalive == null) { return; } mKeepalive.stop(); synchronized (mKeepaliveSyncLock) { if (mKeepaliveStatus == ConnectivityManager.PacketKeepalive.SUCCESS) { try { mKeepaliveSyncLock.wait(2000); } catch (InterruptedException e) { } } } } /** * Builder object to facilitate the creation of IpSecTransform objects. *
<|startcomment|> Is this going to crash the system? If so, perhaps just log an error and continue instead of throwing. <|endcomment|>  protected void releaseResources() { try { getNetdInstance() .ipSecDeleteSecurityAssociation( mResourceId, mDirection, mLocalAddress, mRemoteAddress, mSpi); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { <|startfocus|> throw e.rethrowFromSystemServer(); <|endfocus|> }
<|startcomment|> Is this going to crash the system? if so, add a TODO to fix it. <|endcomment|>  INetd getNetdInstance() { final INetd netd = NetdService.getInstance(); if (netd == null) { <|startfocus|> throw new RemoteException("Failed to Get Netd Instance").rethrowFromSystemServer(); <|endfocus|> } return netd;
<|startcomment|> Long line. <|endcomment|>  } return netd; } boolean isNetdAlive() { synchronized (mLock) { final INetd netd = getNetdInstance(); if (netd == null) { return false; } try { return netd.isAlive(); } catch (RemoteException re) { return false; } } } @Override /** Get a new SPI and maintain the reservation in the system server */ public Bundle reserveSecurityParameterIndex( <|startfocus|> int direction, String remoteAddress, int requestedSpi, IBinder binder) throws RemoteException { <|endfocus|> int resourceId = mNextResourceId.getAndIncrement(); int spi = IpSecManager.INVALID_SECURITY_PARAMETER_INDEX; String localAddress = ""; Bundle retBundle = new Bundle(3); try { spi = getNetdInstance() .ipSecAllocateSpi( resourceId, direction, localAddress, remoteAddress, requestedSpi); Log.d(TAG, "Allocated SPI " + spi); retBundle.putInt(KEY_STATUS, IpSecManager.Status.OK); retBundle.putInt(KEY_RESOURCE_ID, resourceId); retBundle.putInt(KEY_SPI, spi);
<|startcomment|> Long line. <|endcomment|>  * Create a transport mode transform, which represent two security associations (one in each * direction) in the kernel. The transform will be cached by the system server and must be freed * when no longer needed. It is possible to free one, deleting the SA from underneath sockets * that are using it, which will result in all of those sockets becoming unable to send or * receive data. */ @Override <|startfocus|> public Bundle createTransportModeTransform(IpSecConfig c, IBinder binder) throws RemoteException { <|endfocus|> // TODO: Basic input validation here since it's coming over the Binder int resourceId = mNextResourceId.getAndIncrement(); for (int direction : DIRECTIONS) { IpSecAlgorithm auth = c.getAuthentication(direction); IpSecAlgorithm crypt = c.getEncryption(direction); try { int result = getNetdInstance() .ipSecAddSecurityAssociation( resourceId, c.getMode(), direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "",
<|startcomment|> Long line. <|endcomment|>  * system server. If this is called on an inactive (or non-existent) transform, it will not * return an error. It's safe to de-allocate transforms that may have already been deleted for * other reasons. */ @Override public void deleteTransportModeTransform(int resourceId) throws RemoteException { synchronized (mTransformRecords) { TransformRecord record; <|startfocus|> // We want to non-destructively get so that we can check credentials before removing this <|endfocus|> record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } // TODO: if releaseResources() throws RemoteException, we can try again to clean up on binder death. // Need to make sure that path is actually functional record.releaseResources(); mTransformRecords.remove(resourceId);
<|startcomment|> Use Binder.getCalling{Pid,Uid}() <|endcomment|>  */ @Override public void deleteTransportModeTransform(int resourceId) throws RemoteException { synchronized (mTransformRecords) { TransformRecord record; // We want to non-destructively get so that we can check credentials before removing this record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } <|startfocus|> if (record.pid != getCallingPid() || record.uid != getCallingUid()) { <|endfocus|> throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } // TODO: if releaseResources() throws RemoteException, we can try again to clean up on binder death. // Need to make sure that path is actually functional record.releaseResources(); mTransformRecords.remove(resourceId); record.nullifyRecord(); } } /** * Apply an active transport mode transform to a socket, which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override
<|startcomment|> Long line. <|endcomment|>  if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } <|startfocus|> // TODO: if releaseResources() throws RemoteException, we can try again to clean up on binder death. // Need to make sure that path is actually functional <|endfocus|> record.releaseResources(); mTransformRecords.remove(resourceId); record.nullifyRecord(); } } /** * Apply an active transport mode transform to a socket, which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override public void applyTransportModeTransform(ParcelFileDescriptor socket, int resourceId) throws RemoteException { synchronized (mTransformRecords) { TransformRecord info; // FIXME: this code should be factored out into a security check + getter info = mTransformRecords.get(resourceId); 
<|startcomment|> Long line. <|endcomment|>  // TODO: if releaseResources() throws RemoteException, we can try again to clean up on binder death. // Need to make sure that path is actually functional record.releaseResources(); mTransformRecords.remove(resourceId); record.nullifyRecord(); } } /** * Apply an active transport mode transform to a socket, which will apply the IPsec security * association as a correspondent policy to the provided socket */ @Override <|startfocus|> public void applyTransportModeTransform(ParcelFileDescriptor socket, int resourceId) throws RemoteException { <|endfocus|> synchronized (mTransformRecords) { TransformRecord info; // FIXME: this code should be factored out into a security check + getter info = mTransformRecords.get(resourceId); if (info == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not active"); } // TODO: make this a function. if (info.pid != getCallingPid() || info.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may apply it!"); } 
<|startcomment|> Long line. <|endcomment|>  } } } /** * Remove a transport mode transform from a socket, applying the default (empty) policy. This * will ensure that NO IPsec policy is applied to the socket (would be the equivalent of * applying a policy that performs no IPsec). Today the resourceId parameter is passed but not * used: reserved for future improved input validation. */ @Override <|startfocus|> public void removeTransportModeTransform(ParcelFileDescriptor socket, int resourceId) throws RemoteException { <|endfocus|> try { getNetdInstance().ipSecRemoveTransportModeTransform(socket.getFileDescriptor()); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } } @Override protected void dump(FileDescriptor fd, PrintWriter pw, String[] args) { mContext.enforceCallingOrSelfPermission(DUMP, TAG); pw.println("IpSecService Log:"); pw.println("NetdNativeService Connection: " + (isNetdAlive() ? "alive" : "dead")); pw.println(); } } 
<|startcomment|> Do you use it? I don't see any users in this file. If it's unused, delete it. <|endcomment|>  // and a remote IP address int spi; // Encryption Algorithm IpSecAlgorithm encryption; // Authentication Algorithm IpSecAlgorithm authentication; } Flow[] flow = new Flow[] {new Flow(), new Flow()}; // For tunnel mode IPv4 UDP Encapsulation // IpSecTransform#ENCAP_ESP_*, such as ENCAP_ESP_OVER_UDP_IKE int encapType; int encapLocalPort; int encapRemotePort; <|startfocus|> // A bitmask of PROPERTY_* indicating which of the fields // of this class are valid. long properties; <|endfocus|> // An interval, in seconds between the NattKeepalive packets int nattKeepaliveInterval; // Transport or Tunnel public int getMode() { return mode; } public InetAddress getLocalAddress() { return localAddress; } public int getSpi(int direction) { return flow[direction].spi; } public InetAddress getRemoteAddress() { return remoteAddress; } public IpSecAlgorithm getEncryption(int direction) { return flow[direction].encryption; } public IpSecAlgorithm getAuthentication(int direction) {
<|startcomment|> You don't need to do this, since Java guarantees that ints are initialized to 0. I think you might still need an empty constructor though. <|endcomment|>  out.writeParcelable(flow[IpSecTransform.DIRECTION_OUT].encryption, flags); out.writeParcelable(flow[IpSecTransform.DIRECTION_OUT].authentication, flags); out.writeInt(encapType); out.writeInt(encapLocalPort); out.writeInt(encapRemotePort); } // Package Private: Used by the IpSecTransform.Builder; // there should be no public constructor for this object <|startfocus|> IpSecConfig() { flow[IpSecTransform.DIRECTION_IN].spi = 0; flow[IpSecTransform.DIRECTION_OUT].spi = 0; nattKeepaliveInterval = 0; //FIXME constant } <|endfocus|> private static InetAddress readInetAddressFromParcel(Parcel in) { String addrString = in.readString(); if (addrString == null) { return null; } try { return InetAddress.getByName(addrString); } catch (UnknownHostException e) { Log.wtf(TAG, "Invalid IpAddress " + addrString); return null; } } private IpSecConfig(Parcel in) { properties = in.readLong(); localAddress = readInetAddressFromParcel(in); remoteAddress = readInetAddressFromParcel(in);
<|startcomment|> Nit: you only seem to use this once, and you could make that callsite use Context.IPSEC_SERVICE instead. <|endcomment|>  * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net; <|startfocus|> import static android.content.Context.IPSEC_SERVICE; <|endfocus|> import android.annotation.IntDef; import android.annotation.NonNull; import android.annotation.SystemApi; import android.content.Context; import android.os.Binder; import android.os.Bundle; import android.os.IBinder; import android.os.RemoteException; import android.os.ServiceManager; import android.util.Log; import com.android.internal.util.Preconditions; import dalvik.system.CloseGuard; import java.io.IOException; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.net.InetAddress; /** * This class represents an IpSecTransform, which encapsulates both properties and state of IPsec. *
<|startcomment|> This duplicates IpSecManager.SecurityParameterIndex.KEY_STATUS. Consider moving that to IpSecManager and using it instead. <|endcomment|>  private IpSecTransform(Context context, IpSecConfig config) { mContext = context; mConfig = config; mResourceId = INVALID_RESOURCE_ID; } private IIpSecService getIpSecService() { IBinder b = ServiceManager.getService(IPSEC_SERVICE); if (b == null) { throw new RemoteException("Failed to connect to IpSecService") .rethrowAsRuntimeException(); } return IIpSecService.Stub.asInterface(b); } <|startfocus|> /** @hide */ public static final String KEY_STATUS = "status"; /** @hide */ public static final String KEY_RESOURCE_ID = "resourceId"; <|endfocus|> private void checkResultStatus(int status) throws IOException, IpSecManager.ResourceUnavailableException, IpSecManager.SpiUnavailableException { switch (status) { case IpSecManager.Status.OK: return; case IpSecManager.Status.RESOURCE_UNAVAILABLE: throw new IpSecManager.ResourceUnavailableException( "Failed to allocate a new IpSecTransform"); case IpSecManager.Status.SPI_UNAVAILABLE: Log.wtf(TAG, "Attempting to use an SPI that was somehow not reserved"); // Fall through default:
<|startcomment|> Ditto. <|endcomment|>  mConfig = config; mResourceId = INVALID_RESOURCE_ID; } private IIpSecService getIpSecService() { IBinder b = ServiceManager.getService(IPSEC_SERVICE); if (b == null) { throw new RemoteException("Failed to connect to IpSecService") .rethrowAsRuntimeException(); } return IIpSecService.Stub.asInterface(b); } /** @hide */ public static final String KEY_STATUS = "status"; /** @hide */ public static final String KEY_RESOURCE_ID = "resourceId"; <|startfocus|> private void checkResultStatus(int status) <|endfocus|> throws IOException, IpSecManager.ResourceUnavailableException, IpSecManager.SpiUnavailableException { switch (status) { case IpSecManager.Status.OK: return; case IpSecManager.Status.RESOURCE_UNAVAILABLE: throw new IpSecManager.ResourceUnavailableException( "Failed to allocate a new IpSecTransform"); case IpSecManager.Status.SPI_UNAVAILABLE: Log.wtf(TAG, "Attempting to use an SPI that was somehow not reserved"); // Fall through default: throw new IllegalStateException(
<|startcomment|> Maybe give this method a name that suggests that it will throw if there's an error? checkStatusOrThrow? <|endcomment|>  } private IIpSecService getIpSecService() { IBinder b = ServiceManager.getService(IPSEC_SERVICE); if (b == null) { throw new RemoteException("Failed to connect to IpSecService") .rethrowAsRuntimeException(); } return IIpSecService.Stub.asInterface(b); } /** @hide */ public static final String KEY_STATUS = "status"; /** @hide */ public static final String KEY_RESOURCE_ID = "resourceId"; <|startfocus|> private void checkResultStatus(int status) <|endfocus|> throws IOException, IpSecManager.ResourceUnavailableException, IpSecManager.SpiUnavailableException { switch (status) { case IpSecManager.Status.OK: return; case IpSecManager.Status.RESOURCE_UNAVAILABLE: throw new IpSecManager.ResourceUnavailableException( "Failed to allocate a new IpSecTransform"); case IpSecManager.Status.SPI_UNAVAILABLE: Log.wtf(TAG, "Attempting to use an SPI that was somehow not reserved"); // Fall through default: throw new IllegalStateException( "Failed to Create a Transform with status code " + status); } } private IpSecTransform activate()
<|startcomment|> I think this is a negative number. Is that OK? <|endcomment|>  private static final boolean DBG = Log.isLoggable(TAG, Log.DEBUG); private static final String NETD_SERVICE_NAME = "netd"; private static final int[] DIRECTIONS = new int[] {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}; /** Binder context for this service */ private final Context mContext; private Object mLock = new Object(); private static final int NETD_FETCH_TIMEOUT = 5000; //ms <|startfocus|> private AtomicInteger mNextTransformId = new AtomicInteger(0xFADED000); <|endfocus|> private abstract class ManagedResource implements IBinder.DeathRecipient { final int pid; final int uid; private IBinder mBinder; ManagedResource(IBinder binder) { super(); mBinder = binder; pid = getCallingPid(); uid = getCallingUid(); try { mBinder.linkToDeath(this, 0); } catch (RemoteException e) { binderDied(); } } /** * When this record is no longer needed for managing system resources this function should * unlink all references held by the record to allow efficient garbage collection. */
<|startcomment|> Since this is a static method, would suggest explicitly wording it as Binder.getCallingPid(). Same for getCallingUid. <|endcomment|>  /** Binder context for this service */ private final Context mContext; private Object mLock = new Object(); private static final int NETD_FETCH_TIMEOUT = 5000; //ms private AtomicInteger mNextTransformId = new AtomicInteger(0xFADED000); private abstract class ManagedResource implements IBinder.DeathRecipient { final int pid; final int uid; private IBinder mBinder; ManagedResource(IBinder binder) { super(); mBinder = binder; <|startfocus|> pid = getCallingPid(); uid = getCallingUid(); <|endfocus|> try { mBinder.linkToDeath(this, 0); } catch (RemoteException e) { binderDied(); } } /** * When this record is no longer needed for managing system resources this function should * unlink all references held by the record to allow efficient garbage collection. */ public final void release() { //Release all the underlying system resources first releaseResources(); if (mBinder != null) { mBinder.unlinkToDeath(this, 0); } mBinder = null; 
<|startcomment|> Use the class member DIRECTIONS instead? <|endcomment|>  protected void releaseResources() { <|startfocus|> for (int direction : new int[] {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}) { <|endfocus|> try { getNetdInstance() .ipSecDeleteSecurityAssociation( mResourceId, direction, (mConfig.getLocalAddress() != null) ? mConfig.getLocalAddress().getHostAddress() : "", (mConfig.getRemoteAddress() != null) ? mConfig.getRemoteAddress().getHostAddress() : "", mConfig.getSpi(direction)); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } }
<|startcomment|> If this code runs while netd is unavailable (e.g., if it crashed and is restarted), will it crash the system server? We should avoid that if possible. <|endcomment|>  mResourceId, direction, (mConfig.getLocalAddress() != null) ? mConfig.getLocalAddress().getHostAddress() : "", (mConfig.getRemoteAddress() != null) ? mConfig.getRemoteAddress().getHostAddress() : "", mConfig.getSpi(direction)); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { <|startfocus|> throw e.rethrowFromSystemServer(); <|endfocus|> } }
<|startcomment|> Nit: is this the correct status to use? Maybe add a TODO to get the actual error code from netd and do more detailed error reporting. <|endcomment|>  retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_RESOURCE_ID, resourceId); retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_SPI, spi); synchronized (mSpiRecords) { mSpiRecords.put( resourceId, new SpiRecord( resourceId, direction, localAddress, remoteAddress, spi, binder)); } } catch (ServiceSpecificException e) { <|startfocus|> retBundle.putInt( IpSecManager.SecurityParameterIndex.KEY_STATUS, IpSecManager.Status.SPI_UNAVAILABLE); retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_RESOURCE_ID, resourceId); retBundle.putInt(IpSecManager.SecurityParameterIndex.KEY_SPI, spi); <|endfocus|> } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } return retBundle;
<|startcomment|> Nit: long line <|endcomment|>  public void deleteTransportModeTransform(int resourceId) { synchronized (mTransformRecords) { TransformRecord record; <|startfocus|> // We want to non-destructively get so that we can check credentials before removing this <|endfocus|> record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } // remove from the DB because releasing might fail, but it won't ever succeed later mTransformRecords.remove(resourceId); record.releaseResources(); record.nullifyRecord(); }
<|startcomment|> Technically it could, if we try to release it when netd is crashing. Not sure how much we can do about that at this point though. <|endcomment|>  record = mTransformRecords.get(resourceId); if (record == null) { throw new IllegalArgumentException( "Transform " + resourceId + " is not available to be deleted"); } if (record.pid != getCallingPid() || record.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may delete it!"); } <|startfocus|> // remove from the DB because releasing might fail, but it won't ever succeed later mTransformRecords.remove(resourceId); <|endfocus|> record.releaseResources(); record.nullifyRecord(); }
<|startcomment|> Can you use DIRECTIONS instead? <|endcomment|>  info = mTransformRecords.get(resourceId); if (info == null) { throw new IllegalArgumentException("Transform " + resourceId + " is not active"); } if (info.pid != getCallingPid() || info.uid != getCallingUid()) { throw new SecurityException("Only the owner of an IpSec Transform may apply it!"); } IpSecConfig c = info.getConfig(); try { <|startfocus|> for (int direction : new int[] {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}) { <|endfocus|> getNetdInstance() .ipSecApplyTransportModeTransform( socket.getFileDescriptor(), resourceId, direction, (c.getLocalAddress() != null) ? c.getLocalAddress().getHostAddress() : "", (c.getRemoteAddress() != null) ? c.getRemoteAddress().getHostAddress() : "", c.getSpi(direction)); } } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception
<|startcomment|> Have not looked through the whole file, but BluetoothSocket is already very spammy as is. This seems like it has huge potential to be spam-overload. If you're only interested in the log below, maybe move it out of "if (DBG)" instead? <|endcomment|>  * <h3>Developer Guides</h3> * <p>For more information about using Bluetooth, read the * <a href="{@docRoot}guide/topics/connectivity/bluetooth.html">Bluetooth</a> developer guide.</p> * </div> * * {@see BluetoothServerSocket} * {@see java.io.InputStream} * {@see java.io.OutputStream} */ public final class BluetoothSocket implements Closeable { private static final String TAG = "BluetoothSocket"; <|startfocus|> private static final boolean DBG = true; <|endfocus|> private static final boolean VDBG = Log.isLoggable(TAG, Log.VERBOSE); /** @hide */ public static final int MAX_RFCOMM_CHANNEL = 30; /*package*/ static final int MAX_L2CAP_PACKAGE_SIZE = 0xFFFF; /** RFCOMM socket */ public static final int TYPE_RFCOMM = 1; /** SCO socket */ public static final int TYPE_SCO = 2; /** L2CAP socket */ public static final int TYPE_L2CAP = 3; /*package*/ static final int EBADFD = 77; /*package*/ static final int EADDRINUSE = 98; 
<|startcomment|> 7 <|endcomment|> <|startfocus|> * Copyright (C) 2015 The Android Open Source Project <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net.cts; import android.content.Context; import android.net.ConnectivityManager; import android.net.IpSecAlgorithm; import android.net.IpSecManager; import android.net.IpSecTransform; import android.net.Network; import android.test.AndroidTestCase; import java.io.IOException; import java.net.DatagramPacket; import java.net.DatagramSocket; import java.net.InetAddress; import java.net.UnknownHostException; 
<|startcomment|> extra blank line. <|endcomment|> <|startfocus|> public void testAllocSpi() { <|endfocus|> for (InetAddress addr : GOOGLE_DNS_LIST) { IpSecManager.SecurityParameterIndex randomSpi = null, droidSpi = null; try { randomSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_OUT, addr, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); assertTrue(randomSpi.getSpi() != IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); droidSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_IN, addr, DROID_SPI); assertTrue(droidSpi.getSpi() == DROID_SPI); } catch (IpSecManager.ResourceUnavailableException | IpSecManager.SpiUnavailableException ru) { assertTrue(false); } // This *should* throw an SpiUnavailableException try { mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_IN, addr, DROID_SPI); assertTrue(false); // we expect an exception in the above call } catch (IpSecManager.ResourceUnavailableException ru) { assertTrue(false); } catch (IpSecManager.SpiUnavailableException sp) { } randomSpi.close(); droidSpi.close(); }
<|startcomment|> use fail() with a meaningful error msg. Otherwise let the errors propagate and declare testAllocSpi to throws Exception ? <|endcomment|>  try { randomSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_OUT, addr, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); assertTrue(randomSpi.getSpi() != IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); droidSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_IN, addr, DROID_SPI); assertTrue(droidSpi.getSpi() == DROID_SPI); } catch (IpSecManager.ResourceUnavailableException | IpSecManager.SpiUnavailableException ru) { assertTrue(false); } <|startfocus|> // This *should* throw an SpiUnavailableException <|endfocus|> try { mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_IN, addr, DROID_SPI); assertTrue(false); // we expect an exception in the above call } catch (IpSecManager.ResourceUnavailableException ru) { assertTrue(false); } catch (IpSecManager.SpiUnavailableException sp) { } randomSpi.close(); droidSpi.close(); }
<|startcomment|> Consider removing try and letting the errors bubble up. <|endcomment|>  public void testCreateTransform() { try { <|startfocus|> InetAddress remote = InetAddress.getLoopbackAddress(); IpSecManager.SecurityParameterIndex outSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_OUT, remote, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); <|endfocus|> IpSecManager.SecurityParameterIndex inSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_IN, remote, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); IpSecTransform firstTransform = new IpSecTransform.Builder(mContext) .setSpi(IpSecTransform.DIRECTION_OUT, outSpi) .setEncryption( IpSecTransform.DIRECTION_OUT, new IpSecAlgorithm( IpSecAlgorithm.ALGO_CRYPT_AES_CBC, CRYPT_KEY)) .setAuthentication( IpSecTransform.DIRECTION_OUT, new IpSecAlgorithm( IpSecAlgorithm.ALGO_AUTH_HMAC_SHA256, AUTH_KEY, AUTH_KEY.length * 8)) .setSpi(IpSecTransform.DIRECTION_IN, inSpi) .setEncryption( IpSecTransform.DIRECTION_IN, new IpSecAlgorithm( IpSecAlgorithm.ALGO_CRYPT_AES_CBC, CRYPT_KEY)) .setAuthentication(
<|startcomment|> Shouldn't we return immediately here? I think the if-else cascade at the end of this method is a bit more complicated than necessary. <|endcomment|>  TimeZone biasMatch = null; for (int i = 0; i < candidates.size(); i++) { TimeZone match = candidates.get(i); if (!offsetMatchesAtTime(match, offsetSeconds, isDst, whenMillis)) { continue; } if (firstMatch == null) { firstMatch = match; if (bias == null) { // Terminate early if there is no bias. break; } } if (match.getID().equals(bias.getID())) { <|startfocus|> biasMatch = match; break; <|endfocus|> } } TimeZone toReturn; if (biasMatch != null) { toReturn = biasMatch; } else if (firstMatch != null) { toReturn = firstMatch; } else { return null; } return toReturn;
<|startcomment|> ? <|endcomment|> import java.nio.file.Path; import java.nio.file.SimpleFileVisitor; import java.nio.file.attribute.BasicFileAttributes; import java.util.Arrays; import java.util.HashMap; import java.util.HashSet; import java.util.List; import java.util.Map; import java.util.Set; import java.util.stream.Collectors; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertNull; import static org.junit.Assert.fail; public class TimeZoneFinderTest { <|startfocus|> private Path testDir;// 22nd July 2017, 13:14:15 (DST time in UK) <|endfocus|> private static final int HOUR_MILLIS = 60 * 60 * 1000; // Zones used in the tests. NEW_YORK_TZ and LONDON_TZ chosen because they never overlap but both // have DST. private static final TimeZone NEW_YORK_TZ = TimeZone.getTimeZone("America/New_York"); private static final TimeZone LONDON_TZ = TimeZone.getTimeZone("Europe/London"); // A zone that matches LONDON_TZ for WHEN_NO_DST. It does not have DST so differs for WHEN_DST.
<|startcomment|> shouldn't a well-formed but empty file be treated as an error? we'd fall back to an empty map anyway, but I'd expect that to be reported. Also, if the first file is well-formed but empty, shouldn't we fall back to the second file? Yes, I know this could be a slippery slope, because by the same argument a file with just a single argument is probably invalid ... <|endcomment|>  } @Test public void xmlParsing_emptyFile() throws Exception { checkThrowsParserException(""); } @Test public void xmlParsing_unexpectedRootElement() throws Exception { checkThrowsParserException("<foo></foo>\n"); } @Test public void xmlParsing_missingCountryZones() throws Exception { checkThrowsParserException("<timezones></timezones>\n"); } @Test public void xmlParsing_noCountriesOk() throws Exception { <|startfocus|> parse("<timezones>\n" <|endfocus|> + " <countryzones>\n" + " </countryzones>\n" + "</timezones>\n"); } @Test public void xmlParsing_unexpectedElementsIgnored() throws Exception { String unexpectedElement = "<unexpected-element>\n<a /></unexpected-element>\n"; TimeZoneFinder finder = parse("<timezones>\n" + " " + unexpectedElement + " <countryzones>\n" + " <country code=\"gb\">\n" + " <id>Europe/London</id>\n" + " </country>\n" + " </countryzones>\n" + "</timezones>\n");
<|startcomment|> maybe test that comments in various positions (including inside the <id> tag) are ignored. I think XmlPullParser does that for you, but a test would be nice. <|endcomment|>  checkThrowsParserException("<foo></foo>\n"); } @Test public void xmlParsing_missingCountryZones() throws Exception { checkThrowsParserException("<timezones></timezones>\n"); } @Test public void xmlParsing_noCountriesOk() throws Exception { parse("<timezones>\n" + " <countryzones>\n" + " </countryzones>\n" + "</timezones>\n"); } @Test public void xmlParsing_unexpectedElementsIgnored() throws Exception { String unexpectedElement = "<unexpected-element>\n<a /></unexpected-element>\n"; <|startfocus|> TimeZoneFinder finder = parse("<timezones>\n" <|endfocus|> + " " + unexpectedElement + " <countryzones>\n" + " <country code=\"gb\">\n" + " <id>Europe/London</id>\n" + " </country>\n" + " </countryzones>\n" + "</timezones>\n"); assertZonesEqual(zones("Europe/London"), finder.lookupTimeZonesByCountry("gb")); finder = parse("<timezones>\n" + " <countryzones>\n" + " " + unexpectedElement
<|startcomment|> shouldn't this be after the try/catch ? <|endcomment|>  mHandler.sendMessageDelayed(msg1, 1000); } } break; case MSG_INCOMING_CONNECTION_RETRY: if (mBatchs.size() == 0) { Log.i(TAG, "Start Obex Server"); createServerSession(mPendingConnection); mIncomingRetries = 0; mPendingConnection = null; } else { if (mIncomingRetries == 20) { Log.w(TAG, "Retried 20 seconds, reject connection"); <|startfocus|> if (mServerSocket != null) { mServerSocket.prepareForNewConnect(); } <|endfocus|> try { mPendingConnection.close(); } catch (IOException e) { Log.e(TAG, "close tranport error"); } mIncomingRetries = 0; mPendingConnection = null; } else { Log.i(TAG, "OPP busy! Retry after 1 second"); mIncomingRetries = mIncomingRetries + 1; Message msg2 = Message.obtain(mHandler); msg2.what = MSG_INCOMING_CONNECTION_RETRY; mHandler.sendMessageDelayed(msg2, 1000); } } break; }
<|startcomment|> DIRECTIONS <|endcomment|>  protected void releaseResources() { <|startfocus|> for (int direction : new int[] {IpSecTransform.DIRECTION_OUT, IpSecTransform.DIRECTION_IN}) { <|endfocus|> try { getNetdInstance() .ipSecDeleteSecurityAssociation( mResourceId, direction, (mConfig.getLocalAddress() != null) ? mConfig.getLocalAddress().getHostAddress() : "", (mConfig.getRemoteAddress() != null) ? mConfig.getRemoteAddress().getHostAddress() : "", mConfig.getSpi(direction)); } catch (ServiceSpecificException e) { // FIXME: get the error code and throw is at an IOException from Errno Exception } catch (RemoteException e) { throw e.rethrowFromSystemServer(); } }
<|startcomment|> For test methods it's usually easiest to just say "throws Exception" since any exception thrown will result in the test failing. <|endcomment|>  protected void setUp() throws Exception { super.setUp(); mCM = (ConnectivityManager) getContext().getSystemService(Context.CONNECTIVITY_SERVICE); mISM = (IpSecManager) getContext().getSystemService(Context.IPSEC_SERVICE); } /* * Allocate a random SPI * Allocate a specific SPI using previous randomly created SPI value * Realloc the same SPI that was specifically created (expect SpiUnavailable) * Close SPIs */ public void testAllocSpi() throws Exception { for (InetAddress addr : GOOGLE_DNS_LIST) { IpSecManager.SecurityParameterIndex randomSpi = null, droidSpi = null; <|startfocus|> randomSpi = mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_OUT, addr); assertTrue( "Failed to receive a valid SPI", randomSpi.getSpi() != IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); <|endfocus|> droidSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_IN, addr, DROID_SPI); assertTrue( "Failed to allocate specified SPI, " + DROID_SPI, droidSpi.getSpi() == DROID_SPI); try {
<|startcomment|> throws Exception <|endcomment|>  // This is a success case because we expect a dupe SPI to throw } randomSpi.close(); droidSpi.close(); } } /* * Alloc outbound SPI * Alloc inbound SPI * Create transport mode transform * open socket * apply transform to socket * send data on socket * release transform * send data (expect exception) */ public void testCreateTransform() throws Exception { InetAddress local = InetAddress.getLoopbackAddress(); IpSecManager.SecurityParameterIndex outSpi = <|startfocus|> mISM.reserveSecurityParameterIndex(IpSecTransform.DIRECTION_OUT, local); <|endfocus|> IpSecManager.SecurityParameterIndex inSpi = mISM.reserveSecurityParameterIndex( IpSecTransform.DIRECTION_IN, local, outSpi.getSpi()); IpSecTransform transform = new IpSecTransform.Builder(mContext) .setSpi(IpSecTransform.DIRECTION_OUT, outSpi) .setEncryption( IpSecTransform.DIRECTION_OUT, new IpSecAlgorithm(IpSecAlgorithm.CRYPT_AES_CBC, CRYPT_KEY)) .setAuthentication( IpSecTransform.DIRECTION_OUT, new IpSecAlgorithm( IpSecAlgorithm.AUTH_HMAC_SHA256,
<|startcomment|> I think the logic is too brittle. We should strip as many as these format characters as they are from the beginning and the end, and look at what remains. If the length of what remains is 1, return that. Otherwise, return the fallback. For example, with the current logic, if the input is "<LRM>#$", the result is '#', while we want it to be the fallback. <|endcomment|>  if (length == 1) { return symbol.charAt(0); } if (length > 1) { char first = symbol.charAt(0); char second = symbol.charAt(1); if (first == '\u200E' || first == '\u200F' || first == '\u061C') { return second; } if (length == 2 && (second == '\u200E' || second == '\u200F' || second == '\u061C')) { return first; } } <|startfocus|> <|endfocus|> return fallback;
<|startcomment|> Not sure if we need this exception since setting any non-Parcelable NetworkSpecifier will fail as soon as the app tries to use it. Perhaps it's good to keep this for developer convenience because it will complain when the specifier is set, not when it is used. However, that only works some of the time: if the passed-in specifier is Parcelable, it's still possible to for things to fail when the specifier is used (as opposed to when it is set) if the Parcelable is not a framework class because the system won't be able to unparcel it. Up to you whether you want to make one of the two cases more helpful (and keep this exception) or if you want to make the two cases consistent. <|endcomment|>  public NetworkCapabilities setNetworkSpecifier(NetworkSpecifier networkSpecifier) { if (networkSpecifier != null && Long.bitCount(mTransportTypes) != 1) { throw new IllegalStateException("Must have a single transport specified to use " + "setNetworkSpecifier"); } <|startfocus|> if (networkSpecifier != null && !(networkSpecifier instanceof Parcelable)) { throw new IllegalArgumentException("Network specifier must be parcelable"); } <|endfocus|> mNetworkSpecifier = networkSpecifier; return this;
<|startcomment|> This will crash apps that do "setNetworkSpecifier(null)", which I believe does not crash today. <|endcomment|>  * it should document their particulars. For example, Bluetooth may use some sort of * device id while WiFi could used ssid and/or bssid. Cellular may use carrier spn. * * @param networkSpecifier An {@code String} of opaque format used to specify the bearer * specific network specifier where the bearer has a choice of * networks. */ public Builder setNetworkSpecifier(String networkSpecifier) { <|startfocus|> return setNetworkSpecifier(new StringNetworkSpecifier(networkSpecifier)); <|endfocus|> } /** * Sets the optional bearer specific network specifier. * This has no meaning if a single transport is also not specified, so calling * this without a single transport set will generate an exception, as will * subsequently adding or removing transports after this is set. * </p> * * @param networkSpecifier A concrete, parcelable framework class that extends * NetworkSpecifier. * * @hide */ public Builder setNetworkSpecifier(NetworkSpecifier networkSpecifier) { if (networkSpecifier instanceof MatchAllNetworkSpecifier) {
<|startcomment|> I'm not sure what adding this method will do to apps that call "setNetworkSpecifier(null)". It's clear to me that an app that targets O can't do that: it must write setNetworkSpecifier((String) null) or setNetworkSpecifier((NetworkSpecifier) null), or get an error at compile time. But I'm not sure what will happen at runtime to an app that targeted a previous SDK version. Perhaps the binary already contains the fully-qualified name and everything is fine. I've asked the API council to clarify that. <|endcomment|>  } /** * Sets the optional bearer specific network specifier. * This has no meaning if a single transport is also not specified, so calling * this without a single transport set will generate an exception, as will * subsequently adding or removing transports after this is set. * </p> * * @param networkSpecifier A concrete, parcelable framework class that extends * NetworkSpecifier. * * @hide */ <|startfocus|> public Builder setNetworkSpecifier(NetworkSpecifier networkSpecifier) { <|endfocus|> if (networkSpecifier instanceof MatchAllNetworkSpecifier) { throw new IllegalArgumentException( "NetworkRequests must not use MatchAllNetworkSpecifier"); } mNetworkCapabilities.setNetworkSpecifier(networkSpecifier); return this; } /** * Sets the signal strength. This is a signed integer, with higher values indicating a * stronger signal. The exact units are bearer-dependent. For example, Wi-Fi uses the same * RSSI units reported by WifiManager. * <p> * Note that when used to register a network callback, this specifies the minimum acceptable
<|startcomment|> instances of subclasses of this class via other APIs. <|endcomment|>  * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net; /** * Describes specific properties of a network for use in a {@link NetworkRequest}. * <|startfocus|> * Applications cannot instantiate this class by themselves, but can obtain instances of this * class via other APIs. <|endfocus|> * * @hide */ public abstract class NetworkSpecifier { /** * Validate that the input NetworkSpecifier is one of the whitelisted types. * * @hide */ public static boolean isWhitelistedNetworkSpecifier(NetworkSpecifier ns) { return ns instanceof MatchAllNetworkSpecifier || ns instanceof StringNetworkSpecifier; } /** * @hide */ public NetworkSpecifier() {} /** * Returns true if a request with this {@link NetworkSpecifier} is satisfied by a network * with the given NetworkSpecifier. * * @hide */
<|startcomment|> I'm not a fan of having to enumerate all possible classes here. If the user passes in a non-framework Parcelable class we'll already throw an exception because the framework won't know how to unparcel it. Is that enough? <|endcomment|>  /** * Describes specific properties of a network for use in a {@link NetworkRequest}. * * Applications cannot instantiate this class by themselves, but can obtain instances of this * class via other APIs. * * @hide */ public abstract class NetworkSpecifier { /** * Validate that the input NetworkSpecifier is one of the whitelisted types. * * @hide */ <|startfocus|> public static boolean isWhitelistedNetworkSpecifier(NetworkSpecifier ns) { return ns instanceof MatchAllNetworkSpecifier || ns instanceof StringNetworkSpecifier; } /** * @hide */ <|endfocus|> public NetworkSpecifier() {} /** * Returns true if a request with this {@link NetworkSpecifier} is satisfied by a network * with the given NetworkSpecifier. * * @hide */ public abstract boolean satisfiedBy(NetworkSpecifier other); } 
<|startcomment|> What is the advantage of using this |obtainMessageAndSend| over |sendMessage|. We would have been able to mock event |mWifiController.sendMessage| <|endcomment|>  || wiFiEnabledState == WifiManager.WIFI_STATE_DISABLED) { if (startConsentUi(packageName, Binder.getCallingUid(), WifiManager.ACTION_REQUEST_ENABLE)) { return true; } } } else if (wiFiEnabledState == WifiManager.WIFI_STATE_ENABLING || wiFiEnabledState == WifiManager.WIFI_STATE_ENABLED) { if (startConsentUi(packageName, Binder.getCallingUid(), WifiManager.ACTION_REQUEST_DISABLE)) { return true; } } } <|startfocus|> mWifiController.obtainMessageAndSend(CMD_WIFI_TOGGLED); <|endfocus|> return true; } /** * see {@link WifiManager#getWifiState()} * @return One of {@link WifiManager#WIFI_STATE_DISABLED}, * {@link WifiManager#WIFI_STATE_DISABLING}, * {@link WifiManager#WIFI_STATE_ENABLED}, * {@link WifiManager#WIFI_STATE_ENABLING}, * {@link WifiManager#WIFI_STATE_UNKNOWN} */ @Override public int getWifiEnabledState() { enforceAccessPermission(); mLog.trace("getWifiEnabledState uid=%").c(Binder.getCallingUid()).flush();
<|startcomment|> Why the re-factoring? Does this include an update to a newer upstream version too? Can we do that separately please? I'm less concerned about changes to Android-changed sections but I think I'd still prefer to separate them out. <|endcomment|>  * the grouping separator, and so on) needed by <code>DecimalFormat</code> * to format numbers. <code>DecimalFormat</code> creates for itself an instance of * <code>DecimalFormatSymbols</code> from its locale data. If you need to change any * of these symbols, you can get the <code>DecimalFormatSymbols</code> object from * your <code>DecimalFormat</code> and modify it. * <|startfocus|> * @author Mark Davis * @author Alan Liu * @see java.util.Locale * @see DecimalFormat <|endfocus|> */ public class DecimalFormatSymbols implements Cloneable, Serializable { // Android-changed: Removed reference to DecimalFormatSymbolsProvider but suggested // getInstance() be used instead in case Android supports it in future. /** * Create a DecimalFormatSymbols object for the default * {@link java.util.Locale.Category#FORMAT FORMAT} locale. * It is recommended that the {@link #getInstance(Locale) getInstance} method is used * instead. * <p>This is equivalent to calling * {@link #DecimalFormatSymbols(Locale)
<|startcomment|> Do we want to print out the exception? <|endcomment|>  public void testBluetoothDirWrite() { try { File file = new File("/data/misc/bluetooth/test.file"); assertTrue("File not created", file.createNewFile()); file.delete(); <|startfocus|> } catch (Exception e) { fail("Exception creating file /data/misc/bluetooth/test.file"); <|endfocus|> }
<|startcomment|> bad <|endcomment|>  assertEquals( TimeZoneDistroInstaller.INSTALL_SUCCESS, installer.stageInstallWithErrorCode(stagedDistro.getBytes())); assertInstallDistroStaged(stagedDistro); TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder(NEWER_RULES_VERSION, 1) .setTzLookupXml(null) .buildUnvalidated(); assertEquals( TimeZoneDistroInstaller.INSTALL_FAIL_BAD_DISTRO_STRUCTURE, installer.stageInstallWithErrorCode(incompleteDistro.getBytes())); assertInstallDistroStaged(stagedDistro); assertNoInstalledDistro(); } <|startfocus|> /** Tests that a distro with a missing tzlookup file will not update the content. */ <|endfocus|> public void testStageInstallWithErrorCode_badTzLookupFile() throws Exception { TimeZoneDistro stagedDistro = createValidTimeZoneDistro(NEW_RULES_VERSION, 1); assertEquals( TimeZoneDistroInstaller.INSTALL_SUCCESS, installer.stageInstallWithErrorCode(stagedDistro.getBytes())); assertInstallDistroStaged(stagedDistro); TimeZoneDistro incompleteDistro = createValidTimeZoneDistroBuilder(NEWER_RULES_VERSION, 1) .setTzLookupXml("<foo />") .buildUnvalidated(); assertEquals( TimeZoneDistroInstaller.INSTALL_FAIL_VALIDATION_ERROR, installer.stageInstallWithErrorCode(incompleteDistro.getBytes())); assertInstallDistroStaged(stagedDistro);
<|startcomment|> returned <|endcomment|>  /** * Attempts to strip RTL, LTR and Arabic letter markers from {@code symbol}. * If the string contains a single non-marker character (and any number of marker characters), * then that character is returned, otherwise {@code fallback} is returned. * <|startfocus|> * As an implementation detail {@code fallback} is also return when {@code symbol} contains * U+0000, which is tolerated, as that would indicate a considerable problem with the input. * <|endfocus|> * @hide */ // VisibleForTesting public static char maybeStripMarkers(String symbol, char fallback) { final int length = symbol.length(); if (length == 1) { char c = symbol.charAt(0); if (c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000') { return c; } } else if (length > 1) { char nonMarker = 0; for (char c : symbol.toCharArray()) {
<|startcomment|> is tolerated? Or should it be *not* tolerated? Can we just removed the ", which is tolerated,"? <|endcomment|>  /** * Attempts to strip RTL, LTR and Arabic letter markers from {@code symbol}. * If the string contains a single non-marker character (and any number of marker characters), * then that character is returned, otherwise {@code fallback} is returned. * <|startfocus|> * As an implementation detail {@code fallback} is also return when {@code symbol} contains * U+0000, which is tolerated, as that would indicate a considerable problem with the input. * <|endfocus|> * @hide */ // VisibleForTesting public static char maybeStripMarkers(String symbol, char fallback) { final int length = symbol.length(); if (length == 1) { char c = symbol.charAt(0); if (c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000') { return c; } } else if (length > 1) { char nonMarker = 0; for (char c : symbol.toCharArray()) {
<|startcomment|> FYI - toCharArray() allocates a new array. charAt() doesn't and may even have an intrinsic. I'm not overly worried about performance, but don't think it would hurt readability to switch. <|endcomment|>  public static char maybeStripMarkers(String symbol, char fallback) { final int length = symbol.length(); if (length == 1) { char c = symbol.charAt(0); if (c != '\u200E' && c != '\u200F' && c != '\u061C' && c != '\u0000') { return c; } } else if (length > 1) { char nonMarker = 0; <|startfocus|> for (char c : symbol.toCharArray()) { <|endfocus|> if (c == '\u200E' || c == '\u200F' || c == '\u061C') { continue; } if (nonMarker != 0 || c == '\u0000') { // more than one non-marker character or U+0000 in the input string. return fallback; } nonMarker = c; } if (nonMarker != 0) { return nonMarker; } } return fallback;
<|startcomment|> nit: this could be made final too. <|endcomment|>  public static char maybeStripMarkers(String symbol, char fallback) { final int length = symbol.length(); if (length >= 1) { boolean sawNonMarker = false; char nonMarker = 0; for (int i = 0; i < length; i++) { <|startfocus|> char c = symbol.charAt(i); <|endfocus|> if (c == '\u200E' || c == '\u200F' || c == '\u061C') { continue; } if (sawNonMarker) { // More than one non-marker character. return fallback; } sawNonMarker = true; nonMarker = c; } if (sawNonMarker) { return nonMarker; } } return fallback;
<|startcomment|> Nit: if you're OK with the strings being uppercase I think you don't need all this, you can just do: public enum Mode { IDLE, TETHERING, LOCAL_ONLY_HOTSPOT }; <|endcomment|>  private final StateMachine mTetherMasterSM; private final OffloadController mOffloadController; private final UpstreamNetworkMonitor mUpstreamNetworkMonitor; private volatile TetheringConfiguration mConfig; private String mCurrentUpstreamIface; private Notification.Builder mTetheredNotificationBuilder; private int mLastNotificationId; public enum Mode { IDLE("idle"), TETHERING("tethering"), LOCAL_HOTSPOT("local_only_hotspot"); public final String description; Mode(String description) { this.description = description; } } private boolean mRndisEnabled; // track the RNDIS function enabled state private boolean mUsbTetherRequested; // true if USB tethering should be started <|startfocus|> // when RNDIS is enabled <|endfocus|> // True iff WiFi tethering should be started when soft AP is ready. private boolean mWifiTetherRequested; public Tethering(Context context, INetworkManagementService nmService, INetworkStatsService statsService, INetworkPolicyManager policyManager, Looper looper, MockableSystemProperties systemProperties) { mContext = context; mNMService = nmService; mStatsService = statsService; mPolicyManager = policyManager; mLooper = looper; mSystemProperties = systemProperties; 
<|startcomment|> Nit: do you need this cast? <|endcomment|>  return ConnectivityManager.TETHER_ERROR_UNKNOWN_IFACE; } // Ignore the error status of the interface. If the interface is available, // the errors are referring to past tethering attempts anyway. if (tetherState.lastState != IControlsTethering.STATE_AVAILABLE) { Log.e(TAG, "Tried to Tether an unavailable iface: " + iface + ", ignoring"); return ConnectivityManager.TETHER_ERROR_UNAVAIL_IFACE; } <|startfocus|> tetherState.stateMachine.sendMessage( TetherInterfaceStateMachine.CMD_TETHER_REQUESTED, (Object) mode); <|endfocus|> return ConnectivityManager.TETHER_ERROR_NO_ERROR; }
<|startcomment|> Nit: if you're happy with uppercase labels, I think this will work too: public enum Mode { IDLE, TETHERING, LOCAL_HOTSPOT; } toString should work as documented in https://docs.oracle.com/javase/7/docs/api/java/lang/Enum.html#toString() <|endcomment|>  private final StateMachine mTetherMasterSM; private final OffloadController mOffloadController; private final UpstreamNetworkMonitor mUpstreamNetworkMonitor; private volatile TetheringConfiguration mConfig; private String mCurrentUpstreamIface; private Notification.Builder mTetheredNotificationBuilder; private int mLastNotificationId; public enum Mode { IDLE("idle"), TETHERING("tethering"), LOCAL_HOTSPOT("local_only_hotspot"); public final String description; Mode(String description) { this.description = description; } } private boolean mRndisEnabled; // track the RNDIS function enabled state private boolean mUsbTetherRequested; // true if USB tethering should be started <|startfocus|> // when RNDIS is enabled <|endfocus|> // True iff WiFi tethering should be started when soft AP is ready. private boolean mWifiTetherRequested; public Tethering(Context context, INetworkManagementService nmService, INetworkStatsService statsService, INetworkPolicyManager policyManager, Looper looper, MockableSystemProperties systemProperties) { mContext = context; mNMService = nmService; mStatsService = statsService; mPolicyManager = policyManager; mLooper = looper; mSystemProperties = systemProperties; 
<|startcomment|> Note here that this only supports /48s. Also consider making it explicit by making this modulo the size of the prefix. Or add a TODO. <|endcomment|>  public void addActiveDownstream(TetherInterfaceStateMachine downstream) { if (findDownstream(downstream) == null) { // Adding a new downstream appends it to the list. Adding a // downstream a second time without first removing it has no effect. <|startfocus|> if (mActiveDownstreams.offer(new Downstream(downstream, mNextSubnetId))) { mNextSubnetId = (short) Math.max(0, mNextSubnetId + 1); // always positive } <|endfocus|> updateIPv6TetheringInterfaces(); }
<|startcomment|> Will this fit on one line? <|endcomment|>  // Make a local copy, so we can modify it. final RaParams deprecated = new RaParams(deprecatedParams); // Remove any ULA DNS servers. removeULAs(deprecated.dnses); // Process newly deprecated information. mDeprecatedInfoTracker.putPrefixes(deprecated.prefixes); mDeprecatedInfoTracker.putDnses(deprecated.dnses); } // Make a local copy, so we can modify it. final RaParams params = (newParams != null) ? new RaParams(newParams) : null; if (params != null) { // Remove any ULA DNS servers. removeULAs(params.dnses); // Process information that is no longer deprecated. <|startfocus|> mDeprecatedInfoTracker.removePrefixes(params.prefixes); mDeprecatedInfoTracker.removeDnses(params.dnses); <|endfocus|> } mRaParams = params; assembleRaLocked(); } maybeNotifyMulticastTransmitter();
<|startcomment|> workingLocalOnlyHotspot? <|endcomment|>  when(mResources.getStringArray( com.android.internal.R.array.config_mobile_hotspot_provision_app)) .thenReturn(new String[] {"malformedApp"}); assertTrue(!mTethering.isTetherProvisioningRequired()); } private void sendWifiApStateChanged(int state) { final Intent intent = new Intent(WifiManager.WIFI_AP_STATE_CHANGED_ACTION); intent.putExtra(WifiManager.EXTRA_WIFI_AP_STATE, state); mServiceContext.sendStickyBroadcastAsUser(intent, UserHandle.ALL); } @Test <|startfocus|> public void workingWifiHotspot() throws Exception { <|endfocus|> when(mConnectivityManager.isTetheringSupported()).thenReturn(true); when(mWifiManager.setWifiApEnabled(any(WifiConfiguration.class), anyBoolean())) .thenReturn(true); // Emulate externally-visible WifiManager effects, causing the // per-interface state machine starts up, and telling us that hotspot // mode is to be started. mTethering.interfaceStatusChanged(mTestIfname, true); sendWifiApStateChanged(WifiManager.WIFI_AP_STATE_ENABLED); mLooper.dispatchAll(); verify(mNMService, times(1)).listInterfaces(); verify(mNMService, times(1)).getInterfaceConfig(mTestIfname);
<|startcomment|> to start <|endcomment|>  intent.putExtra(WifiManager.EXTRA_WIFI_AP_STATE, state); mServiceContext.sendStickyBroadcastAsUser(intent, UserHandle.ALL); } @Test public void workingWifiHotspot() throws Exception { when(mConnectivityManager.isTetheringSupported()).thenReturn(true); when(mWifiManager.setWifiApEnabled(any(WifiConfiguration.class), anyBoolean())) .thenReturn(true); // Emulate externally-visible WifiManager effects, causing the <|startfocus|> // per-interface state machine starts up, and telling us that hotspot // mode is to be started. <|endfocus|> mTethering.interfaceStatusChanged(mTestIfname, true); sendWifiApStateChanged(WifiManager.WIFI_AP_STATE_ENABLED); mLooper.dispatchAll(); verify(mNMService, times(1)).listInterfaces(); verify(mNMService, times(1)).getInterfaceConfig(mTestIfname); verify(mNMService, times(1)) .setInterfaceConfig(eq(mTestIfname), any(InterfaceConfiguration.class)); verify(mNMService, times(1)).tetherInterface(mTestIfname); verify(mNMService, times(1)).setIpForwardingEnabled(true); verify(mNMService, times(1)).startTethering(any(String[].class)); verifyNoMoreInteractions(mNMService);
<|startcomment|> Nit: nc.mNetworkSpecifier? <|endcomment|>  private void combineSpecifiers(NetworkCapabilities nc) { <|startfocus|> if (mNetworkSpecifier != null && !mNetworkSpecifier.equals(nc.getNetworkSpecifier())) { <|endfocus|> throw new IllegalStateException("Can't combine two networkSpecifiers"); } setNetworkSpecifier(nc.getNetworkSpecifier());
<|startcomment|> Nit: nc.mNetworkSpecifier? <|endcomment|>  private void combineSpecifiers(NetworkCapabilities nc) { if (mNetworkSpecifier != null && !mNetworkSpecifier.equals(nc.getNetworkSpecifier())) { throw new IllegalStateException("Can't combine two networkSpecifiers"); } <|startfocus|> setNetworkSpecifier(nc.getNetworkSpecifier()); <|endfocus|>
<|startcomment|> I think you need to guard against MatchAllNetworkSpecifier here. Maybe factor the check to a new checkValidNetworkSpecifier() function, and call it here and elsewhere? Alternatively, you might be able to put the check into the NetworkRequestInfo constructor(s), assuming it doesn't change any semantics or significantly complicate error handling code. <|endcomment|>  public NetworkRequest pendingRequestForNetwork(NetworkCapabilities networkCapabilities, PendingIntent operation) { checkNotNull(operation, "PendingIntent cannot be null."); networkCapabilities = new NetworkCapabilities(networkCapabilities); enforceNetworkRequestPermissions(networkCapabilities); enforceMeteredApnPolicy(networkCapabilities); ensureRequestableCapabilities(networkCapabilities); <|startfocus|> <|endfocus|> NetworkRequest networkRequest = new NetworkRequest(networkCapabilities, TYPE_NONE, nextNetworkRequestId(), NetworkRequest.Type.REQUEST); NetworkRequestInfo nri = new NetworkRequestInfo(networkRequest, operation); if (DBG) log("pendingRequest for " + nri); mHandler.sendMessage(mHandler.obtainMessage(EVENT_REGISTER_NETWORK_REQUEST_WITH_INTENT, nri)); return networkRequest;
<|startcomment|> Ditto. <|endcomment|>  NetworkCapabilities nc = new NetworkCapabilities(networkCapabilities); if (!ConnectivityManager.checkChangePermission(mContext)) { // Apps without the CHANGE_NETWORK_STATE permission can't use background networks, so // make all their listens include NET_CAPABILITY_FOREGROUND. That way, they will get // onLost and onAvailable callbacks when networks move in and out of the background. // There is no need to do this for requests because an app without CHANGE_NETWORK_STATE // can't request networks. nc.addCapability(NET_CAPABILITY_FOREGROUND); } <|startfocus|> <|endfocus|> NetworkRequest networkRequest = new NetworkRequest(nc, TYPE_NONE, nextNetworkRequestId(), NetworkRequest.Type.LISTEN); NetworkRequestInfo nri = new NetworkRequestInfo(messenger, networkRequest, binder); if (VDBG) log("listenForNetwork for " + nri); mHandler.sendMessage(mHandler.obtainMessage(EVENT_REGISTER_NETWORK_LISTENER, nri)); return networkRequest;
<|startcomment|> Ditto. <|endcomment|>  public void pendingListenForNetwork(NetworkCapabilities networkCapabilities, PendingIntent operation) { checkNotNull(operation, "PendingIntent cannot be null."); if (!hasWifiNetworkListenPermission(networkCapabilities)) { enforceAccessPermission(); } <|startfocus|> <|endfocus|> NetworkRequest networkRequest = new NetworkRequest( new NetworkCapabilities(networkCapabilities), TYPE_NONE, nextNetworkRequestId(), NetworkRequest.Type.LISTEN); NetworkRequestInfo nri = new NetworkRequestInfo(networkRequest, operation); if (VDBG) log("pendingListenForNetwork for " + nri); mHandler.sendMessage(mHandler.obtainMessage(EVENT_REGISTER_NETWORK_LISTENER, nri));
<|startcomment|> Now that setNetworkSpecifier(String) is just a wrapper, can you make this test method take a NetworkSpecifier instead of a String? That is what real NetworkAgents will do. <|endcomment|> <|startfocus|> public void setNetworkSpecifier(String specifier) { if (TextUtils.isEmpty(specifier)) { mNetworkCapabilities.setNetworkSpecifier(null); } else { mNetworkCapabilities.setNetworkSpecifier(new StringNetworkSpecifier(specifier)); } <|endfocus|> mNetworkAgent.sendNetworkCapabilities(mNetworkCapabilities);
<|startcomment|> Can you use a StringNetworkSpecifier for this one, so you can test both the string setter (with "foo") and the NetworkSpecifier setter (here)? <|endcomment|>  public void testNetworkSpecifier() { NetworkRequest rEmpty1 = newWifiRequestBuilder().build(); NetworkRequest rEmpty2 = newWifiRequestBuilder().setNetworkSpecifier((String) null).build(); NetworkRequest rEmpty3 = newWifiRequestBuilder().setNetworkSpecifier("").build(); NetworkRequest rEmpty4 = newWifiRequestBuilder().setNetworkSpecifier( (NetworkSpecifier) null).build(); NetworkRequest rFoo = newWifiRequestBuilder().setNetworkSpecifier("foo").build(); <|startfocus|> NetworkRequest rBar = newWifiRequestBuilder().setNetworkSpecifier("bar").build(); <|endfocus|> TestNetworkCallback cEmpty1 = new TestNetworkCallback(); TestNetworkCallback cEmpty2 = new TestNetworkCallback(); TestNetworkCallback cEmpty3 = new TestNetworkCallback(); TestNetworkCallback cEmpty4 = new TestNetworkCallback(); TestNetworkCallback cFoo = new TestNetworkCallback(); TestNetworkCallback cBar = new TestNetworkCallback(); TestNetworkCallback[] emptyCallbacks = new TestNetworkCallback[] { cEmpty1, cEmpty2, cEmpty3 }; mCm.registerNetworkCallback(rEmpty1, cEmpty1); mCm.registerNetworkCallback(rEmpty2, cEmpty2); mCm.registerNetworkCallback(rEmpty3, cEmpty3);
<|startcomment|> Use StringNetworkSpecifier. <|endcomment|>  mCm.registerNetworkCallback(rEmpty3, cEmpty3); mCm.registerNetworkCallback(rEmpty4, cEmpty4); mCm.registerNetworkCallback(rFoo, cFoo); mCm.registerNetworkCallback(rBar, cBar); mWiFiNetworkAgent = new MockNetworkAgent(TRANSPORT_WIFI); mWiFiNetworkAgent.connect(false); cEmpty1.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty2.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty3.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty4.expectAvailableCallbacks(mWiFiNetworkAgent); assertNoCallbacks(cFoo, cBar); <|startfocus|> mWiFiNetworkAgent.setNetworkSpecifier("foo"); <|endfocus|> cFoo.expectAvailableCallbacks(mWiFiNetworkAgent); for (TestNetworkCallback c: emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); } cFoo.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); cFoo.assertNoCallback(); mWiFiNetworkAgent.setNetworkSpecifier("bar"); cFoo.expectCallback(CallbackState.LOST, mWiFiNetworkAgent); cBar.expectAvailableCallbacks(mWiFiNetworkAgent); for (TestNetworkCallback c: emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); }
<|startcomment|> Use StringNetworkSpecifier. <|endcomment|>  cEmpty2.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty3.expectAvailableCallbacks(mWiFiNetworkAgent); cEmpty4.expectAvailableCallbacks(mWiFiNetworkAgent); assertNoCallbacks(cFoo, cBar); mWiFiNetworkAgent.setNetworkSpecifier("foo"); cFoo.expectAvailableCallbacks(mWiFiNetworkAgent); for (TestNetworkCallback c: emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); } cFoo.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); cFoo.assertNoCallback(); <|startfocus|> mWiFiNetworkAgent.setNetworkSpecifier("bar"); <|endfocus|> cFoo.expectCallback(CallbackState.LOST, mWiFiNetworkAgent); cBar.expectAvailableCallbacks(mWiFiNetworkAgent); for (TestNetworkCallback c: emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); } cBar.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); cBar.assertNoCallback(); mWiFiNetworkAgent.setNetworkSpecifier(null); cBar.expectCallback(CallbackState.LOST, mWiFiNetworkAgent); for (TestNetworkCallback c: emptyCallbacks) { c.expectCallback(CallbackState.NETWORK_CAPABILITIES, mWiFiNetworkAgent); } assertNoCallbacks(cEmpty1, cEmpty2, cEmpty3, cFoo, cBar);
<|startcomment|> What is this code testing exactly? That build() throws? That writeToParcel throws? It seems that here we should be testing that both non-Parcelable and non-framework Parcelable specifiers fail when used. <|endcomment|>  }; class ParcelableSpecifier extends NonParcelableSpecifier implements Parcelable { @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel p, int flags) {} } NetworkRequest.Builder builder; builder = new NetworkRequest.Builder().addTransportType(TRANSPORT_ETHERNET); try { builder.setNetworkSpecifier(new NonParcelableSpecifier()); Parcel parcelW = Parcel.obtain(); builder.build().writeToParcel(parcelW, 0); <|startfocus|> fail("Non-parcelable specifier did not throw exception"); <|endfocus|> } catch (Exception e) { // expected }
<|startcomment|> please catch the NumberFormatException and use INVALID. yeah, I know you didn't introduce this, but while we're here. <|endcomment|>  private int phoneIdForRequest(NetworkRequest netRequest) { NetworkSpecifier specifier = netRequest.networkCapabilities.getNetworkSpecifier(); int subId; if (specifier == null) { subId = mDefaultDataSubscription; } else if (specifier instanceof StringNetworkSpecifier) { <|startfocus|> subId = Integer.parseInt(((StringNetworkSpecifier) specifier).specifier); <|endfocus|> } else { subId = INVALID_SUBSCRIPTION_ID; } int phoneId = INVALID_PHONE_INDEX; if (subId == INVALID_SUBSCRIPTION_ID) return phoneId; for (int i = 0 ; i < mNumPhones; i++) { if (mPhoneSubscriptions[i] == subId) { phoneId = i; break; } } return phoneId;
<|startcomment|> ? <|endcomment|>  * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net; <|startfocus|> import android.net.wifi.aware.WifiAwareNetworkSpecifier; <|endfocus|> /** * Describes specific properties of a network for use in a {@link NetworkRequest}. * * Applications cannot instantiate this class by themselves, but can obtain instances of * subclasses of this class via other APIs. */ public abstract class NetworkSpecifier { public NetworkSpecifier() {} /** * Returns true if a request with this {@link NetworkSpecifier} is satisfied by a network * with the given NetworkSpecifier. * * @hide */ public abstract boolean satisfiedBy(NetworkSpecifier other); } 
<|startcomment|> Int <|endcomment|>  public void resize(int newSize) { <|startfocus|> int oldSize = mSize; mSize = newSize; ensureCapacity(mSize); if (newSize < oldSize) { Arrays.fill(mValues, newSize, oldSize, 0); <|endfocus|> }
<|startcomment|> I don't know why I'm confused, but I think these operands should be reversed, no? (and in the fill(...) below) <|endcomment|>  public void resize(int newSize) { int oldSize = mSize; mSize = newSize; ensureCapacity(mSize); if (newSize < oldSize) { Arrays.fill(mValues, newSize, oldSize, 0); <|startfocus|> } <|endfocus|>
<|startcomment|> reverse? <|endcomment|>  public void resize(int newSize) { // TODO throw on negative Size int oldSize = mSize; mSize = newSize; ensureCapacity(mSize); if (newSize < oldSize) { Arrays.fill(mValues, newSize, oldSize, 0); <|startfocus|> } <|endfocus|>
<|startcomment|> Same here: reverse? <|endcomment|>  public void resize(int newSize) { // TODO throw on negative Size int oldSize = mSize; mSize = newSize; ensureCapacity(mSize); if (newSize < oldSize) { Arrays.fill(mValues, newSize, oldSize, 0); <|startfocus|> } <|endfocus|>
<|startcomment|> I'm not a fan of making NetworkSpecifiers mutable. How about setting the UID inside WifiAwareNetworkSpecifier, and just enforcing it here? Something like something like: NetworkSpecifier ns = networkCapabilities.getNetworkSpecifier(); if (ns != null && ns.hasUid() && ns.getUid() != Binder.getCallingUid()) { throw new SecurityException(...); } and making the WifiAwareNetworkSpecifier constructor take a UID? (The manager can just get one the UID via Process.myUid()) In the base NetworkSpecifier class, hasUid() would just return false and getUid() would throw UnsupportedOperationException. <|endcomment|>  // changes network state. http://b/29964605 enforceMeteredApnPolicy(networkCapabilities); } ensureRequestableCapabilities(networkCapabilities); if (timeoutMs < 0) { throw new IllegalArgumentException("Bad timeout specified"); } if (networkCapabilities.getNetworkSpecifier() instanceof MatchAllNetworkSpecifier) { throw new IllegalArgumentException("NetworkRequest with MatchAllNetworkSpecifier"); } <|startfocus|> if (networkCapabilities.getNetworkSpecifier() instanceof NetworkSpecifier.UidConsumer) { ((NetworkSpecifier.UidConsumer) networkCapabilities.getNetworkSpecifier()) .setRequestorUid(Binder.getCallingUid()); } <|endfocus|> NetworkRequest networkRequest = new NetworkRequest(networkCapabilities, legacyType, nextNetworkRequestId(), type); NetworkRequestInfo nri = new NetworkRequestInfo(messenger, networkRequest, binder); if (DBG) log("requestNetwork for " + nri); mHandler.sendMessage(mHandler.obtainMessage(EVENT_REGISTER_NETWORK_REQUEST, nri)); if (timeoutMs > 0) { mHandler.sendMessageDelayed(mHandler.obtainMessage(EVENT_TIMEOUT_NETWORK_REQUEST, nri), timeoutMs); } return networkRequest;
<|startcomment|> 0x80000001 is also en interesting case. Maybe replace the -999? <|endcomment|>  public static void main(String[] args) { // Set up minint32, maxint32 and some others. int[] xi = new int[8]; xi[0] = 0x80000000; xi[1] = 0x7fffffff; <|startfocus|> xi[2] = -999; <|endfocus|> xi[3] = -13; xi[4] = -1; xi[5] = 0; xi[6] = 1; xi[7] = 999; doitInt(xi); expectEquals32(0x80000000, xi[0]); expectEquals32(0x7fffffff, xi[1]); expectEquals32(999, xi[2]); expectEquals32(13, xi[3]); expectEquals32(1, xi[4]); expectEquals32(0, xi[5]); expectEquals32(1, xi[6]); expectEquals32(999, xi[7]); // Set up minint64, maxint64 and some others. long[] xl = new long[8]; xl[0] = 0x8000000000000000L; xl[1] = 0x7fffffffffffffffL; xl[2] = -999; xl[3] = -13; xl[4] = -1; xl[5] = 0;
<|startcomment|> May want to rename. <|endcomment|>  try { provider.isSameFile(null, filesSetup.getDataFilePath()); fail(); } catch (NullPointerException expected) {} try { provider.isSameFile(filesSetup.getDataFilePath(), null); fail(); } catch (NullPointerException expected) {} } @Test public void test_getFileStore() throws IOException { try { provider.getFileStore(filesSetup.getDataFilePath()); fail(); } catch (SecurityException expected) { } } <|startfocus|> @Test public void test_getFileStore_NPE() throws IOException { <|endfocus|> try { provider.getFileStore(null); fail(); } catch(SecurityException expected) { } } @Test public void test_isHidden() throws IOException { assertFalse(provider.isHidden(filesSetup.getDataFilePath())); // Files can't be hidden using the "dos" view, which is unsupported since it relies // on a custom xattr, which may or may not be available on all FSs. // // Note that this weirdly asymmetric : setting the hidden attribute uses xattrs to
<|startcomment|> Request <|endcomment|>  } else { return false; } } @Rpc(description = "request a network") public String connectivityRequestNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } <|startfocus|> @Rpc(description = "request a Wi-Fi Aware network") <|endfocus|> public String connectivityRequestWifiAwareNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); if (networkRequest.networkCapabilities.getNetworkSpecifier() instanceof StringNetworkSpecifier) { String ns = ((StringNetworkSpecifier) networkRequest.networkCapabilities.getNetworkSpecifier()).specifier; JSONObject j = new JSONObject(ns); networkRequest.networkCapabilities.setNetworkSpecifier(WifiAwareManagerFacade.getNetworkSpecifier(j)); } mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId;
<|startcomment|> More than 80 chars. Move over to next line. <|endcomment|>  mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } @Rpc(description = "request a Wi-Fi Aware network") public String connectivityRequestWifiAwareNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); <|startfocus|> if (networkRequest.networkCapabilities.getNetworkSpecifier() instanceof StringNetworkSpecifier) { String ns = ((StringNetworkSpecifier) networkRequest.networkCapabilities.getNetworkSpecifier()).specifier; <|endfocus|> JSONObject j = new JSONObject(ns); networkRequest.networkCapabilities.setNetworkSpecifier(WifiAwareManagerFacade.getNetworkSpecifier(j)); } mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } @Rpc(description = "Stop listening for connectivity changes") public void connectivityStopTrackingConnectivityStateChange() { if (mTrackingConnectivityStateChange) { mTrackingConnectivityStateChange = false; mContext.unregisterReceiver(mConnectivityReceiver); } } 
<|startcomment|> Same as above. <|endcomment|>  String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } @Rpc(description = "request a Wi-Fi Aware network") public String connectivityRequestWifiAwareNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); if (networkRequest.networkCapabilities.getNetworkSpecifier() instanceof StringNetworkSpecifier) { String ns = ((StringNetworkSpecifier) networkRequest.networkCapabilities.getNetworkSpecifier()).specifier; JSONObject j = new JSONObject(ns); <|startfocus|> networkRequest.networkCapabilities.setNetworkSpecifier(WifiAwareManagerFacade.getNetworkSpecifier(j)); <|endfocus|> } mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } @Rpc(description = "Stop listening for connectivity changes") public void connectivityStopTrackingConnectivityStateChange() { if (mTrackingConnectivityStateChange) { mTrackingConnectivityStateChange = false; mContext.unregisterReceiver(mConnectivityReceiver); } } 
<|startcomment|> Same as above. <|endcomment|>  return key; } @Rpc(description = "request a Wi-Fi Aware network") public String connectivityRequestWifiAwareNetwork(@RpcParameter(name = "configJson") JSONObject configJson) throws JSONException { NetworkRequest networkRequest = buildNetworkRequestFromJson(configJson); if (networkRequest.networkCapabilities.getNetworkSpecifier() instanceof StringNetworkSpecifier) { String ns = ((StringNetworkSpecifier) networkRequest.networkCapabilities.getNetworkSpecifier()).specifier; JSONObject j = new JSONObject(ns); <|startfocus|> networkRequest.networkCapabilities.setNetworkSpecifier(WifiAwareManagerFacade.getNetworkSpecifier(j)); <|endfocus|> } mNetworkCallback = new NetworkCallback(NetworkCallback.EVENT_ALL); mManager.requestNetwork(networkRequest, mNetworkCallback); String key = mNetworkCallback.mId; mNetworkCallbackMap.put(key, mNetworkCallback); return key; } @Rpc(description = "Stop listening for connectivity changes") public void connectivityStopTrackingConnectivityStateChange() { if (mTrackingConnectivityStateChange) { mTrackingConnectivityStateChange = false; mContext.unregisterReceiver(mConnectivityReceiver); } } @Rpc(description = "Get the extra information about the network state provided by lower network layers.")
<|startcomment|> this should never happen, right? insert should happen only from telephony and subId should always be specified. Also, we need to make sure that only system can do an insert. We can use MODIFY_PHONE_STATE or some such permission for it. Can you check how to specify that insert requires a certain permission? <|endcomment|>  public Uri insert(Uri uri, ContentValues values) { if (uri.isPathPrefixMatch(CONTENT_URI)) { // Parse the subId int subId = 0; try { subId = Integer.parseInt(uri.getLastPathSegment()); } catch (NumberFormatException e) { <|startfocus|> Log.d(TAG, "no subId provided, using default."); subId = getDefaultSubId(); <|endfocus|> } Log.d(TAG, "subId=" + subId); // create the new service state ServiceState newSS = new ServiceState(); newSS.setVoiceRegState(values.getAsInteger(VOICE_REG_STATE)); newSS.setDataRegState(values.getAsInteger(DATA_REG_STATE)); newSS.setVoiceOperatorName(values.getAsString(VOICE_OPERATOR_ALPHA_LONG), values.getAsString(VOICE_OPERATOR_ALPHA_SHORT), values.getAsString(VOICE_OPERATOR_NUMERIC)); newSS.setDataOperatorName(values.getAsString(DATA_OPERATOR_ALPHA_LONG), values.getAsString(DATA_OPERATOR_ALPHA_SHORT), values.getAsString(DATA_OPERATOR_NUMERIC)); newSS.setIsManualSelection(values.getAsBoolean(IS_MANUAL_NETWORK_SELECTION));
<|startcomment|> might <|endcomment|>  private static byte getRandomNonZeroByte() { final byte random = (byte) (new Random()).nextInt(); <|startfocus|> // Don't pick the subnet-router anycast address, since that mind be // to the upstream already. <|endfocus|> return (random != 0) ? random : 0x1;
<|startcomment|> Ditto. <|endcomment|>  public boolean processMessage(Message message) { maybeLogMessage(this, message.what); boolean retValue = true; switch (message.what) { case CMD_TETHER_REQUESTED: <|startfocus|> final Mode mode; try { mode = (Mode) message.obj; } catch (ClassCastException e) { Log.e(TAG, "Invalid tethering interface mode given."); break; } <|endfocus|> Log.e(TAG, "CMD_TETHER_REQUESTED with mode " + mode + " when already operating in mode " + mMode); break; case CMD_TETHER_UNREQUESTED: transitionTo(mInitialState); if (DBG) Log.d(TAG, "Untethered (unrequested)" + mIfaceName); break; case CMD_INTERFACE_DOWN: transitionTo(mUnavailableState); if (DBG) Log.d(TAG, "Untethered (ifdown)" + mIfaceName); break; case CMD_TETHER_CONNECTION_CHANGED: if (mMode != Mode.TETHERING) { // Upstream changes are not of interest in our current mode. break; } String newUpstreamIfaceName = (String)(message.obj);
<|startcomment|> You could also add test for shrinking and zeroing behaviour: a.resize(2); assertEquals(0, backingArray[2]); assertEquals(0, backingArray[3]); <|endcomment|>  a.resize(15); a.set(14, 30); verify(new int[]{1, 2, 0, 0, 0, 20, 10, 0, 0, 0, 0, 0, 0, 0, 30}, a); int[] backingArray = new int[]{1, 2, 3, 4}; a = IntArray.wrap(backingArray); a.set(0, 10); assertEquals(10, backingArray[0]); backingArray[1] = 20; backingArray[2] = 30; verify(backingArray, a); assertEquals(2, a.indexOf(30)); <|startfocus|> <|endfocus|> a.add(50); verify(new int[]{10, 20, 30, 4, 50}, a);
<|startcomment|> Same shrinking and zeroing test? <|endcomment|>  a.resize(15); a.set(14, 30); verify(new long[]{1, 2, 0, 0, 0, 20, 10, 0, 0, 0, 0, 0, 0, 0, 30}, a); long[] backingArray = new long[]{1, 2, 3, 4}; a = LongArray.wrap(backingArray); a.set(0, 10); assertEquals(10, backingArray[0]); backingArray[1] = 20; backingArray[2] = 30; verify(backingArray, a); assertEquals(2, a.indexOf(30)); <|startfocus|> <|endfocus|> a.add(50); verify(new long[]{10, 20, 30, 4, 50}, a);
<|startcomment|> unlikely <|endcomment|>  * @throws ResourceUnavailableException indicating that too many SPIs are currently allocated * for this user * @throws SpiUnavailableException indicating that a particular SPI cannot be reserved */ public SecurityParameterIndex reserveSecurityParameterIndex( int direction, InetAddress remoteAddress) throws ResourceUnavailableException { try { return new SecurityParameterIndex( mService, direction, remoteAddress, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); <|startfocus|> } catch (SpiUnavailableException impossible) { /*because we choose the SPI, there will alwayse be one*/ return null; <|endfocus|> } } /** * Reserve an SPI for traffic bound towards the specified remote address. * * <p>If successful, this SPI is guaranteed available until released by a call to {@link * SecurityParameterIndex#close()}. * * @param direction {@link IpSecTransform#DIRECTION_IN} or {@link IpSecTransform#DIRECTION_OUT} * @param remoteAddress address of the remote. SPIs must be unique for each remoteAddress.
<|startcomment|> throw new ResourceUnavailableException("No free SPIs"); <|endcomment|>  * @throws ResourceUnavailableException indicating that too many SPIs are currently allocated * for this user * @throws SpiUnavailableException indicating that a particular SPI cannot be reserved */ public SecurityParameterIndex reserveSecurityParameterIndex( int direction, InetAddress remoteAddress) throws ResourceUnavailableException { try { return new SecurityParameterIndex( mService, direction, remoteAddress, IpSecManager.INVALID_SECURITY_PARAMETER_INDEX); <|startfocus|> } catch (SpiUnavailableException impossible) { /*because we choose the SPI, there will alwayse be one*/ return null; <|endfocus|> } } /** * Reserve an SPI for traffic bound towards the specified remote address. * * <p>If successful, this SPI is guaranteed available until released by a call to {@link * SecurityParameterIndex#close()}. * * @param direction {@link IpSecTransform#DIRECTION_IN} or {@link IpSecTransform#DIRECTION_OUT} * @param remoteAddress address of the remote. SPIs must be unique for each remoteAddress.
<|startcomment|> Maybe also add the explanation/rationale from the commit message here too? <|endcomment|>  } } if (hostName != null) { hostAddr = InetAddress.getByName(hostName); serverSocket = new ServerSocket(port, 0, hostAddr); } else { serverSocket = new ServerSocket(port); } // use as workaround for unspecified behaviour of isAnyLocalAddress() InetAddress iAddress = null; if (hostName != null) { iAddress = serverSocket.getInetAddress(); } else { <|startfocus|> iAddress = InetAddress.getLoopbackAddress(); <|endfocus|> } address = iAddress.getHostName() + ":" + serverSocket.getLocalPort(); return address; } /** * Stops listening for connection on current address. */ @Override public void stopListening() throws IOException { if (serverSocket != null) { serverSocket.close(); } } /** * Accepts transport connection for currently listened address and performs handshaking * for specified timeout. * * @param acceptTimeout timeout for accepting in milliseconds * @param handshakeTimeout timeout for handshaking in milliseconds */ @Override
<|startcomment|> do these need to be fields? It took me a bit to figure out that reduc() will update the vectors. Add a comment if they need to be fields. <|endcomment|>  expectEquals( 8070450532247928832L, geoLongMulLastValue(2147483647L)); expectEquals( 0L, geoLongMulLastValue(-2147483648L)); expectEquals( 8070450532247928832L, geoLongMulLastValue(9223372036854775807L)); expectEquals( 0L, geoLongMulLastValue(-9223372036854775808L)); float[] a = new float[16]; narrowingSubscript(a); for (int i = 0; i < 16; i++) { expectEquals(2.0f, a[i]); } <|startfocus|> xx = new int[2]; yy = new int[469]; reduc(); <|endfocus|> expectEquals(-469, xx[0]); expectEquals(-938, xx[1]); for (int i = 0; i < 469; i++) { expectEquals(2, yy[i]); } System.out.println("passed");
<|startcomment|> phone, not sub <|endcomment|>  mSentSinceLastRecv = 0; putRecoveryAction(RecoveryAction.GET_DATA_CALL_LIST); } else { if (VDBG_STALL) log("updateDataStallInfo: NONE"); } } private boolean isPhoneStateIdle() { for (int i = 0; i < TelephonyManager.getDefault().getPhoneCount(); i++ ) { Phone phone = PhoneFactory.getPhone(i); if (phone != null && phone.getState() != PhoneConstants.State.IDLE) { <|startfocus|> log("isPhoneStateIdle: Voice call active on sub: " + i); <|endfocus|> return false; } } return true; } private void onDataStallAlarm(int tag) { if (mDataStallAlarmTag != tag) { if (DBG) { log("onDataStallAlarm: ignore, tag=" + tag + " expecting " + mDataStallAlarmTag); } return; } updateDataStallInfo(); int hangWatchdogTrigger = Settings.Global.getInt(mResolver, Settings.Global.PDP_WATCHDOG_TRIGGER_PACKET_COUNT, NUMBER_SENT_PACKETS_OF_HANG); boolean suspectedStall = DATA_STALL_NOT_SUSPECTED;
<|startcomment|> Slog.wtf? <|endcomment|>  chosenIface = iface; break; } } } if (chosenIface == null) { Log.e(TAG, "could not find iface of type " + interfaceType); return; } final int result; switch (requestedState) { case IControlsTethering.STATE_UNAVAILABLE: case IControlsTethering.STATE_AVAILABLE: result = untether(chosenIface); break; case IControlsTethering.STATE_TETHERED: case IControlsTethering.STATE_LOCAL_HOTSPOT: result = tether(chosenIface, requestedState); break; default: <|startfocus|> result = -1; <|endfocus|> } if (result != ConnectivityManager.TETHER_ERROR_NO_ERROR) { Log.e(TAG, "unable start or stop tethering on iface " + chosenIface); return; }
<|startcomment|> It seems strange that when a downstream starts up, we immediately realize that an upstream is required, but we only wait until the CMD_TETHER_MODE_REQUESTED is processed to do other bookkeeping? Should mUpstreamWantingIfaces be updated while processing CMD_TETHER_MODE_[UN]REQUESTED instead of here? I don't think this is harmful since everything is on the same thread, but it seems like it might be easier to read. <|endcomment|>  // by sending CMD_CLEAR_ERROR if (error == ConnectivityManager.TETHER_ERROR_MASTER_ERROR) { mTetherMasterSM.sendMessage(TetherMasterSM.CMD_CLEAR_ERROR, who); } switch (state) { case IControlsTethering.STATE_UNAVAILABLE: case IControlsTethering.STATE_AVAILABLE: mUpstreamWantingIfaces.remove(iface); mTetherMasterSM.sendMessage(TetherMasterSM.CMD_TETHER_MODE_UNREQUESTED, who); break; case IControlsTethering.STATE_TETHERED: <|startfocus|> mUpstreamWantingIfaces.add(iface); mTetherMasterSM.sendMessage(TetherMasterSM.CMD_TETHER_MODE_REQUESTED, who); break; <|endfocus|> case IControlsTethering.STATE_LOCAL_HOTSPOT: mUpstreamWantingIfaces.remove(iface); mTetherMasterSM.sendMessage(TetherMasterSM.CMD_TETHER_MODE_REQUESTED, who); break; } sendTetherStateChangedBroadcast();
<|startcomment|> Optional: consider removing. <|endcomment|>  case CMD_START_TETHERING_ERROR: case CMD_STOP_TETHERING_ERROR: case CMD_SET_DNS_FORWARDERS_ERROR: mLastError = ConnectivityManager.TETHER_ERROR_MASTER_ERROR; transitionTo(mInitialState); break; default: return false; } return true; } } class LocalHotspotState extends State { @Override public void enter() { if (DBG) Log.d(TAG, "Local hotspot " + mIfaceName); setInterfaceState(IControlsTethering.STATE_LOCAL_HOTSPOT); } @Override <|startfocus|> public void exit() { } @Override <|endfocus|> public boolean processMessage(Message message) { maybeLogMessage(this, message.what); switch (message.what) { case CMD_TETHER_REQUESTED: Log.e(TAG, "CMD_TETHER_REQUESTED while in local hotspot mode."); break; case CMD_TETHER_CONNECTION_CHANGED: // Ignored in local hotspot state. break; default: return false; } return true; } } class TetheredState extends State { @Override public void enter() { if (DBG) Log.d(TAG, "Tethered " + mIfaceName);
<|startcomment|> Just occurred to me: any reason why this keeps track of interface names instead of TISMs? <|endcomment|>  private final Object mPublicSync; private final Context mContext; private final ArrayMap<String, TetherState> mTetherStates; private final BroadcastReceiver mStateReceiver; private final INetworkManagementService mNMService; private final INetworkStatsService mStatsService; private final INetworkPolicyManager mPolicyManager; private final Looper mLooper; private final MockableSystemProperties mSystemProperties; private final StateMachine mTetherMasterSM; private final OffloadController mOffloadController; private final UpstreamNetworkMonitor mUpstreamNetworkMonitor; <|startfocus|> private final HashSet<String> mIfacesWantingUpstream; <|endfocus|> private volatile TetheringConfiguration mConfig; private String mCurrentUpstreamIface; private Notification.Builder mTetheredNotificationBuilder; private int mLastNotificationId; private boolean mRndisEnabled; // track the RNDIS function enabled state private boolean mUsbTetherRequested; // true if USB tethering should be started // when RNDIS is enabled // True iff WiFi tethering should be started when soft AP is ready. private boolean mWifiTetherRequested; public Tethering(Context context, INetworkManagementService nmService, INetworkStatsService statsService, INetworkPolicyManager policyManager, Looper looper, MockableSystemProperties systemProperties) {
<|startcomment|> Consider Log.wtf since this is a programming error. <|endcomment|>  if (error == ConnectivityManager.TETHER_ERROR_MASTER_ERROR) { mTetherMasterSM.sendMessage(TetherMasterSM.CMD_CLEAR_ERROR, who); } int which; switch (state) { case IControlsTethering.STATE_UNAVAILABLE: case IControlsTethering.STATE_AVAILABLE: which = TetherMasterSM.EVENT_IFACE_SERVING_STATE_INACTIVE; break; case IControlsTethering.STATE_TETHERED: case IControlsTethering.STATE_LOCAL_HOTSPOT: which = TetherMasterSM.EVENT_IFACE_SERVING_STATE_ACTIVE; break; default: <|startfocus|> Log.e(TAG, "Unknown interface state: " + state); <|endfocus|> return; } mTetherMasterSM.sendMessage(which, state, 0, who); sendTetherStateChangedBroadcast();
<|startcomment|> Suggest using putString. This doesn't constrain other potential users to mapping to an int. <|endcomment|>  capabilities |= PhoneAccount.CAPABILITY_VIDEO_CALLING_RELIES_ON_PRESENCE; } if (mIsVideoCapable && isCarrierEmergencyVideoCallsAllowed()) { capabilities |= PhoneAccount.CAPABILITY_EMERGENCY_VIDEO_CALLING; } mIsVideoPauseSupported = isCarrierVideoPauseSupported(); Bundle phoneAccountExtras = new Bundle(); if (isCarrierInstantLetteringSupported()) { capabilities |= PhoneAccount.CAPABILITY_CALL_SUBJECT; phoneAccountExtras = getPhoneAccountExtras(phoneAccountExtras); } phoneAccountExtras.putInt(PhoneAccount.EXTRA_SORT_ORDER, slotId); <|startfocus|> mIsMergeCallSupported = isCarrierMergeCallSupported(); <|endfocus|> mIsVideoConferencingSupported = isCarrierVideoConferencingSupported(); mIsMergeOfWifiCallsAllowedWhenVoWifiOff = isCarrierMergeOfWifiCallsAllowedWhenVoWifiOff(); if (isEmergency && mContext.getResources().getBoolean( R.bool.config_emergency_account_emergency_calls_only)) { capabilities |= PhoneAccount.CAPABILITY_EMERGENCY_CALLS_ONLY; } if (icon == null) { // TODO: Switch to using Icon.createWithResource() once that supports tinting. Resources res = mContext.getResources(); Drawable drawable = res.getDrawable(DEFAULT_SIM_ICON, null);
<|startcomment|> Can this just be "com.android.rs.unit_test.UnitTest"? <|endcomment|>  for (Map.Entry<Class<? extends UnitTest>, Integer> entry : allUnitTests.entrySet()) { int testApiVersion = entry.getValue(); // Only add test if test API version is not greater than build API version. if (testApiVersion <= thisApiVersion) { validUnitTests.add(entry.getKey()); } } return validUnitTests; } @Parameter(0) <|startfocus|> public Class<? extends com.android.rs.unit_test.UnitTest> mTestClass; <|endfocus|> @Test @MediumTest public void testRSUnitTest() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); UnitTest test = mTestClass.getDeclaredConstructor(Context.class).newInstance(ctx); test.runTest(); Assert.assertTrue(test.getSuccess()); } } 
<|startcomment|> Nit: space between `for` and `(`. <|endcomment|>  private static void allocateReachableObjects(ArrayList<MockClass> reachableObjs) { <|startfocus|> for(int i = 0; i < reachableObjNum; i++) { <|endfocus|> reachableObjs.add(new MockClass(true)); }
<|startcomment|> Nit: indentation is off. <|endcomment|>  private static void allocateUnreachableObjects() { <|startfocus|> for(int i = 0; i < unreachableObjNum; i++) { <|endfocus|> new MockClass(false); }
<|startcomment|> Nit: space between `for` and `(`. <|endcomment|>  private static void allocateUnreachableObjects() { <|startfocus|> for(int i = 0; i < unreachableObjNum; i++) { <|endfocus|> new MockClass(false); }
<|startcomment|> perhaps this as well? <|endcomment|>  } if (!mBinaryTestProfilingLibraryPath.isEmpty()) { jsonObject.put(BINARY_TEST_PROFILING_LIBRARY_PATH, new JSONArray(mBinaryTestProfilingLibraryPath)); CLog.i("Added %s to the Json object", BINARY_TEST_PROFILING_LIBRARY_PATH); } <|startfocus|> if (mBinaryTestType.equals(BINARY_TEST_TYPE_HAL_HIDL_GTEST)) { CLog.i("Set flags to stop the framework and native servers for %s", BINARY_TEST_TYPE_HAL_HIDL_GTEST); mBinaryTestStopNativeServers = true; } <|endfocus|> if (mBinaryTestDisableFramework) { jsonObject.put(BINARY_TEST_DISABLE_FRAMEWORK, mBinaryTestDisableFramework); CLog.i("Added %s to the Json object", BINARY_TEST_DISABLE_FRAMEWORK); } if (mBinaryTestStopNativeServers) { jsonObject.put(BINARY_TEST_STOP_NATIVE_SERVERS, mBinaryTestStopNativeServers); CLog.i("Added %s to the Json object", BINARY_TEST_STOP_NATIVE_SERVERS); } if (!mHalHidlReplayTestTracePaths.isEmpty()) { jsonObject.put(HAL_HIDL_REPLAY_TEST_TRACE_PATHS, new JSONArray(mHalHidlReplayTestTracePaths));
<|startcomment|> Is this interface really needed ? What does it bring ? Since is it not on the base NetworkSpecifier class, the caller will always have to know the object is of type WifiAwareNetworkSpecifier to be able to see getUid() to see it anyway. <|endcomment|> import android.util.Log; import java.util.Arrays; import java.util.Objects; /** * Network specifier object used to request a Wi-Fi Aware network. Apps do not create these objects * directly but obtain them using * {@link WifiAwareSession#createNetworkSpecifierOpen(int, byte[])} or * {@link DiscoverySession#createNetworkSpecifierOpen(PeerHandle)} or their secure (Passphrase) * versions. * * @hide */ <|startfocus|> public final class WifiAwareNetworkSpecifier extends NetworkSpecifier implements Parcelable, NetworkSpecifier.UidContainer { <|endfocus|> /** * TYPE: in band, specific peer: role, client_id, session_id, peer_id, pmk/passphrase optional * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB = 0; /** * TYPE: in band, any peer: role, client_id, session_id, pmk/passphrase optional * [only permitted for RESPONDER] * @hide */ public static final int NETWORK_SPECIFIER_TYPE_IB_ANY_PEER = 1; /** * TYPE: out-of-band: role, client_id, peer_mac, pmk/passphrase optional
<|startcomment|> typo <|endcomment|>  mMediaInterface.folderItemsRsp(bdaddr, AvrcpConstants.RSP_INV_RANGE, null); return; } result_items = checkIndexOutofBounds(bdaddr, items, startItem, endItem); /* check for index out of bound errors */ if (result_items == null) { Log.w(TAG, "result_items is null."); mMediaInterface.folderItemsRsp(bdaddr, AvrcpConstants.RSP_INV_RANGE, null); return; } FolderItemsData folderDataNative = new FolderItemsData(result_items.size()); <|startfocus|> /* variables to temperorily add attrs */ <|endfocus|> ArrayList<String> attrArray = new ArrayList<String>(); ArrayList<Integer> attrId = new ArrayList<Integer>(); for (int itemIndex = 0; itemIndex < result_items.size(); itemIndex++) { // get the queue id long qid = result_items.get(itemIndex).getQueueId(); byte[] uid = ByteBuffer.allocate(AvrcpConstants.UID_SIZE).putLong(qid).array(); // get the array of uid from 2d to array 1D array for (int idx = 0; idx < AvrcpConstants.UID_SIZE; idx++) {
<|startcomment|> "attribute"? <|endcomment|>  String value = null; int attribId = isAllAttribRequested ? (idx + 1) : folderItemsReqObj.mAttrIDs[idx]; if (attribId >= AvrcpConstants.ATTRID_TITLE && attribId <= AvrcpConstants.ATTRID_PLAY_TIME) { value = getAttrValue(attribId, result_items, itemIndex); if (value != null) { attrArray.add(value); attrId.add(attribId); attrCnt++; } } else { <|startfocus|> Log.w(TAG, "invalid attributed id is requested: " + attribId); <|endfocus|> } } /* add num attr actually received from media player for a particular item */ folderDataNative.mAttributesNum[itemIndex] = attrCnt; } } /* copy filtered attr ids and attr values to response parameters */ if (folderItemsReqObj.mNumAttr != AvrcpConstants.NUM_ATTR_NONE) { folderDataNative.mAttrIds = new int[attrId.size()]; for (int attrIndex = 0; attrIndex < attrId.size(); attrIndex++) folderDataNative.mAttrIds[attrIndex] = attrId.get(attrIndex);
<|startcomment|> Is it relevant to log the error ? <|endcomment|>  if (oldLp != null && newLp.isIdenticalDnses(oldLp)) { return; // no updating necessary } Collection<InetAddress> dnses = newLp.getDnsServers(); if (DBG) log("Setting DNS servers for network " + netId + " to " + dnses); try { mNetd.setDnsConfigurationForNetwork( netId, NetworkUtils.makeStrings(dnses), newLp.getDomains()); } catch (Exception e) { loge("Exception in setDnsConfigurationForNetwork: " + e); <|startfocus|> } <|endfocus|> flushVmDnsCache();
<|startcomment|> So this implies there can be no commas within one of these test URLs. That seems fine, but I wonder if there's a separate way to have a String[] variable and push its contents such that there aren't delimiter issues. <|endcomment|>  /** * The URL used for fallback HTTP captive portal detection when previous HTTP * and HTTPS captive portal detection attemps did not return a conclusive answer. * * @hide */ public static final String CAPTIVE_PORTAL_FALLBACK_URL = "captive_portal_fallback_url"; /** <|startfocus|> * A comma-separated list of URLs used for captive portal detection in addition to the * fallback HTTP url associated with CAPTIVE_PORTAL_FALLBACK_URL. <|endfocus|> * * @hide */ public static final String CAPTIVE_PORTAL_OTHER_FALLBACK_URLS = "captive_portal_other_fallback_urls"; /** * Whether to use HTTPS for network validation. This is enabled by default and the setting * needs to be set to 0 to disable it. This setting is a misnomer because captive portals * don't actually use HTTPS, but it's consistent with the other settings. * * @hide */ public static final String CAPTIVE_PORTAL_USE_HTTPS = "captive_portal_use_https"; /**
<|startcomment|> Does it make sense to keep getCaptivePortalFallbackUrl() at this point? If anything I would expect getCaptivePortalFallbackUrl() to be implemented in terms of getCaptivePortalFallbackUrls() <|endcomment|>  private URL[] makeCaptivePortalFallbackUrls(Context context) { <|startfocus|> String firstUrl = getCaptivePortalFallbackUrl(context); <|endfocus|> String joinedUrls = firstUrl + "," + getSetting(context, Settings.Global.CAPTIVE_PORTAL_OTHER_FALLBACK_URLS, DEFAULT_OTHER_FALLBACK_URLS); List<URL> urls = new ArrayList<>(); for (String s : joinedUrls.split(",")) { URL u = makeURL(s); if (u == null) { continue; } urls.add(u); } if (urls.isEmpty()) { Log.e(TAG, String.format("could not create any url from %s", joinedUrls)); } return urls.toArray(new URL[urls.size()]);
<|startcomment|> nit: The removed paragraph actually used the spellings "ValueBased" (in the link target) and "value-based" (in the link text), so either of those two spellings would have been slightly preferable ("removed paragraph about value-based class semantics"). But this works too. <|endcomment|>  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA. * * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA * or visit www.oracle.com if you need additional information or have any * questions. */ package java.util; import java.util.function.Consumer; import java.util.function.Function; import java.util.function.Predicate; import java.util.function.Supplier; <|startfocus|> // Android-changed: removed Value-Based paragraph. <|endfocus|> /** * A container object which may or may not contain a non-null value. * If a value is present, {@code isPresent()} will return {@code true} and * {@code get()} will return the value. * * <p>Additional methods that depend on the presence or absence of a contained * value are provided, such as {@link #orElse(java.lang.Object) orElse()} * (return a default value if value not present) and * {@link #ifPresent(java.util.function.Consumer) ifPresent()} (execute a block
<|startcomment|> Missing space <|endcomment|>  * supported on this device. * * @param secondaryPhy Secondary advertising physical channel, can only be * one of {@link BluetoothDevice#PHY_LE_1M}, * {@link BluetoothDevice#PHY_LE_2M} or * {@link BluetoothDevice#PHY_LE_CODED}. * @throws IllegalArgumentException If the secondaryPhy is invalid. */ public Builder setSecondaryPhy(int secondaryPhy) { if (secondaryPhy != BluetoothDevice.PHY_LE_1M && <|startfocus|> secondaryPhy !=BluetoothDevice.PHY_LE_2M && <|endfocus|> secondaryPhy != BluetoothDevice.PHY_LE_CODED) { throw new IllegalArgumentException("bad secondaryPhy " + secondaryPhy); } this.secondaryPhy = secondaryPhy; return this; } /** * Set advertising interval. * * @param interval Bluetooth LE Advertising interval, in 0.625ms unit. Valid * range is from 160 (100ms) to 16777215 (10,485.759375 s). * Recommended values are: * {@link AdvertisingSetParameters#INTERVAL_LOW}, * {@link AdvertisingSetParameters#INTERVAL_MEDIUM}, or
<|startcomment|> should be BEGIN Android-changed / END Android-changed per go/libcore-patch-style <|endcomment|>  public String getDisplayName(boolean daylightTime, int style, Locale locale) { <|startfocus|> // Android-changed: implement using android.icu.text.TimeZoneNames <|endfocus|> TimeZoneNames.NameType nameType; switch (style) { case SHORT: nameType = daylightTime ? TimeZoneNames.NameType.SHORT_DAYLIGHT : TimeZoneNames.NameType.SHORT_STANDARD; break; case LONG: nameType = daylightTime ? TimeZoneNames.NameType.LONG_DAYLIGHT : TimeZoneNames.NameType.LONG_STANDARD; break; default: throw new IllegalArgumentException("Illegal style: " + style); } long now = System.currentTimeMillis(); String canonicalID = android.icu.util.TimeZone.getCanonicalID(getID()); if (canonicalID != null) { TimeZoneNames names = TimeZoneNames.getInstance(locale); String displayName = names.getDisplayName(canonicalID, nameType, now); if (displayName != null) { return displayName; } } // We get here if this is a custom timezone or ICU doesn't have name data for the specific // style and locale. int offsetMillis = getRawOffset();
<|startcomment|> nit: move this to after line 403? (No point in doing this in the case where canonicalID == 0) <|endcomment|>  // Android-changed: implement using android.icu.text.TimeZoneNames TimeZoneNames.NameType nameType; switch (style) { case SHORT: nameType = daylightTime ? TimeZoneNames.NameType.SHORT_DAYLIGHT : TimeZoneNames.NameType.SHORT_STANDARD; break; case LONG: nameType = daylightTime ? TimeZoneNames.NameType.LONG_DAYLIGHT : TimeZoneNames.NameType.LONG_STANDARD; break; default: throw new IllegalArgumentException("Illegal style: " + style); } <|startfocus|> long now = System.currentTimeMillis(); <|endfocus|> String canonicalID = android.icu.util.TimeZone.getCanonicalID(getID()); if (canonicalID != null) { TimeZoneNames names = TimeZoneNames.getInstance(locale); String displayName = names.getDisplayName(canonicalID, nameType, now); if (displayName != null) { return displayName; } } // We get here if this is a custom timezone or ICU doesn't have name data for the specific // style and locale. int offsetMillis = getRawOffset(); if (daylightTime) { offsetMillis += getDSTSavings(); }
<|startcomment|> IsRingerAudible? <|endcomment|>  boolean isRingerAudible = isVolumeOverZero && shouldRingForContact && isRingtonePresent; // Acquire audio focus under any of the following conditions: // 1. Should ring for contact and there's an HFP device attached // 2. Volume is over zero, we should ring for the contact, and there's a audible ringtone // present. boolean shouldAcquireAudioFocus = <|startfocus|> (isVolumeOverZero && shouldRingForContact && isRingtonePresent) || (isHfpDeviceAttached && shouldRingForContact); <|endfocus|> // Don't do call waiting operations or vibration unless these are false. boolean isTheaterModeOn = mSystemSettingsUtil.isTheaterModeOn(mContext); boolean letDialerHandleRinging = mInCallController.doesConnectedDialerSupportRinging(); boolean endEarly = isTheaterModeOn || letDialerHandleRinging; if (endEarly) { if (letDialerHandleRinging) { Log.addEvent(foregroundCall, LogUtils.Events.SKIP_RINGING); } return shouldAcquireAudioFocus;
<|startcomment|> Would it help for debugging to list isVolumeOverZero, shouldRingForContact, and isRingtonePresent? <|endcomment|>  Log.addEvent(foregroundCall, LogUtils.Events.START_RINGER); // Because we wait until a contact info query to complete before processing a // call (for the purposes of direct-to-voicemail), the information about custom // ringtones should be available by the time this code executes. We can safely // request the custom ringtone from the call and expect it to be current. mRingtonePlayer.play(mRingtoneFactory, foregroundCall); } else { <|startfocus|> Log.i(this, "startRinging: skipping because ringer would not be audible."); <|endfocus|> } if (shouldVibrate(mContext, foregroundCall) && !mIsVibrating && shouldRingForContact) { mVibratingCall = foregroundCall; mVibrator.vibrate(VIBRATION_PATTERN, VIBRATION_PATTERN_REPEAT, VIBRATION_ATTRIBUTES); mIsVibrating = true; } else if (mIsVibrating) { Log.addEvent(foregroundCall, LogUtils.Events.SKIP_VIBRATION, "already vibrating"); } return shouldAcquireAudioFocus;
<|startcomment|> This has a slightly funky name. It's more like mNextFallbackUrlSeed or something. I'm not good at naming. <|endcomment|>  private URL nextFallbackUrl() { if (mCaptivePortalFallbackUrls.length == 0) { return null; } <|startfocus|> int idx = Math.abs(mNextFallbackUrl) % mCaptivePortalFallbackUrls.length; mNextFallbackUrl += new Random().nextInt(); // randomely change url without memory. <|endfocus|> return mCaptivePortalFallbackUrls[idx];
<|startcomment|> Also put a fail() line after isInCall to make sure that it throws the exception <|endcomment|>  when(mFakeCallsManager.hasOngoingCalls()).thenReturn(true); assertTrue(mTSIBinder.isInCall(DEFAULT_DIALER_PACKAGE)); } @SmallTest public void testNotIsInCall() throws Exception { when(mFakeCallsManager.hasOngoingCalls()).thenReturn(false); assertFalse(mTSIBinder.isInCall(DEFAULT_DIALER_PACKAGE)); } @SmallTest public void testIsInCallFail() throws Exception { doThrow(new SecurityException()).when(mContext).enforceCallingOrSelfPermission( anyString(), any()); try { <|startfocus|> mTSIBinder.isInCall("blah"); <|endfocus|> } catch (SecurityException e) { // desired result } verify(mFakeCallsManager, never()).hasOngoingCalls(); } @SmallTest public void testIsInManagedCall() throws Exception { when(mFakeCallsManager.hasOngoingManagedCalls()).thenReturn(true); assertTrue(mTSIBinder.isInManagedCall(DEFAULT_DIALER_PACKAGE)); } @SmallTest public void testNotIsInManagedCall() throws Exception { when(mFakeCallsManager.hasOngoingManagedCalls()).thenReturn(false); assertFalse(mTSIBinder.isInManagedCall(DEFAULT_DIALER_PACKAGE)); } @SmallTest
<|startcomment|> Same as above <|endcomment|>  assertTrue(mTSIBinder.isInManagedCall(DEFAULT_DIALER_PACKAGE)); } @SmallTest public void testNotIsInManagedCall() throws Exception { when(mFakeCallsManager.hasOngoingManagedCalls()).thenReturn(false); assertFalse(mTSIBinder.isInManagedCall(DEFAULT_DIALER_PACKAGE)); } @SmallTest public void testIsInManagedCallFail() throws Exception { doThrow(new SecurityException()).when(mContext).enforceCallingOrSelfPermission( anyString(), any()); try { <|startfocus|> mTSIBinder.isInManagedCall("blah"); <|endfocus|> } catch (SecurityException e) { // desired result } verify(mFakeCallsManager, never()).hasOngoingCalls(); } /** * Register phone accounts for the supplied PhoneAccountHandles to make them * visible to all users (via the isVisibleToCaller method in TelecomServiceImpl. * @param handles the handles for which phone accounts should be created for. */ private void makeAccountsVisibleToAllUsers(PhoneAccountHandle... handles) { for (PhoneAccountHandle ph : handles) { when(mFakePhoneAccountRegistrar.getPhoneAccountUnchecked(eq(ph))).thenReturn(
<|startcomment|> How about the following (seems simpler / more readable): (actual == i) // IPV6_TCLASS || (actual == (i & ~INET_ECN_MASK)); // IP_TOS: ECN bits should be 0 Also, it'd be nice include a the expected / observed values in the failure message. <|endcomment|>  for (int i = 0; i <= 255; ++i) { s.setTrafficClass(i); // b/30909505 // Linux does not set ECN bits for IP_TOS, but sets for IPV6_TCLASS. We should // accept either output. int actual = s.getTrafficClass(); assertTrue(i == actual || // IPV6_TCLASS <|startfocus|> (((i & ~INET_ECN_MASK) == (actual & ~INET_ECN_MASK)) && ((actual & INET_ECN_MASK) == 0))); // IP_TOS <|endfocus|> } } } public void testReadAfterClose() throws Exception { MockServer server = new MockServer(); server.enqueue(new byte[]{5, 3}, 0); Socket socket = new Socket("localhost", server.port); InputStream in = socket.getInputStream(); assertEquals(5, in.read()); assertEquals(3, in.read()); assertEquals(-1, in.read()); assertEquals(-1, in.read()); socket.close(); in.close(); /* * Rather astonishingly, read() doesn't throw even though the stream is
<|startcomment|> how about: implement setOption() on top of setSocketOption() which is more informative when only extracting this comment without having the source code (I'm generating an overview of change descriptions of all of the changes we have). Perhaps you can also say *why* we have the different implementation? <|endcomment|>  } } } } private void connectToAddress(InetAddress address, int port, int timeout) throws IOException { if (address.isAnyLocalAddress()) { doConnect(InetAddress.getLocalHost(), port, timeout); } else { doConnect(address, port, timeout); } } public void setOption(int opt, Object val) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } <|startfocus|> // Android-removed: alternative implementation <|endfocus|> /* boolean on = true; switch (opt) { // check type safety b4 going native. These should never * fail, since only java.Socket* has access to * PlainSocketImpl.setOption(). // case SO_LINGER: if (val == null || (!(val instanceof Integer) && !(val instanceof Boolean))) throw new SocketException("Bad parameter for option"); if (val instanceof Boolean) { // true only if disabling - enabling should be Integer on = false; } break; case SO_TIMEOUT:
<|startcomment|> keep /* <|endcomment|>  if (address.isAnyLocalAddress()) { doConnect(InetAddress.getLocalHost(), port, timeout); } else { doConnect(address, port, timeout); } } public void setOption(int opt, Object val) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } // Android-removed: alternative implementation /* boolean on = true; switch (opt) { <|startfocus|> // check type safety b4 going native. These should never <|endfocus|> * fail, since only java.Socket* has access to * PlainSocketImpl.setOption(). // case SO_LINGER: if (val == null || (!(val instanceof Integer) && !(val instanceof Boolean))) throw new SocketException("Bad parameter for option"); if (val instanceof Boolean) { // true only if disabling - enabling should be Integer on = false; } break; case SO_TIMEOUT: if (val == null || (!(val instanceof Integer))) throw new SocketException("Bad parameter for SO_TIMEOUT");
<|startcomment|> should be * <|endcomment|>  } else { doConnect(address, port, timeout); } } public void setOption(int opt, Object val) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } // Android-removed: alternative implementation /* boolean on = true; switch (opt) { // check type safety b4 going native. These should never * fail, since only java.Socket* has access to * PlainSocketImpl.setOption(). <|startfocus|> // <|endfocus|> case SO_LINGER: if (val == null || (!(val instanceof Integer) && !(val instanceof Boolean))) throw new SocketException("Bad parameter for option"); if (val instanceof Boolean) { // true only if disabling - enabling should be Integer on = false; } break; case SO_TIMEOUT: if (val == null || (!(val instanceof Integer))) throw new SocketException("Bad parameter for SO_TIMEOUT"); int tmp = ((Integer) val).intValue(); if (tmp < 0) throw new IllegalArgumentException("timeout < 0");
<|startcomment|> Suggest /* true if disabling - enabling should be Integer * but I'm ambivalent in this case <|endcomment|>  } // Android-removed: alternative implementation /* boolean on = true; switch (opt) { // check type safety b4 going native. These should never * fail, since only java.Socket* has access to * PlainSocketImpl.setOption(). // case SO_LINGER: if (val == null || (!(val instanceof Integer) && !(val instanceof Boolean))) throw new SocketException("Bad parameter for option"); if (val instanceof Boolean) { <|startfocus|> // true only if disabling - enabling should be Integer <|endfocus|> on = false; } break; case SO_TIMEOUT: if (val == null || (!(val instanceof Integer))) throw new SocketException("Bad parameter for SO_TIMEOUT"); int tmp = ((Integer) val).intValue(); if (tmp < 0) throw new IllegalArgumentException("timeout < 0"); timeout = tmp; break; case IP_TOS: if (val == null || !(val instanceof Integer)) { throw new SocketException("bad argument for IP_TOS"); }
<|startcomment|> same here. Please make your change summaries as informative as possible for someone who only reads that summary without seeing the code change. <|endcomment|>  break; default: throw new SocketException("unrecognized TCP option: " + opt); } socketSetOption(opt, on, val); */ if (opt == SO_TIMEOUT) { timeout = (Integer) val; } socketSetOption(opt, val); } public Object getOption(int opt) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } if (opt == SO_TIMEOUT) { return new Integer(timeout); } <|startfocus|> // Android-removed: alternative implementation <|endfocus|> /* int ret = 0; // * The native socketGetOption() knows about 3 options. * The 32 bit value it returns will be interpreted according * to what we're asking. A return of -1 means it understands * the option but its turned off. It will raise a SocketException * if "opt" isn't one it understands. // switch (opt) { case TCP_NODELAY: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_OOBINLINE:
<|startcomment|> Leave this line unchanged "/*", per style guide <|endcomment|>  throw new SocketException("unrecognized TCP option: " + opt); } socketSetOption(opt, on, val); */ if (opt == SO_TIMEOUT) { timeout = (Integer) val; } socketSetOption(opt, val); } public Object getOption(int opt) throws SocketException { if (isClosedOrPending()) { throw new SocketException("Socket Closed"); } if (opt == SO_TIMEOUT) { return new Integer(timeout); } // Android-removed: alternative implementation /* int ret = 0; <|startfocus|> // <|endfocus|> * The native socketGetOption() knows about 3 options. * The 32 bit value it returns will be interpreted according * to what we're asking. A return of -1 means it understands * the option but its turned off. It will raise a SocketException * if "opt" isn't one it understands. // switch (opt) { case TCP_NODELAY: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_OOBINLINE:
<|startcomment|> Per style guide, this should just be "*" rather than "*/" or "//". <|endcomment|>  } if (opt == SO_TIMEOUT) { return new Integer(timeout); } // Android-removed: alternative implementation /* int ret = 0; // * The native socketGetOption() knows about 3 options. * The 32 bit value it returns will be interpreted according * to what we're asking. A return of -1 means it understands * the option but its turned off. It will raise a SocketException * if "opt" isn't one it understands. <|startfocus|> // <|endfocus|> switch (opt) { case TCP_NODELAY: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_OOBINLINE: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_LINGER: ret = socketGetOption(opt, null); return (ret == -1) ? Boolean.FALSE: (Object)(new Integer(ret)); case SO_REUSEADDR: ret = socketGetOption(opt, null); return Boolean.valueOf(ret != -1); case SO_BINDADDR: InetAddressContainer in = new InetAddressContainer();
<|startcomment|> Should be informative to someone who doesn't see the code change. How about: // Android-changed: socket{Get,Set}Option work directly with Object values <|endcomment|>  } abstract void socketCreate(boolean isServer) throws IOException; abstract void socketConnect(InetAddress address, int port, int timeout) throws IOException; abstract void socketBind(InetAddress address, int port) throws IOException; abstract void socketListen(int count) throws IOException; abstract void socketAccept(SocketImpl s) throws IOException; abstract int socketAvailable() throws IOException; abstract void socketClose0(boolean useDeferredClose) throws IOException; abstract void socketShutdown(int howto) throws IOException; <|startfocus|> // Android-changed: Method signature changed. <|endfocus|> abstract void socketSetOption(int cmd, Object value) throws SocketException; abstract Object socketGetOption(int opt) throws SocketException; abstract void socketSendUrgentData(int data) throws IOException; public final static int SHUT_RD = 0; public final static int SHUT_WR = 1; } 
<|startcomment|> Maybe explain this concatenation? <|endcomment|>  public static void main(String[] args) { <|startfocus|> System.out.println("" + test()); <|endfocus|>
<|startcomment|> newPriority? <|endcomment|>  * @see #checkAccess() * @see #getThreadGroup() * @see #MAX_PRIORITY * @see #MIN_PRIORITY * @see ThreadGroup#getMaxPriority() */ public final void setPriority(int newPriority) { ThreadGroup g; checkAccess(); if (newPriority > MAX_PRIORITY || newPriority < MIN_PRIORITY) { // Android-changed: Improve exception message when the new priority // is out of bounds. <|startfocus|> throw new IllegalArgumentException("Priority out of range: " + priority); <|endfocus|> } if((g = getThreadGroup()) != null) { if (newPriority > g.getMaxPriority()) { newPriority = g.getMaxPriority(); } synchronized(this) { this.priority = newPriority; if (isAlive()) { nativeSetPriority(newPriority); } } } } /** * Returns this thread's priority. * * @return this thread's priority. * @see #setPriority */ public final int getPriority() { return priority; } /**
<|startcomment|> Field names should start lower-case. <|endcomment|>  private static void DisableReporting() { <|startfocus|> if (DoDisableReporting == null) { <|endfocus|> return; } try { DoDisableReporting.invoke(null); } catch (Exception e) { throw new Error("Unable to disable reporting!"); }
<|startcomment|> Stale? <|endcomment|>  private static void ensureTestWatcherInitialized() { try { // Make sure the TestWatcher class can be found from the Object <init> function. addToBootClassLoader(LISTENER_LOCATION); // Load TestWatcher from the bootclassloader and make sure it is initialized. Class<?> testwatcher_class = Class.forName("art.test.TestWatcher", true, null); <|startfocus|> // Bind the native functions of testwatcher_class. DoEnableReporting = testwatcher_class.getDeclaredMethod("EnableReporting"); DoDisableReporting = testwatcher_class.getDeclaredMethod("DisableReporting"); <|endfocus|> } catch (Exception e) { throw new Error("Exception while making testwatcher", e); }
<|startcomment|> thanks for this idea, I am using the same for the halving add idiom! <|endcomment|>  /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecAdd loop:<<Loop>> outer_loop:none // /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMultiplyAccumulate kind:Add loop:<<Loop>> outer_loop:none <|startfocus|> public static void SimdMulAdd(int[] array1, int[] array2) { <|endfocus|> for (int j = 0; j < 100; j++) { array2[j] += 12345*array1[j]; } } /// CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecSub loop:<<Loop>> outer_loop:none //
<|startcomment|> here and below, { should be at same line as function def <|endcomment|>  /// CHECK-DAG: VecAdd loop:<<Loop>> outer_loop:none // /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMultiplyAccumulate kind:Add loop:<<Loop>> outer_loop:none public static void SimdMulAdd(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { <|startfocus|> array2[j] += 12345*array1[j]; <|endfocus|> } } /// CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecSub loop:<<Loop>> outer_loop:none // /// CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (after)
<|startcomment|> spaces around operators <|endcomment|>  // /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMultiplyAccumulate kind:Add loop:<<Loop>> outer_loop:none public static void SimdMulAdd(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { <|startfocus|> array2[j] += 12345*array1[j]; <|endfocus|> } } /// CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecSub loop:<<Loop>> outer_loop:none // /// CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none
<|startcomment|> if result != null <|endcomment|>  handleRadioProxyExceptionForRR(rr, "setSimCardPower", e); } } } @Override public void setCarrierInfoForImsiEncryption(PublicKey publicKey, String keyIdentifier, Message result) { IRadio radioProxy = getRadioProxy(result); if (radioProxy != null) { android.hardware.radio.V1_1.IRadio radioProxy11 = android.hardware.radio.V1_1.IRadio.castFrom(radioProxy); if (radioProxy11 == null) { <|startfocus|> AsyncResult.forMessage(result, null, CommandException.fromRilErrno(REQUEST_NOT_SUPPORTED)); result.sendToTarget(); <|endfocus|> } else { RILRequest rr = obtainRequest(RIL_REQUEST_SET_CARRIER_INFO_IMSI_ENCRYPTION, result, mRILDefaultWorkSource); if (RILJ_LOGD) riljLog(rr.serialString() + "> " + requestToString(rr.mRequest)); try { radioProxy11.setCarrierInfoForImsiEncryption( rr.mSerial, publicKeyToArrayList(publicKey), keyIdentifier); } catch (RemoteException | RuntimeException e) { handleRadioProxyExceptionForRR(rr, "setCarrierInfoForImsiEncryption", e); } } } } @Override
<|startcomment|> Is there a compelling reason to extend the arg2 naming scheme into this method? I'd prefer to use a descriptive name for as long as possible (until sendMessage) <|endcomment|>  if (DBG) { log("reportNetworkConnectivity(" + nai.network.netId + ", " + hasConnectivity + ") by " + uid); } synchronized (nai) { // Validating a network that has not yet connected could result in a call to // rematchNetworkAndRequests() which is not meant to work on such networks. if (!nai.everConnected) return; if (isNetworkWithLinkPropertiesBlocked(nai.linkProperties, uid, false)) return; nai.networkMonitor.sendMessage(NetworkMonitor.CMD_FORCE_REEVALUATION, uid); <|startfocus|> } <|endfocus|>
<|startcomment|> Just to make sure, are we handling the case where remote will ask the getItemAttr with this QueueID (0000001)? <|endcomment|>  if (items == null) { Log.i(TAG, "null queue from " + mediaController.getPackageName() + ", constructing current-item list"); MediaMetadata metadata = mediaController.getMetadata(); // Because we are database-unaware, we can just number the item here whatever we want // because they have to re-poll it every time. MediaSession.QueueItem current = getCurrentQueueItem(mediaController, 1); items = new ArrayList<MediaSession.QueueItem>(); items.add(current); <|startfocus|> return items; <|endfocus|> } mNowPlayingList = items; return items; } /* Constructs a queue item representing the current playing metadata from an * active controller with queue id |qid|. */ private MediaSession.QueueItem getCurrentQueueItem(MediaController controller, long qid) { MediaMetadata metadata = controller.getMetadata(); if (metadata == null) { Log.w(TAG, "Controller has no metadata!? Making an empty one"); metadata = (new MediaMetadata.Builder()).build(); } MediaDescription.Builder bob = new MediaDescription.Builder();
<|startcomment|> Should we check for a case, where no track is currently selected. Then, we don't have even the current song and getTotalNumOfItems should return 0? <|endcomment|>  if (mediaController == null) { Log.e(TAG, "mediaController = null, sending no available players response"); mMediaInterface.getItemAttrRsp(bdaddr, AvrcpConstants.RSP_NO_AVBL_PLAY, null); return; } // We don't have the cached list, fetch it from Media Controller items = mediaController.getQueue(); if (items == null) { <|startfocus|> // We're presenting a queue with only 1 item (the current one) mMediaInterface.getTotalNumOfItemsRsp(bdaddr, AvrcpConstants.RSP_NO_ERROR, 0, 1); <|endfocus|> } // Cache the response for later mNowPlayingList = items; mMediaInterface.getTotalNumOfItemsRsp(bdaddr, AvrcpConstants.RSP_NO_ERROR, 0, items.size());
<|startcomment|> Please wrap lines to 100 characters: https://source.android.com/source/code-style#limit-line-length <|endcomment|>  if ((length == 10 || length == 26 || length == 58) && password.matches("[0-9A-Fa-f]*")) { wifiConfiguration.wepKeys[0] = password; } else if (length == 5 || length == 13 || length == 16) { wifiConfiguration.wepKeys[0] = '"' + password + '"'; } } else { <|startfocus|> if (wifiSecurity == WifiSecurity.PSK && password.length() < FormPageDisplayer.PSK_MIN_LENGTH) { <|endfocus|> return; } if (password.matches("[0-9A-Fa-f]{64}")) { wifiConfiguration.preSharedKey = password; } else { wifiConfiguration.preSharedKey = '"' + password + '"'; } }
<|startcomment|> nit: Util.setShort(buffer, (short) 0, (short) 0); ? <|endcomment|>  private void getNumSlots(APDU apdu) { p1p2Unused(apdu); //dataUnused(apdu); // TODO(ascull): how to handle the cases of APDU properly? prepareToSend(apdu, (short) 4); final byte buffer[] = apdu.getBuffer(); <|startfocus|> buffer[(short) 0] = 0; buffer[(short) 1] = 0; <|endfocus|> Util.setShort(buffer, (short) 2, mSlots.getNumSlots()); apdu.sendBytes((short) 0, (byte) 4);
<|startcomment|> Just curious, is there a reason why you go through ImsPhone --> ImsPhoneCallTracker --> ImsCall to do this? The TelephonyConnection's mOriginalConnection is technically the ImsPhoneConnection. So you can just go: (ImsPhoneConnection) mOriginalConnection.getImsCall().blahBlargStuff(textStream). This would remove the need to check for foreground call in ImsPhoneCallTracker. <|endcomment|>  @Override public void onPullExternalCall() { if ((getConnectionProperties() & Connection.PROPERTY_IS_EXTERNAL_CALL) != Connection.PROPERTY_IS_EXTERNAL_CALL) { Log.w(this, "onPullExternalCall - cannot pull non-external call"); return; } if (mOriginalConnection != null) { mOriginalConnection.pullExternalCall(); } } @Override public void onStartRtt(RttTextStream textStream) { if (isImsConnection()) { <|startfocus|> ImsPhone imsPhone = (ImsPhone) getPhone(); imsPhone.sendRttModifyRequest(textStream); <|endfocus|> } else { Log.w(this, "onStartRtt - not in IMS, so RTT cannot be enabled."); } } @Override public void onStopRtt() { // This is not supported by carriers/vendor yet. No-op for now. } @Override public void handleRttUpgradeResponse(RttTextStream textStream) { if (!isImsConnection()) { Log.w(this, "handleRttUpgradeResponse - not in IMS, so RTT cannot be enabled."); return; } ImsPhone imsPhone = (ImsPhone) getPhone();
<|startcomment|> I haven't looked too closely at what this is supposed to be, but you're sure that this will be well formed UTF-8 ? <|endcomment|>  private Attribute sourceDebugExtension(DirectClassFile cf, int offset, int length, ParseObserver observer) { ByteArray bytes = cf.getBytes().slice(offset, offset + length); CstString smapString = new CstString(bytes); Attribute result = new AttSourceDebugExtension(smapString); if (observer != null) { String decoded = smapString.getString(); observer.parsed(bytes, offset, length, "sourceDebugExtension: " + decoded); } <|startfocus|> return result; <|endfocus|>
<|startcomment|> unnecessary delta <|endcomment|> import com.android.dx.rop.cst.CstMethodRef; import com.android.dx.rop.cst.CstNat; import com.android.dx.rop.cst.CstType; import com.android.dx.rop.type.StdTypeList; import com.android.dx.rop.type.Type; import com.android.dx.rop.type.TypeList; import com.android.dx.util.Warning; import java.util.ArrayList; /** * Utility methods that translate various classfile attributes * into forms suitable for use in creating {@code dex} files. */ /*package*/ class AttributeTranslator { <|startfocus|> <|endfocus|> /** * This class is uninstantiable. */ private AttributeTranslator() { // This space intentionally left blank. } /** * Gets the list of thrown exceptions for a given method. * * @param method {@code non-null;} the method in question * @return {@code non-null;} the list of thrown exceptions */ public static TypeList getExceptions(Method method) { AttributeList attribs = method.getAttributes(); AttExceptions exceptions = (AttExceptions) attribs.findFirst(AttExceptions.ATTRIBUTE_NAME); if (exceptions == null) {
<|startcomment|> don't we need vectorizer support for this first? Is a patch missing? <|endcomment|>  public static long $opt$noinline$mulNeg(long left, long right) { if (doThrow) throw new Error(); return - (left * right); } /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecAdd loop:<<Loop>> outer_loop:none <|startfocus|> // <|endfocus|> /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMultiplyAccumulate kind:Add loop:<<Loop>> outer_loop:none public static void SimdMulAdd(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { array2[j] += 12345 * array1[j]; } } 
<|startcomment|> nit: s/thrity/thirty/g <|endcomment|>  private static void throttle(byte[] bArray, short bOff, short failureCount) { short highWord = 0; short lowWord = 0; <|startfocus|> final short thritySecondsInMilliseconds = 0x7530; // = 1000 * 30 <|endfocus|> if (failureCount == 0) { // 0s } else if (failureCount > 0 && failureCount <= 10) { if (failureCount % 5 == 0) { // 30s lowWord = thritySecondsInMilliseconds; } else { // 0s } } else if (failureCount < 30) { // 30s lowWord = thritySecondsInMilliseconds; } else if (failureCount < 140) { // 30 * (2^((x - 30)/10)) final short shift = (short) ((short) (failureCount - 30) / 10); highWord = (short) (thritySecondsInMilliseconds >> (16 - shift)); lowWord = (short) (thritySecondsInMilliseconds << shift); } else { // 1 day in ms = 1000 * 60 * 60 * 24 = 0x526 5C00 highWord = 0x0526;
<|startcomment|> I think you need to keep a reference to the FileDescriptor. Otherwise its finalizer will get called and the fd will silently be set to -1. <|endcomment|>  IpSecTransform.DIRECTION_IN, new IpSecAlgorithm(IpSecAlgorithm.CRYPT_AES_CBC, CRYPT_KEY)) .setAuthentication( IpSecTransform.DIRECTION_IN, new IpSecAlgorithm( IpSecAlgorithm.AUTH_HMAC_SHA256, AUTH_KEY, CRYPT_KEY.length * 8)) .buildTransportModeTransform(local); // Hack to ensure the socket doesn't block indefinitely on failure DatagramSocket localSocket = new DatagramSocket(8888); localSocket.setSoTimeout(500); <|startfocus|> FileDescriptor udpSocket = ParcelFileDescriptor.fromDatagramSocket(localSocket).getFileDescriptor(); <|endfocus|> mISM.applyTransportModeTransform(udpSocket, transform); byte[] data = new String("Best test data ever!").getBytes("UTF-8"); byte[] in = new byte[data.length]; Os.sendto(udpSocket, data, 0, data.length, 0, local, 8888); Os.read(udpSocket, in, 0, in.length); assertTrue("Encapsulated data did not match.", Arrays.equals(data, in)); mISM.removeTransportModeTransform(udpSocket, transform); Os.close(udpSocket); transform.close(); } } 
<|startcomment|> long lines <|endcomment|>  if (mEnableTerminal != null) { updateSwitchPreference(mEnableTerminal, context.getPackageManager().getApplicationEnabledSetting(TERMINAL_APP_PACKAGE) == PackageManager.COMPONENT_ENABLED_STATE_ENABLED); } updateSwitchPreference(mBugreportInPower, Settings.Secure.getInt(cr, Settings.Global.BUGREPORT_IN_POWER_MENU, 0) != 0); updateSwitchPreference(mKeepScreenOn, Settings.Global.getInt(cr, Settings.Global.STAY_ON_WHILE_PLUGGED_IN, 0) != 0); <|startfocus|> updateSwitchPreference(mBtHciSnoopLog, SystemProperties.getBoolean(BLUETOOTH_BTSNOOP_ENABLE_PROPERTY, false)); <|endfocus|> updateSwitchPreference(mDebugViewAttributes, Settings.Global.getInt(cr, Settings.Global.DEBUG_VIEW_ATTRIBUTES, 0) != 0); updateSwitchPreference(mForceAllowOnExternal, Settings.Global.getInt(cr, Settings.Global.FORCE_ALLOW_ON_EXTERNAL, 0) != 0); updateHdcpValues(); updatePasswordSummary(); updateDebuggerOptions(); updateMockLocation(); updateStrictModeVisualOptions(); updatePointerLocationOptions(); updateShowTouchesOptions(); updateFlingerOptions(); updateHardwareUiOptions(); updateMsaaOptions(); updateTrackFrameTimeOptions(); updateShowNonRectClipOptions(); updateShowHwScreenUpdatesOptions(); updateShowHwLayersUpdatesOptions(); updateDebugHwOverdrawOptions();
<|startcomment|> Consider using a String variable to store the address string so that this method only needs to be called once. <|endcomment|>  // Check that this is a valid device address (i.e. not broadcast). if ((val[0] & 0x01) != 0) { // Invalid since this is a broadcast address. errorLog("Invalid device address=" + Utils.getAddressStringFromByte(val) + ". Ignore this address."); break; } mAddress = val; <|startfocus|> debugLog("Address is:" + Utils.getAddressStringFromByte(mAddress)); intent = new Intent(BluetoothAdapter.ACTION_BT_BD_ADDR_CHANGED); intent.putExtra(BluetoothAdapter.EXTRA_BT_BD_ADDR, Utils.getAddressStringFromByte(mAddress)); <|endfocus|> intent.addFlags(Intent.FLAG_RECEIVER_REGISTERED_ONLY_BEFORE_BOOT); mService.sendBroadcastAsUser( intent, UserHandle.ALL, mService.BLUETOOTH_PERM); break; case AbstractionLayer.BT_PROPERTY_CLASS_OF_DEVICE: mBluetoothClass = Utils.byteArrayToInt(val, 0); debugLog("BT Class:" + mBluetoothClass); break; case AbstractionLayer.BT_PROPERTY_ADAPTER_SCAN_MODE: int mode = Utils.byteArrayToInt(val, 0);
<|startcomment|> Unclear - please rewrite. <|endcomment|>  * This extra represents the previous connection state. */ public static final String EXTRA_PREVIOUS_CONNECTION_STATE = "android.bluetooth.adapter.extra.PREVIOUS_CONNECTION_STATE"; /** * Broadcast Action: The Bluetooth adapter state has changed in LE only mode. * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; /** * Broadcast Action: The notifys Bluetooth BD (mac) address * updated event. * * @hide */ <|startfocus|> public static final String ACTION_BT_BD_ADDR_CHANGED = "android.bluetooth.adapter.action.BT_BD_ADDR_CHANGED"; <|endfocus|> /** * Extra used by {@link #ACTION_BT_BD_ADDR_CHANGED} * * This extra represents the BD Address. * * @hide */ public static final String EXTRA_BT_BD_ADDR = "android.bluetooth.adapter.extra.BT_BD_ADDR"; /** * Broadcast Action: The notifys Bluetooth ACL connected event. This will be
<|startcomment|> A system-wide broadcast is an overkill for what we need. The broadcast should be used when multiple receivers are registered for the broadcast. In this case, the receiver is internal in the Bluetooth module and maybe a more internal method should be adopted. <|endcomment|>  /** * Broadcast Action: The Bluetooth adapter state has changed in LE only mode. * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; /** * Broadcast Action: The notifys Bluetooth BD (mac) address * updated event. * * @hide */ <|startfocus|> public static final String ACTION_BT_BD_ADDR_CHANGED = "android.bluetooth.adapter.action.BT_BD_ADDR_CHANGED"; <|endfocus|> /** * Extra used by {@link #ACTION_BT_BD_ADDR_CHANGED} * * This extra represents the BD Address. * * @hide */ public static final String EXTRA_BT_BD_ADDR = "android.bluetooth.adapter.extra.BT_BD_ADDR"; /** * Broadcast Action: The notifys Bluetooth ACL connected event. This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON. This denotes GATT connection
<|startcomment|> Bluetooth address (?) <|endcomment|>  */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; /** * Broadcast Action: The notifys Bluetooth BD (mac) address * updated event. * * @hide */ public static final String ACTION_BT_BD_ADDR_CHANGED = "android.bluetooth.adapter.action.BT_BD_ADDR_CHANGED"; /** * Extra used by {@link #ACTION_BT_BD_ADDR_CHANGED} * * This extra represents the BD Address. * * @hide */ <|startfocus|> public static final String EXTRA_BT_BD_ADDR = "android.bluetooth.adapter.extra.BT_BD_ADDR"; <|endfocus|> /** * Broadcast Action: The notifys Bluetooth ACL connected event. This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON. This denotes GATT connection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of {@link BluetoothDevice#ACTION_ACL_CONNECTED} which
<|startcomment|> Use either BT_ADDR or BD_ADDR, as similar to LOCAL_NAME <|endcomment|>  /** * Broadcast Action: The notifys Bluetooth BD (mac) address * updated event. * * @hide */ public static final String ACTION_BT_BD_ADDR_CHANGED = "android.bluetooth.adapter.action.BT_BD_ADDR_CHANGED"; /** * Extra used by {@link #ACTION_BT_BD_ADDR_CHANGED} * * This extra represents the BD Address. * * @hide */ <|startfocus|> public static final String EXTRA_BT_BD_ADDR = "android.bluetooth.adapter.extra.BT_BD_ADDR"; <|endfocus|> /** * Broadcast Action: The notifys Bluetooth ACL connected event. This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON. This denotes GATT connection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of {@link BluetoothDevice#ACTION_ACL_CONNECTED} which * works in Bluetooth state STATE_ON * @hide */ public static final String ACTION_BLE_ACL_CONNECTED =
<|startcomment|> Is this needed as part of the log message? <|endcomment|>  String newName = intent.getStringExtra(BluetoothAdapter.EXTRA_LOCAL_NAME); if (DBG) Slog.d(TAG, "Bluetooth Adapter name changed to " + newName); if (newName != null) { storeNameAndAddress(newName, null); } } else if (BluetoothAdapter.ACTION_BT_BD_ADDR_CHANGED.equals(action)) { String newAddress = intent.getStringExtra(BluetoothAdapter.EXTRA_BT_BD_ADDR); if (newAddress != null) { <|startfocus|> if (DBG) Slog.d(TAG, "Bluetooth Adapter BD Address changed to " + newAddress); <|endfocus|> storeNameAndAddress(null, newAddress); } else { if (DBG) Slog.e(TAG, "No Bluetooth Adapter BD Address parameter found"); } }
<|startcomment|> Same comment as above. <|endcomment|>  if (newName != null) { storeNameAndAddress(newName, null); } } else if (BluetoothAdapter.ACTION_BT_BD_ADDR_CHANGED.equals(action)) { String newAddress = intent.getStringExtra(BluetoothAdapter.EXTRA_BT_BD_ADDR); if (newAddress != null) { if (DBG) Slog.d(TAG, "Bluetooth Adapter BD Address changed to " + newAddress); storeNameAndAddress(null, newAddress); } else { <|startfocus|> if (DBG) Slog.e(TAG, "No Bluetooth Adapter BD Address parameter found"); <|endfocus|> } }
<|startcomment|> fix indention <|endcomment|>  public void testAospServiceContexts() throws Exception { /* obtain service_contexts file from running device */ deviceSvcFile = File.createTempFile("service_contexts", ".tmp"); deviceSvcFile.deleteOnExit(); mDevice.pullFile("/service_contexts", deviceSvcFile); /* retrieve the AOSP service_contexts file from jar */ aospSvcFile = copyResourceToTempFile("/general_service_contexts"); <|startfocus|> /* retrieve NMR1 AOSP service_contexts file from jar */ if (!isFileStartsWith(aospSvcFile, deviceSvcFile)) { <|endfocus|> aospSvcFile = copyResourceToTempFile("/ab3857191_service_contexts"); assertFileStartsWith(aospSvcFile, deviceSvcFile); } } /** * Tests that the file_contexts.bin file on the device is valid. * * @throws Exception */ @CddTest(requirement="9.7") public void testValidFileContexts() throws Exception { /* retrieve the checkfc executable from jar */ checkFc = copyResourceToTempFile("/checkfc"); checkFc.setExecutable(true); /* obtain file_contexts.bin file from running device */
<|startcomment|> 2017? <|endcomment|> <|startfocus|> * Copyright (C) 2016 The Android Open Source Project <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package art; import java.util.Base64; public class Test985 { static class Transform { private void Start() { System.out.println("hello - private"); } private void Finish() { System.out.println("goodbye - private"); } public void sayHi(Runnable r) { System.out.println("Pre Start private method call"); Start();
<|startcomment|> To reduce the (already likely negligible) possibility that an attacker can tell the difference between success and failure and quickly cut power, I'd do no work inside the transaction other than checking result and writing mFailureCount. Util.arrayCompare should be constant-time so this is already an incredibly narrow needle to thread, but we may as well make it as narrow as possible. <|endcomment|>  byte result = Consts.READ_WRONG_KEY; if (Util.arrayCompare( keyBuffer, keyOffset, mKey, (short) 0, Consts.SLOT_KEY_BYTES) == 0) { return Consts.READ_SUCCESS; } JCSystem.beginTransaction(); if (result == Consts.READ_WRONG_KEY) { if (mFailureCount != 0x7fff) { mFailureCount += 1; } if (throttle(sRemainingBackoff, (short) 0, mFailureCount)) { //mBackoffTimer.startTimer( // sRemainingBackoff, (short) 0, DSTimer.DST_POWEROFFMODE_FALLBACK); } Util.arrayCopyNonAtomic( sRemainingBackoff, (short) 0, outBuffer, outOffset, (byte) 4); <|startfocus|> } else { // This attempt was successful so reset the failures mFailureCount = 0; //mBackoffTimer.stopTimer(); Util.arrayCopyNonAtomic( mValue, (short) 0, outBuffer, outOffset, Consts.SLOT_VALUE_BYTES); <|endfocus|> } JCSystem.commitTransaction(); return result;
<|startcomment|> No other pass is allowed to merge the two fences if the reference does not escape in between? <|endcomment|>  /// CHECK-NOT: InstanceFieldSet /// CHECK-NOT: ConstructorFence /// CHECK-NOT: InstanceFieldGet // Make sure the constructor fence gets eliminated when the allocation is eliminated. static double calcCircleArea(double radius) { return new Circle(radius).getArea(); } /// CHECK-START: double Main.calcEllipseArea(double, double) load_store_elimination (before) /// CHECK: NewInstance /// CHECK: InstanceFieldSet <|startfocus|> /* // TODO: The super constructor fence should not be eliminated already. // CHECK: ConstructorFence */ <|endfocus|> /// CHECK: InstanceFieldSet /// CHECK: ConstructorFence /// CHECK: InstanceFieldGet /// CHECK: InstanceFieldGet /// CHECK-START: double Main.calcEllipseArea(double, double) load_store_elimination (after) /// CHECK-NOT: NewInstance /// CHECK-NOT: InstanceFieldSet /// CHECK-NOT: ConstructorFence /// CHECK-NOT: InstanceFieldGet // Multiple constructor fences can accumulate through inheritance, make sure // they are all eliminated when the allocation is eliminated. static double calcEllipseArea(double vertex, double covertex) {
<|startcomment|> Why is this here? It's separating the CHECKer statements above from the method below. <|endcomment|>  static double calcEllipseArea(double vertex, double covertex) { return new Ellipse(vertex, covertex).getArea(); } /// CHECK-START: double Main.calcCircleAreaOrCircumference(double, boolean) load_store_elimination (before) /// CHECK: NewInstance /// CHECK: InstanceFieldSet /// CHECK: ConstructorFence /// CHECK: InstanceFieldGet /// CHECK-START: double Main.calcCircleAreaOrCircumference(double, boolean) load_store_elimination (after) /// CHECK: NewInstance /// CHECK-NOT: ConstructorFence <|startfocus|> static double someResult; <|endfocus|> // // The object allocation will not be eliminated by LSE because of aliased stores. // However the object is still a singleton, so it never escapes the current thread. // There should not be a constructor fence here after LSE. static double calcCircleAreaOrCircumference(double radius, boolean area_or_circumference) { CalcCircleAreaOrCircumference calc = new CalcCircleAreaOrCircumference( area_or_circumference ? CalcCircleAreaOrCircumference.TYPE_AREA : CalcCircleAreaOrCircumference.TYPE_CIRCUMFERENCE); if (area_or_circumference) { // Area
<|startcomment|> make new section with CHECK-NOT VecMul CHECK-NOT VecAdd to ensure it is replaced (and not put next to it) <|endcomment|>  /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none /// CHECK-DAG: VecAdd loop:<<Loop>> outer_loop:none // /// CHECK-START-ARM64: void Main.SimdMulAdd(int[], int[]) instruction_simplifier_arm64 (after) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none <|startfocus|> /// CHECK-DAG: VecMultiplyAccumulate kind:Add loop:<<Loop>> outer_loop:none <|endfocus|> public static void SimdMulAdd(int[] array1, int[] array2) { for (int j = 0; j < 100; j++) { array2[j] += 12345 * array1[j]; } } /// CHECK-START-ARM64: void Main.SimdMulSub(int[], int[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: Phi loop:<<Loop:B\d+>> outer_loop:none /// CHECK-DAG: VecMul loop:<<Loop>> outer_loop:none
<|startcomment|> 2017 <|endcomment|> <|startfocus|> * Copyright (C) 2015 The Android Open Source Project <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except * in compliance with the License. You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software distributed under the License * is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express * or implied. See the License for the specific language governing permissions and limitations under * the License. */ package com.android.rs.test; import android.content.Context; import android.renderscript.Allocation; import android.renderscript.Element; import android.renderscript.RenderScript; import android.renderscript.RSIllegalArgumentException; import android.renderscript.ScriptIntrinsicBlur; import android.renderscript.Type; import android.util.Log; public class UT_blur_validation extends UnitTest { private static final int ARRAY_SIZE = 256; private static final String TAG = "ScriptIntrinsicBlur validation"; 
<|startcomment|> It would be nice to have the destroy() calls in another method. Makes it more obvious what is tested. <|endcomment|>  output2D.destroy(); scriptBlur.destroy(); pRS.destroy(); passTest(); return; } Log.e(TAG, "setting 1d output does not trigger exception"); pRS.finish(); input1D.destroy(); input2D.destroy(); output1D.destroy(); output2D.destroy(); scriptBlur.destroy(); pRS.destroy(); failTest(); return; } Log.e(TAG, "setting 1d input does not trigger exception"); <|startfocus|> pRS.finish(); input1D.destroy(); input2D.destroy(); output1D.destroy(); output2D.destroy(); scriptBlur.destroy(); pRS.destroy(); <|endfocus|> failTest();
<|startcomment|> 2017 <|endcomment|> <|startfocus|> * Copyright (C) 2016 The Android Open Source Project <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package art; import java.lang.reflect.Method; import java.util.HashMap; public class Test986 { static { // NB This is called before any setup is done so we don't need to worry about getting bind // events. Main.bindAgentJNIForClass(Test986.class); } private static final HashMap<Method, String> SymbolMap = new HashMap<>(); 
<|startcomment|> This is essentially a duplicate of lines 325-336. Can we move this to it's own function and avoid the duplication? <|endcomment|>  ProcessBuilder pb1 = new ProcessBuilder(checkFc.getAbsolutePath(), "-c", aospFcFile.getAbsolutePath(), deviceFcFile.getAbsolutePath()); pb1.redirectOutput(ProcessBuilder.Redirect.PIPE); pb1.redirectErrorStream(true); Process p1 = pb1.start(); p1.waitFor(); BufferedReader result1 = new BufferedReader(new InputStreamReader(p1.getInputStream())); String line1 = result1.readLine(); assertTrue("The file_contexts.bin file did not include the AOSP entries:\n" <|startfocus|> + line1 + "\n", line1.equals("equal") || line1.equals("subset")); <|endfocus|> } } /** * Tests that the property_contexts file on the device contains * the standard AOSP entries. * * @throws Exception */ @CddTest(requirement="9.7") public void testAospPropertyContexts() throws Exception { /* obtain property_contexts file from running device */ devicePcFile = File.createTempFile("property_contexts", ".tmp"); devicePcFile.deleteOnExit();
<|startcomment|> nit protected ? <|endcomment|>  BufferedWriter writer = new BufferedWriter(new FileWriter(sourceList.getAbsolutePath())); for (String f : files) { writer.write(f); writer.write('\n'); } writer.close(); commandLine.add('@' + sourceList.getAbsolutePath()); } @Override @Nonnull public AndroidToolchain setAndroidMinApiLevel(@Nonnull String minApiLevel) throws Exception { this.minApiLevel = minApiLevel; return this; } <|startfocus|> abstract boolean isDesugarEnabled(); <|endfocus|> } 
<|startcomment|> You need to remove "Allocation " here and elsewhere. <|endcomment|>  public void run() { RenderScript pRS = RenderScript.create(mCtx); final int width = 100; final int height = 100; <|startfocus|> Allocation input1D = Allocation.createSized(pRS, Element.U8(pRS), width * height, Allocation.USAGE_SCRIPT); <|endfocus|> final Allocation output1D = Allocation.createTyped(pRS, input1D.getType()); Type.Builder typeBuilder = new Type.Builder(pRS, Element.U8(pRS)); typeBuilder.setX(width); typeBuilder.setY(height); Type ty = typeBuilder.create(); final Allocation input2D = Allocation.createTyped(pRS, ty); final Allocation output2D = Allocation.createTyped(pRS, ty); ScriptIntrinsicBlur scriptBlur = ScriptIntrinsicBlur.create(pRS, Element.U8(pRS)); scriptBlur.setRadius(25f); boolean failed = false; try { scriptBlur.setInput(input1D); } catch (RSIllegalArgumentException e) { scriptBlur.setInput(input2D); try { scriptBlur.forEach(output1D); } catch (RSIllegalArgumentException e1) { scriptBlur.forEach(output2D);
<|startcomment|> Is this variable used/needed? <|endcomment|>  * the License. */ package com.android.rs.test_compat; import android.content.Context; import android.content.res.Resources; import android.support.v8.renderscript.Allocation; import android.support.v8.renderscript.Element; import android.support.v8.renderscript.RenderScript; import android.support.v8.renderscript.RSIllegalArgumentException; import android.support.v8.renderscript.ScriptIntrinsicBlur; import android.support.v8.renderscript.Type; import android.util.Log; public class UT_blur_validation extends UnitTest { <|startfocus|> private static final int ARRAY_SIZE = 256; <|endfocus|> private static final String TAG = "ScriptIntrinsicBlur validation"; protected UT_blur_validation(RSTestCore rstc, Resources res, Context ctx) { super(rstc, TAG, ctx); } public void run() { RenderScript pRS = RenderScript.create(mCtx); final int width = 100; final int height = 100; Allocation input1D = Allocation.createSized(pRS, Element.U8(pRS), width * height, Allocation.USAGE_SCRIPT); final Allocation output1D = Allocation.createTyped(pRS, input1D.getType()); 
<|startcomment|> Notification cancelled ? <|endcomment|>  public void onReceive(Context context, Intent intent) { String action = intent.getAction(); if (action.equals(BluetoothDevice.ACTION_BOND_STATE_CHANGED)) { int bondState = intent.getIntExtra(BluetoothDevice.EXTRA_BOND_STATE, BluetoothDevice.ERROR); if ((bondState != BluetoothDevice.BOND_NONE) && (bondState != BluetoothDevice.BOND_BONDED)) { return; } } else if (action.equals(ACTION_DISMISS_PAIRING)) { <|startfocus|> Log.d(TAG, "Noitifaction cancel for " + mDevice.getAddress() + " (" + <|endfocus|> mDevice.getName() + ")"); } else { int bondState = intent.getIntExtra(BluetoothDevice.EXTRA_BOND_STATE, BluetoothDevice.ERROR); Log.d(TAG, "Dismiss pairing for " + mDevice.getAddress() + " (" + mDevice.getName() + "), BondState: " + bondState); } stopForeground(true); stopSelf();
<|startcomment|> Is this needed? <|endcomment|>  public void sendUssd(String ussdMessage) throws ImsException { logi("sendUssd :: ussdMessage=" + ussdMessage); synchronized(mLockObj) { if (mSession == null) { loge("sendUssd :: "); throw new ImsException("No call session", ImsReasonInfo.CODE_LOCAL_CALL_TERMINATED); } mSession.sendUssd(ussdMessage); } } /** <|startfocus|> * TODO: Delete this method and replace it with a thread that listens to the opened pipe. */ public void sendRttMessage(String rttMessage) { } /** <|endfocus|> * Sends a user-requested RTT upgrade request. */ public void sendRttModifyRequest() { logi("sendRttModifyRequest"); synchronized(mLockObj) { if (mSession == null) { loge("sendRttModifyRequest::no session"); } if (mCallProfile.mMediaProfile.isRttCall()) { logi("sendRttModifyRequest::Already RTT call, ignoring."); return; } // Make a copy of the current ImsCallProfile and modify it to enable RTT Parcel p = Parcel.obtain();
<|startcomment|> so you're switching what this returns? :( I think we need to be consistent, esp given the function names don't provide any hints <|endcomment|> <|startfocus|> public static List<TimeZone> getTimeZonesWithUniqueOffsets(String country) { <|endfocus|> synchronized(sLastUniqueLockObj) { if ((country != null) && country.equals(sLastUniqueCountry)) { if (DBG) { Log.d(TAG, "getTimeZonesWithUniqueOffsets(" + country + "): return cached version"); } return sLastUniqueZoneOffsets; } } Collection<TimeZone> zones = getTimeZones(country); ArrayList<TimeZone> uniqueTimeZones = new ArrayList<>(); for (TimeZone zone : zones) { // See if we already have this offset, // Using slow but space efficient and these are small. boolean found = false; for (int i = 0; i < uniqueTimeZones.size(); i++) { if (uniqueTimeZones.get(i).getRawOffset() == zone.getRawOffset()) { found = true; break; } } if (!found) { if (DBG) { Log.d(TAG, "getTimeZonesWithUniqueOffsets: add unique offset=" +
<|startcomment|> KEY_CARRIER_VOLTE_OVERRIDE_WFC_PROVISIONING_BOOL? <|endcomment|>  return mgr.isVolteProvisioned(); } } return true; } /** * Indicates whether VoLTE is provisioned on this slot. */ public boolean isVolteProvisionedOnDeviceForSlot() { if (getBooleanCarrierConfigForSlot( CarrierConfigManager.KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL)) { return isVolteProvisioned(); } return true; } /** * Indicates whether VoWifi is provisioned on device. * <|startfocus|> * When CarrierConfig KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL is true, and VoLTE is not <|endfocus|> * provisioned on device, this method returns false. * * @deprecated Does not support MSIM devices. Please use * {@link #isWfcProvisionedOnDeviceForSlot()} instead. */ public static boolean isWfcProvisionedOnDevice(Context context) { if (getBooleanCarrierConfig(context, CarrierConfigManager.KEY_CARRIER_VOLTE_OVERRIDE_WFC_PROVISIONING_BOOL)) { if (!isVolteProvisionedOnDevice(context)) { return false; } } if (getBooleanCarrierConfig(context, CarrierConfigManager.KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL)) {
<|startcomment|> same as above <|endcomment|>  return false; } } if (getBooleanCarrierConfig(context, CarrierConfigManager.KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL)) { ImsManager mgr = ImsManager.getInstance(context, SubscriptionManager.getDefaultVoicePhoneId()); if (mgr != null) { return mgr.isWfcProvisioned(); } } return true; } /** * Indicates whether VoWifi is provisioned on slot. * <|startfocus|> * When CarrierConfig KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL is true, and VoLTE is not <|endfocus|> * provisioned on device, this method returns false. */ public boolean isWfcProvisionedOnDeviceForSlot() { if (getBooleanCarrierConfigForSlot( CarrierConfigManager.KEY_CARRIER_VOLTE_OVERRIDE_WFC_PROVISIONING_BOOL)) { if (!isVolteProvisionedOnDeviceForSlot()) { return false; } } if (getBooleanCarrierConfigForSlot( CarrierConfigManager.KEY_CARRIER_VOLTE_PROVISIONING_REQUIRED_BOOL)) { return isWfcProvisioned(); } return true; } /** * Indicates whether VT is provisioned on device * * @deprecated Does not support MSIM devices. Please use
<|startcomment|> Optional: change to just "ArrayList<>()" <|endcomment|>  private void sendTetherStateChangedBroadcast() { if (!getConnectivityManager().isTetheringSupported()) return; <|startfocus|> final ArrayList<String> availableList = new ArrayList<String>(); final ArrayList<String> tetherList = new ArrayList<String>(); final ArrayList<String> hotspotList = new ArrayList<String>(); final ArrayList<String> erroredList = new ArrayList<String>(); <|endfocus|> boolean wifiTethered = false; boolean usbTethered = false; boolean bluetoothTethered = false; final TetheringConfiguration cfg = mConfig; synchronized (mPublicSync) { for (int i = 0; i < mTetherStates.size(); i++) { TetherState tetherState = mTetherStates.valueAt(i); String iface = mTetherStates.keyAt(i); if (tetherState.lastError != ConnectivityManager.TETHER_ERROR_NO_ERROR) { erroredList.add(iface); } else if (tetherState.lastState == IControlsTethering.STATE_AVAILABLE) { availableList.add(iface); } else if (tetherState.lastState == IControlsTethering.STATE_LOCAL_HOTSPOT) { hotspotList.add(iface);
<|startcomment|> Consider static final. <|endcomment|> import android.telephony.CarrierConfigManager; import android.os.Message; import android.os.Messenger; import com.android.internal.util.AsyncChannel; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.MockitoAnnotations; import org.mockito.ArgumentCaptor; import java.util.List; @RunWith(AndroidJUnit4.class) @SmallTest public class NsdManagerTest { @Mock Context mContext; @Mock INsdManager mService; MockServiceHandler mServiceHandler; <|startfocus|> long mTimeoutMs = 100; <|endfocus|> @Before public void setUp() throws Exception { MockitoAnnotations.initMocks(this); mServiceHandler = spy(MockServiceHandler.make(mContext)); when(mService.getMessenger()).thenReturn(new Messenger(mServiceHandler)); } @Test public void testResolveService() { NsdManager manager = makeManager(); NsdServiceInfo request = new NsdServiceInfo("a name", "a type"); NsdServiceInfo reply = new NsdServiceInfo("resolved name", "resolved type"); NsdManager.ResolveListener listener = mock(NsdManager.ResolveListener.class); manager.resolveService(request, listener);
<|startcomment|> Nit: is this a realistic name? Can these names contain spaces? <|endcomment|>  public void testResolveService() { NsdManager manager = makeManager(); <|startfocus|> NsdServiceInfo request = new NsdServiceInfo("a name", "a type"); NsdServiceInfo reply = new NsdServiceInfo("resolved name", "resolved type"); <|endfocus|> NsdManager.ResolveListener listener = mock(NsdManager.ResolveListener.class); manager.resolveService(request, listener); int key1 = verifyRequest(NsdManager.RESOLVE_SERVICE); int err = 33; sendResponse(NsdManager.RESOLVE_SERVICE_FAILED, err, key1, null); verify(listener, timeout(mTimeoutMs).times(1)).onResolveFailed(request, err); manager.resolveService(request, listener); int key2 = verifyRequest(NsdManager.RESOLVE_SERVICE); sendResponse(NsdManager.RESOLVE_SERVICE_SUCCEEDED, 0, key2, reply); verify(listener, timeout(mTimeoutMs).times(1)).onServiceResolved(reply);
<|startcomment|> This type of method is usually called "create" or "from". <|endcomment|> <|startfocus|> public static MockServiceHandler make(Context context) { <|endfocus|> HandlerThread t = new HandlerThread("mock-service-handler"); t.start(); return new MockServiceHandler(t.getLooper(), context);
<|startcomment|> is this if statement always true? <|endcomment|>  mConnected.countDown(); return; case AsyncChannel.CMD_CHANNEL_DISCONNECTED: Log.e(TAG, "Channel lost"); return; default: break; } final NsdServiceInfo ns = getNsdService(key); final Object listener = getListener(key); if (listener == null) { <|startfocus|> // Expected for replies/timouts to resolveService() if (what != RESOLVE_SERVICE_SUCCEEDED || what != RESOLVE_SERVICE_FAILED || what != RESOLVE_SERVICE_TIMEOUT) { Log.d(TAG, "Stale key " + key); } <|endfocus|> return; } if (DBG) { Log.d(TAG, "received " + nameOf(what) + " for key " + key + ", service " + ns); } switch (what) { case DISCOVER_SERVICES_STARTED: String s = getNsdServiceInfoType((NsdServiceInfo) message.obj); ((DiscoveryListener) listener).onDiscoveryStarted(s); break; case DISCOVER_SERVICES_FAILED: removeListener(key); ((DiscoveryListener) listener).onStartDiscoveryFailed(getNsdServiceInfoType(ns), message.arg1); break; case SERVICE_FOUND:
<|startcomment|> "in the Bluetooth address" <|endcomment|>  * * This extra represents the previous connection state. */ public static final String EXTRA_PREVIOUS_CONNECTION_STATE = "android.bluetooth.adapter.extra.PREVIOUS_CONNECTION_STATE"; /** * Broadcast Action: The Bluetooth adapter state has changed in LE only mode. * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; /** <|startfocus|> * Intent used to broadcast the change in MAC address of the * local Bluetooth adapter. <|endfocus|> * <p>Always contains the extra field {@link * #EXTRA_BLUETOOTH_ADDRESS} containing the MAC address. * * Note: only system level processes are allowed to send this * defined broadcast. * * @hide */ public static final String ACTION_BLUETOOTH_ADDRESS_CHANGED = "android.bluetooth.adapter.action.BLUETOOTH_ADDRESS_CHANGED"; /** * Used as a String extra field in {@link * #ACTION_BLUETOOTH_ADDRESS_CHANGED} intent to store the local * Bluetooth MAC address. *
<|startcomment|> Bluetooth <|endcomment|>  "android.bluetooth.adapter.extra.PREVIOUS_CONNECTION_STATE"; /** * Broadcast Action: The Bluetooth adapter state has changed in LE only mode. * @hide */ @SystemApi public static final String ACTION_BLE_STATE_CHANGED = "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; /** * Intent used to broadcast the change in MAC address of the * local Bluetooth adapter. * <p>Always contains the extra field {@link <|startfocus|> * #EXTRA_BLUETOOTH_ADDRESS} containing the MAC address. <|endfocus|> * * Note: only system level processes are allowed to send this * defined broadcast. * * @hide */ public static final String ACTION_BLUETOOTH_ADDRESS_CHANGED = "android.bluetooth.adapter.action.BLUETOOTH_ADDRESS_CHANGED"; /** * Used as a String extra field in {@link * #ACTION_BLUETOOTH_ADDRESS_CHANGED} intent to store the local * Bluetooth MAC address. * * @hide */ public static final String EXTRA_BLUETOOTH_ADDRESS = "android.bluetooth.adapter.extra.BLUETOOTH_ADDRESS"; 
<|startcomment|> Not needed <|endcomment|>  * <p>Always contains the extra field {@link * #EXTRA_BLUETOOTH_ADDRESS} containing the MAC address. * * Note: only system level processes are allowed to send this * defined broadcast. * * @hide */ public static final String ACTION_BLUETOOTH_ADDRESS_CHANGED = "android.bluetooth.adapter.action.BLUETOOTH_ADDRESS_CHANGED"; /** * Used as a String extra field in {@link * #ACTION_BLUETOOTH_ADDRESS_CHANGED} intent to store the local <|startfocus|> * Bluetooth MAC address. <|endfocus|> * * @hide */ public static final String EXTRA_BLUETOOTH_ADDRESS = "android.bluetooth.adapter.extra.BLUETOOTH_ADDRESS"; /** * Broadcast Action: The notifys Bluetooth ACL connected event. This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON. This denotes GATT connection * as Bluetooth LE is the only feature available in STATE_BLE_ON * * This is counterpart of {@link BluetoothDevice#ACTION_ACL_CONNECTED} which
<|startcomment|> "MAC" not needed. <|endcomment|>  String newName = intent.getStringExtra(BluetoothAdapter.EXTRA_LOCAL_NAME); if (DBG) Slog.d(TAG, "Bluetooth Adapter name changed to " + newName); if (newName != null) { storeNameAndAddress(newName, null); } } else if (BluetoothAdapter.ACTION_BLUETOOTH_ADDRESS_CHANGED.equals(action)) { String newAddress = intent.getStringExtra(BluetoothAdapter.EXTRA_BLUETOOTH_ADDRESS); if (newAddress != null) { <|startfocus|> if (DBG) Slog.d(TAG, "Bluetooth Adapter MAC Address changed to " + newAddress); <|endfocus|> storeNameAndAddress(null, newAddress); } else { if (DBG) Slog.e(TAG, "No Bluetooth Adapter MAC Address parameter found"); } }
<|startcomment|> Same comment as above. <|endcomment|>  if (newName != null) { storeNameAndAddress(newName, null); } } else if (BluetoothAdapter.ACTION_BLUETOOTH_ADDRESS_CHANGED.equals(action)) { String newAddress = intent.getStringExtra(BluetoothAdapter.EXTRA_BLUETOOTH_ADDRESS); if (newAddress != null) { if (DBG) Slog.d(TAG, "Bluetooth Adapter MAC Address changed to " + newAddress); storeNameAndAddress(null, newAddress); } else { <|startfocus|> if (DBG) Slog.e(TAG, "No Bluetooth Adapter MAC Address parameter found"); <|endfocus|> } }
<|startcomment|> You can reuse the "filter" variable here: filter = new IntentFilter(...); ... <|endcomment|>  mErrorRecoveryRetryCounter = 0; mContentResolver = context.getContentResolver(); // Observe BLE scan only mode settings change. registerForBleScanModeChange(); mCallbacks = new RemoteCallbackList<IBluetoothManagerCallback>(); mStateChangeCallbacks = new RemoteCallbackList<IBluetoothStateChangeCallback>(); IntentFilter filter = new IntentFilter(BluetoothAdapter.ACTION_LOCAL_NAME_CHANGED); filter.setPriority(IntentFilter.SYSTEM_HIGH_PRIORITY); mContext.registerReceiver(mReceiver, filter); <|startfocus|> IntentFilter filter2 = new IntentFilter(BluetoothAdapter.ACTION_BLUETOOTH_ADDRESS_CHANGED); filter2.setPriority(IntentFilter.SYSTEM_HIGH_PRIORITY); mContext.registerReceiver(mReceiver, filter2); <|endfocus|> loadStoredNameAndAddress(); if (isBluetoothPersistedStateOn()) { if (DBG) Slog.d(TAG, "Startup: Bluetooth persisted state is ON."); mEnableExternal = true; } String airplaneModeRadios = Settings.Global.getString(mContentResolver, Settings.Global.AIRPLANE_MODE_RADIOS); if (airplaneModeRadios == null || airplaneModeRadios.contains(Settings.Global.RADIO_BLUETOOTH)) { mContentResolver.registerContentObserver( Settings.Global.getUriFor(Settings.Global.AIRPLANE_MODE_ON), true, mAirplaneModeObserver); } 
<|startcomment|> My preference is to move away from the obsoleted "BD" acronym and replace it with, say, "BT" or "BLUETOOTH" in the names. Same comment applies to the rest of the changes. <|endcomment|>  "android.bluetooth.adapter.action.BLE_STATE_CHANGED"; /** * Intent used to broadcast the change in MAC address of the * local Bluetooth adapter. * <p>Always contains the extra field {@link #EXTRA_BD_ADDR} * containing the MAC address. * * Note: only system level processes are allowed to send this * defined broadcast * * @hide */ <|startfocus|> public static final String ACTION_BD_ADDR_CHANGED = "android.bluetooth.adapter.action.BD_ADDR_CHANGED"; <|endfocus|> /** * Used as a String extra field in {@link * #ACTION_BD_ADDR_CHANGED} intent to store the local Bluetooth * MAC address. * * @hide */ public static final String EXTRA_BD_ADDR = "android.bluetooth.adapter.extra.BD_ADDR"; /** * Broadcast Action: The notifys Bluetooth ACL connected event. This will be * by BLE Always on enabled application to know the ACL_CONNECTED event * when Bluetooth state in STATE_BLE_ON. This denotes GATT connection
<|startcomment|> The tabbing here looks a little strange. <|endcomment|>  Log.d(TAG, "Notification cancel " + mDevice.getAddress() + " (" + mDevice.getName() + ")"); mDevice.cancelPairingUserInput(); } else { int bondState = intent.getIntExtra(BluetoothDevice.EXTRA_BOND_STATE, BluetoothDevice.ERROR); Log.d(TAG, "Dismiss pairing for " + mDevice.getAddress() + " (" + mDevice.getName() + "), BondState: " + bondState); } stopForeground(true); stopSelf(); } }; <|startfocus|> @Override public void onCreate() { } <|endfocus|> @Override public int onStartCommand(Intent intent, int flags, int startId) { if (intent == null) { Log.e(TAG, "Can't start: null intent!"); stopSelf(); return START_NOT_STICKY; } Resources res = getResources(); Notification.Builder builder = new Notification.Builder(this) .setSmallIcon(android.R.drawable.stat_sys_data_bluetooth) .setTicker(res.getString(R.string.bluetooth_notif_ticker)); PendingIntent pairIntent = PendingIntent.getActivity(this, 0,
<|startcomment|> Ok for now, but the plan in public ICU is to still call the old version if millisInDay fits into an int. <|endcomment|>  } /** * This method can assume EXTENDED_YEAR has been set. * @param millis milliseconds of the date fields (local midnight millis) * @param millisInDay milliseconds of the time fields; may be out * or range. * @return total zone offset (raw + DST) for the given moment <|startfocus|> * @deprecated This method suffers from a potential integer overflow and may be removed in a * future release. Overriding this method in subclasses will not have the desired effect. * See ICU ticket #11632. <|endfocus|> */ protected int computeZoneOffset(long millis, int millisInDay) { int[] offsets = new int[2]; long wall = millis + millisInDay; if (zone instanceof BasicTimeZone) { int duplicatedTimeOpt = (repeatedWallTime == WALLTIME_FIRST) ? BasicTimeZone.LOCAL_FORMER : BasicTimeZone.LOCAL_LATTER; int nonExistingTimeOpt = (skippedWallTime == WALLTIME_FIRST) ? BasicTimeZone.LOCAL_LATTER : BasicTimeZone.LOCAL_FORMER;
<|startcomment|> 2017 <|endcomment|> <|startfocus|> * Copyright (C) 2016 The Android Open Source Project <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ public class Main { public static void main(String[] args) { System.loadLibrary(args[0]); testGetFieldId(TestClass.class, "intField", "I"); testGetFieldId(TestClass.class, "intField", "int"); testGetFieldId(TestClass.class, "intField", "Lint;"); testGetFieldId(TestClass.class, "stringField", "I");
<|startcomment|> just say "Android O" ? That's what it's called in the developer preview. <|endcomment|>  * <tr><td>Android 7.0 (Nougat)</td> * <td><a href="http://site.icu-project.org/download/56">ICU 56.1</a></td> * <td><a href="http://cldr.unicode.org/index/downloads/cldr-28">CLDR 28</a></td> * <td><a href="http://www.unicode.org/versions/Unicode8.0.0/">Unicode 8.0</a></td></tr> <|startfocus|> * <tr><td>Android (TBD)</td> <|endfocus|> * <td><a href="http://site.icu-project.org/download/58">ICU 58.2</a></td> * <td><a href="http://cldr.unicode.org/index/downloads/cldr-30">CLDR 30.0.3</a></td> * <td><a href="http://www.unicode.org/versions/Unicode9.0.0/">Unicode 9.0</a></td></tr> * </table> * * <a name="default_locale"></a><h4>Be wary of the default locale</h3> * <p>Note that there are many convenience methods that automatically use the default locale, but
<|startcomment|> That isn't necessary, 987 will test this. <|endcomment|>  // Disable native bind notify for now to avoid infinite loops. setNativeBindNotify(false); String transSym = SymbolMap.getOrDefault(method, nativeSym); System.out.println(method + " = " + nativeSym + " -> " + transSym); setNativeBindNotify(true); return transSym; } public static void doTest() throws Exception { Method say_hi_method = Transform.class.getDeclaredMethod("sayHi"); <|startfocus|> // Test we will autobind normally. <|endfocus|> Transform.sayHi2(); // Test we can get in the middle of autobind setNativeTransform(say_hi_method, "NoReallySayGoodbye"); Transform.sayHi(); // Test we can get in between manual bind. setNativeTransform(say_hi_method, "Java_art_Test986_00024Transform_sayHi2"); rebindTransformClass(); Transform.sayHi(); // Test we can get rid of transform removeNativeTransform(say_hi_method); rebindTransformClass(); Transform.sayHi(); Main.bindAgentJNIForClass(Main.class); Main.bindAgentJNIForClass(Test986.class); } // Functions called from native code.
<|startcomment|> Remove? <|endcomment|>  // Test we can get in the middle of autobind setNativeTransform(say_hi_method, "NoReallySayGoodbye"); Transform.sayHi(); // Test we can get in between manual bind. setNativeTransform(say_hi_method, "Java_art_Test986_00024Transform_sayHi2"); rebindTransformClass(); Transform.sayHi(); // Test we can get rid of transform removeNativeTransform(say_hi_method); rebindTransformClass(); Transform.sayHi(); <|startfocus|> Main.bindAgentJNIForClass(Main.class); Main.bindAgentJNIForClass(Test986.class); <|endfocus|> } // Functions called from native code. public static void doSayHi() { System.out.println("Hello"); } public static void doSayHi2() { System.out.println("Hello - 2"); } public static void doSayBye() { System.out.println("Bye"); } private static native void setNativeBindNotify(boolean enable); private static native void setupNativeBindNotify(); private static void rebindTransformClass() { rebindTransformClass(Transform.class); } private static native void rebindTransformClass(Class<?> trans); } 
<|startcomment|> Nit: "nc" -> "ns". <|endcomment|> <|startfocus|> private void ensureValidNetworkSpecifier(NetworkSpecifier nc) { MatchAllNetworkSpecifier.checkNotMatchAllNetworkSpecifier(nc); if (nc != null) { nc.assertValidFromUid(Binder.getCallingUid()); <|endfocus|> }
<|startcomment|> 17 <|endcomment|> <|startfocus|> * Copyright (C) 2009 The Android Open Source Project <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.net.cts; import static com.android.server.NetworkManagementSocketTagger.resetKernelUidStats; import java.net.ServerSocket; import android.net.TrafficStats; import android.os.Process; import android.test.AndroidTestCase; import android.util.Log; import android.net.LocalSocket; import java.io.File; import java.io.BufferedReader; import java.io.FileNotFoundException; import java.io.FileReader; import java.io.FileWriter;
<|startcomment|> replace tabs with spaces <|endcomment|>  String line; Pattern ctrlDataPattern = Pattern.compile(PATTERN); while((line = qtaguidReader.readLine()) != null) { Matcher refCountMatcher = ctrlDataPattern.matcher(line); if(refCountMatcher.matches()) { if (refCountMatcher.group(TAG_INDEX).contains(Long.toHexString(fullTag)) && refCountMatcher.group(UID_INDEX).contains(Integer.toString(uid))) { refcnt_res = Integer.parseInt(refCountMatcher.group(REFCNT_INDEX)); Log.d(TAG, "result refcnt:" + refcnt_res); break; } } } <|startfocus|> qtaguidReader.close(); } catch (FileNotFoundException e) { fail("Not able to access qtaguid/ctrl: "+e); } catch (IOException e) { fail("file read error"); <|endfocus|> } return refcnt_res;
<|startcomment|> Consider letting the error bubble up <|endcomment|>  if (refCountMatcher.group(TAG_INDEX).contains(Long.toHexString(fullTag)) && refCountMatcher.group(UID_INDEX).contains(Integer.toString(uid))) { refcnt_res = Integer.parseInt(refCountMatcher.group(REFCNT_INDEX)); Log.d(TAG, "result refcnt:" + refcnt_res); break; } } } qtaguidReader.close(); } catch (FileNotFoundException e) { fail("Not able to access qtaguid/ctrl: "+e); } catch (IOException e) { fail("file read error"); <|startfocus|> } <|endfocus|> return refcnt_res;
<|startcomment|> Should we use mImsManager? <|endcomment|>  public boolean imsIsEnhanced4gLteModeSettingEnabledByPlatform() { <|startfocus|> return ImsManager.isVolteEnabledByPlatformForSlot(); <|endfocus|>
<|startcomment|> "syntactic sugar", perhaps? <|endcomment|>  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.internal.util; import android.annotation.Nullable; import libcore.util.Objects; import java.nio.ByteBuffer; import java.util.Arrays; import java.util.UUID; /** <|startfocus|> * A utility class for handling unsigned integers and unsigned arithmetics, as well as sugar methods * for ByteBuffer. Useful for networking and packet manipulations. <|endfocus|> * {@hide} */ public final class BitUtils { private BitUtils() {} public static boolean maskedEquals(long a, long b, long mask) { return (a & mask) == (b & mask); } public static boolean maskedEquals(byte a, byte b, byte mask) { return (a & mask) == (b & mask); } public static boolean maskedEquals(byte[] a, byte[] b, @Nullable byte[] mask) { if (a == null || b == null) return a == b;
<|startcomment|> Nit: space after '+'. <|endcomment|>  } try { // Verification of TestClass.test() used to crash when processing // the final abstract (erroneous) class. Class<?> tc = Class.forName("TestClass"); Method test = tc.getDeclaredMethod("test"); test.invoke(null); System.out.println("UNREACHABLE!"); } catch (InvocationTargetException ite) { if (ite.getCause() instanceof InstantiationError) { System.out.println( <|startfocus|> ite.getCause().getClass().getName() + ": " +ite.getCause().getMessage()); <|endfocus|> } else { ite.printStackTrace(System.out); } } catch (Throwable t) { t.printStackTrace(System.out); }
<|startcomment|> Be on the lookout for doclava or other warnings about the JavaDoc @deprecated not matching a @Deprecated. It wouldn't be hard to add a code-gen processor to do that if we had to. It can be done as a follow-up if it turns out to be needed / desired. <|endcomment|>  } return findPreviousZoneTransitionTime(tz, upperOffset, mid, lower); } /** * Compute the milliseconds in the day from the fields. This is a * value from 0 to 23:59:59.999 inclusive, unless fields are out of * range, in which case it can be an arbitrary value. This value * reflects local zone wall time. <|startfocus|> * @deprecated This method suffers from a potential integer overflow and may be removed in a future * release. Overriding this method in subclasses will not have the desired effect. See ICU * ticket #11632. <|endfocus|> */ protected int computeMillisInDay() { // Do the time portion of the conversion. int millisInDay = 0; // Find the best set of fields specifying the time of day. There // are only two possibilities here; the HOUR_OF_DAY or the // AM_PM and the HOUR. int hourOfDayStamp = stamp[HOUR_OF_DAY]; int hourStamp = Math.max(stamp[HOUR], stamp[AM_PM]);
<|startcomment|> NIT: Too long. No big deal, though. <|endcomment|>  } return findPreviousZoneTransitionTime(tz, upperOffset, mid, lower); } /** * Compute the milliseconds in the day from the fields. This is a * value from 0 to 23:59:59.999 inclusive, unless fields are out of * range, in which case it can be an arbitrary value. This value * reflects local zone wall time. <|startfocus|> * @deprecated This method suffers from a potential integer overflow and may be removed in a future * release. Overriding this method in subclasses will not have the desired effect. See ICU * ticket #11632. <|endfocus|> */ protected int computeMillisInDay() { // Do the time portion of the conversion. int millisInDay = 0; // Find the best set of fields specifying the time of day. There // are only two possibilities here; the HOUR_OF_DAY or the // AM_PM and the HOUR. int hourOfDayStamp = stamp[HOUR_OF_DAY]; int hourStamp = Math.max(stamp[HOUR], stamp[AM_PM]);
<|startcomment|> That doesn't look right, this constructor exits upstream? You probably meant to document the other constructor around line 323? Also, wording nit: (here and below) "Needed To" / "Needed for" is redundant. It could be worth saying "Constructor to" or similar, since when looking at the diff spreadsheet, it's good for the comments to be meaningful without needing to see the code. E.g. in this particular case, "Android-added: Constructor to retain original encoded form for PKCS7." or "Android-added: Constructor to retain original encoded form, for internal use." or so. <|endcomment|>  * empty String if no provider was explicitly specified. */ private String verifiedProvider; /** * If verifiedPublicKey is not null, result of the verification using * verifiedPublicKey and verifiedProvider. If true, verification was * successful, if false, it failed. */ private boolean verificationResult; /** * Default constructor. */ public X509CertImpl() { } <|startfocus|> // BEGIN Android-added: Needed To retain original encoded form in PKCS7. <|endfocus|> /** * Unmarshals a certificate from its encoded form, parsing the * encoded bytes. This form of constructor is used by agents which * need to examine and use certificate contents. That is, this is * one of the more commonly used constructors. Note that the buffer * must include only a certificate, and no "garbage" may be left at * the end. If you need to ignore data at the end of a certificate, * use another constructor. * * @param certData the encoded bytes, with no trailing padding.
<|startcomment|> Could optionally add a comment, e.g. ": unused code." or similar. (That was the justification given in commit 7b5c7bb3e2ac90c7622a1ce42d4a7d149cc63ad9, which commented this out). <|endcomment|>  * * @param certData the encoded bytes, with no trailing padding. * @exception CertificateException on parsing and initialization errors. */ public X509CertImpl(byte[] certData) throws CertificateException { try { parse(new DerValue(certData)); } catch (IOException e) { signedCert = null; throw new CertificateException("Unable to initialize, " + e, e); } } // END Android-added: Needed To retain original encoded form in PKCS7. <|startfocus|> // BEGIN Android-removed <|endfocus|> /* /** * unmarshals an X.509 certificate from an input stream. If the * certificate is RFC1421 hex-encoded, then it must begin with * the line X509Factory.BEGIN_CERT and end with the line * X509Factory.END_CERT. * * @param in an input stream holding at least one certificate that may * be either DER-encoded or RFC1421 hex-encoded version of the * DER-encoded certificate. * @exception CertificateException on parsing and initialization errors. *
<|startcomment|> this is repeated at line 187 - 190. Can you refactor them into a method and call it from both places? <|endcomment|>  public void onRestoreInstanceState(Bundle savedInstanceState) { if (savedInstanceState != null) { super.onRestoreInstanceState(savedInstanceState); DialogState dialogState = mDialogState.valueOf(savedInstanceState.getString(DIALOG_STATE)); String msg = savedInstanceState.getString(DIALOG_MSG_STRING); updateDialog(dialogState, msg); if (dialogState == DialogState.WPS_START) { <|startfocus|> WpsInfo wpsConfig = new WpsInfo(); wpsConfig.setup = mWpsSetup; mWifiManager.startWps(wpsConfig, mWpsListener); <|endfocus|> } }
<|startcomment|> long? (used as a long below) <|endcomment|> import java.util.Arrays; import java.nio.ByteBuffer; import javax.obex.ServerRequestHandler; import javax.obex.ResponseCodes; import javax.obex.ApplicationParameter; import javax.obex.Operation; import javax.obex.HeaderSet; public class BluetoothPbapObexServer extends ServerRequestHandler { private static final String TAG = "BluetoothPbapObexServer"; private static final boolean D = BluetoothPbapService.DEBUG; private static final boolean V = BluetoothPbapService.VERBOSE; private static final int UUID_LENGTH = 16; <|startfocus|> public static final int INVALID_VALUE_PARAMETER = -1; <|endfocus|> // The length of suffix of vcard name - ".vcf" is 5 private static final int VCARD_NAME_SUFFIX_LENGTH = 5; // 128 bit UUID for PBAP private static final byte[] PBAP_TARGET = new byte[] { 0x79, 0x61, 0x35, (byte)0xf0, (byte)0xf0, (byte)0xc5, 0x11, (byte)0xd8, 0x09, 0x66, 0x08, 0x00, 0x20, 0x0c, (byte)0x9a, 0x66 }; 
<|startcomment|> These should be constants defined somewhere else, probably above. <|endcomment|>  pushResult = ResponseCodes.OBEX_HTTP_INTERNAL_ERROR; } if (!closeStream(outputStream, op)) { pushResult = ResponseCodes.OBEX_HTTP_INTERNAL_ERROR; } return pushResult; } private final int handleAppParaForResponse( AppParamValue appParamValue, int size, HeaderSet reply, Operation op, String name) { byte[] misnum = new byte[1]; ApplicationParameter ap = new ApplicationParameter(); <|startfocus|> long folderVersionCounterbitMask = 0x0008; long databaseIdentifierBitMask = 0x0004; <|endfocus|> boolean needSendCallHistoryVersionCounters = false; if (isNameMatchTarget(name, MCH) || isNameMatchTarget(name, ICH) || isNameMatchTarget(name, OCH) || isNameMatchTarget(name, CCH)) needSendCallHistoryVersionCounters = checkPbapFeatureSupport(folderVersionCounterbitMask); boolean needSendPhonebookVersionCounters = false; if (isNameMatchTarget(name, PB)) needSendPhonebookVersionCounters = checkPbapFeatureSupport(folderVersionCounterbitMask); // In such case, PCE only want the number of index. // So response not contain any Body header. if (mNeedPhonebookSize) {
<|startcomment|> nit: format <|endcomment|>  boolean status = sdpManager.removeSdpRecord(mSdpHandle); Log.d(TAG, "RemoveSDPrecord returns " + status); mSdpHandle = -1; } mSdpHandle = SdpManager.getDefaultManager().createPbapPseRecord( "OBEX Phonebook Access Server", mServerSockets.getRfcommChannel(), mServerSockets.getL2capPsm(), SDP_PBAP_SERVER_VERSION, SDP_PBAP_SUPPORTED_REPOSITORIES, SDP_PBAP_SUPPORTED_FEATURES); <|startfocus|> // Here we might have changed crucial data, hence reset DB // identifier <|endfocus|> updateDbIdentifier(); if (DEBUG) Log.d(TAG, "PBAP server with handle:" + mSdpHandle); }
<|startcomment|> nit: format <|endcomment|>  intent.putExtra(BluetoothDevice.EXTRA_PACKAGE_NAME, getPackageName()); mIsWaitingAuthorization = true; sendOrderedBroadcast(intent, BLUETOOTH_ADMIN_PERM); if (VERBOSE) Log.v(TAG, "waiting for authorization for connection from: " + sRemoteDeviceName); // In case car kit time out and try to use HFP for // phonebook // access, while UI still there waiting for user to // confirm mSessionStatusHandler.sendMessageDelayed( mSessionStatusHandler.obtainMessage(USER_TIMEOUT), USER_CONFIRM_TIMEOUT_VALUE); <|startfocus|> // We will continue the process when we receive // BluetoothDevice.ACTION_CONNECTION_ACCESS_REPLY from Settings app. <|endfocus|> } return true;
<|startcomment|> ? <|endcomment|>  + startPointId; } String selection; if (typeSelection == null) { selection = recordSelection; } else { selection = "(" + typeSelection + ") AND (" + recordSelection + ")"; } if (V) Log.v(TAG, "Call log query selection is: " + selection); <|startfocus|> /*return composeCallLogsAndSendSelectedVCards(op, selection, vcardType21, needSendBody, pbSize, null, ignorefilter, filter, vcardselector, vcardselectorop);*/ <|endfocus|> return composeCallLogsAndSendSelectedVCards(op, selection, vcardType21, needSendBody, pbSize, null, ignorefilter, filter, vcardselector, vcardselectorop, vcardselect); } final int composeAndSendPhonebookVcards(Operation op, final int startPoint, final int endPoint, final boolean vcardType21, String ownerVCard, int needSendBody, int pbSize, boolean ignorefilter, byte[] filter, byte[] vcardselector, String vcardselectorop, boolean vcardselect) { if (startPoint < 1 || startPoint > endPoint) { Log.e(TAG, "internal error: startPoint or endPoint is not correct."); return ResponseCodes.OBEX_HTTP_INTERNAL_ERROR; } 
<|startcomment|> nit: it looks like clang reformatted this comment <|endcomment|>  public String onValueReceived( String rawValue, int type, String label, boolean isPrimary) { <|startfocus|> // 'p' and 'w' are the standard characters for pause and // wait // (see RFC 3601) // so use those when exporting phone numbers via vCard. <|endfocus|> String numberWithControlSequence = rawValue.replace(PhoneNumberUtils.PAUSE, 'p') .replace(PhoneNumberUtils.WAIT, 'w'); return numberWithControlSequence;
<|startcomment|> nit: reformat <|endcomment|>  public String onValueReceived( String rawValue, int type, String label, boolean isPrimary) { <|startfocus|> // 'p' and 'w' are the standard characters for pause and // wait // (see RFC 3601) // so use those when exporting phone numbers via vCard. <|endfocus|> String numberWithControlSequence = rawValue.replace(PhoneNumberUtils.PAUSE, 'p') .replace(PhoneNumberUtils.WAIT, 'w'); return numberWithControlSequence;
<|startcomment|> Is this an error? <|endcomment|>  private boolean checkprop(String vcard, String prop) { String lines[] = vcard.split(SEPARATOR); boolean isPresent = false; for (String line : lines) { if (!Character.isWhitespace(line.charAt(0)) && !line.startsWith("=")) { String currentProp = line.split("[;:]")[0]; if (prop.equals(currentProp)) { <|startfocus|> Log.e(TAG, "bit.prop.equals current prop :" + prop); <|endfocus|> isPresent = true; return isPresent; } } } return isPresent;
<|startcomment|> Is this an error? <|endcomment|>  private boolean CheckVcardSelector(String vcard, String vcardselectorop) { boolean selectedIn = true; for (PropertyMask bit : PropertyMask.values()) { if (checkbit(bit.pos, selector)) { <|startfocus|> Log.e(TAG, "checking for prop :" + bit.prop); <|endfocus|> if (vcardselectorop.equals("0")) { if (checkprop(vcard, bit.prop)) { Log.e(TAG, "bit.prop.equals current prop :" + bit.prop); selectedIn = true; break; } else { selectedIn = false; } } else if (vcardselectorop.equals("1")) { if (!checkprop(vcard, bit.prop)) { Log.e(TAG, "bit.prop.notequals current prop" + bit.prop); selectedIn = false; return selectedIn; } else { selectedIn = true; } } } } return selectedIn;
<|startcomment|> Is this an error? <|endcomment|>  private boolean CheckVcardSelector(String vcard, String vcardselectorop) { boolean selectedIn = true; for (PropertyMask bit : PropertyMask.values()) { if (checkbit(bit.pos, selector)) { Log.e(TAG, "checking for prop :" + bit.prop); if (vcardselectorop.equals("0")) { if (checkprop(vcard, bit.prop)) { <|startfocus|> Log.e(TAG, "bit.prop.equals current prop :" + bit.prop); <|endfocus|> selectedIn = true; break; } else { selectedIn = false; } } else if (vcardselectorop.equals("1")) { if (!checkprop(vcard, bit.prop)) { Log.e(TAG, "bit.prop.notequals current prop" + bit.prop); selectedIn = false; return selectedIn; } else { selectedIn = true; } } } } return selectedIn;
<|startcomment|> ERROR: /usr/local/google/buildbot/src/android/master/packages/apps/Bluetooth/src/com/android/bluetooth/pbap/BluetoothPbapService.java:965.13: The method getPbapDbParams() is undefined for the type BluetoothPbapService <|endcomment|>  boolean status = sdpManager.removeSdpRecord(mSdpHandle); Log.d(TAG, "RemoveSDPrecord returns " + status); mSdpHandle = -1; } mSdpHandle = SdpManager.getDefaultManager().createPbapPseRecord( "OBEX Phonebook Access Server", mServerSockets.getRfcommChannel(), mServerSockets.getL2capPsm(), SDP_PBAP_SERVER_VERSION, SDP_PBAP_SUPPORTED_REPOSITORIES, SDP_PBAP_SUPPORTED_FEATURES); <|startfocus|> // fetch DbIdentifier to check if significant change has happened to Db getPbapDbParams(); <|endfocus|> if (DEBUG) Log.d(TAG, "PBAP server with handle:" + mSdpHandle); }
<|startcomment|> Few lines below you print "No device is connected" log message. For consistency, the same (or similar - as appropriate) log message should be printed here as well. Alternatively, use this "if" check outside the "for" loop. <|endcomment|>  private boolean initialize() { Log.d(TAG, "Start initialize()"); mPMCStatusLogger = new PMCStatusLogger(TAG + ".log", TAG); // Check if any Bluetooth devices are connected ArrayList<BluetoothDevice> results = new ArrayList<BluetoothDevice>(); Set<BluetoothDevice> bondedDevices = mBluetoothAdapter.getBondedDevices(); <|startfocus|> if (bondedDevices == null) return false; <|endfocus|> for (BluetoothDevice bd : bondedDevices) { if (bd.isConnected()) { results.add(bd); } } if (results.isEmpty()) { Log.e(TAG, "No device is connected"); return false; } Log.d(TAG, "Finish initialize()"); return true;
<|startcomment|> Could the getBondedDevices() return value be null? If "yes", then you need to consider that. <|endcomment|>  private boolean initialize() { Log.d(TAG, "Start initialize()"); mPMCStatusLogger = new PMCStatusLogger(TAG + ".log", TAG); // Check if any BT devices are connected ArrayList<BluetoothDevice> results = new ArrayList<BluetoothDevice>(); <|startfocus|> for (BluetoothDevice bd : mBluetoothAdapter.getBondedDevices()) { <|endfocus|> if (bd.isConnected()) { results.add(bd); } } if (results.isEmpty()) { Log.e(TAG, "No device is connected"); return false; } Log.d(TAG, "Finish initialize()"); return true;
<|startcomment|> BT -> Bluetooth Same applies to the rest of the CL below (when using BT in comments). <|endcomment|>  boolean bt_off_mute = false; Bundle extras = intent.getExtras(); if (extras == null) { Log.e(TAG, "No parameters specified"); return; } // Always initialize() if (!initialize()) { mPMCStatusLogger.logStatus("initialize() Failed"); return; } // Check if it is baseline BT is on but not stream if (extras.containsKey("BT_ON_NotPlay")) { <|startfocus|> Log.v(TAG, "NotPlay is specified for baseline case of only BT on"); <|endfocus|> // Do nothing further mPMCStatusLogger.logStatus("READY"); mPMCStatusLogger.logStatus("SUCCEED"); return; } if (!extras.containsKey("PlayTime")) { Log.e(TAG, "No Play Time specified"); return; } tmpStr = extras.getString("PlayTime"); Log.d(TAG, "Play Time = " + tmpStr); playTime = Integer.valueOf(tmpStr); if (!extras.containsKey("MusicURL")) { Log.e(TAG, "No Music URL specified"); return; }
<|startcomment|> typo <|endcomment|>  Log.e(TAG, "No Play Time specified"); return; } tmpStr = extras.getString("PlayTime"); Log.d(TAG, "Play Time = " + tmpStr); playTime = Integer.valueOf(tmpStr); if (!extras.containsKey("MusicURL")) { Log.e(TAG, "No Music URL specified"); return; } musicUrl = extras.getString("MusicURL"); Log.d(TAG, "Music URL = " + musicUrl); <|startfocus|> // playTime and musicUrl are necessory <|endfocus|> if (playTime == 0 || musicUrl.isEmpty() || musicUrl == null) { Log.d(TAG, "Invalid paramters"); return; } // Check if it is the baseline for BT off but streaming with speakers muted if (extras.containsKey("BT_OFF_Mute")) { Log.v(TAG, "Mute is specified for BT off baseline case"); bt_off_mute = true; } else { if (!extras.containsKey("CodecType")) { Log.e(TAG, "No Codec Type specified"); return; }
<|startcomment|> should these comments be marked TODO here as well as above? <|endcomment|>  public void testClientsCanConnect() { NsdService service = makeService(); NsdManager client1 = connectClient(service); NsdManager client2 = connectClient(service); <|startfocus|> // disconnect client1 // disconnect client2 <|endfocus|>
<|startcomment|> Think this should be explicit, if only by providing Charset.defaultCharset() as the argument. On Android defaultCharset() is guaranteed to be UTF-8, but using defaultCharset() is nicely self-documenting. <|endcomment|>  } public MockPrintStream(OutputStream os) { super(os); } @Override public void clearError() { super.clearError(); } @Override public void setError() { super.setError(); } } /** * {@link java.io.PrintStream#PrintStream(String)} */ public void test_Constructor_Ljava_lang_String() throws IOException { PrintStream os = new PrintStream(testFilePath); os.print(UNICODE_STRING); os.close(); <|startfocus|> assertFileContents(UNICODE_STRING.getBytes(), testFile); <|endfocus|> } /** * {@link java.io.PrintStream#PrintStream(String, String)} */ public void test_Constructor_Ljava_lang_String_Ljava_lang_String() throws Exception { // Test that a bogus charset is mentioned in the exception try { new PrintStream(testFilePath, "Bogus"); fail("Exception expected"); } catch (UnsupportedEncodingException e) { assertNotNull(e.getMessage()); } { PrintStream os = new PrintStream(testFilePath, "utf-8"); os.print(UNICODE_STRING); os.close();
<|startcomment|> Suggestion: true /* autoFlush */ because I had to go look it up. YMMV, up to you given the general readability of the existing code. Looks like we don't have any tests for autoFlush=false either, FWIW. We probably have some implicit tests (like this one) for autoflush = true. <|endcomment|>  public void test_ConstructorLjava_io_OutputStreamZLjava_lang_String() throws Exception { try { new PrintStream(new ByteArrayOutputStream(), false, "%Illegal_name!"); fail("Expected UnsupportedEncodingException"); } catch (UnsupportedEncodingException e) { // expected } { ByteArrayOutputStream bos = new ByteArrayOutputStream(); <|startfocus|> PrintStream printStream = new PrintStream(bos, true, "utf-8"); <|endfocus|> printStream.print(UNICODE_STRING); printStream.close(); assertByteArraysEqual(UNICODE_STRING.getBytes(StandardCharsets.UTF_8), bos.toByteArray()); } { ByteArrayOutputStream bos = new ByteArrayOutputStream(); PrintStream printStream = new PrintStream(bos, true, "utf-16"); printStream.print(UNICODE_STRING); printStream.close(); assertByteArraysEqual(UNICODE_STRING.getBytes(StandardCharsets.UTF_16), bos.toByteArray()); }
<|startcomment|> you can use Object.toString() to manage null refs for you and fold both branches into something like: pw.pringln("No active ApfFilter. Capabilities: " + Objects.toString(provisioningConfig.mApfCapabilities); <|endcomment|>  confirmConfiguration(); return; } // Thread-unsafe access to mApfFilter but just used for debugging. final ApfFilter apfFilter = mApfFilter; final ProvisioningConfiguration provisioningConfig = mConfiguration; IndentingPrintWriter pw = new IndentingPrintWriter(writer, " "); pw.println(mTag + " APF dump:"); pw.increaseIndent(); if (apfFilter != null) { apfFilter.dump(pw); } else { <|startfocus|> if (provisioningConfig != null) { pw.println("No active ApfFilter; provisioned capabilities: " + provisioningConfig.mApfCapabilities); } else { pw.println("N/A -- no ProvisioningConfiguration available"); } <|endfocus|> } pw.decreaseIndent(); pw.println(); pw.println(mTag + " current ProvisioningConfiguration:"); pw.increaseIndent(); pw.println((provisioningConfig != null) ? provisioningConfig : "N/A"); pw.decreaseIndent(); pw.println(); pw.println(mTag + " StateMachine dump:"); pw.increaseIndent(); mLocalLog.readOnlyLocalLog().dump(fd, pw, args); pw.decreaseIndent(); pw.println();
<|startcomment|> line too long. <|endcomment|>  return; } // Thread-unsafe access to mApfFilter but just used for debugging. final ApfFilter apfFilter = mApfFilter; final ProvisioningConfiguration provisioningConfig = mConfiguration; IndentingPrintWriter pw = new IndentingPrintWriter(writer, " "); pw.println(mTag + " APF dump:"); pw.increaseIndent(); if (apfFilter != null) { apfFilter.dump(pw); } else { <|startfocus|> if (provisioningConfig != null) { pw.println("No active ApfFilter; provisioned capabilities: " + provisioningConfig.mApfCapabilities); } else { pw.println("N/A -- no ProvisioningConfiguration available"); } <|endfocus|> } pw.decreaseIndent(); pw.println(); pw.println(mTag + " current ProvisioningConfiguration:"); pw.increaseIndent(); pw.println((provisioningConfig != null) ? provisioningConfig : "N/A"); pw.decreaseIndent(); pw.println(); pw.println(mTag + " StateMachine dump:"); pw.increaseIndent(); mLocalLog.readOnlyLocalLog().dump(fd, pw, args); pw.decreaseIndent(); pw.println();
<|startcomment|> Consider using Objects.toString(). <|endcomment|>  pw.increaseIndent(); if (apfFilter != null) { apfFilter.dump(pw); } else { if (provisioningConfig != null) { pw.println("No active ApfFilter; provisioned capabilities: " + provisioningConfig.mApfCapabilities); } else { pw.println("N/A -- no ProvisioningConfiguration available"); } } pw.decreaseIndent(); pw.println(); pw.println(mTag + " current ProvisioningConfiguration:"); pw.increaseIndent(); <|startfocus|> pw.println((provisioningConfig != null) ? provisioningConfig : "N/A"); <|endfocus|> pw.decreaseIndent(); pw.println(); pw.println(mTag + " StateMachine dump:"); pw.increaseIndent(); mLocalLog.readOnlyLocalLog().dump(fd, pw, args); pw.decreaseIndent(); pw.println(); pw.println(mTag + " connectivity packet log:"); pw.println(); pw.println("Debug with python and scapy via:"); pw.println("shell$ python"); pw.println(">>> from scapy import all as scapy");
<|startcomment|> I think the old code also tried to make sure key couldn't be equal to zero. (a) is that true and if so (b) should be check that here too? It's not immediately clear to me why zero is invalid. <|endcomment|>  private int putListener(Object listener, NsdServiceInfo s) { checkListener(listener); final int key; synchronized (mMapLock) { int valueIndex = mListenerMap.indexOfValue(listener); checkArgument(valueIndex == -1, "listener already in use"); <|startfocus|> key = Math.abs(mListenerKey++); <|endfocus|> mListenerMap.put(key, listener); mServiceMap.put(key, s); } return key;
<|startcomment|> nit: let's not mix camel and snake case <|endcomment|>  public void onOwnAddressRead(AdvertisingSet advertisingSet, int addressType, String address) { Log.d("onOwnAddressRead" + mEventType + " " + setIndex); Bundle results = new Bundle(); <|startfocus|> results.putInt("set_id", setIndex); <|endfocus|> results.putInt("addressType", addressType); results.putString("address", address); mEventFacade.postEvent(mEventType + setIndex + "onOwnAddressRead", results);
<|startcomment|> The downside of this is that we no longer can run this test against java (which I continue to use for reference from time to time). It would be nice to keep the java compatibility in some way (in a separate CL) <|endcomment|>  public void run() { <|startfocus|> byte[] annotatedDexContent = Base64.getDecoder().decode(base64DexWithExtensionClass); InMemoryDexClassLoader classLoader = new InMemoryDexClassLoader(ByteBuffer.wrap(annotatedDexContent), ClassLoader.getSystemClassLoader()); <|endfocus|> Class<?> klass = null; try { klass = classLoader.loadClass(classWithSourceDebugExtension); } catch (ClassNotFoundException e) { logWriter.println("--> Debuggee: Could not find class " + classWithSourceDebugExtension); } synchronizer.sendMessage(JPDADebuggeeSynchronizer.SGNL_READY); logWriter.println("--> Debuggee: SourceDebugExtensionDebuggee..."); synchronizer.receiveMessage(JPDADebuggeeSynchronizer.SGNL_CONTINUE);
<|startcomment|> This seems unrelated to the commit message. <|endcomment|> import android.media.MediaDescription; import android.media.MediaMetadata; import android.media.AudioManager; import android.media.session.MediaSessionManager; import android.os.Bundle; import android.os.Looper; import android.test.AndroidTestCase; import android.util.Log; import java.nio.ByteBuffer; import java.util.List; import java.util.Arrays; import java.util.ArrayList; import static org.mockito.Mockito.isA; import static org.mockito.Mockito.anyInt; import static org.mockito.Mockito.mock; import static org.mockito.Mockito.when; public class AvrcpTest extends AndroidTestCase { <|startfocus|> @Override public void setUp() { <|endfocus|> if (Looper.myLooper() == null) Looper.prepare(); } public void testCanBuild() { Avrcp a = Avrcp.make(getContext()); } public void testFailedBrowseStart() { Context mockContext = mock(Context.class); AudioManager mockAudioManager = mock(AudioManager.class); PackageManager mockPackageManager = mock(PackageManager.class); when(mockAudioManager.getStreamMaxVolume(AudioManager.STREAM_MUSIC)).thenReturn(100); when(mockContext.getSystemService(Context.AUDIO_SERVICE)).thenReturn(mockAudioManager); 
<|startcomment|> If length == 16 in ASCII is to be supported below, length == 32 also needs to be added here. <|endcomment|>  protected void setWifiConfigurationPassword( WifiConfiguration wifiConfiguration, WifiSecurity wifiSecurity, String password) { if (wifiSecurity == WifiSecurity.WEP) { int length = password.length(); // WEP-40, WEP-104, and 256-bit WEP (WEP-232?) <|startfocus|> if ((length == 10 || length == 26 || length == 58) <|endfocus|> && password.matches("[0-9A-Fa-f]*")) { wifiConfiguration.wepKeys[0] = password; } else if (length == 5 || length == 13 || length == 16) { wifiConfiguration.wepKeys[0] = '"' + password + '"'; } } else { if (wifiSecurity == WifiSecurity.PSK && password.length() < FormPageDisplayer.PSK_MIN_LENGTH) { return; } if (password.matches("[0-9A-Fa-f]{64}")) { wifiConfiguration.preSharedKey = password; } else { wifiConfiguration.preSharedKey = '"' + password + '"'; } }
<|startcomment|> Please explain why 256-bit WEP is excluded in this condition. <|endcomment|>  protected void setWifiConfigurationPassword( WifiConfiguration wifiConfiguration, WifiSecurity wifiSecurity, String password) { if (wifiSecurity == WifiSecurity.WEP) { int length = password.length(); // WEP-40, WEP-104, and 256-bit WEP (WEP-232?) if ((length == 10 || length == 26 || length == 58) && password.matches("[0-9A-Fa-f]*")) { wifiConfiguration.wepKeys[0] = password; <|startfocus|> } else if (length == 5 || length == 13 || length == 16) { <|endfocus|> wifiConfiguration.wepKeys[0] = '"' + password + '"'; } } else { if (wifiSecurity == WifiSecurity.PSK && password.length() < FormPageDisplayer.PSK_MIN_LENGTH) { return; } if (password.matches("[0-9A-Fa-f]{64}")) { wifiConfiguration.preSharedKey = password; } else { wifiConfiguration.preSharedKey = '"' + password + '"'; } }
<|startcomment|> Test also 1, -1, 0x100000000L, Long.MAX_VALUE, Long.MIN_VALUE. <|endcomment|>  0x8888888877777777L)); assertEqual(5L, $noinline$LongNonmatCondCst_LongVarVar2(0x7FFFFFFFFFFFFFFFL, 5L, 7L)); assertEqual(7L, $noinline$LongNonmatCondCst_LongVarVar2(2L, 5L, 7L)); assertEqual(7L, $noinline$LongNonmatCondCst_LongVarVar3(2L, 5L, 7L)); assertEqual(5L, $noinline$LongNonmatCondCst_LongVarVar4(0L, 5L, 7L)); assertEqual(7L, $noinline$LongNonmatCondCst_LongVarVar4(0xFFFFFFFF00000000L, 5L, 7L)); <|startfocus|> assertEqual(7L, $noinline$LongNonmatCondCst_LongVarVar5(0L, 5L, 7L)); assertEqual(5L, $noinline$LongNonmatCondCst_LongVarVar5(0xFFFFFFFF00000000L, 5L, 7L)); <|endfocus|> assertEqual(5L, $noinline$LongNonmatCondCst_LongVarVar6(0L, 5L, 7L)); assertEqual(5L, $noinline$LongNonmatCondCst_LongVarVar6(2L, 5L, 7L)); assertEqual(7L, $noinline$LongNonmatCondCst_LongVarVar6(-9000L, 5L, 7L)); 
<|startcomment|> Minor comment: though functionally there is no difference, something like import com.android.quicksearchbox.Suggestions; ... Suggestions suggestions = mSearchActivityView.getSuggestions(); if (suggestions == null) { return null; } return suggestions.getResult(); would be preferred. <|endcomment|>  protected SuggestionCursor getCurrentSuggestions() { if (mSearchActivityView.getSuggestions() == null) { return null; } <|startfocus|> return mSearchActivityView.getSuggestions().getResult(); <|endfocus|>
<|startcomment|> this can be misleading (given the name of the old filter). I suggest.. "..we need to make sure we are not interpreting all their code in that process." <|endcomment|>  // Make sure that core apps are optimized according to their own "reason". // If the core apps are not preopted in the B OTA, and REASON_AB_OTA is not speed // (by default is speed-profile) they will be interepreted/JITed. This in itself is // not a problem as we will end up doing profile guided compilation. However, some // core apps may be loaded by system server which doesn't JIT and we need to make <|startfocus|> // sure we don't interpret-only. <|endfocus|> int compilationReason = p.coreApp ? PackageManagerService.REASON_CORE_APP : PackageManagerService.REASON_AB_OTA; mDexoptCommands.addAll(generatePackageDexopts(p, compilationReason)); } for (PackageParser.Package p : others) { // We assume here that there are no core apps left. if (p.coreApp) { throw new IllegalStateException("Found a core app that's not important"); } mDexoptCommands.addAll( generatePackageDexopts(p, PackageManagerService.REASON_FIRST_BOOT)); } completeSize = mDexoptCommands.size(); 
<|startcomment|> SourceDebugExtension <|endcomment|>  classLoader = getClassLoaderInitializedWithDexFile(); } else { classLoader = getClassLoaderInitializedWithClassFile(); } Class<?> klass = null; try { klass = classLoader.loadClass(classWithSourceDebugExtension); } catch (ClassNotFoundException e) { logWriter.println("--> Debuggee: Could not find class " + classWithSourceDebugExtension); } // Create an instance of classWithSourceDebugExtension so the <|startfocus|> // SourceDebugExntension metadata can be reported back to the debugger. <|endfocus|> Object o = null; if (klass != null) { try { o = klass.getConstructor().newInstance(); } catch (Exception e) { logWriter.println("--> Debuggee: Failed to instantiate " + classWithSourceDebugExtension + ": " + e); } } synchronizer.sendMessage(JPDADebuggeeSynchronizer.SGNL_READY); logWriter.println("--> Debuggee: SourceDebugExtensionDebuggee..."); synchronizer.receiveMessage(JPDADebuggeeSynchronizer.SGNL_CONTINUE);
<|startcomment|> Naming convention for these is (might be easier to clean these up now than later when its hardcoded in the bowels of vendor code): android.telephony.mbms.action.DOWNLOAD_RESULT_INTERNAL Also, suggest: ACTION_DOWNLOAD_COMPLETE <|endcomment|>  /** * The MBMS middleware should send this when a download of single file has completed or * failed. Mandatory extras are * {@link #EXTRA_RESULT} * {@link #EXTRA_INFO} * {@link #EXTRA_REQUEST} * {@link #EXTRA_TEMP_LIST} * {@link #EXTRA_FINAL_URI} * * TODO: future systemapi */ public static final String ACTION_DOWNLOAD_RESULT_INTERNAL = <|startfocus|> "android.telephony.mbms.ACTION_DOWNLOAD_RESULT_INTERNAL"; <|endfocus|> /** * The MBMS middleware should send this when it wishes to request {@code content://} URIs to * serve as temp files for downloads or when it wishes to resume paused downloads. Mandatory * extras are * {@link #EXTRA_REQUEST} * * Optional extras are * {@link #EXTRA_FD_COUNT} (0 if not present) * {@link #EXTRA_PAUSED_LIST} (empty if not present) * * TODO: future systemapi */ public static final String ACTION_FILE_DESCRIPTOR_REQUEST =
<|startcomment|> This is just to cleanup a specified list of temp files, right? Might make more sense to just say The MBMS middleware sends this when it wishes to cleanup temporary files in the app's filesystem. <|endcomment|>  * * Optional extras are * {@link #EXTRA_FD_COUNT} (0 if not present) * {@link #EXTRA_PAUSED_LIST} (empty if not present) * * TODO: future systemapi */ public static final String ACTION_FILE_DESCRIPTOR_REQUEST = "android.telephony.mbms.ACTION_FILE_DESCRIPTOR_REQUEST"; /** <|startfocus|> * The MBMS middleware should send this when it wishes to signal that there may be orphaned * files in the app's filesystem. Mandatory extras are <|endfocus|> * {@link #EXTRA_TEMP_FILES_IN_USE} * * TODO: future systemapi */ public static final String ACTION_CLEANUP = "android.telephony.mbms.ACTION_CLEANUP"; /** * Integer extra indicating the result code of the download. * TODO: put in link to error list * TODO: future systemapi (here and and all extras) */ public static final String EXTRA_RESULT = "android.telephony.mbms.EXTRA_RESULT"; /** * Extra containing the {@link android.telephony.mbms.FileInfo} for which the download result
<|startcomment|> .action.CLEANUP_TEMP_FILES <|endcomment|>  * * TODO: future systemapi */ public static final String ACTION_FILE_DESCRIPTOR_REQUEST = "android.telephony.mbms.ACTION_FILE_DESCRIPTOR_REQUEST"; /** * The MBMS middleware should send this when it wishes to signal that there may be orphaned * files in the app's filesystem. Mandatory extras are * {@link #EXTRA_TEMP_FILES_IN_USE} * * TODO: future systemapi */ public static final String ACTION_CLEANUP = <|startfocus|> "android.telephony.mbms.ACTION_CLEANUP"; <|endfocus|> /** * Integer extra indicating the result code of the download. * TODO: put in link to error list * TODO: future systemapi (here and and all extras) */ public static final String EXTRA_RESULT = "android.telephony.mbms.EXTRA_RESULT"; /** * Extra containing the {@link android.telephony.mbms.FileInfo} for which the download result * is for. Must not be null. */ public static final String EXTRA_INFO = "android.telephony.mbms.EXTRA_INFO"; /**
<|startcomment|> Convention is: android.telephony.mbms.extra.RESULT <|endcomment|>  * files in the app's filesystem. Mandatory extras are * {@link #EXTRA_TEMP_FILES_IN_USE} * * TODO: future systemapi */ public static final String ACTION_CLEANUP = "android.telephony.mbms.ACTION_CLEANUP"; /** * Integer extra indicating the result code of the download. * TODO: put in link to error list * TODO: future systemapi (here and and all extras) */ <|startfocus|> public static final String EXTRA_RESULT = "android.telephony.mbms.EXTRA_RESULT"; <|endfocus|> /** * Extra containing the {@link android.telephony.mbms.FileInfo} for which the download result * is for. Must not be null. */ public static final String EXTRA_INFO = "android.telephony.mbms.EXTRA_INFO"; /** * Extra containing the {@link DownloadRequest} for which the download result or file * descriptor request is for. Must not be null. */ public static final String EXTRA_REQUEST = "android.telephony.mbms.EXTRA_REQUEST"; /**
<|startcomment|> Extra used with {@link #ACTION_FILE_DESCRIPTOR_REQUEST} <|endcomment|>  * decoded downloaded file resides. Must not be null. */ public static final String EXTRA_FINAL_URI = "android.telephony.mbms.EXTRA_FINAL_URI"; /** * Extra containing an integer indicating the number of temp files requested. */ public static final String EXTRA_FD_COUNT = "android.telephony.mbms.EXTRA_FD_COUNT"; /** * Extra containing a list of {@link Uri}s that the middleware is requesting write access to. */ <|startfocus|> public static final String EXTRA_PAUSED_LIST = "android.telephony.mbms.EXTRA_PAUSED_LIST"; <|endfocus|> /** * Extra containing a list of {@link android.telephony.mbms.UriPathPair}s, used in the * response to {@link #ACTION_FILE_DESCRIPTOR_REQUEST}. These are temp files that are meant * to be used for new file downloads. */ public static final String EXTRA_FREE_URI_LIST = "android.telephony.mbms.EXTRA_FREE_URI_LIST"; /** * Extra containing a list of {@link android.telephony.mbms.UriPathPair}s, used in the
<|startcomment|> will resume downloading? <|endcomment|>  * decoded downloaded file resides. Must not be null. */ public static final String EXTRA_FINAL_URI = "android.telephony.mbms.EXTRA_FINAL_URI"; /** * Extra containing an integer indicating the number of temp files requested. */ public static final String EXTRA_FD_COUNT = "android.telephony.mbms.EXTRA_FD_COUNT"; /** * Extra containing a list of {@link Uri}s that the middleware is requesting write access to. */ <|startfocus|> public static final String EXTRA_PAUSED_LIST = "android.telephony.mbms.EXTRA_PAUSED_LIST"; <|endfocus|> /** * Extra containing a list of {@link android.telephony.mbms.UriPathPair}s, used in the * response to {@link #ACTION_FILE_DESCRIPTOR_REQUEST}. These are temp files that are meant * to be used for new file downloads. */ public static final String EXTRA_FREE_URI_LIST = "android.telephony.mbms.EXTRA_FREE_URI_LIST"; /** * Extra containing a list of {@link android.telephony.mbms.UriPathPair}s, used in the
<|startcomment|> Convention is to use "Callback" when there are multiple methods; eg. DownloadManagerCallback <|endcomment|>  * still using. */ public static final String EXTRA_TEMP_FILES_IN_USE = "android.telephony.mbms.EXTRA_TEMP_FILES_IN_USE"; public static final int RESULT_SUCCESSFUL = 1; public static final int RESULT_CANCELLED = 2; public static final int RESULT_EXPIRED = 3; // TODO - more results! private final Context mContext; private int mSubId = INVALID_SUBSCRIPTION_ID; private IMbmsDownloadService mService; <|startfocus|> private final IMbmsDownloadManagerListener mCallback; <|endfocus|> private final String mDownloadAppName; public MbmsDownloadManager(Context context, IMbmsDownloadManagerListener callback, String downloadAppName, int subId) { mContext = context; mCallback = callback; mDownloadAppName = downloadAppName; mSubId = subId; } /** * Create a new MbmsDownloadManager using the system default data subscription ID. * * Note that this call will bind a remote service and that may take a bit. This * may throw an Illegal ArgumentException or RemoteException. * * @hide */
<|startcomment|> If you envision only using the createManager method, this should be private <|endcomment|> <|startfocus|> public MbmsDownloadManager(Context context, IMbmsDownloadManagerListener callback, <|endfocus|> String downloadAppName, int subId) { mContext = context; mCallback = callback; mDownloadAppName = downloadAppName; mSubId = subId;
<|startcomment|> private if the static are always doing to be used. <|endcomment|> <|startfocus|> public MbmsStreamingManager(Context context, IMbmsStreamingManagerListener listener, String streamingAppName, int subId) { <|endfocus|> mContext = context; mAppName = streamingAppName; mCallbackToApp = listener; mSubId = subId;
<|startcomment|> subscriptionId (Telephony convention is to use it in full). <|endcomment|> <|startfocus|> public MbmsStreamingManager(Context context, IMbmsStreamingManagerListener listener, String streamingAppName, int subId) { <|endfocus|> mContext = context; mAppName = streamingAppName; mCallbackToApp = listener; mSubId = subId;
<|startcomment|> nit: I'd prefer this to be above line 136, in the same order of the if statement. <|endcomment|>  mBrightnessMode != brightnessMode) { if (DEBUG) Slog.v(TAG, "setLight #" + mId + ": color=#" + Integer.toHexString(color) + ": brightnessMode=" + brightnessMode); mLastColor = mColor; mColor = color; mMode = mode; mOnMS = onMS; mOffMS = offMS; mBrightnessMode = brightnessMode; <|startfocus|> mInitialized = true; <|endfocus|> Trace.traceBegin(Trace.TRACE_TAG_POWER, "setLight(" + mId + ", 0x" + Integer.toHexString(color) + ")"); try { setLight_native(mNativePointer, mId, color, mode, onMS, offMS, brightnessMode); } finally { Trace.traceEnd(Trace.TRACE_TAG_POWER); } }
<|startcomment|> I'm not a big fan of having 5 different hash maps. Could we instead create a helper object that can be used to keep track of all this info? <|endcomment|>  public static boolean contactsLoaded = false; private static HashMap<String, ArrayList<String>> email = new HashMap<String, ArrayList<String>>(); private static HashMap<String, ArrayList<String>> phone = new HashMap<String, ArrayList<String>>(); private static HashMap<String, ArrayList<String>> address = new HashMap<String, ArrayList<String>>(); private static HashMap<String, String> name = new HashMap<String, String>(); private static HashSet<String> ContactSet = new HashSet<String>(); <|startfocus|> <|endfocus|> public static boolean hasFilter(byte[] filter) { return filter != null && filter.length > 0; } public static boolean isNameAndNumberOnly(byte[] filter) { // For vcard 2.0: VERSION,N,TEL is mandatory // For vcard 3.0, VERSION,N,FN,TEL is mandatory // So we only need to make sure that no other fields except optionally // NICKNAME is set // Check that an explicit filter is not set. If not, this means // return everything if (!hasFilter(filter)) {
<|startcomment|> packet <|endcomment|>  } public NetworkStats readNetworkStatsDetail(int limitUid, String[] limitIfaces, int limitTag, NetworkStats lastStats) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; // for recycling synchronized (sStackedIfaces) { <|startfocus|> // For 464xlat traffic, xt_qtaguid sees every IPv4 packets twice, once as an IPv4 packet // unwrapped on the stacked interface, and once as wrapped inside an IPv6 packet on the <|endfocus|> // base interface. For correct stats accounting on the base interface, every 464xlat // packets needs to be subtracted for the root UID on the base interface both for tx // and rx traffic (http://b/12249687, http:/b/33681750). final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust =
<|startcomment|> a native IPv4 packet <|endcomment|>  NetworkStats lastStats) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; // for recycling synchronized (sStackedIfaces) { // For 464xlat traffic, xt_qtaguid sees every IPv4 packets twice, once as an IPv4 packet // unwrapped on the stacked interface, and once as wrapped inside an IPv6 packet on the // base interface. For correct stats accounting on the base interface, every 464xlat <|startfocus|> // packets needs to be subtracted for the root UID on the base interface both for tx <|endfocus|> // and rx traffic (http://b/12249687, http:/b/33681750). final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L);
<|startcomment|> translated to <|endcomment|>  NetworkStats lastStats) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; // for recycling synchronized (sStackedIfaces) { // For 464xlat traffic, xt_qtaguid sees every IPv4 packets twice, once as an IPv4 packet // unwrapped on the stacked interface, and once as wrapped inside an IPv6 packet on the // base interface. For correct stats accounting on the base interface, every 464xlat <|startfocus|> // packets needs to be subtracted for the root UID on the base interface both for tx <|endfocus|> // and rx traffic (http://b/12249687, http:/b/33681750). final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L);
<|startcomment|> from <|endcomment|>  readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; // for recycling synchronized (sStackedIfaces) { // For 464xlat traffic, xt_qtaguid sees every IPv4 packets twice, once as an IPv4 packet // unwrapped on the stacked interface, and once as wrapped inside an IPv6 packet on the // base interface. For correct stats accounting on the base interface, every 464xlat <|startfocus|> // packets needs to be subtracted for the root UID on the base interface both for tx <|endfocus|> // and rx traffic (http://b/12249687, http:/b/33681750). final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) {
<|startcomment|> packet <|endcomment|>  readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; // for recycling synchronized (sStackedIfaces) { // For 464xlat traffic, xt_qtaguid sees every IPv4 packets twice, once as an IPv4 packet // unwrapped on the stacked interface, and once as wrapped inside an IPv6 packet on the // base interface. For correct stats accounting on the base interface, every 464xlat <|startfocus|> // packets needs to be subtracted for the root UID on the base interface both for tx <|endfocus|> // and rx traffic (http://b/12249687, http:/b/33681750). final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) {
<|startcomment|> I don't think so, no. That's an app-settable field which has nothing to do with bytes or packets. Also, IIRC it's not interface-specific. <|endcomment|>  for (int j = 0; j < stats.size(); j++) { entry = stats.getValues(j, entry); if (Objects.equals(entry.iface, stackedIface)) { adjust.rxBytes -= (entry.rxBytes + entry.rxPackets * IPV4V6_HEADER_DELTA); adjust.txBytes -= (entry.txBytes + entry.txPackets * IPV4V6_HEADER_DELTA); adjust.rxPackets -= entry.rxPackets; adjust.txPackets -= entry.txPackets; <|startfocus|> // TODO: does Entry#operations need to be adjusted too ? <|endfocus|> } } stats.combineValues(adjust); } } // For 464xlat traffic, xt_qtaguid only counts the bytes of the inner IPv4 packet sent on // the stacked interface with prefix "v4-" and drops the IPv6 header size after unwrapping. // To account correctly for on-the-wire traffic, adds the 20 additional bytes difference // for all packets (http://b/12249687, http:/b/33681750). for (int i = 0; i < stats.size(); i++) { entry = stats.getValues(i, entry);
<|startcomment|> add <|endcomment|>  adjust.rxPackets -= entry.rxPackets; adjust.txPackets -= entry.txPackets; // TODO: does Entry#operations need to be adjusted too ? } } stats.combineValues(adjust); } } // For 464xlat traffic, xt_qtaguid only counts the bytes of the inner IPv4 packet sent on // the stacked interface with prefix "v4-" and drops the IPv6 header size after unwrapping. <|startfocus|> // To account correctly for on-the-wire traffic, adds the 20 additional bytes difference <|endfocus|> // for all packets (http://b/12249687, http:/b/33681750). for (int i = 0; i < stats.size(); i++) { entry = stats.getValues(i, entry); if (entry.iface != null && entry.iface.startsWith(CLATD_INTERFACE_PREFIX)) { entry.rxBytes = entry.rxPackets * IPV4V6_HEADER_DELTA; entry.txBytes = entry.txPackets * IPV4V6_HEADER_DELTA; entry.rxPackets = 0; entry.txPackets = 0; stats.combineValues(entry); } } return stats; } 
<|startcomment|> "not" <|endcomment|>  private static final String CLATD_INTEFACE_PREFIX = "v4-"; /** Path to {@code /proc/net/xt_qtaguid/iface_stat_all}. */ private final File mStatsXtIfaceAll; /** Path to {@code /proc/net/xt_qtaguid/iface_stat_fmt}. */ private final File mStatsXtIfaceFmt; /** Path to {@code /proc/net/xt_qtaguid/stats}. */ private final File mStatsXtUid; <|startfocus|> // TODO: for testability, do no use a static variable. <|endfocus|> @GuardedBy("sStackedIfaces") private static final ArrayMap<String, String> sStackedIfaces = new ArrayMap<>(); public static void noteStackedIface(String stackedIface, String baseIface) { synchronized (sStackedIfaces) { if (baseIface != null) { sStackedIfaces.put(stackedIface, baseIface); } else { sStackedIfaces.remove(stackedIface); } } } public NetworkStatsFactory() { this(new File("/proc/")); } @VisibleForTesting public NetworkStatsFactory(File procRoot) {
<|startcomment|> I see that NetworkStats.Entry has an add method (that modifies |operations| as well). Two questions: [1] should it have a subtract() method? [2] should we be fixing up |operations| as well? <|endcomment|>  // from root UID on the base interface. NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) { entry = stats.getValues(j, entry); if (Objects.equals(entry.iface, stackedIface)) { <|startfocus|> adjust.txBytes -= entry.txBytes; adjust.txPackets -= entry.txPackets; adjust.rxBytes -= entry.rxBytes; <|endfocus|> adjust.rxPackets -= entry.rxPackets; } } stats.combineValues(adjust); } } // Double sigh, all rx traffic on clat needs to be tweaked to // account for the dropped IPv6 header size post-unwrap. for (int i = 0; i < stats.size(); i++) { entry = stats.getValues(i, entry); if (entry.iface != null && entry.iface.startsWith(CLATD_INTEFACE_PREFIX)) { // Delta between IPv4 header (20b) and IPv6 header (40b) entry.rxBytes = entry.rxPackets * 20;
<|startcomment|> This appears to be incorrect. This should send the NSD_STATE_{ENABLED,DISABLED} values (1 and 2), in order to be consistent. Right? <|endcomment|>  private void sendNsdStateChangeBroadcast(boolean isEnabled) { final Intent intent = new Intent(NsdManager.ACTION_NSD_STATE_CHANGED); intent.addFlags(Intent.FLAG_RECEIVER_REGISTERED_ONLY_BEFORE_BOOT); <|startfocus|> intent.putExtra(NsdManager.EXTRA_NSD_STATE, enabledMessage(isEnabled)); <|endfocus|> mContext.sendStickyBroadcastAsUser(intent, UserHandle.ALL);
<|startcomment|> is you only ever access the key, why not just loop over bc.keySet() ? <|endcomment|>  for (String conscryptAlg : conscryptAlgs) { Provider.Service service = getService(bc, conscryptAlg); if (service != null) { bcClasses.add(service.getClassName()); } } assertTrue(bcClasses.size() > 0); // Sanity check // 3. Determine which IDs in BC point to that set of classes Set<String> shouldBeOverriddenBcIds = new HashSet<>(); <|startfocus|> for (Entry<Object, Object> entry : bc.entrySet()) { String key = (String) entry.getKey(); <|endfocus|> if (key.contains(" ")) { continue; } if (key.startsWith("Alg.Alias.")) { key = key.substring("Alg.Alias.".length()); } Provider.Service service = getService(bc, key); if (bcClasses.contains(service.getClassName())) { shouldBeOverriddenBcIds.add(key); } } // 4. Check each of those IDs to ensure that it's present in Conscrypt Set<String> nonOverriddenIds = new TreeSet<>(); for (String shouldBeOverridenBcId : shouldBeOverriddenBcIds) {
<|startcomment|> these three lines (153-155) do not occur upstream. Upon further investigation, they seem to have existed in 7u40 but not in 8u60 so we probably forgot to drop these in the update to 8u60? <|endcomment|>  * * This terminates at unescaped AVA separators ("+") or RDN * separators (",", ";"), and removes cosmetic whitespace at the end of * values. */ AVA(Reader in, Map<String, String> keywordMap) throws IOException { this(in, DEFAULT, keywordMap); } /** * Parse an AVA string formatted according to format. <|startfocus|> * * XXX format RFC1779 should only allow RFC1779 syntax but is * actually DEFAULT with RFC1779 keywords. <|endfocus|> */ AVA(Reader in, int format) throws IOException { this(in, format, Collections.<String, String>emptyMap()); } /** * Parse an AVA string formatted according to format. * * @param in Reader containing AVA String * @param format parsing format * @param keywordMap a Map where a keyword String maps to a corresponding * OID String. Each AVA keyword will be mapped to the corresponding OID. * If an entry does not exist, it will fallback to the builtin
<|startcomment|> should be BEGIN/END, and the comment doesn't seem accurate because this also skips over newlines. The commit message of the CL that introduced this was: "AVA: Support hex-strings that have contain ' ' or an '\n'" so how about: // BEGIN Android-added: AVA: Support DerValue hex strings that contain ' ' or '\n' ? <|endcomment|>  return s; } catch (IOException e) { // should not occur throw new RuntimeException("AVA error: " + e, e); } } private static DerValue parseHexString (Reader in, int format) throws IOException { int c; ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte b = 0; int cNdx = 0; while (true) { c = in.read(); if (isTerminator(c, format)) { break; } <|startfocus|> // Android-changed: Skip trailing whitespace. <|endfocus|> if (c == ' ' || c == '\n') { do { if (c != ' ' && c != '\n') { throw new IOException("AVA parse, invalid hex " + "digit: "+ (char)c); } c = in.read(); } while (!isTerminator(c, format)); break; } int cVal = hexDigits.indexOf(Character.toUpperCase((char)c)); if (cVal == -1) { throw new IOException("AVA parse, invalid hex " +
<|startcomment|> Add // END Android-added: AVA: Support DerValue hex strings that contain ' ' or '\n' in line 285. <|endcomment|>  while (true) { c = in.read(); if (isTerminator(c, format)) { break; } // Android-changed: Skip trailing whitespace. if (c == ' ' || c == '\n') { do { if (c != ' ' && c != '\n') { throw new IOException("AVA parse, invalid hex " + "digit: "+ (char)c); } c = in.read(); } while (!isTerminator(c, format)); break; } <|startfocus|> <|endfocus|> int cVal = hexDigits.indexOf(Character.toUpperCase((char)c)); if (cVal == -1) { throw new IOException("AVA parse, invalid hex " + "digit: "+ (char)c); } if ((cNdx % 2) == 1) { b = (byte)((b * 16) + (byte)(cVal)); baos.write(b); } else { b = (byte)(cVal); } cNdx++; } // throw exception if no hex digits
<|startcomment|> "so they wouldn't remove spaces" is redundant, that's what trim() does. Personally, I'd prefer the line // Android-changed: Do not trim() DerValue strings. on each of the three lines that changed, together with the commented-out upstream code. There are not that many occurences, so I'd rather be specific. <|endcomment|>  temp.append(hexString); embeddedHex.clear(); } do { c = in.read(); } while ((c == '\n') || (c == ' ')); if (c != -1) { throw new IOException("AVA had characters other than " + "whitespace after terminating quote"); } // encode as PrintableString unless value contains // non-PrintableString chars <|startfocus|> // Android-changed: Removed .trim() from .toString calls so they wouldn't remove spaces <|endfocus|> if (this.oid.equals((Object)PKCS9Attribute.EMAIL_ADDRESS_OID) || (this.oid.equals((Object)X500Name.DOMAIN_COMPONENT_OID) && PRESERVE_OLD_DC_ENCODING == false)) { // EmailAddress and DomainComponent must be IA5String return new DerValue(DerValue.tag_IA5String, temp.toString()); } else if (isPrintableString) { return new DerValue(temp.toString()); } else { return new DerValue(DerValue.tag_UTF8String, temp.toString()); } } private DerValue parseString
<|startcomment|> The changes are actually quite localized in this file, so can we please keep these comments restricted to the small section where they are relevant, rather than at the top level? From what I can see, the only differences between Android and upstream, other than the ones already documented previously, are: 1.) an added short block of code in getName(): // Try to update the name <-> OID mapping table. synchronized (oidTable) { reinitializeMappingTableLocked(); algName = nameTable.get(algid); } 2.) A modified section towards the end of algOID() , consisting of code that was extracted into the helper method reinitializeMappingTableLocked(), and then modified. 2b) related to 2), eager initialization of nameTable and oidTable at the point where they are declared, whereas upstream initializes nameTable in the explicit static { .. } block. The initialization of nameTable doesn't look like it needs to differ from upstream. So adding these toplevel comments here seems like it needlessly obscures the small areas where these changes have been made, and loses us the chance of reverting the parts that can be reverted. <|endcomment|>  * This class is not a general repository for OIDs, or for such string names. * Note that the mappings between algorithm IDs and algorithm names is * not one-to-one. * * * @author David Brownell * @author Amit Kapoor * @author Hemma Prafullchandra */ <|startfocus|> // Android-changed: Parsing mapping as OID even if "OID." prefix isn't specified // Android-changed: Don't clobber existing entries in the AlgorithmId tables // Android-changed: Update algorithm mapping tables for names when OID is used <|endfocus|> public class AlgorithmId implements Serializable, DerEncoder { /** use serialVersionUID from JDK 1.1. for interoperability */ private static final long serialVersionUID = 7205873507486557157L; /** * The object identitifer being used for this algorithm. */ private ObjectIdentifier algid; // The (parsed) parameters private AlgorithmParameters algParams; private boolean constructedFromDer = true; /** * Parameters for this algorithm. These are stored in unparsed * DER-encoded form; subclasses can be made to automaticaly parse
<|startcomment|> Upstream seems to have made the exact same change here as Android (perhaps we upstreamed it), so this Android-changed documentation should go away. Also, upstream has an extra empty line after line 138 that we should also reintroduce, to minimize diffs. <|endcomment|>  } catch (NoSuchAlgorithmException e) { // BEGIN Android-changed // It was searching for the EC parameters in an internal provider in the deleted package // sun.security.ec before setting them to null. Since EC is in the OpenSSL provider, // there's no need for such fallback. Setting it to null directly. /* * This algorithm parameter type is not supported, so we cannot * parse the parameters. */ algParams = null; return; // END Android-changed <|startfocus|> } <|endfocus|> // Decode (parse) the parameters algParams.init(params.toByteArray()); } /** * Marshal a DER-encoded "AlgorithmID" sequence on the DER stream. */ public final void encode(DerOutputStream out) throws IOException { derEncode(out); } /** * DER encode this object onto an output stream. * Implements the <code>DerEncoder</code> interface. * * @param out * the output stream on which to write the DER encoding. * * @exception IOException on encoding error.
<|startcomment|> Nit: Isn't it the opposite of hard coding? Upstream has String literals, we refer to .class objects. How about: // BEGIN Android-changed: Specify Class objects rather for oidMap rather than String literals + reflection. <|endcomment|>  private static final String OCSPNOCHECK = ROOT + "." + OCSPNoCheckExtension.NAME; private static final int NetscapeCertType_data[] = { 2, 16, 840, 1, 113730, 1, 1 }; /** Map ObjectIdentifier(oid) -> OIDInfo(info) */ private final static Map<ObjectIdentifier,OIDInfo> oidMap; /** Map String(friendly name) -> OIDInfo(info) */ private final static Map<String,OIDInfo> nameMap; <|startfocus|> // BEGIN Android-changed: Hardcode class names in OIDMap to fix proguard issues <|endfocus|> static { oidMap = new HashMap<ObjectIdentifier,OIDInfo>(); nameMap = new HashMap<String,OIDInfo>(); addInternal(SUB_KEY_IDENTIFIER, PKIXExtensions.SubjectKey_Id, SubjectKeyIdentifierExtension.class); addInternal(KEY_USAGE, PKIXExtensions.KeyUsage_Id, KeyUsageExtension.class); addInternal(PRIVATE_KEY_USAGE, PKIXExtensions.PrivateKeyUsage_Id, PrivateKeyUsageExtension.class); addInternal(SUB_ALT_NAME, PKIXExtensions.SubjectAlternativeName_Id, SubjectAlternativeNameExtension.class); addInternal(ISSUER_ALT_NAME, PKIXExtensions.IssuerAlternativeName_Id, IssuerAlternativeNameExtension.class); addInternal(BASIC_CONSTRAINTS, PKIXExtensions.BasicConstraints_Id,
<|startcomment|> strictly speaking, the changes extend all the way to line 202 ("return clazz;") so this END line probably should be after line 204? <|endcomment|>  SubjectInfoAccessExtension.class); addInternal(AUTH_INFO_ACCESS, PKIXExtensions.AuthInfoAccess_Id, AuthorityInfoAccessExtension.class); addInternal(ISSUING_DIST_POINT, PKIXExtensions.IssuingDistributionPoint_Id, IssuingDistributionPointExtension.class); addInternal(DELTA_CRL_INDICATOR, PKIXExtensions.DeltaCRLIndicator_Id, DeltaCRLIndicatorExtension.class); addInternal(FRESHEST_CRL, PKIXExtensions.FreshestCRL_Id, FreshestCRLExtension.class); addInternal(OCSPNOCHECK, PKIXExtensions.OCSPNoCheck_Id, OCSPNoCheckExtension.class); } <|startfocus|> // END Android-changed: Hardcode class names in OIDMap to fix proguard issues <|endfocus|> /** * Add attributes to the table. For internal use in the static * initializer. */ private static void addInternal(String name, ObjectIdentifier oid, Class clazz) { OIDInfo info = new OIDInfo(name, oid, clazz); oidMap.put(oid, info); nameMap.put(name, info); } /** * Inner class encapsulating the mapping info and Class loading. */ private static class OIDInfo { final ObjectIdentifier oid; final String name; private volatile Class<?> clazz; OIDInfo(String name, ObjectIdentifier oid, Class<?> clazz) {
<|startcomment|> what's "prev impl", is this referring to Android L? This block of code doesn't seem to match any OpenJDK version between 7u40 and 8u121-b13. <|endcomment|>  private AVAComparator() { // empty } static Comparator<AVA> getInstance() { return INSTANCE; } /** * AVA's containing a standard keyword are ordered alphabetically, * followed by AVA's containing an OID keyword, ordered numerically */ public int compare(AVA a1, AVA a2) { boolean a1Has2253 = a1.hasRFC2253Keyword(); boolean a2Has2253 = a2.hasRFC2253Keyword(); <|startfocus|> // BEGIN Android-changed: Keep sort order of RDN from prev impl <|endfocus|> if (a1Has2253) { if (a2Has2253) { return a1.toRFC2253CanonicalString().compareTo (a2.toRFC2253CanonicalString()); } else { return -1; } } else { if (a2Has2253) { return 1; } else { int[] a1Oid = a1.getObjectIdentifier().toIntArray(); int[] a2Oid = a2.getObjectIdentifier().toIntArray(); int pos = 0; int len = (a1Oid.length > a2Oid.length) ? a2Oid.length :
<|startcomment|> nit: disable <|endcomment|>  * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.nfc; import android.content.BroadcastReceiver; import android.content.Context; import android.content.Intent; import android.content.pm.PackageManager; /** <|startfocus|> * Boot completed receiver. used to diable the application if the device doesn't <|endfocus|> * support NFC when device boots. * */ public class NfcBootCompletedReceiver extends BroadcastReceiver { @Override public void onReceive(Context context, Intent intent) { String action = intent.getAction(); if (action == null) { return; } if (action.equals(Intent.ACTION_BOOT_COMPLETED)) { PackageManager pm = context.getPackageManager(); if (!pm.hasSystemFeature(PackageManager.FEATURE_NFC)) { pm.setApplicationEnabledSetting(context.getPackageName(), PackageManager.COMPONENT_ENABLED_STATE_DISABLED, 0); } } } } 
<|startcomment|> not needed if you just swap the equals test below -- if (Intent.ACTION_BOOT_COMPLETED.equals(action)) { <|endcomment|>  public void onReceive(Context context, Intent intent) { String action = intent.getAction(); if (action == null) { return; } <|startfocus|> if (action.equals(Intent.ACTION_BOOT_COMPLETED)) { <|endfocus|> PackageManager pm = context.getPackageManager(); if (!pm.hasSystemFeature(PackageManager.FEATURE_NFC)) { pm.setApplicationEnabledSetting(context.getPackageName(), PackageManager.COMPONENT_ENABLED_STATE_DISABLED, 0); } }
<|startcomment|> This used to work, but since last year Android Wear has shipped devices that only have FEATURE_NFC_HOST_CARD_EMULATION and not FEATURE_NFC set. See b/28587919 for details. I think you could use the new FEATURE_NFC_ANY feature flag though. <|endcomment|>  public void onReceive(Context context, Intent intent) { String action = intent.getAction(); if (action == null) { return; } if (action.equals(Intent.ACTION_BOOT_COMPLETED)) { PackageManager pm = context.getPackageManager(); <|startfocus|> if (!pm.hasSystemFeature(PackageManager.FEATURE_NFC)) { <|endfocus|> pm.setApplicationEnabledSetting(context.getPackageName(), PackageManager.COMPONENT_ENABLED_STATE_DISABLED, 0); } }
<|startcomment|> I'm going to assume this doesn't compile. <|endcomment|>  NetworkStats lastStats) throws IOException { final NetworkStats stats = readNetworkStatsDetailInternal(limitUid, limitIfaces, limitTag, lastStats); NetworkStats.Entry entry = null; // for recycling synchronized (sStackedIfaces) { // Sigh, xt_qtaguid ends up double-counting tx traffic going through // clatd interfaces, so we need to subtract it here. final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); final String baseIface = sStackedIfaces.valueAt(i); <|startfocus|> // Count up tx (http://b/12249687) and rx (http:/b/33681750) traffic and subtract // from root UID on the base interface. NetworkStats.Entry adjust = <|endfocus|> new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) { entry = stats.getValues(j, entry); if (Objects.equals(entry.iface, stackedIface)) {
<|startcomment|> nit: the fact that this is stored in a sysprop is an implementation detail. Just specify the format of the string (eg X.Y or X.Y.Z or whatever it is) <|endcomment|>  */ public static native String getOsVersion(); /** * @return hardware id extracted from uname() native call */ public static native String getHardwareId(); /** * @return kernel version extracted from uname() native call */ public static native String getKernelVersion(); /** * @return sysprop ro.boot.avb_version */ public static native String getBootAvbVersion(); /** <|startfocus|> * @return sysprop ro.boot.vbmeta.avb_version <|endfocus|> */ public static native String getBootVbmetaAvbVersion(); } 
<|startcomment|> nit: line length should be < 100 characters <|endcomment|>  private void setLightLocked(int color, int mode, int onMS, int offMS, int brightnessMode) { if (shouldBeInLowPersistenceMode()) { brightnessMode = BRIGHTNESS_MODE_LOW_PERSISTENCE; } else if (brightnessMode == BRIGHTNESS_MODE_LOW_PERSISTENCE) { brightnessMode = mLastBrightnessMode; } <|startfocus|> if (!mInitialized || color != mColor || mode != mMode || onMS != mOnMS || offMS != mOffMS || mBrightnessMode != brightnessMode) { <|endfocus|> if (DEBUG) Slog.v(TAG, "setLight #" + mId + ": color=#" + Integer.toHexString(color) + ": brightnessMode=" + brightnessMode); mInitialized = true; mLastColor = mColor; mColor = color; mMode = mode; mOnMS = onMS; mOffMS = offMS; mBrightnessMode = brightnessMode; Trace.traceBegin(Trace.TRACE_TAG_POWER, "setLight(" + mId + ", 0x" + Integer.toHexString(color) + ")"); try {
<|startcomment|> Math.abs is surprising enough to deserve a comment? <|endcomment|>  private int putListener(Object listener, NsdServiceInfo s) { checkListener(listener); final int key; synchronized (mMapLock) { int valueIndex = mListenerMap.indexOfValue(listener); checkArgument(valueIndex == -1, "listener already in use"); <|startfocus|> key = Math.abs(mListenerKey++); <|endfocus|> mListenerMap.put(key, listener); mServiceMap.put(key, s); } return key;
<|startcomment|> not an exception? Are you thinking of different error ranges for each call? I was thinking of a common list as I think some/many will be duplicated <|endcomment|>  public int initialize(IMbmsStreamingManagerCallback listener, String appName, int subId) { String appKey = appName + subId; if (!mAppCallbacks.containsKey(appKey)) { mAppCallbacks.put(appKey, listener); } else { return MbmsInitializationException.ERROR_ALREADY_INITIALIZED; } <|startfocus|> return 0; <|endfocus|>
<|startcomment|> typo <|endcomment|>  @Override public boolean isTrue() throws UiObjectNotFoundException { return device.findObject( new UiSelector().resourceId(Res.GOOGLE_PLAY_INPUT_RES)).exists(); } }); if (inputTextFieldExists) { UiObject inputTextField = device.findObject( new UiSelector().resourceId(Res.GOOGLE_PLAY_INPUT_RES)); inputTextField.clearTextField(); inputTextField.setText(application); device.pressEnter(); } } /** <|startfocus|> * Selects an application listed in the Pl;ay Store. <|endfocus|> */ public static void selectFromGooglePlay(Instrumentation instrumentation, String appDescription) throws Exception { final UiDevice device = UiDevice.getInstance(instrumentation); final String playStore = "Play Store"; final String application = appDescription; boolean isListed = new Wait().until(new Wait.ExpectedCondition() { @Override public boolean isTrue() throws UiObjectNotFoundException { return device.findObject(new UiSelector() .description(application)).exists(); } }); if (isListed) { device.findObject(new UiSelector() .description(application)).clickAndWaitForNewWindow();
<|startcomment|> Sorry, maybe I'm being a bit too nit-picky here, but since you split 19 into 19 and 21, should this check still be for 19? To put it more simply, can the testing framework run API version 19? <|endcomment|> public class RSBackwardCompatibilityTests { private static final String TAG = "RSBackwardCompatibilityTests"; /** * Returns the list of subclasses of UnitTest to run. * * Filters out any tests with API version greater than current API version. */ @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { int thisApiVersion = android.os.Build.VERSION.SDK_INT; <|startfocus|> if (thisApiVersion < 21) { Log.w(TAG, "API version is less than 21, no tests running"); <|endfocus|> } Context ctx = InstrumentationRegistry.getTargetContext(); List<UnitTest> validUnitTests = new ArrayList<>(); for (Class<? extends UnitTest> testClass : RSTests.getTestClassesForCurrentAPIVersion()) { UnitTest test = testClass.getDeclaredConstructor(Context.class).newInstance(ctx); validUnitTests.add(test); } checkDuplicateNames(validUnitTests); return validUnitTests; } /** * Throws RuntimeException if any tests have the same name. */ private static void checkDuplicateNames(List<UnitTest> tests) {
<|startcomment|> Nit: For consistency, it might be helpful to make the layout of this "getParams" more similar to BackwardCompatibilityTests's, but it's up to you. <|endcomment|>  * To run the test, please use command * * adb shell am instrument -w com.android.rs.testforward/android.support.test.runner.AndroidJUnitRunner */ @RunWith(Parameterized.class) public class RSForwardCompatibilityTests { private static final String TAG = "RSForwardCompatibilityTests"; /** * Returns the list of subclasses of UnitTest to run. */ @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); <|startfocus|> Iterable<Class<? extends UnitTest>> unitTestClasses = <|endfocus|> RSUtils.getProperSubclasses(UnitTest.class); List<UnitTest> ret = new ArrayList<>(); for (Class<? extends UnitTest> testClass : unitTestClasses) { UnitTest test = testClass.getDeclaredConstructor(Context.class).newInstance(ctx); ret.add(test); } return ret; } @Parameter(0) public UnitTest mTest; @Test @MediumTest public void testRSUnitTest() throws Exception { String thisDeviceName = android.os.Build.DEVICE; int thisApiVersion = android.os.Build.VERSION.SDK_INT;
<|startcomment|> In BackwardCompatibilityTest, you check if there are any duplicate names. Do you need to do that here as well? <|endcomment|>  */ @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); Iterable<Class<? extends UnitTest>> unitTestClasses = RSUtils.getProperSubclasses(UnitTest.class); List<UnitTest> ret = new ArrayList<>(); for (Class<? extends UnitTest> testClass : unitTestClasses) { UnitTest test = testClass.getDeclaredConstructor(Context.class).newInstance(ctx); ret.add(test); } <|startfocus|> return ret; <|endfocus|> } @Parameter(0) public UnitTest mTest; @Test @MediumTest public void testRSUnitTest() throws Exception { String thisDeviceName = android.os.Build.DEVICE; int thisApiVersion = android.os.Build.VERSION.SDK_INT; Log.i(TAG, String.format("RenderScript forward compatibility testing (%s) " + "on device %s, API version %d", mTest.toString(), thisDeviceName, thisApiVersion)); mTest.runTest(); switch (mTest.getResult()) { case UT_NOT_STARTED: case UT_RUNNING:
<|startcomment|> Is there an extra space on this line, or is this intentional? /** * vs /** * <|endcomment|>  import java.util.ArrayList; import java.util.HashSet; import java.util.List; import java.util.Set; /** * RSTestBackward, functional test for platform RenderScript APIs. * To run the test, please use command * * adb shell am instrument -w com.android.rs.testbackward/android.support.test.runner.AndroidJUnitRunner */ @RunWith(Parameterized.class) public class RSBackwardCompatibilityTests { private static final String TAG = "RSBackwardCompatibilityTests"; /** <|startfocus|> * Returns the list of subclasses of UnitTest to run. * * Filters out any tests with API version greater than current API version. */ <|endfocus|> @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { int thisApiVersion = android.os.Build.VERSION.SDK_INT; if (thisApiVersion < 19) { Log.w(TAG, "API version is less than 19, no tests running"); } Context ctx = InstrumentationRegistry.getTargetContext(); ArrayList<UnitTest> validUnitTests = new ArrayList<>(); 
<|startcomment|> The other document says 21, but I think 19 is correct. The python code said 19 & 20 might not be available for now; if so, we should change this to 21 for now. <|endcomment|> public class RSBackwardCompatibilityTests { private static final String TAG = "RSBackwardCompatibilityTests"; /** * Returns the list of subclasses of UnitTest to run. * * Filters out any tests with API version greater than current API version. */ @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { int thisApiVersion = android.os.Build.VERSION.SDK_INT; <|startfocus|> if (thisApiVersion < 19) { Log.w(TAG, "API version is less than 19, no tests running"); <|endfocus|> } Context ctx = InstrumentationRegistry.getTargetContext(); ArrayList<UnitTest> validUnitTests = new ArrayList<>(); for (Class<? extends UnitTest> testClass : RSTests.getTestClassesForCurrentAPIVersion()) { UnitTest test = testClass.getDeclaredConstructor(Context.class).newInstance(ctx); validUnitTests.add(test); } checkDuplicateNames(validUnitTests); return validUnitTests; } /** * Throws RuntimeException if any tests have the same name. */ private static void checkDuplicateNames(List<UnitTest> tests) {
<|startcomment|> Ditto <|endcomment|>  } Context ctx = InstrumentationRegistry.getTargetContext(); ArrayList<UnitTest> validUnitTests = new ArrayList<>(); for (Class<? extends UnitTest> testClass : RSTests.getTestClassesForCurrentAPIVersion()) { UnitTest test = testClass.getDeclaredConstructor(Context.class).newInstance(ctx); validUnitTests.add(test); } checkDuplicateNames(validUnitTests); return validUnitTests; } /** <|startfocus|> * Throws RuntimeException if any tests have the same name. */ <|endfocus|> private static void checkDuplicateNames(List<UnitTest> tests) { Set<String> names = new HashSet<>(); for (UnitTest test : tests) { String name = test.toString(); if (names.contains(name)) { throw new RuntimeException("duplicate name: " + name); } names.add(name); } } @Parameter(0) public UnitTest mTest; @Test @MediumTest public void testRSUnitTest() throws Exception { String thisDeviceName = android.os.Build.DEVICE; int thisApiVersion = android.os.Build.VERSION.SDK_INT;
<|startcomment|> Should this be 19? <|endcomment|>  import com.android.rs.unittest.*; import java.util.ArrayList; /** * This class is auto-generated by frameworks/rs/tests/java_api/RSUnitTests/RSUnitTests.py. * To change unit tests version, please run the Python script above. */ public class RSTests { public static Iterable<Class<? extends UnitTest>> getTestClassesForCurrentAPIVersion() { int thisApiVersion = android.os.Build.VERSION.SDK_INT; ArrayList<Class<? extends UnitTest>> validClasses = new ArrayList<>(); <|startfocus|> if (thisApiVersion >= 21) { <|endfocus|> validClasses.add(UT_alloc.class); validClasses.add(UT_array_alloc.class); validClasses.add(UT_array_init.class); validClasses.add(UT_atomic.class); validClasses.add(UT_bitfield.class); validClasses.add(UT_bug_char.class); validClasses.add(UT_check_dims.class); validClasses.add(UT_clamp.class); validClasses.add(UT_clamp_relaxed.class); validClasses.add(UT_constant.class); validClasses.add(UT_convert.class); validClasses.add(UT_convert_relaxed.class); validClasses.add(UT_copy_test.class); validClasses.add(UT_element.class);
<|startcomment|> nit: delete extra line <|endcomment|> import android.content.Context; import android.support.test.InstrumentationRegistry; import android.support.test.filters.MediumTest; import android.util.Log; import org.junit.Assert; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameter; import org.junit.runners.Parameterized.Parameters; /** * RSTestForward, functional test for platform RenderScript APIs. * To run the test, please use command * * adb shell am instrument -w com.android.rs.testforward/android.support.test.runner.AndroidJUnitRunner <|startfocus|> * <|endfocus|> */ @RunWith(Parameterized.class) public class RSForwardCompatibilityTests { private static final String TAG = "RSForwardCompatibilityTests"; /** * Returns the list of subclasses of UnitTest to run. */ @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { return RSUtils.getProperSubclasses(UnitTest.class); } @Parameter(0) public Class<? extends UnitTest> mTestClass; @Test @MediumTest public void testRSUnitTest() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext();
<|startcomment|> Extra space here? <|endcomment|> import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameter; import org.junit.runners.Parameterized.Parameters; /** * RSTestForward, functional test for platform RenderScript APIs. * To run the test, please use command * * adb shell am instrument -w com.android.rs.testforward/android.support.test.runner.AndroidJUnitRunner * */ @RunWith(Parameterized.class) public class RSForwardCompatibilityTests { private static final String TAG = "RSForwardCompatibilityTests"; /** <|startfocus|> * Returns the list of subclasses of UnitTest to run. */ <|endfocus|> @Parameters(name = "{0}") public static Iterable<?> getParams() throws Exception { return RSUtils.getProperSubclasses(UnitTest.class); } @Parameter(0) public Class<? extends UnitTest> mTestClass; @Test @MediumTest public void testRSUnitTest() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); UnitTest test = mTestClass.getDeclaredConstructor(Context.class).newInstance(ctx); test.runTest(); switch (test.getResult()) { case UT_NOT_STARTED: case UT_RUNNING:
<|startcomment|> Can you make this block more similar to the equivalent block in RSBackwardCompatibilityTests.java? <|endcomment|>  return RSUtils.getProperSubclasses(UnitTest.class); } @Parameter(0) public Class<? extends UnitTest> mTestClass; @Test @MediumTest public void testRSUnitTest() throws Exception { Context ctx = InstrumentationRegistry.getTargetContext(); UnitTest test = mTestClass.getDeclaredConstructor(Context.class).newInstance(ctx); test.runTest(); switch (test.getResult()) { case UT_NOT_STARTED: case UT_RUNNING: Log.w(TAG, "unexpected unit test result: " + test.getResult().toString()); break; } <|startfocus|> Assert.assertTrue(test.getSuccess()); <|endfocus|> } } 
<|startcomment|> 2017 <|endcomment|> <|startfocus|> * Copyright (C) 2016 The Android Open Source Project <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.android.rs.testforward; import com.android.rs.unittest.UnitTest; import android.content.Context; import android.support.test.InstrumentationRegistry; import dalvik.system.DexFile; import java.io.IOException; import java.util.ArrayList; import java.util.Enumeration; public class RSUtils { /** Returns a list of all proper subclasses of the input class */
<|startcomment|> copy-paste error (and L823) <|endcomment|>  MetricsLogger.histogram(context, "ota_stashed_in_MiBs", bytesStashedInMiB); } if (temperatureStart != -1) { MetricsLogger.histogram(context, "ota_temperature_start", temperatureStart); } if (temperatureEnd != -1) { MetricsLogger.histogram(context, "ota_temperature_end", temperatureEnd); } if (temperatureMax != -1) { MetricsLogger.histogram(context, "ota_temperature_max", temperatureMax); } if (errorCode != -1) { <|startfocus|> MetricsLogger.histogram(context, "ota_blockbased_error_code", timeTotal); <|endfocus|> } if (causeCode != -1) { MetricsLogger.histogram(context, "ota_blockbased_cause_code", timeTotal); } } catch (IOException e) { Log.e(TAG, "Failed to read lines in last_install", e); }
<|startcomment|> these three are wrong, aren't they? aren't they written with underscores? <|endcomment|>  } else if (line.startsWith("source_build")) { sourceVersion = scaled; } else if (line.startsWith("bytes_written")) { bytesWrittenInMiB = (bytesWrittenInMiB == -1) ? scaled : bytesWrittenInMiB + scaled; } else if (line.startsWith("bytes_stashed")) { bytesStashedInMiB = (bytesStashedInMiB == -1) ? scaled : bytesStashedInMiB + scaled; } else if (line.startsWith("temperatureStart")) { temperatureStart = scaled; <|startfocus|> } else if (line.startsWith("temperatureEnd")) { <|endfocus|> temperatureEnd = scaled; } else if (line.startsWith("temperatureMax")) { temperatureMax = scaled; } else if (line.startsWith("error")) { errorCode = scaled; } else if (line.startsWith("cause")) { causeCode = scaled; } } // Don't report data to tron if corresponding entry isn't found in last_install. if (timeTotal != -1) {
<|startcomment|> "w/" -> "with" (?) <|endcomment|>  void sendTrackChangeWithId(int trackChangedNT, MediaController mediaController) { if (DEBUG) Log.d(TAG, "sendTrackChangeWithId"); byte[] track; try { <|startfocus|> if (mediaController == null) { mMediaInterface.trackChangedRsp(trackChangedNT, AvrcpConstants.NO_TRACK_SELECTED); return; } <|endfocus|> String mediaId = mediaController.getMetadata().getDescription().getMediaId(); long qid = MediaSession.QueueItem.UNKNOWN_ID; List<MediaSession.QueueItem> items = mNowPlayingList; /* traverse now playing list for current playing item */ for (QueueItem item : items) { if (item.getDescription().getMediaId().equals(mediaId)) { qid = item.getQueueId(); if (DEBUG) Log.d(TAG, "sendTrackChangeWithId: Found matching qid= " + qid); break; } } /* for any item associated with NowPlaying, uid is queueId */ track = ByteBuffer.allocate(AvrcpConstants.UID_SIZE).putLong(qid).array(); } catch (NullPointerException e) { Log.w(TAG, "NullPointerException getting uid, sending no track selected");
<|startcomment|> Nit: Ids -> IDs <|endcomment|>  } else if (!isPlayerAlreadyAddressed(selectedId)) { // register new Media Controller Callback and update the current Ids if (!updateCurrentController(selectedId, mCurrBrowsePlayerID)) { status = AvrcpConstants.RSP_INTERNAL_ERR; Log.e(TAG, "register for new Address player failed: " + mCurrAddrPlayerID); } <|startfocus|> } else { MediaPlayerInfo info = getAddressedPlayerInfo(); Log.i(TAG, "addressed player " + info + "is already focused"); <|endfocus|> } if (DEBUG) Log.d(TAG, "setAddressedPlayer for selectedId: " + selectedId + " , status: " + status); // Sending address player response to remote setAddressedPlayerRspNative(bdaddr, status);
<|startcomment|> include a reason for enabling here please for the logs. <|endcomment|>  mUnbinding = false; mEnable = false; mState = BluetoothAdapter.STATE_OFF; mQuietEnableExternal = false; mEnableExternal = false; mAddress = null; mName = null; mErrorRecoveryRetryCounter = 0; mContentResolver = context.getContentResolver(); // Observe BLE scan only mode settings change. registerForBleScanModeChange(); mCallbacks = new RemoteCallbackList<IBluetoothManagerCallback>(); mStateChangeCallbacks = new RemoteCallbackList<IBluetoothStateChangeCallback>(); IntentFilter filter = new IntentFilter(BluetoothAdapter.ACTION_LOCAL_NAME_CHANGED); filter.setPriority(IntentFilter.SYSTEM_HIGH_PRIORITY); mContext.registerReceiver(mReceiver, filter); <|startfocus|> IntentFilter filter2 = new IntentFilter(BluetoothAdapter.ACTION_BD_ADDR_CHANGED); filter2.setPriority(IntentFilter.SYSTEM_HIGH_PRIORITY); mContext.registerReceiver(mReceiver, filter2); <|endfocus|> loadStoredNameAndAddress(); if (isBluetoothPersistedStateOn()) { if (DBG) Slog.d(TAG, "Startup: Bluetooth persisted state is ON."); mEnableExternal = true; } String airplaneModeRadios = Settings.Global.getString(mContentResolver, Settings.Global.AIRPLANE_MODE_RADIOS); if (airplaneModeRadios == null ||
<|startcomment|> odex <|endcomment|>  protected int adjustDexoptNeeded(int dexoptNeeded) { if (dexoptNeeded == DexFile.NO_DEXOPT_NEEDED) { // Ensure compilation by pretending a compiler filter change on the <|startfocus|> // apk location. <|endfocus|> return -DexFile.DEX2OAT_FOR_FILTER; } return dexoptNeeded;
<|startcomment|> "restored user setting" would be more clear. <|endcomment|>  private static final int CRASH_LOG_MAX_SIZE = 100; private static final String REASON_AIRPLANE_MODE = "airplane mode"; private static final String REASON_RESTARTED = "automatic restart"; private static final String REASON_START_CRASH = "turn-on crash"; private static final String REASON_SYSTEM_BOOT = "system boot"; private static final String REASON_UNEXPECTED = "unexpected crash"; private static final String REASON_USER_SWITCH = "user switch"; <|startfocus|> private static final String REASON_SYSTEM_RESTORE = "restore BluetoothOn setting"; <|endfocus|> private static final int TIMEOUT_BIND_MS = 3000; //Maximum msec to wait for a bind //Maximum msec to wait for service restart private static final int SERVICE_RESTART_TIME_MS = 200; //Maximum msec to wait for restart due to error private static final int ERROR_RESTART_TIME_MS = 3000; //Maximum msec to delay MESSAGE_USER_SWITCHED private static final int USER_SWITCHED_TIME_MS = 200; // Delay for the addProxy function in msec private static final int ADD_PROXY_DELAY_MS = 100; 
<|startcomment|> identation <|endcomment|>  /// CHECK-DAG: <<Add:d\d+>> VecAdd [<<Load>>,<<Repl>>] /// CHECK-NOT: IntermediateAddress /// CHECK-DAG: VecStore [<<Array>>,<<Address1>>,<<Add>>] /// CHECK-START-ARM64: void Main.checkIntCase(int[]) disassembly (after) /// CHECK: IntermediateAddressIndex <|startfocus|> /// CHECK-NEXT: add w{{[0-9]+}}, w{{[0-9]+}}, w{{[0-9]+}}, lsl #2 <|endfocus|> public static void checkIntCase(int[] a) { for (int i = 0; i < 128; i++) { a[i] += 5; } } /// CHECK-START-ARM64: void Main.checkByteCase(byte[]) instruction_simplifier_arm64 (before) /// CHECK-DAG: <<Array:l\d+>> ParameterValue /// CHECK-DAG: <<Const5:i\d+>> IntConstant 5 /// CHECK-DAG: <<Repl:d\d+>> VecReplicateScalar [<<Const5>>] // -------------- Loop /// CHECK-DAG: <<Index:i\d+>> Phi
<|startcomment|> indentation <|endcomment|>  /// CHECK-DAG: <<Add:d\d+>> VecAdd [<<Load>>,<<Repl>>] /// CHECK-NOT: IntermediateAddress /// CHECK-DAG: VecStore [<<Array>>,<<Address1>>,<<Add>>] /// CHECK-START-ARM64: void Main.checkByteCase(byte[]) disassembly (after) /// CHECK: IntermediateAddressIndex /// CHECK-NEXT: add w{{[0-9]+}}, w{{[0-9]+}}, #0x{{[0-9a-fA-F]+}} /// CHECK: VecLoad <|startfocus|> /// CHECK-NEXT: ldr q{{[0-9]+}}, [x{{[0-9]+}}, x{{[0-9]+}}] <|endfocus|> /// CHECK: VecStore /// CHECK-NEXT: str q{{[0-9]+}}, [x{{[0-9]+}}, x{{[0-9]+}}] public static void checkByteCase(byte[] a) { for (int i = 0; i < 128; i++) { a[i] += 5; } } 
<|startcomment|> Must be 2. <|endcomment|>  /// CHECK: <<Add:d\d+>> VecAdd [<<Load>>,<<Repl>>] /// CHECK-NOT: IntermediateAddress /// CHECK: VecStore [<<Array>>,<<Address1>>,<<Add>>] /// CHECK-START-ARM64: void Main.checkIntCase(int[]) disassembly (after) <|startfocus|> /// CHECK: IntermediateAddressIndex /// CHECK-NEXT: add w{{[0-9]+}}, w{{[0-9]+}}, w{{[0-9]+}}, lsl #{{[0-9]}} <|endfocus|> public static void checkIntCase(int[] a) { for (int i = 0; i < 128; i++) { a[i] += 5; } } /// CHECK-START-ARM64: void Main.checkByteCase(byte[]) instruction_simplifier_arm64 (before) /// CHECK: <<Array:l\d+>> ParameterValue /// CHECK: <<Const5:i\d+>> IntConstant 5 /// CHECK: <<Repl:d\d+>> VecReplicateScalar [<<Const5>>] // -------------- Loop /// CHECK: <<Index:i\d+>> Phi /// CHECK: If
<|startcomment|> 2 <|endcomment|>  public static void checkInt2Float(int[] a, float[] b) { for (int i = 0; i < 128; i++) { <|startfocus|> b[i] = (float)a[i]; <|endfocus|> }
<|startcomment|> space after this cast (also below) <|endcomment|>  public static void checkInt2Float(int[] a, float[] b) { for (int i = 0; i < 128; i++) { <|startfocus|> b[i] = (float)a[i]; <|endfocus|> }
<|startcomment|> Missing checker statements for this method? <|endcomment|>  public static int calcArraySum(int[] a, byte[] b, float[] c) { int sum = 0; for (int i = 0; i < 128; i++) { <|startfocus|> sum += a[i] + b[i] + (int)c[i]; <|endfocus|> } return sum;
<|startcomment|> because....X. <|endcomment|>  * Agreement between Taligent and Sun. This technology is protected * by multiple US and International patents. * * This notice and attribution to Taligent may not be removed. * Taligent is a registered trademark of Taligent, Inc. * */ package java.awt.font; import java.io.InvalidObjectException; import java.text.AttributedCharacterIterator.Attribute; import java.util.Map; import java.util.HashMap; <|startfocus|> // Android-removed: List of classes for use with attribute keys; "Summary of attributes" section. <|endfocus|> /** * The <code>TextAttribute</code> class defines attribute keys and * attribute values used for text rendering. * <p> * <code>TextAttribute</code> instances are used as attribute keys to * identify attributes in classes handling text attributes. Other * constants defined in this class can be used as attribute values. * <p> * For each text attribute, the documentation provides: * <UL> * <LI>the type of its value, * <LI>the relevant predefined constants, if any
<|startcomment|> s/font names/java.awk.Font constants not present on Android/ <|endcomment|>  if (instance != null) { return instance; } else { throw new InvalidObjectException("unknown attribute name"); } } // Serialization compatibility with Java 2 platform v1.2. // 1.2 will throw an InvalidObjectException if ever asked to // deserialize INPUT_METHOD_UNDERLINE. // This shouldn't happen in real life. static final long serialVersionUID = 7744112784117861702L; // // For use with Font. // <|startfocus|> // Android-removed: links to font names from documentation. <|endfocus|> /** * Attribute key for the font name. Values are instances of * <b><code>String</code></b>. The default value is * <code>"Default"</code>, which causes the platform default font * family to be used. * * <p> The <code>Font</code> class defines constants for the logical * font names. * * <p>This defines the value passed as <code>name</code> to the * <code>Font</code> constructor. Both logical and physical
<|startcomment|> TransformAttribute >class that is not present on Android<. <|endcomment|>  * and the rendering system might not render text at these sizes. * Negative sizes are illegal and result in the default size. * * <p>Note that the appearance and metrics of a 12pt font with a * 2x transform might be different than that of a 24 point font * with no transform. */ public static final TextAttribute SIZE = new TextAttribute("size"); <|startfocus|> // Android-removed: Sections of documentation about TransformAttribute. <|endfocus|> /** * Attribute key for the transform of a font. Values are * instances of <b><code>TransformAttribute</code></b>. The * default value is <code>TransformAttribute.IDENTITY</code>. * * <p>The primary intent is to support scaling and skewing, though * other effects are possible.</p> * * <p>Some transforms will cause the baseline to be rotated and/or * shifted. The text and the baseline are transformed together so * that the text follows the new baseline. For example, with text
<|startcomment|> ... not present on Android. <|endcomment|>  * and descent can never become negative, however. */ public static final TextAttribute SUPERSCRIPT = new TextAttribute("superscript"); /** * Standard superscript. * @see #SUPERSCRIPT */ public static final Integer SUPERSCRIPT_SUPER = Integer.valueOf(1); /** * Standard subscript. * @see #SUPERSCRIPT */ public static final Integer SUPERSCRIPT_SUB = Integer.valueOf(-1); <|startfocus|> // Android-removed: Documentation sections about java.awt.Font. <|endfocus|> /** * Attribute key used to provide the font to use to render text. * * The default * value is null, indicating that normal resolution of a * <code>Font</code> from attributes should be performed. * * <p><code>TextLayout</code> and * <code>AttributedCharacterIterator</code> work in terms of * <code>Maps</code> of <code>TextAttributes</code>. Normally, * all the attributes are examined and used to select and * configure a <code>Font</code> instance. If a <code>FONT</code>
<|startcomment|> As above. <|endcomment|>  * default value for <code>JUSTIFICATION</code>. * @see #JUSTIFICATION */ public static final Float JUSTIFICATION_FULL = Float.valueOf(1.0f); /** * Do not allow the line to be justified. * @see #JUSTIFICATION */ public static final Float JUSTIFICATION_NONE = Float.valueOf(0.0f); // // For use by input method. // <|startfocus|> // Android-removed: Documentation sections about java.awt.im.InputMethodHighlight <|endfocus|> /** * Attribute key for input method highlight styles. * * The default value is <code>null</code>, * which means that input method styles should not be applied * before rendering. * * @see java.text.Annotation */ public static final TextAttribute INPUT_METHOD_HIGHLIGHT = new TextAttribute("input method highlight"); /** * Attribute key for input method underlines. Values * are instances of <b><code>Integer</code></b>. The default * value is <code>-1</code>, which means no underline. *
<|startcomment|> Restoring Bluetooth state to disabled <|endcomment|>  mHandler.removeMessages(MESSAGE_RESTART_BLUETOOTH_SERVICE); if (mEnable && mBluetooth != null) { waitForOnOff(true, false); mEnable = false; handleDisable(); waitForOnOff(false, false); } else { mEnable = false; handleDisable(); } break; case MESSAGE_RESTORE_ON_SETTING: try { if ((msg.arg1 == RESTORE_SETTING_TO_OFF) && mEnable) { <|startfocus|> if (DBG) Slog.d(TAG, "Restore to disable Bluetooth"); <|endfocus|> disable(REASON_RESTORE_USER_SETTING, true); } else if ((msg.arg1 == RESTORE_SETTING_TO_ON) && !mEnable) { if (DBG) Slog.d(TAG, "Restore to enable Bluetooth"); enable(REASON_RESTORE_USER_SETTING); } } catch (RemoteException e) { Slog.e(TAG,"Unable to change Bluetooth On setting",e); } break; case MESSAGE_REGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.register(callback); break; } case MESSAGE_UNREGISTER_ADAPTER:
<|startcomment|> Restoring Bluetooth state to enabled <|endcomment|>  } else { mEnable = false; handleDisable(); } break; case MESSAGE_RESTORE_ON_SETTING: try { if ((msg.arg1 == RESTORE_SETTING_TO_OFF) && mEnable) { if (DBG) Slog.d(TAG, "Restore to disable Bluetooth"); disable(REASON_RESTORE_USER_SETTING, true); } else if ((msg.arg1 == RESTORE_SETTING_TO_ON) && !mEnable) { <|startfocus|> if (DBG) Slog.d(TAG, "Restore to enable Bluetooth"); <|endfocus|> enable(REASON_RESTORE_USER_SETTING); } } catch (RemoteException e) { Slog.e(TAG,"Unable to change Bluetooth On setting",e); } break; case MESSAGE_REGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.register(callback); break; } case MESSAGE_UNREGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.unregister(callback); break; } case MESSAGE_REGISTER_STATE_CHANGE_CALLBACK: {
<|startcomment|> prefer this to be RESTORE_USER_SETTING to make it clear that it's coming from elsewhere <|endcomment|>  private static final int MESSAGE_BLUETOOTH_STATE_CHANGE = 60; private static final int MESSAGE_TIMEOUT_BIND = 100; private static final int MESSAGE_TIMEOUT_UNBIND = 101; private static final int MESSAGE_GET_NAME_AND_ADDRESS = 200; private static final int MESSAGE_USER_SWITCHED = 300; private static final int MESSAGE_USER_UNLOCKED = 301; private static final int MESSAGE_ADD_PROXY_DELAYED = 400; private static final int MESSAGE_BIND_PROFILE_SERVICE = 401; <|startfocus|> private static final int MESSAGE_RESTORE_ON_SETTING = 500; <|endfocus|> private static final int RESTORE_SETTING_TO_ON = 1; private static final int RESTORE_SETTING_TO_OFF = 0; private static final int MAX_SAVE_RETRIES = 3; private static final int MAX_ERROR_RESTART_RETRIES = 6; // Bluetooth persisted setting is off private static final int BLUETOOTH_OFF=0; // Bluetooth persisted setting is on // and Airplane mode won't affect Bluetooth state at start up private static final int BLUETOOTH_ON_BLUETOOTH=1; // Bluetooth persisted setting is on
<|startcomment|> it's more idiomatic to either: mHandler.obtainMessage(...).sendToTarget() or Message msg = mHandler.obtainMessage(...); msg.obj = ... mHandler.sendMessage(msg); <|endcomment|>  Intent.EXTRA_SETTING_NEW_VALUE); if (DBG) Slog.d(TAG, "ACTION_SETTING_RESTORED with BLUETOOTH_ON, prevValue=" + prevValue + ", newValue=" + newValue); if ((newValue != null) && (prevValue != null) && !prevValue.equals(newValue)) { <|startfocus|> mHandler.sendMessage( mHandler.obtainMessage(MESSAGE_RESTORE_ON_SETTING, newValue.equals("0") ? RESTORE_SETTING_TO_OFF : RESTORE_SETTING_TO_ON, 0)); <|endfocus|> } } }
<|startcomment|> nit: spaces after commas <|endcomment|>  if ((msg.arg1 == RESTORE_SETTING_TO_OFF) && mEnable) { if (DBG) Slog.d(TAG, "Restore Bluetooth state to disabled"); disable(REASON_RESTORE_USER_SETTING, true); } else if ((msg.arg1 == RESTORE_SETTING_TO_ON) && !mEnable) { if (DBG) Slog.d(TAG, "Restore Bluetooth state to enabled"); enable(REASON_RESTORE_USER_SETTING); } } catch (RemoteException e) { <|startfocus|> Slog.e(TAG,"Unable to change Bluetooth On setting",e); <|endfocus|> } break; case MESSAGE_REGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.register(callback); break; } case MESSAGE_UNREGISTER_ADAPTER: { IBluetoothManagerCallback callback = (IBluetoothManagerCallback) msg.obj; mCallbacks.unregister(callback); break; } case MESSAGE_REGISTER_STATE_CHANGE_CALLBACK: { IBluetoothStateChangeCallback callback = (IBluetoothStateChangeCallback) msg.obj; mStateChangeCallbacks.register(callback); break; } case MESSAGE_UNREGISTER_STATE_CHANGE_CALLBACK: {
<|startcomment|> empty line? <|endcomment|>  * @hide */ public class ServiceInfo implements Parcelable { // arbitrary limit on the number of locale -> name pairs we support final static int MAP_LIMIT = 50; /** * User displayable names listed by language. Unmodifiable. */ final Map<Locale, String> names; /** * The class name for this service - used to catagorize and filter */ final String className; /** * The language for this service content */ final Locale locale; /** <|startfocus|> <|endfocus|> * The carrier's identifier for the service. */ final String serviceId; /** * The start time indicating when this service will be available. */ final Date sessionStartTime; /** * The end time indicating when this sesion stops being available. */ final Date sessionEndTime; public ServiceInfo(Map<Locale, String> newNames, String newClassName, Locale newLocale, String newServiceId, Date start, Date end) {
<|startcomment|> list what ints are allowed? <|endcomment|>  /** * Initialize streaming service for this app and subId, registering the listener. * * @param listener The callback to use to communicate with the app. * @param appName The package name of the calling app. * @param subscriptionId The subscription ID to use. * @return {@link MbmsException#ERROR_ALREADY_INITIALIZED} or {@link MbmsException#SUCCESS}. */ @Override public int initialize(IMbmsStreamingManagerCallback listener, String appName, <|startfocus|> int subscriptionId) throws RemoteException { <|endfocus|> return 0; } /** * Registers serviceClasses of interest with the appName/subId key. * Starts async fetching data on streaming services of matching classes to be reported * later via {@link IMbmsStreamingManagerCallback#streamingServicesUpdated(List)} * * Note that subsequent calls with the same appName and subId will replace * the service class list. * * @param appName The package name of the calling app. * @param subscriptionId The subscription id for eMBMS
<|startcomment|> same line? <|endcomment|>  /** * Initialize streaming service for this app and subId, registering the listener. * * @param listener The callback to use to communicate with the app. * @param appName The package name of the calling app. * @param subscriptionId The subscription ID to use. * @return {@link MbmsException#ERROR_ALREADY_INITIALIZED} or {@link MbmsException#SUCCESS}. */ @Override public int initialize(IMbmsStreamingManagerCallback listener, String appName, <|startfocus|> int subscriptionId) throws RemoteException { <|endfocus|> return 0; } /** * Registers serviceClasses of interest with the appName/subId key. * Starts async fetching data on streaming services of matching classes to be reported * later via {@link IMbmsStreamingManagerCallback#streamingServicesUpdated(List)} * * Note that subsequent calls with the same appName and subId will replace * the service class list. * * @param appName The package name of the calling app. * @param subscriptionId The subscription id for eMBMS
<|startcomment|> and uid. Another app should be able to get services for the same appName and that's handled separately. We should also keep a list of tests we need to verify the impl meets expectations. <|endcomment|>  */ @Override public int initialize(IMbmsStreamingManagerCallback listener, String appName, int subscriptionId) throws RemoteException { return 0; } /** * Registers serviceClasses of interest with the appName/subId key. * Starts async fetching data on streaming services of matching classes to be reported * later via {@link IMbmsStreamingManagerCallback#streamingServicesUpdated(List)} * <|startfocus|> * Note that subsequent calls with the same appName and subId will replace <|endfocus|> * the service class list. * * @param appName The package name of the calling app. * @param subscriptionId The subscription id for eMBMS * @param serviceClasses The service classes that the app wishes to get info on. The strings * may contain arbitrary data as negotiated between the app and the * carrier. */ @Override public int getStreamingServices(String appName, int subscriptionId, List<String> serviceClasses) throws MbmsException { return 0; } @Override public StreamingService startStreaming(String appName, int subId,
<|startcomment|> should probably use "name" for consistency with your change to the second argument. <|endcomment|>  security.checkWrite(name); } } */ if (name == null) { // Android-changed: different exception message in ctor when file == null. // throw new NullPointerException(); throw new NullPointerException("file == null"); } if (file.isInvalid()) { throw new FileNotFoundException("Invalid file path"); } this.path = name; this.mode = imode; // BEGIN Android-changed: Use IoBridge.open() instead of open. <|startfocus|> fd = IoBridge.open(file.getPath(), imode); <|endfocus|> if (syncMetadata) { try { fd.sync(); } catch (IOException e) { // Ignored } } guard.open("close"); // END Android-changed: Use IoBridge.open() instead of open. } /** * Returns the opaque file descriptor object associated with this * stream. * * @return the file descriptor object associated with this stream. * @exception IOException if an I/O error occurs. * @see java.io.FileDescriptor */
<|startcomment|> Could this comment be improved a bit, it is a bit cryptic. <|endcomment|>  if (VDBG) Log.d(TAG, "Tether Mode requested by " + who); handleInterfaceServingStateActive(message.arg1, who); who.sendMessage(TetherInterfaceStateMachine.CMD_TETHER_CONNECTION_CHANGED, mCurrentUpstreamIface); // If there has been a change and an upstream is now // desired, kick off the selection process. final boolean previousUpstreamWanted = updateUpstreamWanted(); if (!previousUpstreamWanted && mUpstreamWanted) { chooseUpstreamType(true); } break; } <|startfocus|> case EVENT_IFACE_SERVING_STATE_INACTIVE: { <|endfocus|> TetherInterfaceStateMachine who = (TetherInterfaceStateMachine)message.obj; if (VDBG) Log.d(TAG, "Tether Mode unrequested by " + who); handleInterfaceServingStateInactive(who); if (mNotifyList.isEmpty()) { turnOffMasterTetherSettings(); // transitions appropriately } else { if (DBG) { Log.d(TAG, "TetherModeAlive still has " + mNotifyList.size() + " live requests:"); for (TetherInterfaceStateMachine o : mNotifyList) {
<|startcomment|> Maybe add some context what that means? <|endcomment|>  // /// CHECK-START: int Main.getSum21() instruction_simplifier$after_bce (after) /// CHECK-DAG: <<Int:i\d+>> IntConstant 21 loop:none /// CHECK-DAG: Return [<<Int>>] loop:none private static int getSum21() { int k = 0; int sum = 0; for (int i = 0; i < 6; i++) { k++; sum += k; } return sum; } <|startfocus|> // Ensure double induction does not "overshoot". <|endfocus|> private static int getIncr2(int[] arr) { for (int i = 0; i < 12; ) { arr[i++] = 30; arr[i++] = 29; } int sum = 0; for (int i = 0; i < 12; i++) { sum += arr[i]; } return sum; } // TODO: handle as closed/empty eventually? static int mainIndexReturnedN(int n) { int i; for (i = 0; i < n; i++); return i; }
<|startcomment|> Ouch. Should we just move this into the preceding synchronized block? <|endcomment|>  // To account correctly for on-the-wire traffic, add the 20 additional bytes difference // for all packets (http://b/12249687, http:/b/33681750). for (int i = 0; i < stats.size(); i++) { entry = stats.getValues(i, entry); if (entry.iface == null || !entry.iface.startsWith(CLATD_INTERFACE_PREFIX)) { continue; } <|startfocus|> synchronized (sStackedIfaces) { if (!sStackedIfaces.containsKey(entry.iface)) { continue; } } <|endfocus|> entry.rxBytes = entry.rxPackets * IPV4V6_HEADER_DELTA; entry.txBytes = entry.txPackets * IPV4V6_HEADER_DELTA; entry.rxPackets = 0; entry.txPackets = 0; stats.combineValues(entry); } return stats; } private NetworkStats readNetworkStatsDetailInternal(int limitUid, String[] limitIfaces, int limitTag, NetworkStats lastStats) throws IOException { if (USE_NATIVE_PARSING) { final NetworkStats stats; if (lastStats != null) { stats = lastStats; stats.setElapsedRealtime(SystemClock.elapsedRealtime()); } else {
<|startcomment|> For safety, can/should we also check that stackedIface.startsWith(CLATD_INTERFACE_PREFIX) ? <|endcomment|>  // base interface. For correct stats accounting on the base interface, every 464xlat // packets needs to be subtracted for the root UID on the base interface both for tx // and rx traffic (http://b/12249687, http:/b/33681750). final int size = sStackedIfaces.size(); for (int i = 0; i < size; i++) { final String stackedIface = sStackedIfaces.keyAt(i); <|startfocus|> final String baseIface = sStackedIfaces.valueAt(i); <|endfocus|> NetworkStats.Entry adjust = new NetworkStats.Entry(baseIface, 0, 0, 0, 0L, 0L, 0L, 0L, 0L); for (int j = 0; j < stats.size(); j++) { entry = stats.getValues(j, entry); if (Objects.equals(entry.iface, stackedIface)) { adjust.rxBytes -= (entry.rxBytes + entry.rxPackets * IPV4V6_HEADER_DELTA); adjust.txBytes -= (entry.txBytes + entry.txPackets * IPV4V6_HEADER_DELTA); adjust.rxPackets -= entry.rxPackets; adjust.txPackets -= entry.txPackets;
<|startcomment|> Nit: traffic <|endcomment|>  assertStatsEntry(stats, "lo", 0, SET_DEFAULT, 0x0, 1288L, 1288L); NetworkStatsFactory.noteStackedIface("v4-wlan0", null); } public void testDoubleClatAccounting100MBDownload() throws Exception { // Downloading 100mb from an ipv4 only destination in a foreground activity long appRxBytesBefore = 328684029L; long appRxBytesAfter = 439237478L; <|startfocus|> assertEquals("App traffix should be ~100MB", 110553449, appRxBytesAfter - appRxBytesBefore); <|endfocus|> long rootRxBytesBefore = 1394011L; long rootRxBytesAfter = 1398634L; assertEquals("Root traffic should be ~0", 4623, rootRxBytesAfter - rootRxBytesBefore); NetworkStatsFactory.noteStackedIface("v4-wlan0", "wlan0"); NetworkStats stats; // Stats snapshot before the download stats = parseDetailedStats(R.raw.xt_qtaguid_with_clat_100mb_download_before); assertStatsEntry(stats, "v4-wlan0", 10106, SET_FOREGROUND, 0x0, appRxBytesBefore, 5199872L); assertStatsEntry(stats, "wlan0", 0, SET_DEFAULT, 0x0, rootRxBytesBefore, 647888L); 
<|startcomment|> Nit: UID 0 <|endcomment|>  } public void testDoubleClatAccounting100MBDownload() throws Exception { // Downloading 100mb from an ipv4 only destination in a foreground activity long appRxBytesBefore = 328684029L; long appRxBytesAfter = 439237478L; assertEquals("App traffix should be ~100MB", 110553449, appRxBytesAfter - appRxBytesBefore); long rootRxBytesBefore = 1394011L; long rootRxBytesAfter = 1398634L; <|startfocus|> assertEquals("Root traffic should be ~0", 4623, rootRxBytesAfter - rootRxBytesBefore); <|endfocus|> NetworkStatsFactory.noteStackedIface("v4-wlan0", "wlan0"); NetworkStats stats; // Stats snapshot before the download stats = parseDetailedStats(R.raw.xt_qtaguid_with_clat_100mb_download_before); assertStatsEntry(stats, "v4-wlan0", 10106, SET_FOREGROUND, 0x0, appRxBytesBefore, 5199872L); assertStatsEntry(stats, "wlan0", 0, SET_DEFAULT, 0x0, rootRxBytesBefore, 647888L); // Stats snapshot after the download stats = parseDetailedStats(R.raw.xt_qtaguid_with_clat_100mb_download_after);
<|startcomment|> For readability, I'd prefer the conditional to be in brackets; e.g. controller = (info == null) ? ... <|endcomment|>  public void onConnected() { Log.d(TAG, "BrowsablePlayerListBuilder: " + mCurrentPlayer.packageName + " OK"); mCurrentBrowser.disconnect(); mCurrentBrowser = null; mBrowsePlayerInfoList.add(mCurrentPlayer); MediaPlayerInfo info = getMediaPlayerInfo(mCurrentPlayer.packageName); <|startfocus|> MediaController controller = info == null ? null : info.getMediaController(); <|endfocus|> // Refresh the media player entry so it notices we can browse if (controller != null) { addMediaPlayerController(controller.getWrappedInstance()); } else { addMediaPlayerPackage(mCurrentPlayer.packageName); } mPlayersChanged = true; connectNextPlayer();
<|startcomment|> 254 <|endcomment|>  } shr32(); for (int i = 0; i < 128; i++) { expectEquals(0x3fffffff, a[i], "shr32"); } shr33(); for (int i = 0; i < 128; i++) { expectEquals(0x1fffffff, a[i], "shr33"); } shrMinus254(); for (int i = 0; i < 128; i++) { <|startfocus|> expectEquals(0x07ffffff, a[i], "shrMinus255"); <|endfocus|> } // Bit-wise not operator. not(); for (int i = 0; i < 128; i++) { expectEquals(0xf8000000, a[i], "not"); } // Done. System.out.println("passed");
<|startcomment|> Minus254 <|endcomment|>  } shr64(); for (int i = 0; i < 128; i++) { expectEquals(0x3fffffffffffffffL, a[i], "shr64"); } shr65(); for (int i = 0; i < 128; i++) { expectEquals(0x1fffffffffffffffL, a[i], "shr65"); } shrMinus254(); for (int i = 0; i < 128; i++) { <|startfocus|> expectEquals(0x07ffffffffffffffL, a[i], "shr65"); <|endfocus|> } // Bit-wise not operator. not(); for (int i = 0; i < 128; i++) { expectEquals(0xf800000000000000L, a[i], "not"); } // Done. System.out.println("passed");
<|startcomment|> android <|endcomment|>  */ @SdkConstant(SdkConstantType.BROADCAST_INTENT_ACTION) public static final String ACTION_REPORT = "android.bluetooth.input.profile.action.REPORT"; /** * @hide */ @SdkConstant(SdkConstantType.BROADCAST_INTENT_ACTION) public static final String ACTION_VIRTUAL_UNPLUG_STATUS = "android.bluetooth.input.profile.action.VIRTUAL_UNPLUG_STATUS"; /** * @hide */ @SdkConstant(SdkConstantType.BROADCAST_INTENT_ACTION) public static final String ACTION_IDLE_TIME_CHANGED = <|startfocus|> "codeaurora.bluetooth.input.profile.action.IDLE_TIME_CHANGED"; <|endfocus|> /** * Return codes for the connect and disconnect Bluez / Dbus calls. * @hide */ public static final int INPUT_DISCONNECT_FAILED_NOT_CONNECTED = 5000; /** * @hide */ public static final int INPUT_CONNECT_FAILED_ALREADY_CONNECTED = 5001; /** * @hide */ public static final int INPUT_CONNECT_FAILED_ATTEMPT_FAILED = 5002; /** * @hide */ public static final int INPUT_OPERATION_GENERIC_FAILURE = 5003; /** * @hide */
<|startcomment|> android <|endcomment|>  /** * @hide */ public static final String EXTRA_REPORT = "android.bluetooth.BluetoothInputDevice.extra.REPORT"; /** * @hide */ public static final String EXTRA_STATUS = "android.bluetooth.BluetoothInputDevice.extra.STATUS"; /** * @hide */ public static final String EXTRA_VIRTUAL_UNPLUG_STATUS = "android.bluetooth.BluetoothInputDevice.extra.VIRTUAL_UNPLUG_STATUS"; /** * @hide */ <|startfocus|> public static final String EXTRA_IDLE_TIME = "codeaurora.bluetooth.BluetoothInputDevice.extra.IDLE_TIME"; <|endfocus|> private Context mContext; private ServiceListener mServiceListener; private BluetoothAdapter mAdapter; private IBluetoothInputDevice mService; final private IBluetoothStateChangeCallback mBluetoothStateChangeCallback = new IBluetoothStateChangeCallback.Stub() { public void onBluetoothStateChange(boolean up) { if (DBG) Log.d(TAG, "onBluetoothStateChange: up=" + up); if (!up) { if (VDBG) Log.d(TAG,"Unbinding service..."); synchronized (mConnection) { try { mService = null; mContext.unbindService(mConnection);
<|startcomment|> Looking at TelephonyRegistry it doesn't look like listening for SignalStrength requires a permission - we should mimic other accessors of SignalStrength in this regard. <|endcomment|>  */ public boolean getEmergencyCallbackMode(int subId) { try { ITelephony telephony = getITelephony(); if (telephony == null) { return false; } return telephony.getEmergencyCallbackMode(subId); } catch (RemoteException e) { Log.e(TAG, "Error calling ITelephony#getEmergencyCallbackMode", e); } return false; } /** * Get the most recently available signal strength information. * <|startfocus|> * <p>Requires Permission: * {@link android.Manifest.permission#READ_PHONE_STATE} * <|endfocus|> * Get the most recent SignalStrength information reported by the modem. Due * to power saving this information may not always be current. * @return the most recent cached signal strength info from the modem * @hide */ @Nullable public SignalStrength getSignalStrength() { try { ITelephony service = getITelephony(); if (service != null) { return service.getSignalStrength(getSubId(), getOpPackageName()); } } catch (RemoteException e) {
<|startcomment|> -> have an associated dex cache. (here and below). <|endcomment|>  * class. The testcase checks that no any unexpected ERROR is returned and that * the JSR45 metadata matches the expected value. */ public void testSourceDebugExtension001() { doTest("testSourceDebugExtension001", "Lorg/apache/harmony/jpda/tests/jdwp/Events/SourceDebugExtensionMockClass;", JDWPConstants.Error.NONE); } /** * This testcase exercises ReferenceType.SourceDebugExtension command. * * The class queried is a primitive type which on ART does not <|startfocus|> * have a DEX cache installed. <|endfocus|> */ public void testSourceDebugExtension002() { doTest("testSourceDebugExtension001", "I", JDWPConstants.Error.ABSENT_INFORMATION); } /** * This testcase exercises ReferenceType.SourceDebugExtension command. * * The class queried is a primitive array which on ART does not * have a DEX cache installed. */ public void testSourceDebugExtension003() { doTest("testSourceDebugExtension003", "[I", JDWPConstants.Error.ABSENT_INFORMATION); } /** * This testcase exercises ReferenceType.SourceDebugExtension command. *
<|startcomment|> probably needs a change comment: // Android-change: lazy initialization of hostnameVerifier. or similar? <|endcomment|>  * the server name from the certificate mismatch. */ defaultHostnameVerifier = (HostnameVerifier) Class.forName("com.android.okhttp.internal.tls.OkHostnameVerifier") .getField("INSTANCE").get(null); originalDefaultHostnameVerifierClass = defaultHostnameVerifier.getClass(); } catch (Exception e) { throw new AssertionError("Failed to obtain okhttp HostnameVerifier", e); } } } /** * The <code>hostnameVerifier</code> for this object. */ <|startfocus|> protected HostnameVerifier hostnameVerifier; <|endfocus|> /** * Sets the default <code>HostnameVerifier</code> inherited by a * new instance of this class. * <P> * If this method is not called, the default * <code>HostnameVerifier</code> assumes the connection should not * be permitted. * * @param v the default host name verifier * @throws IllegalArgumentException if the <code>HostnameVerifier</code> * parameter is null. * @throws SecurityException if a security manager exists and its * <code>checkPermission</code> method does not allow
<|startcomment|> This is redundant: If the right hand side of the '||' operator is evaluated, it is because ni != null. <|endcomment|>  // missing server, so no trusted time available return false; } // We can't do this at initialization time: ConnectivityService might not be running yet. synchronized (this) { if (mCM == null) { mCM = (ConnectivityManager) sContext.getSystemService(Context.CONNECTIVITY_SERVICE); } } final NetworkInfo ni = mCM == null ? null : mCM.getActiveNetworkInfo(); <|startfocus|> if (ni == null || (ni != null && !ni.isConnected())) { <|endfocus|> if (LOGD) Log.d(TAG, "forceRefresh: no connectivity"); return false; } if (LOGD) Log.d(TAG, "forceRefresh() from cache miss"); final SntpClient client = new SntpClient(); if (client.requestTime(mServer, (int) mTimeout)) { mHasCache = true; mCachedNtpTime = client.getNtpTime(); mCachedNtpElapsedRealtime = client.getNtpTimeReference(); mCachedNtpCertainty = client.getRoundTripTime() / 2; return true; } else { return false; }
<|startcomment|> line too long <|endcomment|>  private void onPollNetworkTime(int event) { // If Automatic time is not set, don't bother. <|startfocus|> final NetworkInfo netInfo = mConnManager == null ? null : mConnManager.getActiveNetworkInfo(); if (!isAutomaticTimeRequested() || !netInfo.isConnected()) return; <|endfocus|> mWakeLock.acquire(); try { onPollNetworkTimeUnderWakeLock(event); } finally { mWakeLock.release(); }
<|startcomment|> Could you unfold this similarly to the original "if (!isAutomaticTimeRequested()) return;": if (!isAutomaticTimeRequested()) return; if (mConnManager == null) return; if (!mConnManager.getActiveNetworkInfo().isConnected()) return; This would prevent the bug where mConnManager is null, netInfo gets assigned to null on line 167, and netInfo.isConnected() throws a NPE on line 168. Also, getActiveNetworkInfo() is a binder call that needs to take a lock in the framework. It would be better if it is done after the early return from !isAutomaticTimeRequested(). <|endcomment|>  private void onPollNetworkTime(int event) { // If Automatic time is not set, don't bother. <|startfocus|> final NetworkInfo netInfo = mConnManager == null ? null : mConnManager.getActiveNetworkInfo(); if (!isAutomaticTimeRequested() || !netInfo.isConnected()) return; <|endfocus|> mWakeLock.acquire(); try { onPollNetworkTimeUnderWakeLock(event); } finally { mWakeLock.release(); }
<|startcomment|> What does "unavailable" mean? These classes exist, do you mean "nonfunctional"? (I think the term "legacy security code" is used elsewhere). When the change is not *purely* a removal, I personally prefer Android-changed. I also prefer a "." at the end, when there is space. But up to you. <|endcomment|>  * * You should have received a copy of the GNU General Public License version * 2 along with this work; if not, write to the Free Software Foundation, * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA. * * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA * or visit www.oracle.com if you need additional information or have any * questions. */ package javax.security.auth; <|startfocus|> // Android-removed: This permission system is unavailable on Android <|endfocus|> /** * Legacy security code; do not use. */ public final class AuthPermission extends java.security.BasicPermission { public AuthPermission(String name) { super(""); } public AuthPermission(String name, String actions) { super("", ""); } } 
<|startcomment|> [nit] Okay with me to use a name like "mCM", if only to help avoid line length issues and line-wrapping. <|endcomment|>  public NetworkTimeUpdateService(Context context) { mContext = context; mTime = NtpTrustedTime.getInstance(context); mAlarmManager = (AlarmManager) mContext.getSystemService(Context.ALARM_SERVICE); <|startfocus|> mConnManager = (ConnectivityManager) mContext.getSystemService(Context.CONNECTIVITY_SERVICE); <|endfocus|> Intent pollIntent = new Intent(ACTION_POLL, null); mPendingPollIntent = PendingIntent.getBroadcast(mContext, POLL_REQUEST, pollIntent, 0); mPollingIntervalMs = mContext.getResources().getInteger( com.android.internal.R.integer.config_ntpPollingInterval); mPollingIntervalShorterMs = mContext.getResources().getInteger( com.android.internal.R.integer.config_ntpPollingIntervalShorter); mTryAgainTimesMax = mContext.getResources().getInteger( com.android.internal.R.integer.config_ntpRetry); mTimeErrorThresholdMs = mContext.getResources().getInteger( com.android.internal.R.integer.config_ntpThreshold); mWakeLock = ((PowerManager) context.getSystemService(Context.POWER_SERVICE)).newWakeLock( PowerManager.PARTIAL_WAKE_LOCK, TAG);
<|startcomment|> Might be better to call it something like NetworkTimeCallback or TimeServiceNetworkCallback, to avoid confusion with the same name of its base class. <|endcomment|>  } } }; /** Handler to do the network accesses on */ private class MyHandler extends Handler { public MyHandler(Looper l) { super(l); } @Override public void handleMessage(Message msg) { switch (msg.what) { case EVENT_AUTO_TIME_CHANGED: case EVENT_POLL_NETWORK_TIME: case EVENT_NETWORK_CHANGED: onPollNetworkTime(msg.what); break; } } } <|startfocus|> private class NetworkCallback extends ConnectivityManager.NetworkCallback{ <|endfocus|> @Override public void onCapabilitiesChanged(Network network, NetworkCapabilities networkCapabilities) { if (networkCapabilities.hasCapability(NetworkCapabilities.NET_CAPABILITY_VALIDATED)){ mNetworkValidated = true; }else { mNetworkValidated = false; } } } /** Observer to watch for changes to the AUTO_TIME setting */ private static class SettingsObserver extends ContentObserver { private int mMsg; private Handler mHandler; SettingsObserver(Handler handler, int msg) { super(handler); mHandler = handler; mMsg = msg; } void observe(Context context) {
<|startcomment|> [nit] a space before { would be nice. <|endcomment|>  } } }; /** Handler to do the network accesses on */ private class MyHandler extends Handler { public MyHandler(Looper l) { super(l); } @Override public void handleMessage(Message msg) { switch (msg.what) { case EVENT_AUTO_TIME_CHANGED: case EVENT_POLL_NETWORK_TIME: case EVENT_NETWORK_CHANGED: onPollNetworkTime(msg.what); break; } } } <|startfocus|> private class NetworkCallback extends ConnectivityManager.NetworkCallback{ <|endfocus|> @Override public void onCapabilitiesChanged(Network network, NetworkCapabilities networkCapabilities) { if (networkCapabilities.hasCapability(NetworkCapabilities.NET_CAPABILITY_VALIDATED)){ mNetworkValidated = true; }else { mNetworkValidated = false; } } } /** Observer to watch for changes to the AUTO_TIME setting */ private static class SettingsObserver extends ContentObserver { private int mMsg; private Handler mHandler; SettingsObserver(Handler handler, int msg) { super(handler); mHandler = handler; mMsg = msg; } void observe(Context context) {
<|startcomment|> Could just be: mNetworkValidated = netCap.hasCapability(NET_...VALIDATED); <|endcomment|>  public void onCapabilitiesChanged(Network network, NetworkCapabilities networkCapabilities) { if (networkCapabilities.hasCapability(NetworkCapabilities.NET_CAPABILITY_VALIDATED)){ mNetworkValidated = true; }else { mNetworkValidated = false; } <|startfocus|> <|endfocus|>
<|startcomment|> This is kind of the old way of doing things. I think a better way would be to have this class register a request to track the default network via CM.registerDefaultNetworkCallback(cb, mHandler). The callback could just update a volatile boolean "isConnected" for now whenever the network capabilities have NET_CAPABILITY_VALIDATED. <|endcomment|>  private void onPollNetworkTime(int event) { // If Automatic time is not set, don't bother. final NetworkInfo netInfo = mConnManager == null ? null : mConnManager.getActiveNetworkInfo(); <|startfocus|> if (!isAutomaticTimeRequested() || <|endfocus|> netInfo == null || !netInfo.isConnected()) return; mWakeLock.acquire(); try { onPollNetworkTimeUnderWakeLock(event); } finally { mWakeLock.release(); }
<|startcomment|> Just relying on this state might lead to problems, especially if there are errors which cause the meta data to be loaded but not consumed. Looks like p1 and p2 are already being used so maybe a new instruction to split the meta/no-meta locks? It still requires locks with meta data to "use it right" but I'm not sure what the potential cost of that might be. <|endcomment|>  return; case INS_GET_LOCK: /* getLock(lockId, sendMetadata) */ resp = sendLockData(apdu, p1, p2); if (resp != 0) { sendResponseCode(apdu, resp); } return; case INS_SET_LOCK: /* setlock(index, val) { data } */ if (p1 >= (byte)locks.length) { sendResponseCode(apdu, (short)0x0100); return; } <|startfocus|> if (metadataLength == (short) 0) { resp = locks[p1].set(p2); sendResponseCode(apdu, resp); <|endfocus|> return; } resp = locks[p1].setWithMetadata(p2, metadata, (short) 0, metadataLength); // "Consume" the metadata. metadataLength = (short)0; sendResponseCode(apdu, resp); return; case INS_SET_PRODUCTION: /* setProduction(p1) */ if (globalState.setProduction(enable) == true) { resp = 0x0000; } else { resp = 0x0001; } sendResponseCode(apdu, resp); return; /* carrierLockTest() { testVector } */
<|startcomment|> deactivate? <|endcomment|> import android.widget.TextView; import java.io.IOException; import java.net.HttpURLConnection; import java.net.MalformedURLException; import java.net.URL; import java.lang.InterruptedException; import java.lang.reflect.Field; import java.lang.reflect.Method; import java.util.Random; public class CaptivePortalLoginActivity extends Activity { private static final String TAG = CaptivePortalLoginActivity.class.getSimpleName(); private static final boolean DBG = true; <|startfocus|> // Turn this flag on to desactivate auto-closing after successful captive portal login. private static final boolean NO_AUTOCLOSE = false; <|endfocus|> private static final int SOCKET_TIMEOUT_MS = 10000; private enum Result { DISMISSED, UNWANTED, WANTED_AS_IS }; private URL mUrl; private String mUserAgent; private Network mNetwork; private CaptivePortal mCaptivePortal; private NetworkCallback mNetworkCallback; private ConnectivityManager mCm; private boolean mLaunchBrowser = false; private MyWebViewClient mWebViewClient; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); mCm = ConnectivityManager.from(this);
<|startcomment|> Does this belong here or at the end of done()? I would seem to me, with only a cursory glance, that it might be better with: done(...) { if (!NO_AUTOCLOSE) { finishAndRemoveTask(); } } maybe? <|endcomment|>  private void testForCaptivePortal() { <|startfocus|> if (NO_AUTOCLOSE) { return; } <|endfocus|> // TODO: reuse NetworkMonitor facilities for consistent captive portal detection. new Thread(new Runnable() { public void run() { // Give time for captive portal to open. try { Thread.sleep(1000); } catch (InterruptedException e) { } HttpURLConnection urlConnection = null; int httpResponseCode = 500; try { urlConnection = (HttpURLConnection) mNetwork.openConnection(mUrl); urlConnection.setInstanceFollowRedirects(false); urlConnection.setConnectTimeout(SOCKET_TIMEOUT_MS); urlConnection.setReadTimeout(SOCKET_TIMEOUT_MS); urlConnection.setUseCaches(false); if (mUserAgent != null) { urlConnection.setRequestProperty("User-Agent", mUserAgent); } // cannot read request header after connection String requestHeader = urlConnection.getRequestProperties().toString(); urlConnection.getInputStream(); httpResponseCode = urlConnection.getResponseCode(); if (DBG) { Log.d(TAG, "probe at " + mUrl +
<|startcomment|> onPollNetworkTime will be call when network available, so we think that the line is useless. @Erik <|endcomment|>  public void systemRunning() { registerForTelephonyIntents(); registerForAlarms(); HandlerThread thread = new HandlerThread(TAG); thread.start(); mHandler = new MyHandler(thread.getLooper()); mNetworkTimeUpdateCallback = new NetworkTimeUpdateCallback(); mCM.registerDefaultNetworkCallback(mNetworkTimeUpdateCallback, mHandler); <|startfocus|> // Check the network time on the new thread mHandler.obtainMessage(EVENT_POLL_NETWORK_TIME).sendToTarget(); <|endfocus|> mSettingsObserver = new SettingsObserver(mHandler, EVENT_AUTO_TIME_CHANGED); mSettingsObserver.observe(mContext);
<|startcomment|> "netCap" makes this line shorter. <|endcomment|> <|startfocus|> public void onCapabilitiesChanged(Network network, NetworkCapabilities networkCapabilities) { mNetworkValidated = networkCapabilities.hasCapability( <|endfocus|> NetworkCapabilities.NET_CAPABILITY_VALIDATED);
<|startcomment|> import android.net.Network; <|endcomment|> <|startfocus|> public void onCapabilitiesChanged(Network network, NetworkCapabilities networkCapabilities) { mNetworkValidated = networkCapabilities.hasCapability( <|endfocus|> NetworkCapabilities.NET_CAPABILITY_VALIDATED);
<|startcomment|> import android.net.NetworkCapabilities; <|endcomment|> <|startfocus|> public void onCapabilitiesChanged(Network network, NetworkCapabilities networkCapabilities) { mNetworkValidated = networkCapabilities.hasCapability( <|endfocus|> NetworkCapabilities.NET_CAPABILITY_VALIDATED);
<|startcomment|> Why aren't there loop_optimization after cases? Why aren't there disassembly after cases? It's neither checking for vector HIR nor SIMD instructions actually being emitted. Am I misunderstanding something? (Here and in all the other test files) <|endcomment|>  /// CHECK-DAG: <<Get2:b\d+>> ArrayGet loop:<<Loop>> outer_loop:none /// CHECK-DAG: <<Max:i\d+>> InvokeStaticOrDirect [<<Get1>>,<<Get2>>] intrinsic:MathMaxIntInt loop:<<Loop>> outer_loop:none /// CHECK-DAG: <<Cnv:b\d+>> TypeConversion [<<Max>>] loop:<<Loop>> outer_loop:none /// CHECK-DAG: ArraySet [{{l\d+}},<<Phi>>,<<Cnv>>] loop:<<Loop>> outer_loop:none // <|startfocus|> // TODO: narrow type vectorization. <|endfocus|> private static void doitMax(byte[] x, byte[] y, byte[] z) { int min = Math.min(x.length, Math.min(y.length, z.length)); for (int i = 0; i < min; i++) { x[i] = (byte) Math.max(y[i], z[i]); } } public static void main(String[] args) { // Initialize cross-values for the interesting values. int total = 256 * 256; byte[] x = new byte[total];
<|startcomment|> remove? <|endcomment|>  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package android.telephony; import android.content.ComponentName; import android.content.Context; import android.content.Intent; import android.content.ServiceConnection; import android.content.pm.PackageManager; import android.content.pm.ResolveInfo; import android.os.DeadObjectException; import android.os.IBinder; import android.os.RemoteException; <|startfocus|> import android.telephony.mbms.IMbmsStreamingManagerCallback; import android.telephony.mbms.IStreamingServiceCallback; <|endfocus|> import android.telephony.mbms.MbmsException; import android.telephony.mbms.StreamingService; import android.telephony.mbms.StreamingServiceInfo; import android.telephony.mbms.vendor.IMbmsStreamingService; import android.util.Log; import java.util.LinkedList; import java.util.List; import java.util.concurrent.CountDownLatch; import java.util.concurrent.TimeUnit; import static android.telephony.SubscriptionManager.INVALID_SUBSCRIPTION_ID; /** @hide */ public class MbmsStreamingManager { private interface ServiceListener { void onServiceConnected(); void onServiceDisconnected(); } private static final String LOG_TAG = "MbmsStreamingManager";
<|startcomment|> I am wondering what is the risk here, because the with this version SDK_INT is known at compile time, whereas with the framework version, the value is known a runtime. Maybe the desugaring tool take the value by introspection, but, anyway, it is an implementation detail, no? <|endcomment|>  * limitations under the License. */ package android.os; /** * Mimics the real Android class when running tests on host. This class is needed by the code * generated by Desugar to choose the runtime strategy of try-with-resource based on the android * runtime version. Set it to 17 to force to use the mimic desugaring strategy. */ public class Build { public static class VERSION { public static final int SDK_INT = 17; <|startfocus|> public static final String SDK = "17"; <|endfocus|> } } 
<|startcomment|> Needed? <|endcomment|>  * limitations under the License. */ package android.os; /** * Mimics the real Android class when running tests on host. This class is needed by the code * generated by Desugar to choose the runtime strategy of try-with-resource based on the android * runtime version. Set it to 17 to force to use the mimic desugaring strategy. */ public class Build { public static class VERSION { public static final int SDK_INT = 17; <|startfocus|> public static final String SDK = "17"; <|endfocus|> } } 
<|startcomment|> Maybe rename to VALID_USER and VALID_PASSWORD since it's now appearing in the tests. <|endcomment|> import java.util.List; import java.util.Locale; import java.util.Objects; import java.util.Random; import java.util.concurrent.CountDownLatch; import java.util.concurrent.Semaphore; import java.util.concurrent.TimeUnit; import static java.nio.charset.StandardCharsets.UTF_8; /** * Tests URLConnections for ftp:// URLs. */ public class FtpURLConnectionTest extends TestCase { private static final String FILE_PATH = "test/file/for/FtpURLConnectionTest.txt"; <|startfocus|> private static final String USER = "user"; private static final String PASSWORD = "password"; <|endfocus|> private static final String SERVER_HOSTNAME = "localhost"; private static final String USER_HOME_DIR = "/home/user"; private FakeFtpServer fakeFtpServer; private UnixFakeFileSystem fileSystem; @Override public void setUp() throws Exception { super.setUp(); fakeFtpServer = new FakeFtpServer(); fakeFtpServer.setServerControlPort(0 /* allocate port number automatically */); fakeFtpServer.addUserAccount(new UserAccount(USER, PASSWORD, USER_HOME_DIR)); fileSystem = new UnixFakeFileSystem(); fakeFtpServer.setFileSystem(fileSystem);
<|startcomment|> Remove one blank line. <|endcomment|>  int total = interesting.length * interesting.length; short[] x = new short[total]; short[] y = new short[total]; short[] z = new short[total]; int k = 0; for (int i = 0; i < interesting.length; i++) { for (int j = 0; j < interesting.length; j++) { x[k] = 0; y[k] = interesting[i]; z[k] = interesting[j]; k++; } } <|startfocus|> <|endfocus|> // And test. doitMin(x, y, z); for (int i = 0; i < total; i++) { short expected = (short) Math.min(y[i], z[i]); expectEquals(expected, x[i]); } doitMax(x, y, z); for (int i = 0; i < total; i++) { short expected = (short) Math.max(y[i], z[i]); expectEquals(expected, x[i]); } System.out.println("passed");
<|startcomment|> What about an enum for categories ? toString() on enum will print the name as expected. <|endcomment|> <|startfocus|> private void recordAndEmit(String category, String msg) { <|endfocus|> final String entry = logLine(category, msg); mLocalLog.log(entry); if (ERROR.equals(category)) { Log.e(mTag, entry); } else { Log.d(mTag, entry); }
<|startcomment|> Unused? <|endcomment|>  import android.content.Context; import android.content.ContextWrapper; import android.content.res.Resources; import android.support.test.filters.SmallTest; import android.support.test.runner.AndroidJUnit4; import android.telephony.TelephonyManager; import com.android.internal.util.test.BroadcastInterceptingContext; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.MockitoAnnotations; @RunWith(AndroidJUnit4.class) @SmallTest public class TetheringConfigurationTest { <|startfocus|> private static final String[] PROVISIONING_APP_NAME = {"some", "app"}; <|endfocus|> @Mock private Context mContext; @Mock private TelephonyManager mTelephonyManager; @Mock private Resources mResources; private Context mMockContext; private boolean mWithTelephonyManager; private class MockContext extends BroadcastInterceptingContext { MockContext(Context base) { super(base); } @Override public Resources getResources() { return mResources; } @Override public Object getSystemService(String name) { if (Context.TELEPHONY_SERVICE.equals(name)) { return mWithTelephonyManager ? mTelephonyManager : null; } return super.getSystemService(name); } }
<|startcomment|> mHasTelephonyManager? <|endcomment|> import android.telephony.TelephonyManager; import com.android.internal.util.test.BroadcastInterceptingContext; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.MockitoAnnotations; @RunWith(AndroidJUnit4.class) @SmallTest public class TetheringConfigurationTest { private static final String[] PROVISIONING_APP_NAME = {"some", "app"}; @Mock private Context mContext; @Mock private TelephonyManager mTelephonyManager; @Mock private Resources mResources; private Context mMockContext; <|startfocus|> private boolean mWithTelephonyManager; <|endfocus|> private class MockContext extends BroadcastInterceptingContext { MockContext(Context base) { super(base); } @Override public Resources getResources() { return mResources; } @Override public Object getSystemService(String name) { if (Context.TELEPHONY_SERVICE.equals(name)) { return mWithTelephonyManager ? mTelephonyManager : null; } return super.getSystemService(name); } } @Before public void setUp() throws Exception { MockitoAnnotations.initMocks(this);
<|startcomment|> update this. <|endcomment|>  * is only meant for debugging and is not guaranteed to be stable across * releases and/or devices. * * @hide */ public static native String getDexFileStatus(String fileName, String instructionSet) throws FileNotFoundException; /** <|startfocus|> * Returns the full file path of the optimized dex file {@code fileName}. The returned string * is the full file name including path of optimized dex file, if it exists. <|endfocus|> * @hide */ public static native String[] getDexFileOutputPath(String fileName, String instructionSet) throws FileNotFoundException; /** * Returns whether the given filter is a valid filter. * * @hide */ public native static boolean isValidCompilerFilter(String filter); /** * Returns whether the given filter is based on profiles. * * @hide */ public native static boolean isProfileGuidedCompilerFilter(String filter); /** * Returns the version of the compiler filter that is not based on profiles.
<|startcomment|> Rename this to getDexFileOutputPaths ? <|endcomment|>  * releases and/or devices. * * @hide */ public static native String getDexFileStatus(String fileName, String instructionSet) throws FileNotFoundException; /** * Returns the full file path of the optimized dex file {@code fileName}. The returned string * is the full file name including path of optimized dex file, if it exists. * @hide */ <|startfocus|> public static native String[] getDexFileOutputPath(String fileName, String instructionSet) <|endfocus|> throws FileNotFoundException; /** * Returns whether the given filter is a valid filter. * * @hide */ public native static boolean isValidCompilerFilter(String filter); /** * Returns whether the given filter is based on profiles. * * @hide */ public native static boolean isProfileGuidedCompilerFilter(String filter); /** * Returns the version of the compiler filter that is not based on profiles. * If the input is not a valid filter, or the filter is already not based on
<|startcomment|> files <|endcomment|>  // determine the ABI from either ApplicationInfo or Build String arch = "arm"; if (cameraInfo.primaryCpuAbi != null && VMRuntime.is64BitAbi(cameraInfo.primaryCpuAbi)) { arch = arch + "64"; } else { if (VMRuntime.is64BitAbi(Build.SUPPORTED_ABIS[0])) { arch = arch + "64"; } } // get the path to the odex or oat file String baseCodePath = cameraInfo.getBaseCodePath(); String[] optimizedCode = null; try { <|startfocus|> optimizedCode = DexFile.getDexFileOutputPath(baseCodePath, arch); <|endfocus|> } catch (IOException ioe) {} if (optimizedCode == null) { return true; } //not pinning the oat/odex is not a fatal error for (int i = 0; i < optimizedCode.length; i++) { pf = pinFile(optimizedCode[i], 0, 0, MAX_CAMERA_PIN_SIZE); if (pf != null) { mPinnedCameraFiles.add(pf); if (DEBUG) { Slog.i(TAG, "Pinned " + pf.mFilename); } }
<|startcomment|> for (String file : files) <|endcomment|>  String baseCodePath = cameraInfo.getBaseCodePath(); String[] optimizedCode = null; try { optimizedCode = DexFile.getDexFileOutputPath(baseCodePath, arch); } catch (IOException ioe) {} if (optimizedCode == null) { return true; } //not pinning the oat/odex is not a fatal error <|startfocus|> for (int i = 0; i < optimizedCode.length; i++) { pf = pinFile(optimizedCode[i], 0, 0, MAX_CAMERA_PIN_SIZE); <|endfocus|> if (pf != null) { mPinnedCameraFiles.add(pf); if (DEBUG) { Slog.i(TAG, "Pinned " + pf.mFilename); } } } return true;
<|startcomment|> MAX_CAMERA_PIN_SIZE can now be exceeded if the sum of the sizes of files returned by getDexFileOutputPaths exceeds it. Is that intentional? <|endcomment|>  String baseCodePath = cameraInfo.getBaseCodePath(); String[] optimizedCode = null; try { optimizedCode = DexFile.getDexFileOutputPath(baseCodePath, arch); } catch (IOException ioe) {} if (optimizedCode == null) { return true; } //not pinning the oat/odex is not a fatal error <|startfocus|> for (int i = 0; i < optimizedCode.length; i++) { pf = pinFile(optimizedCode[i], 0, 0, MAX_CAMERA_PIN_SIZE); <|endfocus|> if (pf != null) { mPinnedCameraFiles.add(pf); if (DEBUG) { Slog.i(TAG, "Pinned " + pf.mFilename); } } } return true;
<|startcomment|> The broadcast is sent to all running users except the one that has been removed. so registerReceiever should be good enough. <|endcomment|>  packageIntentFilter.addAction(Intent.ACTION_PACKAGE_REMOVED); packageIntentFilter.addAction(Intent.ACTION_PACKAGE_ADDED); packageIntentFilter.addDataScheme("package"); context.registerReceiverAsUser(mReceiver, UserHandle.ALL, packageIntentFilter, null, null); IntentFilter bootIntentFilter = new IntentFilter(Intent.ACTION_BOOT_COMPLETED); context.registerReceiverAsUser(mReceiver, UserHandle.ALL, bootIntentFilter, null, null); IntentFilter userRemovedFilter = new IntentFilter(Intent.ACTION_USER_REMOVED); <|startfocus|> context.registerReceiverAsUser(mReceiver, UserHandle.ALL, userRemovedFilter, null, null); <|endfocus|> Uri defaultDialerSetting = Settings.Secure.getUriFor(Settings.Secure.DIALER_DEFAULT_APPLICATION); context.getContentResolver() .registerContentObserver(defaultDialerSetting, false, mDefaultDialerObserver, UserHandle.USER_ALL);
<|startcomment|> Is there a reason why the log is the first parameter? (Here and elsewhere.) Often the recommendation is to have the most important parameters at the beginning. <|endcomment|> <|startfocus|> public IPv6TetheringCoordinator( SharedLog log, ArrayList<TetherInterfaceStateMachine> notifyList) { mLog = log.forSubComponent(TAG); <|endfocus|> mNotifyList = notifyList; mActiveDownstreams = new LinkedList<>(); mUniqueLocalPrefix = generateUniqueLocalPrefix(); mNextSubnetId = 0;
<|startcomment|> Also consider using "e" here for consistency with android.util.Log. Other levels might be "i", "w", "v", etc. <|endcomment|> <|startfocus|> public void error(String msg) { recordAndEmit(Category.ERROR, msg); <|endfocus|>
<|startcomment|> There's an inconsistency here between what logs+emits and what just logs. In the future I fear we could be surprised if we do: error(...); event(...); error(...); and we don't find event in the system log. Maybe make all the functions both emit and log? <|endcomment|>  } public void dump(FileDescriptor fd, PrintWriter writer, String[] args) { mLocalLog.readOnlyLocalLog().dump(fd, writer, args); } public void error(Exception e) { recordAndEmit(Category.ERROR, e.toString()); } public void error(String msg) { recordAndEmit(Category.ERROR, msg); } public void event(String msg) { record(Category.EVENT, msg); } public void log(String msg) { record(Category.NONE, msg); } <|startfocus|> public void logAndEmit(String msg) { recordAndEmit(Category.NONE, msg); } <|endfocus|> public void mark(String msg) { record(Category.MARK, msg); } private void record(Category category, String msg) { mLocalLog.log(logLine(category, msg)); } private void recordAndEmit(Category category, String msg) { final String entry = logLine(category, msg); mLocalLog.log(entry); if (Category.ERROR.equals(category)) { Log.e(mTag, entry); } else { Log.d(mTag, entry); } } 
<|startcomment|> required <|endcomment|>  phoneAccountHandle = extras.getParcelable( TelecomManager.EXTRA_PHONE_ACCOUNT_HANDLE); } boolean isSelfManaged = phoneAccountHandle != null && isSelfManagedConnectionService(phoneAccountHandle); if (isSelfManaged) { mContext.enforceCallingOrSelfPermission(Manifest.permission.MANAGE_OWN_CALLS, "Self-managed ConnectionServices require MANAGE_OWN_CALLS permission."); if (!callingPackage.equals( phoneAccountHandle.getComponentName().getPackageName()) && !canCallPhone(callingPackage, <|startfocus|> "CALL_PHONE permission requried to place calls.")) { <|endfocus|> // The caller is not allowed to place calls, so we want to ensure that it // can only place calls through itself. throw new SecurityException("Self-managed ConnectionServices can only " + "place calls through their own ConnectionService."); } } else if (!canCallPhone(callingPackage, "placeCall")) { throw new SecurityException("Package " + callingPackage + " is not allowed to place phone calls"); } // Note: we can still get here for the default/system dialer, even if the Phone
<|startcomment|> Just FYI: pointer equality works for enums. <|endcomment|>  private String logLine(Category category, String msg) { final StringJoiner sj = new StringJoiner(" "); if (!isRootLogInstance()) sj.add("[" + mComponent + "]"); <|startfocus|> if (!Category.NONE.equals(category)) sj.add(category.toString()); <|endfocus|> return sj.add(msg).toString();
<|startcomment|> .. but you're pinging locally, right? Also see comments about ping on GatewayClient <|endcomment|>  * is used for accessing the key store and trust store for TLS * certificates. * * @param target The base URL for the server to be accessed. * @param conf The configuration for certificates and credentials. * @param mapper The object mapper. * @param loader The resource loader. */ public GatewayClient(String target, ClientConfig conf, ObjectMapper mapper, ResourceLoader loader) { super(target, conf, mapper, loader); } /** <|startfocus|> * Ping the peer Acumos. <|endfocus|> * * @param peerId The ID of the peer Acumos. * @return Information about the peer. */ public MLPPeer ping(String peerId) { return handleResponse(PEER_PFX + FederationClient.PING_URI, new ParameterizedTypeReference<JsonResponse<MLPPeer>>(){}, peerId); } /** * Ask the peer about its peers. * * @param peerId The ID of the peer Acumos. * @return The list of the peer's peers. */ public List<MLPPeer> getPeers(String peerId) {
<|startcomment|> What does registration accomplish? I mean, does it cause a change in state inside the target local gateway? <|endcomment|>  } /** * Ask the peer about its peers. * * @param peerId The ID of the peer Acumos. * @return The list of the peer's peers. */ public List<MLPPeer> getPeers(String peerId) { return handleResponse(PEER_PFX + FederationClient.PEERS_URI, new ParameterizedTypeReference<JsonResponse<List<MLPPeer>>>(){}, peerId); } /** <|startfocus|> * Register with the peer. <|endfocus|> * * @param peerId The ID of the peer Acumos. * @return Information about the peer. */ public MLPPeer register(String peerId) { return handleResponse(PEER_PFX + FederationClient.REGISTER_URI, HttpMethod.POST, new ParameterizedTypeReference<JsonResponse<MLPPeer>>(){}, peerId); } /** * Ask the peer for a list of catalogs. * * @param peerId The ID of the peer Acumos. * @return The list of catalogs (enhanced with their sizes), the peer is willing to share. */ public List<MLPCatalog> getCatalogs(String peerId) {
<|startcomment|> server <|endcomment|>  * * Configuration classes are also Conponents so they are subject to Component scanning. */ @SpringBootApplication @EnableAutoConfiguration(exclude = { DataSourceAutoConfiguration.class, DataSourceTransactionManagerAutoConfiguration.class, HibernateJpaAutoConfiguration.class }) @EnableConfigurationProperties @ComponentScan(basePackages = "org.acumos.federation", useDefaultFilters = false, includeFilters = @ComponentScan.Filter(type=FilterType.ASSIGNABLE_TYPE, classes={org.acumos.federation.gateway.config.GatewayConfiguration.class, org.acumos.federation.gateway.config.AdapterConfiguration.class})) <|startfocus|> public class Application { <|endfocus|> private final static EELFLoggerDelegate logger = EELFLoggerDelegate.getLogger(Application.class); /** * We should be able to swap the LocalConfiguration in the case of adapters. */ public static void main(String[] args) throws Exception { SpringApplicationBuilder gatewayBuilder = new SpringApplicationBuilder(Application.class) .bannerMode(Banner.Mode.OFF) .web(false); gatewayBuilder.child(FederationConfiguration.class) .bannerMode(Banner.Mode.OFF) .web(true) .run(args); gatewayBuilder.child(LocalConfiguration.class)
<|startcomment|> CDS createSolution() method creates tags not seen before. One of the very few things it does without being asked. <|endcomment|>  public MLPSolution createSolution(MLPSolution solution) { <|startfocus|> Set<MLPTag> tags = solution.getTags(); solution.setTags(Collections.emptySet()); solution = clients.getCDSClient().createSolution(solution); doTags(tags, solution.getSolutionId()); return solution; <|endfocus|>
<|startcomment|> Would you possibly consider a less generic name, just for clarity? <|endcomment|>  import com.github.dockerjava.api.DockerClient; import com.github.dockerjava.core.DefaultDockerClientConfig; import com.github.dockerjava.core.DockerClientBuilder; import org.acumos.cds.client.ICommonDataServiceRestClient; import org.acumos.cds.client.CommonDataServiceRestClientImpl; import org.acumos.federation.client.config.ClientConfig; import org.acumos.federation.client.ClientBase; import org.acumos.federation.client.FederationClient; /** * Defines all beans used to access outside services. * * By mocking this bean, all external access can be stubbed out. */ <|startfocus|> public class Clients { <|endfocus|> @Autowired private FederationConfig federation; @Autowired private ServiceConfig cdmsConfig; @Autowired private NexusConfig nexusConfig; @Autowired private DockerConfig dockerConfig; private ICommonDataServiceRestClient cdsClient; private NexusClient nexusClient; private DockerClient dockerClient; public FederationClient getFederationClient(String url) { return new FederationClient(url, federation); } public synchronized ICommonDataServiceRestClient getCDSClient() { if (cdsClient == null) { String url = cdmsConfig.getUrl(); ClientConfig cc = new ClientConfig(); cc.setCreds(cdmsConfig);
<|startcomment|> stream. Does this method close the stream when it's done? <|endcomment|>  public InputStream getArtifactContent(MLPArtifact artifact); /** * Set the URI for an artifact. * * @param solutionId The ID of the solution. * @param artifact The artifact to set the URI on. */ public void setArtifactUri(String solutionId, MLPArtifact artifact); /** * Put the content of an artifact. * * @param artifact The artifact to put. * @param tag The image tag in the input data. <|startfocus|> * @param is The data to put. <|endfocus|> */ public void putArtifactContent(MLPArtifact artifact, String tag, InputStream is); /** * Get the body of a document. * * @param document The document to retrieve. * @return An InputStream for reading the document's content. */ public InputStream getDocumentContent(MLPDocument document); /** * Set the URI for an document. * * @param solutionId The ID of the solution. * @param document The document to set the URI on. */
<|startcomment|> stream. Does this method close the stream when it's done? <|endcomment|>  */ public InputStream getDocumentContent(MLPDocument document); /** * Set the URI for an document. * * @param solutionId The ID of the solution. * @param document The document to set the URI on. */ public void setDocumentUri(String solutionId, MLPDocument document); /** * Put the content of a document. * * @param document The document to put. <|startfocus|> * @param is The data to put. <|endfocus|> */ public void putDocumentContent(MLPDocument document, InputStream is); } 
<|startcomment|> This isn't a web site -- why is this needed? <|endcomment|> import org.acumos.cds.domain.MLPSolutionRevision; import org.acumos.cds.domain.MLPArtifact; import org.acumos.cds.domain.MLPDocument; import org.acumos.federation.client.ClientBase; import org.acumos.federation.client.config.ClientConfig; import org.acumos.federation.client.FederationClient; import org.acumos.federation.client.data.Artifact; import org.acumos.federation.client.data.Document; import org.acumos.federation.client.data.JsonResponse; import org.acumos.federation.client.data.SolutionRevision; /** * Controller bean for the external (public) API. */ @Controller @CrossOrigin public class FederationController { <|startfocus|> private static final Logger log = LoggerFactory.getLogger(FederationController.class); <|endfocus|> @Autowired private FederationConfig federation; @Autowired private WebSecurityConfigurerAdapter security; @Autowired private PeerService peerService; @Autowired private CatalogService catalogService; @Autowired private ContentService contentService; private UriTemplateHandler originBuilder; private String makeOrigin(String uri, Object... params) { if (originBuilder == null) {
<|startcomment|> Please use the method handles lookup trick <|endcomment|> import org.acumos.cds.domain.MLPDocument; import org.acumos.federation.client.ClientBase; import org.acumos.federation.client.config.ClientConfig; import org.acumos.federation.client.FederationClient; import org.acumos.federation.client.data.Artifact; import org.acumos.federation.client.data.Document; import org.acumos.federation.client.data.JsonResponse; import org.acumos.federation.client.data.SolutionRevision; /** * Controller bean for the external (public) API. */ @Controller @CrossOrigin public class FederationController { <|startfocus|> private static final Logger log = LoggerFactory.getLogger(FederationController.class); <|endfocus|> @Autowired private FederationConfig federation; @Autowired private WebSecurityConfigurerAdapter security; @Autowired private PeerService peerService; @Autowired private CatalogService catalogService; @Autowired private ContentService contentService; private UriTemplateHandler originBuilder; private String makeOrigin(String uri, Object... params) { if (originBuilder == null) { originBuilder = ClientBase.buildRestTemplate("https://" + ((Security)security).getSelf().getSubjectName() + ":" + federation.getServer().getPort(), new ClientConfig(), null, null).getUriTemplateHandler(); }
<|startcomment|> Please call log.error, not info <|endcomment|>  public JsonResponse<Void> badRequestError(HttpServletRequest request, HttpServletResponse response, BadRequestException badRequest) { <|startfocus|> log.info("Request {} failed {} {} {}", request.getRequestURI(), badRequest.getMessage(), badRequest.getCode(), badRequest); <|endfocus|> JsonResponse<Void> ret = new JsonResponse<>(); ret.setError(badRequest.getMessage()); response.setStatus(badRequest.getCode()); return ret;
<|startcomment|> Please don't repeat the class name, use the MethodHandles.lookupClass() trick. <|endcomment|>  import org.acumos.cds.domain.MLPCatalog; import org.acumos.cds.domain.MLPSolution; import org.acumos.cds.domain.MLPPeer; import org.acumos.cds.domain.MLPPeerSubscription; import org.acumos.federation.client.FederationClient; import org.acumos.federation.client.GatewayClient; import org.acumos.federation.client.data.JsonResponse; /** * Controller bean for the internal (gateway) API. */ @Controller @CrossOrigin @Secured(Security.ROLE_INTERNAL) @RequestMapping(GatewayClient.PEER_PFX) public class GatewayController { <|startfocus|> private static final Logger log = LoggerFactory.getLogger(GatewayController.class); <|endfocus|> @Autowired private Clients clients; @Autowired private PeerService peerService; @Autowired private PeerGateway peerGateway; @ApiOperation(value = "Invoked by local Acumos to get a list of catalogs available from a peer Acumos instance .", response = MLPCatalog.class, responseContainer = "List") @RequestMapping(value = FederationClient.CATALOGS_URI, method = RequestMethod.GET, produces = MediaType.APPLICATION_JSON_UTF8_VALUE) @ResponseBody public JsonResponse<List<MLPCatalog>> getCatalogs( HttpServletResponse response, @PathVariable("peerId") String peerId) {
<|startcomment|> would you possibly consider a less generic name, maybe GatewaySecurity or ? <|endcomment|> import org.springframework.security.config.http.SessionCreationPolicy; import org.springframework.security.core.authority.SimpleGrantedAuthority; import org.springframework.security.core.context.SecurityContextHolder; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.userdetails.User; import org.acumos.cds.domain.MLPPeer; import org.acumos.federation.client.config.TlsConfig; import org.acumos.federation.client.FederationClient; /** * Service bean implementing authentication and peer identification services * on requests to the Federation Gateway. */ @Configuration @EnableWebSecurity <|startfocus|> public class Security extends WebSecurityConfigurerAdapter { <|endfocus|> /** * The role indicating a peer is allowed to register. */ public static final String ROLE_REGISTER = "ROLE_REGISTRATION"; /** * The role indicating a peer is allowed to cancel their registration. */ public static final String ROLE_UNREGISTER = "ROLE_UNREGISTRATION"; /** * The role indicating a peer has normal access to the gateway. */ public static final String ROLE_PEER = "ROLE_PEER"; /** * The role indicating a peer has trusted access to the gateway. */
<|startcomment|> Please log the exception. Maybe this is normal, but it sure looks like a strange case, creating an empty peer <|endcomment|>  if (alias == null) { Enumeration<String> aliases = ks.aliases(); while (aliases.hasMoreElements()) { alias = aliases.nextElement(); if (ks.entryInstanceOf(alias, KeyStore.PrivateKeyEntry.class)) { break; } } } myself = peerService.getSelf(getLdapNameField(new LdapName(((X509Certificate)ks.getCertificate(alias)).getSubjectX500Principal().getName()), "CN")); } } catch (Exception e) { myself = new MLPPeer(); <|startfocus|> myself.setStatusCode(PSC_UNKNOWN); <|endfocus|> }
<|startcomment|> This cast is not needed. Please remove. <|endcomment|>  logger.debug("JWTAuthorizationFilter() begin"); this.secretKey = secretKey; this.userService = new UserService(cdsClient); logger.debug("JWTAuthorizationFilter() end"); } /** * Method is called internally and should not be accessible directly using class instance. * */ @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws IOException, ServletException { logger.debug("doFilterInternal() begin"); <|startfocus|> HttpServletRequest httpRequest = (HttpServletRequest) request; <|endfocus|> String authToken = null; authToken = httpRequest.getHeader(AUTHORIZATION_HEADER_KEY); logger.debug("AUTHORIZATION_HEADER_KEY : " + authToken); if (authToken == null) { authToken = httpRequest.getHeader(JWT_TOKEN_HEADER_KEY); logger.debug("JWT_TOKEN_HEADER_KEY : " + authToken); } if (authToken == null) { authToken = request.getParameter(JWT_TOKEN_HEADER_KEY); logger.debug("JWT_TOKEN_HEADER_KEY : " + authToken); } if (authToken != null) {
<|startcomment|> no reason to separate these if conditions, please merge them. <|endcomment|>  logger.debug("JWT_TOKEN_HEADER_KEY : " + authToken); } if (authToken != null) { authToken = authToken.replace(TOKEN_PASS_KEY, ""); logger.debug("TOKEN_PASS_KEY : " + authToken); JWTTokenVO jwtTokenVO = JwtTokenUtil.getUserToken(authToken, secretKey); if (jwtTokenVO != null <|startfocus|> && !(SecurityContextHolder.getContext().getAuthentication() instanceof AnonymousAuthenticationToken)) { //validate token if (validateToken(jwtTokenVO, secretKey)) { <|endfocus|> MLPUser mlpUser = userService.findUserByUsername(jwtTokenVO.getUserName()); //TODO : Need to implement role base authority UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken( new AuthenticatedUser(mlpUser), authToken, new ArrayList<>()); authentication.setDetails(new WebAuthenticationDetailsSource() .buildDetails(httpRequest)); SecurityContextHolder.getContext().setAuthentication(authentication); } } } chain.doFilter(request, response); logger.debug("doFilterInternal() End"); } private boolean validateToken(JWTTokenVO jwtTokenVO, String secretKey) { logger.debug("validateToken() Begin");
<|startcomment|> This is *great* but please add a few bits of javadoc, or if you've explained it in RST somewhere, add a link to that. <|endcomment|>  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.federation.client; import java.util.List; import org.acumos.cds.domain.MLPCatalog; import org.acumos.federation.client.config.ClientConfig; import org.acumos.federation.client.config.TlsConfig; import org.acumos.federation.client.data.Catalog; import org.acumos.federation.client.FederationClient; import org.acumos.federation.client.GatewayClient; <|startfocus|> <|endfocus|> public class ClientDemo { private static final String peerApiUrl = "https://public.otheracumos.org:9084"; private static final String internalApiUrl = "https://federation-service:9011"; private static final String keystore = "keystore.jks"; private static final String keystorepass = "keystore_pass"; private static final String firstpeerid = "12345678-1234-1234-1234-1234567890ab"; private static final String secondpeerid = "cafebebe-cafe-bebe-cafe-bebecafebebe"; public static void main(String[] args) throws Exception { ClientConfig cconf = new ClientConfig();
<|startcomment|> Would you please add a PING (healthcheck) as the first item demonstrated? <|endcomment|>  private static final String keystorepass = "keystore_pass"; private static final String firstpeerid = "12345678-1234-1234-1234-1234567890ab"; private static final String secondpeerid = "cafebebe-cafe-bebe-cafe-bebecafebebe"; public static void main(String[] args) throws Exception { ClientConfig cconf = new ClientConfig(); cconf.setSsl(new TlsConfig()); cconf.getSsl().setKeyStore(keystore); cconf.getSsl().setKeyStorePassword(keystorepass); <|startfocus|> FederationClient fedclient = new FederationClient(peerApiUrl, cconf); <|endfocus|> System.out.println("Listing remote acumos catalogs using public E5 interface"); for (MLPCatalog mcat: fedclient.getCatalogs()) { System.out.println("Catalog " + mcat.getName() + " has " + ((Catalog)mcat).getSize() + " models"); } GatewayClient gwclient = new GatewayClient(internalApiUrl, cconf); System.out.println("Fetching first peer's catalogs from inside Acumos using private interface"); for (MLPCatalog mcat: gwclient.getCatalogs(firstpeerid)) {
<|startcomment|> remove empty comment <|endcomment|> import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.http.HttpStatus; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.ResponseBody; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(value = "/") public class PipeLineServiceController { <|startfocus|> /** * */ <|endfocus|> private static final String PIPELINE_INPROGRESS = "IP"; private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired @Qualifier("InputValidationServiceImpl") private InputValidationService inputValidationService; @Autowired @Qualifier("PipeLineValidationServiceImpl") private PipeLineValidationService pipeLineValidationService; @Autowired @Qualifier("PipeLineServiceImpl") private PipeLineService pipeLineService; @Autowired private PipeLineCacheService pipelineCacheService; /** * Creates new independent Pipeline for a user. * @param authenticatedUserId
<|startcomment|> Java Doc is missingc <|endcomment|>  } else { logger.debug("Skipping flow creation...flow " + pipelineName + " already exists for user " + acumosLoginId + " in NiFi Registry."); // THROW AN EXCEPTION TO MLWB-UI - REQUESTED PIPELINE NAME ALREADY EXISTS BOTH IN NIFI IN AND REGISTRY throw new DuplicatePipeLineException("Request PipeLine Name : " + pipelineName + " already Exists in Both NiFi Server and NiFi Registry"); } logger.debug("NiFi createPipeline() end"); return flowURL; } <|startfocus|> <|endfocus|> public boolean checkifNifiPodRunning(String acumosLoginId) { boolean nifiPodRunning = false; logger.debug("checkifNifiPodRunning() begin"); nifiPodRunning = createNiFi.checkifNifiPodRunning(acumosLoginId); logger.debug("checkifNifiPodRunning() End"); return nifiPodRunning; } public String createNiFiInstance(String acumosLoginId) { logger.debug("createNiFiInstance() Begin"); String nifiURL = null; // Call the Kubernetes API to create a NiFi Instance try { nifiURL = createNiFi.createNiFiInstanceForUser(acumosLoginId);
<|startcomment|> Java Doc missing <|endcomment|>  throw new DuplicatePipeLineException("Request PipeLine Name : " + pipelineName + " already Exists in Both NiFi Server and NiFi Registry"); } logger.debug("NiFi createPipeline() end"); return flowURL; } public boolean checkifNifiPodRunning(String acumosLoginId) { boolean nifiPodRunning = false; logger.debug("checkifNifiPodRunning() begin"); nifiPodRunning = createNiFi.checkifNifiPodRunning(acumosLoginId); logger.debug("checkifNifiPodRunning() End"); return nifiPodRunning; } <|startfocus|> <|endfocus|> public String createNiFiInstance(String acumosLoginId) { logger.debug("createNiFiInstance() Begin"); String nifiURL = null; // Call the Kubernetes API to create a NiFi Instance try { nifiURL = createNiFi.createNiFiInstanceForUser(acumosLoginId); } catch (NiFiInstanceCreationException e) { logger.error("Exception occured while creating NiFi Instance for User",e); throw new NiFiInstanceCreationException("Exception occured while creating NiFi Instance for User "); } logger.debug("createNiFiInstance() End"); return nifiURL; } 
<|startcomment|> Java Doc missing <|endcomment|> */ package org.acumos.workbench.pipelineservice.service; import java.lang.invoke.MethodHandles; import org.acumos.workbench.common.vo.Pipeline; import org.acumos.workbench.pipelineservice.exception.DuplicateRequestException; import org.acumos.workbench.pipelineservice.util.MLWBRequestCache; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; @Service public class PipeLineCacheService { private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired private MLWBRequestCache requestCache; <|startfocus|> <|endfocus|> public void putCreateRequest(String requestId, Pipeline pipeline) { logger.debug("putCreateRequest() Begin "); Boolean exist = requestCache.checkIfCreateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addCreateRequest(requestId, pipeline); } logger.debug("putCreateRequest() End"); } public void removeCreateRequest(String requestId, Pipeline pipeline) { requestCache.removeCreateRequest(requestId); } 
<|startcomment|> Java Doc missing <|endcomment|>  private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired private MLWBRequestCache requestCache; public void putCreateRequest(String requestId, Pipeline pipeline) { logger.debug("putCreateRequest() Begin "); Boolean exist = requestCache.checkIfCreateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addCreateRequest(requestId, pipeline); } logger.debug("putCreateRequest() End"); } <|startfocus|> <|endfocus|> public void removeCreateRequest(String requestId, Pipeline pipeline) { requestCache.removeCreateRequest(requestId); } public void putUpdateRequest(String requestId, Pipeline pipeline) { logger.debug("putUpdateRequest() Begin "); Boolean exist = requestCache.checkIfUpdateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addUpdateRequest(requestId, pipeline); } logger.debug("putUpdateRequest() End "); } 
<|startcomment|> Java Doc missing <|endcomment|>  public void putCreateRequest(String requestId, Pipeline pipeline) { logger.debug("putCreateRequest() Begin "); Boolean exist = requestCache.checkIfCreateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addCreateRequest(requestId, pipeline); } logger.debug("putCreateRequest() End"); } public void removeCreateRequest(String requestId, Pipeline pipeline) { requestCache.removeCreateRequest(requestId); } <|startfocus|> <|endfocus|> public void putUpdateRequest(String requestId, Pipeline pipeline) { logger.debug("putUpdateRequest() Begin "); Boolean exist = requestCache.checkIfUpdateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addUpdateRequest(requestId, pipeline); } logger.debug("putUpdateRequest() End "); } public void removeUpdateRequest(String requestId, Pipeline pipeline) { requestCache.removeUpdateRequest(requestId); } 
<|startcomment|> Java Doc missing <|endcomment|>  } public void removeCreateRequest(String requestId, Pipeline pipeline) { requestCache.removeCreateRequest(requestId); } public void putUpdateRequest(String requestId, Pipeline pipeline) { logger.debug("putUpdateRequest() Begin "); Boolean exist = requestCache.checkIfUpdateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addUpdateRequest(requestId, pipeline); } logger.debug("putUpdateRequest() End "); } <|startfocus|> <|endfocus|> public void removeUpdateRequest(String requestId, Pipeline pipeline) { requestCache.removeUpdateRequest(requestId); } public void putDeleteRequest(String requestId, String pipelineId) { logger.debug("putDeleteRequest() Begin "); Boolean exist = requestCache.checkIfDeleteRequestExists(requestId, pipelineId); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addDeleteRequest(requestId, pipelineId); } logger.debug("putDeleteRequest() End "); } 
<|startcomment|> Java Doc missing <|endcomment|>  } public void putUpdateRequest(String requestId, Pipeline pipeline) { logger.debug("putUpdateRequest() Begin "); Boolean exist = requestCache.checkIfUpdateRequestExists(requestId, pipeline); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addUpdateRequest(requestId, pipeline); } logger.debug("putUpdateRequest() End "); } public void removeUpdateRequest(String requestId, Pipeline pipeline) { requestCache.removeUpdateRequest(requestId); } <|startfocus|> <|endfocus|> public void putDeleteRequest(String requestId, String pipelineId) { logger.debug("putDeleteRequest() Begin "); Boolean exist = requestCache.checkIfDeleteRequestExists(requestId, pipelineId); if(exist) { logger.error("Duplicate Request Exception ocured. "); throw new DuplicateRequestException(); } else { requestCache.addDeleteRequest(requestId, pipelineId); } logger.debug("putDeleteRequest() End "); } public void removeDeleteRequest(String requestId, String pipelineId) { requestCache.removeDeleteRequest(requestId); } 
<|startcomment|> Java Doc missing <|endcomment|>  @ApplicationScope @Component public class MLWBRequestCache implements Serializable { private static final long serialVersionUID = -4688732173089705360L; private Map<String, Pipeline> createRequests; // Key is Request Id and value is pipeline input private Map<String, Pipeline> updateRequests; // Key is Request Id and value is pipeline input private Map<String, String> deleteRequests; // Key is Request Id and value is pipeline Id private Map<String, String> archiveRequests; // Key is Request Id and value is pipeline Id <|startfocus|> <|endfocus|> public MLWBRequestCache() { createRequests = new HashMap<String, Pipeline>(); updateRequests = new HashMap<String, Pipeline>(); deleteRequests = new HashMap<String, String>(); archiveRequests = new HashMap<String, String>(); } public void addCreateRequest(String key, Pipeline value) { createRequests.put(key, value); } public void removeCreateRequest(String key) { createRequests.remove(key); } public Pipeline getCreateRequestByKey(String key) { if(createRequests.containsKey(key)) { return createRequests.get(key);
<|startcomment|> Java Doc missing <|endcomment|>  private Map<String, String> deleteRequests; // Key is Request Id and value is pipeline Id private Map<String, String> archiveRequests; // Key is Request Id and value is pipeline Id public MLWBRequestCache() { createRequests = new HashMap<String, Pipeline>(); updateRequests = new HashMap<String, Pipeline>(); deleteRequests = new HashMap<String, String>(); archiveRequests = new HashMap<String, String>(); } <|startfocus|> <|endfocus|> public void addCreateRequest(String key, Pipeline value) { createRequests.put(key, value); } public void removeCreateRequest(String key) { createRequests.remove(key); } public Pipeline getCreateRequestByKey(String key) { if(createRequests.containsKey(key)) { return createRequests.get(key); } return null; } /** * Check if request with given requestId or Pipeline already exists in the cache. * @param key * request Id * @param value * Pipeline * @return boolean
<|startcomment|> remove commented code if not required <|endcomment|>  List<Nodes> nodesList = new ArrayList<Nodes>(); nodesList.add(node); cdump.setNodes(nodesList); String nodeId = "123"; String userId = "123"; //try { when(props.getPackagepath()).thenReturn("org/acumos/vo/"); when(props.getClassName()).thenReturn("DataVO"); Resource resource1 = resourceLoader.getResource(PROTOBUF_TEMPLATE_NAME) ; when(resourceLoader.getResource("classpath:Protobuf_Template.txt")).thenReturn(resource1); <|startfocus|> //when(resourceLoader.getInputStream()).thenReturn(inputStream); //gdmServiceImpl.createDeployGDM(cdump, nodeId, userId); //} catch (ServiceException e) { // e.printStackTrace(); //} <|endfocus|> 
<|startcomment|> Please remove empty comment <|endcomment|>  * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ /** * */ package org.acumos.designstudio.test; <|startfocus|> import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertNotNull; import static org.junit.Assert.assertTrue; <|endfocus|> import java.lang.invoke.MethodHandles; import java.util.ArrayList; import java.util.List; import java.util.Properties; import org.acumos.designstudio.ce.util.ConfigurationProperties; import org.acumos.designstudio.ce.vo.DSSolution; import org.acumos.designstudio.ce.vo.MatchingModel; import org.acumos.designstudio.ce.vo.SuccessErrorMessage; import org.acumos.designstudio.ce.vo.blueprint.BPCollatorMap; import org.acumos.designstudio.ce.vo.blueprint.BPDataBrokerMap;
<|startcomment|> Class is not formatted. <|endcomment|>  import com.google.common.collect.Lists; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.service.ApiInfo; import springfox.documentation.service.ApiKey; import springfox.documentation.service.AuthorizationScope; import springfox.documentation.service.Contact; import springfox.documentation.service.SecurityReference; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spi.service.contexts.SecurityContext; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; @Configuration @EnableSwagger2 public class SwaggerConfiguration { <|startfocus|> <|endfocus|> @Bean public Docket swaggerSpringfoxDocket() { Docket docket = new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .forCodeGeneration(true) .genericModelSubstitutes(ResponseEntity.class) .ignoredParameterTypes(Pageable.class) .ignoredParameterTypes(java.sql.Date.class) .directModelSubstitute(java.time.LocalDate.class, java.sql.Date.class) .directModelSubstitute(java.time.ZonedDateTime.class, Date.class) .directModelSubstitute(java.time.LocalDateTime.class, Date.class) .securityContexts(Lists.newArrayList(securityContext()))
<|startcomment|> Please format the code <|endcomment|>  } // Secure the endpoints with HTTP Basic authentication @Override protected void configure(HttpSecurity http) throws Exception { http .csrf().disable() .sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .authorizeRequests() .antMatchers("/swagger-ui.html").permitAll() .anyRequest().authenticated() .and() .addFilterBefore(jwtAuthorizationFilterBean(), UsernamePasswordAuthenticationFilter.class); } @Bean public JWTAuthorizationFilter jwtAuthorizationFilterBean() throws Exception { <|startfocus|> JWTAuthorizationFilter jwtAuthorizationFilter = new JWTAuthorizationFilter(authenticationManagerBean(),conf.getJwtSecretKey(), cdsClient); <|endfocus|> return jwtAuthorizationFilter; } } 
<|startcomment|> If you use the Eclipse code formatter, it will instantly clean up all dangling whitespace problems like this <|endcomment|>  * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.workbench.modelservice.service; import org.acumos.workbench.common.vo.Model; public interface ModelValidationService { /** <|startfocus|> * To Validate the Input Data * <|endfocus|> * @param authenticatedUserId the authenticated User Id * @param model the model */ public void validateInputData(String authenticatedUserId, Model model); } 
<|startcomment|> what is this 1. ?? <|endcomment|>  * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.workbench.modelservice.service; import org.acumos.workbench.common.vo.Model; public interface ModelValidationService { /** <|startfocus|> * To Validate the Input for : * 1. <|endfocus|> * @param authenticatedUserId * @param model */ public void validateInputData(String authenticatedUserId, Model model); } 
<|startcomment|> update to 2019 <|endcomment|>  * ===============LICENSE_START======================================================= * Acumos * =================================================================================== <|startfocus|> * Copyright (C) 2017 AT&T Intellectual Property & Tech Mahindra. All rights reserved. <|endfocus|> * =================================================================================== * This Acumos software file is distributed by AT&T and Tech Mahindra * under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.designstudio.toscagenerator.test; import java.io.File; import java.io.IOException; import java.lang.invoke.MethodHandles; import java.time.Instant; import java.util.ArrayList; import java.util.List; import org.acumos.cds.domain.MLPSolutionRevision; import org.acumos.designstudio.toscagenerator.ToscaGeneratorClient;
<|startcomment|> Class don't have any test method <|endcomment|> import org.junit.Rule; import org.junit.Test; import org.mockito.MockitoAnnotations; import org.mockito.junit.MockitoJUnit; import org.mockito.junit.MockitoRule; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class ToscaGeneratorClientTest { private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Rule public MockitoRule mockitoRule = MockitoJUnit.rule(); @Before public void setUp() { MockitoAnnotations.initMocks(this); } <|startfocus|> //@Test(expected = ServiceException.class) <|endfocus|> public void ToscaClientTest(){
<|startcomment|> Remove commented code. <|endcomment|>  mlpRev.setModified(Instant.now()); mlpRev.setOnboarded(Instant.now()); mlpRev.setPublisher("techmdev"); mlpRev.setRevisionId("123"); mlpRev.setSolutionId("123"); mlpRev.setUserId("123"); mlpRev.setVerifiedLicense("Yes"); mlpRev.setVerifiedVulnerability("Yes"); mlpRev.setVersion("1"); List<MLPSolutionRevision> listMLPSolRev = new ArrayList<>(); listMLPSolRev.add(mlpRev); try { <|startfocus|> //when(protoService.createProtoJson("123", "1", tagFile)).thenReturn("str"); //when(toscaGeneratorService.uploadFilesToRepository("123", "1", artList)).thenReturn(artList); //when(cdmsClient.getSolutionRevisions("123")).thenReturn(listMLPSolRev); <|endfocus|> client.generateTOSCA("123", "123", "1", "123", protoFile, tagFile); } catch (AcumosException e) { logger.error("AcumosException occured while generating the TOSCA File"); } 
<|startcomment|> Remove 2018, should be consistent across <|endcomment|>  * ===============LICENSE_START======================================================= * Acumos * =================================================================================== <|startfocus|> * Copyright (C) 2018 - 2019 AT&T Intellectual Property & Tech Mahindra. All rights reserved. <|endfocus|> * =================================================================================== * This Acumos software file is distributed by AT&T and Tech Mahindra * under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.csvdatabroker.vo; import static org.junit.Assert.assertTrue; import org.junit.Test; public class CSVdatabrokerVOTest { @Test public void csvdatabrokerVOTest() { DataBrokerMap dataBrokerMap = new DataBrokerMap(); dataBrokerMap.setScript("test");
<|startcomment|> Remove 2018 <|endcomment|>  * ===============LICENSE_START======================================================= * Acumos * =================================================================================== <|startfocus|> * Copyright (C) 2018 - 2019 AT&T Intellectual Property & Tech Mahindra. All rights reserved. <|endfocus|> * =================================================================================== * This Acumos software file is distributed by AT&T and Tech Mahindra * under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.sqldatabroker.vo; import static org.junit.Assert.assertTrue; import java.util.ArrayList; import java.util.List; import org.acumos.sqldatabroker.exceptionhandler.ServiceException; import org.junit.Test; public class DataBrokerMapVOTest { @Test
<|startcomment|> Remove 2018, also fix similar other occurrences. <|endcomment|>  * ===============LICENSE_START======================================================= * Acumos * =================================================================================== <|startfocus|> * Copyright (C) 2018 - 2019 AT&T Intellectual Property & Tech Mahindra. All rights reserved. <|endfocus|> * =================================================================================== * This Acumos software file is distributed by AT&T and Tech Mahindra * under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * This file is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * ===============LICENSE_END========================================================= */ package org.acumos.csvdatabroker.vo; import static org.junit.Assert.assertTrue; import org.junit.Test; public class CSVdatabrokerVOTest { @Test public void csvdatabrokerVOTest() { DataBrokerMap dataBrokerMap = new DataBrokerMap(); dataBrokerMap.setScript("test");
<|startcomment|> need to rephrase the API operation <|endcomment|>  @RestController @RequestMapping(value = "/") public class ModelServiceController { private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired @Qualifier("InputValidationServiceImpl") private InputValidationService inputValidationService; @Autowired @Qualifier("ModelValidationServiceImpl") private ModelValidationService modelValidationService; @Autowired @Qualifier("ModelServiceImpl") private ModelService modelService; <|startfocus|> @ApiOperation(value = "This API will list out all the Models that belongs to user") <|endfocus|> @RequestMapping(value = "/users/{authenticatedUserId}/models/", method = RequestMethod.GET) public ResponseEntity<?> listModels(HttpServletRequest request,@ApiParam(value="Acumos User login Id",required = true)@PathVariable("authenticatedUserId") String authenticatedUserId){ logger.debug("listModels() Begin"); String authToken = getAuthJWTToken(request); //1. Check the Authenticated User Id is present or not inputValidationService.isValuePresent(ModelServiceConstants.MODEL_AUTHENTICATED_USER_ID, authenticatedUserId);
<|startcomment|> Pleas include a line between import and start of the class definition. <|endcomment|> import org.acumos.workbench.common.vo.Version; import org.acumos.workbench.modelservice.exceptionhandling.ModelNotFoundException; import org.acumos.workbench.modelservice.util.ConfigurationProperties; import org.acumos.workbench.modelservice.util.ModelServiceProperties; import org.acumos.workbench.modelservice.util.ModelServiceUtil; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.slf4j.MDC; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.HttpStatus; import org.springframework.http.ResponseEntity; import org.springframework.stereotype.Service; <|startfocus|> import org.springframework.web.client.RestClientResponseException; <|endfocus|> @Service("ModelServiceImpl") public class ModelServiceImpl implements ModelService { private static final Logger logger = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); @Autowired private CommonDataServiceRestClientImpl cdsClient; @Autowired private ModelServiceProperties props; @Autowired private ConfigurationProperties confprops; @Autowired private ProjectServiceRestClientImpl psClient; @Override public List<Model> getModels(String authenticatedUserId, String projectId) { logger.debug("getModels() Begin"); List<Model> modelList = new ArrayList<Model>(); MLPUser mlpUser = getUserDetails(authenticatedUserId);
<|startcomment|> Use AssociationException instead. <|endcomment|>  Model model = getModelWithErrorStatus(ex); return new ResponseEntity<Model>(model, HttpStatus.NOT_FOUND); } /** * To handle AssociationExistsException and returns appropriate response to UI. * @param ex * the exception thrown by the service method * @param request * the WebRequest * @return ResponseEntitiy<Model> * returns Model with ServiceStatus indicating error */ <|startfocus|> @ExceptionHandler(AssociationExistsException.class) public final ResponseEntity<?> handleAssociationExistsException(AssociationExistsException ex, WebRequest request) { <|endfocus|> Model model = getModelWithErrorStatus(ex); return new ResponseEntity<Model>(model, HttpStatus.NOT_FOUND); } /** * To handle AssociationNotFoundException and returns appropriate response to UI. * @param ex * the exception thrown by the service method * @param request * the WebRequest * @return ResponseEntitiy<Model> * returns Model with ServiceStatus indicating error */ @ExceptionHandler(ProjectModelAssociationNotFoundException.class)
<|startcomment|> Remove text "This method will" and stat with "To validate the....." <|endcomment|>  * * @param fieldName * The name of the filed to be shown in the error message. * @param value * The value to be validated * @throws ValueNotFoundException * throws ValueNotFoundException in case value is null or empty. */ public void isValuePresent(String fieldName, String value) throws ValueNotFoundException; /** <|startfocus|> * This method will validates the input Json value of Model <|endfocus|> * @param model * the model object with input values * @throws InvalidInputJSONException * throws InvalidInputJSONException in case of error in the input JSON */ public void validateModelInputJson(Model model) throws InvalidInputJSONException; } 
<|startcomment|> No underscore in name please. <|endcomment|>  * ===============LICENSE_END========================================================= */ package org.acumos.workbench.modelservice.util; public class ModelServiceConstants { public static final String MODEL_AUTHENTICATED_USER_ID = "AuthenticatedUserId"; public static final String DELETED = "DELETED"; public static final String MODEL_IS_ACTIVE = "Model is Active"; public static final String CATALOGNAMES = "CATALOG_NAMES"; public static final String UNARCHIVE = "UA"; public static final String ARCHIVE = "A"; <|startfocus|> public static final String PROJECT_ID = "projectId"; <|endfocus|> public static final String ASSOCIATIONID = "ASSOCIATION_ID"; public static final String MODELTYPECODE = "MODEL_TYPE_CODE"; public static final String MODELPUBLISHSTATUS = "MODEL_PUBLISH_STATUS"; } 
<|startcomment|> Because of complete class formatting, comments in TODO is multi lined, Please get the comment on same line. <|endcomment|>  private List<String> getConnectedPortInputMsgNames(List<ProtobufServiceOperation> operations) { List<String> inputMessageNames = null; for (ProtobufServiceOperation o : operations) { <|startfocus|> // TODO : Current logic returns the first operation's input msg // name, but need to update the logic to return the connected port // input message name <|endfocus|> inputMessageNames = o.getInputMessageNames(); } return inputMessageNames;
<|startcomment|> Please fix the TODO pending on you. <|endcomment|>  // 1. Get the list of SolutionRevision for the solutionId. mlpSolutionRevisionList = getSolutionRevisionsList(solutionId); // 2. Match the version with the SolutionRevision and get the // solutionRevisionId. if (null != mlpSolutionRevisionList && !mlpSolutionRevisionList.isEmpty()) { solutionRevisionId = mlpSolutionRevisionList.stream().filter(mlp -> mlp.getVersion().equals(version)) .findFirst().get().getRevisionId(); <|startfocus|> logger.debug(EELFLoggerDelegator.debugLogger," SolutionRevisonId for Version : {} ", solutionRevisionId); <|endfocus|> } else { result = String.format(error, "501", "Failed to fetch the Solution Revision List"); } } catch (Exception e) { logger.error(EELFLoggerDelegator.errorLogger, "Error : Exception in fetchJsonTOSCA() : Failed to fetch the Solution Revision List", e); result = String.format(error, "501", "Failed to fetch the Solution Revision List for the version {} ", version); } if (null != solutionRevisionId) {
<|startcomment|> Please remove unnecessary empty lines. Please check rest of the class and remove empty lines. <|endcomment|>  // add protobuf file addProtobufFile(protobufJarEntryName, tempJar); // add DavaVO.class file List<String> dataVOEntryList = addDataVOClasses(DataVOClassEntryName, tempJar); JarEntry entry = null; // Open the original jar jar = new JarFile(jarFile); // Loop through the jar entries and add them to the temp jar, // skipping the entry that was added to the temp jar already. for (Enumeration entries = jar.entries(); entries.hasMoreElements();) { // Get the next entry. <|startfocus|> entry = (JarEntry) entries.nextElement(); <|endfocus|> // If the entry has not been added already, add it. if (!entry.getName().equals(fieldMappingJarEntryName) && !dataVOEntryList.contains(entry.getName())) { // Get an input stream for the entry. InputStream entryStream = jar.getInputStream(entry); // Read the entry and write it to the temp jar. tempJar.putNextEntry(entry); while ((bytesRead = entryStream.read(buffer)) != -1) {
<|startcomment|> MAJOR SonarQube violation: This block of commented-out lines of code should be removed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3ACommentedOutCodeLine <|endcomment|>  curPartIdx++; if (curPartIdx <= endPartIdx) { boolean suitablePartFound = false; for (int i = curPartIdx; i <= endPartIdx; i++) { // Prune partition because no element in it can satisfy the occurrence threshold. if (partitionCursors[i] == null || partitionCursors[i].size() < occurrenceThreshold) { <|startfocus|> // Temp : // System.out // .println("\nPartitionedTOccurrenceSearcher::continueSearch() skipping the partition " + i); // <|endfocus|> continue; } suitablePartFound = true; curPartIdx = i; break; } // If no partition is availble to explore, we stop here. if (!suitablePartFound) { isFinishedSearch = true; invListMerger.close(); finalSearchResult.finalizeWrite(); return true; } // Temp : // System.out.println("\nMerging the cursor for the partition " + curPartIdx + " start " // + partitions.getMinValidPartitionIndex() + " end " + endPartIdx // + " - PartitionedTOccurrenceSearcher::continueSearch()"); // 
<|startcomment|> MAJOR SonarQube violation: Split this 126 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  isSingleInvertedList = true; needToReadNewPart = true; } else { singleInvListCursor = null; isSingleInvertedList = false; needToReadNewPart = invListMerger.merge(partitionCursors[curPartIdx], occurrenceThreshold, numPrefixLists, finalSearchResult); searchResultBuffer = finalSearchResult.getNextFrame(); searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); <|startfocus|> // Temp : // System.out.println("PartitionedTOccurrenceSearcher::continueSearch() - " + needToReadNewPart // + " tupleCount " + searchResultFta.getTupleCount()); // <|endfocus|> } // Finished processing one partition if (needToReadNewPart && isFinalPartIdx) { invListMerger.close(); finalSearchResult.finalizeWrite(); isFinishedSearch = true; // Temp : // System.out.println("Final partition " + curPartIdx + " Search done"); return true; } } else { isFinishedSearch = true; } return false; } public void setNumTokensBoundsInSearchKeys(short numTokensLowerBound, short numTokensUpperBound) {
<|startcomment|> MAJOR SonarQube violation: This block of commented-out lines of code should be removed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3ACommentedOutCodeLine <|endcomment|>  needToReadNewPart = true; } else { singleInvListCursor = null; isSingleInvertedList = false; needToReadNewPart = invListMerger.merge(partitionCursors[curPartIdx], occurrenceThreshold, numPrefixLists, finalSearchResult); searchResultBuffer = finalSearchResult.getNextFrame(); searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); <|startfocus|> // Temp : // System.out.println("PartitionedTOccurrenceSearcher::continueSearch() - " + needToReadNewPart // + " tupleCount " + searchResultFta.getTupleCount()); // <|endfocus|> } // Finished processing one partition if (needToReadNewPart && isFinalPartIdx) { invListMerger.close(); finalSearchResult.finalizeWrite(); isFinishedSearch = true; // Temp : // System.out.println("Final partition " + curPartIdx + " Search done"); return true; } } else { isFinishedSearch = true; } return false; } public void setNumTokensBoundsInSearchKeys(short numTokensLowerBound, short numTokensUpperBound) {
<|startcomment|> MAJOR SonarQube violation: This block of commented-out lines of code should be removed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3ACommentedOutCodeLine <|endcomment|>  searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); // Temp : // System.out.println("PartitionedTOccurrenceSearcher::continueSearch() - " + needToReadNewPart // + " tupleCount " + searchResultFta.getTupleCount()); // } // Finished processing one partition if (needToReadNewPart && isFinalPartIdx) { invListMerger.close(); finalSearchResult.finalizeWrite(); isFinishedSearch = true; <|startfocus|> // Temp : // System.out.println("Final partition " + curPartIdx + " Search done"); <|endfocus|> return true; } } else { isFinishedSearch = true; } return false; } public void setNumTokensBoundsInSearchKeys(short numTokensLowerBound, short numTokensUpperBound) { ShortPointable.setShort(lowerBoundTuple.getFieldData(0), lowerBoundTuple.getFieldStart(0), numTokensLowerBound); ShortPointable.setShort(upperBoundTuple.getFieldData(0), upperBoundTuple.getFieldStart(0), numTokensUpperBound); } public ITupleReference getPrefixSearchKey() { return searchKey; } public ITupleReference getFullLowSearchKey() { return fullLowSearchKey;
<|startcomment|> MAJOR SonarQube violation: Replace this usage of System.out or System.err by a logger. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS106 <|endcomment|>  singleInvListCursor.prepareLoadPages(); singleInvListCursor.loadPages(); isSingleInvertedList = true; isFinishedSearch = true; } else { finalSearchResult.reset(); isFinishedSearch = invListMerger.merge(invListCursors, occurrenceThreshold, numPrefixLists, finalSearchResult); searchResultBuffer = finalSearchResult.getNextFrame(); searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); <|startfocus|> // Temp : System.out.println("PartitionedTOccurrenceSearcher::search() - " + isFinishedSearch + " tupleCount " + searchResultFta.getTupleCount()); // <|endfocus|> } if (isFinishedSearch) { invListMerger.close(); finalSearchResult.finalizeWrite(); } // Some or all output was generated by the merger. Let the result cursor fetch the output. resultCursor.open(null, searchPred); } /** * Continues a search process if it was paused because the output buffer (one frame) of the final result was full. * This method should not be called for a single inverted list case since there cannot be multiple inverted list * cursors for a single keyword.
<|startcomment|> MAJOR SonarQube violation: Replace this usage of System.out or System.err by a logger. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS106 <|endcomment|>  * false otherwise. * @throws HyracksDataException */ @Override public boolean continueSearch() throws HyracksDataException { if (isFinishedSearch) { return true; } isFinishedSearch = invListMerger.continueMerge(); searchResultBuffer = finalSearchResult.getNextFrame(); searchResultTupleIndex = 0; searchResultFta.reset(searchResultBuffer); <|startfocus|> // Temp : System.out.println("PartitionedTOccurrenceSearcher::continueSearch() - " + isFinishedSearch + " tupleCount " + searchResultFta.getTupleCount()); // <|endfocus|> if (isFinishedSearch) { invListMerger.close(); finalSearchResult.finalizeWrite(); } return isFinishedSearch; } } 
<|startcomment|> MAJOR SonarQube violation: trailing WS is not allowed Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3Aasterixdb_trailingws <|endcomment|>  * Otherwise, it performs an insert. * * @param tuple * Tuple to be deleted. * @throws HyracksDataException * If the BufferCache throws while un/pinning or un/latching. * @throws IndexException * If there is no matching tuple in the index. * */ public void upsert(ITupleReference tuple) throws HyracksDataException; /** * Creates a cursor appropriate for passing into search(). <|startfocus|> * <|endfocus|> * @throws HyracksDataException * */ public IIndexCursor createSearchCursor(boolean exclusive) throws HyracksDataException; /** * Open the given cursor for an index search using the given predicate as * search condition. * * @param icursor * Cursor over the index entries satisfying searchPred. * @param searchPred * Search condition. * @throws HyracksDataException * If the BufferCache throws while un/pinning or un/latching. * @throws IndexException */ public void search(IIndexCursor cursor, ISearchPredicate searchPred) throws HyracksDataException; } 
<|startcomment|> MAJOR SonarQube violation: Replace this usage of System.out or System.err by a logger. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS106 <|endcomment|>  public boolean append(byte[] bytes, int offset, int length) { if (tupleDataEndOffset + length + TUPLE_COUNT_SIZE <= frameSize) { <|startfocus|> if (buffer == null) { System.out.println("buffer null"); } <|endfocus|> System.arraycopy(bytes, offset, buffer.array(), tupleDataEndOffset, length); tupleDataEndOffset += length; return true; } return false;
<|startcomment|> MAJOR SonarQube violation: Remove this unused "countp" local variable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1481 <|endcomment|>  invListTuple = invListCursor.getTuple(); if (!newSearchResult.append(invListTuple, 1)) { // For a final result, needs to pause when a frame becomes full to let the caller // consume the frame. SearchResult.append() should only return false for this case. return false; } invListTidx++; if (invListCursor.hasNext()) { invListCursor.next(); } } // append remaining elements from previous result set <|startfocus|> int countp = 0; <|endfocus|> while (resultTidx < prevResultFrameTupleCount) { resultTuple.reset(prevCurrentBuffer.array(), resultFrameTupleAcc.getTupleStartOffset(resultTidx)); count = getCount(resultTuple); if (!newSearchResult.append(resultTuple, count)) { // For a final result, needs to pause when a frame becomes full to let the caller // consume the frame. SearchResult.append() should only return false for this case. return false; } resultTidx++; checkPrevResultAndFetchNextFrame(prevSearchResult); } return finishMergingOneList(isFinalList, prevSearchResult, newSearchResult); } 
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "dataBuffer". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  } private static final Map<Integer, ReplicationRequestType> TYPES = new HashMap<>(); static { Stream.of(ReplicationRequestType.values()).forEach(type -> TYPES.put(type.ordinal(), type)); } public static ByteBuffer readRequest(SocketChannel socketChannel, ByteBuffer dataBuffer) throws IOException { //read request size NetworkingUtil.readBytes(socketChannel, dataBuffer, Integer.BYTES); final int requestSize = dataBuffer.getInt(); if (dataBuffer.capacity() < requestSize) { dataBuffer = ByteBuffer.allocate(requestSize); } //read request <|startfocus|> NetworkingUtil.readBytes(socketChannel, dataBuffer, requestSize); <|endfocus|> return dataBuffer; } public static ReplicationRequestType getRequestType(SocketChannel socketChannel, ByteBuffer byteBuffer) throws IOException { //read replication request type NetworkingUtil.readBytes(socketChannel, byteBuffer, REPLICATION_REQUEST_TYPE_SIZE); return TYPES.get(byteBuffer.getInt()); } private static ByteBuffer getGoodbyeBuffer() { ByteBuffer bb = ByteBuffer.allocate(REPLICATION_REQUEST_TYPE_SIZE); bb.putInt(ReplicationRequestType.GOODBYE.ordinal()); bb.flip(); return bb; } 
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|> <|startfocus|> public static int getJobIdFromLogAckMessage(String msg) { return Integer.parseInt(msg.substring((msg.indexOf(JOB_REPLICATION_ACK) + 1))); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: Split this 150 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  ITupleReference highSearchKey = null; partSearcher.setNumTokensBoundsInSearchKeys(numTokensLowerBound, numTokensUpperBound); if (numTokensLowerBound < 0) { ctx.getBtreePred().setLowKeyComparator(ctx.getPrefixSearchCmp()); lowSearchKey = partSearcher.getPrefixSearchKey(); } else { ctx.getBtreePred().setLowKeyComparator(ctx.getSearchCmp()); lowSearchKey = partSearcher.getFullLowSearchKey(); } if (numTokensUpperBound < 0) { <|startfocus|> ctx.getBtreePred().setHighKeyComparator(ctx.getPrefixSearchCmp()); <|endfocus|> highSearchKey = partSearcher.getPrefixSearchKey(); } else { ctx.getBtreePred().setHighKeyComparator(ctx.getSearchCmp()); highSearchKey = partSearcher.getFullHighSearchKey(); } ctx.getBtreePred().setLowKey(lowSearchKey, true); ctx.getBtreePred().setHighKey(highSearchKey, true); ctx.getBtreeAccessor().search(ctx.getBtreeCursor(), ctx.getBtreePred()); boolean tokenExists = false; try { while (ctx.getBtreeCursor().hasNext()) { ctx.getBtreeCursor().next(); ITupleReference btreeTuple = ctx.getBtreeCursor().getTuple();
<|startcomment|> MAJOR SonarQube violation: This block of commented-out lines of code should be removed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3ACommentedOutCodeLine <|endcomment|>  } protected void createAndOpenFile() throws HyracksDataException { if (isInMemoryOpMode) { // In-memory mode should not generate a file. return; } if (searchResultWriter == null) { FileReference file = ctx.getJobletContext().createManagedWorkspaceFile(FILE_PREFIX); searchResultWriter = new RunFileWriter(file, ctx.getIoManager()); searchResultWriter.open(); isFileOpened = true; } <|startfocus|> // Temp : // System.out.println(file + " - InvertedIndexSearchResult::file create and open - "); <|endfocus|> } // Deallocates the I/O buffer (one frame). This should be the last oepration. protected void deallocateIOBuffer() throws HyracksDataException { if (ioBufferFrame != null) { // Temp : // System.out.println( // "InvertedIndexSearchResult::deallocateIOBuffer() buffer - " + ObjectUtils.identityToString(ioBuffer)); bufferManager.releaseFrame(ioBuffer); buffers.clear(); ioBufferFrame = null; ioBuffer = null; } } /**
<|startcomment|> MAJOR SonarQube violation: Refactor this code to not nest more than 4 if/for/while/switch/try statements. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS134 <|endcomment|>  foundIn = i; return true; } } if (i == 0 && includeMutableComponent) { // unlatch/unpin btreeCursors[i].reset(); searchCallback.reconcile(predicate.getLowKey()); reconciled = true; // retraverse btreeAccessors[0].search(btreeCursors[i], predicate); if (btreeCursors[i].hasNext()) { btreeCursors[i].next(); if (((ILSMTreeTupleReference) btreeCursors[i].getTuple()).isAntimatter()) { searchCallback.cancel(predicate.getLowKey()); <|startfocus|> btreeCursors[i].close(); <|endfocus|> return false; } else { frameTuple = btreeCursors[i].getTuple(); foundTuple = true; searchCallback.complete(predicate.getLowKey()); foundIn = i; return true; } } else { searchCallback.cancel(predicate.getLowKey()); btreeCursors[i].close(); } } else { frameTuple = btreeCursors[i].getTuple(); searchCallback.reconcile(frameTuple); searchCallback.complete(frameTuple); foundTuple = true; foundIn = i;
<|startcomment|> why can't we reset the interrupted once the critical section is complete? <|endcomment|>  protected void appendToLogTail(ILogRecord logRecord) { syncAppendToLogTail(logRecord); if (waitForFlush(logRecord) && !logRecord.isFlushed()) { synchronized (logRecord) { while (!logRecord.isFlushed()) { try { logRecord.wait(); } catch (InterruptedException e) { // NOSONAR ensure txn survive at this stage // ignore interrupt } } <|startfocus|> } <|endfocus|> }
<|startcomment|> none <|endcomment|>  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.common.replication; import java.util.HashMap; import java.util.Map; public class ReplicationStrategyFactory { private static final Map<String, Class<? extends IReplicationStrategy>> BUILT_IN_REPLICATION_STRATEGY = new HashMap<>(); static { <|startfocus|> BUILT_IN_REPLICATION_STRATEGY.put("no_replication", NoReplicationStrategy.class); <|endfocus|> BUILT_IN_REPLICATION_STRATEGY.put("all", AllDatasetsReplicationStrategy.class); BUILT_IN_REPLICATION_STRATEGY.put("metadata", MetadataOnlyReplicationStrategy.class); } private ReplicationStrategyFactory() { throw new AssertionError(); } public static IReplicationStrategy create(String name) { String strategyName = name.toLowerCase(); if (!BUILT_IN_REPLICATION_STRATEGY.containsKey(strategyName)) { throw new IllegalStateException("Couldn't find strategy with name: " + name); } Class<? extends IReplicationStrategy> clazz = BUILT_IN_REPLICATION_STRATEGY.get(strategyName); try {
<|startcomment|> MAJOR SonarQube violation: Rename "partitionIndexes" which hides the field declared at line 34. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AHiddenFieldCheck <|endcomment|>  setNumActiveIOOps(getNumActiveIOOps() + 1); } public synchronized void undeclareActiveIOOperation() { setNumActiveIOOps(getNumActiveIOOps() - 1); //notify threads waiting on this dataset info notifyAll(); } public synchronized Set<ILSMIndex> getDatasetIndexes() { Set<ILSMIndex> datasetIndexes = new HashSet<>(); for (IndexInfo iInfo : getIndexes().values()) { if (iInfo.isOpen()) { datasetIndexes.add(iInfo.getIndex()); } } <|startfocus|> return datasetIndexes; <|endfocus|> } @Override public int compareTo(DatasetInfo i) { // sort by (isOpen, referenceCount, lastAccess) ascending, where true < false // // Example sort order: // ------------------- // (F, 0, 70) <-- largest // (F, 0, 60) // (T, 10, 80) // (T, 10, 70) // (T, 9, 90) // (T, 0, 100) <-- smallest if (isOpen() && !i.isOpen()) { return -1;
<|startcomment|> MAJOR SonarQube violation: Split this 133 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { ArrayList<DatasetLifecycle> openDatasets = new ArrayList<>(datasetLifecycles.values()); for (DatasetLifecycle dslc : openDatasets) { closeDataset(dslc.getDatasetInfo()); } } @Override public synchronized void closeUserDatasets() throws HyracksDataException { <|startfocus|> ArrayList<DatasetLifecycle> openDatasets = new ArrayList<>(datasetLifecycles.values()); for (DatasetLifecycle dslc : openDatasets) { if (dslc.getDatasetID() >= getFirstAvilableUserDatasetID()) { closeDataset(dslc.getDatasetInfo()); <|endfocus|> } } } @Override public synchronized void stop(boolean dumpState, OutputStream outputStream) throws IOException { if (stopped) { return; } if (dumpState) { dumpState(outputStream); } closeAllDatasets(); datasetLifecycles.clear();
<|startcomment|> MAJOR SonarQube violation: Split this 128 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { ArrayList<DatasetLifecycle> openDatasets = new ArrayList<>(datasetLifecycles.values()); for (DatasetLifecycle dslc : openDatasets) { closeDataset(dslc.getDatasetInfo()); } } @Override public synchronized void closeUserDatasets() throws HyracksDataException { <|startfocus|> ArrayList<DatasetLifecycle> openDatasets = new ArrayList<>(datasetLifecycles.values()); for (DatasetLifecycle dslc : openDatasets) { if (dslc.getDatasetID() >= getFirstAvilableUserDatasetID()) { closeDataset(dslc.getDatasetInfo()); <|endfocus|> } } } @Override public synchronized void stop(boolean dumpState, OutputStream outputStream) throws IOException { if (stopped) { return; } if (dumpState) { dumpState(outputStream); } closeAllDatasets(); datasetLifecycles.clear(); stopped = true; } @Override
<|startcomment|> MAJOR SonarQube violation: ':' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  protected void cleanupForAbort() { <|startfocus|> for(Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>>e:primaryIndexTrackers.entrySet()) { <|endfocus|> AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); }
<|startcomment|> MAJOR SonarQube violation: ':' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  protected void cleanupForAbort() { <|startfocus|> for(Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>>e:primaryIndexTrackers.entrySet()) { <|endfocus|> AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); }
<|startcomment|> MAJOR SonarQube violation: '>' is followed by an illegal character. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3Acom.puppycrawl.tools.checkstyle.checks.whitespace.GenericWhitespaceCheck <|endcomment|>  protected void cleanupForAbort() { <|startfocus|> for(Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>>e:primaryIndexTrackers.entrySet()) { <|endfocus|> AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); }
<|startcomment|> MAJOR SonarQube violation: 'for' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  protected void cleanupForAbort() { <|startfocus|> for(Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>>e:primaryIndexTrackers.entrySet()) { <|endfocus|> AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); }
<|startcomment|> MAJOR SonarQube violation: Split this 130 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  protected void cleanupForAbort() { <|startfocus|> for(Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>>e:primaryIndexTrackers.entrySet()) { <|endfocus|> AtomicInteger pendingOps = partitionPendingOps.get(e.getKey()); e.getValue().first.cleanupNumActiveOperationsForAbortedJob(pendingOps.get()); }
<|startcomment|> MAJOR SonarQube violation: The Cyclomatic Complexity of this method "createSearchKeyExpr" is 32 which is greater than 20 authorized. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AMethodCyclomaticComplexity <|endcomment|>  return primaryKeyVars; } /** * Returns the search key expression which feeds a secondary-index search. If we are optimizing a selection query * then this method returns the a ConstantExpression from the first constant value in the optimizable function * expression. * If we are optimizing a join, then this method returns the VariableReferenceExpression that should feed the * secondary index probe. * * @throws AlgebricksException */ <|startfocus|> public static Pair<ILogicalExpression, ILogicalExpression> createSearchKeyExpr(Index index, <|endfocus|> IOptimizableFuncExpr optFuncExpr, IAType indexedFieldType, OptimizableOperatorSubTree probeSubTree) throws AlgebricksException { if (probeSubTree == null) { // We are optimizing a selection query. Search key is a constant. // Type Checking and type promotion is done here if (optFuncExpr.getNumConstantExpr() == 0) { //We are looking at a selection case, but using two variables //This means that the second variable comes from a nonPure function call //TODO: Right now we miss on type promotion for nonpure functions
<|startcomment|> CRITICAL SonarQube violation: Remove this call to "wait" or move it into a "while" loop. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2274 <|endcomment|>  if (dsInfo.isDurable()) { synchronized (logRecord) { TransactionUtil.formFlushLogRecord(logRecord, dsInfo.getDatasetID(), null, logManager.getNodeId(), indexes.size()); try { logManager.log(logRecord); } catch (ACIDException e) { throw new HyracksDataException("could not write flush log while closing dataset", e); } try { //notification will come from LogBuffer class (notifyFlushTerminator) logRecord.wait(); } catch (InterruptedException e) { <|startfocus|> throw new HyracksDataException(e); <|endfocus|> } } } for (ILSMIndex index : indexes) { //update resource lsn AbstractLSMIOOperationCallback ioOpCallback = (AbstractLSMIOOperationCallback) index.getIOOperationCallback(); ioOpCallback.updateLastLSN(logRecord.getLSN()); } if (asyncFlush) { for (ILSMIndex index : indexes) { ILSMIndexAccessor accessor = index.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.scheduleFlush(index.getIOOperationCallback()); } } else { for (ILSMIndex index : indexes) {
<|startcomment|> CRITICAL SonarQube violation: Either re-interrupt this method or rethrow the "InterruptedException". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2142 <|endcomment|>  synchronized (logRecord) { TransactionUtil.formFlushLogRecord(logRecord, dsInfo.getDatasetID(), null, logManager.getNodeId(), indexes.size()); try { logManager.log(logRecord); } catch (ACIDException e) { throw new HyracksDataException("could not write flush log while closing dataset", e); } try { //notification will come from LogBuffer class (notifyFlushTerminator) logRecord.wait(); } catch (InterruptedException e) { <|startfocus|> throw new HyracksDataException(e); <|endfocus|> } } } for (ILSMIndex index : indexes) { //update resource lsn AbstractLSMIOOperationCallback ioOpCallback = (AbstractLSMIOOperationCallback) index.getIOOperationCallback(); ioOpCallback.updateLastLSN(logRecord.getLSN()); } if (asyncFlush) { for (ILSMIndex index : indexes) { ILSMIndexAccessor accessor = index.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.scheduleFlush(index.getIOOperationCallback()); } } else { for (ILSMIndex index : indexes) { // TODO: This is not efficient since we flush the indexes sequentially.
<|startcomment|> CRITICAL SonarQube violation: Remove this call to "wait" or move it into a "while" loop. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2274 <|endcomment|>  try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } try { flushDatasetOpenIndexes(dsInfo, false); } catch (Exception e) { throw new HyracksDataException(e); } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { <|startfocus|> if (iInfo.isOpen()) { ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } <|endfocus|> } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dsr : openDatasets) { closeDataset(dsr.getDatasetInfo()); } } @Override public synchronized void closeUserDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dsr : openDatasets) {
<|startcomment|> CRITICAL SonarQube violation: Either re-interrupt this method or rethrow the "InterruptedException". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2142 <|endcomment|>  try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } try { flushDatasetOpenIndexes(dsInfo, false); } catch (Exception e) { throw new HyracksDataException(e); } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { <|startfocus|> if (iInfo.isOpen()) { ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } <|endfocus|> } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dsr : openDatasets) { closeDataset(dsr.getDatasetInfo()); } } @Override public synchronized void closeUserDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values()); for (DatasetResource dsr : openDatasets) {
<|startcomment|> remove this. It is better that we get the warning so that we know this is a good candidate to refactor. <|endcomment|>  // we will force all jobs to spill their cached entities to disk. // This could happen only when we have many jobs with small // number of records and none of them have job commit. freeJobsCachedEntities(txnId); } jobId2WinnerEntitiesMap.put(txnId, jobEntityWinners); } else { jobEntityWinners = jobId2WinnerEntitiesMap.get(txnId); } jobEntityWinners.add(logRecord); } <|startfocus|> @SuppressWarnings({"squid:MethodCyclomaticComplexity","squid:S134"}) <|endfocus|> private synchronized void startRecoveryRedoPhase(Set<Integer> partitions, ILogReader logReader, long lowWaterMarkLSN, Set<Long> winnerTxnSet) throws IOException, ACIDException { int redoCount = 0; long txnId = 0; long resourceId; long maxDiskLastLsn; long lsn = -1; ILSMIndex index = null; LocalResource localResource = null; DatasetLocalResource localResourceMetadata = null; boolean foundWinner = false; JobEntityCommits jobEntityWinners = null; IAppRuntimeContextProvider appRuntimeContext = txnSubsystem.getAsterixAppRuntimeContextProvider(); IDatasetLifecycleManager datasetLifecycleManager = appRuntimeContext.getDatasetLifecycleManager();
<|startcomment|> writeEntityResource <|endcomment|>  private void doWriteLogRecord(ByteBuffer buffer) { buffer.put(logSource); buffer.put(logType); buffer.putLong(txnId); switch (logType) { case LogType.ENTITY_COMMIT: <|startfocus|> writeEntityInfo(buffer); <|endfocus|> break; case LogType.UPDATE: writeEntityInfo(buffer); buffer.putLong(resourceId); buffer.putInt(logSize); buffer.putInt(newValueFieldCount); buffer.put(newOp); buffer.putInt(newValueSize); writeTuple(buffer, newValue, newValueSize); if (oldValueSize > 0) { buffer.putInt(oldValueSize); buffer.putInt(oldValueFieldCount); writeTuple(buffer, oldValue, oldValueSize); } break; case LogType.FILTER: writeEntityInfoNoPK(buffer); buffer.putLong(resourceId); buffer.putInt(logSize); buffer.putInt(newValueFieldCount); buffer.put(newOp); buffer.putInt(newValueSize); writeTuple(buffer, newValue, newValueSize); break; case LogType.FLUSH: buffer.putInt(datasetId); break; case LogType.MARKER: buffer.putInt(datasetId); buffer.putInt(resourcePartition); callback.before(buffer); buffer.putInt(logSize);
<|startcomment|> writeEntityValue <|endcomment|> <|startfocus|> private void writeEntityInfo(ByteBuffer buffer) { buffer.putInt(resourcePartition); buffer.putInt(datasetId); <|endfocus|> buffer.putInt(PKHashValue); if (PKValueSize <= 0) { throw new IllegalStateException("Primary Key Size is less than or equal to 0"); } buffer.putInt(PKValueSize); writePKValue(buffer);
<|startcomment|> remove <|endcomment|> <|startfocus|> private void writeEntityInfo(ByteBuffer buffer) { buffer.putInt(resourcePartition); buffer.putInt(datasetId); <|endfocus|> buffer.putInt(PKHashValue); if (PKValueSize <= 0) { throw new IllegalStateException("Primary Key Size is less than or equal to 0"); } buffer.putInt(PKValueSize); writePKValue(buffer);
<|startcomment|> writeEntityResource <|endcomment|> <|startfocus|> private void writeEntityInfoNoPK(ByteBuffer buffer) { <|endfocus|> buffer.putInt(resourcePartition); buffer.putInt(datasetId);
<|startcomment|> readEntityResource <|endcomment|>  txnId = buffer.getLong(); switch (logType) { case LogType.FLUSH: if (buffer.remaining() < ILogRecord.DS_LEN) { return RecordReadStatus.TRUNCATED; } datasetId = buffer.getInt(); resourceId = 0l; // fall throuh case LogType.WAIT: computeAndSetLogSize(); break; case LogType.JOB_COMMIT: case LogType.ABORT: datasetId = -1; PKHashValue = -1; computeAndSetLogSize(); break; case LogType.ENTITY_COMMIT: <|startfocus|> if (readEntityInfo(buffer)) { <|endfocus|> computeAndSetLogSize(); } else { return RecordReadStatus.TRUNCATED; } break; case LogType.UPDATE: if (readEntityInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; } break; case LogType.FILTER: if (readEntityNoPKInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) {
<|startcomment|> readEntityResource <|endcomment|>  if (readEntityInfo(buffer)) { computeAndSetLogSize(); } else { return RecordReadStatus.TRUNCATED; } break; case LogType.UPDATE: if (readEntityInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; } break; case LogType.FILTER: <|startfocus|> if (readEntityNoPKInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; <|endfocus|> } break; case LogType.MARKER: if (buffer.remaining() < DS_LEN + RS_PARTITION_LEN + PRVLSN_LEN + LOGRCD_SZ_LEN) { return RecordReadStatus.TRUNCATED; } datasetId = buffer.getInt(); resourcePartition = buffer.getInt(); prevMarkerLSN = buffer.getLong(); logSize = buffer.getInt(); int lenRemaining = logSize - MARKER_BASE_LOG_SIZE;
<|startcomment|> return <|endcomment|>  computeAndSetLogSize(); } else { return RecordReadStatus.TRUNCATED; } break; case LogType.UPDATE: if (readEntityInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; } break; case LogType.FILTER: <|startfocus|> if (readEntityNoPKInfo(buffer)) { RecordReadStatus updStatus = readUpdateInfo(buffer); if (updStatus != RecordReadStatus.OK) { return updStatus; } } else { return RecordReadStatus.TRUNCATED; <|endfocus|> } break; case LogType.MARKER: if (buffer.remaining() < DS_LEN + RS_PARTITION_LEN + PRVLSN_LEN + LOGRCD_SZ_LEN) { return RecordReadStatus.TRUNCATED; } datasetId = buffer.getInt(); resourcePartition = buffer.getInt(); prevMarkerLSN = buffer.getLong(); logSize = buffer.getInt(); int lenRemaining = logSize - MARKER_BASE_LOG_SIZE; if (buffer.remaining() < lenRemaining) {
<|startcomment|> readEntityValue <|endcomment|>  private boolean readEntityInfo(ByteBuffer buffer) { //attempt to read in the resourcePartition, dsid, PK hash and PK length <|startfocus|> if (buffer.remaining() < ENTITYCOMMIT_UPDATE_HEADER_LEN) { <|endfocus|> return false; } resourcePartition = buffer.getInt(); datasetId = buffer.getInt(); PKHashValue = buffer.getInt(); PKValueSize = buffer.getInt(); // attempt to read in the PK if (buffer.remaining() < PKValueSize) { return false; } if (PKValueSize <= 0) { throw new IllegalStateException("Primary Key Size is less than or equal to 0"); } PKValue = readPKValue(buffer); return true;
<|startcomment|> remove <|endcomment|>  private boolean readEntityInfo(ByteBuffer buffer) { //attempt to read in the resourcePartition, dsid, PK hash and PK length if (buffer.remaining() < ENTITYCOMMIT_UPDATE_HEADER_LEN) { return false; } <|startfocus|> resourcePartition = buffer.getInt(); datasetId = buffer.getInt(); <|endfocus|> PKHashValue = buffer.getInt(); PKValueSize = buffer.getInt(); // attempt to read in the PK if (buffer.remaining() < PKValueSize) { return false; } if (PKValueSize <= 0) { throw new IllegalStateException("Primary Key Size is less than or equal to 0"); } PKValue = readPKValue(buffer); return true;
<|startcomment|> readEntityResource <|endcomment|> <|startfocus|> private boolean readEntityNoPKInfo(ByteBuffer buffer) { //attempt to read in the resourcePartition, dsid, PK hash and PK length if (buffer.remaining() < ENTITYCOMMIT_UPDATE_HEADER_LEN) { <|endfocus|> return false; } resourcePartition = buffer.getInt(); datasetId = buffer.getInt(); return true;
<|startcomment|> fix comment <|endcomment|> <|startfocus|> private boolean readEntityNoPKInfo(ByteBuffer buffer) { //attempt to read in the resourcePartition, dsid, PK hash and PK length if (buffer.remaining() < ENTITYCOMMIT_UPDATE_HEADER_LEN) { <|endfocus|> return false; } resourcePartition = buffer.getInt(); datasetId = buffer.getInt(); return true;
<|startcomment|> this isn't correct. You need a new one for entity resource length, then adjust ENTITYCOMMIT_UPDATE_HEADER_LEN <|endcomment|> <|startfocus|> private boolean readEntityNoPKInfo(ByteBuffer buffer) { //attempt to read in the resourcePartition, dsid, PK hash and PK length if (buffer.remaining() < ENTITYCOMMIT_UPDATE_HEADER_LEN) { <|endfocus|> return false; } resourcePartition = buffer.getInt(); datasetId = buffer.getInt(); return true;
<|startcomment|> revert <|endcomment|>  if (isDeleteOperation(tuple, numOfPrimaryKeys)) { // Only delete if it is a delete and not upsert abstractModCallback.setOp(Operation.DELETE); lsmAccessor.forceDelete(tuple); recordWasDeleted = true; } else { abstractModCallback.setOp(Operation.UPSERT); lsmAccessor.forceUpsert(tuple); recordWasInserted = true; } if (isFiltered && prevTuple != null) { // need to update the filter of the new component with the previous value <|startfocus|> lsmAccessor.updateFilter(prevTuple, true); <|endfocus|> } writeOutput(index, recordWasInserted, recordWasDeleted); } catch (Exception e) { throw HyracksDataException.create(e); } } @Override public void start() throws HyracksDataException { lsmAccessor.getCtx().setOperation(IndexOperation.UPSERT); } @Override public void finish() throws HyracksDataException { lsmAccessor.getCtx().setOperation(IndexOperation.UPSERT); } }; } // we have the permutation which has [pk locations, record location, optional:filter-location] // the index -> we don't need anymore data?
<|startcomment|> you shouldn't need this <|endcomment|>  * * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.am.common.ophelpers; public enum IndexOperation { CREATE, INSERT, DELETE, UPDATE, UPSERT, FILTER_MOD, <|startfocus|> SEARCH, <|endfocus|> DISKORDERSCAN, PHYSICALDELETE, NOOP, MERGE, FULL_MERGE, FLUSH, REPLICATE, DISK_COMPONENT_SCAN, DELETE_MEMORY_COMPONENT, DELETE_DISK_COMPONENTS } 
<|startcomment|> remove <|endcomment|>  ctx.setOperation(IndexOperation.UPSERT); lsmHarness.forceUpdateMeta(ctx, key, value); } @Override public ITreeIndexCursor createSearchCursor(boolean exclusive) { return cursorFactory.create(ctx); } @Override public void updateFilter(ITupleReference tuple) throws HyracksDataException { ctx.setOperation(IndexOperation.UPSERT); lsmHarness.updateFilter(ctx, tuple); } <|startfocus|> public void updateFilter(ITupleReference tuple, boolean callback) throws HyracksDataException { ctx.setOperation(IndexOperation.UPSERT); lsmHarness.updateFilter(ctx, tuple, callback); } <|endfocus|> public void batchOperate(FrameTupleAccessor accessor, FrameTupleReference tuple, IFrameTupleProcessor processor, IFrameOperationCallback frameOpCallback) throws HyracksDataException { lsmHarness.batchOperate(ctx, accessor, tuple, processor, frameOpCallback); } @Override public void scanDiskComponents(IIndexCursor cursor) throws HyracksDataException { ctx.setOperation(IndexOperation.DISK_COMPONENT_SCAN); lsmHarness.scanDiskComponents(ctx, cursor); } @Override public String toString() { return getClass().getSimpleName() + ':' + lsmHarness.toString(); } @Override
<|startcomment|> you shouldn't need this <|endcomment|>  } @Override public void found(ITupleReference before, ITupleReference after) throws HyracksDataException { if (isFoundNull) { Assert.assertEquals(null, before); } else { Assert.assertEquals(0, cmp.compare(AbstractModificationOperationCallbackTest.this.tuple, before)); } Assert.assertEquals(0, cmp.compare(AbstractModificationOperationCallbackTest.this.tuple, after)); } <|startfocus|> @Override public void after(ITupleReference tuple) throws HyracksDataException { Assert.assertEquals(0, cmp.compare(AbstractModificationOperationCallbackTest.this.tuple, tuple)); } <|endfocus|> } } 
<|startcomment|> you shouldn't need this <|endcomment|>  // Do nothing. } @Override public void before(ITupleReference tuple) { // Do nothing. } @Override public void found(ITupleReference before, ITupleReference after) { // Do nothing. } @Override public void cancel(ITupleReference tuple) { // Do nothing. } @Override public void complete(ITupleReference tuple) throws HyracksDataException { // Do nothing. } <|startfocus|> @Override public void after(ITupleReference tuple) throws HyracksDataException { // Do nothing. } <|endfocus|> } 
<|startcomment|> you shouldn't need this <|endcomment|>  public void after(ITupleReference tuple) { <|startfocus|> <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: Remove this useless assignment to local variable "secondaryKeyFieldUsedAfterSelectOrJoinOp". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1854 <|endcomment|>  IOptimizationContext context, Quadruple<Boolean, Boolean, Boolean, Boolean> indexOnlyPlanInfo) throws AlgebricksException { // index-only plan possible? boolean isIndexOnlyPlan = false; // secondary key field usage after the select (join) operators // This boolean is mainly used for R-Tree case since R-Tree index generates an MBR // and we can restore original point or rectangle from this MBR if an index is built on point or rectangle. <|startfocus|> boolean secondaryKeyFieldUsedAfterSelectOrJoinOp = indexOnlyPlanInfo.getSecond(); <|endfocus|> // Whether a post verification (especially for R-Tree case) is required after the secondary index search // (e.g., the shape of the given query is not a point or rectangle. // Then, we may need to apply the select again using the real polygon, not MBR of it to get the true // result, not a super-set of it.) boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo.getThird(); // Does the given index can cover all search predicates? boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo.getFourth(); 
<|startcomment|> MAJOR SonarQube violation: Remove this useless assignment to local variable "doesSIdxSearchCoverAllPredicates". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1854 <|endcomment|>  // (e.g., the shape of the given query is not a point or rectangle. // Then, we may need to apply the select again using the real polygon, not MBR of it to get the true // result, not a super-set of it.) boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo.getThird(); // Does the given index can cover all search predicates? <|startfocus|> boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo.getFourth(); <|endfocus|> // matched function expressions List<IOptimizableFuncExpr> matchedFuncExprs = analysisCtx.getMatchedFuncExprs(); // If no-index-only option is given, we stop here to honor that request. boolean noIndexOnlyPlanOption = getNoIndexOnlyOption(context); if (noIndexOnlyPlanOption) { indexOnlyPlanInfo.setFirst(isIndexOnlyPlan); return; } // logical variables that select (join) operator is using List<LogicalVariable> usedVarsInSelJoinOp = new ArrayList<>(); List<LogicalVariable> usedVarsInSelJoinOpTemp = new ArrayList<>(); // live variables that select (join) operator can access
<|startcomment|> MAJOR SonarQube violation: The Cyclomatic Complexity of this method "analyzeGetItemFuncExpr" is 23 which is greater than 20 authorized. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AMethodCyclomaticComplexity <|endcomment|>  || funcExpr.getFunctionIdentifier() == BuiltinFunctions.FULLTEXT_CONTAINS_WO_OPTION) { boolean matches = AccessMethodUtils.analyzeFuncExprArgsForOneConstAndVarAndUpdateAnalysisCtx(funcExpr, analysisCtx, context, typeEnvironment); if (!matches) { matches = AccessMethodUtils.analyzeFuncExprArgsForTwoVarsAndUpdateAnalysisCtx(funcExpr, analysisCtx); } return matches; } return analyzeGetItemFuncExpr(funcExpr, assignsAndUnnests, analysisCtx); } public boolean analyzeGetItemFuncExpr(AbstractFunctionCallExpression funcExpr, List<AbstractLogicalOperator> assignsAndUnnests, AccessMethodAnalysisContext analysisCtx) <|startfocus|> throws AlgebricksException { <|endfocus|> if (funcExpr.getFunctionIdentifier() != BuiltinFunctions.GET_ITEM) { return false; } ILogicalExpression arg1 = funcExpr.getArguments().get(0).getValue(); ILogicalExpression arg2 = funcExpr.getArguments().get(1).getValue(); // The second arg is the item index to be accessed. It must be a constant. if (arg2.getExpressionTag() != LogicalExpressionTag.CONSTANT) { return false; } // The first arg must be a variable or a function expr.
<|startcomment|> MAJOR SonarQube violation: The Cyclomatic Complexity of this method "initFromSubTree" is 22 which is greater than 20 authorized. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AMethodCyclomaticComplexity <|endcomment|>  // (E.g. There are index-nested-loop-joins in the plan.) private List<Mutable<ILogicalOperator>> ixJoinOuterAdditionalDataSourceRefs = null; private List<DataSourceType> ixJoinOuterAdditionalDataSourceTypes = null; private List<Dataset> ixJoinOuterAdditionalDatasets = null; private List<ARecordType> ixJoinOuterAdditionalRecordTypes = null; /** * Identifies the root of the subtree and initializes the data-source, assign, and unnest information. */ <|startfocus|> public boolean initFromSubTree(Mutable<ILogicalOperator> subTreeOpRef, IOptimizationContext context) throws AlgebricksException { <|endfocus|> reset(); rootRef = subTreeOpRef; root = subTreeOpRef.getValue(); boolean passedSource = false; boolean result = false; Mutable<ILogicalOperator> searchOpRef = subTreeOpRef; // Examine the op's children to match the expected patterns. AbstractLogicalOperator subTreeOp = (AbstractLogicalOperator) searchOpRef.getValue(); MetadataProvider metadataProvider = (MetadataProvider) context.getMetadataProvider(); do { // Skips the limit operator. if (subTreeOp.getOperatorTag() == LogicalOperatorTag.LIMIT) {
<|startcomment|> MAJOR SonarQube violation: 'else' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  // object creation: should be relatively low btreeCursors = new ITreeIndexCursor[numBTrees]; btreeAccessors = new BTreeAccessor[numBTrees]; bloomFilters = new BloomFilter[numBTrees]; } includeMutableComponent = false; for (int i = 0; i < numBTrees; i++) { ILSMComponent component = operationalComponents.get(i); BTree btree = (BTree) component.getIndex(); if (component.getType() == LSMComponentType.MEMORY) { includeMutableComponent = true; bloomFilters[i] = null; <|startfocus|> }else { <|endfocus|> bloomFilters[i] = ((LSMBTreeWithBloomFilterDiskComponent) component).getBloomFilter(); } if (btreeAccessors[i] == null) { btreeAccessors[i] = btree.createAccessor(NoOpIndexAccessParameters.INSTANCE); btreeCursors[i] = btreeAccessors[i].createPointCursor(false); } else { // re-use btreeAccessors[i].reset(btree, NoOpOperationCallback.INSTANCE, NoOpOperationCallback.INSTANCE); btreeCursors[i].close(); } } nextHasBeenCalled = false; foundTuple = false; } @Override public void next() throws HyracksDataException { nextHasBeenCalled = true;
<|startcomment|> MAJOR SonarQube violation: '}' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  // object creation: should be relatively low btreeCursors = new ITreeIndexCursor[numBTrees]; btreeAccessors = new BTreeAccessor[numBTrees]; bloomFilters = new BloomFilter[numBTrees]; } includeMutableComponent = false; for (int i = 0; i < numBTrees; i++) { ILSMComponent component = operationalComponents.get(i); BTree btree = (BTree) component.getIndex(); if (component.getType() == LSMComponentType.MEMORY) { includeMutableComponent = true; bloomFilters[i] = null; <|startfocus|> }else { <|endfocus|> bloomFilters[i] = ((LSMBTreeWithBloomFilterDiskComponent) component).getBloomFilter(); } if (btreeAccessors[i] == null) { btreeAccessors[i] = btree.createAccessor(NoOpIndexAccessParameters.INSTANCE); btreeCursors[i] = btreeAccessors[i].createPointCursor(false); } else { // re-use btreeAccessors[i].reset(btree, NoOpOperationCallback.INSTANCE, NoOpOperationCallback.INSTANCE); btreeCursors[i].close(); } } nextHasBeenCalled = false; foundTuple = false; } @Override public void next() throws HyracksDataException { nextHasBeenCalled = true;
<|startcomment|> shouldn't this have || isDecisive? <|endcomment|>  public int compare(ReferenceEntry tp1, ReferenceEntry tp2) { int[] tPointers1 = tp1.getTPointers(); int[] tPointers2 = tp2.getTPointers(); int cmp = NormalizedKeyUtils.compareNormalizeKeys(tPointers1, 0, tPointers2, 0, normalizedKeyLength); <|startfocus|> if (cmp != 0) { <|endfocus|> return cmp; } IFrameTupleAccessor fta1 = tp1.getAccessor(); IFrameTupleAccessor fta2 = tp2.getAccessor(); byte[] b1 = fta1.getBuffer().array(); byte[] b2 = fta2.getBuffer().array(); for (int f = 0; f < sortFields.length; ++f) { int c; try { c = comparators[f].compare(b1, tPointers1[2 * f + normalizedKeyLength], tPointers1[2 * f + normalizedKeyLength + 1], b2, tPointers2[2 * f + normalizedKeyLength], tPointers2[2 * f + normalizedKeyLength + 1]); if (c != 0) { return c; } } catch (HyracksDataException e) {
<|startcomment|> CRITICAL SonarQube violation: Either re-interrupt this method or rethrow the "InterruptedException". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2142 <|endcomment|>  flushAndWaitForIO(dsInfo, iInfo); } } } private void closeDataset(DatasetInfo dsInfo) throws HyracksDataException { // First wait for any ongoing IO operations synchronized (dsInfo) { while (dsInfo.getNumActiveIOOps() > 0) { try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } try { flushDatasetOpenIndexes(dsInfo, false); } catch (Exception e) { <|startfocus|> throw new HyracksDataException(e); <|endfocus|> } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { if (iInfo.isOpen()) { ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException { ArrayList<DatasetResource> openDatasets = new ArrayList<>(datasets.values());
<|startcomment|> Let's change this line to: if (dsType != DataSource.Type.INTERNAL_DATASET && dsType != DataSource.Type.EXTERNAL_DATASET) { return false; } this should fix CB issue (we have additional datasource types) <|endcomment|>  if (op2.getOperatorTag() == LogicalOperatorTag.DATASOURCESCAN) { DataSourceScanOperator scan = (DataSourceScanOperator) op2; int n = scan.getVariables().size(); LogicalVariable scanRecordVar = scan.getVariables().get(n - 1); IDataSource<DataSourceId> dataSource = (IDataSource<DataSourceId>) scan.getDataSource(); byte dsType = ((DataSource) dataSource).getDatasourceType(); <|startfocus|> if (dsType == DataSource.Type.FEED || dsType == DataSource.Type.LOADABLE || dsType == DataSource.Type.FUNCTION) { <|endfocus|> return false; } DataSourceId asid = dataSource.getId(); MetadataProvider mp = (MetadataProvider) context.getMetadataProvider(); Dataset dataset = mp.findDataset(asid.getDataverseName(), asid.getDatasourceName()); if (dataset == null) { throw new AlgebricksException("Dataset " + asid.getDatasourceName() + " not found."); } if (dataset.getDatasetType() != DatasetType.INTERNAL) { setAsFinal(access, context, finalAnnot); return false; } String tName = dataset.getItemTypeName();
<|startcomment|> MAJOR SonarQube violation: Replace this usage of System.out or System.err by a logger. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS106 <|endcomment|>  buffer.putInt(newValueSize); writeTuple(buffer, newValue, newValueSize); if (oldValueSize > 0) { buffer.putInt(oldValueSize); buffer.putInt(oldValueFieldCount); writeTuple(buffer, oldValue, oldValueSize); } break; case LogType.FILTER: writeEntityResource(buffer); buffer.putLong(resourceId); buffer.putInt(logSize); buffer.putInt(newValueFieldCount); buffer.put(newOp); buffer.putInt(newValueSize); writeTuple(buffer, newValue, newValueSize); <|startfocus|> System.out.println(newValueSize); <|endfocus|> break; case LogType.FLUSH: buffer.putInt(datasetId); break; case LogType.MARKER: buffer.putInt(datasetId); buffer.putInt(resourcePartition); callback.before(buffer); buffer.putInt(logSize); buffer.put(marker); break; default: // Do nothing }
<|startcomment|> MAJOR SonarQube violation: '{' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.am.common.api; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.dataflow.common.data.accessors.ITupleReference; import org.apache.hyracks.storage.common.IModificationOperationCallback; public interface IExtendedModificationOperationCallback extends <|startfocus|> IModificationOperationCallback{ <|endfocus|> /** * Called after the action taken in found, to take action on a tuple that is not part of the index * itself but is part of an ancillary structure that is updated alongside the index. An example would * be a simple statistic on the index that records the minimum and maximum values. * * @param after The tuple to feed to the ancilliary structure * @throws HyracksDataException */ void after(ITupleReference after) throws HyracksDataException; } 
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { <|startfocus|> return createAccessor(createOpContext(((IExtendedModificationOperationCallback) (iap.getModificationCallback())), <|endfocus|> iap.getSearchOperationCallback()));
<|startcomment|> MAJOR SonarQube violation: Split this 121 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { <|startfocus|> return createAccessor(createOpContext(((IExtendedModificationOperationCallback) (iap.getModificationCallback())), <|endfocus|> iap.getSearchOperationCallback()));
<|startcomment|> BLOCKER SonarQube violation: Change this condition so that it does not always evaluate to "true" Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2583 <|endcomment|>  if (minTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); minTupleBytes = new byte[numBytes]; opCallback.after(tuple); logged = true; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); minTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, minTuple); if (c < 0) { <|startfocus|> if(!logged) { <|endfocus|> opCallback.after(tuple); logged = true; } int numBytes = tupleWriter.bytesRequired(tuple); if (minTupleBytes.length < numBytes) { minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple);
<|startcomment|> MAJOR SonarQube violation: 'if' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  if (minTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); minTupleBytes = new byte[numBytes]; opCallback.after(tuple); logged = true; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); minTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, minTuple); if (c < 0) { <|startfocus|> if(!logged) { <|endfocus|> opCallback.after(tuple); logged = true; } int numBytes = tupleWriter.bytesRequired(tuple); if (minTupleBytes.length < numBytes) { minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple);
<|startcomment|> MAJOR SonarQube violation: 'if' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  if (minTupleBytes.length < numBytes) { minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); maxTupleBytes = new byte[numBytes]; <|startfocus|> if(!logged) { <|endfocus|> opCallback.after(tuple); logged = true; } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); maxTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, maxTuple); if (c > 0) { if(!logged) { opCallback.after(tuple); } int numBytes = tupleWriter.bytesRequired(tuple); if (maxTupleBytes.length < numBytes) {
<|startcomment|> MAJOR SonarQube violation: Remove this useless assignment to local variable "logged". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1854 <|endcomment|>  minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); maxTupleBytes = new byte[numBytes]; if(!logged) { opCallback.after(tuple); <|startfocus|> logged = true; <|endfocus|> } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); maxTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, maxTuple); if (c > 0) { if(!logged) { opCallback.after(tuple); } int numBytes = tupleWriter.bytesRequired(tuple); if (maxTupleBytes.length < numBytes) { maxTupleBytes = new byte[numBytes];
<|startcomment|> MAJOR SonarQube violation: 'if' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  int numBytes = tupleWriter.bytesRequired(tuple); maxTupleBytes = new byte[numBytes]; if(!logged) { opCallback.after(tuple); logged = true; } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); maxTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, maxTuple); if (c > 0) { <|startfocus|> if(!logged) { <|endfocus|> opCallback.after(tuple); } int numBytes = tupleWriter.bytesRequired(tuple); if (maxTupleBytes.length < numBytes) { maxTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); } else { tupleWriter.writeTuple(tuple, maxTupleBytes, 0); } ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } } } @Override public ITupleReference getMinTuple() { return minTuple; } @Override
<|startcomment|> MAJOR SonarQube violation: Split this 124 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  return new LSMInvertedIndexAccessor(getHarness(), createOpContext((IExtendedModificationOperationCallback) (iap.getModificationCallback()), iap.getSearchOperationCallback())); } @Override protected LSMInvertedIndexOpContext createOpContext(IExtendedModificationOperationCallback modificationCallback, ISearchOperationCallback searchCallback) throws HyracksDataException { return new LSMInvertedIndexOpContext(this, memoryComponents, modificationCallback, searchCallback, invertedIndexFieldsForNonBulkLoadOps, filterFieldsForNonBulkLoadOps, getFilterCmpFactories(), tracer); } <|startfocus|> protected LSMInvertedIndexOpContext createRecoveryOpContext(IExtendedModificationOperationCallback modificationCallback, ISearchOperationCallback searchCallback) throws HyracksDataException { return new LSMInvertedIndexOpContext(this, memoryComponents, modificationCallback, searchCallback, invertedIndexFieldsForNonBulkLoadOps, null, null, tracer); } <|endfocus|> @Override public ITypeTraits[] getInvListTypeTraits() { return invListTypeTraits; } @Override public IBinaryComparatorFactory[] getInvListCmpFactories() { return invListCmpFactories; } @Override public ITypeTraits[] getTokenTypeTraits() { return tokenTypeTraits; } @Override public IBinaryComparatorFactory[] getTokenCmpFactories() { return tokenCmpFactories; } 
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { <|startfocus|> LSMRTreeOpContext opCtx = createOpContext(((IExtendedModificationOperationCallback) (iap.getModificationCallback())), <|endfocus|> iap.getSearchOperationCallback()); return new LSMTreeIndexAccessor(getHarness(), opCtx, cursorFactory);
<|startcomment|> MAJOR SonarQube violation: Split this 125 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { <|startfocus|> LSMRTreeOpContext opCtx = createOpContext(((IExtendedModificationOperationCallback) (iap.getModificationCallback())), <|endfocus|> iap.getSearchOperationCallback()); return new LSMTreeIndexAccessor(getHarness(), opCtx, cursorFactory);
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { LSMRTreeOpContext opCtx = <|startfocus|> createOpContext(((IExtendedModificationOperationCallback) iap.getModificationCallback()), iap.getSearchOperationCallback()); <|endfocus|> return new LSMTreeIndexAccessor(getHarness(), opCtx, cursorFactory);
<|startcomment|> CRITICAL SonarQube violation: Remove this call to "wait" or move it into a "while" loop. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2274 <|endcomment|>  // may lead to a deadlock scenario between the DatasetLifeCycleManager and the PrimaryIndexOperationTracker. flushAndWaitForIO(dsInfo, iInfo); } } } private void closeDataset(DatasetInfo dsInfo) throws HyracksDataException { // First wait for any ongoing IO operations synchronized (dsInfo) { while (dsInfo.getNumActiveIOOps() > 0) { try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } try { <|startfocus|> flushDatasetOpenIndexes(dsInfo, false); <|endfocus|> } catch (Exception e) { throw new HyracksDataException(e); } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { if (iInfo.isOpen()) { ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException {
<|startcomment|> CRITICAL SonarQube violation: Either re-interrupt this method or rethrow the "InterruptedException". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2142 <|endcomment|>  // may lead to a deadlock scenario between the DatasetLifeCycleManager and the PrimaryIndexOperationTracker. flushAndWaitForIO(dsInfo, iInfo); } } } private void closeDataset(DatasetInfo dsInfo) throws HyracksDataException { // First wait for any ongoing IO operations synchronized (dsInfo) { while (dsInfo.getNumActiveIOOps() > 0) { try { dsInfo.wait(); } catch (InterruptedException e) { throw new HyracksDataException(e); } } } try { <|startfocus|> flushDatasetOpenIndexes(dsInfo, false); <|endfocus|> } catch (Exception e) { throw new HyracksDataException(e); } for (IndexInfo iInfo : dsInfo.getIndexes().values()) { if (iInfo.isOpen()) { ILSMOperationTracker opTracker = iInfo.getIndex().getOperationTracker(); synchronized (opTracker) { iInfo.getIndex().deactivate(false); } iInfo.setOpen(false); } } removeDatasetFromCache(dsInfo.getDatasetID()); dsInfo.setOpen(false); } @Override public synchronized void closeAllDatasets() throws HyracksDataException {
<|startcomment|> MAJOR SonarQube violation: Refactor this code to not nest more than 4 if/for/while/switch/try statements. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS134 <|endcomment|>  } catch (HyracksDataException e) { datasetLifecycleManager.close(localResource.getPath()); throw e; } //#. set resourceId and maxDiskLastLSN to the map resourceId2MaxLSNMap.put(resourceId, maxDiskLastLsn); } else { maxDiskLastLsn = resourceId2MaxLSNMap.get(resourceId); } <|startfocus|> // lsn @ maxDiskLastLsn is either a flush log or a master replica log if (lsn >= maxDiskLastLsn) { redo(logRecord, datasetLifecycleManager); redoCount++; } <|endfocus|> } break; case LogType.JOB_COMMIT: case LogType.ENTITY_COMMIT: case LogType.ABORT: case LogType.FLUSH: case LogType.WAIT: case LogType.MARKER: //do nothing break; default: throw new ACIDException("Unsupported LogType: " + logRecord.getLogType()); } logRecord = logReader.next(); } LOGGER.info("Logs REDO phase completed. Redo logs count: " + redoCount); } finally {
<|startcomment|> BLOCKER SonarQube violation: Change this condition so that it does not always evaluate to "true" Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2583 <|endcomment|>  int numBytes = tupleWriter.bytesRequired(tuple); minTupleBytes = new byte[numBytes]; opCallback.after(tuple); logged = true; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); minTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, minTuple); if (c < 0) { <|startfocus|> if (!logged) { opCallback.after(tuple); logged = true; } <|endfocus|> int numBytes = tupleWriter.bytesRequired(tuple); if (minTupleBytes.length < numBytes) { minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple);
<|startcomment|> MAJOR SonarQube violation: Remove this useless assignment to local variable "logged". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1854 <|endcomment|>  minTupleBytes = new byte[numBytes]; tupleWriter.writeTuple(tuple, minTupleBytes, 0); minTupleBuf = ByteBuffer.wrap(minTupleBytes); } else { tupleWriter.writeTuple(tuple, minTupleBytes, 0); } ((ITreeIndexTupleReference) minTuple).resetByTupleOffset(minTupleBuf.array(), 0); } } if (maxTuple == null) { int numBytes = tupleWriter.bytesRequired(tuple); maxTupleBytes = new byte[numBytes]; if (!logged) { opCallback.after(tuple); <|startfocus|> logged = true; <|endfocus|> } tupleWriter.writeTuple(tuple, maxTupleBytes, 0); maxTupleBuf = ByteBuffer.wrap(maxTupleBytes); maxTuple = tupleWriter.createTupleReference(); ((ITreeIndexTupleReference) maxTuple).resetByTupleOffset(maxTupleBuf.array(), 0); } else { int c = cmp.compare(tuple, maxTuple); if (c > 0) { if (!logged) { opCallback.after(tuple); } int numBytes = tupleWriter.bytesRequired(tuple); if (maxTupleBytes.length < numBytes) { maxTupleBytes = new byte[numBytes];
<|startcomment|> MAJOR SonarQube violation: 'catch' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  return pin(dpid, newPage, null); } @Override public ICachedPage pin(long dpid, boolean newPage, ILargePageHelper helper) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { <|startfocus|> while(confiscatedPages.contains(c)){ throw new IllegalStateException(); } <|endfocus|> } } } finally{ confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; }
<|startcomment|> MAJOR SonarQube violation: '{' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  return pin(dpid, newPage, null); } @Override public ICachedPage pin(long dpid, boolean newPage, ILargePageHelper helper) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { <|startfocus|> while(confiscatedPages.contains(c)){ throw new IllegalStateException(); } <|endfocus|> } } } finally{ confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; }
<|startcomment|> MAJOR SonarQube violation: '}' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  return pin(dpid, newPage, null); } @Override public ICachedPage pin(long dpid, boolean newPage, ILargePageHelper helper) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { <|startfocus|> while(confiscatedPages.contains(c)){ throw new IllegalStateException(); } <|endfocus|> } } } finally{ confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; }
<|startcomment|> MAJOR SonarQube violation: Remove this use of "Thread.sleep()". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2925 <|endcomment|>  return null; } }); } for(int i=0;i<bufferCacheNumPages;i++){ synchronized (readers[i]){ while(readers[i].getValue() == null){ readers[i].wait(); } } } final long start = System.currentTimeMillis(); while(System.currentTimeMillis() - start < duration){ for(int i=0;i<bufferCacheNumPages;i++){ readers[i].getValue().interrupt(); } <|startfocus|> Thread.sleep(25); <|endfocus|> } try { for (int i = 0; i < bufferCacheNumPages; i++) { futures[i].get(); } } finally { bufferCache.deleteFile(fileId); bufferCache.close(); } } @Test public void simpleOpenPinCloseTest() throws HyracksException { TestStorageManagerComponentHolder.init(PAGE_SIZE, NUM_PAGES, MAX_OPEN_FILES); IBufferCache bufferCache = TestStorageManagerComponentHolder.getBufferCache(ctx.getJobletContext().getServiceContext()); IIOManager ioManager = TestStorageManagerComponentHolder.getIOManager(); String fileName = getFileName(); FileReference file = ioManager.resolve(fileName);
<|startcomment|> BLOCKER SonarQube violation: Change this condition so that it does not always evaluate to "true" Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2583 <|endcomment|>  this.btreePred = (RangePredicate) searchPred; btreeAccessor.search(btreeCursor, btreePred); openInvListRangeSearchCursor(); } @Override public boolean hasNext() throws HyracksDataException { // No more results possible if (!isInvListCursorOpen) { return false; } if (invListRangeSearchCursor.hasNext()) { return true; } // The current inverted-list-range-search cursor is exhausted. <|startfocus|> if (isInvListCursorOpen) { invListRangeSearchCursor.close(); isInvListCursorOpen = false; } <|endfocus|> openInvListRangeSearchCursor(); return isInvListCursorOpen; } @Override public void next() throws HyracksDataException { invListRangeSearchCursor.next(); if (concatTuple.hasMaxTuples()) { concatTuple.removeLastTuple(); } concatTuple.addTuple(invListRangeSearchCursor.getTuple()); } @Override public void destroy() throws HyracksDataException { if (isInvListCursorOpen) { invListRangeSearchCursor.unloadPages(); invListRangeSearchCursor.destroy(); isInvListCursorOpen = false; } btreeCursor.destroy(); } @Override
<|startcomment|> MAJOR SonarQube violation: 'finally' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { <|startfocus|> while(confiscatedPages.contains(c)){ throw new IllegalStateException(); } <|endfocus|> } } } finally{ confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; } pageReplacementStrategy.notifyCachePageAccess(cPage); if(DEBUG){ pinnedPageOwner.put((CachedPage) cPage, Thread.currentThread().getStackTrace()); } cPage.setLargePageHelper(helper);
<|startcomment|> MAJOR SonarQube violation: '{' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { <|startfocus|> while(confiscatedPages.contains(c)){ throw new IllegalStateException(); } <|endfocus|> } } } finally{ confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; } pageReplacementStrategy.notifyCachePageAccess(cPage); if(DEBUG){ pinnedPageOwner.put((CachedPage) cPage, Thread.currentThread().getStackTrace()); } cPage.setLargePageHelper(helper);
<|startcomment|> MAJOR SonarQube violation: 'if' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } CachedPage cPage = findPage(dpid, false); if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { <|startfocus|> while(confiscatedPages.contains(c)){ throw new IllegalStateException(); } <|endfocus|> } } } finally{ confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage, helper); cPage.valid = true; } } } else { cPage.valid = true; } pageReplacementStrategy.notifyCachePageAccess(cPage); if(DEBUG){ pinnedPageOwner.put((CachedPage) cPage, Thread.currentThread().getStackTrace()); } cPage.setLargePageHelper(helper);
<|startcomment|> warn <|endcomment|>  pageReplacementStrategy.notifyCachePageAccess(cPage); return cPage; } cPage = cPage.next; } } finally { bucket.bucketLock.unlock(); } return cPage; } @Override public ICachedPage pin(long dpid, boolean newPage) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } <|startfocus|> CachedPage cPage = findPage(dpid); <|endfocus|> if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { throw new IllegalStateException(); } } } finally { confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage); cPage.valid = true; } } } else {
<|startcomment|> let's move the unpin to a finally, if a boolean (i.e. success) isn't set after the tryRead(), so that we handle non-Exception throwables here as well. <|endcomment|>  pageReplacementStrategy.notifyCachePageAccess(cPage); return cPage; } cPage = cPage.next; } } finally { bucket.bucketLock.unlock(); } return cPage; } @Override public ICachedPage pin(long dpid, boolean newPage) throws HyracksDataException { // Calling the pinSanityCheck should be used only for debugging, since // the synchronized block over the fileInfoMap is a hot spot. if (DEBUG) { pinSanityCheck(dpid); } <|startfocus|> CachedPage cPage = findPage(dpid); <|endfocus|> if (!newPage) { if (DEBUG) { confiscateLock.lock(); try { for (CachedPage c : confiscatedPages) { if (c.dpid == dpid && c.confiscated.get()) { throw new IllegalStateException(); } } } finally { confiscateLock.unlock(); } } // Resolve race of multiple threads trying to read the page from // disk. synchronized (cPage) { if (!cPage.valid) { read(cPage); cPage.valid = true; } } } else {
<|startcomment|> Welcome to IntelliJ. You need to change the config to not use * until the number of imports in the same package is > 99. Also the formatting of the whole file isn't right. You will need to import the Eclipse config file. <|endcomment|>  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.common; import java.io.File; import java.text.SimpleDateFormat; import java.util.ArrayList; import java.util.Date; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Random; <|startfocus|> import java.util.concurrent.*; import java.util.concurrent.atomic.AtomicInteger; <|endfocus|> import org.apache.commons.lang3.mutable.Mutable; import org.apache.commons.lang3.mutable.MutableObject; import org.apache.hyracks.api.context.IHyracksTaskContext; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.api.exceptions.HyracksException; import org.apache.hyracks.api.io.FileReference; import org.apache.hyracks.api.io.IIOManager; import org.apache.hyracks.storage.common.buffercache.CachedPage; import org.apache.hyracks.storage.common.buffercache.IBufferCache; import org.apache.hyracks.storage.common.buffercache.ICachedPage; import org.apache.hyracks.storage.common.file.BufferedFileHandle;
<|startcomment|> MAJOR SonarQube violation: Rename "failed" which hides the field declared at line 62. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AHiddenFieldCheck <|endcomment|>  } this.writer = writer; } @Override public void setInputRecordDescriptor(int index, RecordDescriptor recordDescriptor) { // input is not accessed } @Override public void open() throws HyracksDataException { if (idx == 0) { writer.open(); } } @Override public void nextFrame(ByteBuffer buffer) throws HyracksDataException { writer.nextFrame(buffer); } @Override public void fail() throws HyracksDataException { <|startfocus|> boolean failed = this.failed.getValue(); this.failed.setValue(Boolean.TRUE); <|endfocus|> if (!failed) { writer.fail(); } } @Override public void close() throws HyracksDataException { if (idx == 0) { writer.close(); } } } } 
<|startcomment|> MAJOR SonarQube violation: Split this 141 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  int n = subplans.size(); AlgebricksPipeline[] result = new AlgebricksPipeline[n]; for (int i = 0; i < n; i++) { List<AlgebricksPipeline> subplanOps = subplans.get(i); if (subplanOps.size() != 1) { throw new AlgebricksException("Attempting to construct a nested plan with " + subplanOps.size() <|startfocus|> + " operator descriptors. Currently, nested plans can only consist in linear pipelines of Asterix micro operators."); <|endfocus|> } result[i] = subplanOps.get(0); } return result; } protected List<List<AlgebricksPipeline>> compileSubplansImpl(IOperatorSchema outerPlanSchema, AbstractOperatorWithNestedPlans npOp, IOperatorSchema opSchema, JobGenContext context) throws AlgebricksException { List<List<AlgebricksPipeline>> subplans = new ArrayList<>(npOp.getNestedPlans().size()); PlanCompiler pc = new PlanCompiler(context); for (ILogicalPlan p : npOp.getNestedPlans()) { subplans.add(buildPipelineWithProjection(p, outerPlanSchema, npOp, opSchema, pc)); } return subplans; } 
<|startcomment|> MAJOR SonarQube violation: Split this 126 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  context.getTypeEnvironment(op.getInputs().get(0).getValue()), inputSchemas[0], context); IMissingWriterFactory[] missingWriterFactories = new IMissingWriterFactory[np.get(0).getOutputWidth()]; for (int i = 0; i < missingWriterFactories.length; i++) { missingWriterFactories[i] = context.getMissingWriterFactory(); } RecordDescriptor recDesc = JobGenHelper.mkRecordDescriptor(context.getTypeEnvironment(op), opSchema, context); <|startfocus|> SubplanRuntimeFactory runtime = new SubplanRuntimeFactory(np, missingWriterFactories, inputRecordDesc, recDesc, null); <|endfocus|> builder.contributeMicroOperator(subplan, runtime, recDesc); ILogicalOperator src = op.getInputs().get(0).getValue(); builder.contributeGraphEdge(src, 0, op, 0); } @Override public boolean expensiveThanMaterialization() { return true; } } 
<|startcomment|> MAJOR SonarQube violation: Add a nested comment explaining why this method is empty, throw an UnsupportedOperationException or complete the implementation. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1186 <|endcomment|> <|startfocus|> public void setInputRecordDescriptor(int index, RecordDescriptor recordDescriptor) { <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: Remove usage of generic wildcard type. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1452 <|endcomment|>  return useConnectorPolicyForScheduling; } public void setUseConnectorPolicyForScheduling(boolean useConnectorPolicyForScheduling) { this.useConnectorPolicyForScheduling = useConnectorPolicyForScheduling; } public void setRequiredClusterCapacity(IClusterCapacity capacity) { this.requiredClusterCapacity = capacity; } public IClusterCapacity getRequiredClusterCapacity() { return requiredClusterCapacity; } public void setMetaOps(List<? extends IOperatorDescriptor> metaOps) { this.metaOps = metaOps; } <|startfocus|> public List<? extends IOperatorDescriptor> getMetaOps() { <|endfocus|> return metaOps; } private <K, V> void insertIntoIndexedMap(Map<K, List<V>> map, K key, int index, V value) { List<V> vList = map.computeIfAbsent(key, k -> new ArrayList<>()); extend(vList, index); vList.set(index, value); } @Override public String toString() { StringBuilder buffer = new StringBuilder(); opMap.forEach((key, value) -> { buffer.append(key.getId()).append(" : ").append(value.toString()).append("\n");
<|startcomment|> MAJOR SonarQube violation: Add a private constructor to hide the implicit public one. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1118 <|endcomment|>  * * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.ipc.impl; import org.apache.hyracks.ipc.api.IIPCEventListener; public class NoOpIPCEventListener implements IIPCEventListener { <|startfocus|> public static final IIPCEventListener INSTANCE = new NoOpIPCEventListener(); <|endfocus|> } 
<|startcomment|> MAJOR SonarQube violation: Split this 129 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  return new BloomFilterBuilder(numElements, numHashes, numBitsPerElement); } public class BloomFilterBuilder implements IIndexBulkLoader { private final long[] hashes = BloomFilter.createHashArray(); private final long numElements; private final int numHashes; private final long numBits; private final int numPages; private final IFIFOPageQueue queue; private final ICachedPage[] pages; private ICachedPage metaDataPage = null; <|startfocus|> public BloomFilterBuilder(long numElements, int numHashes, int numBitsPerElement) throws HyracksDataException { <|endfocus|> if (!isActivated) { throw HyracksDataException.create(ErrorCode.CANNOT_CREATE_BLOOM_FILTER_BUILDER_FOR_INACTIVE_FILTER); } queue = bufferCache.createFIFOQueue(); this.numElements = numElements; this.numHashes = numHashes; numBits = this.numElements * numBitsPerElement; long tmp = (long) Math.ceil(numBits / (double) numBitsPerPage); if (tmp > Integer.MAX_VALUE) { throw HyracksDataException.create(ErrorCode.CANNOT_CREATE_BLOOM_FILTER_WITH_NUMBER_OF_PAGES, tmp); } numPages = (int) tmp; pages = new ICachedPage[numPages];
<|startcomment|> long line <|endcomment|> import org.apache.hyracks.tests.util.NoOpOperatorDescriptor; import org.junit.Assert; import org.junit.Test; public class JobFailureTest extends AbstractMultiNCIntegrationTest { @Test public void failureOnCreatePushRuntime() throws Exception { JobId jobId = null; for (int i = 0; i < 20; i++) { JobSpecification spec = new JobSpecification(); <|startfocus|> JobId runJobId = runTest(spec, new ExceptionOnCreatePushRuntimeOperatorDescriptor(spec, 0, 1, new int[]{4}, true)); <|endfocus|> if (i == 0) { jobId = runJobId; // passes. read from job archive waitForCompletion(jobId, ExceptionOnCreatePushRuntimeOperatorDescriptor.ERROR_MESSAGE); } } // passes. read from job history waitForCompletion(jobId, ExceptionOnCreatePushRuntimeOperatorDescriptor.ERROR_MESSAGE); for (int i = 0; i < 300; i++) { JobSpecification spec = new JobSpecification(); runTest(spec, new ExceptionOnCreatePushRuntimeOperatorDescriptor(spec, 0, 1, new int[] { 4 }, true)); } // passes. history has been cleared
<|startcomment|> Do we need this? <|endcomment|>  * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.api.http.server; import java.util.Map; import java.util.UUID; import java.util.concurrent.ConcurrentMap; import java.util.concurrent.TimeUnit; import java.util.concurrent.TimeoutException; import java.util.function.Function; <|startfocus|> import javax.xml.transform.Result; <|endfocus|> import org.apache.asterix.algebra.base.ILangExtension; import org.apache.asterix.app.message.CancelQueryRequest; import org.apache.asterix.app.message.ExecuteStatementRequestMessage; import org.apache.asterix.app.message.ExecuteStatementResponseMessage; import org.apache.asterix.app.result.ResultReader; import org.apache.asterix.common.api.Duration; import org.apache.asterix.common.api.IApplicationContext; import org.apache.asterix.common.config.GlobalConfig; import org.apache.asterix.common.exceptions.ErrorCode; import org.apache.asterix.common.exceptions.ExceptionUtils; import org.apache.asterix.common.exceptions.RuntimeDataException; import org.apache.asterix.common.messaging.api.INCMessageBroker;
<|startcomment|> Should this/does this fail the request? <|endcomment|>  channel.abort(); } finally { channel.close(); resultState.readClose(); // if resultState has been exhausted, delete the result partition if (resultState.isExhausted()) { datasetPartitionManager.removePartition(resultState.getResultSetPartitionId().getJobId(), resultState.getResultSetPartitionId().getResultSetId(), resultState.getResultSetPartitionId().getPartition()); } } } catch (HyracksDataException e) { LOGGER.error("unexpected failure in partition reader", e); } <|startfocus|> if (LOGGER.isInfoEnabled()) { LOGGER.info("result reading successful(" + resultState.getResultSetPartitionId() + ")"); <|endfocus|> }
<|startcomment|> fixme <|endcomment|>  * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.translator; import java.util.Map; import org.apache.asterix.translator.IStatementExecutor.Stats; import org.apache.hyracks.api.dataset.IHyracksDataset; public interface IRequestParameters { /** * @return A Hyracks dataset client object that is used to read the results. */ IHyracksDataset getHyracksDataset(); /** <|startfocus|> * @return The {@code ResultDelivery} kind required for queries in the list of statements <|endfocus|> */ ResultProperties getResultProperties(); /** * @return a reference to write the stats of executed queries */ Stats getStats(); /** * @return a reference to write the metadata of executed queries */ IStatementExecutor.ResultMetadata getOutMetadata(); /** * @return the client context id for the query */ String getClientContextId(); /** * @return Optional request parameters. Otherwise null. */ Map<String, String> getOptionalParameters(); } 
<|startcomment|> To be more clear, I think this should be "current component's filter"? <|endcomment|>  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.am.common.api; import org.apache.hyracks.dataflow.common.data.accessors.ITupleReference; import org.apache.hyracks.storage.common.IIndexCursor; public interface ILSMIndexCursor extends IIndexCursor { /** <|startfocus|> * @return the min tuple of the current index's filter <|endfocus|> */ ITupleReference getFilterMinTuple(); /** * * @return the max tuple of the current index's filter */ ITupleReference getFilterMaxTuple(); } 
<|startcomment|> MAJOR SonarQube violation: '{' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  * * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.am.common.api; import org.apache.hyracks.dataflow.common.data.accessors.ITupleReference; import org.apache.hyracks.storage.common.IIndexCursor; <|startfocus|> public interface ILSMIndexCursor extends IIndexCursor{ <|endfocus|> /** * @return the min tuple of the current index's filter */ ITupleReference getFilterMinTuple(); /** * * @return the max tuple of the current index's filter */ ITupleReference getFilterMaxTuple(); } 
<|startcomment|> Since we here anyways, can you change that to refernce OperatorPropertiesUtil.MOVABLE instead? <|endcomment|>  AbstractLogicalOperator op2 = (AbstractLogicalOperator) opRef2.getValue(); // If it's not an indexed field, it is pushed so that scan can be // rewritten into index search. if (op2.getOperatorTag() == LogicalOperatorTag.PROJECT || context.checkAndAddToAlreadyCompared(access, op2) && !(op2.getOperatorTag() == LogicalOperatorTag.SELECT && isAccessToIndexedField(access, context))) { return false; } <|startfocus|> Object annotation = op2.getAnnotations().get(IS_MOVABLE); <|endfocus|> if (annotation != null && !((Boolean) annotation)) { return false; } if (tryingToPushThroughSelectionWithSameDataSource(access, op2)) { return false; } if (testAndModifyRedundantOp(access, op2)) { propagateFieldAccessRec(opRef2, context, finalAnnot); return true; } List<LogicalVariable> usedInAccess = new LinkedList<>(); VariableUtilities.getUsedVariables(access, usedInAccess); List<LogicalVariable> produced2 = new LinkedList<>(); if (op2.getOperatorTag() == LogicalOperatorTag.GROUP) { VariableUtilities.getLiveVariables(op2, produced2);
<|startcomment|> MAJOR SonarQube violation: Add the "@Override" annotation above this method signature Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1161 <|endcomment|>  import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalOperator; import org.apache.hyracks.algebricks.core.algebra.base.LogicalVariable; import org.apache.hyracks.algebricks.core.algebra.properties.VariablePropagationPolicy; import org.apache.hyracks.algebricks.core.algebra.visitors.ILogicalExpressionReferenceTransform; public abstract class AbstractBinaryJoinOperator extends AbstractLogicalOperator { protected final Mutable<ILogicalExpression> condition; protected JoinKind joinKind; <|startfocus|> public Map<Integer, Integer> getPhaseToInput() { return phaseToInput; } protected Map<Integer,Integer> phaseToInput; <|endfocus|> public enum JoinKind { INNER, LEFT_OUTER } public AbstractBinaryJoinOperator(JoinKind joinKind, Mutable<ILogicalExpression> condition) { this.joinKind = joinKind; this.condition = condition; this.phaseToInput = new HashMap<>(); phaseToInput.put(0,1); phaseToInput.put(1,0); } public AbstractBinaryJoinOperator(JoinKind joinKind, Mutable<ILogicalExpression> condition, Mutable<ILogicalOperator> input1, Mutable<ILogicalOperator> input2) { this(joinKind, condition);
<|startcomment|> MAJOR SonarQube violation: "phaseToInput" is the name of a field in "AbstractLogicalOperator". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2387 <|endcomment|> import org.apache.hyracks.algebricks.core.algebra.base.ILogicalExpression; import org.apache.hyracks.algebricks.core.algebra.base.ILogicalOperator; import org.apache.hyracks.algebricks.core.algebra.base.LogicalVariable; import org.apache.hyracks.algebricks.core.algebra.properties.VariablePropagationPolicy; import org.apache.hyracks.algebricks.core.algebra.visitors.ILogicalExpressionReferenceTransform; public abstract class AbstractBinaryJoinOperator extends AbstractLogicalOperator { protected final Mutable<ILogicalExpression> condition; protected JoinKind joinKind; <|startfocus|> public Map<Integer, Integer> getPhaseToInput() { return phaseToInput; } protected Map<Integer,Integer> phaseToInput; <|endfocus|> public enum JoinKind { INNER, LEFT_OUTER } public AbstractBinaryJoinOperator(JoinKind joinKind, Mutable<ILogicalExpression> condition) { this.joinKind = joinKind; this.condition = condition; this.phaseToInput = new HashMap<>(); phaseToInput.put(0,1); phaseToInput.put(1,0); } public AbstractBinaryJoinOperator(JoinKind joinKind, Mutable<ILogicalExpression> condition, Mutable<ILogicalOperator> input1, Mutable<ILogicalOperator> input2) { this(joinKind, condition); inputs.add(input1); inputs.add(input2); } 
<|startcomment|> MAJOR SonarQube violation: 'if' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  if (connection != null) { inp.put("input", connection.getLeft().getLeft().getOperatorId().toString()); } } } if (pleObject.size() > 0) { pcObject.set("location", pleObject); } if (pcObject.size() > 0) { op.set("partition-constraints", pcObject); } <|startfocus|> if(inp.size() > 0) { op.set("inputs", inp); } <|endfocus|> } jopArray.add(op); }); jjob.set("operators", jopArray); ArrayNode jcArray = om.createArrayNode(); connMap.forEach((key, value) -> { ObjectNode conn = om.createObjectNode(); Pair<Pair<IOperatorDescriptor, Integer>, Pair<IOperatorDescriptor, Integer>> connection = connectorOpMap.get(key); if (connection != null) { conn.put("in-operator-id", connection.getLeft().getLeft().getOperatorId().toString()); conn.put("in-operator-port", connection.getLeft().getRight().intValue());
<|startcomment|> should we handle both InterruptedException & ClosedByInterruptException here? <|endcomment|>  } } return false; } /** * Executes the passed interruptible, retrying if the operation fails due to {@link ClosedByInterruptException}. * Once the interruptible completes, the current thread will be re-interrupted, if the original operation was * interrupted. */ public static void doIoUninterruptibly(ThrowingIOInterruptible interruptible) throws IOException { boolean interrupted = false; try { while (true) { try { interruptible.run(); break; <|startfocus|> } catch (ClosedByInterruptException e) { <|endfocus|> LOGGER.error("IO operation Interrupted. Retrying..", e); interrupted = true; Thread.interrupted(); } } } finally { if (interrupted) { Thread.currentThread().interrupt(); } } } @FunctionalInterface public interface Interruptible { void run() throws InterruptedException; } @FunctionalInterface public interface ThrowingInterruptible { void run() throws Exception; // NOSONAR } @FunctionalInterface public interface ThrowingIOInterruptible { void run() throws IOException; } } 
<|startcomment|> if you extend per comment on line 163, += InterruptedException here <|endcomment|>  } catch (ClosedByInterruptException e) { LOGGER.error("IO operation Interrupted. Retrying..", e); interrupted = true; Thread.interrupted(); } } } finally { if (interrupted) { Thread.currentThread().interrupt(); } } } @FunctionalInterface public interface Interruptible { void run() throws InterruptedException; } @FunctionalInterface public interface ThrowingInterruptible { void run() throws Exception; // NOSONAR } @FunctionalInterface public interface ThrowingIOInterruptible { <|startfocus|> void run() throws IOException; <|endfocus|> } } 
<|startcomment|> MAJOR SonarQube violation: Remove this unused "latestCheckpoint" local variable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1481 <|endcomment|>  if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("Substitute node joining : " + serviceContext.getNodeId()); } updateOnNodeJoin(); } appContext.initialize(initialRun); MessagingProperties messagingProperties = ((IPropertiesProvider) appContext).getMessagingProperties(); messageBroker = new NCMessageBroker(controllerService, messagingProperties); serviceContext.setMessageBroker(messageBroker); MessagingChannelInterfaceFactory interfaceFactory = new MessagingChannelInterfaceFactory((NCMessageBroker) messageBroker, messagingProperties); <|startfocus|> serviceContext.setMessagingChannelInterfaceFactory(interfaceFactory); <|endfocus|> boolean replicationEnabled = ClusterProperties.INSTANCE.isReplicationEnabled(); boolean autoFailover = ClusterProperties.INSTANCE.isAutoFailoverEnabled(); if (initialRun) { LOGGER.info("System is being initialized. (first run)"); } else { IRecoveryManager recoveryMgr = appContext.getTransactionSubsystem().getRecoveryManager(); systemState = recoveryMgr.getSystemState(); if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("System is in a state: " + systemState); } //do not attempt to perform remote recovery if this is a virtual NC if (autoFailover && !virtualNC) {
<|startcomment|> MAJOR SonarQube violation: Remove this useless assignment to local variable "latestCheckpoint". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1854 <|endcomment|>  if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("Substitute node joining : " + serviceContext.getNodeId()); } updateOnNodeJoin(); } appContext.initialize(initialRun); MessagingProperties messagingProperties = ((IPropertiesProvider) appContext).getMessagingProperties(); messageBroker = new NCMessageBroker(controllerService, messagingProperties); serviceContext.setMessageBroker(messageBroker); MessagingChannelInterfaceFactory interfaceFactory = new MessagingChannelInterfaceFactory((NCMessageBroker) messageBroker, messagingProperties); <|startfocus|> serviceContext.setMessagingChannelInterfaceFactory(interfaceFactory); <|endfocus|> boolean replicationEnabled = ClusterProperties.INSTANCE.isReplicationEnabled(); boolean autoFailover = ClusterProperties.INSTANCE.isAutoFailoverEnabled(); if (initialRun) { LOGGER.info("System is being initialized. (first run)"); } else { IRecoveryManager recoveryMgr = appContext.getTransactionSubsystem().getRecoveryManager(); systemState = recoveryMgr.getSystemState(); if (LOGGER.isLoggable(Level.INFO)) { LOGGER.info("System is in a state: " + systemState); } //do not attempt to perform remote recovery if this is a virtual NC if (autoFailover && !virtualNC) {
<|startcomment|> Just remove "Asterix" here (it's part of Algebricks anyway ...). <|endcomment|>  int n = subplans.size(); AlgebricksPipeline[] result = new AlgebricksPipeline[n]; for (int i = 0; i < n; i++) { List<AlgebricksPipeline> subplanOps = subplans.get(i); if (subplanOps.size() != 1) { throw new AlgebricksException("Attempting to construct a nested plan with " + subplanOps.size() + " operator descriptors. Currently, nested plans can only consist in linear pipelines of " <|startfocus|> + "Asterix micro operators."); <|endfocus|> } result[i] = subplanOps.get(0); } return result; } protected List<List<AlgebricksPipeline>> compileSubplansImpl(IOperatorSchema outerPlanSchema, AbstractOperatorWithNestedPlans npOp, IOperatorSchema opSchema, JobGenContext context) throws AlgebricksException { List<List<AlgebricksPipeline>> subplans = new ArrayList<>(npOp.getNestedPlans().size()); PlanCompiler pc = new PlanCompiler(context); for (ILogicalPlan p : npOp.getNestedPlans()) { subplans.add(buildPipelineWithProjection(p, outerPlanSchema, npOp, opSchema, pc)); } return subplans; } 
<|startcomment|> Remove "Asterix" (and Hyracks)? <|endcomment|>  opSchema.addAllVariables(topOpInSubplanScm); Map<OperatorDescriptorId, IOperatorDescriptor> opMap = nestedJob.getOperatorMap(); List<? extends IOperatorDescriptor> metaOps = nestedJob.getMetaOps(); if (opMap.size() != metaOps.size()) { for (IOperatorDescriptor opd : opMap.values()) { if (!(opd instanceof AlgebricksMetaOperatorDescriptor)) { throw new AlgebricksException( <|startfocus|> "Can only generate Hyracks jobs for pipelinable Asterix nested plans, not for " + opd <|endfocus|> .getClass().getName()); } } throw new IllegalStateException(); } List<AlgebricksPipeline> result = new ArrayList<>(metaOps.size()); for (IOperatorDescriptor opd : metaOps) { AlgebricksMetaOperatorDescriptor amod = (AlgebricksMetaOperatorDescriptor) opd; result.add(amod.getPipeline()); } return result; } } 
<|startcomment|> It seems that there is no way to leave this branch alive. Do the earlier checks help to identify errors? Should we add a message to this exception? <|endcomment|>  Map<OperatorDescriptorId, IOperatorDescriptor> opMap = nestedJob.getOperatorMap(); List<? extends IOperatorDescriptor> metaOps = nestedJob.getMetaOps(); if (opMap.size() != metaOps.size()) { for (IOperatorDescriptor opd : opMap.values()) { if (!(opd instanceof AlgebricksMetaOperatorDescriptor)) { throw new AlgebricksException( "Can only generate Hyracks jobs for pipelinable Asterix nested plans, not for " + opd .getClass().getName()); } } <|startfocus|> throw new IllegalStateException(); <|endfocus|> } List<AlgebricksPipeline> result = new ArrayList<>(metaOps.size()); for (IOperatorDescriptor opd : metaOps) { AlgebricksMetaOperatorDescriptor amod = (AlgebricksMetaOperatorDescriptor) opd; result.add(amod.getPipeline()); } return result; } } 
<|startcomment|> Can everything except for these lines be pulled up into AbstractUnionAllPOperator as well? <|endcomment|>  return true; } @Override public void contributeRuntimeOperator(IHyracksJobBuilder builder, JobGenContext context, ILogicalOperator op, IOperatorSchema opSchema, IOperatorSchema[] inputSchemas, IOperatorSchema outerPlanSchema) throws AlgebricksException { RecordDescriptor recordDescriptor = JobGenHelper.mkRecordDescriptor(context.getTypeEnvironment(op), opSchema, context); List<Mutable<ILogicalOperator>> inputs = op.getInputs(); int nInputs = inputs.size(); MicroUnionAllRuntimeFactory runtime = new MicroUnionAllRuntimeFactory(nInputs); builder.contributeMicroOperator(op, runtime, recordDescriptor); <|startfocus|> for (int i = 0; i < nInputs; i++) { ILogicalOperator src = inputs.get(i).getValue(); builder.contributeGraphEdge(src, 0, op, i); } <|endfocus|> } } 
<|startcomment|> Add a message? <|endcomment|>  RecordDescriptor pipelineLastRecordDescriptor = pipeline.getRecordDescriptors()[pipeline.getRecordDescriptors().length - 1]; RecordDescriptor outputRecordDescriptor; IFrameWriter outputWriter; if (i == 0) { // primary pipeline outputWriter = new TupleOuterProduct(pipelineLastRecordDescriptor, missingWriters); outputRecordDescriptor = SubplanRuntimeFactory.this.outputRecordDesc; } else { // secondary pipeline IPushRuntime outputPushRuntime = linkSecondaryPipeline(pipeline, pipelineAssemblers, i); if (outputPushRuntime == null) { <|startfocus|> throw new IllegalStateException(); <|endfocus|> } outputPushRuntime.setInputRecordDescriptor(0, pipelineLastRecordDescriptor); outputWriter = outputPushRuntime; outputRecordDescriptor = pipelineLastRecordDescriptor; } PipelineAssembler pa = new PipelineAssembler(pipeline, 1, 1, inputRecordDesc, outputRecordDescriptor); startOfPipelines[i] = (NestedTupleSourceRuntime) pa.assemblePipeline(outputWriter, ctx); pipelineAssemblers[i] = pa; } } IPushRuntime linkSecondaryPipeline(AlgebricksPipeline pipeline, PipelineAssembler[] pipelineAssemblers, int pipelineAssemblersCount) { IPushRuntimeFactory[] outputRuntimeFactories = pipeline.getOutputRuntimeFactories();
<|startcomment|> MAJOR SonarQube violation: '=' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} <|startfocus|> if(n>0xff){n>>>=8;log|=8;} <|endfocus|> if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '=' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} <|startfocus|> if(n>0xff){n>>>=8;log|=8;} <|endfocus|> if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} <|startfocus|> if(n>0xff){n>>>=8;log|=8;} <|endfocus|> if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} <|startfocus|> if(n>0xff){n>>>=8;log|=8;} <|endfocus|> if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>=' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} <|startfocus|> if(n>0xff){n>>>=8;log|=8;} <|endfocus|> if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>=' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} <|startfocus|> if(n>0xff){n>>>=8;log|=8;} <|endfocus|> if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>>>=' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} <|startfocus|> if(n>0xff){n>>>=8;log|=8;} <|endfocus|> if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>>>=' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} <|startfocus|> if(n>0xff){n>>>=8;log|=8;} <|endfocus|> if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: 'if' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} <|startfocus|> if(n>0xff){n>>>=8;log|=8;} <|endfocus|> if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: 'if' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} <|startfocus|> if(n>0xff){n>>>=8;log|=8;} <|endfocus|> if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '{' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} <|startfocus|> if(n>0xff){n>>>=8;log|=8;} <|endfocus|> if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '{' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} <|startfocus|> if(n>0xff){n>>>=8;log|=8;} <|endfocus|> if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '}' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} <|startfocus|> if(n>0xff){n>>>=8;log|=8;} <|endfocus|> if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "n". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} <|startfocus|> if(n>0xff){n>>>=8;log|=8;} <|endfocus|> if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} <|startfocus|> if(n>0xf){n>>>=4;log|=4;} <|endfocus|> if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} <|startfocus|> if(n>0xf){n>>>=4;log|=4;} <|endfocus|> if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>>>=' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} <|startfocus|> if(n>0xf){n>>>=4;log|=4;} <|endfocus|> if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>>>=' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} <|startfocus|> if(n>0xf){n>>>=4;log|=4;} <|endfocus|> if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: 'if' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} <|startfocus|> if(n>0xf){n>>>=4;log|=4;} <|endfocus|> if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '{' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} <|startfocus|> if(n>0xf){n>>>=4;log|=4;} <|endfocus|> if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '{' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} <|startfocus|> if(n>0xf){n>>>=4;log|=4;} <|endfocus|> if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '|=' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} <|startfocus|> if(n>0xf){n>>>=4;log|=4;} <|endfocus|> if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '|=' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} <|startfocus|> if(n>0xf){n>>>=4;log|=4;} <|endfocus|> if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '}' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} <|startfocus|> if(n>0xf){n>>>=4;log|=4;} <|endfocus|> if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "n". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} <|startfocus|> if(n>0xf){n>>>=4;log|=4;} <|endfocus|> if(n>0b11){n>>>=2;log|=2;} return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} <|startfocus|> if(n>0b11){n>>>=2;log|=2;} <|endfocus|> return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} <|startfocus|> if(n>0b11){n>>>=2;log|=2;} <|endfocus|> return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>>>=' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} <|startfocus|> if(n>0b11){n>>>=2;log|=2;} <|endfocus|> return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>>>=' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} <|startfocus|> if(n>0b11){n>>>=2;log|=2;} <|endfocus|> return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: 'if' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} <|startfocus|> if(n>0b11){n>>>=2;log|=2;} <|endfocus|> return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '{' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} <|startfocus|> if(n>0b11){n>>>=2;log|=2;} <|endfocus|> return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '{' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} <|startfocus|> if(n>0b11){n>>>=2;log|=2;} <|endfocus|> return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '|=' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} <|startfocus|> if(n>0b11){n>>>=2;log|=2;} <|endfocus|> return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '|=' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} <|startfocus|> if(n>0b11){n>>>=2;log|=2;} <|endfocus|> return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '}' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} <|startfocus|> if(n>0b11){n>>>=2;log|=2;} <|endfocus|> return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "n". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} <|startfocus|> if(n>0b11){n>>>=2;log|=2;} <|endfocus|> return log+(n>>>1);
<|startcomment|> MAJOR SonarQube violation: '>' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: '>' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: '>>>=' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: '>>>=' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: 'if' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: '{' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: '{' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: '|=' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: '|=' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: '}' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "n". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: '+' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: '+' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: '>>>' is not followed by whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: '>>>' is not preceded with whitespace. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3AWhitespace_Around <|endcomment|>  public static int log2Floor(int n) { assert n>=1;int log=0;if(n>0xffff){n>>>=16;log=16;} if(n>0xff){n>>>=8;log|=8;} if(n>0xf){n>>>=4;log|=4;} if(n>0b11){n>>>=2;log|=2;} <|startfocus|> return log+(n>>>1); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  public Ini toIni(boolean includeDefaults) { Ini ini = new Ini(); (includeDefaults ? configurationMap : definedMap).forEach((option, value) -> { if (value != null) { ini.add(option.section().sectionName(), option.ini(), option.type().serializeToIni(value)); } }); <|startfocus|> getSections().forEach((section -> { ini.add(section.sectionName()); })); <|endfocus|> nodeSpecificMap.forEach((key, nodeValueMap) -> { String section = Section.NC.sectionName() + "/" + key; synchronized (nodeValueMap) { for (Map.Entry<IOption, Object> entry : nodeValueMap.entrySet()) { if (entry.getValue() != null) { final IOption option = entry.getKey(); ini.add(section, option.ini(), option.type().serializeToIni(entry.getValue())); } } } }); extensionOptions.forEach((extension, options) -> { options.forEach(option -> ini .add(extension, option.getKey(), option.getValue())); }); return ini;
<|startcomment|> CRITICAL SonarQube violation: Define and throw a dedicated exception instead of using a generic one. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00112 <|endcomment|>  public void sendApplicationMessageToCC(byte[] data, DeploymentId deploymentId, String nodeId) throws Exception; public void registerResultPartitionLocation(JobId jobId, ResultSetId rsId, boolean orderedResult, boolean emptyResult, int partition, int nPartitions, NetworkAddress networkAddress) throws Exception; public void reportResultPartitionWriteCompletion(JobId jobId, ResultSetId rsId, int partition) throws Exception; public void reportResultPartitionFailure(JobId jobId, ResultSetId rsId, int partition, HyracksDataException cause) throws Exception; public void getNodeControllerInfos() throws Exception; <|startfocus|> public void notifyThreadDump(String nodeId, String requestId, String threadDumpJSON) throws Exception; <|endfocus|> } 
<|startcomment|> CRITICAL SonarQube violation: Define and throw a dedicated exception instead of using a generic one. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00112 <|endcomment|>  List<TaskAttemptDescriptor> taskDescriptors, Map<ConnectorDescriptorId, IConnectorPolicy> connectorPolicies, Set<JobFlag> flags, Map<String, byte[]> contextRuntTimeVarMap) throws Exception; public void abortTasks(JobId jobId, List<TaskAttemptId> tasks) throws Exception; public void cleanUpJoblet(JobId jobId, JobStatus status) throws Exception; public void reportPartitionAvailability(PartitionId pid, NetworkAddress networkAddress) throws Exception; public void deployBinary(DeploymentId deploymentId, List<URL> url) throws Exception; public void undeployBinary(DeploymentId deploymentId) throws Exception; <|startfocus|> public void distributeJob(JobId jobId, byte[] planBytes) throws Exception; public void destroyJob(JobId jobId) throws Exception; <|endfocus|> public void dumpState(String stateDumpId) throws Exception; public void shutdown(boolean terminateNCService) throws Exception; public void sendApplicationMessageToNC(byte[] data, DeploymentId deploymentId, String nodeId) throws Exception; public void takeThreadDump(String requestId) throws Exception; } 
<|startcomment|> BLOCKER SonarQube violation: Catch Exception instead of Throwable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1181 <|endcomment|>  throws HyracksDataException { this.ctx = ctx; this.treeIndexHelper = indexHelperFactory.create(ctx.getJobletContext().getServiceContext(), partition); this.searchCallbackFactory = searchCallbackFactory; } @Override public void initialize() throws HyracksDataException { treeIndexHelper.open(); try { try { writer.open(); FrameTupleAppender appender = new FrameTupleAppender(new VSizeFrame(ctx)); scan(appender); appender.write(writer, true); } catch (Throwable th) { writer.fail(); <|startfocus|> throw HyracksDataException.create(th); } finally { <|endfocus|> writer.close(); } } catch (Throwable th) { throw HyracksDataException.create(th); } } private void scan(FrameTupleAppender appender) throws IOException { ITreeIndex treeIndex = (ITreeIndex) treeIndexHelper.getIndexInstance(); LocalResource resource = treeIndexHelper.getResource(); ISearchOperationCallback searchCallback = searchCallbackFactory.createSearchOperationCallback(resource.getId(), ctx, null); IIndexAccessParameters iap = new IndexAccessParameters(NoOpOperationCallback.INSTANCE, searchCallback); ITreeIndexAccessor indexAccessor = (ITreeIndexAccessor) treeIndex.createAccessor(iap); try {
<|startcomment|> BLOCKER SonarQube violation: Catch Exception instead of Throwable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1181 <|endcomment|>  this.searchCallbackFactory = searchCallbackFactory; } @Override public void initialize() throws HyracksDataException { treeIndexHelper.open(); try { try { writer.open(); FrameTupleAppender appender = new FrameTupleAppender(new VSizeFrame(ctx)); scan(appender); appender.write(writer, true); } catch (Throwable th) { writer.fail(); throw HyracksDataException.create(th); } finally { writer.close(); } <|startfocus|> } catch (Throwable th) { throw HyracksDataException.create(th); <|endfocus|> } } private void scan(FrameTupleAppender appender) throws IOException { ITreeIndex treeIndex = (ITreeIndex) treeIndexHelper.getIndexInstance(); LocalResource resource = treeIndexHelper.getResource(); ISearchOperationCallback searchCallback = searchCallbackFactory.createSearchOperationCallback(resource.getId(), ctx, null); IIndexAccessParameters iap = new IndexAccessParameters(NoOpOperationCallback.INSTANCE, searchCallback); ITreeIndexAccessor indexAccessor = (ITreeIndexAccessor) treeIndex.createAccessor(iap); try { doScan(treeIndex, indexAccessor, appender); } finally { indexAccessor.destroy(); } } 
<|startcomment|> MAJOR SonarQube violation: Refactor this code to not nest more than 4 if/for/while/switch/try statements. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS134 <|endcomment|>  for (int i = 0; i < mergeOp.getMergingComponents().size(); ++i) { filterTuples.add(mergeOp.getMergingComponents().get(i).getLSMComponentFilter().getMinTuple()); filterTuples.add(mergeOp.getMergingComponents().get(i).getLSMComponentFilter().getMaxTuple()); } getFilterManager().updateFilter(mergedComponent.getLSMComponentFilter(), filterTuples); getFilterManager().writeFilter(mergedComponent.getLSMComponentFilter(), mergedComponent.getMetadataHolder()); } componentBulkLoader.end(); return mergedComponent; } @Override public ILSMIndexAccessor createAccessor(IIndexAccessParameters iap) { <|startfocus|> return new LSMRTreeAccessor(getLsmHarness(), <|endfocus|> createOpContext(iap.getModificationCallback(), iap.getSearchOperationCallback()), buddyBTreeFields); } // This function is modified for R-Trees without antimatter tuples to allow buddy B-Tree to have only primary keys @Override public void modify(IIndexOperationContext ictx, ITupleReference tuple) throws HyracksDataException { LSMRTreeOpContext ctx = (LSMRTreeOpContext) ictx; if (ctx.getOperation() == IndexOperation.PHYSICALDELETE) {
<|startcomment|> BLOCKER SonarQube violation: Remove this throw statement from this finally block. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1143 <|endcomment|>  public void resetNonIndexFieldsTuple(ITupleReference newValue) { tupleWithNonIndexFields.reset(newValue); } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; HyracksDataException failure = null; try { accessor.destroy(); } catch (HyracksDataException e) { failure = e; } finally { try { if (cursor != null) { cursor.destroy(); } } catch (Exception e) { throw HyracksDataException.suppress(failure, e); } <|startfocus|> } <|endfocus|> } } 
<|startcomment|> CRITICAL SonarQube violation: Refactor this code to not throw exceptions in finally blocks. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1163 <|endcomment|>  public void resetNonIndexFieldsTuple(ITupleReference newValue) { tupleWithNonIndexFields.reset(newValue); } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; HyracksDataException failure = null; try { accessor.destroy(); } catch (HyracksDataException e) { failure = e; } finally { try { if (cursor != null) { cursor.destroy(); } } catch (Exception e) { throw HyracksDataException.suppress(failure, e); } <|startfocus|> } <|endfocus|> } } 
<|startcomment|> BLOCKER SonarQube violation: Catch Exception instead of Throwable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1181 <|endcomment|>  builder.addField(diskTuple.getFieldData(i), diskTuple.getFieldStart(i), diskTuple.getFieldLength(i)); } } @Override public ITupleReference doGetTuple() { return outputTuple; } @Override public void doDestroy() throws HyracksDataException { Throwable failure = null; if (lsmHarness != null) { if (rangeCursors != null) { for (int i = 0; i < rangeCursors.length; i++) { try { rangeCursors[i].destroy(); <|startfocus|> } catch (Throwable th) { <|endfocus|> failure = ExceptionUtils.suppress(failure, th); } } rangeCursors = null; } try { lsmHarness.endScanDiskComponents(opCtx); } catch (Throwable th) { failure = ExceptionUtils.suppress(failure, th); } } foundNext = false; if (failure != null) { throw HyracksDataException.create(failure); } } @Override protected void setPriorityQueueComparator() { if (pqCmp == null || cmp != pqCmp.getMultiComparator()) { pqCmp = new PriorityQueueScanComparator(cmp); } } 
<|startcomment|> BLOCKER SonarQube violation: Catch Exception instead of Throwable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1181 <|endcomment|>  } @Override public void doDestroy() throws HyracksDataException { Throwable failure = null; if (lsmHarness != null) { if (rangeCursors != null) { for (int i = 0; i < rangeCursors.length; i++) { try { rangeCursors[i].destroy(); } catch (Throwable th) { failure = ExceptionUtils.suppress(failure, th); } } rangeCursors = null; } try { lsmHarness.endScanDiskComponents(opCtx); <|startfocus|> } catch (Throwable th) { <|endfocus|> failure = ExceptionUtils.suppress(failure, th); } } foundNext = false; if (failure != null) { throw HyracksDataException.create(failure); } } @Override protected void setPriorityQueueComparator() { if (pqCmp == null || cmp != pqCmp.getMultiComparator()) { pqCmp = new PriorityQueueScanComparator(cmp); } } private class PriorityQueueScanComparator extends PriorityQueueComparator { public PriorityQueueScanComparator(MultiComparator cmp) { super(cmp); } @Override
<|startcomment|> MAJOR SonarQube violation: Add a private constructor to hide the implicit public one. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1118 <|endcomment|>  * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.am.lsm.common.util; import org.apache.hyracks.storage.am.common.api.IIndexOperationContext; import org.apache.hyracks.storage.common.IIndexAccessor; import org.apache.hyracks.storage.common.IIndexCursor; public class DestroyUtils { <|startfocus|> <|endfocus|> public static <T extends IIndexOperationContext> Throwable destroy(T[] contexts) { Throwable failure = null; for (int i = 0; i < contexts.length; i++) { if (contexts[i] != null) { try { contexts[i].destroy(); } catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } public static <T extends IIndexAccessor> Throwable destroy(T[] accessors) { Throwable failure = null;
<|startcomment|> BLOCKER SonarQube violation: Catch Exception instead of Throwable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1181 <|endcomment|> package org.apache.hyracks.storage.am.lsm.common.util; import org.apache.hyracks.storage.am.common.api.IIndexOperationContext; import org.apache.hyracks.storage.common.IIndexAccessor; import org.apache.hyracks.storage.common.IIndexCursor; public class DestroyUtils { public static <T extends IIndexOperationContext> Throwable destroy(T[] contexts) { Throwable failure = null; for (int i = 0; i < contexts.length; i++) { if (contexts[i] != null) { try { contexts[i].destroy(); <|startfocus|> } catch (Throwable th) { <|endfocus|> if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } public static <T extends IIndexAccessor> Throwable destroy(T[] accessors) { Throwable failure = null; for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { try { accessors[i].destroy(); } catch (Throwable th) { if (failure == null) { failure = th;
<|startcomment|> BLOCKER SonarQube violation: Catch Exception instead of Throwable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1181 <|endcomment|>  } catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } public static <T extends IIndexAccessor> Throwable destroy(T[] accessors) { Throwable failure = null; for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { try { accessors[i].destroy(); <|startfocus|> } catch (Throwable th) { <|endfocus|> if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } public static <T extends IIndexCursor> Throwable destroy(T[] cursors) { Throwable failure = null; for (int i = 0; i < cursors.length; i++) { if (cursors[i] != null) { try { cursors[i].destroy(); } catch (Throwable th) { if (failure == null) { failure = th; } else {
<|startcomment|> BLOCKER SonarQube violation: Catch Exception instead of Throwable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1181 <|endcomment|>  } catch (Throwable th) { if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } public static <T extends IIndexCursor> Throwable destroy(T[] cursors) { Throwable failure = null; for (int i = 0; i < cursors.length; i++) { if (cursors[i] != null) { try { cursors[i].destroy(); <|startfocus|> } catch (Throwable th) { <|endfocus|> if (failure == null) { failure = th; } else { failure.addSuppressed(th); } } } } return failure; } } 
<|startcomment|> MAJOR SonarQube violation: Split this 130 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  boolean abort = true; try { try { ISearchPredicate rtreeSearchPred = new SearchPredicate(null, null); ILSMIndexOperationContext opCtx = ((LSMRTreeSortedCursor) cursor).getOpCtx(); search(opCtx, cursor, rtreeSearchPred); try { mergedComponent = createDiskComponent(componentFactory, mergeOp.getTarget(), mergeOp.getBTreeTarget(), mergeOp.getBloomFilterTarget(), true); <|startfocus|> // In case we must keep the deleted-keys BTrees, then they must be merged *before* merging the r-trees so that <|endfocus|> // lsmHarness.endSearch() is called once when the r-trees have been merged. if (mergeOp.getMergingComponents().get(mergeOp.getMergingComponents().size() - 1) != diskComponents .get(diskComponents.size() - 1)) { // Keep the deleted tuples since the oldest disk component is not included in the merge operation long numElements = 0L; for (int i = 0; i < mergeOp.getMergingComponents().size(); ++i) { numElements += ((LSMRTreeDiskComponent) mergeOp.getMergingComponents().get(i))
<|startcomment|> MAJOR SonarQube violation: Split this 121 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  // In case we must keep the deleted-keys BTrees, then they must be merged *before* merging the r-trees so that // lsmHarness.endSearch() is called once when the r-trees have been merged. if (mergeOp.getMergingComponents().get(mergeOp.getMergingComponents().size() - 1) != diskComponents .get(diskComponents.size() - 1)) { <|startfocus|> // Keep the deleted tuples since the oldest disk component is not included in the merge operation <|endfocus|> long numElements = 0L; for (int i = 0; i < mergeOp.getMergingComponents().size(); ++i) { numElements += ((LSMRTreeDiskComponent) mergeOp.getMergingComponents().get(i)) .getBloomFilter().getNumElements(); } componentBulkLoader = mergedComponent.createBulkLoader(1.0f, false, numElements, false, false, false); LSMRTreeDeletedKeysBTreeMergeCursor btreeCursor = new LSMRTreeDeletedKeysBTreeMergeCursor(opCtx); try { search(opCtx, btreeCursor, rtreeSearchPred); try { while (btreeCursor.hasNext()) {
<|startcomment|> MAJOR SonarQube violation: Merge this if statement with the enclosing one. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1066 <|endcomment|>  } doOpen(initialState, searchPred); state = State.OPENED; if (STORE_TRACES) { openCallStack = new Throwable().getStackTrace(); } } protected void doOpen(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { // Do nothing } @Override public final boolean hasNext() throws HyracksDataException { <|startfocus|> if (ENFORCE_NEXT_HAS_NEXT) { if (state != State.OPENED) { throw new IllegalStateException("Cannot call hasNext() on a cursor in the state " + state); } <|endfocus|> } return doHasNext(); } protected boolean doHasNext() throws HyracksDataException { return false; } @Override public final void next() throws HyracksDataException { if (ENFORCE_NEXT_HAS_NEXT) { if (state != State.OPENED) { throw new IllegalStateException("Cannot call next() on a cursor in the state " + state); } } doNext(); } protected void doNext() throws HyracksDataException { // Do nothing } @Override
<|startcomment|> MAJOR SonarQube violation: Merge this if statement with the enclosing one. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1066 <|endcomment|>  if (state != State.OPENED) { throw new IllegalStateException("Cannot call hasNext() on a cursor in the state " + state); } } return doHasNext(); } protected boolean doHasNext() throws HyracksDataException { return false; } @Override public final void next() throws HyracksDataException { <|startfocus|> if (ENFORCE_NEXT_HAS_NEXT) { if (state != State.OPENED) { throw new IllegalStateException("Cannot call next() on a cursor in the state " + state); } <|endfocus|> } doNext(); } protected void doNext() throws HyracksDataException { // Do nothing } @Override public final void destroy() throws HyracksDataException { if (ENFORCE_OPEN_CLOSE_DESTROY) { if (state == State.DESTROYED) { LOGGER.log(Level.WARN, "multiple cursor.destroy() call in " + Arrays.toString(new Throwable().getStackTrace())); return; } else if (state != State.CLOSED) { if (STORE_TRACES && openCallStack != null) {
<|startcomment|> MAJOR SonarQube violation: This block of commented-out lines of code should be removed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3ACommentedOutCodeLine <|endcomment|>  private ByteBuffer buffer; private volatile long dpid; private int multiplier; private VirtualPage next; <|startfocus|> private AtomicInteger readCount = new AtomicInteger(0); private AtomicInteger writeCount = new AtomicInteger(0); // String readStackTrace; <|endfocus|> public VirtualPage(ByteBuffer buffer, int pageSize) { this.buffer = buffer; this.pageSize = pageSize; latch = new ReentrantReadWriteLock(true); dpid = -1; next = null;
<|startcomment|> MAJOR SonarQube violation: This block of commented-out lines of code should be removed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3ACommentedOutCodeLine <|endcomment|>  public void acquireReadLatch() { latch.readLock().lock(); <|startfocus|> readCount.incrementAndGet(); // readStackTrace = Arrays.toString(new Throwable().getStackTrace()); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: Refactor this code to not nest more than 4 if/for/while/switch/try statements. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS134 <|endcomment|>  LOGGER.info("Disk-Order Scan:"); } ITreeIndexAccessor treeIndexAccessor = (ITreeIndexAccessor) indexAccessor; TreeIndexDiskOrderScanCursor diskOrderCursor = (TreeIndexDiskOrderScanCursor) treeIndexAccessor.createDiskOrderScanCursor(); try { treeIndexAccessor.diskOrderScan(diskOrderCursor); try { while (diskOrderCursor.hasNext()) { diskOrderCursor.next(); ITupleReference frameTuple = diskOrderCursor.getTuple(); String rec = TupleUtils.printTuple(frameTuple, fieldSerdes); <|startfocus|> if (LOGGER.isInfoEnabled()) { LOGGER.info(rec); } <|endfocus|> } } finally { diskOrderCursor.close(); } } finally { diskOrderCursor.destroy(); } } catch (UnsupportedOperationException e) { // Ignore exception because some indexes, e.g. the LSMRTree, don't // support disk-order scan. if (LOGGER.isInfoEnabled()) { LOGGER.info("Ignoring disk-order scan since it's not supported."); } } catch (ClassCastException e) { // Ignore exception because IIndexAccessor sometimes isn't // an ITreeIndexAccessor, e.g., for the LSMRTree.
<|startcomment|> CRITICAL SonarQube violation: Define and throw a dedicated exception instead of using a generic one. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00112 <|endcomment|>  Class<?> c = Class.forName(className); ncAppEntryPoint = (INCApplicationEntryPoint) c.newInstance(); String[] args = ncConfig.appArgs == null ? new String[0] : ncConfig.appArgs.toArray(new String[ncConfig.appArgs.size()]); ncAppEntryPoint.start(appCtx, args); } executor = Executors.newCachedThreadPool(appCtx.getThreadFactory()); } @Override public synchronized void stop() throws Exception { if (!shuttedDown) { LOGGER.log(Level.INFO, "Stopping NodeControllerService"); executor.shutdownNow(); if (!executor.awaitTermination(10, TimeUnit.SECONDS)) { <|startfocus|> LOGGER.log(Level.SEVERE, "Some jobs failed to exit, continuing with abnormal shutdown"); <|endfocus|> } partitionManager.close(); datasetPartitionManager.close(); netManager.stop(); datasetNetworkManager.stop(); if (messagingNetManager != null) { messagingNetManager.stop(); } queue.stop(); if (ncAppEntryPoint != null) { ncAppEntryPoint.stop(); } /** * Stop heartbeat after NC has stopped to avoid false node failure detection
<|startcomment|> MAJOR SonarQube violation: Add the missing @deprecated Javadoc tag. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AMissingDeprecatedCheck <|endcomment|>  CCNCFunctions.NodeRegistrationResult nrrf = (CCNCFunctions.NodeRegistrationResult) fn; setNodeRegistrationResult(nrrf.getNodeParameters(), nrrf.getException()); return; case GET_NODE_CONTROLLERS_INFO_RESPONSE: CCNCFunctions.GetNodeControllersInfoResponseFunction gncirf = (CCNCFunctions.GetNodeControllersInfoResponseFunction) fn; setNodeControllersInfo(gncirf.getNodeControllerInfos()); return; case DEPLOY_BINARY: CCNCFunctions.DeployBinaryFunction dbf = (CCNCFunctions.DeployBinaryFunction) fn; queue.schedule(new DeployBinaryWork(NodeControllerService.this, dbf.getDeploymentId(), dbf.getBinaryURLs())); <|startfocus|> return; <|endfocus|> case UNDEPLOY_BINARY: CCNCFunctions.UnDeployBinaryFunction ndbf = (CCNCFunctions.UnDeployBinaryFunction) fn; queue.schedule(new UnDeployBinaryWork(NodeControllerService.this, ndbf.getDeploymentId())); return; case STATE_DUMP_REQUEST: final CCNCFunctions.StateDumpRequestFunction dsrf = (StateDumpRequestFunction) fn; queue.schedule(new StateDumpWork(NodeControllerService.this, dsrf.getStateDumpId())); return; case SHUTDOWN_REQUEST: final CCNCFunctions.ShutdownRequestFunction sdrf = (CCNCFunctions.ShutdownRequestFunction) fn;
<|startcomment|> private <|endcomment|>  */ package org.apache.hyracks.api.job; import java.io.DataInput; import java.io.DataOutput; import java.io.IOException; import java.io.Serializable; import org.apache.hyracks.api.control.CcId; import org.apache.hyracks.api.exceptions.ErrorCode; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.api.io.IWritable; public final class JobId implements IWritable, Serializable, Comparable { <|startfocus|> public static final int CC_BITS = Short.SIZE; public static final int ID_BITS = Long.SIZE - CC_BITS; public static final long MAX_ID = (1L << ID_BITS) - 1; <|endfocus|> public static final JobId INVALID = null; private static final long serialVersionUID = 1L; private long id; private transient CcId ccId; public static JobId create(DataInput dis) throws IOException { JobId jobId = new JobId(); jobId.readFields(dis); return jobId; } private JobId() { } public JobId(long id) { this.id = id; } public long getId() {
<|startcomment|> private <|endcomment|> import java.io.DataOutput; import java.io.IOException; import java.io.Serializable; import org.apache.hyracks.api.control.CcId; import org.apache.hyracks.api.exceptions.ErrorCode; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.api.io.IWritable; public final class JobId implements IWritable, Serializable, Comparable { <|startfocus|> public static final int CC_BITS = Short.SIZE; public static final int ID_BITS = Long.SIZE - CC_BITS; public static final long MAX_ID = (1L << ID_BITS) - 1; <|endfocus|> public static final JobId INVALID = null; private static final long serialVersionUID = 1L; private long id; private transient CcId ccId; public static JobId create(DataInput dis) throws IOException { JobId jobId = new JobId(); jobId.readFields(dis); return jobId; } private JobId() { } public JobId(long id) { this.id = id; } public long getId() { return id; } public CcId getCcId() {
<|startcomment|> need to stop its heartbeat thread too <|endcomment|>  ncAppEntryPoint.stop(); /* * Stop heartbeat after NC has stopped to avoid false node failure detection * on CC if an NC takes a long time to stop. */ heartbeatTask.cancel(); LOGGER.log(Level.INFO, "Stopped NodeControllerService"); shuttedDown = true; } } public String getId() { return id; } public ServerContext getServerContext() { return serverCtx; } public Map<JobId, Joblet> getJobletMap() { return jobletMap; } <|startfocus|> public Map<JobId, ActivityClusterGraph> getActivityClusterGraphMap() { return activityClusterGraphMap; } <|endfocus|> public NetworkManager getNetworkManager() { return netManager; } public DatasetNetworkManager getDatasetNetworkManager() { return datasetNetworkManager; } public PartitionManager getPartitionManager() { return partitionManager; } public IClusterController getClusterController() { return ccs; } public NodeParameters getNodeParameters() { return nodeParameters; } public ExecutorService getExecutorService() { return executor; } public NCConfig getConfiguration() {
<|startcomment|> s/class/static class/ :) <|endcomment|>  currentRecordChannel = new DatasetNetworkInputChannel(netManager, getSocketAddress(record), jobId, resultSetId, currentRecord, NUM_READ_BUFFERS); currentRecordMonitor = getMonitor(currentRecord); currentRecordChannel.registerMonitor(currentRecordMonitor); currentRecordChannel.open(datasetClientCtx); } private boolean isFirstRead() { return currentRecord == -1; } private boolean isLastRecord() { return knownRecords != null && currentRecord == knownRecords.length - 1; } <|startfocus|> private class DatasetInputChannelMonitor implements IInputChannelMonitor { <|endfocus|> private int availableFrames; private boolean eos; private boolean failed; DatasetInputChannelMonitor() { eos = false; failed = false; } @Override public synchronized void notifyFailure(IInputChannel channel) { failed = true; notifyAll(); } @Override public synchronized void notifyDataAvailability(IInputChannel channel, int nFrames) { availableFrames += nFrames; notifyAll(); } @Override public synchronized void notifyEndOfStream(IInputChannel channel) { eos = true; notifyAll(); } synchronized boolean failed() { return failed; } 
<|startcomment|> why 1 when there's use of partition 0 in the index creation? <|endcomment|>  private static final boolean[] UNIQUE_META_FIELDS = null; private static final int[] KEY_INDEXES = { 0 }; private static final int[] KEY_INDICATORS = { Index.RECORD_INDICATOR }; private static final List<Integer> KEY_INDICATORS_LIST = Arrays.asList(new Integer[] { Index.RECORD_INDICATOR }); private static final int TOTAL_NUM_OF_RECORDS = 10000; private static final int RECORDS_PER_COMPONENT = 1000; private static final int DATASET_ID = 101; <|startfocus|> private static final int PARTITION_ID = 1; <|endfocus|> private static final String DATAVERSE_NAME = "TestDV"; private static final String DATASET_NAME = "TestDS"; private static final String DATA_TYPE_NAME = "DUMMY"; private static final String NODE_GROUP_NAME = "DEFAULT"; private static final Predicate<ILSMComponent> memoryComponentsPredicate = c -> c instanceof ILSMMemoryComponent; private static final StorageComponentProvider storageManager = new StorageComponentProvider(); private static TestNodeController nc; private static TestLsmBtree lsmBtree; private static NCAppRuntimeContext ncAppCtx; private static IDatasetLifecycleManager dsLifecycleMgr; private static Dataset dataset;
<|startcomment|> javadocs? <|endcomment|>  /** * @return the operation callback */ ILSMIOOperationCallback getCallback(); /** * @return the index id */ String getIndexIdentifier(); /** * @return the operation type */ LSMIOOperationType getIOOpertionType(); @Override Boolean call() throws HyracksDataException; /** * @return The target of the io operation */ FileReference getTarget(); /** * @return the accessor of the operation */ ILSMIndexAccessor getAccessor(); <|startfocus|> <|endfocus|> LSMComponentFileReferences getComponentFiles(); } 
<|startcomment|> What's the usage of this "isScan"? I remembered previous there is a similar functionality by checking the search predicate itself. <|endcomment|> <|startfocus|> private boolean isScan; <|endfocus|> public LSMBTreeCursorInitialState(ITreeIndexFrameFactory leafFrameFactory, MultiComparator cmp, MultiComparator bloomFilterCmp, ILSMHarness lsmHarness, ISearchPredicate predicate, ISearchOperationCallback searchCallback, List<ILSMComponent> operationalComponents) { this.leafFrameFactory = leafFrameFactory; this.cmp = cmp; this.bloomFilterCmp = bloomFilterCmp; this.lsmHarness = lsmHarness; this.searchCallback = searchCallback; this.predicate = predicate; this.operationalComponents = operationalComponents;
<|startcomment|> why call closeCursors instead of destroyCursors here? <|endcomment|>  btreeCursors[i] = btreeAccessors[i].createPointCursor(false); } else { // re-use btreeAccessors[i].reset(btree, NoOpOperationCallback.INSTANCE, NoOpOperationCallback.INSTANCE); btreeCursors[i].reset(); } } nextHasBeenCalled = false; foundTuple = false; } @Override public void next() throws HyracksDataException { nextHasBeenCalled = true; } @Override <|startfocus|> public void close() throws HyracksDataException { if (lsmHarness != null) { try { closeCursors(); btreeCursors = null; } finally { lsmHarness.endSearch(opCtx); <|endfocus|> } } nextHasBeenCalled = false; foundTuple = false; } @Override public ITupleReference getTuple() { return frameTuple; } @Override public ITupleReference getFilterMinTuple() { ILSMComponentFilter filter = getFilter(); return filter == null ? null : filter.getMinTuple(); } @Override public ITupleReference getFilterMaxTuple() { ILSMComponentFilter filter = getFilter(); return filter == null ? null : filter.getMaxTuple(); } 
<|startcomment|> I see the usage here...But I suggest we should change the name of isScan to make it more clear (this is very different from a normal index scan). For example, isDiskComponentScan. <|endcomment|>  private final LSMBTreeRangeSearchCursor rangeCursor; private ITreeIndexCursor currentCursor; public LSMBTreeSearchCursor(ILSMIndexOperationContext opCtx) { pointCursor = new LSMBTreePointSearchCursor(opCtx); rangeCursor = new LSMBTreeRangeSearchCursor(opCtx); } @Override public void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { LSMBTreeCursorInitialState lsmInitialState = (LSMBTreeCursorInitialState) initialState; RangePredicate btreePred = (RangePredicate) searchPred; <|startfocus|> currentCursor = btreePred.isPointPredicate(lsmInitialState.getOriginalKeyComparator()) ? pointCursor : rangeCursor; <|endfocus|> currentCursor.open(lsmInitialState, searchPred); } @Override public boolean hasNext() throws HyracksDataException { return currentCursor.hasNext(); } @Override public void next() throws HyracksDataException { currentCursor.next(); } @Override public void close() throws HyracksDataException { if (currentCursor != null) { currentCursor.close(); } currentCursor = null; } @Override public void reset() throws HyracksDataException { if (currentCursor != null) { currentCursor.reset(); } currentCursor = null;
<|startcomment|> MAJOR SonarQube violation: Remove this unused method parameter "context". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1172 <|endcomment|>  // (E.g. There are index-nested-loop-joins in the plan.) private List<Mutable<ILogicalOperator>> ixJoinOuterAdditionalDataSourceRefs = null; private List<DataSourceType> ixJoinOuterAdditionalDataSourceTypes = null; private List<Dataset> ixJoinOuterAdditionalDatasets = null; private List<ARecordType> ixJoinOuterAdditionalRecordTypes = null; /** * Identifies the root of the subtree and initializes the data-source, assign, and unnest information. */ <|startfocus|> public boolean initFromSubTree(Mutable<ILogicalOperator> subTreeOpRef, IOptimizationContext context) throws AlgebricksException { <|endfocus|> reset(); rootRef = subTreeOpRef; root = subTreeOpRef.getValue(); boolean passedSource = false; boolean result = false; Mutable<ILogicalOperator> searchOpRef = subTreeOpRef; // Examine the op's children to match the expected patterns. AbstractLogicalOperator subTreeOp = (AbstractLogicalOperator) searchOpRef.getValue(); do { // Skips select operator. if (subTreeOp.getOperatorTag() == LogicalOperatorTag.SELECT) { searchOpRef = subTreeOp.getInputs().get(0);
<|startcomment|> CRITICAL SonarQube violation: Either log or rethrow this exception. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1166 <|endcomment|>  } } /** * Computes and returns the byte array for an integer value. */ public static byte[] computeByteArrayForIntValue(int value) throws AlgebricksException { ArrayBackedValueStorage castBuffer = new ArrayBackedValueStorage(); try { AInt32 val = new AInt32(value); SerializerDeserializerUtil.serializeTag(val, castBuffer.getDataOutput()); AInt32SerializerDeserializer.INSTANCE.serialize(val, castBuffer.getDataOutput()); } catch (HyracksDataException e) { <|startfocus|> throw CompilationException.create(ErrorCode.CANNOT_SERIALIZE_A_VALUE); <|endfocus|> } return castBuffer.getByteArray(); } } 
<|startcomment|> MAJOR SonarQube violation: Remove this unused "numberOfFieldFromIndex" private field. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1068 <|endcomment|>  private ITreeIndexAccessor[] btreeAccessors; private RTreeSearchCursor[] mutableRTreeCursors; private ITreeIndexCursor[] btreeCursors; private RangePredicate btreeRangePredicate; private boolean foundNext; private ITupleReference frameTuple; private int[] comparatorFields; private MultiComparator btreeCmp; private int currentCursor; private SearchPredicate rtreeSearchPredicate; private int numMutableComponents; private boolean open; protected ISearchOperationCallback searchCallback; private boolean resultOfsearchCallBackProceed = false; <|startfocus|> private int numberOfFieldFromIndex = 0; private ArrayTupleBuilder tupleBuilderForProceedResult; private ArrayTupleReference copyTuple = null; <|endfocus|> public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx) { this(opCtx, false); } public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx, boolean returnDeletedTuples) { super(opCtx, returnDeletedTuples); currentCursor = 0; } @Override public void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = (LSMRTreeCursorInitialState) initialState; cmp = lsmInitialState.getHilbertCmp(); btreeCmp = lsmInitialState.getBTreeCmp(); lsmHarness = lsmInitialState.getLSMHarness();
<|startcomment|> MAJOR SonarQube violation: Remove this unused "tupleBuilderForProceedResult" private field. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1068 <|endcomment|>  private RTreeSearchCursor[] mutableRTreeCursors; private ITreeIndexCursor[] btreeCursors; private RangePredicate btreeRangePredicate; private boolean foundNext; private ITupleReference frameTuple; private int[] comparatorFields; private MultiComparator btreeCmp; private int currentCursor; private SearchPredicate rtreeSearchPredicate; private int numMutableComponents; private boolean open; protected ISearchOperationCallback searchCallback; private boolean resultOfsearchCallBackProceed = false; <|startfocus|> private int numberOfFieldFromIndex = 0; private ArrayTupleBuilder tupleBuilderForProceedResult; private ArrayTupleReference copyTuple = null; <|endfocus|> public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx) { this(opCtx, false); } public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx, boolean returnDeletedTuples) { super(opCtx, returnDeletedTuples); currentCursor = 0; } @Override public void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = (LSMRTreeCursorInitialState) initialState; cmp = lsmInitialState.getHilbertCmp(); btreeCmp = lsmInitialState.getBTreeCmp(); lsmHarness = lsmInitialState.getLSMHarness();
<|startcomment|> MAJOR SonarQube violation: Remove this unused "copyTuple" private field. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1068 <|endcomment|>  private RTreeSearchCursor[] mutableRTreeCursors; private ITreeIndexCursor[] btreeCursors; private RangePredicate btreeRangePredicate; private boolean foundNext; private ITupleReference frameTuple; private int[] comparatorFields; private MultiComparator btreeCmp; private int currentCursor; private SearchPredicate rtreeSearchPredicate; private int numMutableComponents; private boolean open; protected ISearchOperationCallback searchCallback; private boolean resultOfsearchCallBackProceed = false; <|startfocus|> private int numberOfFieldFromIndex = 0; private ArrayTupleBuilder tupleBuilderForProceedResult; private ArrayTupleReference copyTuple = null; <|endfocus|> public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx) { this(opCtx, false); } public LSMRTreeWithAntiMatterTuplesSearchCursor(ILSMIndexOperationContext opCtx, boolean returnDeletedTuples) { super(opCtx, returnDeletedTuples); currentCursor = 0; } @Override public void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { LSMRTreeCursorInitialState lsmInitialState = (LSMRTreeCursorInitialState) initialState; cmp = lsmInitialState.getHilbertCmp(); btreeCmp = lsmInitialState.getBTreeCmp(); lsmHarness = lsmInitialState.getLSMHarness();
<|startcomment|> Let's rename this method too. maybe getPrimaryOperationTracker <|endcomment|>  public interface INcApplicationContext extends IApplicationContext { IIOManager getIoManager(); Executor getThreadExecutor(); ITransactionSubsystem getTransactionSubsystem(); void preStop() throws Exception; boolean isShuttingdown(); ILSMIOOperationScheduler getLSMIOScheduler(); ILSMMergePolicyFactory getMetadataMergePolicyFactory(); IBufferCache getBufferCache(); ILocalResourceRepository getLocalResourceRepository(); IDatasetLifecycleManager getDatasetLifecycleManager(); IDatasetMemoryManager getDatasetMemoryManager(); IResourceIdFactory getResourceIdFactory(); <|startfocus|> ILSMOperationTracker getLSMBTreeOperationTracker(int datasetID, int partition); <|endfocus|> void initialize(boolean initialRun) throws IOException, ACIDException, AlgebricksException; void setShuttingdown(boolean b); void deinitialize() throws HyracksDataException; double getBloomFilterFalsePositiveRate(); Object getActiveManager(); IReplicationManager getReplicationManager(); IReplicationChannel getReplicationChannel(); /** * Exports the metadata node to the metadata RMI port. * * @throws RemoteException */ void exportMetadataNodeStub() throws RemoteException; /** * Initializes the metadata node and bootstraps the metadata. * * @param newUniverse * @throws Exception */
<|startcomment|> CRITICAL SonarQube violation: Remove this call to "wait" or move it into a "while" loop. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2274 <|endcomment|>  idGenerator.refresh(); if (dsInfo.isDurable()) { synchronized (logRecord) { TransactionUtil.formFlushLogRecord(logRecord, dsInfo.getDatasetID(), null); try { logManager.log(logRecord); } catch (ACIDException e) { throw new HyracksDataException("could not write flush log while closing dataset", e); } try { //notification will come from LogBuffer class (notifyFlushTerminator) logRecord.wait(); } catch (InterruptedException e) { <|startfocus|> throw new HyracksDataException(e); <|endfocus|> } } } for (ILSMIndex index : indexes) { //update resource lsn AbstractLSMIOOperationCallback ioOpCallback = (AbstractLSMIOOperationCallback) index.getIOOperationCallback(); ioOpCallback.updateLastLSN(logRecord.getLSN()); } if (asyncFlush) { for (ILSMIndex index : indexes) { ILSMIndexAccessor accessor = index.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.scheduleFlush(index.getIOOperationCallback()); } } else { for (ILSMIndex index : indexes) { // TODO: This is not efficient since we flush the indexes sequentially.
<|startcomment|> CRITICAL SonarQube violation: Either re-interrupt this method or rethrow the "InterruptedException". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2142 <|endcomment|>  idGenerator.refresh(); if (dsInfo.isDurable()) { synchronized (logRecord) { TransactionUtil.formFlushLogRecord(logRecord, dsInfo.getDatasetID(), null); try { logManager.log(logRecord); } catch (ACIDException e) { throw new HyracksDataException("could not write flush log while closing dataset", e); } try { //notification will come from LogBuffer class (notifyFlushTerminator) logRecord.wait(); } catch (InterruptedException e) { <|startfocus|> throw new HyracksDataException(e); <|endfocus|> } } } for (ILSMIndex index : indexes) { //update resource lsn AbstractLSMIOOperationCallback ioOpCallback = (AbstractLSMIOOperationCallback) index.getIOOperationCallback(); ioOpCallback.updateLastLSN(logRecord.getLSN()); } if (asyncFlush) { for (ILSMIndex index : indexes) { ILSMIndexAccessor accessor = index.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.scheduleFlush(index.getIOOperationCallback()); } } else { for (ILSMIndex index : indexes) { // TODO: This is not efficient since we flush the indexes sequentially.
<|startcomment|> let's rename to getDatasetPartitionOpenIndexes ? since this only cares about the open ones <|endcomment|>  this.setMemoryAllocated(false); } @Override public void touch() { super.touch(); setLastAccess(System.currentTimeMillis()); } @Override public void untouch() { super.untouch(); setLastAccess(System.currentTimeMillis()); } public synchronized void declareActiveIOOperation() { numActiveIOOps++; } public synchronized void undeclareActiveIOOperation() { numActiveIOOps--; //notify threads waiting on this dataset info notifyAll(); } <|startfocus|> public synchronized Set<ILSMIndex> getDatasetPartitionIndexes(int partition) { <|endfocus|> Set<ILSMIndex> indexSet = new HashSet<>(); Set<IndexInfo> partitionIndexInfos = this.partitionIndexes.get(partition); if (partitionIndexInfos != null) { for (IndexInfo iInfo : partitionIndexInfos) { if (iInfo.isOpen()) { indexSet.add(iInfo.getIndex()); } } } return indexSet; } @Override public int compareTo(DatasetInfo i) { // sort by (isOpen, referenceCount, lastAccess) ascending, where true < false // // Example sort order: // -------------------
<|startcomment|> space <|endcomment|>  public String toString() { <|startfocus|> return "JID:[" + getCcId() + "]" + getIdOnly(); <|endfocus|>
<|startcomment|> is this needed? <|endcomment|> import java.util.Map; import java.util.Set; import org.apache.hyracks.api.application.ICCServiceContext; import org.apache.hyracks.api.application.IClusterLifecycleListener; import org.apache.hyracks.api.config.IApplicationConfig; import org.apache.hyracks.api.config.IOption; import org.apache.hyracks.api.context.ICCContext; import org.apache.hyracks.api.exceptions.HyracksException; import org.apache.hyracks.api.job.IJobLifecycleListener; import org.apache.hyracks.api.job.JobId; import org.apache.hyracks.api.job.JobSpecification; import org.apache.hyracks.api.job.JobStatus; <|startfocus|> import org.apache.hyracks.api.messages.IMessageBroker; <|endfocus|> import org.apache.hyracks.api.service.IControllerService; import org.apache.hyracks.control.cc.ClusterControllerService; import org.apache.hyracks.control.common.application.ServiceContext; import org.apache.hyracks.control.common.context.ServerContext; import org.apache.hyracks.control.common.utils.HyracksThreadFactory; import org.apache.hyracks.control.common.work.IResultCallback; public class CCServiceContext extends ServiceContext implements ICCServiceContext { private final ICCContext ccContext; protected final Set<String> initPendingNodeIds; protected final Set<String> deinitPendingNodeIds; protected IResultCallback<Object> initializationCallback; protected IResultCallback<Object> deinitializationCallback; 
<|startcomment|> MAJOR SonarQube violation: Remove this useless assignment to local variable "secondaryKeyFieldUsedAfterSelectOrJoinOp". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1854 <|endcomment|>  indexOnlyPlanInfo.setFirst(false); return; } // index-only plan possible? boolean isIndexOnlyPlan = false; // secondary key field usage after the select (join) operators // This boolean is mainly used for R-Tree case since R-Tree index generates an MBR // and we can restore original point or rectangle from this MBR if an index is built on point or rectangle. <|startfocus|> boolean secondaryKeyFieldUsedAfterSelectOrJoinOp = indexOnlyPlanInfo.getSecond(); <|endfocus|> // Whether a post verification (especially for R-Tree case) is required after the secondary index search // (e.g., the shape of the given query is not a point or rectangle. // Then, we may need to apply the select again using the real polygon, not MBR of it to get the true // result, not a super-set of it.) boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo.getThird(); // Does the given index can cover all search predicates? boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo.getFourth(); // matched function expressions
<|startcomment|> MAJOR SonarQube violation: Remove this useless assignment to local variable "doesSIdxSearchCoverAllPredicates". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1854 <|endcomment|>  // (e.g., the shape of the given query is not a point or rectangle. // Then, we may need to apply the select again using the real polygon, not MBR of it to get the true // result, not a super-set of it.) boolean requireVerificationAfterSIdxSearch = indexOnlyPlanInfo.getThird(); // Does the given index can cover all search predicates? <|startfocus|> boolean doesSIdxSearchCoverAllPredicates = indexOnlyPlanInfo.getFourth(); <|endfocus|> // matched function expressions List<IOptimizableFuncExpr> matchedFuncExprs = analysisCtx.getMatchedFuncExprs(); // logical variables that select (join) operator is using List<LogicalVariable> usedVarsInSelJoinOp = new ArrayList<>(); List<LogicalVariable> usedVarsInSelJoinOpTemp = new ArrayList<>(); // live variables that select (join) operator can access List<LogicalVariable> liveVarsAfterSelJoinOp = new ArrayList<>(); // PK, record variable List<LogicalVariable> dataScanPKRecordVars; List<LogicalVariable> dataScanPKVars = new ArrayList<>(); List<LogicalVariable> dataScanRecordVars = new ArrayList<>(); 
<|startcomment|> MAJOR SonarQube violation: Reduce this anonymous class number of lines from 53 to at most 20, or make it a named class. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1188 <|endcomment|>  public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) { return new IScalarEvaluatorFactory() { private static final long serialVersionUID = 1L; @Override @SuppressWarnings("unchecked") public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException { return new IScalarEvaluator() { <|startfocus|> private final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); private final DataOutput out = resultStorage.getDataOutput(); private final IPointable argPtr0 = new VoidPointable(); private final IScalarEvaluator eval0 = args[0].createScalarEvaluator(ctx); <|endfocus|> private final AMutableInt32 intRes = new AMutableInt32(0); @Override public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { resultStorage.reset(); eval0.evaluate(tuple, argPtr0); try { byte[] bytes0 = argPtr0.getByteArray(); int offset0 = argPtr0.getStartOffset(); int len0 = argPtr0.getLength(); ATypeTag tag = EnumDeserializer.ATYPETAGDESERIALIZER.deserialize(bytes0[offset0]); if (tag != ATypeTag.GEOMETRY) {
<|startcomment|> MAJOR SonarQube violation: Reduce this anonymous class number of lines from 29 to at most 20, or make it a named class. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1188 <|endcomment|>  public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) { return new IScalarEvaluatorFactory() { private static final long serialVersionUID = 1L; @Override public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException { return new IScalarEvaluator() { <|startfocus|> private ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); private DataOutput out = resultStorage.getDataOutput(); private IPointable inputArg = new VoidPointable(); private IScalarEvaluator eval = args[0].createScalarEvaluator(ctx); <|endfocus|> @Override public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { eval.evaluate(tuple, inputArg); byte[] data = inputArg.getByteArray(); int offset = inputArg.getStartOffset(); int len = inputArg.getLength(); if (data[offset] != ATypeTag.SERIALIZED_BINARY_TYPE_TAG) { throw new TypeMismatchException(BuiltinFunctions.ST_GEOM_FROM_WKB, 0, data[offset], ATypeTag.SERIALIZED_BINARY_TYPE_TAG); } try { out.writeByte(ATypeTag.SERIALIZED_GEOMETRY_TYPE_TAG);
<|startcomment|> MAJOR SonarQube violation: Reduce this anonymous class number of lines from 44 to at most 20, or make it a named class. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1188 <|endcomment|>  public IScalarEvaluatorFactory createEvaluatorFactory(final IScalarEvaluatorFactory[] args) { return new IScalarEvaluatorFactory() { private static final long serialVersionUID = 1L; @Override public IScalarEvaluator createScalarEvaluator(IHyracksTaskContext ctx) throws HyracksDataException { <|startfocus|> return new IScalarEvaluator() { private ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); private DataOutput out = resultStorage.getDataOutput(); private IPointable inputArg = new VoidPointable(); private IScalarEvaluator eval = args[0].createScalarEvaluator(ctx); <|endfocus|> @Override @SuppressWarnings("unchecked") public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { eval.evaluate(tuple, inputArg); byte[] bytes = inputArg.getByteArray(); int offset = inputArg.getStartOffset(); int len = inputArg.getLength(); AOrderedListType type = new AOrderedListType(BuiltinType.AGEOMETRY, null); byte typeTag = inputArg.getByteArray()[inputArg.getStartOffset()]; ISerializerDeserializer serde; if (typeTag == ATypeTag.SERIALIZED_ORDEREDLIST_TYPE_TAG) { serde = new AOrderedListSerializerDeserializer(type);
<|startcomment|> use Objects.hash() as Pair/Triple do <|endcomment|>  public int hashCode() { <|startfocus|> return first.hashCode() * 71 + second.hashCode() * 31 + third.hashCode() * 17 + fourth.hashCode(); <|endfocus|>
<|startcomment|> Use Objects.equals() as Pair/Triple do (it handles 'null' values) <|endcomment|>  public boolean equals(Object o) { if (!(o instanceof Quadruple<?, ?, ?, ?>)) { return false; } <|startfocus|> Quadruple<?, ?, ?, ?> quadRuple = (Quadruple<?, ?, ?, ?>) o; return first.equals(quadRuple.first) && second.equals(quadRuple.second) && third.equals(quadRuple.third) && fourth.equals(quadRuple.fourth); <|endfocus|>
<|startcomment|> return currentElementIx < numElements <|endcomment|>  public boolean hasNext() { <|startfocus|> if (currentElementIx < numElements) { return true; } else { return false; } <|endfocus|>
<|startcomment|> shouldn't this be an abstract class with the // do nothing methods as abstract methods? <|endcomment|>  * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.storage.common; import java.util.Arrays; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.dataflow.common.data.accessors.ITupleReference; import org.apache.logging.log4j.Level; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; <|startfocus|> public class EnforcedIndexCursor implements IIndexCursor { <|endfocus|> enum State { CLOSED, OPENED, DESTROYED } private static final boolean STORE_TRACES = false; private static final boolean ENFORCE_NEXT_HAS_NEXT = true; private static final boolean ENFORCE_OPEN_CLOSE_DESTROY = true; private static final Logger LOGGER = LogManager.getLogger(); private State state = State.CLOSED; private StackTraceElement[] openCallStack; private StackTraceElement[] destroyCallStack; @Override public final void open(ICursorInitialState initialState, ISearchPredicate searchPred) throws HyracksDataException { if (ENFORCE_OPEN_CLOSE_DESTROY && state != State.CLOSED) {
<|startcomment|> CRITICAL SonarQube violation: Make "txnIdFactory" transient or serializable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1948 <|endcomment|>  private static final long serialVersionUID = 1L; private static final int METADATA_DATASET_ID = MetadataPrimaryIndexes.PROPERTIES_METADATA.getDatasetId(); // shared between core and extension private IDatasetLifecycleManager datasetLifecycleManager; private ITransactionSubsystem transactionSubsystem; private int metadataStoragePartition; // core only private transient MetadataTupleTranslatorProvider tupleTranslatorProvider; // extension only private Map<ExtensionMetadataDatasetId, ExtensionMetadataDataset<?>> extensionDatasets; public static final MetadataNode INSTANCE = new MetadataNode(); private MetadataNode() { super(); } <|startfocus|> public void initialize(IAppRuntimeContext runtimeContext, <|endfocus|> MetadataTupleTranslatorProvider tupleTranslatorProvider, List<IMetadataExtension> metadataExtensions) { this.tupleTranslatorProvider = tupleTranslatorProvider; this.transactionSubsystem = runtimeContext.getTransactionSubsystem(); this.datasetLifecycleManager = runtimeContext.getDatasetLifecycleManager(); this.metadataStoragePartition = ((IPropertiesProvider) runtimeContext).getMetadataProperties() .getMetadataPartition().getPartitionId(); if (metadataExtensions != null) { extensionDatasets = new HashMap<>(); for (IMetadataExtension metadataExtension : metadataExtensions) { for (ExtensionMetadataDataset<?> extensionIndex : metadataExtension.getExtensionIndexes()) {
<|startcomment|> MAJOR SonarQube violation: Rename this field "TXN_BLOCK_SIZE" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  import java.util.concurrent.atomic.AtomicLong; import java.util.function.Supplier; import org.apache.asterix.common.transactions.ILongBlockFactory; import org.apache.asterix.common.transactions.ITxnIdFactory; import org.apache.asterix.common.transactions.TxnId; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; /** * Represents a factory to generate unique transaction IDs. */ <|startfocus|> /*package*/ class CcTxnIdFactory implements ITxnIdFactory { private static int TXN_BLOCK_SIZE = 10; <|endfocus|> private static final Logger LOGGER = LogManager.getLogger(); private final Supplier<ILongBlockFactory> blockFactorySupplier; private volatile Block block = new Block(0, 0); public CcTxnIdFactory(Supplier<ILongBlockFactory> blockFactorySupplier) { this.blockFactorySupplier = blockFactorySupplier; } @Override public TxnId create() throws AlgebricksException { while (true) { try { return new TxnId(block.nextId()); } catch (BlockExhaustedException ex) { // retry
<|startcomment|> CRITICAL SonarQube violation: Either log or rethrow this exception. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1166 <|endcomment|>  private static int TXN_BLOCK_SIZE = 10; private static final Logger LOGGER = LogManager.getLogger(); private final Supplier<ILongBlockFactory> blockFactorySupplier; private volatile Block block = new Block(0, 0); public CcTxnIdFactory(Supplier<ILongBlockFactory> blockFactorySupplier) { this.blockFactorySupplier = blockFactorySupplier; } @Override public TxnId create() throws AlgebricksException { while (true) { try { return new TxnId(block.nextId()); } catch (BlockExhaustedException ex) { <|startfocus|> // retry <|endfocus|> block = new Block(blockFactorySupplier.get().getBlock(TXN_BLOCK_SIZE), TXN_BLOCK_SIZE); } } } @Override public void ensureMinimumId(long id) throws AlgebricksException { blockFactorySupplier.get().ensureMinimum(id); } static class Block { private static final BlockExhaustedException BLOCK_EXHAUSTED_EXCEPTION = new BlockExhaustedException(); private final AtomicLong id; private final long start; private final long endExclusive; private Block(long start, long blockSize) { this.id = new AtomicLong(start); this.start = start;
<|startcomment|> MAJOR SonarQube violation: Remove this unused "proxies" local variable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1481 <|endcomment|>  } @Override public ActiveManager getActiveManager() { return activeManager; } @Override public ReplicationProperties getReplicationProperties() { return replicationProperties; } @Override public IReplicationChannel getReplicationChannel() { return replicationChannel; } @Override public IReplicationManager getReplicationManager() { return replicationManager; } @Override public ILibraryManager getLibraryManager() { return libraryManager; } @Override public void initializeMetadata(boolean newUniverse) throws Exception { <|startfocus|> Collection<IAsterixStateProxy> proxies; LOGGER.info("Bootstrapping metadata"); <|endfocus|> MetadataNode.INSTANCE.initialize(this, ncExtensionManager.getMetadataTupleTranslatorProvider(), ncExtensionManager.getMetadataExtensions()); //noinspection unchecked ConcurrentHashMap<CcId, IAsterixStateProxy> proxyMap = ((ConcurrentHashMap<CcId, IAsterixStateProxy>) getServiceContext().getDistributedState()); if (proxyMap == null) { throw new IllegalStateException("Metadata node cannot access distributed state"); } // This is a special case, we just give the metadataNode directly. // This way we can delay the registration of the metadataNode until // it is completely initialized.
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  return replicationManager; } @Override public ILibraryManager getLibraryManager() { return libraryManager; } @Override public void initializeMetadata(boolean newUniverse) throws Exception { Collection<IAsterixStateProxy> proxies; LOGGER.info("Bootstrapping metadata"); MetadataNode.INSTANCE.initialize(this, ncExtensionManager.getMetadataTupleTranslatorProvider(), ncExtensionManager.getMetadataExtensions()); <|startfocus|> //noinspection unchecked ConcurrentHashMap<CcId, IAsterixStateProxy> proxyMap = ((ConcurrentHashMap<CcId, IAsterixStateProxy>) getServiceContext().getDistributedState()); if (proxyMap == null) { <|endfocus|> throw new IllegalStateException("Metadata node cannot access distributed state"); } // This is a special case, we just give the metadataNode directly. // This way we can delay the registration of the metadataNode until // it is completely initialized. MetadataManager.initialize(proxyMap.values(), MetadataNode.INSTANCE); MetadataBootstrap.startUniverse(getServiceContext(), newUniverse); MetadataBootstrap.startDDLRecovery(); ncExtensionManager.initializeMetadata(getServiceContext()); LOGGER.info("Metadata node bound"); } @Override public synchronized void exportMetadataNodeStub() throws RemoteException {
<|startcomment|> this is runtime, it doesn't have to be here <|endcomment|>  } } catch (InterruptedException e) { Thread.currentThread().interrupt(); throw HyracksDataException.create(e); } catch (RemoteException e) { throw new RuntimeDataException(ErrorCode.REMOTE_EXCEPTION_WHEN_CALLING_METADATA_NODE, e); } super.init(); } } private static class NCMetadataManagerImpl extends MetadataManager { public NCMetadataManagerImpl(Collection<IAsterixStateProxy> proxies, IMetadataNode metadataNode) { super(proxies, metadataNode); } @Override <|startfocus|> public MetadataTransactionContext beginTransaction() throws RemoteException, ACIDException { <|endfocus|> TxnId txnId = new TxnId(metadataNode.reserveTxnIdBlock(1)); metadataNode.beginTransaction(txnId); return new MetadataTransactionContext(txnId); } } } 
<|startcomment|> remove <|endcomment|>  import java.util.concurrent.atomic.AtomicLong; import java.util.function.Supplier; import org.apache.asterix.common.transactions.ILongBlockFactory; import org.apache.asterix.common.transactions.ITxnIdFactory; import org.apache.asterix.common.transactions.TxnId; import org.apache.hyracks.algebricks.common.exceptions.AlgebricksException; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; /** * Represents a factory to generate unique transaction IDs. */ <|startfocus|> /*package*/ class CcTxnIdFactory implements ITxnIdFactory { private static int TXN_BLOCK_SIZE = 10; <|endfocus|> private static final Logger LOGGER = LogManager.getLogger(); private final Supplier<ILongBlockFactory> blockFactorySupplier; private volatile Block block = new Block(0, 0); public CcTxnIdFactory(Supplier<ILongBlockFactory> blockFactorySupplier) { this.blockFactorySupplier = blockFactorySupplier; } @Override public TxnId create() throws AlgebricksException { while (true) { try { return new TxnId(block.nextId()); } catch (BlockExhaustedException ex) { // retry
<|startcomment|> CRITICAL SonarQube violation: Define and throw a dedicated exception instead of using a generic one. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00112 <|endcomment|>  } @Override public synchronized void stop() throws Exception { if (!shuttedDown) { LOGGER.log(Level.INFO, "Stopping NodeControllerService"); executor.shutdownNow(); if (!executor.awaitTermination(10, TimeUnit.SECONDS)) { LOGGER.log(Level.SEVERE, "Some jobs failed to exit, continuing with abnormal shutdown"); } partitionManager.close(); datasetPartitionManager.close(); netManager.stop(); datasetNetworkManager.stop(); <|startfocus|> if (messagingNetManager != null) { messagingNetManager.stop(); <|endfocus|> } workQueue.stop(); ncAppEntryPoint.stop(); /* * Stop heartbeat after NC has stopped to avoid false node failure detection * on CC if an NC takes a long time to stop. */ heartbeatTask.cancel(); LOGGER.log(Level.INFO, "Stopped NodeControllerService"); shuttedDown = true; } } public String getId() { return id; } public ServerContext getServerContext() { return serverCtx; } public Map<JobId, Joblet> getJobletMap() { return jobletMap; } 
<|startcomment|> use <|endcomment|>  } @Override public synchronized void stop() throws Exception { if (!shuttedDown) { LOGGER.log(Level.INFO, "Stopping NodeControllerService"); executor.shutdownNow(); if (!executor.awaitTermination(10, TimeUnit.SECONDS)) { LOGGER.log(Level.SEVERE, "Some jobs failed to exit, continuing with abnormal shutdown"); } partitionManager.close(); datasetPartitionManager.close(); netManager.stop(); datasetNetworkManager.stop(); if (messagingNetManager != null) { messagingNetManager.stop(); } <|startfocus|> workQueue.stop(); ncAppEntryPoint.stop(); /* <|endfocus|> * Stop heartbeat after NC has stopped to avoid false node failure detection * on CC if an NC takes a long time to stop. */ heartbeatTask.cancel(); LOGGER.log(Level.INFO, "Stopped NodeControllerService"); shuttedDown = true; } } public String getId() { return id; } public ServerContext getServerContext() { return serverCtx; } public Map<JobId, Joblet> getJobletMap() { return jobletMap; } 
<|startcomment|> MAJOR SonarQube violation: Split this 131 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  // Scan diskInvertedIndexes ignoring the memoryInvertedIndex. // Create an inverted index instance. ILSMDiskComponent component = createDiskComponent(componentFactory, mergeOp.getTarget(), mergeOp.getDeletedKeysBTreeTarget(), mergeOp.getBloomFilterTarget(), true); ILSMDiskComponentBulkLoader componentBulkLoader; <|startfocus|> // In case we must keep the deleted-keys BTrees, then they must be merged *before* merging the inverted indexes so that // lsmHarness.endSearch() is called once when the inverted indexes have been merged. <|endfocus|> if (mergeOp.getMergingComponents().get(mergeOp.getMergingComponents().size() - 1) != diskComponents .get(diskComponents.size() - 1)) { // Keep the deleted tuples since the oldest disk component is not included in the merge operation LSMInvertedIndexDeletedKeysBTreeMergeCursor btreeCursor = new LSMInvertedIndexDeletedKeysBTreeMergeCursor(opCtx); try { long numElements = 0L; for (int i = 0; i < mergeOp.getMergingComponents().size(); ++i) { numElements += ((LSMInvertedIndexDiskComponent) mergeOp.getMergingComponents().get(i))
<|startcomment|> MAJOR SonarQube violation: Remove this unused "LOGGER" private field. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1068 <|endcomment|>  private boolean isOpen; <|startfocus|> private final Map<Long, List<StackTraceElement[]>> callers = new HashMap<>(); <|endfocus|> public Info() { referenceCount = 0; isOpen = false;
<|startcomment|> CRITICAL SonarQube violation: Define and throw a dedicated exception instead of using a generic one. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00112 <|endcomment|>  public void untouch() { long tid = Thread.currentThread().getId(); List<StackTraceElement[]> caller = callers.get(tid); if (caller == null || caller.isEmpty()) { throw new RuntimeException("Untouch of an untouched resource by thread: " + tid); } caller.remove(caller.size() - 1); <|startfocus|> --referenceCount; <|endfocus|>
<|startcomment|> CRITICAL SonarQube violation: Define and throw a dedicated exception instead of using a generic one. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00112 <|endcomment|>  public void touch() { long tid = Thread.currentThread().getId(); if (callers.containsKey(tid)) { LOGGER.log(Level.WARN, "\"Double touch of a resource by thread:" + tid + ". Previous call was from: " + Arrays.toString(callers.get(tid)) + ". This call is from: " + Arrays.toString(new Throwable().getStackTrace())); throw new RuntimeException("Double touch of a resource by thread: " + tid); } <|startfocus|> callers.put(tid, new Throwable().getStackTrace()); <|endfocus|> ++referenceCount;
<|startcomment|> is undefined? seems like a strict contract to mandate throwing exceptions... <|endcomment|>  * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.api.dataflow; import org.apache.hyracks.api.exceptions.HyracksDataException; public interface IDestroyable { /** * Destroy the object and releases any system resources associated * with it. If the object is already destroyed then invoking this * method has no effect. <|startfocus|> * All other calls after this method is invoked must throw exceptions <|endfocus|> * * @throws HyracksDataException */ void destroy() throws HyracksDataException; } 
<|startcomment|> let's create an enum for requested keys. 0,1,2 is not very informative <|endcomment|>  dest.add(context.newVar()); } } /** * Gets the primary key variables from the unnest-map or left-outer-unnest-map operator * that does a secondary index lookup. * The order: SK, PK, [Optional: the result of a TryLock on PK] */ public static List<LogicalVariable> getKeyVarsFromSecondaryUnnestMap(Dataset dataset, ARecordType recordType, <|startfocus|> ARecordType metaRecordType, ILogicalOperator unnestMapOp, Index index, int keyType, boolean outputPrimaryKeysOnlyFromSIdxSearch) throws AlgebricksException { <|endfocus|> int numPrimaryKeys; int numSecondaryKeys = KeyFieldTypeUtil.getNumSecondaryKeys(index, recordType, metaRecordType); if (dataset.getDatasetType() == DatasetType.EXTERNAL) { numPrimaryKeys = IndexingConstants .getRIDSize(((ExternalDatasetDetails) dataset.getDatasetDetails()).getProperties()); } else { numPrimaryKeys = dataset.getPrimaryKeys().size(); } List<LogicalVariable> keyVars = new ArrayList<>(); List<LogicalVariable> sourceVars = ((AbstractUnnestMapOperator) unnestMapOp).getVariables(); // Assumption: the primary keys are located after the secondary key.
<|startcomment|> it's a bit strange that we need do cannot tell this information from the operator itself, but instead rely on the function parameter. I think currently outputPrimaryKeysOnlyFromSIdxSearch is set to true only for inverted indexes. can we just set it here by looking at the index type instead? <|endcomment|>  numPrimaryKeys = IndexingConstants .getRIDSize(((ExternalDatasetDetails) dataset.getDatasetDetails()).getProperties()); } else { numPrimaryKeys = dataset.getPrimaryKeys().size(); } List<LogicalVariable> keyVars = new ArrayList<>(); List<LogicalVariable> sourceVars = ((AbstractUnnestMapOperator) unnestMapOp).getVariables(); // Assumption: the primary keys are located after the secondary key. int start; int stop; <|startfocus|> // If a secondary-index search didn't generate SKs if (outputPrimaryKeysOnlyFromSIdxSearch) { <|endfocus|> numSecondaryKeys = 0; } // Fetches keys: type 0 - PK, type 1 - SK, type 2 - the result of instantTryLock() on PK switch (keyType) { case 0: // Fetches primary keys - the second position start = numSecondaryKeys; stop = numSecondaryKeys + numPrimaryKeys; break; case 1: // Fetches secondary keys - the first position start = 0; stop = numSecondaryKeys; break; case 2: // Fetches conditional splitter - the last position
<|startcomment|> should we just set stop = start + 1 here? sourceVars might have more variables if propagateIndexFilter = true <|endcomment|>  switch (keyType) { case 0: // Fetches primary keys - the second position start = numSecondaryKeys; stop = numSecondaryKeys + numPrimaryKeys; break; case 1: // Fetches secondary keys - the first position start = 0; stop = numSecondaryKeys; break; case 2: // Fetches conditional splitter - the last position start = numSecondaryKeys + numPrimaryKeys; <|startfocus|> stop = sourceVars.size(); <|endfocus|> break; default: return Collections.emptyList(); } for (int i = start; i < stop; i++) { keyVars.add(sourceVars.get(i)); } return keyVars; } public static List<LogicalVariable> getPrimaryKeyVarsFromSecondaryUnnestMap(Dataset dataset, ILogicalOperator unnestMapOp) { int numPrimaryKeys; if (dataset.getDatasetType() == DatasetType.EXTERNAL) { numPrimaryKeys = IndexingConstants .getRIDSize(((ExternalDatasetDetails) dataset.getDatasetDetails()).getProperties()); } else { numPrimaryKeys = dataset.getPrimaryKeys().size(); } List<LogicalVariable> primaryKeyVars = new ArrayList<>();
<|startcomment|> 1) it seems like this floor/ceil conversion is needed for index on closed-field (as the comment below indicates). For other indexes relaxing condition from < to <= would still work fine as before. So can we limit it to this case by changing this condition to "realTypeConvertedToIntegerType && !index.isEnforced() && !index.isOverridingKeyFieldTypes()" 2) The precision loss is also possible when converting a large BIGINT to FLOAT/DOUBLE. I wonder whether we need to deal with this in the new code? <|endcomment|>  // If the constant type and target type does not match, we may need to do a type conversion. if (constantValueTag != indexedFieldTypeTag && constantValue != null) { // To check whether the constant is REAL values, and target field is an INT type field. // In this case, we need to change the search parameter. Refer to the caller section for the detail. realTypeConvertedToIntegerType = isRealTypeConvertedToIntegerType(constantValueTag, indexedFieldTypeTag); <|startfocus|> if (realTypeConvertedToIntegerType) { <|endfocus|> // For the index on a closed-type field, // if a DOUBLE or FLOAT constant is converted to an INT type value, // we need to check a corner case where two real values are located // between an INT value. For example, the following query, // // for $emp in dataset empDataset // where $emp.age > double("2.3") and $emp.age < double("3.3") // return $emp.id; //
<|startcomment|> throw IllegalStateException here. NEQ is not expected here. <|endcomment|>  mathFunctionTypeForNumericTypeCasting); break; case EQ: // equality case - both CEIL and FLOOR need to be applied. replacedConstantValue = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.FLOOR); replacedConstantValueForEQCase = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.CEIL); break; default: break; } <|startfocus|> } // Type conversion only case: (e.g., INT -> BIGINT) if (mathFunctionTypeForNumericTypeCasting == TypeCastingMathFunctionType.NONE) { <|endfocus|> replacedConstantValue = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.NONE); } } // No type-casting at all if (replacedConstantValue == null) { return new Triple<>(constantAtRuntimeExpression, null, false); } // A type-casting happened, but not EQ case if (replacedConstantValueForEQCase == null) {
<|startcomment|> this should probably be "else if" from the previous "if" because mathFunctionTypeForNumericTypeCasting is assigned there to CEIL/FLOOR. Also the EQ case is weird because it does not assign mathFunctionTypeForNumericTypeCasting and therefore causes this if statement to run which will reassign replacedConstantValue. I think this problem would go away if we make this "else if" and we'll no longer need variable for mathFunctionTypeForNumericTypeCasting because it won't be used outside of the switch. <|endcomment|>  replacedConstantValueForEQCase = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.CEIL); break; default: break; } } // Type conversion only case: (e.g., INT -> BIGINT) if (mathFunctionTypeForNumericTypeCasting == TypeCastingMathFunctionType.NONE) { replacedConstantValue = getReplacedConstantValue(constantValue.getObject(), constantValueTag, indexedFieldTypeTag, index.isEnforced(), TypeCastingMathFunctionType.NONE); } <|startfocus|> <|endfocus|> } // No type-casting at all if (replacedConstantValue == null) { return new Triple<>(constantAtRuntimeExpression, null, false); } // A type-casting happened, but not EQ case if (replacedConstantValueForEQCase == null) { return new Triple<>(new ConstantExpression(replacedConstantValue), null, realTypeConvertedToIntegerType); } // A type-casting happened and it's an EQ case. return new Triple<>(new ConstantExpression(replacedConstantValue), new ConstantExpression(replacedConstantValueForEQCase), realTypeConvertedToIntegerType); }
<|startcomment|> MAJOR SonarQube violation: Reduce this lambda expression number of lines from 33 to at most 20. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1188 <|endcomment|>  private final String nodeId; private final List<INCLifecycleTask> tasks; public RegistrationTasksResponseMessage(String nodeId, List<INCLifecycleTask> tasks) { this.nodeId = nodeId; this.tasks = tasks; } @Override public void handle(INcApplicationContext appCtx) throws HyracksDataException, InterruptedException { INCMessageBroker broker = (INCMessageBroker) appCtx.getServiceContext().getMessageBroker(); IControllerService cs = appCtx.getServiceContext().getControllerService(); <|startfocus|> cs.getExecutor().submit(() -> { boolean success = true; <|endfocus|> try { Throwable exception = null; try { for (INCLifecycleTask task : tasks) { if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Starting startup task: " + task); } task.perform(getCcId(), cs); if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Completed startup task: " + task); } } } catch (Throwable e) { //NOSONAR all startup failures should be reported to CC LOGGER.log(Level.ERROR, "Failed during startup task", e);
<|startcomment|> CRITICAL SonarQube violation: Either log or rethrow this exception. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1166 <|endcomment|> class CachingTxnIdFactory implements ITxnIdFactory { private static final Logger LOGGER = LogManager.getLogger(); private final INcApplicationContext appCtx; private volatile Block block = new Block(0, 0); public CachingTxnIdFactory(INcApplicationContext appCtx) { this.appCtx = appCtx; } @Override public TxnId create() throws AlgebricksException { while (true) { try { return new TxnId(block.nextId()); } catch (BlockExhaustedException ex) { // retry LOGGER.info("block exhausted; obtaining new block from supplier"); <|startfocus|> TxnIdBlockRequestMessage.Block newBlock; <|endfocus|> try { newBlock = TxnIdBlockRequestMessage.send(appCtx); } catch (HyracksDataException e) { throw new AlgebricksException(e); } block = new Block(newBlock.getStartingId(), newBlock.getBlockSize()); } } } @Override public void ensureMinimumId(long id) throws AlgebricksException { throw new UnsupportedOperationException(); } @Override public long getIdBlock(int blockSize) { throw new UnsupportedOperationException(); } @Override
<|startcomment|> Let's do the max in NCAppRuntimeContext itself so that this logic will be centralized there instead of this msg. In there, you will need to check if (txnSubsystem == null) and throw IllegalStateException if it is the case to prevent someone from calling getMaxTxnId before TransactionSubsystem is initialized. <|endcomment|>  ((ClusterControllerService) appCtx.getServiceContext().getControllerService()).getJobIdFactory() .setMaxJobId(maxJobId); } public static void send(CcId ccId, NodeControllerService ncs) throws HyracksDataException { INcApplicationContext appContext = (INcApplicationContext) ncs.getApplicationContext(); long maxResourceId = Math.max(appContext.getLocalResourceRepository().maxId(), MetadataIndexImmutableProperties.FIRST_AVAILABLE_USER_DATASET_ID); <|startfocus|> long maxTxnId = Math.max(appContext.getMaxTxnId(), appContext.getTransactionSubsystem().getTransactionManager().getMaxTxnId()); <|endfocus|> long maxJobId = ncs.getMaxJobId(ccId); ReportLocalCountersMessage countersMessage = new ReportLocalCountersMessage(ncs.getId(), maxResourceId, maxTxnId, maxJobId); try { ((INCMessageBroker) ncs.getContext().getMessageBroker()).sendMessageToCC(ccId, countersMessage); } catch (Exception e) { LOGGER.log(Level.ERROR, "Unable to report local counters", e); throw HyracksDataException.create(e); } } @Override public String toString() { return ReportLocalCountersMessage.class.getSimpleName(); } } 
<|startcomment|> BLOCKER SonarQube violation: Catch Exception instead of Throwable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1181 <|endcomment|>  public static Throwable close(ITupleForwarder tupleForwarder, Throwable root) { if (tupleForwarder != null) { try { tupleForwarder.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); <|startfocus|> } catch (Throwable loggingFailure) { // Do nothing <|endfocus|> } root = ExceptionUtils.suppress(root, th); } } return root;
<|startcomment|> CRITICAL SonarQube violation: Either log or rethrow this exception. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1166 <|endcomment|>  public static Throwable close(ITupleForwarder tupleForwarder, Throwable root) { if (tupleForwarder != null) { try { tupleForwarder.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); <|startfocus|> } catch (Throwable loggingFailure) { // Do nothing <|endfocus|> } root = ExceptionUtils.suppress(root, th); } } return root;
<|startcomment|> @FunctionalInterface <|endcomment|>  * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.api.dataflow; import org.apache.hyracks.api.exceptions.HyracksDataException; <|startfocus|> <|endfocus|> public interface IDestroyable { /** * Destroy the object and releases any system resources associated * with it. If the object is already destroyed then invoking this * method has no effect. * All other calls after this method is invoked is undefined * * @throws HyracksDataException */ void destroy() throws HyracksDataException; } 
<|startcomment|> The behavior of <|endcomment|>  * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.hyracks.api.dataflow; import org.apache.hyracks.api.exceptions.HyracksDataException; public interface IDestroyable { /** * Destroy the object and releases any system resources associated * with it. If the object is already destroyed then invoking this * method has no effect. <|startfocus|> * All other calls after this method is invoked is undefined <|endfocus|> * * @throws HyracksDataException */ void destroy() throws HyracksDataException; } 
<|startcomment|> BLOCKER SonarQube violation: Catch Exception instead of Throwable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1181 <|endcomment|>  public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); <|startfocus|> } catch (Throwable loggingFailure) { <|endfocus|> // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root;
<|startcomment|> CRITICAL SonarQube violation: Either log or rethrow this exception. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1166 <|endcomment|>  public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); <|startfocus|> } catch (Throwable loggingFailure) { <|endfocus|> // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root;
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "root". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable loggingFailure) { // Do nothing } <|startfocus|> root = ExceptionUtils.suppress(root, th); <|endfocus|> } } return root;
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "root". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  public static Throwable close(List<IIndexDataflowHelper> indexHelpers, Throwable root) { for (int i = 0; i < indexHelpers.size(); i++) { <|startfocus|> root = close(indexHelpers, root); <|endfocus|> } return root;
<|startcomment|> throw if not null? <|endcomment|>  reusablePred.setHighKeyComparator(predicate.getHighKeyComparator()); includeMutableComponent = false; int numBTrees = operationalComponents.size(); if (rangeCursors == null) { // object creation: should be relatively low rangeCursors = new IIndexCursor[numBTrees]; btreeAccessors = new BTreeAccessor[numBTrees]; } else if (rangeCursors.length != numBTrees) { // should destroy first Throwable failure = ExceptionUtils.suppress(DestroyUtils.destroy(btreeAccessors), DestroyUtils.destroy(rangeCursors)); <|startfocus|> if (failure != null) { throw HyracksDataException.create(failure); } <|endfocus|> rangeCursors = new IIndexCursor[numBTrees]; btreeAccessors = new BTreeAccessor[numBTrees]; } for (int i = 0; i < numBTrees; i++) { ILSMComponent component = operationalComponents.get(i); BTree btree; if (component.getType() == LSMComponentType.MEMORY) { includeMutableComponent = true; } btree = (BTree) component.getIndex(); if (btreeAccessors[i] == null) { btreeAccessors[i] = btree.createAccessor(NoOpIndexAccessParameters.INSTANCE); rangeCursors[i] = btreeAccessors[i].createSearchCursor(false);
<|startcomment|> MAJOR SonarQube violation: Remove this useless assignment to local variable "failure". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1854 <|endcomment|>  try { indexHelper.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } } try { // will definitely be called regardless of exceptions writer.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } if (closeException != null) { <|startfocus|> throw closeException; <|endfocus|> } } @Override public void doFail() throws HyracksDataException { failed = true; writer.fail(); } } 
<|startcomment|> MAJOR SonarQube violation: Remove this useless assignment to local variable "failure". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1854 <|endcomment|>  indexHelper.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } } try { // will definitely be called regardless of exceptions writer.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } if (closeException != null) { <|startfocus|> throw closeException; <|endfocus|> } } @Override public void doFail() throws HyracksDataException { failed = true; writer.fail(); } } 
<|startcomment|> MAJOR SonarQube violation: Remove this useless assignment to local variable "failure". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1854 <|endcomment|>  } } try { indexHelper.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } } try { // will definitely be called regardless of exceptions writer.close(); } catch (Throwable th) { if (closeException == null) { closeException = new HyracksDataException(th); } else { closeException.addSuppressed(th); } } if (closeException != null) { <|startfocus|> throw closeException; <|endfocus|> } } @Override public void doFail() throws HyracksDataException { failed = true; writer.fail(); } } 
<|startcomment|> HyracksDataException.throwIfNotNull(failure);? <|endcomment|>  .getLongValue()); file.setLastModefiedTime(new Date( ((ADateTime) externalFileRecord.getValueByPos(FilesIndexDescription.EXTERNAL_FILE_MOD_DATE_FIELD_INDEX)) .getChrononTime())); } public void close() throws HyracksDataException { Throwable failure = ResourceReleaseUtils.close(fileIndexSearchCursor, null); failure = DestroyUtils.destroy(fileIndexSearchCursor, failure); failure = DestroyUtils.destroy(fileIndexAccessor, failure); failure = ResourceReleaseUtils.close(indexDataflowHelper, failure); <|startfocus|> if (failure != null) { throw HyracksDataException.create(failure); } <|endfocus|> } } 
<|startcomment|> ignore <|endcomment|>  public static Throwable close(ITupleForwarder tupleForwarder, Throwable root) { if (tupleForwarder != null) { try { tupleForwarder.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); <|startfocus|> } catch (Throwable loggingFailure) { // Do nothing <|endfocus|> } root = ExceptionUtils.suppress(root, th); } } return root;
<|startcomment|> ignore <|endcomment|>  public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); <|startfocus|> } catch (Throwable loggingFailure) { <|endfocus|> // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root;
<|startcomment|> throwIfNotNull <|endcomment|>  try { rangeCursors[i].destroy(); } catch (Throwable th) { // NOSONAR. Must destroy all cursors failure = ExceptionUtils.suppress(failure, th); } } rangeCursors = null; } try { lsmHarness.endScanDiskComponents(opCtx); } catch (Throwable th) { // NOSONAR. Don't lose the root cause failure = ExceptionUtils.suppress(failure, th); } } foundNext = false; <|startfocus|> if (failure != null) { throw HyracksDataException.create(failure); } <|endfocus|> } @Override protected void setPriorityQueueComparator() { if (pqCmp == null || cmp != pqCmp.getMultiComparator()) { pqCmp = new PriorityQueueScanComparator(cmp); } } private class PriorityQueueScanComparator extends PriorityQueueComparator { public PriorityQueueScanComparator(MultiComparator cmp) { super(cmp); } @Override public int compare(PriorityQueueElement elementA, PriorityQueueElement elementB) { int result; try { result = cmp.compare(elementA.getTuple(), elementB.getTuple()); if (result != 0) { return result; }
<|startcomment|> update this <|endcomment|>  */ package org.apache.asterix.test.base; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; import org.junit.rules.TestWatcher; import org.junit.runner.Description; /* * Traces method entry/exit to System.out (or supplied PrintStream). To use, add the following to your test class: * * @Rule * public TestRule watcher = new TestMethodTracer(); * * @Rule <|startfocus|> * public TestRule watcher = new TestMethodTracer(System.err); <|endfocus|> */ public class TestMethodTracer extends TestWatcher { private static final Logger LOGGER = LogManager.getLogger(); @Override protected void starting(Description description) { LOGGER.info("### {} START", description.getMethodName()); } @Override protected void failed(Throwable e, Description description) { LOGGER.info("### {} FAILED ({})", description.getMethodName(), e.getClass().getName()); } @Override protected void succeeded(Description description) { LOGGER.info("### {} SUCCEEDED", description.getMethodName()); } } 
<|startcomment|> BLOCKER SonarQube violation: Catch Exception instead of Throwable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1181 <|endcomment|>  public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable ignore) { // Do nothing } <|startfocus|> root = ExceptionUtils.suppress(root, th); <|endfocus|> } } return root;
<|startcomment|> CRITICAL SonarQube violation: Either log or rethrow this exception. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1166 <|endcomment|>  public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable ignore) { // Do nothing } <|startfocus|> root = ExceptionUtils.suppress(root, th); <|endfocus|> } } return root;
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "root". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  public static Throwable destroy(IDestroyable destroyable, Throwable root) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable ignore) { // Do nothing } <|startfocus|> root = ExceptionUtils.suppress(root, th); <|endfocus|> } } return root;
<|startcomment|> can remove this now, right? <|endcomment|>  } public LSMBTreePointSearchCursor getInsertSearchCursor() { return insertSearchCursor; } public BTreeRangeSearchCursor getMemCursor() { return memCursor; } public LSMBTreeCursorInitialState getSearchInitialState() { return searchInitialState; } public MultiComparator getCmp() { return cmp; } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; Throwable failure = DestroyUtils.destroy(null, mutableBTreeAccessors); failure = DestroyUtils.destroy(failure, mutableBTreeOpCtxs); <|startfocus|> failure = DestroyUtils.destroy(insertSearchCursor, failure); failure = DestroyUtils.destroy(memCursor, failure); <|endfocus|> if (failure != null) { throw HyracksDataException.create(failure); } } } 
<|startcomment|> see comment in DestroyUtils, very confusing to support both parameter orders for DestroyUtils.destroy() <|endcomment|>  public BTreeRangeSearchCursor getMemCursor() { return memCursor; } public LSMBTreeCursorInitialState getSearchInitialState() { return searchInitialState; } public MultiComparator getCmp() { return cmp; } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; Throwable failure = DestroyUtils.destroy(null, mutableBTreeAccessors); failure = DestroyUtils.destroy(failure, mutableBTreeOpCtxs); <|startfocus|> failure = DestroyUtils.destroy(insertSearchCursor, failure); failure = DestroyUtils.destroy(memCursor, failure); <|endfocus|> if (failure != null) { throw HyracksDataException.create(failure); } } } 
<|startcomment|> can't we just have one statement here: Throwable failure = DestroyUtils.destroy(mutableBTreeAccessors, mutableBTreeOpCtxs, insertSearchCursor, memCursor)? <|endcomment|>  return memCursor; } public LSMBTreeCursorInitialState getSearchInitialState() { return searchInitialState; } public MultiComparator getCmp() { return cmp; } @Override public void destroy() throws HyracksDataException { if (destroyed) { return; } destroyed = true; Throwable failure = DestroyUtils.destroy(null, mutableBTreeAccessors); failure = DestroyUtils.destroy(failure, mutableBTreeOpCtxs); <|startfocus|> failure = DestroyUtils.destroy(insertSearchCursor, failure); failure = DestroyUtils.destroy(memCursor, failure); <|endfocus|> if (failure != null) { throw HyracksDataException.create(failure); } } } 
<|startcomment|> Should we pull the trimming of strings out of these function calls and instead create a few well-named local variables? <|endcomment|>  } Function f = new Function(dataverse, getExternalFunctionFullName(libraryName, function.getName().trim()), args.size(), args, function.getReturnType().trim(), function.getDefinition().trim(), library.getLanguage().trim(), function.getFunctionType().trim(), null); MetadataManager.INSTANCE.addFunction(mdTxnCtx, f); if (LOGGER.isInfoEnabled()) { <|startfocus|> LOGGER.info("Installed function: " + getExternalFunctionFullName(libraryName, function.getName().trim())); <|endfocus|> } } } if (LOGGER.isInfoEnabled()) { LOGGER.info("Installed functions in library :" + libraryName); } // Add adapters if (library.getLibraryAdapters() != null) { for (LibraryAdapter adapter : library.getLibraryAdapters().getLibraryAdapter()) { String adapterFactoryClass = adapter.getFactoryClass().trim(); String adapterName = getExternalFunctionFullName(libraryName, adapter.getName().trim()); AdapterIdentifier aid = new AdapterIdentifier(dataverse, adapterName); DatasourceAdapter dsa =
<|startcomment|> Again, is thin one or more parameters? <|endcomment|>  * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.api; import org.apache.asterix.external.library.java.JTypeTag; import org.apache.hyracks.api.exceptions.HyracksDataException; public interface IFunctionHelper { public IJObject getArgument(int index); public IJObject getResultObject(); public void setResult(IJObject result) throws HyracksDataException; public boolean isValidResult(); public IJObject getObject(JTypeTag jtypeTag) throws HyracksDataException; public void reset(); <|startfocus|> public String getParameters(); <|endfocus|> } 
<|startcomment|> One or more parameters? <|endcomment|> import org.apache.hyracks.data.std.api.IDataOutputProvider; import org.apache.hyracks.data.std.api.IValueReference; public class JavaFunctionHelper implements IFunctionHelper { private final IExternalFunctionInfo finfo; private final IDataOutputProvider outputProvider; private final IJObject[] arguments; private IJObject resultHolder; private final IObjectPool<IJObject, IAType> objectPool = new ListObjectPool<>(JTypeObjectFactory.INSTANCE); private final JObjectPointableVisitor pointableVisitor; private final PointableAllocator pointableAllocator; private final Map<Integer, TypeInfo> poolTypeInfo; <|startfocus|> private final String parameters; <|endfocus|> private boolean isValidResult = false; public JavaFunctionHelper(IExternalFunctionInfo finfo, IDataOutputProvider outputProvider, String parameters) throws HyracksDataException { this.finfo = finfo; this.outputProvider = outputProvider; this.pointableVisitor = new JObjectPointableVisitor(); this.pointableAllocator = new PointableAllocator(); this.arguments = new IJObject[finfo.getArgumentList().size()]; int index = 0; for (IAType param : finfo.getArgumentList()) { this.arguments[index++] = objectPool.allocate(param); } this.resultHolder = objectPool.allocate(finfo.getReturnType());
<|startcomment|> same comment above on name, etc. <|endcomment|>  try { while (true) { pageCleanerPolicy.notifyCleanCycleStart(this); int curPage = 0; while (true) { synchronized (cachedPages) { if (curPage >= cachedPages.size()) { break; } CachedPage cPage = (CachedPage) cachedPages.get(curPage); if (cPage != null) { cleanPage(cPage, false); } } curPage++; } if (shutdownStart) { break; } pageCleanerPolicy.notifyCleanCycleFinish(this); } <|startfocus|> } catch (Exception e) { e.printStackTrace(); } finally { shutdownComplete = true; notifyAll(); <|endfocus|> } } } @Override public void close() { closed = true; fifoWriter.destroyQueue(); synchronized (cleanerThread) { cleanerThread.shutdownStart = true; cleanerThread.notifyAll(); while (!cleanerThread.shutdownComplete) { try { cleanerThread.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } synchronized (fileInfoMap) { try {
<|startcomment|> same comment above on name <|endcomment|>  synchronized (cachedPages) { if (curPage >= cachedPages.size()) { break; } CachedPage cPage = (CachedPage) cachedPages.get(curPage); if (cPage != null) { cleanPage(cPage, false); } } curPage++; } if (shutdownStart) { break; } pageCleanerPolicy.notifyCleanCycleFinish(this); } } catch (Exception e) { e.printStackTrace(); } finally { shutdownComplete = true; notifyAll(); <|startfocus|> } <|endfocus|> } } @Override public void close() { closed = true; fifoWriter.destroyQueue(); synchronized (cleanerThread) { cleanerThread.shutdownStart = true; cleanerThread.notifyAll(); while (!cleanerThread.shutdownComplete) { try { cleanerThread.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } synchronized (fileInfoMap) { try { for (Map.Entry<Integer, BufferedFileHandle> entry : fileInfoMap.entrySet()) {
<|startcomment|> same comment above on name <|endcomment|>  public void close() { closed = true; fifoWriter.destroyQueue(); <|startfocus|> synchronized (cleanerThread) { cleanerThread.shutdownStart = true; cleanerThread.notifyAll(); while (!cleanerThread.shutdownComplete) { try { cleanerThread.wait(); } catch (InterruptedException e) { e.printStackTrace(); <|endfocus|> } } } synchronized (fileInfoMap) { try { for (Map.Entry<Integer, BufferedFileHandle> entry : fileInfoMap.entrySet()) { boolean fileHasBeenDeleted = entry.getValue().fileHasBeenDeleted(); sweepAndFlush(entry.getKey(), !fileHasBeenDeleted); if (!fileHasBeenDeleted) { ioManager.close(entry.getValue().getFileHandle()); } } } catch (HyracksDataException e) { e.printStackTrace(); } fileInfoMap.clear(); }
<|startcomment|> why is the queue empty? <|endcomment|>  CachedPage cPage = bucket.cachedPage; bucket.cachedPage = bucket.cachedPage.next; cPage.next = null; } } } finally { bucket.bucketLock.unlock(); } } } private boolean invalidateIfFileIdMatch(int fileId, CachedPage cPage, boolean flushDirtyPages) throws HyracksDataException { if (BufferedFileHandle.getFileId(cPage.dpid) == fileId) { <|startfocus|> int pinCount = -1; <|endfocus|> if (cPage.dirty.get()) { if (flushDirtyPages) { write(cPage); } cPage.dirty.set(false); pinCount = cPage.pinCount.decrementAndGet(); } else { pinCount = cPage.pinCount.get(); } if (pinCount > 0) { throw new IllegalStateException("Page " + BufferedFileHandle.getFileId(cPage.dpid) + ":" + BufferedFileHandle.getPageId(cPage.dpid) + " is pinned and file is being closed. Pincount is: " + pinCount + " Page is confiscated: " + cPage.confiscated); } cPage.invalidate(); return true; }
<|startcomment|> MAJOR SonarQube violation: Reduce the total number of break and continue statements in this loop to use at most one. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS135 <|endcomment|>  isFinishedSearch = true; invListMerger.close(); finalSearchResult.finalizeWrite(); return true; } return false; } // Finished one partition for the both cases #1 and #2. So, moves to the next partition. curPartIdx++; if (curPartIdx <= endPartIdx) { boolean suitablePartFound = false; for (int i = curPartIdx; i <= endPartIdx; i++) { // Prune partition because no element in it can satisfy the occurrence threshold. <|startfocus|> if (partitionCursors[i] == null || partitionCursors[i].size() < occurrenceThreshold) { <|endfocus|> continue; } suitablePartFound = true; curPartIdx = i; break; } // If no partition is availble to explore, we stop here. if (!suitablePartFound) { isFinishedSearch = true; invListMerger.close(); finalSearchResult.finalizeWrite(); return true; } // Merge inverted lists of current partition. numPrefixLists = searchModifier.getNumPrefixLists(occurrenceThreshold, partitionCursors[curPartIdx].size()); invListMerger.reset(); finalSearchResult.resetBuffer();
<|startcomment|> MAJOR SonarQube violation: Reduce this anonymous class number of lines from 124 to at most 20, or make it a named class. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1188 <|endcomment|>  this.argTypes = argTypes; this.failOnArgTypeMismatch = failOnArgTypeMismatch; } @Override public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException { final IScalarEvaluator[] argEvals = new IScalarEvaluator[args.length]; final IPointable[] argPtrs = new IPointable[args.length]; for (int i = 0; i < args.length; i++) { argEvals[i] = args[i].createScalarEvaluator(ctx); argPtrs[i] = new VoidPointable(); } return new IScalarEvaluator() { <|startfocus|> final ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); final DataOutput resultOutput = resultStorage.getDataOutput(); <|endfocus|> final ARecordVisitablePointable openRecordPointable = new ARecordVisitablePointable(DefaultOpenFieldType.NESTED_OPEN_RECORD_TYPE); final ARecordVisitablePointable[] argVisitablePointables; final BitSet castRequired; final ACastVisitor castVisitor; final Triple<IVisitablePointable, IAType, Boolean> castVisitorArg; final RecordBuilder outRecordBuilder = new RecordBuilder(); final BinaryEntry keyEntry = new BinaryEntry(); final BinaryEntry valEntry = new BinaryEntry(); final BinaryHashMap fieldMap =
<|startcomment|> MAJOR SonarQube violation: Move the contents of this initializer to a standard constructor or to field initializers. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1171 <|endcomment|>  final BitSet castRequired; final ACastVisitor castVisitor; final Triple<IVisitablePointable, IAType, Boolean> castVisitorArg; final RecordBuilder outRecordBuilder = new RecordBuilder(); final BinaryEntry keyEntry = new BinaryEntry(); final BinaryEntry valEntry = new BinaryEntry(); final BinaryHashMap fieldMap = new BinaryHashMap(TABLE_SIZE, TABLE_FRAME_SIZE, outRecordBuilder.getFieldNameHashFunction(), outRecordBuilder.getFieldNameHashFunction(), outRecordBuilder.getFieldNameComparator()); <|startfocus|> { outRecordBuilder.reset(openRecordPointable.getInputRecordType()); valEntry.set(new byte[0], 0, 0); <|endfocus|> int argCount = argEvals.length; ARecordVisitablePointable[] vp = new ARecordVisitablePointable[argCount]; BitSet cr = new BitSet(); ACastVisitor cv = null; Triple<IVisitablePointable, IAType, Boolean> ca = null; for (int i = 0; i < argCount; i++) { ARecordType argType = argTypes[i]; if (argType != null) { vp[i] = new ARecordVisitablePointable(argType); if (hasDerivedType(argType.getFieldTypes())) {
<|startcomment|> class/enum names start with a capital letter, so should be "SecondaryUnnestMapOutputVarType" <|endcomment|> import org.apache.hyracks.algebricks.core.algebra.operators.logical.visitors.VariableUtilities; import org.apache.hyracks.algebricks.core.algebra.plan.ALogicalPlanImpl; import org.apache.hyracks.algebricks.core.algebra.util.OperatorPropertiesUtil; import org.apache.hyracks.api.exceptions.HyracksDataException; import org.apache.hyracks.storage.am.lsm.invertedindex.tokenizers.DelimitedUTF8StringBinaryTokenizer; /** * Static helper functions for rewriting plans using indexes. */ public class AccessMethodUtils { // Output variable type from a secondary unnest-map <|startfocus|> enum secondaryUnnestMapOutputVarType { <|endfocus|> PRIMARY_KEY, SECONDARY_KEY, CONDITIONAL_SPLIT_VAR } public static void appendPrimaryIndexTypes(Dataset dataset, IAType itemType, IAType metaItemType, List<Object> target) throws AlgebricksException { ARecordType recordType = (ARecordType) itemType; ARecordType metaRecordType = (ARecordType) metaItemType; target.addAll(KeyFieldTypeUtil.getPartitoningKeyTypes(dataset, recordType, metaRecordType)); // Adds data record type. target.add(itemType); // Adds meta record type if any. if (dataset.hasMetaPart()) { target.add(metaItemType); } } 
<|startcomment|> Need to throw this exception. <|endcomment|>  switch (keyVarType) { case PRIMARY_KEY: // Fetches primary keys - the second position start = numSecondaryKeys; stop = numSecondaryKeys + numPrimaryKeys; break; case SECONDARY_KEY: // Fetches secondary keys - the first position start = 0; stop = numSecondaryKeys; break; case CONDITIONAL_SPLIT_VAR: // Sanity check - the given unnest map should generate this variable. if (!abstractUnnestMapOp.getGenerateCallBackProceedResultVar()) { <|startfocus|> CompilationException.create(ErrorCode.CANNOT_GET_CONDITIONAL_SPLIT_KEY_VARIABLE); <|endfocus|> } // Fetches conditional splitter - the last position start = numSecondaryKeys + numPrimaryKeys; stop = start + 1; break; default: return Collections.emptyList(); } for (int i = start; i < stop; i++) { keyVars.add(sourceVars.get(i)); } return keyVars; } public static List<LogicalVariable> getPrimaryKeyVarsFromPrimaryUnnestMap(Dataset dataset, ILogicalOperator unnestMapOp) { int numPrimaryKeys = dataset.getPrimaryKeys().size();
<|startcomment|> unnestMapMemorySize = textSearchMemorySize + frameSize? This is because we will also allocate the operator frame for writing the result to be consumed by the next operator <|endcomment|>  case UPDATE: case WRITE: case WRITE_RESULT: case INDEX_INSERT_DELETE_UPSERT: case INSERT_DELETE_UPSERT: case INTERSECT: return getOperatorRequiredMemory(operator, frameSize); case LEFT_OUTER_UNNEST_MAP: case UNNEST_MAP: // Since an inverted-index search requires certain amount of memory, needs to calculate // the memory size differently if the given index-search is an inverted-index search. long unnestMapMemorySize = frameSize; if (isInvertedIndexSearch((AbstractUnnestMapOperator) operator)) { <|startfocus|> unnestMapMemorySize = textSearchMemorySize; <|endfocus|> } return getOperatorRequiredMemory(operator, unnestMapMemorySize); case EXCHANGE: return getExchangeRequiredMemory((ExchangeOperator) operator); case GROUP: return getOperatorRequiredMemory(operator, groupByMemorySize); case ORDER: return getOperatorRequiredMemory(operator, sortMemorySize); case INNERJOIN: case LEFTOUTERJOIN: return getOperatorRequiredMemory(operator, joinMemorySize); default: throw new IllegalStateException("Unrecognized operator: " + operator.getOperatorTag()); }
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "root". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  public static Throwable destroy(Throwable root, IDestroyable... destroyables) { for (IDestroyable destroyable : destroyables) { if (destroyable != null) { try { destroyable.destroy(); } catch (Throwable th) { // NOSONAR. Had to be done to satisfy contracts try { LOGGER.log(Level.WARN, "Failure destroying a destroyable resource", th); } catch (Throwable loggingFailure) { // NOSONAR // Do nothing } <|startfocus|> root = ExceptionUtils.suppress(root, th); <|endfocus|> } } } return root;
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "root". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  public static Throwable close(IFrameWriter writer, Throwable root) { if (writer != null) { try { writer.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); } catch (Throwable loggingFailure) { // NOSONAR // Do nothing } <|startfocus|> root = ExceptionUtils.suppress(root, th); <|endfocus|> } } return root;
<|startcomment|> should we add HttpServer as a method parameter, and return server.getCHannelCloseHandler() here? it might make use of this less clunky, but no strong preference <|endcomment|>  */ String[] getPaths(); /** * @return the context associated with this IServlet */ ConcurrentMap<String, Object> ctx(); /** * handle the IServletRequest writing the response in the passed IServletResponse * * @param request * @param response */ void handle(IServletRequest request, IServletResponse response); /** * @return the handler for channel close events */ <|startfocus|> default IChannelCloseHandler getChannelCloseHandler() { return null; <|endfocus|> } } 
<|startcomment|> we need an overall timeout for all completions before we...? <|endcomment|>  Collection<Task> tasks = joblet.getTaskMap().values(); for (Task task : tasks) { task.abort(); allTasks.add(task); } final JobId jobId = joblet.getJobId(); if (dpm != null) { dpm.abortReader(jobId); dpm.sweep(jobId); } ncs.getWorkQueue().schedule(new CleanupJobletWork(ncs, jobId, JobStatus.FAILURE)); }); <|startfocus|> for (int i = 0; i < allTasks.size(); i++) { allTasks.get(i).awaitCompletion(); } <|endfocus|> } } 
<|startcomment|> MAJOR SonarQube violation: Make this final field static too. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1170 <|endcomment|>  import java.io.DataOutput; import java.io.IOException; import java.util.LinkedHashMap; import java.util.Map; public final class JRecord implements IJObject { private ARecordType recordType; private IJObject[] fields; private Map<String, IJObject> openFields; RecordBuilder recordBuilder = new RecordBuilder(); ArrayBackedValueStorage fieldName = new ArrayBackedValueStorage(); ArrayBackedValueStorage fieldValue = new ArrayBackedValueStorage(); AMutableString nameString = new AMutableString(""); <|startfocus|> private final AStringSerializerDeserializer aStringSerDer = AStringSerializerDeserializer.INSTANCE; <|endfocus|> public JRecord(ARecordType recordType, IJObject[] fields) { this.recordType = recordType; this.fields = fields; this.openFields = new LinkedHashMap<>(); } public JRecord(ARecordType recordType, IJObject[] fields, LinkedHashMap<String, IJObject> openFields) { this(recordType, fields); this.openFields = openFields; } public void addField(String fieldName, IJObject fieldValue) throws HyracksDataException { int pos = getFieldPosByName(fieldName); if (pos >= 0) {
<|startcomment|> MAJOR SonarQube violation: The type of the "openFields" object should be an interface such as "Map" rather than the implementation "LinkedHashMap". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1319 <|endcomment|> <|startfocus|> public JRecord(ARecordType recordType, IJObject[] fields, LinkedHashMap<String, IJObject> openFields) { <|endfocus|> this(recordType, fields); this.openFields = openFields;
<|startcomment|> MAJOR SonarQube violation: The type of the "openFields" object should be an interface such as "Map" rather than the implementation "LinkedHashMap". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1319 <|endcomment|>  return new ARecord(mergedRecordType, mergedFields); } @Override public void reset() throws HyracksDataException { if (openFields != null && !openFields.isEmpty()) { openFields.clear(); } if (fields != null) { for (IJObject field : fields) { if (field != null) { field.reset(); } } } } <|startfocus|> public void reset(IJObject[] fields, LinkedHashMap<String, IJObject> openFields) throws HyracksDataException { <|endfocus|> this.reset(); this.fields = fields; this.openFields = openFields; } } 
<|startcomment|> MAJOR SonarQube violation: Add a private constructor to hide the implicit public one. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1118 <|endcomment|>  * * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { <|startfocus|> public static JBuiltinType JBooleanType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() {
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JBooleanType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { <|startfocus|> public static JBuiltinType JBooleanType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } };
<|startcomment|> MAJOR SonarQube violation: Make JBooleanType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { <|startfocus|> public static JBuiltinType JBooleanType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } };
<|startcomment|> MAJOR SonarQube violation: Rename this field "JBooleanType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { <|startfocus|> public static JBuiltinType JBooleanType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } };
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JByteType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; <|startfocus|> public static JBuiltinType JByteType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override
<|startcomment|> MAJOR SonarQube violation: Make JByteType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; <|startfocus|> public static JBuiltinType JByteType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override
<|startcomment|> MAJOR SonarQube violation: Rename this field "JByteType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base.builtin; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; <|startfocus|> public static JBuiltinType JByteType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JCircleType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; <|startfocus|> public static JBuiltinType JCircleType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() {
<|startcomment|> MAJOR SonarQube violation: Make JCircleType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; <|startfocus|> public static JBuiltinType JCircleType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() {
<|startcomment|> MAJOR SonarQube violation: Rename this field "JCircleType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; public abstract class JBuiltinType implements IJType { public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; <|startfocus|> public static JBuiltinType JCircleType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() {
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JDateType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; <|startfocus|> public static JBuiltinType JDateType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; 
<|startcomment|> MAJOR SonarQube violation: Make JDateType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; <|startfocus|> public static JBuiltinType JDateType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; 
<|startcomment|> MAJOR SonarQube violation: Rename this field "JDateType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  public static JBuiltinType JBooleanType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; <|startfocus|> public static JBuiltinType JDateType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; 
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JDateTimeType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; <|startfocus|> public static JBuiltinType JDateTimeType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; 
<|startcomment|> MAJOR SonarQube violation: Make JDateTimeType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; <|startfocus|> public static JBuiltinType JDateTimeType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; 
<|startcomment|> MAJOR SonarQube violation: Rename this field "JDateTimeType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JByteType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; <|startfocus|> public static JBuiltinType JDateTimeType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; 
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JDoubleType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; <|startfocus|> public static JBuiltinType JDoubleType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; 
<|startcomment|> MAJOR SonarQube violation: Make JDoubleType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; <|startfocus|> public static JBuiltinType JDoubleType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; 
<|startcomment|> MAJOR SonarQube violation: Rename this field "JDoubleType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JCircleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; <|startfocus|> public static JBuiltinType JDoubleType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; 
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JDurationType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; <|startfocus|> public static JBuiltinType JDurationType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; 
<|startcomment|> MAJOR SonarQube violation: Make JDurationType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; <|startfocus|> public static JBuiltinType JDurationType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; 
<|startcomment|> MAJOR SonarQube violation: Rename this field "JDurationType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JDateType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATE; } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; <|startfocus|> public static JBuiltinType JDurationType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; 
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JFloatType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; <|startfocus|> public static JBuiltinType JFloatType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } };
<|startcomment|> MAJOR SonarQube violation: Make JFloatType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; <|startfocus|> public static JBuiltinType JFloatType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } };
<|startcomment|> MAJOR SonarQube violation: Rename this field "JFloatType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JDateTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADATETIME; } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; <|startfocus|> public static JBuiltinType JFloatType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } };
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JIntType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; <|startfocus|> public static JBuiltinType JIntType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } };
<|startcomment|> MAJOR SonarQube violation: Make JIntType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; <|startfocus|> public static JBuiltinType JIntType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } };
<|startcomment|> MAJOR SonarQube violation: Rename this field "JIntType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JDoubleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADOUBLE; } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; <|startfocus|> public static JBuiltinType JIntType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } };
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JIntervalType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; <|startfocus|> public static JBuiltinType JIntervalType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } };
<|startcomment|> MAJOR SonarQube violation: Make JIntervalType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; <|startfocus|> public static JBuiltinType JIntervalType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } };
<|startcomment|> MAJOR SonarQube violation: Rename this field "JIntervalType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JDurationType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ADURATION; } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; <|startfocus|> public static JBuiltinType JIntervalType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } };
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JLineType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; <|startfocus|> public static JBuiltinType JLineType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } };
<|startcomment|> MAJOR SonarQube violation: Make JLineType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; <|startfocus|> public static JBuiltinType JLineType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } };
<|startcomment|> MAJOR SonarQube violation: Rename this field "JLineType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JFloatType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AFLOAT; } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; <|startfocus|> public static JBuiltinType JLineType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } };
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JLongType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; <|startfocus|> public static JBuiltinType JLongType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } };
<|startcomment|> MAJOR SonarQube violation: Make JLongType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; <|startfocus|> public static JBuiltinType JLongType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } };
<|startcomment|> MAJOR SonarQube violation: Rename this field "JLongType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JIntType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT32; } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; <|startfocus|> public static JBuiltinType JLongType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } };
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JMissingType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; <|startfocus|> public static JBuiltinType JMissingType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } };
<|startcomment|> MAJOR SonarQube violation: Make JMissingType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; <|startfocus|> public static JBuiltinType JMissingType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } };
<|startcomment|> MAJOR SonarQube violation: Rename this field "JMissingType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JIntervalType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; <|startfocus|> public static JBuiltinType JMissingType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } };
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JNullType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; <|startfocus|> public static JBuiltinType JNullType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } };
<|startcomment|> MAJOR SonarQube violation: Make JNullType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; <|startfocus|> public static JBuiltinType JNullType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } };
<|startcomment|> MAJOR SonarQube violation: Rename this field "JNullType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JLineType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ALINE; } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; <|startfocus|> public static JBuiltinType JNullType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } };
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JPointType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; <|startfocus|> public static JBuiltinType JPointType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } };
<|startcomment|> MAJOR SonarQube violation: Make JPointType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; <|startfocus|> public static JBuiltinType JPointType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } };
<|startcomment|> MAJOR SonarQube violation: Rename this field "JPointType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JLongType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT64; } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; <|startfocus|> public static JBuiltinType JPointType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } };
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JPoint3DType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; <|startfocus|> public static JBuiltinType JPoint3DType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } };
<|startcomment|> MAJOR SonarQube violation: Make JPoint3DType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; <|startfocus|> public static JBuiltinType JPoint3DType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } };
<|startcomment|> MAJOR SonarQube violation: Rename this field "JPoint3DType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JMissingType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AMISSING; } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; <|startfocus|> public static JBuiltinType JPoint3DType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } };
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JPolygonType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; <|startfocus|> public static JBuiltinType JPolygonType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } };
<|startcomment|> MAJOR SonarQube violation: Make JPolygonType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; <|startfocus|> public static JBuiltinType JPolygonType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } };
<|startcomment|> MAJOR SonarQube violation: Rename this field "JPolygonType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JNullType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ANULL; } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; <|startfocus|> public static JBuiltinType JPolygonType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } };
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JRectangleType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; <|startfocus|> public static JBuiltinType JRectangleType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; } 
<|startcomment|> MAJOR SonarQube violation: Make JRectangleType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; <|startfocus|> public static JBuiltinType JRectangleType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; } 
<|startcomment|> MAJOR SonarQube violation: Rename this field "JRectangleType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JPointType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT; } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; <|startfocus|> public static JBuiltinType JRectangleType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; } 
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JShortType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; <|startfocus|> public static JBuiltinType JShortType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; } 
<|startcomment|> MAJOR SonarQube violation: Make JShortType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; <|startfocus|> public static JBuiltinType JShortType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; } 
<|startcomment|> MAJOR SonarQube violation: Rename this field "JShortType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JPoint3DType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOINT3D; } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; <|startfocus|> public static JBuiltinType JShortType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; } 
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JStringType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; <|startfocus|> public static JBuiltinType JStringType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; } 
<|startcomment|> MAJOR SonarQube violation: Make JStringType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; <|startfocus|> public static JBuiltinType JStringType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; } 
<|startcomment|> MAJOR SonarQube violation: Rename this field "JStringType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JPolygonType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.APOLYGON; } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; <|startfocus|> public static JBuiltinType JStringType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; public static JBuiltinType JTimeType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ATIME; } }; } 
<|startcomment|> CRITICAL SonarQube violation: Make this "public static JTimeType" field final Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1444 <|endcomment|>  } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; <|startfocus|> public static JBuiltinType JTimeType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ATIME; } }; } 
<|startcomment|> MAJOR SonarQube violation: Make JTimeType a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; <|startfocus|> public static JBuiltinType JTimeType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ATIME; } }; } 
<|startcomment|> MAJOR SonarQube violation: Rename this field "JTimeType" to match the regular expression '^[a-z][a-zA-Z0-9]*$'. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS3008 <|endcomment|>  } }; public static JBuiltinType JRectangleType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ARECTANGLE; } }; public static JBuiltinType JShortType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.AINT8; } }; public static JBuiltinType JStringType = new JBuiltinType() { @Override public IAType getIAType() { return BuiltinType.ASTRING; } }; <|startfocus|> public static JBuiltinType JTimeType = new JBuiltinType() { <|endfocus|> @Override public IAType getIAType() { return BuiltinType.ATIME; } }; } 
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  ((AMutableCircle) (value)).setValue((APoint) center.getIAObject(), radius); } @Override public IAType getIAType() { return BuiltinType.ACIRCLE; } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.CIRCLE.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } <|startfocus|> ACircleSerializerDeserializer.INSTANCE.serialize(((AMutableCircle) (value)), dataOutput); <|endfocus|> } @Override public void reset() { ((AMutableCircle) value).setValue(null, 0); } } 
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  public JDate(int chrononTimeInDays) { super(new AMutableDate(chrononTimeInDays)); } public void setValue(int chrononTimeInDays) { ((AMutableDate) value).setValue(chrononTimeInDays); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.DATE.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } <|startfocus|> ADateSerializerDeserializer.INSTANCE.serialize(((AMutableDate) value), dataOutput); <|endfocus|> } @Override public void reset() { ((AMutableDate) value).setValue(0); } @Override public IAType getIAType() { return BuiltinType.ADATE; } } 
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  public JDateTime(long chrononTime) { super(new AMutableDateTime(chrononTime)); } public void setValue(long chrononTime) { ((AMutableDateTime) value).setValue(chrononTime); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.DATETIME.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } <|startfocus|> ADateTimeSerializerDeserializer.INSTANCE.serialize(((AMutableDateTime) value), dataOutput); <|endfocus|> } @Override public void reset() { ((AMutableDateTime) value).setValue(0); } @Override public IAType getIAType() { return BuiltinType.ADATETIME; } } 
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  super(new AMutableDuration(months, milliseconds)); } public void setValue(int months, long milliseconds) { ((AMutableDuration) value).setValue(months, milliseconds); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.DURATION.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } <|startfocus|> ADurationSerializerDeserializer.INSTANCE.serialize(((AMutableDuration) value), dataOutput); <|endfocus|> } @Override public void reset() { ((AMutableDuration) value).setValue(0, 0); } @Override public IAType getIAType() { return BuiltinType.ADURATION; } } 
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  } public long getIntervalEnd() { return ((AMutableInterval) value).getIntervalEnd(); } public short getIntervalType() { return ((AMutableInterval) value).getIntervalType(); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.INTERVAL.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } <|startfocus|> AIntervalSerializerDeserializer.INSTANCE.serialize(((AMutableInterval) value), dataOutput); <|endfocus|> } @Override public void reset() throws HyracksDataException { ((AMutableInterval) value).setValue(0L, 0L, (byte) 0); } @Override public IAType getIAType() { return BuiltinType.AINTERVAL; } } 
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  } public void setValue(APoint p1, APoint p2) { ((AMutableLine) value).setValue(p1, p2); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.LINE.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } <|startfocus|> ALineSerializerDeserializer.INSTANCE.serialize(((AMutableLine) value), dataOutput); <|endfocus|> } @Override public void reset() { ((AMutableLine) value).setValue(null, null); } @Override public IAType getIAType() { return BuiltinType.ALINE; } } 
<|startcomment|> MAJOR SonarQube violation: Add a nested comment explaining why this method is empty, throw an UnsupportedOperationException or complete the implementation. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1186 <|endcomment|> <|startfocus|> public void reset() { <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  public double getYValue() { return ((AMutablePoint3D) value).getY(); } public double getZValue() { return ((AMutablePoint3D) value).getZ(); } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { if (writeTypeTag) { try { dataOutput.writeByte(ATypeTag.POINT3D.serialize()); } catch (IOException e) { throw new HyracksDataException(e); } } <|startfocus|> APoint3DSerializerDeserializer.INSTANCE.serialize(((AMutablePoint3D) value), dataOutput); <|endfocus|> } @Override public void reset() { ((AMutablePoint3D) value).setValue(0, 0, 0); } @Override public IAType getIAType() { return BuiltinType.APOINT3D; } } 
<|startcomment|> CRITICAL SonarQube violation: Equality tests should not be made with floating point values. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1244 <|endcomment|>  builder.appendString(String.valueOf(i)); break; } case BIGINT: { long l = AInt64SerializerDeserializer.getLong(serString, startOffset); builder.appendString(String.valueOf(l)); break; } case DOUBLE: { double d = ADoubleSerializerDeserializer.getDouble(serString, startOffset); if (Double.isNaN(d)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (d == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); <|startfocus|> } else if (d == Double.NEGATIVE_INFINITY) { <|endfocus|> builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Double.NEGATIVE_INFINITY) {
<|startcomment|> CRITICAL SonarQube violation: Equality tests should not be made with floating point values. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1244 <|endcomment|>  break; } case BIGINT: { long l = AInt64SerializerDeserializer.getLong(serString, startOffset); builder.appendString(String.valueOf(l)); break; } case DOUBLE: { double d = ADoubleSerializerDeserializer.getDouble(serString, startOffset); if (Double.isNaN(d)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (d == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); <|startfocus|> } else if (d == Double.NEGATIVE_INFINITY) { <|endfocus|> builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Double.NEGATIVE_INFINITY) {
<|startcomment|> CRITICAL SonarQube violation: Equality tests should not be made with floating point values. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1244 <|endcomment|>  } else if (d == Double.NEGATIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); <|startfocus|> } else if (f == Double.NEGATIVE_INFINITY) { <|endfocus|> builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(f)); } break; } case BOOLEAN: { boolean b = ABooleanSerializerDeserializer.getBoolean(serString, startOffset); builder.appendString(String.valueOf(b)); break; } // NotYetImplemented case CIRCLE: case DATE: case DATETIME: case LINE: case TIME: case DURATION: case YEARMONTHDURATION: case DAYTIMEDURATION: case INTERVAL: case ARRAY: case POINT:
<|startcomment|> CRITICAL SonarQube violation: Equality tests should not be made with floating point values. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1244 <|endcomment|>  builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); <|startfocus|> } else if (f == Double.NEGATIVE_INFINITY) { <|endfocus|> builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(f)); } break; } case BOOLEAN: { boolean b = ABooleanSerializerDeserializer.getBoolean(serString, startOffset); builder.appendString(String.valueOf(b)); break; } // NotYetImplemented case CIRCLE: case DATE: case DATETIME: case LINE: case TIME: case DURATION: case YEARMONTHDURATION: case DAYTIMEDURATION: case INTERVAL: case ARRAY: case POINT: case POINT3D: case RECTANGLE: case POLYGON:
<|startcomment|> Add // NOSONAR at the end of the line. <|endcomment|>  builder.appendString(String.valueOf(i)); break; } case BIGINT: { long l = AInt64SerializerDeserializer.getLong(serString, startOffset); builder.appendString(String.valueOf(l)); break; } case DOUBLE: { double d = ADoubleSerializerDeserializer.getDouble(serString, startOffset); if (Double.isNaN(d)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (d == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); <|startfocus|> } else if (d == Double.NEGATIVE_INFINITY) { <|endfocus|> builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); } else if (f == Double.NEGATIVE_INFINITY) {
<|startcomment|> Float <|endcomment|>  } else if (d == Double.NEGATIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(d)); } break; } case FLOAT: { float f = AFloatSerializerDeserializer.getFloat(serString, startOffset); if (Float.isNaN(f)) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NAN); } else if (f == Double.POSITIVE_INFINITY) { builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.POSITIVE_INF); <|startfocus|> } else if (f == Double.NEGATIVE_INFINITY) { <|endfocus|> builder.appendUtf8StringPointable(AbstractDoubleConstructorEvaluator.NEGATIVE_INF); } else { builder.appendString(String.valueOf(f)); } break; } case BOOLEAN: { boolean b = ABooleanSerializerDeserializer.getBoolean(serString, startOffset); builder.appendString(String.valueOf(b)); break; } // NotYetImplemented case CIRCLE: case DATE: case DATETIME: case LINE: case TIME: case DURATION: case YEARMONTHDURATION: case DAYTIMEDURATION: case INTERVAL: case ARRAY: case POINT:
<|startcomment|> replace this by flushIfNeeded and move the < 0 check to decrementNumActiveOperations <|endcomment|>  completeOperation(index, opType, searchCallback, modificationCallback); } } @Override public synchronized void completeOperation(ILSMIndex index, LSMOperationType opType, ISearchOperationCallback searchCallback, IModificationOperationCallback modificationCallback) throws HyracksDataException { if (opType == LSMOperationType.MODIFICATION || opType == LSMOperationType.FORCE_MODIFICATION) { decrementNumActiveOperations(modificationCallback); <|startfocus|> if (numActiveOperations.get() == 0) { flushIfRequested(); } else if (numActiveOperations.get() < 0) { throw new HyracksDataException("The number of active operations cannot be negative!"); } <|endfocus|> } else if (opType == LSMOperationType.FLUSH || opType == LSMOperationType.MERGE || opType == LSMOperationType.REPLICATE) { dsInfo.undeclareActiveIOOperation(); } } public synchronized void flushIfNeeded() throws HyracksDataException { if (numActiveOperations.get() == 0) { flushIfRequested(); } } public void flushIfRequested() throws HyracksDataException { // If we need a flush, and this is the last completing operation, then schedule the flush,
<|startcomment|> BLOCKER SonarQube violation: Catch Exception instead of Throwable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1181 <|endcomment|>  public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); <|startfocus|> } catch (Throwable loggingFailure) { // Do nothing <|endfocus|> } root = ExceptionUtils.suppress(root, th); } } return root;
<|startcomment|> CRITICAL SonarQube violation: Either log or rethrow this exception. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1166 <|endcomment|>  public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); <|startfocus|> } catch (Throwable loggingFailure) { // Do nothing <|endfocus|> } root = ExceptionUtils.suppress(root, th); } } return root;
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "root". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); } catch (Throwable loggingFailure) { // Do nothing } <|startfocus|> root = ExceptionUtils.suppress(root, th); <|endfocus|> } } return root;
<|startcomment|> CRITICAL SonarQube violation: Either re-interrupt this method or rethrow the "InterruptedException". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2142 <|endcomment|>  } public void write(IFileHandle fHandle, long offset, ByteBuffer data) throws HyracksDataException { if (state != State.INITIAL) { throw new IllegalStateException("Can't request a read operation through a " + state + " request"); } state = State.WRITE_REQUESTED; this.fHandle = fHandle; this.offset = offset; this.data = data; queue(); } private void queue() throws HyracksDataException { try { submittedRequests.put(this); <|startfocus|> } catch (InterruptedException e) { <|endfocus|> throw HyracksDataException.create(e); } } @Override public void await() throws InterruptedException { synchronized (this) { while (state != State.OPERATION_FAILED && state != State.OPERATION_SUCCEEDED) { wait(); } } } synchronized void handle() { try { if (state == State.READ_REQUESTED) { read = ioManager.doSyncRead(fHandle, offset, data); } else if (state == State.WRITE_REQUESTED) { if (data != null) { // single buffer
<|startcomment|> BLOCKER SonarQube violation: Catch Exception instead of Throwable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1181 <|endcomment|>  read = ioManager.doSyncRead(fHandle, offset, data); } else if (state == State.WRITE_REQUESTED) { if (data != null) { // single buffer write = ioManager.doSyncWrite(fHandle, offset, data); } else { // multiple buffers writes = ioManager.doSyncWrite(fHandle, offset, dataArray); } } else { throw new IllegalStateException("IO Request with state = " + state); } state = State.OPERATION_SUCCEEDED; <|startfocus|> } catch (Throwable th) { <|endfocus|> state = State.OPERATION_FAILED; failure = HyracksDataException.create(th); } notifyAll(); } public State getState() { return state; } void recycle() { reset(); freeRequests.offer(this); } public int getRead() { return read; } public int getWrite() { return write; } public long getWrites() { return writes; } @Override public void run() throws InterruptedException { await(); } public HyracksDataException getFailure() { return failure;
<|startcomment|> MAJOR SonarQube violation: Reduce the total number of break and continue statements in this loop to use at most one. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS135 <|endcomment|>  public void run() { Thread.currentThread().setName(getClass().getSimpleName() + "-" + num); <|startfocus|> while (true) { <|endfocus|> IoRequest next; try { next = queue.take(); } catch (InterruptedException e) { LOGGER.log(Level.WARN, "Ignoring interrupt. IO threads should never be interrupted."); continue; } if (next == POISON_PILL) { LOGGER.log(Level.INFO, "Exiting"); InvokeUtil.doUninterruptibly(() -> queue.put(POISON_PILL)); if (Thread.interrupted()) { LOGGER.log(Level.ERROR, "Ignoring interrupt. IO threads should never be interrupted."); } break; } next.handle(); }
<|startcomment|> CRITICAL SonarQube violation: Either re-interrupt this method or rethrow the "InterruptedException". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2142 <|endcomment|>  public void run() { Thread.currentThread().setName(getClass().getSimpleName() + "-" + num); while (true) { IoRequest next; try { next = queue.take(); <|startfocus|> } catch (InterruptedException e) { <|endfocus|> LOGGER.log(Level.WARN, "Ignoring interrupt. IO threads should never be interrupted."); continue; } if (next == POISON_PILL) { LOGGER.log(Level.INFO, "Exiting"); InvokeUtil.doUninterruptibly(() -> queue.put(POISON_PILL)); if (Thread.interrupted()) { LOGGER.log(Level.ERROR, "Ignoring interrupt. IO threads should never be interrupted."); } break; } next.handle(); }
<|startcomment|> suppressed <|endcomment|>  public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); <|startfocus|> } catch (Throwable th) { // NOSONAR Will be re-thrown <|endfocus|> try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); } catch (Throwable loggingFailure) { // Do nothing } root = ExceptionUtils.suppress(root, th); } } return root;
<|startcomment|> Suppress SQ warnings? <|endcomment|>  public static Throwable close(AutoCloseable closable, Throwable root) { if (closable != null) { try { closable.close(); } catch (Throwable th) { // NOSONAR Will be re-thrown try { LOGGER.log(Level.WARN, "Failure closing a closeable resource", th); <|startfocus|> } catch (Throwable loggingFailure) { // Do nothing <|endfocus|> } root = ExceptionUtils.suppress(root, th); } } return root;
<|startcomment|> Move this close to the other asyncWrite method? <|endcomment|>  executor.execute(req); return req; } @Override public void close(IFileHandle fHandle) throws HyracksDataException { try { ((FileHandle) fHandle).close(); } catch (IOException e) { throw new HyracksDataException(e); } } public synchronized FileReference createWorkspaceFile(String prefix) throws HyracksDataException { IODeviceHandle dev = workAreaIODevices.get(workAreaDeviceIndex); workAreaDeviceIndex = (workAreaDeviceIndex + 1) % workAreaIODevices.size(); String waPath = dev.getWorkAreaPath(); File waf; try { <|startfocus|> waf = File.createTempFile(prefix, WORKSPACE_FILE_SUFFIX, new File(dev.getPath(), waPath)); <|endfocus|> } catch (IOException e) { throw new HyracksDataException(e); } return dev.createFileReference(waPath + File.separator + waf.getName()); } private abstract class AsyncRequest implements IIOFuture, Runnable { protected final FileHandle fHandle; protected final long offset; protected final ByteBuffer data; private boolean complete; private HyracksDataException exception; private int result; 
<|startcomment|> Suppress SQ warning? <|endcomment|>  public void run() { Thread.currentThread().setName(getClass().getSimpleName() + "-" + num); while (true) { IoRequest next; try { next = queue.take(); <|startfocus|> } catch (InterruptedException e) { <|endfocus|> LOGGER.log(Level.WARN, "Ignoring interrupt. IO threads should never be interrupted."); continue; } if (next == POISON_PILL) { LOGGER.log(Level.INFO, "Exiting"); InvokeUtil.doUninterruptibly(() -> queue.put(POISON_PILL)); if (Thread.interrupted()) { LOGGER.log(Level.ERROR, "Ignoring interrupt. IO threads should never be interrupted."); } break; } next.handle(); }
<|startcomment|> not asking again <|endcomment|>  boolean finishConnect = false; try { finishConnect = channel.finishConnect(); } catch (IOException e) { key.cancel(); synchronized (connectionListener) { connectionListener.connectionFailure((InetSocketAddress) key.attachment(), e); } } if (finishConnect) { createConnection(key, channel); } } } } } catch (Exception e) { <|startfocus|> LOGGER.error(() -> new ParameterizedMessage("Error in TCPEndpoint {}", localAddress), e); <|endfocus|> } }
<|startcomment|> Remove. <|endcomment|>  TestHelper.deleteExistingInstanceFiles(); String configPath = System.getProperty("user.dir") + File.separator + "src" + File.separator + "test" + File.separator + "resources" + File.separator + "cc.conf"; nc = new TestNodeController(configPath, false); nc.init(); ncAppCtx = nc.getAppRuntimeContext(); dsLifecycleMgr = ncAppCtx.getDatasetLifecycleManager(); } @AfterClass public static void tearDown() throws Exception { <|startfocus|> System.out.println("TearDown"); <|endfocus|> nc.deInit(); TestHelper.deleteExistingInstanceFiles(); } @Before public void createIndex() throws Exception { PrimaryIndexInfo primaryIndexInfo = StorageTestUtils.createPrimaryIndex(nc, PARTITION); IndexDataflowHelperFactory iHelperFactory = new IndexDataflowHelperFactory(nc.getStorageManager(), primaryIndexInfo.getFileSplitProvider()); JobId jobId = nc.newJobId(); ctx = nc.createTestContext(jobId, PARTITION, false); indexDataflowHelper = iHelperFactory.create(ctx.getJobletContext().getServiceContext(), PARTITION); indexDataflowHelper.open(); lsmBtree = (TestLsmBtree) indexDataflowHelper.getIndexInstance();
<|startcomment|> Rename. <|endcomment|> <|startfocus|> public void testRollbackWhileNoOp() { <|endfocus|> try { // allow all operations StorageTestUtils.allowAllOps(lsmBtree); // ensure no disk component and memory component is empty Assert.assertEquals(0, lsmBtree.getDiskComponents().size()); Assert.assertFalse(lsmBtree.isMemoryComponentsAllocated()); MutableArrayValueReference key = new MutableArrayValueReference("FlushMetadataOnlyTestKey".getBytes()); MutableArrayValueReference value = new MutableArrayValueReference("FlushMetadataOnlyTestValue".getBytes()); indexDataflowHelper.open(); ILSMIndexAccessor accessor = lsmBtree.createAccessor(NoOpIndexAccessParameters.INSTANCE); accessor.updateMeta(key, value); Assert.assertTrue(lsmBtree.isMemoryComponentsAllocated()); Assert.assertTrue(lsmBtree.getCurrentMemoryComponent().isModified()); indexDataflowHelper.close(); // flush synchronously StorageTestUtils.flush(dsLifecycleMgr, lsmBtree, false); // assert one disk component Assert.assertEquals(1, lsmBtree.getDiskComponents().size()); VoidPointable pointable = VoidPointable.FACTORY.createPointable(); ComponentUtils.get(lsmBtree, key, pointable); Assert.assertTrue(DataUtils.equals(pointable, value)); // ensure that we can search this component
<|startcomment|> MAJOR SonarQube violation: Either override Object.equals(Object), or totally rename the method to prevent any confusion. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1201 <|endcomment|> <|startfocus|> public static boolean equals(IValueReference first, IValueReference second) { <|endfocus|> if (first.getLength() != second.getLength()) { return false; } return equalsInRange(first.getByteArray(), first.getStartOffset(), second.getByteArray(), second.getStartOffset(), first.getLength());
<|startcomment|> use FilePath.joinPath <|endcomment|>  private static TestLsmBtree lsmBtree; private static NCAppRuntimeContext ncAppCtx; private static IDatasetLifecycleManager dsLifecycleMgr; private static IHyracksTaskContext ctx; private static IIndexDataflowHelper indexDataflowHelper; private static final int PARTITION = 0; @BeforeClass public static void setUp() throws Exception { TestHelper.deleteExistingInstanceFiles(); <|startfocus|> String configPath = System.getProperty("user.dir") + File.separator + "src" + File.separator + "test" + File.separator + "resources" + File.separator + "cc.conf"; <|endfocus|> nc = new TestNodeController(configPath, false); nc.init(); ncAppCtx = nc.getAppRuntimeContext(); dsLifecycleMgr = ncAppCtx.getDatasetLifecycleManager(); } @AfterClass public static void tearDown() throws Exception { System.out.println("TearDown"); nc.deInit(); TestHelper.deleteExistingInstanceFiles(); } @Before public void createIndex() throws Exception { PrimaryIndexInfo primaryIndexInfo = StorageTestUtils.createPrimaryIndex(nc, PARTITION); IndexDataflowHelperFactory iHelperFactory =
<|startcomment|> MAJOR SonarQube violation: Split this 123 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  ncSection = ccini.add(sectionName); } if (ncConfig.getString(NCConfig.Option.CLUSTER_ADDRESS) == null) { ncSection.put(NCConfig.Option.CLUSTER_ADDRESS.ini(), ccs.getCCConfig().getClusterPublicAddress()); ncSection.put(NCConfig.Option.CLUSTER_PORT.ini(), String.valueOf(ccs.getCCConfig().getClusterPublicPort())); } // if not already configured, set GC max pause time millis to not exceed 1/2 the total max heartbeat miss period... String ncJvmArgs = ncConfig.getString(NCConfig.Option.JVM_ARGS); <|startfocus|> if (ncJvmArgs == null || !ncJvmArgs.contains("-XX:MaxGCPauseMillis")) { String gcMaxPauseArg = "-XX:MaxGCPauseMillis=" + getGcMaxPauseMillis(); <|endfocus|> ncSection.put(NCConfig.Option.JVM_ARGS.ini(), ncJvmArgs == null ? gcMaxPauseArg : ncJvmArgs + " " + gcMaxPauseArg); } // Finally insert *this* NC's name into localnc section - this is a fixed // entry point so that NCs can determine where all their config is.
<|startcomment|> constant <|endcomment|>  ncSection.put(NCConfig.Option.CLUSTER_PORT.ini(), String.valueOf(ccs.getCCConfig().getClusterPublicPort())); } // if not already configured, set GC max pause time millis to not exceed 1/2 the total max heartbeat miss period... String ncJvmArgs = ncConfig.getString(NCConfig.Option.JVM_ARGS); <|startfocus|> if (ncJvmArgs == null || !ncJvmArgs.contains("-XX:MaxGCPauseMillis")) { String gcMaxPauseArg = "-XX:MaxGCPauseMillis=" + getGcMaxPauseMillis(); <|endfocus|> ncSection.put(NCConfig.Option.JVM_ARGS.ini(), ncJvmArgs == null ? gcMaxPauseArg : ncJvmArgs + " " + gcMaxPauseArg); } // Finally insert *this* NC's name into localnc section - this is a fixed // entry point so that NCs can determine where all their config is. ccini.put(Section.LOCALNC.sectionName(), NCConfig.Option.NODE_ID.ini(), ncId); ccini.store(iniString); if (LOGGER.isDebugEnabled()) { LOGGER.debug("Returning Ini file:\n" + iniString.toString()); } return iniString.toString();
<|startcomment|> MAJOR SonarQube violation: Replace "Collections.EMPTY_LIST" by "Collections.emptyList()". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1596 <|endcomment|>  public List<String> getFunctionParameters(String dataverseName, String fullFunctionName) { <|startfocus|> return externalFunctionParameters.getOrDefault(dataverseName + "." + fullFunctionName, Collections.EMPTY_LIST); <|endfocus|>
<|startcomment|> This is exactly the definition of functionFullName in l.218. Let's use that. <|endcomment|>  String functionReturnType = function.getReturnType().trim(); String functionDefinition = function.getDefinition().trim(); String functionLanguage = library.getLanguage().trim(); String functionType = function.getFunctionType().trim(); List<String> args = new ArrayList<>(); for (String arg : fargs) { args.add(arg); } <|startfocus|> FunctionSignature signature = new FunctionSignature(dataverse, getExternalFunctionFullName(libraryName, function.getName().trim()), args.size()); <|endfocus|> Function f = new Function(signature, args, functionReturnType, functionDefinition, functionLanguage, functionType, null); MetadataManager.INSTANCE.addFunction(mdTxnCtx, f); if (LOGGER.isInfoEnabled()) { LOGGER.info("Installed function: " + functionFullName); } } } if (LOGGER.isInfoEnabled()) { LOGGER.info("Installed functions in library :" + libraryName); } // Add adapters if (library.getLibraryAdapters() != null) { for (LibraryAdapter adapter : library.getLibraryAdapters().getLibraryAdapter()) {
<|startcomment|> you can use forEach without stream <|endcomment|>  configManager.set(nodeId, NCConfig.Option.NCSERVICE_PORT, NCConfig.NCSERVICE_PORT_DISABLED); final INCApplication ncApplication = createNCApplication(); ConfigManager ncConfigManager; if (confFile == null) { ncConfigManager = new ConfigManager(); } else { ncConfigManager = new ConfigManager(new String[] { "-config-file", confFile }); } ncApplication.registerConfig(ncConfigManager); <|startfocus|> opts.stream().forEach(opt -> ncConfigManager.set(nodeId, opt.getLeft(), opt.getRight())); <|endfocus|> nodeControllers.add( new NodeControllerService(fixupIODevices(createNCConfig(nodeId, ncConfigManager)), ncApplication)); } opts.stream().forEach(opt -> configManager.set(opt.getLeft(), opt.getRight())); cc.start(); // Starts ncs. nodeNames = ccConfig.getConfigManager().getNodeNames(); List<Thread> startupThreads = new ArrayList<>(); for (NodeControllerService nc : nodeControllers) { Thread ncStartThread = new Thread("IntegrationUtil-" + nc.getId()) { @Override public void run() { try { nc.start();
<|startcomment|> use TimeUnit <|endcomment|>  throws Exception { flushPartition(dslLifecycleMgr, lsmBtree, DATASET, async); } public static void flushPartition(IDatasetLifecycleManager dslLifecycleMgr, TestLsmBtree lsmBtree, Dataset dataset, boolean async) throws Exception { waitForOperations(lsmBtree); PrimaryIndexOperationTracker opTracker = (PrimaryIndexOperationTracker) lsmBtree.getOperationTracker(); opTracker.setFlushOnExit(true); opTracker.flushIfNeeded(); long maxWaitTime = 60000L; // 1min // wait for log record is flushed, i.e., the flush is scheduled <|startfocus|> long before = System.currentTimeMillis(); <|endfocus|> while (opTracker.isFlushLogCreated()) { Thread.sleep(5); // NOSONAR: Test code with a timeout if (System.currentTimeMillis() - before > maxWaitTime) { throw new IllegalStateException( (System.currentTimeMillis() - before) + "ms passed without scheduling the flush operation"); } } if (!async) { DatasetInfo dsInfo = dslLifecycleMgr.getDatasetInfo(dataset.getDatasetId()); dsInfo.waitForIO(); } } 
<|startcomment|> it isn't safe to use System.currentTimeMillis(), use System.nanoTime <|endcomment|>  throws Exception { flushPartition(dslLifecycleMgr, lsmBtree, DATASET, async); } public static void flushPartition(IDatasetLifecycleManager dslLifecycleMgr, TestLsmBtree lsmBtree, Dataset dataset, boolean async) throws Exception { waitForOperations(lsmBtree); PrimaryIndexOperationTracker opTracker = (PrimaryIndexOperationTracker) lsmBtree.getOperationTracker(); opTracker.setFlushOnExit(true); opTracker.flushIfNeeded(); long maxWaitTime = 60000L; // 1min // wait for log record is flushed, i.e., the flush is scheduled <|startfocus|> long before = System.currentTimeMillis(); <|endfocus|> while (opTracker.isFlushLogCreated()) { Thread.sleep(5); // NOSONAR: Test code with a timeout if (System.currentTimeMillis() - before > maxWaitTime) { throw new IllegalStateException( (System.currentTimeMillis() - before) + "ms passed without scheduling the flush operation"); } } if (!async) { DatasetInfo dsInfo = dslLifecycleMgr.getDatasetInfo(dataset.getDatasetId()); dsInfo.waitForIO(); } } 
<|startcomment|> MAJOR SonarQube violation: Add a nested comment explaining why this method is empty, throw an UnsupportedOperationException or complete the implementation. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1186 <|endcomment|>  * harness callback simply. */ public class StubIOOperationCallback implements ILSMIOOperationCallback { private ILSMIndexOperationContext opCtx = null; @Override public void beforeOperation(ILSMIndexOperationContext opCtx) throws HyracksDataException { // Not interested in this } @Override public void afterOperation(ILSMIndexOperationContext opCtx) throws HyracksDataException { this.opCtx = opCtx; } @Override <|startfocus|> public void afterFinalize(ILSMIndexOperationContext opCtx) throws HyracksDataException { <|endfocus|> } public List<ILSMDiskComponent> getLastOldComponents() { return opCtx.getComponentsToBeMerged(); } public ILSMDiskComponent getLastNewComponent() { return opCtx.getNewComponent(); } @Override public void recycled(ILSMMemoryComponent component, boolean componentSwitched) { // Not interested in this } @Override public void allocated(ILSMMemoryComponent component) { // Not interested in this } } 
<|startcomment|> why is this synchronized? <|endcomment|>  * harness callback simply. */ public class StubIOOperationCallback implements ILSMIOOperationCallback { private ILSMIndexOperationContext opCtx = null; @Override public void beforeOperation(ILSMIndexOperationContext opCtx) throws HyracksDataException { // Not interested in this } @Override public void afterOperation(ILSMIndexOperationContext opCtx) throws HyracksDataException { this.opCtx = opCtx; } @Override <|startfocus|> public synchronized void afterFinalize(ILSMIndexOperationContext opCtx) throws HyracksDataException { // Redundant info from after <|endfocus|> } public List<ILSMDiskComponent> getLastOldComponents() { return opCtx.getComponentsToBeMerged(); } public ILSMDiskComponent getLastNewComponent() { return opCtx.getNewComponent(); } @Override public void recycled(ILSMMemoryComponent component, boolean componentSwitched) { // Not interested in this } @Override public void allocated(ILSMMemoryComponent component) { // Not interested in this } } 
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  protected LSMRTreeOpContext createOpContext(IIndexAccessParameters iap) { return new LSMRTreeOpContext(this, memoryComponents, rtreeLeafFrameFactory, rtreeInteriorFrameFactory, <|startfocus|> btreeLeafFrameFactory, ((IExtendedModificationOperationCallback) iap.getModificationCallback()), <|endfocus|> iap.getSearchOperationCallback(), getTreeFields(), getFilterFields(), getHarness(), comparatorFields, linearizerArray, getFilterCmpFactories(), tracer);
<|startcomment|> Do we still need this? <|endcomment|>  * * Unless required by applicable law or agreed to in writing, * software distributed under the License is distributed on an * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.api; import java.io.DataOutput; import org.apache.asterix.om.base.IAObject; <|startfocus|> import org.apache.asterix.om.types.ATypeTag; <|endfocus|> import org.apache.asterix.om.types.IAType; import org.apache.hyracks.api.exceptions.HyracksDataException; public interface IJObject { IAType getIAType(); IAObject getIAObject(); void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException; void reset() throws HyracksDataException; } 
<|startcomment|> Should this be an ordered list? <|endcomment|>  super(); this.listType = new AOrderedListType(listItemType, null); } @Override public IAType getIAType() { return listType; } @Override public IAObject getIAObject() { AMutableOrderedList v = new AMutableOrderedList(listType); for (IJObject jObj : jObjects) { v.add(jObj.getIAObject()); } return v; } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { <|startfocus|> IAsterixListBuilder listBuilder = new UnorderedListBuilder(); <|endfocus|> listBuilder.reset(listType); ArrayBackedValueStorage fieldValue = new ArrayBackedValueStorage(); for (IJObject jObject : jObjects) { fieldValue.reset(); jObject.serialize(fieldValue.getDataOutput(), true); listBuilder.addItem(fieldValue); } listBuilder.write(dataOutput, writeTypeTag); } @Override public void reset() { jObjects.clear(); } } 
<|startcomment|> MAJOR SonarQube violation: "value" is the name of a field in "JObject". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2387 <|endcomment|>  * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.external.library.java.base; import org.apache.asterix.dataflow.data.nontagged.serde.ABooleanSerializerDeserializer; import org.apache.asterix.om.base.ABoolean; import org.apache.asterix.om.base.IAObject; import org.apache.asterix.om.types.ATypeTag; import org.apache.asterix.om.types.BuiltinType; import org.apache.asterix.om.types.IAType; import org.apache.hyracks.api.exceptions.HyracksDataException; import java.io.DataOutput; public final class JBoolean extends JObject { <|startfocus|> private boolean value; <|endfocus|> public JBoolean(boolean value) { this.value = value; } public void setValue(boolean value) { this.value = value; } public boolean getValue() { return value; } @Override public IAType getIAType() { return BuiltinType.ABOOLEAN; } @Override public IAObject getIAObject() { return value ? ABoolean.TRUE : ABoolean.FALSE; } @Override public void serialize(DataOutput dataOutput, boolean writeTypeTag) throws HyracksDataException { serializeTypeTag(writeTypeTag, dataOutput, ATypeTag.BOOLEAN);
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  public ARectangle getValue() { <|startfocus|> return ((AMutableRectangle) value); <|endfocus|>
<|startcomment|> MAJOR SonarQube violation: Use "Integer.toString" instead. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS2131 <|endcomment|> <|startfocus|> public ITupleReference getSearchKey() { return MetadataNode.createTuple(signature.getNamespace(), signature.getName(), "" + signature.getArity()); <|endfocus|>
<|startcomment|> BLOCKER SonarQube violation: Catch Exception instead of Throwable. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1181 <|endcomment|>  adapterRuntimeManager = new AdapterRuntimeManager(ctx, feedId, adapter, writer, partition); ActiveRuntimeId runtimeId = new ActiveRuntimeId(feedId, FeedRuntimeType.INTAKE.toString(), partition); ingestionRuntime = new IngestionRuntime(feedId, runtimeId, adapterRuntimeManager, ctx); feedManager.registerRuntime(ingestionRuntime); <|startfocus|> writer.open(); <|endfocus|> TaskUtils.putInSharedMap(HyracksConstants.KEY_MESSAGE, new VSizeFrame(ctx), ctx); adapterRuntimeManager.start(); synchronized (adapterRuntimeManager) { while (!adapterRuntimeManager.isDone()) { adapterRuntimeManager.wait(); } } if (adapterRuntimeManager.isFailed()) { throw new HyracksDataException("Unable to ingest data"); } } catch (Throwable ie) { /* * An Interrupted Exception is thrown if the Intake job cannot progress further due to failure of another node involved in the Hyracks job. * As the Intake job involves only the intake operator, the exception is indicative of a failure at the sibling intake operator location. * The surviving intake partitions must continue to live and receive data from the external source. */
<|startcomment|> return <|endcomment|>  public static void exit(int status) { if (exitThread.isAlive()) { LOGGER.warn("ignoring duplicate request to exit with status " + status + "; already exiting with status " + exitThread.status + "..."); } <|startfocus|> exitThread.setStatus(status); exitThread.start(); <|endfocus|>
<|startcomment|> move these codes as well <|endcomment|> import org.apache.logging.log4j.Level; import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; /** * Shutdown hook that invokes {@link NodeControllerService#stop() stop} method. * This shutdown hook must have a failsafe mechanism to halt the process in case the shutdown * operation is hanging for any reason */ public class NCShutdownHook extends Thread { <|startfocus|> public static final int FAILED_TO_STARTUP_EXIT_CODE = 2; public static final int FAILED_TO_RECOVER_EXIT_CODE = 3; <|endfocus|> private static final Logger LOGGER = LogManager.getLogger(); private final NodeControllerService nodeControllerService; NCShutdownHook(NodeControllerService nodeControllerService) { super("ShutdownHook-" + nodeControllerService.getId()); this.nodeControllerService = nodeControllerService; } @Override public void run() { try { try { LOGGER.info("Shutdown hook called"); } catch (Throwable th) {//NOSONAR } LOGGER.log(Level.INFO, () -> "Thread dump at shutdown: " + ThreadDumpUtil.takeDumpString()); nodeControllerService.stop();
<|startcomment|> why do we do this exact thing n (pendingOps) times? <|endcomment|>  protected void cleanup() { for (Entry<Integer, Pair<PrimaryIndexOperationTracker, IModificationOperationCallback>> e : primaryIndexTrackers .entrySet()) { int pendingOps = partitionPendingOps.get(e.getKey()).intValue(); for (int i = 0; i < pendingOps; i++) { try { e.getValue().first.completeOperation(null, LSMOperationType.MODIFICATION, null, e.getValue().second); } catch (HyracksDataException ex) { throw new ACIDException(ex); } <|startfocus|> } <|endfocus|> }
<|startcomment|> should we include info on the timeout (like how long it was configured for) in the exception message, in case this will reach a log? <|endcomment|>  if (interrupted) { Thread.currentThread().interrupt(); } } } /** * Runs the supplied {@code action} until {@code stopCondition} is met or timeout. */ public static void runWithTimeout(ThrowingAction action, BooleanSupplier stopCondition, long timeout, TimeUnit unit) throws Exception { long remainingTime = unit.toNanos(timeout); final long startTime = System.nanoTime(); while (!stopCondition.getAsBoolean()) { if (remainingTime <= 0) { <|startfocus|> throw new TimeoutException(); <|endfocus|> } action.run(); remainingTime -= System.nanoTime() - startTime; } } } 
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  throws HyracksDataException { // start+1 and len-1 due to type tag ignore (only interested in String value) return comparator.compare(a.getByteArray(), a.getStartOffset() + 1, a.getLength() - 1, b.getByteArray(), b.getStartOffset() + 1, b.getLength() - 1); } public static boolean isEqual(IValueReference a, IValueReference b, IBinaryComparator comparator) throws HyracksDataException { <|startfocus|> return (compareStringBinValues(a, b, comparator) == 0); <|endfocus|> } public static boolean byteArrayEqual(IValueReference valueRef1, IValueReference valueRef2) { return byteArrayEqual(valueRef1, valueRef2, 3); } public static boolean byteArrayEqual(IValueReference valueRef1, IValueReference valueRef2, int dataOffset) { if (valueRef1 == null || valueRef2 == null) { return false; } if (valueRef1 == valueRef2) { return true; } int length1 = valueRef1.getLength(); int length2 = valueRef2.getLength(); if (length1 != length2) { return false; }
<|startcomment|> -> comparator <|endcomment|>  utf8Writer = new UTF8StringWriter(); } public static IBinaryComparator createStringBinaryComparator() { return PointableBinaryComparatorFactory.of(UTF8StringPointable.FACTORY).createBinaryComparator(); } public static int compareStringBinValues(IValueReference a, IValueReference b, IBinaryComparator comparitor) throws HyracksDataException { // start+1 and len-1 due to type tag ignore (only interested in String value) <|startfocus|> return comparitor.compare(a.getByteArray(), a.getStartOffset() + 1, a.getLength() - 1, b.getByteArray(), <|endfocus|> b.getStartOffset() + 1, b.getLength() - 1); } public static boolean isEqual(IValueReference a, IValueReference b, IBinaryComparator comparitor) throws HyracksDataException { return (compareStringBinValues(a, b, comparitor) == 0); } public static boolean byteArrayEqual(IValueReference valueRef1, IValueReference valueRef2) { return byteArrayEqual(valueRef1, valueRef2, 3); } public static boolean byteArrayEqual(IValueReference valueRef1, IValueReference valueRef2, int dataOffset) { if (valueRef1 == null || valueRef2 == null) {
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "th". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  } IndexCursorUtils.open(btreeAccessors, btreeCursors, btreeRangePredicate); try { for (int i = 0; i < numberOfTrees; i++) { if (btreeCursors[i].hasNext()) { btreeCursors[i].next(); } else { depletedBtreeCursors[i] = true; } } } catch (Throwable th) { // NOSONAR Must catch all failures to close before throwing for (int i = 0; i < numberOfTrees; i++) { <|startfocus|> th = IndexCursorUtils.close(btreeCursors[i], th); <|endfocus|> } throw HyracksDataException.create(th); } } } 
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "root". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  public static Throwable close(IIndexCursor cursor, Throwable root) { if (cursor != null) { try { cursor.close(); } catch (Throwable th) { // NOSONAR Will be suppressed try { LOGGER.log(Level.WARN, "Failure closing a cursor", th); } catch (Throwable loggingFailure) { // NOSONAR: Ignore catching Throwable // NOSONAR ignore logging failure } <|startfocus|> root = ExceptionUtils.suppress(root, th); <|endfocus|> } } return root;
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "th". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  throws HyracksDataException { int opened = 0; try { for (int i = 0; i < cursors.length; i++) { if (accessors.get(i) != null) { accessors.get(i).search(cursors[i], pred); } opened++; } } catch (Throwable th) { // NOSONAR: Much catch all failures for (int j = 0; j < opened; j++) { <|startfocus|> th = IndexCursorUtils.close(cursors[j], th); <|endfocus|> } throw HyracksDataException.create(th); } } public static void open(IIndexAccessor[] accessors, IIndexCursor[] cursors, ISearchPredicate pred) throws HyracksDataException { int opened = 0; try { for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { accessors[i].search(cursors[i], pred); } opened++; } } catch (Throwable th) { // NOSONAR: Much catch all failures for (int j = 0; j < opened; j++) { th = IndexCursorUtils.close(cursors[j], th);
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "th". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  throws HyracksDataException { int opened = 0; try { for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { accessors[i].search(cursors[i], pred); } opened++; } } catch (Throwable th) { // NOSONAR: Much catch all failures for (int j = 0; j < opened; j++) { <|startfocus|> th = IndexCursorUtils.close(cursors[j], th); <|endfocus|> } throw HyracksDataException.create(th); } } public static Throwable close(IIndexCursor[] cursors, Throwable th) { for (int j = 0; j < cursors.length; j++) { th = IndexCursorUtils.close(cursors[j], th); } return th; } } 
<|startcomment|> MAJOR SonarQube violation: Introduce a new variable instead of reusing the parameter "th". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1226 <|endcomment|>  public static Throwable close(IIndexCursor[] cursors, Throwable th) { for (int j = 0; j < cursors.length; j++) { <|startfocus|> th = IndexCursorUtils.close(cursors[j], th); <|endfocus|> } return th;
<|startcomment|> MAJOR SonarQube violation: trailing WS is not allowed Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=checkstyle%3Aasterixdb_trailingws <|endcomment|>  ILSMOperationTracker getOperationTracker(); ILSMIOOperationScheduler getIOScheduler(); ILSMIOOperationCallback getIOOperationCallback(); /** * components with lower indexes are newer than components with higher index */ List<ILSMDiskComponent> getDiskComponents(); boolean isPrimaryIndex(); void modify(IIndexOperationContext ictx, ITupleReference tuple) throws HyracksDataException; /** * If this method returns successfully, then the cursor has been opened, and need to be closed * Otherwise, it has not been opened <|startfocus|> * <|endfocus|> * @param ictx * @param cursor * @param pred * @throws HyracksDataException */ void search(ILSMIndexOperationContext ictx, IIndexCursor cursor, ISearchPredicate pred) throws HyracksDataException; public void scanDiskComponents(ILSMIndexOperationContext ctx, IIndexCursor cursor) throws HyracksDataException; void scheduleFlush(ILSMIndexOperationContext ctx, ILSMIOOperationCallback callback) throws HyracksDataException; ILSMDiskComponent flush(ILSMIOOperation operation) throws HyracksDataException; void scheduleMerge(ILSMIndexOperationContext ctx, ILSMIOOperationCallback callback) throws HyracksDataException; ILSMDiskComponent merge(ILSMIOOperation operation) throws HyracksDataException; 
<|startcomment|> what needs to be suppressed here? <|endcomment|>  public static Throwable close(IIndexCursor cursor, Throwable root) { if (cursor != null) { try { cursor.close(); } catch (Throwable th) { // NOSONAR Will be suppressed try { LOGGER.log(Level.WARN, "Failure closing a cursor", th); } catch (Throwable loggingFailure) { // NOSONAR: Ignore catching Throwable // NOSONAR ignore logging failure } <|startfocus|> root = ExceptionUtils.suppress(root, th); // NOSONAR <|endfocus|> } } return root;
<|startcomment|> can remove if we stick to collections <|endcomment|>  IOperatorNodePushable operatorNodePushable = operatorNodePushables.get(activityIdInputIndex.getLeft()); return operatorNodePushable.getInputFrameWriter(activityIdInputIndex.getRight()); } @Override public String getDisplayName() { return "Super Activity " + parent.getActivityMap().values().toString(); } @FunctionalInterface interface OperatorNodePushableAction { void run(IOperatorNodePushable op) throws HyracksDataException; } @SuppressWarnings("unchecked") private void runInParallel(OperatorNodePushableAction action) throws HyracksDataException { <|startfocus|> Future<Void>[] tasks = new Future[operatorNodePushablesBFSOrder.size()]; Throwable[] failures = new Throwable[operatorNodePushablesBFSOrder.size()]; <|endfocus|> final Semaphore startSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size()); final Semaphore completeSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size()); int completed = 0; Throwable root = null; try { for (int i = 0; i < operatorNodePushablesBFSOrder.size(); i++) { final int current = i; tasks[i] = ctx.getExecutorService().submit(() -> { startSemaphore.release(); try {
<|startcomment|> why not leave as lists? we can then remove the use of indexes and just operate on the collections as before? <|endcomment|>  } @FunctionalInterface interface OperatorNodePushableAction { void run(IOperatorNodePushable op) throws HyracksDataException; } @SuppressWarnings("unchecked") private void runInParallel(OperatorNodePushableAction action) throws HyracksDataException { Future<Void>[] tasks = new Future[operatorNodePushablesBFSOrder.size()]; Throwable[] failures = new Throwable[operatorNodePushablesBFSOrder.size()]; final Semaphore startSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size()); final Semaphore completeSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size()); <|startfocus|> int completed = 0; <|endfocus|> Throwable root = null; try { for (int i = 0; i < operatorNodePushablesBFSOrder.size(); i++) { final int current = i; tasks[i] = ctx.getExecutorService().submit(() -> { startSemaphore.release(); try { action.run(operatorNodePushablesBFSOrder.get(current)); } catch (Throwable th) { // NOSONAR: Must catch all causes of failure failures[current] = th; throw th; } finally { completeSemaphore.release(); } return null; }); }
<|startcomment|> MAJOR SonarQube violation: Extract this nested try block into a separate method. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1141 <|endcomment|>  final Semaphore completeSemaphore = new Semaphore(1 - operatorNodePushablesBFSOrder.size()); int completed = 0; Throwable root = null; try { for (int i = 0; i < operatorNodePushablesBFSOrder.size(); i++) { final int current = i; tasks[i] = ctx.getExecutorService().submit(() -> { startSemaphore.release(); try { action.run(operatorNodePushablesBFSOrder.get(current)); } catch (Throwable th) { // NOSONAR: Must catch all causes of failure <|startfocus|> failures[current] = th; <|endfocus|> throw th; } finally { completeSemaphore.release(); } return null; }); } for (Future<Void> task : tasks) { task.get(); completed++; } } catch (ExecutionException e) { root = e.getCause(); completed++; } catch (Throwable e) { // NOSONAR: Must catch all causes of failure root = e; } if (root != null) { cancelTasks(tasks, startSemaphore, completeSemaphore);
<|startcomment|> how about this? void secure(TxnId id); You can call this in TransactionManager before the rollback. Make it syncrhonized in CheckpointManager and just use a hash map to store the secured txnId and the current low water mark. Whenever a checkpoint attempt happens after that, check the minimum secured low water mark in the map and fail the checkpoint if its target is greater than that minimum. For any other reader, you can use a dummy txnId (e.g. -1) just to secure the low water mark. <|endcomment|>  */ Checkpoint getLatest() throws ACIDException; /** * Performs a sharp checkpoint. * * @throws HyracksDataException */ void doSharpCheckpoint() throws HyracksDataException; /** * Attempts to perform a soft checkpoint at the specified {@code checkpointTargetLSN}. * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint. * @throws HyracksDataException */ long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; void unlockLSN(long lsn); <|startfocus|> void lockLSN(long lsn); <|endfocus|> } 
<|startcomment|> How about this? void completed(TxnId id); Call this in the finally block in TransactionManager in about. Make the method synchronized in CheckpointManager and just remove the txnid from the secured txns map. <|endcomment|>  /** * Performs a sharp checkpoint. * * @throws HyracksDataException */ void doSharpCheckpoint() throws HyracksDataException; /** * Attempts to perform a soft checkpoint at the specified {@code checkpointTargetLSN}. * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint. * @throws HyracksDataException */ long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; void unlockLSN(long lsn); <|startfocus|> void lockLSN(long lsn); <|endfocus|> } 
<|startcomment|> WS <|endcomment|>  DataflowUtils.addTupleToFrame(tupleAppender, tuple, insertOp); lowWaterMarkLSN = recoveryManager.getMinFirstLSN(); currentLowWaterMarkLogFileId = logManager.getLogFileId(lowWaterMarkLSN); } } /* * At this point, the low-water mark is not in the initialLowWaterMarkFileId, so * a checkpoint should delete it. We will also start a second <|startfocus|> * job to ensure that the checkpointing coexists peacefully * with other concurrent readers of the log that request <|endfocus|> * deletions to be witheld */ JobId jobId2 = nc.newJobId(); IHyracksTaskContext ctx2 = nc.createTestContext(jobId2, 0, false); nc.getTransactionManager().beginTransaction(nc.getTxnJobId(ctx2), new TransactionOptions(ITransactionManager.AtomicityLevel.ENTITY_LEVEL)); // Prepare insert operation LSMInsertDeleteOperatorNodePushable insertOp2 = nc.getInsertPipeline(ctx2, dataset, KEY_TYPES, RECORD_TYPE, META_TYPE, null, KEY_INDEXES, KEY_INDICATOR_LIST, storageManager, null).getLeft(); insertOp2.open(); VSizeFrame frame2 = new VSizeFrame(ctx2);
<|startcomment|> Use logger <|endcomment|>  RECORD_TYPE, META_TYPE, null, KEY_INDEXES, KEY_INDICATOR_LIST, storageManager, null).getLeft(); insertOp2.open(); VSizeFrame frame2 = new VSizeFrame(ctx2); FrameTupleAppender tupleAppender2 = new FrameTupleAppender(frame2); for (int i = 0; i < 4; i++) { long lastCkpoint = recoveryManager.getMinFirstLSN(); long lastFileId = logManager.getLogFileId(lastCkpoint); <|startfocus|> System.out.println("ckpoint: " + lastCkpoint); <|endfocus|> checkpointManager.tryCheckpoint(lowWaterMarkLSN); // Validate initialLowWaterMarkFileId was deleted for (Long fileId : logManager.getLogFileIds()) { Assert.assertNotEquals(initialLowWaterMarkFileId, fileId.longValue()); } while (currentLowWaterMarkLogFileId == lastFileId) { ITupleReference tuple = tupleGenerator.next(); DataflowUtils.addTupleToFrame(tupleAppender2, tuple, insertOp2); lowWaterMarkLSN = recoveryManager.getMinFirstLSN(); currentLowWaterMarkLogFileId = logManager.getLogFileId(lowWaterMarkLSN); } }
<|startcomment|> why lock specific LSNs? all what you need is to block the checkpoint from advancing the current low water mark until the log reader is done. <|endcomment|>  /** * Performs a sharp checkpoint. * * @throws HyracksDataException */ void doSharpCheckpoint() throws HyracksDataException; /** * Attempts to perform a soft checkpoint at the specified {@code checkpointTargetLSN}. * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint. * @throws HyracksDataException */ long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; void unlockLSN(long lsn); <|startfocus|> void lockLSN(long lsn); <|endfocus|> } 
<|startcomment|> why? <|endcomment|>  private void touchLogFile(long fileId) { synchronized (txnLogFileId2ReaderCount) { if (txnLogFileId2ReaderCount.containsKey(fileId)) { txnLogFileId2ReaderCount.put(fileId, txnLogFileId2ReaderCount.get(fileId) + 1); } else { txnLogFileId2ReaderCount.put(fileId, 1); } <|startfocus|> } <|endfocus|>
<|startcomment|> why? <|endcomment|>  public void run() { <|startfocus|> while (true) { <|endfocus|> try { logRecord = flushLogsQ.take(); appendToLogTail(logRecord); } catch (ACIDException e) { e.printStackTrace(); } catch (InterruptedException e) { //ignore } }
<|startcomment|> why TreeMap? <|endcomment|>  if (!checkpointDir.exists()) { if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Checkpoint directory " + checkpointDirPath + " didn't exist. Creating one"); } checkpointDir.mkdirs(); } lsnThreshold = checkpointProperties.getLsnThreshold(); pollFrequency = checkpointProperties.getPollFrequency(); // We must keep at least the latest checkpoint historyToKeep = checkpointProperties.getHistoryToKeep() == 0 ? 1 : checkpointProperties.getHistoryToKeep(); <|startfocus|> lockedLSNs = new TreeMap<>(); <|endfocus|>
<|startcomment|> I don't see any reason for synchronizing on logManager. The log manager shouldn't be involved in protecting LSN. All ingestion threads are already competing on log manager, it wouldn't be wise to add additional unnecessary synchronization there. <|endcomment|>  if (checkpointSucceeded) { ILogManager logManager = txnSubsystem.getLogManager(); synchronized (logManager) { for (Long l : lockedLSNs.keySet()) { if (minFirstLSN > l) { return minFirstLSN; } } logManager.deleteOldLogFiles(minFirstLSN); LOGGER.info(String.format("soft checkpoint succeeded at LSN(%s)", minFirstLSN)); } } return minFirstLSN; } @Override public void lockLSN(long lsn) { <|startfocus|> synchronized (txnSubsystem.getLogManager()) { <|endfocus|> if (!lockedLSNs.containsKey(lsn)) { lockedLSNs.put(lsn, 1); } else { lockedLSNs.replace(lsn, lockedLSNs.get(lsn) + 1); } } } @Override public void unlockLSN(long lsn) { synchronized (txnSubsystem.getLogManager()) { if (!lockedLSNs.containsKey(lsn)) { return; } else { if (lockedLSNs.get(lsn) == 1) { lockedLSNs.remove(lsn); } else { lockedLSNs.replace(lsn, lockedLSNs.get(lsn) - 1); } } } } } 
<|startcomment|> if this happens, then something is wrong <|endcomment|>  } } return minFirstLSN; } @Override public void lockLSN(long lsn) { synchronized (txnSubsystem.getLogManager()) { if (!lockedLSNs.containsKey(lsn)) { lockedLSNs.put(lsn, 1); } else { lockedLSNs.replace(lsn, lockedLSNs.get(lsn) + 1); } } } @Override public void unlockLSN(long lsn) { synchronized (txnSubsystem.getLogManager()) { if (!lockedLSNs.containsKey(lsn)) { <|startfocus|> return; <|endfocus|> } else { if (lockedLSNs.get(lsn) == 1) { lockedLSNs.remove(lsn); } else { lockedLSNs.replace(lsn, lockedLSNs.get(lsn) - 1); } } } } } 
<|startcomment|> let's make it lower case. This is not a static constant anymore <|endcomment|>  final IVisitablePointable vp1 = pa.allocateRecordValue(inRecType1); final IPointable argPtr0 = new VoidPointable(); final IPointable argPtr1 = new VoidPointable(); final IScalarEvaluator eval0 = args[0].createScalarEvaluator(ctx); final IScalarEvaluator eval1 = args[1].createScalarEvaluator(ctx); final List<RecordBuilder> rbStack = new ArrayList<>(); final ArrayBackedValueStorage tabvs = new ArrayBackedValueStorage(); <|startfocus|> final IBinaryComparator STRING_BINARY_COMPARATOR = PointableHelper.createStringBinaryComparator(); <|endfocus|> return new IScalarEvaluator() { private final RuntimeRecordTypeInfo runtimeRecordTypeInfo = new RuntimeRecordTypeInfo(); private final DeepEqualAssessor deepEqualAssesor = new DeepEqualAssessor(); private ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); private DataOutput out = resultStorage.getDataOutput(); @Override public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { resultStorage.reset(); eval0.evaluate(tuple, argPtr0); eval1.evaluate(tuple, argPtr1); vp0.set(argPtr0); vp1.set(argPtr1); 
<|startcomment|> let's make it lower case. This is not a static constant anymore <|endcomment|>  public IScalarEvaluator createScalarEvaluator(final IHyracksTaskContext ctx) throws HyracksDataException { final PointableAllocator pa = new PointableAllocator(); final IVisitablePointable vp0 = pa.allocateRecordValue(inputRecType); final IVisitablePointable vp1 = pa.allocateListValue(inputListType); final IPointable inputArg0 = new VoidPointable(); final IPointable inputArg1 = new VoidPointable(); final IScalarEvaluator eval0 = inputRecordEvalFactory.createScalarEvaluator(ctx); final IScalarEvaluator eval1 = removeFieldPathsFactory.createScalarEvaluator(ctx); <|startfocus|> final IBinaryComparator STRING_BINARY_COMPARATOR = PointableHelper.createStringBinaryComparator(); <|endfocus|> return new IScalarEvaluator() { private final RuntimeRecordTypeInfo runtimeRecordTypeInfo = new RuntimeRecordTypeInfo(); private final List<RecordBuilder> rbStack = new ArrayList<>(); private final ArrayBackedValueStorage tabvs = new ArrayBackedValueStorage(); private final Deque<IVisitablePointable> recordPath = new ArrayDeque<>(); private ArrayBackedValueStorage resultStorage = new ArrayBackedValueStorage(); private DataOutput out = resultStorage.getDataOutput(); @Override public void evaluate(IFrameTupleReference tuple, IPointable result) throws HyracksDataException { resultStorage.reset();
<|startcomment|> it seems this isn't needed, can we remove it? <|endcomment|>  } IndexCursorUtils.open(btreeAccessors, btreeCursors, btreeRangePredicate); try { for (int i = 0; i < numberOfTrees; i++) { if (btreeCursors[i].hasNext()) { btreeCursors[i].next(); } else { depletedBtreeCursors[i] = true; } } } catch (Throwable th) { // NOSONAR Must catch all failures to close before throwing for (int i = 0; i < numberOfTrees; i++) { <|startfocus|> th = IndexCursorUtils.close(btreeCursors[i], th); <|endfocus|> } throw HyracksDataException.create(th); } } } 
<|startcomment|> this seems unneeded, remove it? <|endcomment|>  throws HyracksDataException { int opened = 0; try { for (int i = 0; i < cursors.length; i++) { if (accessors.get(i) != null) { accessors.get(i).search(cursors[i], pred); } opened++; } } catch (Throwable th) { // NOSONAR: Much catch all failures for (int j = 0; j < opened; j++) { <|startfocus|> th = IndexCursorUtils.close(cursors[j], th); <|endfocus|> } throw HyracksDataException.create(th); } } public static void open(IIndexAccessor[] accessors, IIndexCursor[] cursors, ISearchPredicate pred) throws HyracksDataException { int opened = 0; try { for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { accessors[i].search(cursors[i], pred); } opened++; } } catch (Throwable th) { // NOSONAR: Much catch all failures for (int j = 0; j < opened; j++) { th = IndexCursorUtils.close(cursors[j], th);
<|startcomment|> this seems unneeded, remove it? <|endcomment|>  throws HyracksDataException { int opened = 0; try { for (int i = 0; i < accessors.length; i++) { if (accessors[i] != null) { accessors[i].search(cursors[i], pred); } opened++; } } catch (Throwable th) { // NOSONAR: Much catch all failures for (int j = 0; j < opened; j++) { <|startfocus|> th = IndexCursorUtils.close(cursors[j], th); <|endfocus|> } throw HyracksDataException.create(th); } } public static Throwable close(IIndexCursor[] cursors, Throwable th) { for (int j = 0; j < cursors.length; j++) { th = IndexCursorUtils.close(cursors[j], th); } return th; } } 
<|startcomment|> replace with a one-liner? e.g. failures.forEach(f -> ExceptionUtils.suppress(root, f)) <|endcomment|>  initializationTasks.add(ctx.getExecutorService().submit(new Callable<Void>() { @Override public Void call() throws Exception { opAction.runAction(op, opIndex); return null; } })); } // Waits until all parallel actions to finish. for (Future<Void> initializationTask : initializationTasks) { initializationTask.get(); } } catch (Throwable th) { for (Future<Void> initializationTask : initializationTasks) { initializationTask.cancel(true); } <|startfocus|> throw new HyracksDataException(th); <|endfocus|> } } } 
<|startcomment|> should we just log this in the log, not include in the exception? also, can we please log the bytes in byte buffer, starting at position() prior to calling readLogRecord (or even some bytes before if available) up to the current position at time of status != RecordReadStatus.OK (including some bytes after if available)? <|endcomment|>  public LogRecord next() { if (buffer.position() == endOffset) { return null; } RecordReadStatus status = logRecord.readLogRecord(buffer); //underflow is not expected because we are at the very tail of the current log buffer if (status != RecordReadStatus.OK) { <|startfocus|> throw new IllegalStateException( "Unexpected log read status: " + status + ". Read log: " + logRecord.getLogRecordForDisplay()); <|endfocus|> } return logRecord;
<|startcomment|> MAJOR SonarQube violation: Use isEmpty() to check whether the collection is empty or not. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1155 <|endcomment|>  IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem.getApplicationContext().getDatasetLifecycleManager(); datasetLifecycleManager.scheduleAsyncFlushForLaggingDatasets(checkpointTargetLSN); } capture(minFirstLSN, false); if (checkpointSucceeded) { txnSubsystem.getLogManager().deleteOldLogFiles(minFirstLSN); LOGGER.info(String.format("soft checkpoint succeeded at LSN(%s)", minFirstLSN)); } return minFirstLSN; } private synchronized long getMinSecuredLSN() { <|startfocus|> return securedLSNs.values().size() > 0 ? Collections.min(securedLSNs.values()) : -1; <|endfocus|> } @Override public synchronized void secure(TxnId id) throws HyracksDataException { securedLSNs.put(id, txnSubsystem.getRecoveryManager().getMinFirstLSN()); } @Override public synchronized void completed(TxnId id) { securedLSNs.remove(id); } } 
<|startcomment|> /** * Notifies this {@link ICheckpointManager} that the transaction identified by {@code id} completed. * * @param id */ <|endcomment|>  Checkpoint getLatest() throws ACIDException; /** * Performs a sharp checkpoint. * * @throws HyracksDataException */ void doSharpCheckpoint() throws HyracksDataException; /** * Attempts to perform a soft checkpoint at the specified {@code checkpointTargetLSN}. * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint. * @throws HyracksDataException */ long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; void secure(TxnId id) throws HyracksDataException; <|startfocus|> <|endfocus|> void completed(TxnId id); } 
<|startcomment|> move it to CheckpointManager and make it private final <|endcomment|>  */ public abstract class AbstractCheckpointManager implements ICheckpointManager { private static final Logger LOGGER = LogManager.getLogger(); private static final String CHECKPOINT_FILENAME_PREFIX = "checkpoint_"; public static final long SHARP_CHECKPOINT_LSN = -1; private static final FilenameFilter filter = (File dir, String name) -> name.startsWith(CHECKPOINT_FILENAME_PREFIX); private final File checkpointDir; private final int historyToKeep; private final int lsnThreshold; private final int pollFrequency; <|startfocus|> protected Map<TxnId, Long> securedLSNs; <|endfocus|> protected final ITransactionSubsystem txnSubsystem; private CheckpointThread checkpointer; public AbstractCheckpointManager(ITransactionSubsystem txnSubsystem, CheckpointProperties checkpointProperties) { this.txnSubsystem = txnSubsystem; String checkpointDirPath = checkpointProperties.getCheckpointDirPath(); if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Checkpoint directory = " + checkpointDirPath); } if (!checkpointDirPath.endsWith(File.separator)) { checkpointDirPath += File.separator; } checkpointDir = new File(checkpointDirPath); // Create the checkpoint directory if missing if (!checkpointDir.exists()) {
<|startcomment|> Refactor as getMinSecuredLsn and please use a better variable name than I. Also, make the check at the beginning of this method against checkpointTargetLSN to avoid scheduling the flushes (i.e. never move beyond the current secured low water mark). <|endcomment|>  final long minFirstLSN = txnSubsystem.getRecoveryManager().getMinFirstLSN(); boolean checkpointSucceeded = minFirstLSN >= checkpointTargetLSN; if (!checkpointSucceeded) { // Flush datasets with indexes behind target checkpoint LSN IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem.getApplicationContext().getDatasetLifecycleManager(); datasetLifecycleManager.scheduleAsyncFlushForLaggingDatasets(checkpointTargetLSN); } capture(minFirstLSN, false); if (checkpointSucceeded) { <|startfocus|> for (Long l : securedLSNs.values()) { if (minFirstLSN >= l) { return minFirstLSN; } } <|endfocus|> txnSubsystem.getLogManager().deleteOldLogFiles(minFirstLSN); LOGGER.info(String.format("soft checkpoint succeeded at LSN(%s)", minFirstLSN)); } return minFirstLSN; } @Override public synchronized void secure(TxnId id) throws HyracksDataException { securedLSNs.put(id, txnSubsystem.getRecoveryManager().getMinFirstLSN()); } @Override public synchronized void completed(TxnId id) throws IllegalStateException { if (securedLSNs.containsKey(id)) { securedLSNs.remove(id); } else { throw new IllegalStateException(
<|startcomment|> remove <|endcomment|>  } } @Override public void abortTransaction(TxnId txnId) throws ACIDException { final ITransactionContext txnCtx = getTransactionContext(txnId); try { if (txnCtx.isWriteTxn()) { LogRecord logRecord = new LogRecord(); TransactionUtil.formJobTerminateLogRecord(txnCtx, logRecord, false); txnSubsystem.getLogManager().log(logRecord); txnSubsystem.getCheckpointManager().secure(txnId); txnSubsystem.getRecoveryManager().rollbackTransaction(txnCtx); txnCtx.setTxnState(ITransactionManager.ABORTED); } <|startfocus|> } catch (ACIDException | HyracksDataException e) { <|endfocus|> String msg = "Could not complete rollback! System is in an inconsistent state"; if (LOGGER.isErrorEnabled()) { LOGGER.log(Level.ERROR, msg, e); } throw new ACIDException(msg, e); } finally { txnCtx.complete(); txnSubsystem.getLockManager().releaseLocks(txnCtx); txnCtxRepository.remove(txnCtx.getTxnId()); txnSubsystem.getCheckpointManager().completed(txnId); } } @Override public long getMaxTxnId() { return maxTxnId.get(); } @Override public void start() {
<|startcomment|> MAJOR SonarQube violation: Make securedLSNs a static final constant or non-public and provide accessors if needed. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AClassVariableVisibilityCheck <|endcomment|>  */ public abstract class AbstractCheckpointManager implements ICheckpointManager { private static final Logger LOGGER = LogManager.getLogger(); private static final String CHECKPOINT_FILENAME_PREFIX = "checkpoint_"; public static final long SHARP_CHECKPOINT_LSN = -1; private static final FilenameFilter filter = (File dir, String name) -> name.startsWith(CHECKPOINT_FILENAME_PREFIX); private final File checkpointDir; private final int historyToKeep; private final int lsnThreshold; private final int pollFrequency; <|startfocus|> public Map<TxnId, Long> securedLSNs; <|endfocus|> protected final ITransactionSubsystem txnSubsystem; private CheckpointThread checkpointer; public AbstractCheckpointManager(ITransactionSubsystem txnSubsystem, CheckpointProperties checkpointProperties) { this.txnSubsystem = txnSubsystem; String checkpointDirPath = checkpointProperties.getCheckpointDirPath(); if (LOGGER.isInfoEnabled()) { LOGGER.log(Level.INFO, "Checkpoint directory = " + checkpointDirPath); } if (!checkpointDirPath.endsWith(File.separator)) { checkpointDirPath += File.separator; } checkpointDir = new File(checkpointDirPath); // Create the checkpoint directory if missing if (!checkpointDir.exists()) {
<|startcomment|> private static final TxnId recoveryTxnId = new TxnId(-1); <|endcomment|>  for (DatasetResourceReference indexRef : partitionResources) { long remoteIndexMaxLSN = idxCheckpointMgrProvider.get(indexRef).getLowWatermark(); minRemoteLSN = Math.min(minRemoteLSN, remoteIndexMaxLSN); } } return minRemoteLSN; } @Override public synchronized void replayReplicaPartitionLogs(Set<Integer> partitions, boolean flush) throws HyracksDataException { //replay logs > minLSN that belong to these partitions final TxnId randomDummyTxnId = new TxnId(ThreadLocalRandom.current().nextInt(Integer.MIN_VALUE, -1)); try { <|startfocus|> checkpointManager.secure(randomDummyTxnId); <|endfocus|> long minLSN = getPartitionsMinLSN(partitions); long readableSmallestLSN = logMgr.getReadableSmallestLSN(); if (minLSN < readableSmallestLSN) { minLSN = readableSmallestLSN; } replayPartitionsLogs(partitions, logMgr.getLogReader(true), minLSN); if (flush) { appCtx.getDatasetLifecycleManager().flushAllDatasets(); } } catch (IOException | ACIDException e) { throw HyracksDataException.create(e); } finally { checkpointManager.completed(randomDummyTxnId); } } @Override
<|startcomment|> remove <|endcomment|>  void doSharpCheckpoint() throws HyracksDataException; /** * Attempts to perform a soft checkpoint at the specified {@code checkpointTargetLSN}. * * @param checkpointTargetLSN * @return The LSN recorded on the captured checkpoint. * @throws HyracksDataException */ long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; /** * Secures the current low-water mark until the transaction identified by {@code id} completes. * * @param id * @throws HyracksDataException */ <|startfocus|> <|endfocus|> void secure(TxnId id) throws HyracksDataException; /** * Notifies this {@link ICheckpointManager} that the transaction identified by {@code id} completed. * * @param id */ void completed(TxnId id); } 
<|startcomment|> remove <|endcomment|>  * @throws HyracksDataException */ long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException; /** * Secures the current low-water mark until the transaction identified by {@code id} completes. * * @param id * @throws HyracksDataException */ void secure(TxnId id) throws HyracksDataException; /** * Notifies this {@link ICheckpointManager} that the transaction identified by {@code id} completed. * * @param id */ <|startfocus|> <|endfocus|> void completed(TxnId id); } 
<|startcomment|> revert? <|endcomment|>  * KIND, either express or implied. See the License for the * specific language governing permissions and limitations * under the License. */ package org.apache.asterix.transaction.management.service.recovery; import java.io.BufferedWriter; import java.io.File; import java.io.FilenameFilter; import java.io.IOException; import java.io.OutputStream; import java.nio.channels.ClosedByInterruptException; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; <|startfocus|> import java.util.HashMap; <|endfocus|> import java.util.List; import java.util.Map; import org.apache.asterix.common.exceptions.ACIDException; import org.apache.asterix.common.transactions.Checkpoint; import org.apache.asterix.common.transactions.CheckpointProperties; import org.apache.asterix.common.transactions.ICheckpointManager; import org.apache.asterix.common.transactions.ILogManager; import org.apache.asterix.common.transactions.ITransactionManager; import org.apache.asterix.common.transactions.ITransactionSubsystem; import org.apache.asterix.common.transactions.TxnId; import org.apache.asterix.common.utils.StorageConstants; import org.apache.hyracks.api.exceptions.HyracksDataException;
<|startcomment|> you shouldn't return this here since no checkpoint was actually captured at this lsn. Just check with the target before checking the current minFirstLSN: final long minSecuredLsn = getMinSecuredLsn(); if (checkpointTargetLSN >= minSecuredLsn) { return minSecuredLsn; } <|endcomment|>  * log files that end with LSN < {@code checkpointTargetLSN} are deleted. */ @Override public synchronized long tryCheckpoint(long checkpointTargetLSN) throws HyracksDataException { LOGGER.info("Attemping soft checkpoint..."); final long minFirstLSN = txnSubsystem.getRecoveryManager().getMinFirstLSN(); final long minSecuredLSN = getMinSecuredLSN(); <|startfocus|> if (minSecuredLSN != -1 && minFirstLSN >= getMinSecuredLSN()) { return minFirstLSN; <|endfocus|> } boolean checkpointSucceeded = minFirstLSN >= checkpointTargetLSN; if (!checkpointSucceeded) { // Flush datasets with indexes behind target checkpoint LSN IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem.getApplicationContext().getDatasetLifecycleManager(); datasetLifecycleManager.scheduleAsyncFlushForLaggingDatasets(checkpointTargetLSN); } capture(minFirstLSN, false); if (checkpointSucceeded) { txnSubsystem.getLogManager().deleteOldLogFiles(minFirstLSN); LOGGER.info(String.format("soft checkpoint succeeded at LSN(%s)", minFirstLSN)); } return minFirstLSN; } private synchronized long getMinSecuredLSN() {
<|startcomment|> if you are going to use special values, define them as constants. I prefer that you replace this by the following and remove the special value: return securedTxn.values().stream().min(Long::compareTo).orElse(Long.MAX_VALUE); <|endcomment|>  IDatasetLifecycleManager datasetLifecycleManager = txnSubsystem.getApplicationContext().getDatasetLifecycleManager(); datasetLifecycleManager.scheduleAsyncFlushForLaggingDatasets(checkpointTargetLSN); } capture(minFirstLSN, false); if (checkpointSucceeded) { txnSubsystem.getLogManager().deleteOldLogFiles(minFirstLSN); LOGGER.info(String.format("soft checkpoint succeeded at LSN(%s)", minFirstLSN)); } return minFirstLSN; } private synchronized long getMinSecuredLSN() { <|startfocus|> return securedLSNs.isEmpty() ? -1 : Collections.min(securedLSNs.values()); <|endfocus|> } @Override public synchronized void secure(TxnId id) throws HyracksDataException { securedLSNs.put(id, txnSubsystem.getRecoveryManager().getMinFirstLSN()); } @Override public synchronized void completed(TxnId id) { securedLSNs.remove(id); } } 
<|startcomment|> MAJOR SonarQube violation: The return type of this method should be an interface such as "List" rather than the implementation "ArrayList". Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1319 <|endcomment|>  public void run() { Thread ct = Thread.currentThread(); <|startfocus|> String threadName = ct.getName(); <|endfocus|> // Calls synchronized addPendingThread(..) to make sure that in the abort() method, // the thread is not escaped from interruption. if (!addPendingThread(ct)) { exceptions.add(new InterruptedException("Task " + getTaskAttemptId() + " was aborted!")); ExceptionUtils.setNodeIds(exceptions, ncs.getId()); ncs.getWorkQueue().schedule(new NotifyTaskFailureWork(ncs, this, exceptions)); return; } try { ct.setName(displayName + ":" + taskAttemptId + ":" + 0); try { operator.initialize(); if (collectors.length > 0) { final Semaphore sem = new Semaphore(collectors.length - 1); for (int i = 1; i < collectors.length; ++i) { final IPartitionCollector collector = collectors[i]; final IFrameWriter writer = operator.getInputFrameWriter(i); sem.acquire(); final int cIdx = i; executorService.execute(new Runnable() { @Override
<|startcomment|> why not use Charset here and avoid the lookup? <|endcomment|>  int tzCount = tzIds.length; TIMEZONE_IDS = new byte[tzCount][]; TIMEZONE_OFFSETS = new int[tzCount]; for (int i = 0; i < tzCount; i++) { TIMEZONE_IDS[i] = encode(tzIds[i]); } Arrays.sort(TIMEZONE_IDS, byteArrayComparator); for (int i = 0; i < tzCount; i++) { <|startfocus|> String tzId; try { tzId = new String(TIMEZONE_IDS[i], ENCODING); } catch (UnsupportedEncodingException e) { throw new IllegalStateException(ENCODING, e); } TIMEZONE_OFFSETS[i] = TimeZone.getTimeZone(tzId).getRawOffset(); <|endfocus|> } } private static final DateTimeFormatUtils INSTANCE = new DateTimeFormatUtils(); public static DateTimeFormatUtils getInstance() { return INSTANCE; } private DateTimeFormatUtils() { } private int parseFormatField(byte[] format, int formatStart, int formatLength, int formatPointer, char formatChar, int maxAllowedFormatCharCopied) { int formatCharCopies = 0; formatPointer++; formatCharCopies++;
<|startcomment|> MAJOR SonarQube violation: Refactor this code to not nest more than 4 if/for/while/switch/try statements. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS134 <|endcomment|>  && data[dataStart + timezoneEndField] <= 'Z') || data[dataStart + timezoneEndField] == '/' || data[dataStart + timezoneEndField] == '_')) { timezoneEndField++; } int searchIdx = binaryTimezoneIDSearch(data, dataStart + dataStringPointer, timezoneEndField - dataStringPointer); if (searchIdx >= 0) { timezone = TIMEZONE_OFFSETS[searchIdx]; } else { if (raiseParseDataError) { <|startfocus|> throw new AsterixTemporalTypeParseException("Unexpected timezone string: " + decode(data, dataStart + dataStringPointer, dataStart + timezoneEndField)); <|endfocus|> } else { return false; } } dataStringPointer = timezoneEndField; } timezoneExists = true; break; case AMPM: if (dataStringPointer + 1 < dataLength) { if (hour > 12 || hour <= 0) { if (raiseParseDataError) { throw new AsterixTemporalTypeParseException( "Hour " + hour + " cannot be a time for AM/PM.");
<|startcomment|> MAJOR SonarQube violation: Refactor this code to not nest more than 4 if/for/while/switch/try statements. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS134 <|endcomment|>  } else { return false; } } if (byteArrayEqualToString(data, dataStart + dataStringPointer, 2, AM_BYTEARRAY)) { // do nothing } else if (byteArrayEqualToString(data, dataStart + dataStringPointer, 2, PM_BYTEARRAY)) { hour += 12; if (hour == 24) { hour = 0; } } else { if (raiseParseDataError) { <|startfocus|> throw new AsterixTemporalTypeParseException( "Unexpected string for AM/PM marker " + decode(data, dataStart + dataStringPointer, dataStart + dataStringPointer + 2)); <|endfocus|> } else { return false; } } dataStringPointer += 2; } else { if (raiseParseDataError) { throw new AsterixTemporalTypeParseException("Cannot find valid AM/PM marker."); } else { return false; } } break; case SKIPPER: // just skip all continuous character and numbers
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  public long getWrites() { try { List<String> rows = getInfo(); long writes = extractRow(rows, 5); long cancelledWrites = extractRow(rows, 6); <|startfocus|> return (writes - cancelledWrites); <|endfocus|> } catch (Exception e) { LOGGER.log(failureCount++ > 0 ? Level.DEBUG : Level.WARN, "Failure getting writes", e); return IOCounterDefault.IO_COUNTER_UNAVAILABLE; }
<|startcomment|> MAJOR SonarQube violation: Merge this if statement with the enclosing one. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1066 <|endcomment|>  "Input stream given to OnDiskInvertedIndex bulk load is not sorted."); } } // Remember last tuple by creating a copy. // TODO: This portion can be optimized by only copying the token when it changes, and using the last appended inverted-list element as a reference. lastTupleBuilder.reset(); for (int i = 0; i < tuple.getFieldCount(); i++) { lastTupleBuilder.addField(tuple.getFieldData(i), tuple.getFieldStart(i), tuple.getFieldLength(i)); <|startfocus|> } <|endfocus|> } @Override public void end() throws HyracksDataException { // The last tuple builder is empty if add() was never called. if (lastTupleBuilder.getSize() != 0) { createAndInsertBTreeTuple(); } btreeBulkloader.end(); if (currentPage != null) { queue.put(currentPage); } invListsMaxPageId = currentPageId; bufferCache.finishQueue(); } @Override public void abort() throws HyracksDataException { if (btreeBulkloader != null) { btreeBulkloader.abort(); } } } @Override
<|startcomment|> MAJOR SonarQube violation: Split this 163 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  lastTupleBuilder.reset(); for (int i = 0; i < tuple.getFieldCount(); i++) { lastTupleBuilder.addField(tuple.getFieldData(i), tuple.getFieldStart(i), tuple.getFieldLength(i)); } } @Override public void end() throws HyracksDataException { // The last tuple builder is empty if add() was never called. if (lastTupleBuilder.getSize() != 0) { createAndInsertBTreeTuple(); <|startfocus|> } <|endfocus|> btreeBulkloader.end(); if (currentPage != null) { queue.put(currentPage); } invListsMaxPageId = currentPageId; bufferCache.finishQueue(); } @Override public void abort() throws HyracksDataException { if (btreeBulkloader != null) { btreeBulkloader.abort(); } } } @Override public IBufferCache getBufferCache() { return bufferCache; } public int getInvListsFileId() { return fileId; } public int getInvListsMaxPageId() { return invListsMaxPageId; } @Override public IBinaryComparatorFactory[] getInvListCmpFactories() {
<|startcomment|> MAJOR SonarQube violation: Split this 163 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  } public class OnDiskInvertedIndexAccessor implements IInvertedIndexAccessor { private final OnDiskInvertedIndex index; private final IInvertedIndexSearcher searcher; private final IIndexOperationContext opCtx = new OnDiskInvertedIndexOpContext(btree); public OnDiskInvertedIndexAccessor(OnDiskInvertedIndex index) throws HyracksDataException { this.index = index; this.searcher = new TOccurrenceSearcher(ctx, index); } // Let subclasses initialize. protected OnDiskInvertedIndexAccessor(OnDiskInvertedIndex index, IInvertedIndexSearcher searcher) { this.index = index; this.searcher = searcher; } @Override <|startfocus|> public IIndexCursor createSearchCursor(boolean exclusive) { return new OnDiskInvertedIndexSearchCursor(searcher, index.getInvListTypeTraits().length); <|endfocus|> } @Override public void search(IIndexCursor cursor, ISearchPredicate searchPred) throws HyracksDataException { searcher.search((OnDiskInvertedIndexSearchCursor) cursor, (InvertedIndexSearchPredicate) searchPred, opCtx); } @Override public IInvertedListCursor createInvertedListCursor() { return index.createInvertedListCursor(); } @Override public void openInvertedListCursor(IInvertedListCursor listCursor, ITupleReference searchKey) throws HyracksDataException {
<|startcomment|> MAJOR SonarQube violation: Remove those useless parentheses. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AUselessParenthesesCheck <|endcomment|>  public void setKeyTuple(ITupleReference key) { <|startfocus|> newToken = (this.keyTuple == null); <|endfocus|> this.keyTuple = key;
<|startcomment|> what's the rationale behind changing this method? <|endcomment|>  for (int i = 0; i < end; i++) { if (bloomFilters[i] != null && !bloomFilters[i].contains(keysOnlyTuple, hashes)) { continue; } deletedKeysBTreeAccessors.get(i).search(deletedKeysBTreeCursors[i], keySearchPred); try { if (deletedKeysBTreeCursors[i].hasNext()) { return true; } } finally { deletedKeysBTreeCursors[i].close(); } } return false; } @Override public void doClose() throws HyracksDataException { <|startfocus|> <<<<<<< HEAD <|endfocus|> try { super.doClose(); } finally { if (deletedKeysBTreeCursors != null) { for (int i = 0; i < deletedKeysBTreeCursors.length; i++) { deletedKeysBTreeCursors[i].close(); } } } ======= if (deletedKeysBTreeCursors != null) { for (int i = 0; i < deletedKeysBTreeCursors.length; i++) { deletedKeysBTreeCursors[i].close(); } } super.doClose(); >>>>>>> initial commit } @Override public void doDestroy() throws HyracksDataException {
<|startcomment|> Remove this comment? <|endcomment|>  IIndex invIndex = testCtx.getIndex(); if (LOGGER.isInfoEnabled()) { LOGGER.info("Validating index: " + invIndex); } // Validate index and compare against expected index. invIndex.validate(); if (invIndexType == InvertedIndexType.INMEMORY || invIndexType == InvertedIndexType.ONDISK) { // This comparison method exercises different features of these types of inverted indexes. LSMInvertedIndexTestUtils.compareActualAndExpectedIndexes(testCtx); } <|startfocus|> //LSMInvertedIndexTestUtils.compareActualAndExpectedIndexesRangeSearch(testCtx); <|endfocus|> if (invIndexType == InvertedIndexType.LSM || invIndexType == InvertedIndexType.PARTITIONED_LSM) { LSMInvertedIndex lsmIndex = (LSMInvertedIndex) invIndex; if (!lsmIndex.isMemoryComponentsAllocated() || lsmIndex.isCurrentMutableComponentEmpty()) { LSMInvertedIndexTestUtils.compareActualAndExpectedIndexesMergeSearch(testCtx); } } } /** * Runs a workload of queries using different search modifiers, and verifies the correctness of the results. */ protected void runTinySearchWorkload(LSMInvertedIndexTestContext testCtx, TupleGenerator tupleGen) throws IOException { for (IInvertedIndexSearchModifier searchModifier : TEST_SEARCH_MODIFIERS) {
<|startcomment|> just return true? get rid of nullable variable? <|endcomment|>  * @throws AlgebricksException */ public boolean isSubFieldNullable(List<String> subFieldName) throws AlgebricksException { IAType subRecordType = getFieldType(subFieldName.get(0)); boolean nullable = false; for (int i = 1; i < subFieldName.size(); i++) { if (subRecordType == null) { // open field is nullable return true; } if (subRecordType.getTypeTag().equals(ATypeTag.UNION)) { if (NonTaggedFormatUtil.isOptional(subRecordType)) { <|startfocus|> nullable = true; <|endfocus|> } subRecordType = ((AUnionType) subRecordType).getActualType(); if (subRecordType.getTypeTag() != ATypeTag.OBJECT) { throw new AsterixException( "Field accessor is not defined for values of type " + subRecordType.getTypeTag()); } } subRecordType = ((ARecordType) subRecordType).getFieldType(subFieldName.get(i)); } return nullable || subRecordType == null || NonTaggedFormatUtil.isOptional(subRecordType); } /**
<|startcomment|> MAJOR SonarQube violation: Split this 147 characters long line (which is greater than 120 authorized). Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS00103 <|endcomment|>  boolean changed = changeRec(expr, arg); if (!checkArgs(expr) || !expr.isFunctional()) { return new Pair<>(changed, expr); } // Skip Constant Folding for the record-related functions. if (FUNC_ID_SET_THAT_SHOULD_NOT_BE_APPLIED.contains(expr.getFunctionIdentifier())) { return new Pair<>(false, null); } try { <|startfocus|> //Current List SerDe assumes a strongly typed list, so we do not constant fold the list constructors if they are not strongly typed <|endfocus|> if (expr.getFunctionIdentifier().equals(BuiltinFunctions.UNORDERED_LIST_CONSTRUCTOR) || expr.getFunctionIdentifier().equals(BuiltinFunctions.ORDERED_LIST_CONSTRUCTOR)) { AbstractCollectionType listType = (AbstractCollectionType) TypeCastUtils.getRequiredType(expr); if (listType != null && (listType.getItemType().getTypeTag() == ATypeTag.ANY || listType.getItemType() instanceof AbstractCollectionType)) { //case1: listType == null, could be a nested list inside a list<ANY> //case2: itemType = ANY //case3: itemType = a nested list
<|startcomment|> CRITICAL SonarQube violation: Either log or rethrow this exception. Read more: https://asterix-sonar.ics.uci.edu/coding_rules#rule_key=squid%3AS1166 <|endcomment|>  IScalarEvaluator eval = fact.createScalarEvaluator(null); eval.evaluate(null, p); Object t = _emptyTypeEnv.getType(expr); @SuppressWarnings("rawtypes") ISerializerDeserializer serde = jobGenCtx.getSerializerDeserializerProvider().getSerializerDeserializer(t); bbis.setByteBuffer(ByteBuffer.wrap(p.getByteArray(), p.getStartOffset(), p.getLength()), 0); IAObject o = (IAObject) serde.deserialize(dis); return new Pair<>(true, new ConstantExpression(new AsterixConstantValue(o))); <|startfocus|> } catch (HyracksDataException | AlgebricksException e) { <|endfocus|> return new Pair<>(false, null); } } @Override public Pair<Boolean, ILogicalExpression> visitAggregateFunctionCallExpression( AggregateFunctionCallExpression expr, Void arg) throws AlgebricksException { boolean changed = changeRec(expr, arg); return new Pair<>(changed, expr); } @Override public Pair<Boolean, ILogicalExpression> visitStatefulFunctionCallExpression( StatefulFunctionCallExpression expr, Void arg) throws AlgebricksException { boolean changed = changeRec(expr, arg); return new Pair<>(changed, expr); } @Override
<|startcomment|> Why this was removed? the rule scans the whole plan starting from the root. why run rewritePre() on each operator? <|endcomment|>  empty-tuple-source -- |UNPARTITIONED| assign [$$29] <- [TRUE] -- |UNPARTITIONED| assign [$$26] <- [TRUE] -- |UNPARTITIONED| data-scan []<-[$$20, $$21, $$2] <- tpch:LineItems -- |UNPARTITIONED| empty-tuple-source -- |UNPARTITIONED| */ public class InlineSubplanInputForNestedTupleSourceRule implements IAlgebraicRewriteRule { @Override public boolean rewritePre(Mutable<ILogicalOperator> opRef, IOptimizationContext context) <|startfocus|> throws AlgebricksException { <|endfocus|> if (context.checkIfInDontApplySet(this, opRef.getValue())) { return false; } Pair<Boolean, LinkedHashMap<LogicalVariable, LogicalVariable>> result = rewriteSubplanOperator(opRef, context); return result.first; } private Pair<Boolean, LinkedHashMap<LogicalVariable, LogicalVariable>> rewriteSubplanOperator( Mutable<ILogicalOperator> opRef, IOptimizationContext context) throws AlgebricksException { AbstractLogicalOperator op = (AbstractLogicalOperator) opRef.getValue(); // Recursively traverses input operators as if the current operator before rewriting the current operator. Pair<Boolean, LinkedHashMap<LogicalVariable, LogicalVariable>> changedAndVarMap = traverseNonSubplanOperator(op, context);
<|startcomment|> counter.set(context.getVarCounter()) <|endcomment|>  translator.addVariableToMetaScope(new VarIdentifier("$$RIGHT_" + i), rightInputVarCopy); for (int j = 0; j < rightInputPKs.size(); j++) { rightInputVarCopy = copyVisitor.varCopy(rightInputPKs.get(j)); translator.addVariableToMetaScope(new VarIdentifier("$$RIGHTPK_" + i + "_" + j), rightInputVarCopy); } copyVisitor.updatePrimaryKeys(context); copyVisitor.reset(); } <|startfocus|> int incrementedCounter = context.getVarCounter() - contextCounter; counter.set(counter.get() + incrementedCounter); <|endfocus|> AQLPlusParser parser = new AQLPlusParser(new StringReader(aqlPlus)); parser.initScope(); parser.setVarCounter(counter); List<Clause> clauses; try { clauses = parser.Clauses(); } catch (ParseException e) { throw new AlgebricksException(e); } // Step 4. The essential substitution with translator. ILogicalPlan plan; try { plan = translator.translate(clauses); } catch (AsterixException e) { throw new AlgebricksException(e); } context.setVarCounter(counter.get()); 
<|startcomment|> nit: can now reformat this code in a less strange way <|endcomment|>  } while (triggerCount == previousTriggerCount); return triggerCount; } /** * Test time-based invalidation in CatalogdTableInvalidator. */ @Test public void testCatalogdTableInvalidator() throws CatalogException, InterruptedException { Reference<Boolean> tblWasRemoved = new Reference<>(); Reference<Boolean> dbWasAdded = new Reference<>(); String dbName = "functional"; String tblName = "alltypes"; <|startfocus|> catalog_ .invalidateTable(new TTableName(dbName, tblName), tblWasRemoved, dbWasAdded); <|endfocus|> MockTicker ticker = new MockTicker(); CatalogdTableInvalidator.TIME_SOURCE = ticker; catalog_.setCatalogdTableInvalidator( new CatalogdTableInvalidator(catalog_, /*unusedTableTtlSec=*/ 2, /*invalidateTablesOnMemoryPressure=*/false, /*oldGenFullThreshold=*/ 0.6, /*gcInvalidationFraction=*/0.1)); Assert.assertFalse(catalog_.getDb(dbName).getTable(tblName).isLoaded()); Table table = catalog_.getOrLoadTable(dbName, tblName); Assert.assertTrue(table.isLoaded()); Assert.assertEquals(ticker.now_, table.getLastUsedTime()); long previousTriggerCount = catalog_.getCatalogdTableInvalidator().triggerCount_.get();
<|startcomment|> spelling: thread-local <|endcomment|>  profile_ = new TRuntimeProfileNode("Frontend", /*num_children=*/ 0, /*counters=*/new ArrayList<>(), /*metadata=*/-1L, // TODO(todd) what is this used for? why is it required? /*indent=*/false, /*info_strings=*/new HashMap<>(), /*info_strings_display_order*/new ArrayList<>(), /*child_counters_map=*/ImmutableMap.of(ROOT_COUNTER_NAME, new HashSet<>())); } /** <|startfocus|> * Create a new profile, setting it as the current thread-lcoal profile for the <|endfocus|> * length of the current scope. This is meant to be used in a try-with-resources * statement. */ public static Scope createNewWithScope() { return new Scope(new FrontendProfile()); } /** * Get the profile attached to the current thread, throw IllegalStateException if there * is none. */ @Nonnull public static FrontendProfile getCurrent() { FrontendProfile prof = THREAD_LOCAL.get(); Preconditions.checkState(prof != null, "no profile in scope"); return prof; } /**
<|startcomment|> How about: Table invalidation due to memory pressure was skipped. <|endcomment|>  private boolean shouldEvictFromFullHeapAfterGc() { if (!invalidateTableOnMemoryPressure_) return false; long gcCount = oldGenGcBean_.getCollectionCount(); if (gcCount > lastObservedGcCount_) { lastObservedGcCount_ = gcCount; GcInfo lastGcInfo = oldGenGcBean_.getLastGcInfo(); if (lastGcInfo == null) { <|startfocus|> LOG.warn("gcBean.getLastGcInfo() returns null. Will continue without " + "invalidating tables based on memory pressure this time."); <|endfocus|> return false; } MemoryUsage tenuredGenUsage = lastGcInfo.getMemoryUsageAfterGc().get(oldGcGenName_); return tenuredGenUsage.getMax() * oldGenFullThreshold_ < tenuredGenUsage.getUsed(); } return false;
<|startcomment|> from the docs, getMemoryUsageAfterGc should be non-null and given that we found the pool on L163, this should also be non-null. add a precondition for this? <|endcomment|>  long gcCount = oldGenGcBean_.getCollectionCount(); if (gcCount > lastObservedGcCount_) { lastObservedGcCount_ = gcCount; GcInfo lastGcInfo = oldGenGcBean_.getLastGcInfo(); if (lastGcInfo == null) { LOG.warn("gcBean.getLastGcInfo() returns null. Will continue without " + "invalidating tables based on memory pressure this time."); return false; } <|startfocus|> MemoryUsage tenuredGenUsage = lastGcInfo.getMemoryUsageAfterGc().get(oldGcGenName_); <|endfocus|> return tenuredGenUsage.getMax() * oldGenFullThreshold_ < tenuredGenUsage.getUsed(); } return false;
<|startcomment|> Do we need to do this for CreateFunction? <|endcomment|>  if (removedDb == null) { // Nothing was removed from the catalogd's cache. resp.result.setVersion(catalog_.getCatalogVersion()); return; } // Make sure the cache directives, if any, of the underlying tables are removed for (String tableName: removedDb.getAllTableNames()) { uncacheTable(removedDb.getTable(tableName)); } removedObject = removedDb.toTCatalogObject(); } <|startfocus|> updateDatabasePrivileges(db.getName(), /* tableName */ null, params.server_name, <|endfocus|> db.getMetaStoreDb().getOwnerName(), db.getMetaStoreDb().getOwnerType(), /* newOwner */ null, /* newOwnerType */ null, resp); Preconditions.checkNotNull(removedObject); resp.result.setVersion(removedObject.getCatalog_version()); resp.result.addToRemoved_catalog_objects(removedObject); addSummary(resp, "Database has been dropped."); } /** * Drops all the Kudu tables of database 'db' from the Kudu storage engine. Retrieves * the Kudu table name of each table in 'db' from HMS. Throws an ImpalaException if
<|startcomment|> line too long (92 > 90) <|endcomment|>  table = catalog_.removeTable(params.getTable_name().db_name, params.getTable_name().table_name); if (table == null) { // Nothing was removed from the catalogd's cache. resp.result.setVersion(catalog_.getCatalogVersion()); return; } resp.result.setVersion(table.getCatalogVersion()); uncacheTable(table); } if (table.getMetaStoreTable() != null) { <|startfocus|> updateDatabasePrivileges(table.getDb().getName(), table.getName(), params.server_name, table.getMetaStoreTable().getOwner(), table.getMetaStoreTable().getOwnerType(), /* newOwner */ null, /* newOwnerType */ null, resp); <|endfocus|> } removedObject.setType(TCatalogObjectType.TABLE); removedObject.setTable(new TTable()); removedObject.getTable().setTbl_name(tableName.getTbl()); removedObject.getTable().setDb_name(tableName.getDb()); removedObject.setCatalog_version(resp.result.getVersion()); resp.result.addToRemoved_catalog_objects(removedObject); } /**
<|startcomment|> line too long (96 > 90) <|endcomment|>  // list of the revoked privileges that contain the grant option. The rolePrivileges // parameter will contain a list of new privileges without the grant option that are // granted. If this is simply a revoke of a privilege without grant options, the // api will still return revoked privileges, but the rolePrivileges will be empty // since there will be no newly granted privileges. rolePrivileges = Lists.newArrayList(); <|startfocus|> removedGrantOptPrivileges = catalog_.getSentryProxy().revokeRolePrivileges(requestingUser, roleName, privileges, grantRevokePrivParams.isHas_grant_opt(), rolePrivileges); <|endfocus|> addSummary(resp, "Privilege(s) have been revoked."); } Preconditions.checkNotNull(rolePrivileges); List<TCatalogObject> updatedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv: rolePrivileges) { updatedPrivs.add(rolePriv.toTCatalogObject()); } List<TCatalogObject> removedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv: removedGrantOptPrivileges) { removedPrivs.add(rolePriv.toTCatalogObject()); } 
<|startcomment|> are these meant to be 'added'? <|endcomment|>  } resp.result.setVersion(role.getCatalogVersion()); } /** * Grants or revokes one or more privileges to/from a Sentry role on behalf of the * requestingUser. */ private void grantRevokeRolePrivilege(User requestingUser, TGrantRevokePrivParams grantRevokePrivParams, TDdlExecResponse resp) throws ImpalaException { Preconditions.checkNotNull(requestingUser); verifySentryServiceEnabled(); String roleName = grantRevokePrivParams.getRole_name(); List<TPrivilege> privileges = grantRevokePrivParams.getPrivileges(); <|startfocus|> List<PrincipalPrivilege> rolePrivileges = null; <|endfocus|> List<PrincipalPrivilege> removedGrantOptPrivileges = Lists.newArrayList(); if (grantRevokePrivParams.isIs_grant()) { rolePrivileges = catalog_.getSentryProxy().grantRolePrivileges(requestingUser, roleName, privileges); addSummary(resp, "Privilege(s) have been granted."); } else { // If this is a revoke of a privilege that contains the grant option, the privileges // with the grant option will be revoked and new privileges without the grant option
<|startcomment|> what's special about the first one? is there some homogeneity assumption here that should rather be a param? <|endcomment|>  } if (!updatedPrivs.isEmpty() || !removedPrivs.isEmpty()) { // If this is a REVOKE statement with hasGrantOpt, only the GRANT OPTION is removed // from the privileges. Otherwise the privileges are removed from the catalog. if (grantRevokePrivParams.isIs_grant()) { resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setVersion( updatedPrivs.get(updatedPrivs.size() - 1).getCatalog_version()); <|startfocus|> } else if (privileges.get(0).isHas_grant_opt()) { <|endfocus|> resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setRemoved_catalog_objects(removedPrivs); resp.result.setVersion( updatedPrivs.get(updatedPrivs.size() - 1).getCatalog_version() > removedPrivs.get(removedPrivs.size() - 1).getCatalog_version() ? updatedPrivs.get(updatedPrivs.size() - 1).getCatalog_version() : removedPrivs.get(removedPrivs.size() - 1).getCatalog_version()); } else { resp.result.setRemoved_catalog_objects(removedPrivs); resp.result.setVersion(
<|startcomment|> nit: space before -= <|endcomment|>  private static final String ERROR_MSG_BAD_COLUMN_VALUE = "Raw value '" + ROW_BAD_COLUMN_VALUE + "' couldn't be parsed to type Type: int8 for column 'byteFld'"; private static final String POLICY_REJECT = "REJECT"; private static final String POLICY_WARN = "WARN"; private static final String POLICY_IGNORE = "IGNORE"; @Rule <|startfocus|> public ExpectedException thrown= ExpectedException.none(); <|endfocus|> @Test public void testMissingColumnThrowsExceptionDefaultConfig() throws Exception { Context additionalContext = new Context(); additionalContext.put(PATTERN_PROP, TEST_REGEXP_MISSING_COLUMN); testThrowsException(additionalContext, ERROR_MSG_MISSING_COLUMN, ROW_MISSING_COLUMN); } @Test public void testMissingColumnThrowsExceptionDeprecated() throws Exception { Context additionalContext = new Context(); additionalContext.put(PATTERN_PROP, TEST_REGEXP_MISSING_COLUMN); additionalContext.put(SKIP_MISSING_COLUMN_PROP, String.valueOf(false)); testThrowsException(additionalContext, ERROR_MSG_MISSING_COLUMN, ROW_MISSING_COLUMN); } @Test public void testMissingColumnThrowsException() throws Exception { Context additionalContext = new Context();
<|startcomment|> nit: plus <|endcomment|>  * The phases of aggregate computation are as follows. Also see AggregateInfo. * - Only a non-distinct class: * - Example: SELECT max(a) FROM... * - 1-phase aggregation * - One distinct class, and optionally a non-distinct class: * - Example: SELECT count(distinct a)[, max(b)] FROM... * - coalesced into a single AggregateInfo to preserve the pre-IMPALA-110 behavior <|startfocus|> * - 2-phase aggregation, 1st phase groups by GROUP BY ples DISTINCT exprs, 2nd phase <|endfocus|> * groups by GROUP BY * - the non-distinct class is carried along the two phases, aggregated in 1st phase and * merged in 2nd phase * - Multiple distinct classes, and optionally a non-distinct class * - Example: SELECT count(distinct a), count(distinct b)[, max(c)] FROM... * - 2-phase aggregation followed by a transposition aggregation * - aggregation nodes update and maintain the state of all aggregation classes at once
<|startcomment|> nit, simplify: scan happened. <|endcomment|>  */ final private Thread daemonThread_; /** * The threshold above which the old gen is considered almost full. */ final private double oldGenFullThreshold_; /** * The ratio of tables to invalidate when the old gen is almost full. */ final private double gcInvalidationFraction_; /** * The number of times the daemon thread wakes up and scans the tables for invalidation. <|startfocus|> * It's useful for tests to ensure that a scanning occurred and to proceed. <|endfocus|> */ @VisibleForTesting AtomicLong scanCount_ = new AtomicLong(); private GarbageCollectorMXBean oldGenGcBean_; /** * The name of the old gen memory pool. */ private String oldGcGenName_; /** * The value of oldGenGcBean_.getCollectionCount() when the last memory-based * invalidation was executed. */ private long lastObservedGcCount_; private boolean stopped_ = false; /** * Last time an time-based invalidation is executed in nanoseconds. */ private long lastInvalidationTime_; 
<|startcomment|> nit: returned <|endcomment|>  private boolean shouldEvictFromFullHeapAfterGc() { if (!invalidateTableOnMemoryPressure_) return false; long gcCount = oldGenGcBean_.getCollectionCount(); if (gcCount > lastObservedGcCount_) { lastObservedGcCount_ = gcCount; GcInfo lastGcInfo = oldGenGcBean_.getLastGcInfo(); if (lastGcInfo == null) { <|startfocus|> LOG.warn("gcBean.getLastGcInfo() returns null. Will continue without " + "invalidating tables based on memory pressure this time."); <|endfocus|> return false; } MemoryUsage tenuredGenUsage = lastGcInfo.getMemoryUsageAfterGc().get(oldGcGenName_); return tenuredGenUsage.getMax() * oldGenFullThreshold_ < tenuredGenUsage.getUsed(); } return false;
<|startcomment|> nit: condense to (example: owner pr..). <|endcomment|>  * If a user with the same name already exists it will be overwritten. */ public User addUser(String userName) { Principal user = addPrincipal(userName, Sets.<String>newHashSet(), TPrincipalType.USER); Preconditions.checkState(user instanceof User); return (User) user; } /** * Add a user to the catalog if it doesn't exist. This is necessary so privileges <|startfocus|> * can be added for a user. For example owner privileges. <|endfocus|> */ public org.apache.impala.catalog.User addUserIfNotExists(String owner) { versionLock_.writeLock().lock(); try { org.apache.impala.catalog.User user = getAuthPolicy().getUser(owner); if (user == null) { user = addUser(owner); } return user; } finally { versionLock_.writeLock().unlock(); } } private Principal addPrincipal(String principalName, Set<String> grantGroups, TPrincipalType type) { versionLock_.writeLock().lock(); try { Principal principal = Principal.newInstance(principalName, type, grantGroups);
<|startcomment|> removing <|endcomment|>  PrincipalPrivilege privilege = owner.getPrivilege(filter.getPrivilege_name()); if (privilege != null) { PrincipalPrivilege removedPrivilege = catalog_.getAuthPolicy() .removePrivilege(privilege); removedPrivilege.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToRemoved_catalog_objects(removedPrivilege .toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } } } catch (CatalogException e) { <|startfocus|> LOG.error("Error modifying privilege: ", e); <|endfocus|> } } /** * This is a helper method to take care of catalog related updates when removing * a privilege. */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; if (ownerType == PrincipalType.USER) { owner = catalog_.addUserIfNotExists(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER);
<|startcomment|> adding <|endcomment|>  } else { owner = catalog_.getAuthPolicy().getRole(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog_.addRolePrivilege(ownerString, filter); } owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToUpdated_catalog_objects(cPrivilege.toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } catch (CatalogException e) { <|startfocus|> LOG.error("Error modifying privilege: ", e); <|endfocus|> } } /** * Create a new HMS Partition. */ private static Partition createHmsPartition(List<TPartitionKeyValue> partitionSpec, org.apache.hadoop.hive.metastore.api.Table msTbl, TableName tableName, String location) { List<String> values = Lists.newArrayList(); // Need to add in the values in the same order they are defined in the table. for (FieldSchema fs: msTbl.getPartitionKeys()) { for (TPartitionKeyValue kv: partitionSpec) {
<|startcomment|> something looks off with this change: prior, this branch was run only when the user already existed. that can be fixed by adding a Reference bool parameter to the method indicating if the user was added or not. the other thing I'll note is that prior, there was less contention for the write lock. since we have multiple ways to add a user, this will compete with all other operations. this may be something to look at again when we stress it. <|endcomment|>  Map<String, Set<TSentryPrivilege>> allUsersPrivileges = sentryPolicyService_.listAllUsersPrivileges(processUser_); for (Map.Entry<String, Set<TSentryPrivilege>> userPrivilegesEntry: allUsersPrivileges.entrySet()) { String userName = userPrivilegesEntry.getKey(); // This user exists and should not be removed so remove it from the // usersToRemove set. usersToRemove.remove(userName); <|startfocus|> org.apache.impala.catalog.User user = catalog_.addUserIfNotExists(userName); if (resetVersions_) { <|endfocus|> user.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); } refreshPrivilegesInCatalog(user, allUsersPrivileges); } return usersToRemove; } /** * Updates the privileges for a given principal in the catalog since the last Sentry * sync update. */ private void refreshPrivilegesInCatalog(Principal principal, Map<String, Set<TSentryPrivilege>> allPrincipalPrivileges) throws CatalogException { // Assume all privileges should be removed. Privileges that still exist are // deleted from this set and we are left with the set of privileges that need // to be removed.
<|startcomment|> Style: if statements should always have {} braces and conform to normal Java formatting. That said you don't need an if statement here at all ands can use ? : construct. <|endcomment|>  TableName tableName = table.getTableName(); PrivilegeRequestBuilder builder = new PrivilegeRequestBuilder() .onTable(tableName.getDb(), tableName.getTbl()) .allOf(priv); if (requireGrantOption) { builder.grantOption(); } registerPrivReq(builder.toRequest()); } /** * Returns the server name if authorization is enabled. Returns null when authorization * is not enabled. */ public String getServerName() { <|startfocus|> if (getAuthzConfig().isEnabled()) return getAuthzConfig().getServerName(); return null; <|endfocus|> } } 
<|startcomment|> Style: The first sentence of Javadoc is used in special ways - it should be a very short description of what the method is doing. <|endcomment|>  } } Preconditions.checkNotNull(newDb); // TODO(todd): if client is a 'v2' impalad, only send back invalidation resp.result.addToUpdated_catalog_objects(newDb.toTCatalogObject()); } updateOwnerPrivileges(newDb.getName(), /* tableName */ null, params.server_name, /* oldOwner */ null, /* oldOwnerType */ null, newDb.getMetaStoreDb().getOwnerName(), newDb.getMetaStoreDb().getOwnerType(), resp); resp.result.setVersion(newDb.getCatalogVersion()); } <|startfocus|> /** <|endfocus|> * If object ownership is enabled in Sentry, we need to update the owner privilege * in the catalog so that any subsequent statements that rely on that privilege, or * the absence, will function correctly without waiting for the next refresh. * If oldOwner is not null, the privilege will be removed. If newOwner is not null, * the privilege will be added. * The catalog will correctly reflect the owner in HMS, however because the owner
<|startcomment|> Style: it is better to use isEmpty() rather then compare size with 0. <|endcomment|>  String serverName, String oldOwner, PrincipalType oldOwnerType, String newOwner, PrincipalType newOwnerType, TDdlExecResponse resp) { if (catalog_.getSentryProxy() == null || !catalog_.getSentryProxy() .isObjectOwnershipEnabled()) return; Preconditions.checkNotNull(serverName); TPrivilege filter; if (tableName == null) { filter = createDatabaseOwnerPrivilegeFilter(databaseName, serverName); } else { filter = createTableOwnerPrivilegeFilter(databaseName, tableName, serverName); } <|startfocus|> if(oldOwner != null && oldOwner.length() > 0) { <|endfocus|> removePrivilegeFromCatalog(oldOwner, oldOwnerType, filter, resp); } if(newOwner != null && newOwner.length() > 0) { addPrivilegeToCatalog(newOwner, newOwnerType, filter, resp); } } private void createFunction(TCreateFunctionParams params, TDdlExecResponse resp) throws ImpalaException { Function fn = Function.fromThrift(params.getFn()); if (LOG.isTraceEnabled()) { LOG.trace(String.format("Adding %s: %s", fn.getClass().getSimpleName(), fn.signatureString())); }
<|startcomment|> Can this fail? <|endcomment|>  PrincipalType newOwnerType, TDdlExecResponse resp) { if (catalog_.getSentryProxy() == null || !catalog_.getSentryProxy() .isObjectOwnershipEnabled()) return; Preconditions.checkNotNull(serverName); TPrivilege filter; if (tableName == null) { filter = createDatabaseOwnerPrivilegeFilter(databaseName, serverName); } else { filter = createTableOwnerPrivilegeFilter(databaseName, tableName, serverName); } <|startfocus|> if(oldOwner != null && oldOwner.length() > 0) { <|endfocus|> removePrivilegeFromCatalog(oldOwner, oldOwnerType, filter, resp); } if(newOwner != null && newOwner.length() > 0) { addPrivilegeToCatalog(newOwner, newOwnerType, filter, resp); } } private void createFunction(TCreateFunctionParams params, TDdlExecResponse resp) throws ImpalaException { Function fn = Function.fromThrift(params.getFn()); if (LOG.isTraceEnabled()) { LOG.trace(String.format("Adding %s: %s", fn.getClass().getSimpleName(), fn.signatureString())); } boolean isPersistentJavaFn =
<|startcomment|> Why are we setting different version for owner and removedPrivilege? <|endcomment|>  TPrivilege filter, TDdlExecResponse response) { try { Principal owner = catalog_.getAuthPolicy().getPrincipal(ownerString, ownerType == PrincipalType.ROLE ? TPrincipalType.ROLE : TPrincipalType.USER); if (owner != null) { PrincipalPrivilege privilege = owner.getPrivilege(filter.getPrivilege_name()); if (privilege != null) { PrincipalPrivilege removedPrivilege = catalog_.getAuthPolicy() .removePrivilege(privilege); removedPrivilege.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); <|startfocus|> owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); <|endfocus|> response.result.addToRemoved_catalog_objects(removedPrivilege .toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } } } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } } /** * This is a helper method to take care of catalog related updates when removing * a privilege. */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege;
<|startcomment|> Is it Ok to eat this error? <|endcomment|>  PrincipalPrivilege privilege = owner.getPrivilege(filter.getPrivilege_name()); if (privilege != null) { PrincipalPrivilege removedPrivilege = catalog_.getAuthPolicy() .removePrivilege(privilege); removedPrivilege.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToRemoved_catalog_objects(removedPrivilege .toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } } } catch (CatalogException e) { <|startfocus|> LOG.error("Error removing privilege: ", e); <|endfocus|> } } /** * This is a helper method to take care of catalog related updates when removing * a privilege. */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; Reference<Boolean> existingUser = new Reference<>(); if (ownerType == PrincipalType.USER) { owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId());
<|startcomment|> Why do you need Reference here? <|endcomment|>  } } } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } } /** * This is a helper method to take care of catalog related updates when removing * a privilege. */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; <|startfocus|> Reference<Boolean> existingUser = new Reference<>(); <|endfocus|> if (ownerType == PrincipalType.USER) { owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); } else { owner = catalog_.getAuthPolicy().getRole(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog_.addRolePrivilege(ownerString, filter); } if (!existingUser.getRef()) { owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); }
<|startcomment|> What if there is owner type distinct from USER or ROLE? <|endcomment|>  * a privilege. */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; Reference<Boolean> existingUser = new Reference<>(); if (ownerType == PrincipalType.USER) { owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); <|startfocus|> cPrivilege = catalog_.addUserPrivilege(ownerString, filter); <|endfocus|> } else { owner = catalog_.getAuthPolicy().getRole(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog_.addRolePrivilege(ownerString, filter); } if (!existingUser.getRef()) { owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); } response.result.addToUpdated_catalog_objects(cPrivilege.toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } catch (CatalogException e) { LOG.error("Error adding privilege: ", e); } } 
<|startcomment|> Owner is a shared entity - others may access/modify it as well - do you need any locking/synchronization here? <|endcomment|>  if (ownerType == PrincipalType.USER) { owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); } else { owner = catalog_.getAuthPolicy().getRole(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog_.addRolePrivilege(ownerString, filter); <|startfocus|> } if (!existingUser.getRef()) { <|endfocus|> owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); } response.result.addToUpdated_catalog_objects(cPrivilege.toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } catch (CatalogException e) { LOG.error("Error adding privilege: ", e); } } /** * Create a new HMS Partition. */ private static Partition createHmsPartition(List<TPartitionKeyValue> partitionSpec, org.apache.hadoop.hive.metastore.api.Table msTbl, TableName tableName, String location) {
<|startcomment|> Just use new ArrayList<>(), or better give an estimated size. Also you allocate it here but may overwrite later <|endcomment|>  } /** * Grants or revokes one or more privileges to/from a Sentry role on behalf of the * requestingUser. */ private void grantRevokeRolePrivilege(User requestingUser, TGrantRevokePrivParams grantRevokePrivParams, TDdlExecResponse resp) throws ImpalaException { Preconditions.checkNotNull(requestingUser); verifySentryServiceEnabled(); String roleName = grantRevokePrivParams.getRole_name(); List<TPrivilege> privileges = grantRevokePrivParams.getPrivileges(); List<PrincipalPrivilege> addedRolePrivileges = null; <|startfocus|> List<PrincipalPrivilege> removedGrantOptPrivileges = Lists.newArrayList(); <|endfocus|> if (grantRevokePrivParams.isIs_grant()) { addedRolePrivileges = catalog_.getSentryProxy().grantRolePrivileges(requestingUser, roleName, privileges); addSummary(resp, "Privilege(s) have been granted."); } else { // If this is a revoke of a privilege that contains the grant option, the privileges // with the grant option will be revoked and new privileges without the grant option // will be added. The privilege in the catalog cannot simply be updated since the
<|startcomment|> Just use new ArrayList<>() (or better specify the size) <|endcomment|>  // list of the revoked privileges that contain the grant option. The // addedRolePrivileges parameter will contain a list of new privileges without the // grant option that are granted. If this is simply a revoke of a privilege without // grant options, the api will still return revoked privileges, but the // addedRolePrivileges will be empty since there will be no newly granted // privileges. <|startfocus|> addedRolePrivileges = Lists.newArrayList(); <|endfocus|> removedGrantOptPrivileges = catalog_.getSentryProxy() .revokeRolePrivileges(requestingUser, roleName, privileges, grantRevokePrivParams.isHas_grant_opt(), addedRolePrivileges); addSummary(resp, "Privilege(s) have been revoked."); } Preconditions.checkNotNull(addedRolePrivileges); List<TCatalogObject> updatedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv: addedRolePrivileges) { updatedPrivs.add(rolePriv.toTCatalogObject()); } List<TCatalogObject> removedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv: removedGrantOptPrivileges) { removedPrivs.add(rolePriv.toTCatalogObject()); } 
<|startcomment|> Just use new ArrayList(addedRolePrivileges.size()). Also if you know that it will be an empty list or 1-element list you can avoid allocations at all. <|endcomment|>  // grant options, the api will still return revoked privileges, but the // addedRolePrivileges will be empty since there will be no newly granted // privileges. addedRolePrivileges = Lists.newArrayList(); removedGrantOptPrivileges = catalog_.getSentryProxy() .revokeRolePrivileges(requestingUser, roleName, privileges, grantRevokePrivParams.isHas_grant_opt(), addedRolePrivileges); addSummary(resp, "Privilege(s) have been revoked."); } Preconditions.checkNotNull(addedRolePrivileges); <|startfocus|> List<TCatalogObject> updatedPrivs = Lists.newArrayList(); <|endfocus|> for (PrincipalPrivilege rolePriv: addedRolePrivileges) { updatedPrivs.add(rolePriv.toTCatalogObject()); } List<TCatalogObject> removedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv: removedGrantOptPrivileges) { removedPrivs.add(rolePriv.toTCatalogObject()); } if (!updatedPrivs.isEmpty() || !removedPrivs.isEmpty()) { // If this is a REVOKE statement with hasGrantOpt, only the GRANT OPTION is removed // from the privileges. Otherwise the privileges are removed from the catalog.
<|startcomment|> Same as above. <|endcomment|>  // privileges. addedRolePrivileges = Lists.newArrayList(); removedGrantOptPrivileges = catalog_.getSentryProxy() .revokeRolePrivileges(requestingUser, roleName, privileges, grantRevokePrivParams.isHas_grant_opt(), addedRolePrivileges); addSummary(resp, "Privilege(s) have been revoked."); } Preconditions.checkNotNull(addedRolePrivileges); List<TCatalogObject> updatedPrivs = Lists.newArrayList(); for (PrincipalPrivilege rolePriv: addedRolePrivileges) { updatedPrivs.add(rolePriv.toTCatalogObject()); } <|startfocus|> List<TCatalogObject> removedPrivs = Lists.newArrayList(); <|endfocus|> for (PrincipalPrivilege rolePriv: removedGrantOptPrivileges) { removedPrivs.add(rolePriv.toTCatalogObject()); } if (!updatedPrivs.isEmpty() || !removedPrivs.isEmpty()) { // If this is a REVOKE statement with hasGrantOpt, only the GRANT OPTION is removed // from the privileges. Otherwise the privileges are removed from the catalog. if (grantRevokePrivParams.isIs_grant()) { resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setVersion(
<|startcomment|> can privileges be empty? <|endcomment|>  } if (!updatedPrivs.isEmpty() || !removedPrivs.isEmpty()) { // If this is a REVOKE statement with hasGrantOpt, only the GRANT OPTION is removed // from the privileges. Otherwise the privileges are removed from the catalog. if (grantRevokePrivParams.isIs_grant()) { resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setVersion( updatedPrivs.get(updatedPrivs.size() - 1).getCatalog_version()); <|startfocus|> } else if (privileges.get(0).isHas_grant_opt()) { <|endfocus|> resp.result.setUpdated_catalog_objects(updatedPrivs); resp.result.setRemoved_catalog_objects(removedPrivs); resp.result.setVersion( getLastItemVersion(updatedPrivs) > getLastItemVersion(removedPrivs) ? getLastItemVersion(updatedPrivs) : getLastItemVersion(removedPrivs)); } else { resp.result.setRemoved_catalog_objects(removedPrivs); resp.result.setVersion( removedPrivs.get(removedPrivs.size() - 1).getCatalog_version()); } } } /** * Returns the version from the last item in the list. This assumes that the items
<|startcomment|> Style: use ? : operator <|endcomment|>  } /** * Throws a CatalogException if the Sentry Service is not enabled. */ private void verifySentryServiceEnabled() throws CatalogException { if (catalog_.getSentryProxy() == null) { throw new CatalogException("Sentry Service is not enabled on the " + "CatalogServer."); } } /** * Checks if with grant is enabled for object ownership in Sentry. */ private boolean isObjectOwnershipGrantEnabled() { <|startfocus|> if (catalog_.getSentryProxy() == null) return false; return catalog_.getSentryProxy().isObjectOwnershipGrantEnabled(); <|endfocus|> } /** * Alters partitions in batches of size 'MAX_PARTITION_UPDATES_PER_RPC'. This * reduces the time spent in a single update and helps avoid metastore client * timeouts. */ private void bulkAlterPartitions(String dbName, String tableName, List<HdfsPartition> modifiedParts) throws ImpalaException { List<org.apache.hadoop.hive.metastore.api.Partition> hmsPartitions = Lists.newArrayList(); for (HdfsPartition p: modifiedParts) {
<|startcomment|> Do we need any locking here? Can getSentryProxy() become null after the check? <|endcomment|>  */ private void verifySentryServiceEnabled() throws CatalogException { if (catalog_.getSentryProxy() == null) { throw new CatalogException("Sentry Service is not enabled on the " + "CatalogServer."); } } /** * Checks if with grant is enabled for object ownership in Sentry. */ private boolean isObjectOwnershipGrantEnabled() { <|startfocus|> if (catalog_.getSentryProxy() == null) return false; return catalog_.getSentryProxy().isObjectOwnershipGrantEnabled(); <|endfocus|> } /** * Alters partitions in batches of size 'MAX_PARTITION_UPDATES_PER_RPC'. This * reduces the time spent in a single update and helps avoid metastore client * timeouts. */ private void bulkAlterPartitions(String dbName, String tableName, List<HdfsPartition> modifiedParts) throws ImpalaException { List<org.apache.hadoop.hive.metastore.api.Partition> hmsPartitions = Lists.newArrayList(); for (HdfsPartition p: modifiedParts) { org.apache.hadoop.hive.metastore.api.Partition msPart = p.toHmsPartition();
<|startcomment|> Is there a chance that we do this for the wrong database in case of a race condition? <|endcomment|>  originalOwnerName = msDb.getOwnerName(); originalOwnerType = msDb.getOwnerType(); msDb.setOwnerName(params.owner_name); msDb.setOwnerType(PrincipalType.valueOf(params.owner_type.name())); try { applyAlterDatabase(db); } catch (ImpalaRuntimeException e) { msDb.setOwnerName(originalOwnerName); msDb.setOwnerType(originalOwnerType); throw e; } } addDbToCatalogUpdate(db, response.result); <|startfocus|> updateOwnerPrivileges(db.getName(), /* tableName */ null, params.server_name, originalOwnerName, originalOwnerType, db.getMetaStoreDb().getOwnerName(), db.getMetaStoreDb().getOwnerType(), response); <|endfocus|> addSummary(response, "Updated database."); } private void addDbToCatalogUpdate(Db db, TCatalogUpdateResult result) { Preconditions.checkNotNull(db); // Updating the new catalog version and setting it to the DB catalog version while // holding the catalog version lock for an atomic operation. Most DB operations are // short-lived. It is unnecessary to have a fine-grained DB lock.
<|startcomment|> Use try-as-resource construct to open a client <|endcomment|>  } throw new InternalException(String.format("Error making '%s' RPC to " + "Sentry Service: ", type == TPrincipalType.ROLE ? "listAllRolesPrivileges" : "listAllUsersPrivileges"), e); } finally { client.close(); } } /** * Returns the configuration value for the specified key. Will return an empty string * if no value is set. */ public String getConfigValue(String key) throws ImpalaException { <|startfocus|> SentryServiceClient client = new SentryServiceClient(); try { <|endfocus|> return client.get().getConfigValue(key, ""); } catch (SentryUserException e) { throw new InternalException("Error making 'getConfigValue' RPC to Sentry Service: ", e); } finally { client.close(); } } /** * Utility function that converts a TSentryPrivilege to an Impala TPrivilege object. */ public static TPrivilege sentryPrivilegeToTPrivilege(TSentryPrivilege sentryPriv, Principal principal) { TPrivilege privilege = new TPrivilege(); privilege.setServer_name(sentryPriv.getServerName());
<|startcomment|> Why do you need config file? <|endcomment|>  public SentryProxy(SentryConfig sentryConfig, CatalogServiceCatalog catalog, String kerberosPrincipal) throws ImpalaException { Preconditions.checkNotNull(catalog); Preconditions.checkNotNull(sentryConfig); catalog_ = catalog; if (Strings.isNullOrEmpty(kerberosPrincipal)) { processUser_ = new User(System.getProperty("user.name")); } else { processUser_ = new User(kerberosPrincipal); } sentryPolicyService_ = new SentryPolicyService(sentryConfig); // For some tests, we create a config but may not have a config file. <|startfocus|> if (sentryConfig.getConfigFile() != null && sentryConfig.getConfigFile().length()>0) { <|endfocus|> objectOwnershipConfigValue_ = sentryPolicyService_ .getConfigValue(ServiceConstants.ServerConfig .SENTRY_DB_POLICY_STORE_OWNER_AS_PRIVILEGE); } else { objectOwnershipConfigValue_ = SentryOwnerPrivilegeType.NONE.toString(); } policyReader_.scheduleAtFixedRate(new PolicyReader(false), 0, BackendConfig.INSTANCE.getSentryCatalogPollingFrequency(), TimeUnit.SECONDS); } /** * Refreshes the authorization policy metadata by querying the Sentry Policy Service.
<|startcomment|> use isEmpty() <|endcomment|>  Preconditions.checkNotNull(catalog); Preconditions.checkNotNull(sentryConfig); catalog_ = catalog; if (Strings.isNullOrEmpty(kerberosPrincipal)) { processUser_ = new User(System.getProperty("user.name")); } else { processUser_ = new User(kerberosPrincipal); } sentryPolicyService_ = new SentryPolicyService(sentryConfig); // For some tests, we create a config but may not have a config file. <|startfocus|> if (sentryConfig.getConfigFile() != null && sentryConfig.getConfigFile().length()>0) { <|endfocus|> objectOwnershipConfigValue_ = sentryPolicyService_ .getConfigValue(ServiceConstants.ServerConfig .SENTRY_DB_POLICY_STORE_OWNER_AS_PRIVILEGE); } else { objectOwnershipConfigValue_ = SentryOwnerPrivilegeType.NONE.toString(); } policyReader_.scheduleAtFixedRate(new PolicyReader(false), 0, BackendConfig.INSTANCE.getSentryCatalogPollingFrequency(), TimeUnit.SECONDS); } /** * Refreshes the authorization policy metadata by querying the Sentry Policy Service. * There is currently no way to get a snapshot of the policy from the Sentry Service,
<|startcomment|> Could you add Javadocs to the class as well as to all public non-visiblefortesting methods, explaining how they work and how to use them? <|endcomment|> // software distributed under the License is distributed on an // "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.kudu.util; import javax.annotation.concurrent.NotThreadSafe; import java.nio.charset.StandardCharsets; import com.sangupta.murmur.Murmur2; import org.apache.yetus.audience.InterfaceAudience; import org.apache.yetus.audience.InterfaceStability; @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { <|startfocus|> private int nBits; private byte[] bitmap; private int nHashes; private byte[] byteBuffer; private HashFunction hashFunction; <|endfocus|> private BloomFilter(int nBits, byte[] bitmap, int nHashes, HashFunction hashFunction) { this.nBits = nBits; this.bitmap = bitmap; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2);
<|startcomment|> Curious why you chose to implement your own bitmap instead of reusing java.util.BitSet? <|endcomment|> // "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.kudu.util; import javax.annotation.concurrent.NotThreadSafe; import java.nio.charset.StandardCharsets; import com.sangupta.murmur.Murmur2; import org.apache.yetus.audience.InterfaceAudience; import org.apache.yetus.audience.InterfaceStability; @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { <|startfocus|> private int nBits; private byte[] bitmap; private int nHashes; private byte[] byteBuffer; private HashFunction hashFunction; <|endfocus|> private BloomFilter(int nBits, byte[] bitmap, int nHashes, HashFunction hashFunction) { this.nBits = nBits; this.bitmap = bitmap; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } 
<|startcomment|> Shouldn't this be nBits? I'm surprised this worked as-is; could you add a unit test that would fail or malfunction when this is nBytes? <|endcomment|>  public static BloomFilter ByCountAndFPRate(int expectedCount, double fpRate, HashFunction hashFunction) { int nBytes = optimalNumOfBytes(expectedCount, fpRate); int nBits = nBytes * 8; <|startfocus|> byte[] bitmap = new byte[nBytes]; int nHashes = computeOptimalHashCount(nBytes, optimalExpectedCount(nBytes, fpRate)); return new BloomFilter(nBits, bitmap, nHashes, hashFunction); <|endfocus|>
<|startcomment|> Nit: byteBuffer[0] = data ? 1 : 0; <|endcomment|>  public void put(boolean data) { <|startfocus|> if (data) { byteBuffer[0] = 1; } else { byteBuffer[0] = 0; } updateBitmap(byteBuffer, 1); <|endfocus|>
<|startcomment|> Should we precondition that bitmap.size >= length? <|endcomment|> <|startfocus|> private void updateBitmap(byte[] byteBuffer, int length) { <|endfocus|> long h = Murmur2.hash64(byteBuffer, length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = pickBit(tmp, nBits); bitmapSet(bitmap, bitPos); tmp = tmp + h2; }
<|startcomment|> Nit: tmp += h2; <|endcomment|>  private void updateBitmap(byte[] byteBuffer, int length) { long h = Murmur2.hash64(byteBuffer, length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { <|startfocus|> long bitPos = pickBit(tmp, nBits); bitmapSet(bitmap, bitPos); tmp = tmp + h2; <|endfocus|> }
<|startcomment|> Methods whose visibility has been increased for testing should be annotated with: @InterfaceAudience.LimitedPrivate("Testâ) Then you don't need the "This is for test" comments either. See https://github.com/apache/kudu/commit/abbde75e12f2275e1a286df60d788e9c5b411bcb for more details. <|endcomment|>  } } } private void updateBitmap(byte[] byteBuffer, int length) { long h = Murmur2.hash64(byteBuffer, length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = pickBit(tmp, nBits); bitmapSet(bitmap, bitPos); tmp = tmp + h2; } } <|startfocus|> // This is for test. <|endfocus|> public boolean mayContain(byte[] data) { return checkIfContains(data); } // This is for test. public boolean mayContain(boolean data) { byte[] byteBuffer = new byte[1]; if (data) { byteBuffer[0] = 1; } else { byteBuffer[0] = 0; } return checkIfContains(byteBuffer); } // This is for test. public boolean mayContain(byte data) { byte[] byteBuffer = new byte[1]; byteBuffer[0] = data; return checkIfContains(byteBuffer);
<|startcomment|> Nit: bitPos (camel-case) <|endcomment|>  private boolean checkIfContains(byte[] bytes) { long h = Murmur2.hash64(bytes, bytes.length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; int remHashes = nHashes; while (remHashes != 0) { <|startfocus|> long bitpos = pickBit(tmp, nBits); if (!bitmapTest(bitmap, bitpos)) { <|endfocus|> return false; } tmp = tmp + h2; remHashes--; } return true;
<|startcomment|> Nit: tmp += h2; <|endcomment|>  private boolean checkIfContains(byte[] bytes) { long h = Murmur2.hash64(bytes, bytes.length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; int remHashes = nHashes; while (remHashes != 0) { long bitpos = pickBit(tmp, nBits); if (!bitmapTest(bitmap, bitpos)) { return false; } <|startfocus|> tmp = tmp + h2; <|endfocus|> remHashes--; } return true;
<|startcomment|> Nit: reformat as: private static double kNaturalLog2 = 0.69314; (separate the assignment operator '=' from the variable name 'kNaturalLog2' with a space) <|endcomment|>  long h = Murmur2.hash64(bytes, bytes.length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; int remHashes = nHashes; while (remHashes != 0) { long bitpos = pickBit(tmp, nBits); if (!bitmapTest(bitmap, bitpos)) { return false; } tmp = tmp + h2; remHashes--; } return true; } <|startfocus|> private static double kNaturalLog2= 0.69314; <|endfocus|> private static int optimalNumOfBytes(int expectedCount, double fpRate) { if (fpRate == 0) { fpRate = Double.MIN_VALUE; } return (int) (-expectedCount * Math.log(fpRate) / (Math.log(2) * Math.log(2) * 8)); } private static int optimalExpectedCount(int nBytes, double fpRate) { int nBits = nBytes * 8; return (int) (Math.ceil(nBits * kNaturalLog2 * kNaturalLog2 / Math.log(fpRate))); } 
<|startcomment|> Nit: camel-case in Java, so 'nBits' <|endcomment|> <|startfocus|> private static int computeOptimalHashCount(int n_bits, int elems) { int nHashes = (int)(n_bits * kNaturalLog2 / elems); <|endfocus|> if (nHashes < 1) nHashes = 1; return nHashes;
<|startcomment|> By reusing the same seed, you'll get the exact same PRNG sequencing with every test run, so the test coverage will remain static. Why not seed using the system time or something like that? <|endcomment|> // software distributed under the License is distributed on an // "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.kudu.client; import static org.junit.Assert.assertTrue; import java.util.Random; import org.apache.kudu.util.BloomFilter; import org.junit.Test; public class TestBloomFilter { private int nBytes = 32 * 1024; <|startfocus|> private int kRandomSeed = 0xdeadbeef; <|endfocus|> private int nKeys = 2000; private double fpRate = 0.01; @Test public void testIntGenBFBySizeAndFPRate() { final BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); // Put integers into bloomfilter by random Random rand = new Random(kRandomSeed); for (int i = 0; i < nKeys; i++) { bf.put(rand.nextInt()); } // Reset the rand and check existence of the keys. rand = new Random(kRandomSeed);
<|startcomment|> 'Float' <|endcomment|> <|startfocus|> public void testFLoat() { <|endfocus|> final BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); // Put floats into bloomfilter by random Random rand = new Random(kRandomSeed); for (int i = 0; i < nKeys; i++) { bf.put(rand.nextFloat()); } // Reset the rand and check existence of the keys. rand = new Random(kRandomSeed); for (int i = 0; i < nKeys; i++) { assertTrue(bf.mayContain(rand.nextFloat())); }
<|startcomment|> it might be helpful to show the optional parameters too in the comment. <|endcomment|>  import java.util.List; import org.apache.impala.authorization.PrivilegeRequestBuilder; import org.apache.impala.common.AnalysisException; import org.apache.impala.common.InternalException; import org.apache.impala.common.Pair; import org.apache.impala.thrift.TAdminRequest; import org.apache.impala.thrift.TAdminRequestType; import org.apache.impala.thrift.TNetworkAddress; import org.apache.impala.thrift.TShutdownParams; import com.google.common.base.Joiner; import com.google.common.base.Preconditions; import com.google.common.collect.Lists; /** <|startfocus|> * Represents an administrative function call, e.g. ": shutdown()". <|endfocus|> * * This "admin statement" framework provides a way to expand the set of supported admin * statements without modifying the SQL grammar. For now, the only supported function is * shutdown(), so the logic in here is not generic. */ public class AdminFnStmt extends StatementBase { // Name of the function. Validated during analysis. private final String fnName_; // Arguments to the function. Always non-null. private final List<Expr> params_; // Parameters for the shutdown() command.
<|startcomment|> nit: update <|endcomment|>  * not used since it accesses multiple catalog entities in order to compute a snapshot * of catalog metadata. * * Operations that CREATE/DROP catalog objects such as tables and databases employ the * following locking protocol: * 1. Acquire the metastoreDdlLock_ * 2. Update the Hive Metastore * 3. Increment and get a new catalog version * 4. Update the catalog * 5. Make Sentry cache changes if ownership is enabled. <|startfocus|> * 5. Release the metastoreDdlLock_ <|endfocus|> * * It is imperative that other operations that need to hold both the catalog lock and * table locks at the same time follow the same locking protocol and acquire these * locks in that particular order. Also, operations that modify table metadata * (e.g. alter table statements) should not acquire the metastoreDdlLock_. * * TODO: Refactor the CatalogOpExecutor and CatalogServiceCatalog classes and consolidate * the locking protocol into a single class. * * TODO: Improve catalog's consistency guarantees by using a hierarchical locking scheme.
<|startcomment|> I'm somewhat concerned that you modify owner (which is a shared object) without holding any locks. Is it safe here? <|endcomment|>  filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); if (existingUser.getRef()) { owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); } } else if (ownerType == PrincipalType.ROLE) { owner = catalog_.getAuthPolicy().getRole(ownerString); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.ROLE); cPrivilege = catalog_.addRolePrivilege(ownerString, filter); <|startfocus|> owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); <|endfocus|> } else { throw new CatalogException("Unexpected PrincipalType: " + ownerType.name()); } response.result.addToUpdated_catalog_objects(cPrivilege.toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } catch (CatalogException e) { LOG.error("Error adding privilege: ", e); } } /** * Create a new HMS Partition. */ private static Partition createHmsPartition(List<TPartitionKeyValue> partitionSpec, org.apache.hadoop.hive.metastore.api.Table msTbl, TableName tableName, String location) {
<|startcomment|> Nit: "A space-efficient filter which offers an approximate containment check"? <|endcomment|> // "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.kudu.util; import javax.annotation.concurrent.NotThreadSafe; import java.nio.charset.StandardCharsets; import java.util.BitSet; import com.sangupta.murmur.Murmur2; import org.apache.yetus.audience.InterfaceAudience; import org.apache.yetus.audience.InterfaceStability; /** <|startfocus|> * An space-efficient filter and offers an approximate containment check. <|endfocus|> * * <p>It can be used to filter all the records which are wanted, but doesn't guarantee to filter out * all the records which are <i>not</i> wanted. * * <p>Please check this <a * href="https://en.wikipedia.org/wiki/Bloom_filter">wiki</a> for more details. * * <p>The {@code BloomFilter} here is a scanning filter and used to shrink the amount of records
<|startcomment|> Nit: "constrain the number" <|endcomment|>  /** * An space-efficient filter and offers an approximate containment check. * * <p>It can be used to filter all the records which are wanted, but doesn't guarantee to filter out * all the records which are <i>not</i> wanted. * * <p>Please check this <a * href="https://en.wikipedia.org/wiki/Bloom_filter">wiki</a> for more details. * <|startfocus|> * <p>The {@code BloomFilter} here is a scanning filter and used to shrink the amount of records <|endfocus|> * returned from TServer. It provides different types of {@code put} methods. When you {@code put} a * record into {@code BloomFilter}, it means you are expecting TServer to return records have * the same value in a scan. * * <p>Here is an example for use: * <pre> * {@code * BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); * bf.put(1); * bf.put(3); * bf.put(4);
<|startcomment|> "implement" and "serializing" <|endcomment|>  * the same value in a scan. * * <p>Here is an example for use: * <pre> * {@code * BloomFilter bf = BloomFilter.BySizeAndFPRate(nBytes, fpRate); * bf.put(1); * bf.put(3); * bf.put(4); * byte[] bitSet = bf.getBitSet(); * byte[] nHashes = bf.getNHashes(); * String hashFunctionName = bf.getHashFunctionName(); <|startfocus|> * // TODO: implemnt the interface for serializaing and sending <|endfocus|> * // (bitSet, nHashes, hashFunctionName) to TServer. * } * </pre> */ @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { if (bitSet.size() < 8) {
<|startcomment|> You can use Guava's Preconditions to simplify these assertions: Preconditions.checkArgument(bitset.size() < 8, "..."); <|endcomment|>  * </pre> */ @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { <|startfocus|> if (bitSet.size() < 8) { throw new IllegalArgumentException("Number of bits in bitset should be at least 8, but found " + bitSet.length()); } <|endfocus|> this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } /** * Generate bloom filter, Murmur2 is used for hashing by default. * @param nBytes size of Bloom filter * @param fpRate false positive rate */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } 
<|startcomment|> Could you look into whether bitSet.size() is a constant time operation? If it is, there's no need to store nBits separately; we could just query bitSet.size() whenever we need the number of bits. <|endcomment|>  * </pre> */ @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { <|startfocus|> if (bitSet.size() < 8) { throw new IllegalArgumentException("Number of bits in bitset should be at least 8, but found " + bitSet.length()); } <|endfocus|> this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } /** * Generate bloom filter, Murmur2 is used for hashing by default. * @param nBytes size of Bloom filter * @param fpRate false positive rate */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } 
<|startcomment|> Nit: "size of bloom filter in bytes" <|endcomment|>  if (bitSet.size() < 8) { throw new IllegalArgumentException("Number of bits in bitset should be at least 8, but found " + bitSet.length()); } this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } /** <|startfocus|> * Generate bloom filter, Murmur2 is used for hashing by default. * @param nBytes size of Bloom filter * @param fpRate false positive rate <|endfocus|> */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate, HashFunction hashFunction) { int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, optimalExpectedCount(nBytes, fpRate)); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction); } /**
<|startcomment|> Nit: lower case "bloom" (to be consistent with how you've written "bloom filter" in other Javadoc. <|endcomment|>  } public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate, HashFunction hashFunction) { int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, optimalExpectedCount(nBytes, fpRate)); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction); } /** <|startfocus|> * Generate bloom filter, Murmur2 is used for hashing by default. * @param expectedCount The expected number of elements, targeted by this Bloom filter. <|endfocus|> * It is used to size the bloom filter. * @param fpRate false positive rate */ public static BloomFilter ByCountAndFPRate(int expectedCount, double fpRate) { return ByCountAndFPRate(expectedCount, fpRate, HashFunctions.MURMUR2); } public static BloomFilter ByCountAndFPRate(int expectedCount, double fpRate, HashFunction hashFunction) { int nBytes = optimalNumOfBytes(expectedCount, fpRate); int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, expectedCount); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction); } 
<|startcomment|> Please Javadoc the various put() methods. <|endcomment|>  * @param fpRate false positive rate */ public static BloomFilter ByCountAndFPRate(int expectedCount, double fpRate) { return ByCountAndFPRate(expectedCount, fpRate, HashFunctions.MURMUR2); } public static BloomFilter ByCountAndFPRate(int expectedCount, double fpRate, HashFunction hashFunction) { int nBytes = optimalNumOfBytes(expectedCount, fpRate); int nBits = nBytes * 8; int nHashes = computeOptimalHashCount(nBits, expectedCount); return new BloomFilter(new BitSet(nBits), nHashes, hashFunction); } <|startfocus|> <|endfocus|> public void put(byte[] data) { updateBitset(data, data.length); } public void put(boolean data) { byteBuffer[0] = (byte)(data ? 1 : 0); updateBitset(byteBuffer, 1); } public void put(byte data) { byteBuffer[0] = data; updateBitset(byteBuffer, 1); } public void put(short data) { byteBuffer[0] = (byte) (data >>> 0); byteBuffer[1] = (byte) (data >>> 8); updateBitset(byteBuffer, 2); } 
<|startcomment|> Are these testing only? If so, annotate them as such. If not, provide Javadoc. <|endcomment|>  updateBitset(byteBuffer, 8); } public void put(float data) { put(Float.floatToIntBits(data)); } public void put(double data) { put(Double.doubleToLongBits(data)); } public void put(String data) { put(data.getBytes(StandardCharsets.UTF_8)); } public byte[] getBitSet() { return bitSet.toByteArray(); } public int getNHashes() { return nHashes; } <|startfocus|> <|endfocus|> public String getHashFunctionName() { return hashFunction.toString(); } // Mark it `private` and user can only use the `HashFunction` specified in the // enumeration below. Thus user cannot send TServer a self defined `HashFunction`, // which might not be identified by TServer. private interface HashFunction { long hash(byte[] data, int length, long seed); } public enum HashFunctions implements HashFunction { // Currently only Murmur2 is provided as an option for hashing. // We can consider to provide some other options like Murmur3, CityHash in the future.
<|startcomment|> Nit: use Guava's Preconditions here. <|endcomment|>  // Currently only Murmur2 is provided as an option for hashing. // We can consider to provide some other options like Murmur3, CityHash in the future. MURMUR2() { @Override public long hash(byte[] data, int length, long seed) { return Murmur2.hash(data, length, seed); } @Override public String toString() { return "Murmur2"; } } } private void updateBitset(byte[] byteBuffer, int length) { <|startfocus|> assert (byteBuffer.length >= length); <|endfocus|> long h = Murmur2.hash64(byteBuffer, length, 0); long h1 = (0xFFFFFFFFL & h); long h2 = (h >>> 32); long tmp = h1; for (int i = 0; i < nHashes; i++) { long bitPos = tmp % nBits; bitSet.set((int)bitPos); tmp += h2; } } @InterfaceAudience.LimitedPrivate("Test") public boolean mayContain(byte[] data) { return checkIfContains(data); } 
<|startcomment|> line too long (91 > 90) <|endcomment|>  TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onDatabase("functional", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onTable("functional", "alltypes", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes")) .error(accessError(true, "functional.alltypes"), onServer(true, allExcept( TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) <|startfocus|> .error(accessError(true, "functional.alltypes"), onDatabase(true, "functional", allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) <|endfocus|> .error(accessError(true, "functional.alltypes"), onTable(true, "functional", "alltypes", allExcept( TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))); } } finally { authzCatalog_.removeRole("foo_owner"); } // Alter table rename. authorize("alter table functional.alltypes rename to functional_parquet.new_table") .ok(onServer(TPrivilegeLevel.ALL)) .ok(onServer(TPrivilegeLevel.OWNER)) .ok(onDatabase("functional", TPrivilegeLevel.ALL), onDatabase("functional_parquet", TPrivilegeLevel.CREATE))
<|startcomment|> adding <|endcomment|>  owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToRemoved_catalog_objects(removedPrivilege .toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } } } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } finally { catalog_.getLock().writeLock().unlock(); } } /** <|startfocus|> * This is a helper method to take care of catalog related updates when removing * a privilege. <|endfocus|> */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; if (ownerType == PrincipalType.USER) { Reference<Boolean> existingUser = new Reference<>(); owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); if (!existingUser.getRef()) {
<|startcomment|> it also add a user if specifying a user and that user does not exist. <|endcomment|>  owner.setCatalogVersion(catalog_.incrementAndGetCatalogVersion()); response.result.addToRemoved_catalog_objects(removedPrivilege .toTCatalogObject()); response.result.addToUpdated_catalog_objects(owner.toTCatalogObject()); } } } catch (CatalogException e) { LOG.error("Error removing privilege: ", e); } finally { catalog_.getLock().writeLock().unlock(); } } /** <|startfocus|> * This is a helper method to take care of catalog related updates when removing * a privilege. <|endfocus|> */ private void addPrivilegeToCatalog(String ownerString, PrincipalType ownerType, TPrivilege filter, TDdlExecResponse response) { try { Principal owner; PrincipalPrivilege cPrivilege; if (ownerType == PrincipalType.USER) { Reference<Boolean> existingUser = new Reference<>(); owner = catalog_.addUserIfNotExists(ownerString, existingUser); filter.setPrincipal_id(owner.getId()); filter.setPrincipal_type(TPrincipalType.USER); cPrivilege = catalog_.addUserPrivilege(ownerString, filter); if (!existingUser.getRef()) {
<|startcomment|> Should be >=, right? <|endcomment|>  * } * </pre> */ @InterfaceAudience.Public @InterfaceStability.Unstable @NotThreadSafe public class BloomFilter { private final int nBits; private final BitSet bitSet; private final int nHashes; private final byte[] byteBuffer; private final HashFunction hashFunction; private static final double DEFAULT_FP_RATE = 0.01; private BloomFilter(BitSet bitSet, int nHashes, HashFunction hashFunction) { <|startfocus|> Preconditions.checkArgument(bitSet.size() > 8, "Number of bits in " + <|endfocus|> "bitset should be at least 8, but found %s.", bitSet.size()); this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } /** * Generate bloom filter, default hashing is {@code Murmur2} and false positive rate is 0.01. * @param nBytes size of bloom filter in bytes */ public static BloomFilter BySize(int nBytes) { return BySizeAndFPRate(nBytes, DEFAULT_FP_RATE); }
<|startcomment|> In our Java code we use lowerCamelCase to name functions and variables. So "BySize" should actually be "bySize", and "BySizeAndFPRate" should be "bySizeAndFPRate". Etc. <|endcomment|>  "bitset should be at least 8, but found %s.", bitSet.size()); this.nBits = bitSet.size(); this.bitSet = bitSet; this.nHashes = nHashes; this.hashFunction = hashFunction; byteBuffer = new byte[8]; } /** * Generate bloom filter, default hashing is {@code Murmur2} and false positive rate is 0.01. * @param nBytes size of bloom filter in bytes */ <|startfocus|> public static BloomFilter BySize(int nBytes) { return BySizeAndFPRate(nBytes, DEFAULT_FP_RATE); <|endfocus|> } /** * Generate bloom filter, default hashing is {@code Murmur2}. * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been {@code put} into the {@code BloomFilter}. */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } /**
<|startcomment|> For @params that span multiple lines, please align the continuation lines with the first letter of the explanation on the first line: @param fpRate the probability ... ever been put into the ... That's the Javadoc style we follow. Below too. <|endcomment|>  * @param nBytes size of bloom filter in bytes */ public static BloomFilter BySize(int nBytes) { return BySizeAndFPRate(nBytes, DEFAULT_FP_RATE); } /** * Generate bloom filter, default hashing is {@code Murmur2}. * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not <|startfocus|> * ever been {@code put} into the {@code BloomFilter}. <|endfocus|> */ public static BloomFilter BySizeAndFPRate(int nBytes, double fpRate) { return BySizeAndFPRate(nBytes, fpRate, HashFunctions.MURMUR2); } /** * Generate bloom filter. * @param nBytes size of bloom filter in bytes * @param fpRate the probability that TServer will erroneously return a record that has not * ever been {@code put} into the {@code BloomFilter}. * @param hashFunction hashing used when updating or checking containment, user should pick * the hashing function from {@code HashFunctions}
<|startcomment|> line too long (91 > 90) <|endcomment|>  TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onDatabase("functional", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes"), onTable("functional", "alltypes", TPrivilegeLevel.values())) .error(accessError(true, "functional.alltypes")) .error(accessError(true, "functional.alltypes"), onServer(true, allExcept( TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) <|startfocus|> .error(accessError(true, "functional.alltypes"), onDatabase(true, "functional", allExcept(TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))) <|endfocus|> .error(accessError(true, "functional.alltypes"), onTable(true, "functional", "alltypes", allExcept( TPrivilegeLevel.ALL, TPrivilegeLevel.OWNER))); } } finally { authzCatalog_.removeRole("foo_owner"); } boolean exceptionThrown = false; try { parseAndAnalyze("alter table functional.alltypes set owner role foo_owner", analysisContext_ , frontend_); } catch (AnalysisException e) { exceptionThrown = true; assertEquals("Role 'foo_owner' does not exist.", e.getLocalizedMessage()); }
<|startcomment|> Add some detail of why this is present? <|endcomment|>  private final long MISSING_TBL_LOAD_WAIT_TIMEOUT_MS = 2 * 60 * 1000; // Max time to wait for a catalog update notification. private final long MAX_CATALOG_UPDATE_WAIT_TIME_MS = 2 * 1000; //TODO: Make the reload interval configurable. private static final int AUTHORIZATION_POLICY_RELOAD_INTERVAL_SECS = 5 * 60; private ImpaladCatalog impaladCatalog_; private final AuthorizationConfig authzConfig_; private final AtomicReference<AuthorizationChecker> authzChecker_; private final ScheduledExecutorService policyReader_ = Executors.newScheduledThreadPool(1); <|startfocus|> private final String defaultKuduMasterHosts_; <|endfocus|> public Frontend(AuthorizationConfig authorizationConfig, String defaultKuduMasterHosts) { this(authorizationConfig, new ImpaladCatalog(defaultKuduMasterHosts)); } /** * C'tor used by tests to pass in a custom ImpaladCatalog. */ public Frontend(AuthorizationConfig authorizationConfig, ImpaladCatalog catalog) { authzConfig_ = authorizationConfig; impaladCatalog_ = catalog; defaultKuduMasterHosts_ = catalog.getDefaultKuduMasterHosts(); authzChecker_ = new AtomicReference<AuthorizationChecker>( new AuthorizationChecker(authzConfig_, impaladCatalog_.getAuthPolicy()));
<|startcomment|> Should we use getHostString() in place of getHostName()? The documentation says getHostName() may do a reverse lookup. Whether that happens or doesn't depends on how the InetSocketAddress was built (the lookup happens "if the address was created with a literal IP address"), but I don't know if that condition means the InetSocketAddress must have been constructed with a InetAddress argument, or with a hostname of "1.2.3.4" (see my other question about this in NetUtil). <|endcomment|>  public String getHostname() { <|startfocus|> return hostPort.getHostText(); <|endfocus|>
<|startcomment|> FWIW, the reason these methods were prefixed with 'start' and not 'restart' is because you can't use them to start a server from scratch; you can only bring back up a server that was previously started when the cluster itself was started, and subsequently killed. <|endcomment|>  /** * Kills the TS listening on the provided port. Doesn't do anything if the TS was already killed. * @param port port on which the tablet server is listening on * @throws InterruptedException */ public void killTabletServerOnPort(int port) throws InterruptedException { Process ts = tserverProcesses.remove(port); if (ts == null) { // The TS is already dead, good. return; } <|startfocus|> LOG.info("Killing server at port " + port); destroyAndWaitForProcess(ts); <|endfocus|> } /** * Kills all tablet servers. * @throws InterruptedException */ public void killTabletServers() throws InterruptedException { for (Process tserver : tserverProcesses.values()) { destroyAndWaitForProcess(tserver); } tserverProcesses.clear(); } /** * Restarts any tablet servers which were previously killed. */ public void restartDeadTabletServers() throws Exception { for (int port : tserverPorts) { if (tserverProcesses.containsKey(port)) continue; restartDeadTabletServerOnPort(port); } } 
<|startcomment|> Some of these lines look to be too long. <|endcomment|>  private static String findBinaryDir() { // First check the system property, which is our standard override. String kuduHomeProp = System.getProperty(KUDU_BIN_DIR_PROP); if (kuduHomeProp != null) { <|startfocus|> LOG.info("Using Kudu binary directory specified by system property '{}': {}", KUDU_BIN_DIR_PROP, kuduHomeProp); <|endfocus|> return kuduHomeProp; } // Next, check the environment variable. String kuduHomeVar = System.getenv(KUDU_HOME_VAR); if (kuduHomeVar != null) { LOG.info("Using Kudu home directory specified by environment variable '{}': {}", KUDU_HOME_VAR, kuduHomeVar); String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; } // Last, use the kudu that is available on the path. try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) {
<|startcomment|> In various places in the codebase, the KUDU_HOME env variable refers to the root of the Kudu source tree (i.e. where the www/ subdirectory can be found). This isn't that, so I don't think we should overload the name. In fact, I'm not really sure what this directory is. Seems like maybe a vendor-specific directory root? <|endcomment|>  String kuduHomeProp = System.getProperty(KUDU_BIN_DIR_PROP); if (kuduHomeProp != null) { LOG.info("Using Kudu binary directory specified by system property '{}': {}", KUDU_BIN_DIR_PROP, kuduHomeProp); return kuduHomeProp; } // Next, check the environment variable. String kuduHomeVar = System.getenv(KUDU_HOME_VAR); if (kuduHomeVar != null) { <|startfocus|> LOG.info("Using Kudu home directory specified by environment variable '{}': {}", KUDU_HOME_VAR, kuduHomeVar); <|endfocus|> String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; } // Last, use the kudu that is available on the path. try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { try (final Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { String kuduBinary = CharStreams.toString(reader);
<|startcomment|> That's not quite what this is doing though; it's using 'kudu' on the path as a proxy for where the bin dir should be. <|endcomment|>  return kuduHomeProp; } // Next, check the environment variable. String kuduHomeVar = System.getenv(KUDU_HOME_VAR); if (kuduHomeVar != null) { LOG.info("Using Kudu home directory specified by environment variable '{}': {}", KUDU_HOME_VAR, kuduHomeVar); String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; } <|startfocus|> // Last, use the kudu that is available on the path. <|endfocus|> try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { try (final Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { String kuduBinary = CharStreams.toString(reader); String kuduBinDir = new File(kuduBinary).getParent(); LOG.info("Using Kudu binary directory found on path with 'which kudu': {}", kuduBinDir); return kuduBinDir; } } } catch (IOException | InterruptedException ex) {
<|startcomment|> Where's the 'catch' or finally' for this 'try'? Is it L78? <|endcomment|>  String kuduBinDir = new File(kuduHomeVar, "bin").getPath(); return kuduBinDir; } // Last, use the kudu that is available on the path. try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { <|startfocus|> try (final Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { <|endfocus|> String kuduBinary = CharStreams.toString(reader); String kuduBinDir = new File(kuduBinary).getParent(); LOG.info("Using Kudu binary directory found on path with 'which kudu': {}", kuduBinDir); return kuduBinDir; } } } catch (IOException | InterruptedException ex) { throw new RuntimeException("Error while locating kudu binary", ex); } throw new RuntimeException("Could not locate the kudu binary directory. " + "Set the system variable " + KUDU_BIN_DIR_PROP + ", environment variable " + KUDU_HOME_VAR +
<|startcomment|> optional: I would add a function like getShortName() to Analyzer/StatementBase/User that does the exception translation to avoid code duplication. <|endcomment|> public class AlterViewStmt extends CreateOrAlterViewStmtBase { public AlterViewStmt( TableName tableName, List<ColumnDef> columnDefs, QueryStmt viewDefStmt) { super(false, tableName, columnDefs, null, viewDefStmt); } @Override public void analyze(Analyzer analyzer) throws AnalysisException { // Enforce Hive column labels for view compatibility. analyzer.setUseHiveColLabels(true); viewDefStmt_.analyze(analyzer); Preconditions.checkState(tableName_ != null && !tableName_.isEmpty()); dbName_ = analyzer.getTargetDbName(tableName_); <|startfocus|> try { owner_ = analyzer.getUser().getShortName(); } catch (InternalException e) { throw new AnalysisException("Error calling getShortName() for user: " + analyzer.getUser().getName(), e); } <|endfocus|> // Set the servername here if authorization is enabled because analyzer_ is not // available in the toThrift() method. serverName_ = analyzer.getServerName(); FeTable table = analyzer.getTable(tableName_, Privilege.ALTER); Preconditions.checkNotNull(table); if (!(table instanceof FeView)) {
<|startcomment|> Nit: the other methods earlier name this argument hostAndPort rather than address. Below too. <|endcomment|>  try { miniCluster.waitFor(); } catch (InterruptedException e) { LOG.warn("Minicluster process did not exit, destroying"); miniCluster.destroy(); } } } /** * Returns a master server identified by an address. * * @param address unique address identifying the server * @return the DaemonInfo of the server * @throws RuntimeException if the server is not found */ <|startfocus|> private DaemonInfo getMasterServer(HostAndPort address) throws RuntimeException { DaemonInfo d = masterServers.get(address); <|endfocus|> if (d == null) { throw new RuntimeException(String.format("Master server %s not found", address)); } return d; } /** * Returns a tablet server identified by an address. * * @param address unique address identifying the server * @return the DaemonInfo of the server * @throws RuntimeException if the server is not found */ private DaemonInfo getTabletServer(HostAndPort address) throws RuntimeException { DaemonInfo d = tabletServers.get(address);
<|startcomment|> HostAndPort Below too. <|endcomment|>  import static org.junit.Assert.assertArrayEquals; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; import java.net.InetAddress; import java.net.InetSocketAddress; import java.util.Arrays; import java.util.List; import org.apache.kudu.client.HostAndPort; import org.junit.Test; /** * Test for {@link NetUtil}. */ public class TestNetUtil { /** <|startfocus|> * Tests parsing strings into {@link InetSocketAddress} objects with and without specifying <|endfocus|> * the port in the string. */ @Test public void testParseString() { String aStringWithPort = "1.2.3.4:1234"; HostAndPort hostAndPortForAStringWithPort = NetUtil.parseString(aStringWithPort, 0); assertEquals(hostAndPortForAStringWithPort.getHost(), "1.2.3.4"); assertEquals(hostAndPortForAStringWithPort.getPort(), 1234); String aStringWithoutPort = "1.2.3.4"; HostAndPort hostAndPortForAStringWithoutPort = NetUtil.parseString(aStringWithoutPort, 12345);
<|startcomment|> Nit: kuduHomeProp? Or kuduBinProp? <|endcomment|>  private static String findBinaryDir() { // If kuduBinDir system property is set, use that. <|startfocus|> String kuduHomeProp = System.getProperty(KUDU_BIN_DIR_PROP); if (kuduHomeProp != null) { <|endfocus|> LOG.info("Using Kudu binary directory specified by system property '{}': {}", KUDU_BIN_DIR_PROP, kuduHomeProp); return kuduHomeProp; } // If the `kudu` binary is found on the PATH using `which kudu`, use its parent directory. try { Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec("which kudu"); int errorCode = process.waitFor(); if (errorCode == 0) { try(Reader reader = new InputStreamReader(process.getInputStream(), UTF_8)) { String kuduBinary = CharStreams.toString(reader); String kuduBinDir = new File(kuduBinary).getParent(); LOG.info("Using Kudu binary directory found on path with 'which kudu': {}", kuduBinDir); return kuduBinDir; } } } catch (IOException | InterruptedException ex) {
<|startcomment|> nit: end regular comment sentence w/ a period. <|endcomment|>  private PrivilegedExecutor privilegedExecutor; public KuduSink() { this(null); } @InterfaceAudience.LimitedPrivate("Test") @InterfaceAudience.Private public KuduSink(KuduClient kuduClient) { this.client = kuduClient; } @Override public synchronized void start() { Preconditions.checkState(table == null && session == null, "Please call stop before calling start on an old instance."); // Client is not null only inside tests. if (client == null) { <|startfocus|> // Creating client with FlumeAuthenticator <|endfocus|> client = privilegedExecutor.execute( new PrivilegedAction<KuduClient>() { @Override public KuduClient run() { return new KuduClient.KuduClientBuilder(masterAddresses).build(); } } ); } session = client.newSession(); session.setFlushMode(SessionConfiguration.FlushMode.MANUAL_FLUSH); session.setTimeoutMillis(timeoutMillis); session.setIgnoreAllDuplicateRows(ignoreDuplicateRows); session.setMutationBufferSpace(batchSize); try { table = client.openTable(tableName); } catch (Exception ex) { sinkCounter.incrementConnectionFailedCount();
<|startcomment|> nit: indent at least 4 spaces on a line continuation <|endcomment|>  TABLE_NAME); batchSize = context.getInteger(BATCH_SIZE, DEFAULT_BATCH_SIZE); timeoutMillis = context.getLong(TIMEOUT_MILLIS, DEFAULT_TIMEOUT_MILLIS); ignoreDuplicateRows = context.getBoolean(IGNORE_DUPLICATE_ROWS, DEFAULT_IGNORE_DUPLICATE_ROWS); String operationProducerType = context.getString(PRODUCER); String kerberosPrincipal = context.getString(KERBEROS_PRINCIPAL); String kerberosKeytab = context.getString(KERBEROS_KEYTAB); String proxyUser = context.getString(PROXY_USER); privilegedExecutor = FlumeAuthenticationUtil.getAuthenticator( <|startfocus|> kerberosPrincipal, kerberosKeytab).proxyAs(proxyUser); <|endfocus|> // Check for operations producer, if null set default operations producer type. if (operationProducerType == null || operationProducerType.isEmpty()) { operationProducerType = DEFAULT_KUDU_OPERATION_PRODUCER; logger.warn("No Kudu operations producer provided, using default"); } Context producerContext = new Context(); producerContext.putAll(context.getSubProperties( KuduSinkConfigurationConstants.PRODUCER_PREFIX)); try { Class<? extends KuduOperationsProducer> clazz = (Class<? extends KuduOperationsProducer>) Class.forName(operationProducerType); operationsProducer = clazz.getDeclaredConstructor().newInstance();
<|startcomment|> nit: extra indentation? <|endcomment|>  .nullable(true).build()); columns.add(new ColumnSchema.ColumnSchemaBuilder("stringField", Type.STRING).build()); columns.add(new ColumnSchema.ColumnSchemaBuilder("decimalField", Type.DECIMAL) .typeAttributes(DecimalUtil.typeAttributes(9, 1)).build()); CreateTableOptions createOptions = new CreateTableOptions().setRangePartitionColumns(ImmutableList.of("key")) .setNumReplicas(1); return createTable(tableName, new Schema(columns), createOptions); } private List<Event> generateEvents(int eventCount, <|startfocus|> SchemaLocation schemaLocation) throws Exception { <|endfocus|> List<Event> events = new ArrayList<>(); for (int i = 0; i < eventCount; i++) { AvroKuduOperationsProducerTestRecord record = new AvroKuduOperationsProducerTestRecord(); record.setKey(10 * i); record.setLongField(2L * i); record.setDoubleField(2.71828 * i); record.setNullableField(i % 2 == 0 ? null : "taco"); record.setStringField(String.format("hello %d", i)); record.setDecimalField(BigDecimal.valueOf(i, 1));
<|startcomment|> nit: please use 4-space indentation on both continuation lines, like this: static void processEventsCreatingSink( KuduClient syncClient, Context context, String tableName, List<Event> events) throws EventDeliveryException { KuduSink sink = ... <|endcomment|>  return sink; } static KuduSink createSecureSink(String tableName, String masterAddresses, String clusterRoot) { Context context = new Context(); context.put(KERBEROS_KEYTAB, clusterRoot + "/krb5kdc/test-user.keytab"); context.put(KERBEROS_PRINCIPAL, "test-user@KRBTEST.COM"); return createSink(tableName, null, context, masterAddresses); } static void processEventsCreatingSink( KuduClient syncClient, Context context, String tableName, List<Event> events <|startfocus|> ) throws EventDeliveryException { <|endfocus|> KuduSink sink = createSink(syncClient, tableName, context); sink.start(); processEvents(sink, events); } static void processEvents(KuduSink sink, List<Event> events) throws EventDeliveryException { Channel channel = sink.getChannel(); Transaction tx = channel.getTransaction(); tx.begin(); for (Event e : events) { channel.put(e); } tx.commit(); tx.close(); Status status = sink.process(); if (events.isEmpty()) { assertSame("incorrect status for empty channel", status, Status.BACKOFF); } else {
<|startcomment|> nit: append _SEC or _SECONDS to these variable names <|endcomment|> import org.slf4j.LoggerFactory; import org.apache.kudu.ColumnSchema; import org.apache.kudu.Schema; import org.apache.kudu.Type; import org.apache.kudu.client.BaseKuduTest; import org.apache.kudu.client.CreateTableOptions; import org.apache.kudu.client.KuduTable; import org.apache.kudu.client.MiniKuduCluster.MiniKuduClusterBuilder; public class SecureKuduSinkTest extends BaseKuduTest { private static final Logger LOG = LoggerFactory.getLogger(SecureKuduSinkTest.class); <|startfocus|> private static final int TICKET_LIFETIME = 10; private static final int RENEWABLE_LIFETIME = 30; <|endfocus|> @Before public void clearTicketCacheProperty() { // Let Flume authenticate System.clearProperty(KUDU_TICKETCACHE_PROPERTY); } @Override protected MiniKuduClusterBuilder getMiniClusterBuilder() { return super.getMiniClusterBuilder() .kdcTicketLifetime(TICKET_LIFETIME + "s") .kdcRenewLifetime(RENEWABLE_LIFETIME + "s") .enableKerberos(); } @Test public void testEventsWithShortTickets() throws Exception { LOG.info("Creating new table..."); ArrayList<ColumnSchema> columns = new ArrayList<>(1);
<|startcomment|> Make these stuff static? Used below too. <|endcomment|>  public PartitionRefImpl(TPartialPartitionInfo p) { <|startfocus|> this.info_ = p; <|endfocus|>
<|startcomment|> Switch to TUnit::NONE for types like this to not include x (x) stuff? Maybe makes sense for stuff like bytes/time that get pretty printed. <|endcomment|>  public PartitionRefImpl(TPartialPartitionInfo p) { <|startfocus|> this.info_ = p; <|endfocus|>
<|startcomment|> Can we factor out the per-host scan range calculation into a helper? I know it's short but the logic isn't trivial and I think we expect it to be identical between the scan node implementations (unless something changes in future). <|endcomment|>  private boolean tryConvertKuduPredicate(Analyzer analyzer, org.apache.kudu.client.KuduTable table, Expr expr) { if (!(expr instanceof BinaryPredicate)) return false; BinaryPredicate predicate = (BinaryPredicate) expr; // TODO KUDU-931 look into handling implicit/explicit casts on the SlotRef. <|startfocus|> predicate = normalizeSlotRefComparison(predicate, analyzer); <|endfocus|> if (predicate == null) return false; ComparisonOp op = getKuduOperator(predicate.getOp()); if (op == null) return false; SlotRef ref = (SlotRef) predicate.getChild(0); LiteralExpr literal = (LiteralExpr) predicate.getChild(1); // Cannot push prediates with null literal values (KUDU-1595). if (literal instanceof NullLiteral) return false; String colName = ref.getDesc().getColumn().getName(); ColumnSchema column = table.getSchema().getColumn(colName); KuduPredicate kuduPredicate = null; switch (literal.getType().getPrimitiveType()) { case BOOLEAN: { kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((BoolLiteral)literal).getValue()); break; } case TINYINT:
<|startcomment|> This new indentation seems weird to me. <|endcomment|>  if (!(expr instanceof BinaryPredicate)) return false; BinaryPredicate predicate = (BinaryPredicate) expr; // TODO KUDU-931 look into handling implicit/explicit casts on the SlotRef. predicate = normalizeSlotRefComparison(predicate, analyzer); if (predicate == null) return false; <|startfocus|> ComparisonOp op = getKuduOperator(predicate.getOp()); <|endfocus|> if (op == null) return false; SlotRef ref = (SlotRef) predicate.getChild(0); LiteralExpr literal = (LiteralExpr) predicate.getChild(1); // Cannot push prediates with null literal values (KUDU-1595). if (literal instanceof NullLiteral) return false; String colName = ref.getDesc().getColumn().getName(); ColumnSchema column = table.getSchema().getColumn(colName); KuduPredicate kuduPredicate = null; switch (literal.getType().getPrimitiveType()) { case BOOLEAN: { kuduPredicate = KuduPredicate.newComparisonPredicate(column, op, ((BoolLiteral)literal).getValue()); break; } case TINYINT: case SMALLINT: case INT: { kuduPredicate = KuduPredicate.newComparisonPredicate(column, op,
<|startcomment|> I'd suggest restructuring this logic so that it's more obvious that the getPerInstanceNdv calculation is irrelevant in the clustered case, e.g. if (inputIsClustered_) { numBufferedPartitionsPerInstance = 1; } else { // .. long numConcurrentPartitionsPerInstance = fragment_.getPerInstanceNdv(queryOptions.getMt_dop(), partitionKeyExprs_); if (numConcurrentPartitionsPerInstance == -1) { numConcurrentPartitionsPerInstance = DEFAULT_NUM_PARTITIONS; } } This adds an extra level of nesting but 2 levels of nesting is still perfectly readable and I think makes the logic overall clearer. <|endcomment|>  // Compute the per-instance number of concurrent partitions, taking the number // of nodes and the data partition of the fragment executing this sink into account. long numConcurrentPartitionsPerInstance = fragment_.getPerInstanceNdv(queryOptions.getMt_dop(), partitionKeyExprs_); if (numConcurrentPartitionsPerInstance == -1) { numConcurrentPartitionsPerInstance = DEFAULT_NUM_PARTITIONS; } <|startfocus|> // If the insert is clustered, it produces a single partition at a time. if (inputIsClustered_) numConcurrentPartitionsPerInstance = 1; <|endfocus|> FeFsTable table = (FeFsTable) targetTable_; // TODO: Estimate the memory requirements more accurately by partition type. Set<HdfsFileFormat> formats = table.getFileFormats(); long perPartitionMemReq = getPerPartitionMemReq(formats); long perInstanceMemEstimate; // The estimate is based purely on the per-partition mem req if the input cardinality_ // or the avg row size is unknown. if (inputNode.getCardinality() == -1 || inputNode.getAvgRowSize() == -1) { perInstanceMemEstimate = numConcurrentPartitionsPerInstance * perPartitionMemReq;
<|startcomment|> state that options can be null. <|endcomment|>  FunctionCallExpr mergeAggInputFn) { super(); fnName_ = fnName; params_ = params; mergeAggInputFn_ = mergeAggInputFn == null ? null : (FunctionCallExpr)mergeAggInputFn.clone(); if (params.exprs() != null) children_ = Lists.newArrayList(params_.exprs()); } /** * Returns an Expr that evaluates the function call <fnName>(<params>). The returned * Expr is not necessarily a FunctionCallExpr (example: DECODE()) */ <|startfocus|> public static Expr createExpr(FunctionName fnName, FunctionParams params) { <|endfocus|> FunctionCallExpr functionCallExpr = new FunctionCallExpr(fnName, params); if (fnName.getFnNamePath().size() == 1 && fnName.getFnNamePath().get(0).equalsIgnoreCase("decode") || fnName.getFnNamePath().size() == 2 && fnName.getFnNamePath().get(0).equalsIgnoreCase(Catalog.BUILTINS_DB) && fnName.getFnNamePath().get(1).equalsIgnoreCase("decode")) { return new CaseExpr(functionCallExpr); } return functionCallExpr; } 
<|startcomment|> remove. git blame should be enough to see why we make them equiv. <|endcomment|>  public static FunctionCallExpr createMergeAggCall( FunctionCallExpr agg, List<Expr> params) { Preconditions.checkState(agg.isAnalyzed()); Preconditions.checkState(agg.isAggregateFunction()); FunctionCallExpr result = new FunctionCallExpr( <|startfocus|> agg.fnName_, new FunctionParams(false, params), agg); <|endfocus|> // Inherit the function object from 'agg'. result.fn_ = agg.fn_; result.type_ = agg.type_; // Set an explicit label based on the input agg. if (agg.isMergeAggFn()) { result.label_ = agg.label_; } else { // fn(input) becomes fn:merge(input). result.label_ = agg.toSql().replaceFirst(agg.fnName_.toString(), agg.fnName_.toString() + ":merge"); } Preconditions.checkState(!result.type_.isWildcardDecimal()); return result;
<|startcomment|> simplify: '%' and 'mod' are equivalent when using DECIMAL V2. <|endcomment|>  public static FunctionCallExpr createMergeAggCall( FunctionCallExpr agg, List<Expr> params) { Preconditions.checkState(agg.isAnalyzed()); Preconditions.checkState(agg.isAggregateFunction()); FunctionCallExpr result = new FunctionCallExpr( <|startfocus|> agg.fnName_, new FunctionParams(false, params), agg); <|endfocus|> // Inherit the function object from 'agg'. result.fn_ = agg.fn_; result.type_ = agg.type_; // Set an explicit label based on the input agg. if (agg.isMergeAggFn()) { result.label_ = agg.label_; } else { // fn(input) becomes fn:merge(input). result.label_ = agg.toSql().replaceFirst(agg.fnName_.toString(), agg.fnName_.toString() + ":merge"); } Preconditions.checkState(!result.type_.isWildcardDecimal()); return result;
<|startcomment|> line too long (100 > 90) <|endcomment|>  // For CTAS the overall TExecRequest statement type is DDL, but the // query_exec_request should be DML result.stmt_type = analysisResult.isCreateTableAsSelectStmt() ? TStmtType.DDL : TStmtType.DML; result.query_exec_request.stmt_type = TStmtType.DML; // create finalization params of insert stmt InsertStmt insertStmt = analysisResult.getInsertStmt(); if (insertStmt.getTargetTable() instanceof HdfsTable) { TFinalizeParams finalizeParams = new TFinalizeParams(); finalizeParams.setIs_overwrite(insertStmt.isOverwrite()); finalizeParams.setTable_name(insertStmt.getTargetTableName().getTbl()); <|startfocus|> finalizeParams.setTable_id(insertStmt.getTargetTable().getId()); <|endfocus|> String db = insertStmt.getTargetTableName().getDb(); finalizeParams.setTable_db(db == null ? queryCtx.session.database : db); HdfsTable hdfsTable = (HdfsTable) insertStmt.getTargetTable(); finalizeParams.setHdfs_base_dir(hdfsTable.getHdfsBaseDir()); finalizeParams.setStaging_dir( hdfsTable.getHdfsBaseDir() + "/_impala_insert_staging"); queryExecRequest.setFinalize_params(finalizeParams); }
<|startcomment|> nit: this term (class) needs a definition. either put a forward ref to where its defined in MultiAggInfo or remove it. <|endcomment|> import org.slf4j.LoggerFactory; import com.google.common.base.Objects; import com.google.common.base.Preconditions; import com.google.common.collect.Lists; /** * Encapsulates all the information needed to compute a list of aggregate functions with * compatible grouping including their distributed execution. * * Each SELECT block containing aggregates will have a single MultiAggregateInfo which * will contain one AggregateInfo per unique list of DISTINCT expressions. If there is <|startfocus|> * only a single DISTINCT class, a single AggregateInfo will be created which will * represent that class and any non-DISTINCT aggregates. If there is more than one * DISTINCT class, the non-DISTINCT aggregates will be grouped together in their own <|endfocus|> * AggregateInfo. * * Execution is modeled as a tree of AggregateInfo objects which express the local and * merging aggregate computations. The tree structure looks as follows: * - for non-distinct aggregation: * - aggInfo: contains the original aggregation functions and grouping exprs * - aggInfo.mergeAggInfo: contains the merging aggregation functions (grouping
<|startcomment|> Could be worth mentioning why they're volatile, because it's an unusual and somewhat risky pattern if misapplied. E.g. "Volatile to allow populating metrics concurrently with the values being updated without staleness (but with no other synchronization guarantees)." <|endcomment|>  private long warnThresholdMs_; private static final long WARN_THRESHOLD_MS = 10000; // log INFO if we detect a pause longer than this threshold. private long infoThresholdMs_; private static final long INFO_THRESHOLD_MS = 1000; // Daemon thread running the pause monitor loop. private Thread monitorThread_; private volatile boolean shouldRun = true; <|startfocus|> // Singleton isntance of this pause monitor. <|endfocus|> public static JvmPauseMonitor INSTANCE = new JvmPauseMonitor(); // Initializes the pause monitor. No-op if called multiple times. public static void initPauseMonitor() { if (INSTANCE.isStarted()) return; INSTANCE.init(); } private JvmPauseMonitor() { this(INFO_THRESHOLD_MS, WARN_THRESHOLD_MS); } private JvmPauseMonitor(long infoThresholdMs, long warnThresholdMs) { this.infoThresholdMs_ = infoThresholdMs; this.warnThresholdMs_ = warnThresholdMs; } protected void init() { monitorThread_ = new Thread(new Monitor(), "JVM pause monitor"); monitorThread_.setDaemon(true); monitorThread_.start(); } 
<|startcomment|> Why was this removed? Isn't it necessary for the key? There can be multiple privileges with the same principal id. <|endcomment|>  switch (catalogObject.getType()) { case DATABASE: return "DATABASE:" + catalogObject.getDb().getDb_name().toLowerCase(); case TABLE: case VIEW: TTable tbl = catalogObject.getTable(); return "TABLE:" + tbl.getDb_name().toLowerCase() + "." + tbl.getTbl_name().toLowerCase(); case FUNCTION: return "FUNCTION:" + catalogObject.getFn().getName() + "(" + catalogObject.getFn().getSignature() + ")"; <|startfocus|> case ROLE: return "ROLE:" + catalogObject.getRole().getRole_name().toLowerCase(); <|endfocus|> case PRIVILEGE: return "PRIVILEGE:" + catalogObject.getPrivilege().getPrivilege_name().toLowerCase() + "." + Integer.toString(catalogObject.getPrivilege().getRole_id()); case HDFS_CACHE_POOL: return "HDFS_CACHE_POOL:" + catalogObject.getCache_pool().getPool_name().toLowerCase(); case DATA_SOURCE: return "DATA_SOURCE:" + catalogObject.getData_source().getName().toLowerCase(); default:
<|startcomment|> some of these have semicolons and some don't; perhaps remove all of them? <|endcomment|>  public void testBasicsWithStats() { // Return all rows. Cardinality is row count; <|startfocus|> runTest("SELECT id FROM functional.alltypes;", 7300); <|endfocus|> // Return all rows. Cardinality is row count, // should not be influenced by limited NDV of selected // column. runTest("SELECT bool_col FROM functional.alltypes;", 7300); // Result cardinality reduced by limited NDV. // Boolean column has cardinality 3 (true, false, null). // Since we have metadata, and know the column is non-null, // NDV is 2. We select one of them. runTest("SELECT id FROM functional.alltypes WHERE bool_col = TRUE;", 7300/2); // Result cardinality reduced by NDV. // NDV should be 10 (from metadata). runTest("SELECT id FROM functional.alltypes WHERE int_col = 1;", 7300/10); // Assume classic 0.1 selectivity for other operators // IMPALA-7560 says this should be revised. runTest("SELECT id FROM functional.alltypes WHERE int_col != 1", 730); 
<|startcomment|> consider renaming to "expectCardinality(query, expected)" which helps make this a tad more obvious. <|endcomment|> <|startfocus|> protected void runTest(String query, long expected) { <|endfocus|> List<PlanFragment> plan = getPlan(query); PlanNode planRoot = plan.get(0).getPlanRoot(); assertEquals(expected, planRoot.getCardinality());
<|startcomment|> Maybe add the query string to the message here? <|endcomment|>  protected void runTest(String query, long expected) { List<PlanFragment> plan = getPlan(query); PlanNode planRoot = plan.get(0).getPlanRoot(); <|startfocus|> assertEquals(expected, planRoot.getCardinality()); <|endfocus|>
<|startcomment|> planCtx.setCapturePlan(true)? <|endcomment|>  private List<PlanFragment> getPlan(String query) { // Set up the query context. Note that we need to deep copy it before planning each // time since planning modifies it. TQueryCtx queryCtx = TestUtils.createQueryContext( "default", System.getProperty("user.name")); queryCtx.client_request.setStmt(query); TQueryOptions queryOptions = queryCtx.client_request.getQuery_options(); queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); <|startfocus|> planCtx.capturePlan(); <|endfocus|> // Discard the actual execution plan. Return the cached // internal form instead. try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { System.out.println(plan.get(0).getExplainString( queryOptions, TExplainLevel.EXTENDED)); } return plan;
<|startcomment|> nit: remove <|endcomment|>  // Set up the query context. Note that we need to deep copy it before planning each // time since planning modifies it. TQueryCtx queryCtx = TestUtils.createQueryContext( "default", System.getProperty("user.name")); queryCtx.client_request.setStmt(query); TQueryOptions queryOptions = queryCtx.client_request.getQuery_options(); queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.capturePlan(); // Discard the actual execution plan. Return the cached // internal form instead. <|startfocus|> <|endfocus|> try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { System.out.println(plan.get(0).getExplainString( queryOptions, TExplainLevel.EXTENDED)); } return plan;
<|startcomment|> line too long (93 > 90) <|endcomment|>  queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.capturePlan(); // Discard the actual execution plan. Return the cached // internal form instead. try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { <|startfocus|> System.out.println(plan.get(0).getExplainString(queryOptions, TExplainLevel.EXTENDED)); <|endfocus|> } return plan;
<|startcomment|> line has trailing whitespace <|endcomment|>  computeNdv(); analysisDone(); } /** * C'tor for cloning. */ private SlotRef(SlotRef other) { super(other); rawPath_ = other.rawPath_; label_ = other.label_; desc_ = other.desc_; type_ = other.type_; } /** * Adjusting the NDV-without-nulls of the stats world to the * NDV-with-nulls needed by the planner. */ <|startfocus|> <|endfocus|> private void computeNdv() { if (desc_.getStats().hasStats()) { numDistinctValues_ = desc_.getStats().getNumDistinctValues(); // Potentially adjust NDV for nulls if the column is nullable // and is not Boolean. (ColumnStats already does adjustments for // Boolean only). // Only adjust for small amounts; has no impact on larger values. // Adjust only if we don't know the null count or we know it is // not zero. // (This is an estimate, just has to be in the ball park.)
<|startcomment|> It seems a little weird that numDistinctValues_ is modified both in computeNdv() and here in line 156. Perhaps we should move lines 153-157 into computeNdv()? Or write: numDistinctValues_ = computePreliminaryNdv() <|endcomment|>  // e.g. map. We could report a better error if we stored the original // HMS string. throw new AnalysisException("Unsupported type in '" + toSql() + "'."); } <|startfocus|> computeNdv(); FeTable rootTable = resolvedPath.getRootTable(); <|endfocus|> if (rootTable != null && rootTable.getNumRows() > 0) { // The NDV cannot exceed the #rows in the table. numDistinctValues_ = Math.min(numDistinctValues_, rootTable.getNumRows()); } } @Override protected float computeEvalCost() { return SLOT_REF_COST; } @Override protected boolean isConstantImpl() { return false; } public SlotDescriptor getDesc() { Preconditions.checkState(isAnalyzed()); Preconditions.checkNotNull(desc_); return desc_; } public SlotId getSlotId() { Preconditions.checkState(isAnalyzed()); Preconditions.checkNotNull(desc_); return desc_.getId(); } public Path getResolvedPath() { Preconditions.checkState(isAnalyzed()); return desc_.getPath(); } @Override
<|startcomment|> nit: adds <|endcomment|>  for (String groupName: groupNames) { roles.addAll(fe.getCatalog().getAuthPolicy().getGrantedRoles(groupName)); } for (Role role: roles) { Principal rolePrincipal = getRole(role.getName()); if (rolePrincipal != null) { createShowUserPrivilegesResultRows(result, rolePrincipal.getPrivileges(), filter, rolePrincipal.getName(), TPrincipalType.ROLE); } } return result; } /** <|startfocus|> * This method add the rows to the output for the SHOW GRANT USER statement for user <|endfocus|> * and associated roles. */ private void createShowUserPrivilegesResultRows(TResultSet result, List<PrincipalPrivilege> privileges, TPrivilege filter, String name, TPrincipalType type) { for (PrincipalPrivilege p : privileges) { TPrivilege privilege = p.toThrift(); if (filter != null && isPrivilegeFiltered(filter, privilege)) continue; TResultRowBuilder rowBuilder = new TResultRowBuilder(); rowBuilder.add(Strings.nullToEmpty(type.name().toUpperCase())); rowBuilder.add(Strings.nullToEmpty(name));
<|startcomment|> nit: this should be Role <|endcomment|>  * Allows for filtering based on a specific privilege spec or showing all privileges * granted to the role. Used by the SHOW GRANT ROLE statement. */ public synchronized TResultSet getRolePrivileges(String principalName, TPrivilege filter) { TResultSet result = new TResultSet(); result.setSchema(new TResultSetMetadata()); addColumnOutputColumns(result.getSchema()); result.setRows(Lists.<TResultRow>newArrayList()); <|startfocus|> Principal role = getRole(principalName); <|endfocus|> if (role != null) { for (PrincipalPrivilege p : role.getPrivileges()) { TPrivilege privilege = p.toThrift(); if (filter != null && isPrivilegeFiltered(filter, privilege)) continue; TResultRowBuilder rowBuilder = new TResultRowBuilder(); result.addToRows(addShowPrincipalOutputResults(privilege, rowBuilder).get()); } } return result; } /** * Check if the filter matches the privilege. */ private boolean isPrivilegeFiltered(TPrivilege filter, TPrivilege privilege) { filter.setPrivilege_level(privilege.getPrivilege_level()); String privName = PrincipalPrivilege.buildPrivilegeName(filter);
<|startcomment|> nit: this should be User <|endcomment|>  Type.STRING.toThrift())); addColumnOutputColumns(result.getSchema()); result.setRows(Lists.<TResultRow>newArrayList()); // A user should be considered to not exist if they do not have any groups. Set<String> groupNames = fe.getAuthzChecker().getUserGroups( new org.apache.impala.authorization.User(principalName)); if (groupNames.isEmpty()) { throw new AnalysisException(String.format("User '%s' does not exist.", principalName)); } <|startfocus|> Principal user = getUser(principalName); <|endfocus|> if (user != null) { for (PrincipalPrivilege p : user.getPrivileges()) { TPrivilege privilege = p.toThrift(); if (filter != null) { if (isPrivilegeFiltered(filter, privilege)) continue; } TResultRowBuilder rowBuilder = new TResultRowBuilder(); rowBuilder.add(Strings.nullToEmpty(TPrincipalType.USER.name().toUpperCase())); rowBuilder.add(Strings.nullToEmpty(principalName)); result.addToRows(addShowPrincipalOutputResults(privilege, rowBuilder).get()); } } 
<|startcomment|> remove empty line <|endcomment|> import org.apache.sentry.provider.common.GroupMappingService; import java.util.Map; import java.util.Set; /** * This class is used for testing complex privileges where we don't create * users and groups on the system. * * The current structure is: * user_1group -> group_1 * user_2group -> group_2a, group_2b * user1_shared -> group_3 * user2_shared -> group_3 */ public class CustomClusterGroupMapper implements GroupMappingService { <|startfocus|> <|endfocus|> private final Map<String, Set<String>> groupsMap_ = Maps.newHashMap(); public CustomClusterGroupMapper() { // Need to make sure we can resolve the dev user. String devUser = System.getProperty("user.name"); groupsMap_.put(devUser, Sets.newHashSet(devUser)); groupsMap_.put("user_1group", Sets.newHashSet("group_1")); groupsMap_.put("user_2group", Sets.newHashSet("group_2a", "group_2b")); groupsMap_.put("user1_shared", Sets.newHashSet("group_3"));
<|startcomment|> fix indentation <|endcomment|>  public CustomClusterResourceAuthorizationProvider(String resource, PolicyEngine policy, <|startfocus|> Model model) { <|endfocus|> super(policy, new CustomClusterGroupMapper(), model);
<|startcomment|> fix indentation <|endcomment|>  public CustomClusterResourceAuthorizationProvider(Configuration conf, String resource, <|startfocus|> PolicyEngine policy, Model model) { <|endfocus|> super(policy, new CustomClusterGroupMapper(), model);
<|startcomment|> nit: lots of 'value' in this comment. perhaps replace this with "make sense". <|endcomment|> import org.apache.impala.catalog.Type; import org.apache.impala.common.AnalysisException; import org.apache.impala.thrift.TExprNode; import org.apache.impala.thrift.TExprNodeType; import org.apache.impala.thrift.TSlotRef; import com.google.common.base.Joiner; import com.google.common.base.Objects; import com.google.common.base.Preconditions; public class SlotRef extends Expr { // Magic number to use to decide whether to adjust the // reported NDV value to account for possible null values. <|startfocus|> // Above this number, the adjustment does not add value. // Making this value any higher causes TPC-H plan tests to <|endfocus|> // fail because that has several two-value, non-nullable // fields that are marked as nullable. private static final int NULL_ADJUST_THRESHOLD = 1; private final List<String> rawPath_; private final String label_; // printed in toSql() // Results of analysis. private SlotDescriptor desc_; public SlotRef(ArrayList<String> rawPath) { super(); rawPath_ = rawPath; label_ = ToSqlUtils.getPathSql(rawPath_); } 
<|startcomment|> use a logger. <|endcomment|> import static org.junit.Assert.fail; import java.util.List; import org.apache.impala.common.ImpalaException; import org.apache.impala.service.Frontend.PlanCtx; import org.apache.impala.testutil.TestUtils; import org.apache.impala.thrift.TExplainLevel; import org.apache.impala.thrift.TQueryCtx; import org.apache.impala.thrift.TQueryOptions; import org.junit.Test; /** * Test the inference of tuple cardinality from NDV and * selectivity. */ public class CardinalityTest extends PlannerTestBase { <|startfocus|> private static final boolean DEBUG_MODE = false; <|endfocus|> /** * Test the happy path: table with stats, no all-null cols. */ @Test public void testBasicsWithStats() { // Return all rows. Cardinality is row count; verifyCardinality("SELECT id FROM functional.alltypes", 7300); // Return all rows. Cardinality is row count, // should not be influenced by limited NDV of selected // column. verifyCardinality("SELECT bool_col FROM functional.alltypes", 7300); // Result cardinality reduced by limited NDV. // Boolean column has cardinality 3 (true, false, null).
<|startcomment|> use a logger <|endcomment|>  queryOptions.setNum_nodes(1); PlanCtx planCtx = new PlanCtx(queryCtx); planCtx.requestPlanCapture(); // Discard the actual execution plan. Return the cached // internal form instead. try { frontend_.createExecRequest(planCtx); } catch (ImpalaException e) { fail(e.getMessage()); } <|startfocus|> List<PlanFragment> plan = planCtx.getPlan(); if (DEBUG_MODE) { System.out.println(plan.get(0).getExplainString( queryOptions, TExplainLevel.EXTENDED)); } return plan; <|endfocus|>
<|startcomment|> line too long (91 > 90) <|endcomment|>  public void testJoinWithoutStats() { // NDV multiplied out on group by <|startfocus|> expectCardinality("SELECT d FROM functional.alltypes, functional.nullrows", 7300 * 26); <|endfocus|> // With that as the basis, add a GROUP BY String baseStmt = "SELECT COUNT(*) " + "FROM functional.alltypes, functional.nullrows " + "GROUP BY "; // Unique values, one group per row expectCardinality(baseStmt + "id", 7300); // NDV(a) = 26 expectCardinality(baseStmt + "a", 26); // b has NDV=1, but adjust for nulls expectCardinality(baseStmt + "b", 2); // f has NDV=6 expectCardinality(baseStmt + "f", 6); // c is all nulls expectCardinality(baseStmt + "c", 1); // NDV(a) = 26 * ndv(c) = 1 expectCardinality(baseStmt + "a, c", 26); // NDV(a) = 26 * ndv(f) = 156 // Planner does not know that a determines f expectCardinality(baseStmt + "a, f", 156);
<|startcomment|> line too long (96 > 90) <|endcomment|>  public void testJoins() { // Cartesian product String joinClause = " FROM functional.alltypes t1, functional.alltypes t2 "; expectCardinality("SELECT t1.id" + joinClause, 7300 * 7300); // Cartesian product, reduced by NDV of group key <|startfocus|> expectCardinality("SELECT COUNT(*)" + joinClause + "GROUP BY t1.id", 7300); expectCardinality("SELECT COUNT(*)" + joinClause + "GROUP BY t1.id, t1.int_col", 7300 * 10); <|endfocus|>
<|startcomment|> 'kudu' is a pretty vague noun to use for this thing. If you end up renaming KuduRule to KuduTestFoo as I suggested in a different comment, I'd use the foo as the name of the instance. So for example if you use KuduTestHarness, this should be called 'harness'. <|endcomment|> import org.apache.hadoop.util.GenericOptionsParser; import org.apache.kudu.test.KuduRule; import org.junit.After; import org.junit.Rule; import org.junit.Test; import org.apache.kudu.mapreduce.CommandLineParser; import org.apache.kudu.mapreduce.HadoopTestingUtility; public class ITExportCsv { private static final String TABLE_NAME = ITExportCsv.class.getName() + "-" + System.currentTimeMillis(); private static final HadoopTestingUtility HADOOP_UTIL = new HadoopTestingUtility(); <|startfocus|> @Rule public KuduRule kudu = new KuduRule(); <|endfocus|> @After public void tearDown() throws Exception { HADOOP_UTIL.cleanup(); } @Test public void test() throws Exception { Configuration conf = new Configuration(); String testHome = HADOOP_UTIL.setupAndGetTestDir(ITExportCsv.class.getName(), conf).getAbsolutePath(); // create a table with on empty tablet and 3 tablets of 3 rows each. createFourTabletsTableWithNineRows(kudu.getAsyncClient(), TABLE_NAME, DEFAULT_SLEEP); String[] args = new String[] {
<|startcomment|> No retry rule. <|endcomment|> // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.kudu.client; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertNotNull; import static org.junit.Assert.assertNotSame; import static org.junit.Assert.assertTrue; import com.stumbleupon.async.Deferred; import org.junit.Test; import org.apache.kudu.util.NetUtil; public class TestConnectionCache { <|startfocus|> <|endfocus|> @Test(timeout = 50000) public void test() throws Exception { MiniKuduCluster cluster = null; try { cluster = new MiniKuduCluster.MiniKuduClusterBuilder().numMasterServers(3).build(); final AsyncKuduClient client = new AsyncKuduClient.AsyncKuduClientBuilder(cluster.getMasterAddressesAsString()).build(); // Below we ping the masters directly using RpcProxy, so if they aren't ready to process // RPCs we'll get an error. Here by listing the tables we make sure this won't happen since
<|startcomment|> useful <|endcomment|>  private MiniKuduClusterBuilder clusterBuilder; private MiniKuduCluster miniCluster; // We create both versions of the asyncClient for ease of use. public AsyncKuduClient asyncClient; public KuduClient client; public KuduRule(final MiniKuduClusterBuilder clusterBuilder) { this.clusterBuilder = clusterBuilder; } public KuduRule() { this.clusterBuilder = getBaseClusterBuilder(); } /** * Returns the base MiniKuduClusterBuilder used when creating a <|startfocus|> * KuduRule with the default constructor. This is usefull <|endfocus|> * if you want to add to the default cluster setup. * * @return */ public static MiniKuduClusterBuilder getBaseClusterBuilder() { return new MiniKuduClusterBuilder() .numMasterServers(NUM_MASTER_SERVERS) .numTabletServers(NUM_TABLET_SERVERS); } @Override public Statement apply(Statement base, Description description) { // Set any master server flags defined in the method level annotation. MasterServerConfig masterServerConfig = description.getAnnotation(MasterServerConfig.class); if (masterServerConfig != null) { for(String flag : masterServerConfig.flags()) {
<|startcomment|> for (String Above too. <|endcomment|>  // Set any master server flags defined in the method level annotation. MasterServerConfig masterServerConfig = description.getAnnotation(MasterServerConfig.class); if (masterServerConfig != null) { for(String flag : masterServerConfig.flags()) { clusterBuilder.addMasterServerFlag(flag); } } // Set any tablet server flags defined in the method level annotation. TabletServerConfig tabletServerConfig = description.getAnnotation(TabletServerConfig.class); if (tabletServerConfig != null) { <|startfocus|> for(String flag : tabletServerConfig.flags()) { <|endfocus|> clusterBuilder.addTabletServerFlag(flag); } } // Generate the ExternalResource Statement. Statement statement = super.apply(base, description); // Wrap in the RetryRule to rerun flaky tests. // We use this with Gradle because it doesn't support // Surefire/Failsafe rerunFailingTestsCount like Maven does. return new RetryRule().apply(statement, description);
<|startcomment|> I'd rewrite this, because as written it sounds like we're somehow only using this with Gradle. You can talk about how Maven's surefire/failsafe execution frameworks both support rerunning failed tests, but Gradle doesn't, and so it was a lot easier to implement retrying as a JUnit rule to be applied universally than it was to hack up Gradle to support the equivalent logic. <|endcomment|>  // Set any tablet server flags defined in the method level annotation. TabletServerConfig tabletServerConfig = description.getAnnotation(TabletServerConfig.class); if (tabletServerConfig != null) { for(String flag : tabletServerConfig.flags()) { clusterBuilder.addTabletServerFlag(flag); } } // Generate the ExternalResource Statement. Statement statement = super.apply(base, description); // Wrap in the RetryRule to rerun flaky tests. <|startfocus|> // We use this with Gradle because it doesn't support // Surefire/Failsafe rerunFailingTestsCount like Maven does. <|endfocus|> return new RetryRule().apply(statement, description);
<|startcomment|> Line too long? <|endcomment|>  // Wrap in the RetryRule to rerun flaky tests. // We use this with Gradle because it doesn't support // Surefire/Failsafe rerunFailingTestsCount like Maven does. return new RetryRule().apply(statement, description); } @Override public void before() throws Exception { FakeDNS.getInstance().install(); LOG.info("Creating a new MiniKuduCluster..."); miniCluster = clusterBuilder.build(); LOG.info("Creating a new Kudu client..."); <|startfocus|> asyncClient = new AsyncKuduClient.AsyncKuduClientBuilder(miniCluster.getMasterAddressesAsString()) <|endfocus|> .defaultAdminOperationTimeoutMs(DEFAULT_SLEEP) .build(); client = asyncClient.syncClient(); } @Override public void after() { try { if (asyncClient != null) { client.shutdown(); // No need to explicitly shutdown the async client, // shutting down the sync client effectively does that. } } catch (KuduException e) { LOG.warn("Error while shutting down the test client"); } finally { if (miniCluster != null) { miniCluster.shutdown(); } } }
<|startcomment|> Shouldn't this be a client != null check? <|endcomment|>  public void after() { try { <|startfocus|> if (asyncClient != null) { <|endfocus|> client.shutdown(); // No need to explicitly shutdown the async client, // shutting down the sync client effectively does that. } } catch (KuduException e) { LOG.warn("Error while shutting down the test client"); } finally { if (miniCluster != null) { miniCluster.shutdown(); } }
<|startcomment|> Add Javadoc? <|endcomment|>  client.shutdown(); // No need to explicitly shutdown the async client, // shutting down the sync client effectively does that. } } catch (KuduException e) { LOG.warn("Error while shutting down the test client"); } finally { if (miniCluster != null) { miniCluster.shutdown(); } } } public KuduClient getClient() { return client; } public AsyncKuduClient getAsyncClient() { return asyncClient; } <|startfocus|> public KuduTable createTable(String tableName, Schema schema, CreateTableOptions builder) throws KuduException { LOG.info("Creating table: {}", tableName); return asyncClient.syncClient().createTable(tableName, schema, builder); } <|endfocus|> /** * Helper method to open a table. It sets the default sleep time when joining on the Deferred. * @param name Name of the table * @return A KuduTable * @throws Exception MasterErrorException if the table doesn't exist */ public KuduTable openTable(String name) throws Exception {
<|startcomment|> Indentation <|endcomment|>  // shutting down the sync client effectively does that. } } catch (KuduException e) { LOG.warn("Error while shutting down the test client"); } finally { if (miniCluster != null) { miniCluster.shutdown(); } } } public KuduClient getClient() { return client; } public AsyncKuduClient getAsyncClient() { return asyncClient; } <|startfocus|> public KuduTable createTable(String tableName, Schema schema, CreateTableOptions builder) throws KuduException { LOG.info("Creating table: {}", tableName); return asyncClient.syncClient().createTable(tableName, schema, builder); } <|endfocus|> /** * Helper method to open a table. It sets the default sleep time when joining on the Deferred. * @param name Name of the table * @return A KuduTable * @throws Exception MasterErrorException if the table doesn't exist */ public KuduTable openTable(String name) throws Exception { Deferred<KuduTable> d = asyncClient.openTable(name); return d.join(DEFAULT_SLEEP); } 
<|startcomment|> Too long. <|endcomment|>  * into the Kerberos credential cache. * @param username the username to kinit as */ public void kinit(String username) throws IOException { miniCluster.kinit(username); } /** * Resets the clients so that their state is completely fresh, including meta * cache, connections, open tables, sessions and scanners, and propagated timestamp. */ public void resetClients() throws IOException { client.shutdown(); <|startfocus|> asyncClient = new AsyncKuduClient.AsyncKuduClientBuilder(miniCluster.getMasterAddressesAsString()) <|endfocus|> .defaultAdminOperationTimeoutMs(DEFAULT_SLEEP) .build(); client = asyncClient.syncClient(); } /** * An annotation that can be added to each test method to * define additional master server flags to be used when * creating the test cluster. * * ex: @MasterServerConfig(flags = { "key1=valA", "key2=valB" }) */ @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.METHOD}) public @interface MasterServerConfig { String[] flags(); } /**
<|startcomment|> nit: How about inverting it? I think that is more readable. if (hint.is("straight_join) { setIsStraightJoin(); } else { addWarning() } <|endcomment|>  public void analyzePlanHints(Analyzer analyzer) { for (PlanHint hint: planHints_) { if (!hint.is("straight_join")) { analyzer.addWarning("PLAN hint not recognized: " + hint); } <|startfocus|> analyzer.setIsStraightJoin(); <|endfocus|> }
<|startcomment|> nit: move L89 to L88 <|endcomment|>  public void analyzePlanHints(Analyzer analyzer) { for (PlanHint hint: planHints_) { if (!hint.is("straight_join")) { analyzer.addWarning("PLAN hint not recognized: " + hint); <|startfocus|> } else { <|endfocus|> analyzer.setIsStraightJoin(); } }
<|startcomment|> line too long (95 > 90) <|endcomment|>  // be moved from this location, the user needs to have all permission. sourceDataPath_.analyze(analyzer, Privilege.ALL); // Catch all exceptions thrown by accessing files, and rethrow as AnalysisExceptions. try { Path source = sourceDataPath_.getPath(); FileSystem fs = source.getFileSystem(FileSystemUtil.getConfiguration()); if (!(fs instanceof DistributedFileSystem) && !(fs instanceof S3AFileSystem) && <|startfocus|> !(fs instanceof AzureBlobFileSystem) && !(fs instanceof SecureAzureBlobFileSystem) && <|endfocus|> !(fs instanceof AdlFileSystem)) { throw new AnalysisException(String.format("INPATH location '%s' " + "must point to an HDFS, S3A, ADL or ABFS filesystem.", sourceDataPath_)); } if (!fs.exists(source)) { throw new AnalysisException(String.format( "INPATH location '%s' does not exist.", sourceDataPath_)); } // If the source file is a directory, we must be able to read from and write to
<|startcomment|> Update? <|endcomment|>  public static byte[] deflateCompress(byte[] input) { if (input == null) return null; ByteArrayOutputStream bos = new ByteArrayOutputStream(input.length); <|startfocus|> // TODO: Benchmark other compression levels. <|endfocus|> DeflaterOutputStream stream = new DeflaterOutputStream(bos, new Deflater(Deflater.BEST_SPEED)); try { stream.write(input); stream.close(); } catch (IOException e) { LOG.error("Error compressing input bytes.", e); return null; } return bos.toByteArray();
<|startcomment|> nit: add /*varNames=*/ <|endcomment|>  // so it's necessary to use the HMS APIs directly. HiveMetastoreConfig hmsConfig = client.getHiveMetastoreConfig(); HiveConf hiveConf = new HiveConf(); hiveConf.setVar(HiveConf.ConfVars.METASTOREURIS, hmsConfig.getHiveMetastoreUris()); hiveConf.setBoolVar( HiveConf.ConfVars.METASTORE_USE_THRIFT_SASL, hmsConfig.getHiveMetastoreSaslEnabled()); // Check that the owner of the table in the HMS matches. <|startfocus|> IMetaStoreClient hmsClient = new HiveMetaStoreClient(hiveConf, null, false); <|endfocus|> assertEquals(owner, hmsClient.getTable("default", "testOverrideTableOwner").getOwner()); // Altering the table should not result in a change of ownership. client.alterTable( tableName, new AlterTableOptions().renameTable("default.testOverrideTableOwner_renamed")); assertEquals(owner, hmsClient.getTable("default", "testOverrideTableOwner_renamed").getOwner()); } } 
<|startcomment|> Should any of this bubble up to the runtime profiles (if one exists) for these requests? <|endcomment|>  PrivilegeRequest request = new PrivilegeRequestBuilder() .any().onAnyTable(db.getName()).toRequest(); return authzChecker_.get().hasAccess(user, request); } /** * Returns all data sources that match the pattern. If pattern is null, * matches all data sources. */ public List<DataSource> getDataSrcs(String pattern) { return impaladCatalog_.getDataSources( PatternMatcher.createHivePatternMatcher(pattern)); } /** * Generate result set and schema for a SHOW COLUMN STATS command. */ public TResultSet getColumnStats(String dbName, String tableName) throws ImpalaException { <|startfocus|> Table table = impaladCatalog_.getTable(dbName, tableName); <|endfocus|> TResultSet result = new TResultSet(); TResultSetMetadata resultSchema = new TResultSetMetadata(); result.setSchema(resultSchema); resultSchema.addToColumns(new TColumn("Column", Type.STRING.toThrift())); resultSchema.addToColumns(new TColumn("Type", Type.STRING.toThrift())); resultSchema.addToColumns( new TColumn("#Distinct Values", Type.BIGINT.toThrift()));
<|startcomment|> , exception) to log the trace and you can probably skip exception.getMessage() <|endcomment|>  return authzChecker_.get().hasAccess(user, request); } /** * Returns all data sources that match the pattern. If pattern is null, * matches all data sources. */ public List<DataSource> getDataSrcs(String pattern) { return impaladCatalog_.getDataSources( PatternMatcher.createHivePatternMatcher(pattern)); } /** * Generate result set and schema for a SHOW COLUMN STATS command. */ public TResultSet getColumnStats(String dbName, String tableName) throws ImpalaException { <|startfocus|> Table table = impaladCatalog_.getTable(dbName, tableName); <|endfocus|> TResultSet result = new TResultSet(); TResultSetMetadata resultSchema = new TResultSetMetadata(); result.setSchema(resultSchema); resultSchema.addToColumns(new TColumn("Column", Type.STRING.toThrift())); resultSchema.addToColumns(new TColumn("Type", Type.STRING.toThrift())); resultSchema.addToColumns( new TColumn("#Distinct Values", Type.BIGINT.toThrift())); resultSchema.addToColumns(new TColumn("#Nulls", Type.BIGINT.toThrift()));
<|startcomment|> You could move this above L298 and then add a check to useTopN, that way the check below stays concise: if (useTopN) ... <|endcomment|>  } else { root.setLimit(stmt.getLimit()); root.computeStats(analyzer); } return root; } /** * If there are unassigned conjuncts that are bound by tupleIds or if there are slot * equivalences for tupleIds that have not yet been enforced, returns a SelectNode on * top of root that evaluates those conjuncts; otherwise returns root unchanged. * TODO: change this to assign the unassigned conjuncts to root itself, if that is * semantically correct */ private PlanNode addUnassignedConjuncts( <|startfocus|> Analyzer analyzer, List<TupleId> tupleIds, PlanNode root) throws ImpalaException { <|endfocus|> // No point in adding SelectNode on top of an EmptyNode. if (root instanceof EmptySetNode) return root; Preconditions.checkNotNull(root); // Gather unassigned conjuncts and generate predicates to enfore // slot equivalences for each tuple id. List<Expr> conjuncts = analyzer.getUnassignedConjuncts(root); for (TupleId tid: tupleIds) { analyzer.createEquivConjuncts(tid, conjuncts); } if (conjuncts.isEmpty()) return root;
<|startcomment|> Can you explain the relation of the two toSql() functions in the comment? If I understand correctly, then toSql() should always call toSql(ToSqlOptions options) with default option. At the first glance I thought that the parameterless toSql should be removed to avoid possible mistakes, but then I realized the huge number of places where it is called, so now I agree with this solution. <|endcomment|> // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { /** * Perform semantic analysis of node and all of its children. * Throws exception if any semantic errors were found. */ void analyze(Analyzer analyzer) throws AnalysisException; /** * Returns the SQL string corresponding to this node. */ <|startfocus|> String toSql(); <|endfocus|> /** * Returns the SQL string corresponding to this node. * @param options controls what sql is returned * @see ToSqlOptions */ String toSql(ToSqlOptions options); } 
<|startcomment|> spurious newline <|endcomment|>  List<Expr> tupleIsNullPreds = Lists.newArrayList(); for (Expr rhsExpr: inputSmap.getRhs()) { // Ignore substitutions that are irrelevant at this plan node and its ancestors. if (!rhsExpr.isBoundByTupleIds(input.getTupleIds())) continue; rhsExpr.collect(TupleIsNullPredicate.class, tupleIsNullPreds); } Expr.removeDuplicates(tupleIsNullPreds); sortInfo.addMaterializedExprs(tupleIsNullPreds, analyzer_); } sortInfo.getSortTupleDescriptor().materializeSlots(); return sortInfo; } <|startfocus|> <|endfocus|> /** * Create plan tree for the entire sort group, including all contained window groups. * Marks the SortNode as requiring its input to be partitioned if partitionExprs * is not null (partitionExprs represent the data partition of the entire partition * group of which this sort group is a part). */ private PlanNode createSortGroupPlan(PlanNode root, SortGroup sortGroup, List<Expr> partitionExprs) throws ImpalaException { List<Expr> partitionByExprs = sortGroup.partitionByExprs; List<OrderByElement> orderByElements = sortGroup.orderByElements;
<|startcomment|> where'd the return go? pls look into why tests did not get bothered by this... the profile could have been overwritten down below, in which case we'd get possibly different estimates. <|endcomment|>  public void computeResourceProfile(TQueryOptions queryOptions) { Preconditions.checkState(hasValidStats()); if (type_ == TSortType.TOPN) { <|startfocus|> long perInstanceMemEstimate = (long) Math.ceil((cardinality_ + offset_) * avgRowSize_); resourceProfile_ = new ResourceProfile(perInstanceMemEstimate, 0); <|endfocus|> return; } // For an external sort, set the memory cost to be what is required for a 2-phase // sort. If the input to be sorted would take up N blocks in memory, then the // memory required for a 2-phase sort is sqrt(N) blocks. A single run would be of // size sqrt(N) blocks, and we could merge sqrt(N) such runs with sqrt(N) blocks // of memory. double fullInputSize = getChild(0).cardinality_ * avgRowSize_; boolean hasVarLenSlots = false; for (SlotDescriptor slotDesc: info_.getSortTupleDescriptor().getSlots()) { if (slotDesc.isMaterialized() && !slotDesc.getType().isFixedLengthType()) { hasVarLenSlots = true; break;
<|startcomment|> Do you know what the answer is here? <|endcomment|>  * true AND 'expr' -> 'expr' * false AND 'expr' -> false * true OR 'expr' -> true * false OR 'expr' -> 'expr' * * Unlike other rules here such as IF, we cannot in general simplify CompoundPredicates * with a NullLiteral child (unless the other child is a BoolLiteral), eg. null and * 'expr' is false if 'expr' is false but null if 'expr' is true. * * NOT is covered by FoldConstantRule. */ private Expr simplifyCompoundPredicate(CompoundPredicate expr) { <|startfocus|> Expr leftChild = expr.getChild(0); if (!(leftChild instanceof BoolLiteral)) return expr; <|endfocus|> if (expr.getOp() == CompoundPredicate.Operator.AND) { if (((BoolLiteral) leftChild).getValue()) { // TRUE AND 'expr', so return 'expr'. return expr.getChild(1); } else { // FALSE AND 'expr', so return FALSE. return leftChild; }
<|startcomment|> nit: can just return this expression <|endcomment|>  private boolean isBroadcastExchange() { // If the output of the sink is not partitioned but the target fragment is // partitioned, then the data exchange is broadcast. Preconditions.checkState(!children_.isEmpty()); DataSink sink = getChild(0).getFragment().getSink(); if (sink == null) return false; Preconditions.checkState(sink instanceof DataStreamSink); DataStreamSink streamSink = (DataStreamSink) sink; <|startfocus|> if (!streamSink.getOutputPartition().isPartitioned() && fragment_.isPartitioned()) { return true; } return false; <|endfocus|>
<|startcomment|> checkArgument <|endcomment|>  byte [] partitionStats, boolean hasIncrementalStats) { table_ = Preconditions.checkNotNull(table); spec_ = Preconditions.checkNotNull(spec); msPartition_ = Preconditions.checkNotNull(msPartition); <|startfocus|> fileDescriptors_ = fileDescriptors; partitionStats_ = partitionStats; hasIncrementalStats_ = hasIncrementalStats; // Columns should have been removed in the cache. Preconditions.checkState(msPartition_.getSd().getCols() == null); <|endfocus|>
<|startcomment|> nit: it's weird that there are two spaces there. <|endcomment|>  * nullif(expr1, expr2) * nvl(a, ifNull) * * Since every function is rewritten to a CASE * statement, the planner runs the rule to simplify CASE * after this rule. Where that other rule can perform simplifications, * those simplifications are omitted here. However, the CASE * case rules are limited (See IMPALA-7750), so several optimizations * appear here that can be removed once IMPALA-7750 is fixed. */ <|startfocus|> public class RewriteConditionalFnsRule implements ExprRewriteRule { <|endfocus|> public static RewriteConditionalFnsRule INSTANCE = new RewriteConditionalFnsRule(); private RewriteConditionalFnsRule() { } @Override public Expr apply(Expr expr, Analyzer analyzer) throws AnalysisException { if (!expr.isAnalyzed()) return expr; // Rewrite conditional functions to use CASE. The result becomes // the original expression since there is no implementation for the // rewritten function. All rewritten functions use CASE, so we'll // then want to allow CASE to do any simplification (reverting to // the original case expression if we don't pass the aggregate
<|startcomment|> If we're not using HTML, is the <br> here noise? <|endcomment|>  Lists.newArrayList( new CaseWhenClause( // WHEN cond THEN thenExpr expr.getChild(0), expr.getChild(1))), expr.getChild(2)); // ELSE elseExpr END } /** * Rewrites IFNULL(a, x), which is an alias * for ISNULL(a, x) and NVL(a, x). * * IFNULL(NULL, x) --> x * IFNULL(a, x) --> a, if a is a non-null literal <|startfocus|> * IFNULL(a, x) --> <br> <|endfocus|> * CASE WHEN a IS NULL THEN x ELSE a END */ private Expr rewriteIfNullFn(FunctionCallExpr expr) { Preconditions.checkState(expr.getChildren().size() == 2); Expr child0 = expr.getChild(0); return new CaseExpr(null, // CASE Lists.newArrayList( new CaseWhenClause( // WHEN a IS NULL new IsNullPredicate(child0, false), expr.getChild(1))), // THEN x child0.clone()); // ELSE a END } /**
<|startcomment|> nit: including the subject of the JIRA here may make it obvious why... <|endcomment|>  } /** * Test some basic simplifications that are assumed in the * subsequent tests. These uncovered subtle errors and are here * to prevent regressions. */ @Test public void sanityTest() throws ImpalaException { verifySelectRewrite("null + 1", "NULL"); verifySelectRewrite("null is null", "TRUE"); verifySelectRewrite("id + (2 + 3)", "id + 5"); verifySelectRewrite("1 + 2 + id", "3 + id"); <|startfocus|> // TODO: IMPALA-7766 <|endfocus|> // verifySelectRewrite("id + 1 + 2", "id + 3"); // TODO: IMPALA-7769 // verifySelectRewrite("cast(null as INT) IS NULL", "TRUE"); // verifySelectRewrite("(null + 1) is null", "TRUE"); // verifySelectRewrite("(1 + 1) is null", "FALSE"); // verifySelectRewrite("CASE WHEN null + 1 THEN 10 ELSE 20 END", "20"); } @Test public void testIf() throws ImpalaException { // Simplifications provided by CASE rewriting
<|startcomment|> Should we be testing the boring case: if(a, b, c) => case when a then b else c for columns a, b, c. (As opposed to aggregations or constants.) Update: I think this is covered in the next test file. <|endcomment|>  // TODO: IMPALA-7766 // verifySelectRewrite("id + 1 + 2", "id + 3"); // TODO: IMPALA-7769 // verifySelectRewrite("cast(null as INT) IS NULL", "TRUE"); // verifySelectRewrite("(null + 1) is null", "TRUE"); // verifySelectRewrite("(1 + 1) is null", "FALSE"); // verifySelectRewrite("CASE WHEN null + 1 THEN 10 ELSE 20 END", "20"); } @Test public void testIf() throws ImpalaException { <|startfocus|> <|endfocus|> // Simplifications provided by CASE rewriting verifySelectRewrite("if(true, id, id+1)", "id"); verifySelectRewrite("if(false, id, id+1)", "id + 1"); verifySelectRewrite("if(null, id, id+1)", "id + 1"); // Nothing to simplify verifySelectRewrite("if(id = 0, true, false)", "CASE WHEN id = 0 THEN TRUE ELSE FALSE END"); // Don't simplify if drops last aggregate verifySelectRewrite("if(true, 0, sum(id))",
<|startcomment|> line too long (91 > 90) <|endcomment|>  SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getSelectList().getItems().get(0).getExpr(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; } public Expr RewritesOkWhereExpr(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { <|startfocus|> return RewritesOkWhereExpr("functional.alltypessmall", exprStr, rule, expectedExprStr); <|endfocus|> } public Expr RewritesOkWhereExpr(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select count(1) from " + tableName + " where " + exprStr; // Analyze without rewrites since that's what we want to test here. SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr);
<|startcomment|> line too long (104 > 90) <|endcomment|>  this.wrapped = wrapped; } public Expr apply(Expr expr, Analyzer analyzer) throws AnalysisException { Expr ret = wrapped.apply(expr, analyzer); if (expr != ret) rewrites++; return ret; } } public Expr RewritesOk(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOk("functional.alltypessmall", exprStr, rule, expectedExprStr); } <|startfocus|> public Expr RewritesOk(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) <|endfocus|> throws ImpalaException { return RewritesOk(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOk(String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { return RewritesOk("functional.alltypessmall", exprStr, rules, expectedExprStr); } public Expr RewritesOk(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select " + exprStr + " from " + tableName;
<|startcomment|> line too long (93 > 90) <|endcomment|>  return ret; } } public Expr RewritesOk(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOk("functional.alltypessmall", exprStr, rule, expectedExprStr); } public Expr RewritesOk(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOk(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } <|startfocus|> public Expr RewritesOk(String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) <|endfocus|> throws ImpalaException { return RewritesOk("functional.alltypessmall", exprStr, rules, expectedExprStr); } public Expr RewritesOk(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select " + exprStr + " from " + tableName; // Analyze without rewrites since that's what we want to test here. SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getSelectList().getItems().get(0).getExpr();
<|startcomment|> line too long (95 > 90) <|endcomment|>  String stmtStr = "select " + exprStr + " from " + tableName; // Analyze without rewrites since that's what we want to test here. SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getSelectList().getItems().get(0).getExpr(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; } <|startfocus|> public Expr RewritesOkWhereExpr(String exprStr, ExprRewriteRule rule, String expectedExprStr) <|endfocus|> throws ImpalaException { return RewritesOkWhereExpr("functional.alltypessmall", exprStr, rule, expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException {
<|startcomment|> line too long (113 > 90) <|endcomment|>  AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getSelectList().getItems().get(0).getExpr(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; } public Expr RewritesOkWhereExpr(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr("functional.alltypessmall", exprStr, rule, expectedExprStr); } <|startfocus|> public Expr RewritesOkWhereExpr(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) <|endfocus|> throws ImpalaException { return RewritesOkWhereExpr(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, String expectedExprStr) throws ImpalaException { String stmtStr = "select count(1) from " + tableName + " where " + exprStr; // Analyze without rewrites since that's what we want to test here. SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getWhereClause();
<|startcomment|> line too long (96 > 90) <|endcomment|>  return rewrittenExpr; } public Expr RewritesOkWhereExpr(String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr("functional.alltypessmall", exprStr, rule, expectedExprStr); } public Expr RewritesOkWhereExpr(String tableName, String exprStr, ExprRewriteRule rule, String expectedExprStr) throws ImpalaException { return RewritesOkWhereExpr(tableName, exprStr, Lists.newArrayList(rule), expectedExprStr); } <|startfocus|> public Expr RewritesOkWhereExpr(String tableName, String exprStr, List<ExprRewriteRule> rules, <|endfocus|> String expectedExprStr) throws ImpalaException { String stmtStr = "select count(1) from " + tableName + " where " + exprStr; // Analyze without rewrites since that's what we want to test here. SelectStmt stmt = (SelectStmt) ParsesOk(stmtStr); AnalyzesOkNoRewrite(stmt); Expr origExpr = stmt.getWhereClause(); Expr rewrittenExpr = verifyExprEquivalence(origExpr, expectedExprStr, rules, stmt.getAnalyzer()); return rewrittenExpr; } private Expr verifyExprEquivalence(Expr origExpr, String expectedExprStr,
<|startcomment|> nit: pls use consistent case (SQL, sql, Sql) <|endcomment|> // specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { /** * Perform semantic analysis of node and all of its children. * Throws exception if any semantic errors were found. */ void analyze(Analyzer analyzer) throws AnalysisException; /** * Returns the SQL string corresponding to this node and its descendants. <|startfocus|> * @param options controls the form of the sql that is returned. * @see ToSqlOptions <|endfocus|> */ String toSql(ToSqlOptions options); /** * Returns the SQL string corresponding to this node and its descendants. * This should return the same result as calling toSql(ToSqlOptions.DEFAULT). */ String toSql(); } 
<|startcomment|> pls omit these javadoc annotations. <|endcomment|> // specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { /** * Perform semantic analysis of node and all of its children. * Throws exception if any semantic errors were found. */ void analyze(Analyzer analyzer) throws AnalysisException; /** * Returns the SQL string corresponding to this node and its descendants. <|startfocus|> * @param options controls the form of the sql that is returned. * @see ToSqlOptions <|endfocus|> */ String toSql(ToSqlOptions options); /** * Returns the SQL string corresponding to this node and its descendants. * This should return the same result as calling toSql(ToSqlOptions.DEFAULT). */ String toSql(); } 
<|startcomment|> would be good to do this via a default interface method. pls add a todo for when we fully move to Java 8. <|endcomment|>  * Throws exception if any semantic errors were found. */ void analyze(Analyzer analyzer) throws AnalysisException; /** * Returns the SQL string corresponding to this node and its descendants. * @param options controls the form of the sql that is returned. * @see ToSqlOptions */ String toSql(ToSqlOptions options); /** * Returns the SQL string corresponding to this node and its descendants. <|startfocus|> * This should return the same result as calling toSql(ToSqlOptions.DEFAULT). <|endfocus|> */ String toSql(); } 
<|startcomment|> "normal" makes sense if you know what is currently done. perhaps "original query without rewrites"? <|endcomment|> // Unless required by applicable law or agreed to in writing, // software distributed under the License is distributed on an // "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY // KIND, either express or implied. See the License for the // specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; /** * Options to configure how Sql should be outputted by toSql() and related calls. */ public enum ToSqlOptions { /** <|startfocus|> * The default, normal way of displaying Sql <|endfocus|> */ DEFAULT(false, false), /** * Show rewritten query if it exists */ REWRITTEN(true, false), /** * Show Implicit Casts */ // To see implicit casts we must also show rewrites as otherwise we see original sql. // This does have the consequence that the sql with implict casts may not pssibly fail // to parse if resubmitted as, for example, rewritten semi-joins are not legal Sql. SHOW_IMPLICIT_CASTS(true, true); private boolean rewritten_; 
<|startcomment|> what's this? <|endcomment|>  public static String wrapString(String s, int wrapLength) { <|startfocus|> StringBuilder ret = new StringBuilder(s.length() + 32); <|endfocus|> String[] split = s.split("\n"); for (int i = 0; i < split.length; i++) { String line = split[i]; String wrappedLine = WordUtils.wrap(line, wrapLength, null, true); // we keep any exiting newlines in text - these should be commented hints ret.append(wrappedLine); if (i < split.length - 1) ret.append("\n"); } return ret.toString();
<|startcomment|> sp. existing? <|endcomment|>  public static String wrapString(String s, int wrapLength) { StringBuilder ret = new StringBuilder(s.length() + 32); String[] split = s.split("\n"); for (int i = 0; i < split.length; i++) { String line = split[i]; String wrappedLine = WordUtils.wrap(line, wrapLength, null, true); <|startfocus|> // we keep any exiting newlines in text - these should be commented hints <|endfocus|> ret.append(wrappedLine); if (i < split.length - 1) ret.append("\n"); } return ret.toString();
<|startcomment|> remove <|endcomment|>  checkNumericLiteralCasts(ctx, "double_col", "1", "TINYINT"); checkNumericLiteralCasts(ctx, "double_col", "1.0", "DECIMAL(2,1)"); checkNumericLiteralCasts(ctx, "double_col", "100000.001", "DECIMAL(9,3)"); } /** * Generate an insert query into a column and check that the toSql() with implicit casts <|startfocus|> * looks as expected * @param columnName the name of a column in functional.alltypesnopart * @param data the literal value to insert * @param castColumn the type to which the literal is expected to be cast <|endfocus|> */ private void checkNumericLiteralCasts( AnalysisContext ctx, String columnName, String data, String castColumn) { String query = "insert into table functional.alltypesnopart (" + columnName + ") " + "values(" + data + ")"; String expectedToSql = "INSERT INTO TABLE " + "functional.alltypesnopart(" + columnName + ") " + "SELECT CAST(" + data + " AS " + castColumn + ")"
<|startcomment|> rm? <|endcomment|>  private void assertToSqlWithImplicitCasts( AnalysisContext ctx, String query, String expectedToSqlWithImplicitCasts) { StatementBase stmt = (StatementBase) AnalyzesOk(query, ctx); <|startfocus|> // AnalyzesOk(stmt.toSql(true), ctx); <|endfocus|> String actual = stmt.toSql(SHOW_IMPLICIT_CASTS); Assert.assertEquals("Bad sql with implicit casts from original query:\n" + query, expectedToSqlWithImplicitCasts, actual);
<|startcomment|> remove the comment annotations. <|endcomment|>  ignoreExplainHeader); } catch (CatalogException e) { errorLog.append(String.format("Failed to plan query\n%s\n%s", testCase.getQuery(), e.getMessage())); } actualOutput.append("====\n"); } // Create the actual output file if (GENERATE_OUTPUT_FILE) { try { <|startfocus|> File outDirFile = new File(outDir_); outDirFile.mkdirs(); FileWriter fw = new FileWriter(outDir_ + testFile + ".test"); <|endfocus|> fw.write(actualOutput.toString()); fw.close(); } catch (IOException e) { errorLog.append("Unable to create output file: " + e.getMessage()); } } if (errorLog.length() != 0) { fail(errorLog.toString()); }
<|startcomment|> nit: Capital W + . at the end. <|endcomment|>  assertEquals("8.42PB", PrintUtils.printBytesRoundedToMb( (long)(1024L * 1024L * 1024L * 1024L * 1024L * 8.42))); // Negative values always get bytes as unit. // TODO: fix this behaviour if needed. assertEquals("-10B", PrintUtils.printBytesRoundedToMb(-10L)); assertEquals("-123456789B", PrintUtils.printBytesRoundedToMb(-123456789L)); } /** <|startfocus|> * wrap length for testWrapText() - less than 80 to make test layout nicer <|endfocus|> */ private static final int WRAP_LENGTH = 60; /** * Test for PrintUtils.wrapString(). * */ @Test public void testWrapText() { // Simple query wrapping. assertWrap( "Analyzed query: SELECT * FROM functional_kudu.alltypestiny WHERE CAST(bigint_col" + " AS DOUBLE) < CAST(10 AS DOUBLE)", "Analyzed query: SELECT * FROM functional_kudu.alltypestiny\n" + "WHERE CAST(bigint_col AS DOUBLE) < CAST(10 AS DOUBLE)");
<|startcomment|> nit: extra * <|endcomment|>  // Negative values always get bytes as unit. // TODO: fix this behaviour if needed. assertEquals("-10B", PrintUtils.printBytesRoundedToMb(-10L)); assertEquals("-123456789B", PrintUtils.printBytesRoundedToMb(-123456789L)); } /** * wrap length for testWrapText() - less than 80 to make test layout nicer */ private static final int WRAP_LENGTH = 60; /** * Test for PrintUtils.wrapString(). <|startfocus|> * */ <|endfocus|> @Test public void testWrapText() { // Simple query wrapping. assertWrap( "Analyzed query: SELECT * FROM functional_kudu.alltypestiny WHERE CAST(bigint_col" + " AS DOUBLE) < CAST(10 AS DOUBLE)", "Analyzed query: SELECT * FROM functional_kudu.alltypestiny\n" + "WHERE CAST(bigint_col AS DOUBLE) < CAST(10 AS DOUBLE)"); // Simple query with a hint retains newlines surrounding hint. assertWrap("SELECT \n" + "-- +straight_join\n" + " * FROM tpch_parquet.orders INNER JOIN \n"
<|startcomment|> nit: missing . <|endcomment|>  assertWrap("insert into foo values (' " + " " + " ')", "insert into foo values (' \n" + "')"); // test that long words are broken up for clarity assertWrap("select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx", "select\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxx"); } /** <|startfocus|> * Check that code that has been wrapped is correctly formatted * @param input input to wrap <|endfocus|> * @param expected what it should be */ private void assertWrap(String input, String expected) { String actual = PrintUtils.wrapString(input, WRAP_LENGTH); assertEquals(expected, actual); assertNoBlankLines(actual); assertNoTerminatingNewline(actual); assertNoLongLines(actual); } /** * Assert that all lines of wrapped output are 80 chars or less. */ private void assertNoLongLines(String s) { for (String line : s.split("\n")) {
<|startcomment|> rm <|endcomment|>  + " " + " ')", "insert into foo values (' \n" + "')"); // test that long words are broken up for clarity assertWrap("select xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx", "select\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n" + "xxxxxxxxxxxxxxxxxxxxxxxxx"); } /** <|startfocus|> * Check that code that has been wrapped is correctly formatted * @param input input to wrap <|endfocus|> * @param expected what it should be */ private void assertWrap(String input, String expected) { String actual = PrintUtils.wrapString(input, WRAP_LENGTH); assertEquals(expected, actual); assertNoBlankLines(actual); assertNoTerminatingNewline(actual); assertNoLongLines(actual); } /** * Assert that all lines of wrapped output are 80 chars or less. */ private void assertNoLongLines(String s) { for (String line : s.split("\n")) {
<|startcomment|> is this accurate given the comments in the commit message about order by? <|endcomment|> import java.util.List; import org.apache.impala.analysis.Analyzer; import org.apache.impala.analysis.CaseExpr; import org.apache.impala.analysis.CaseWhenClause; import org.apache.impala.analysis.Expr; import org.apache.impala.analysis.FunctionCallExpr; import org.apache.impala.analysis.IsNullPredicate; import org.apache.impala.analysis.NullLiteral; import org.apache.impala.common.AnalysisException; import com.google.common.base.Preconditions; import com.google.common.collect.Lists; /** * Rewrites conditional functions to use a CASE statement. * The conditional functions vanish from the plan after this <|startfocus|> * rewrite: there is no back-end implementation for these functions. <|endfocus|> * * coalesce(v1, v2, ...) * if(condition, ifTrue, ifFalseOrNull) * ifnull(a, ifNull) * isnull(a, ifNull) * nullif(expr1, expr2) * nvl(a, ifNull) * * Since every function is rewritten to a CASE * statement, the planner runs the rule to simplify CASE * after this rule. Where that other rule can perform simplifications, * those simplifications are omitted here. However, the CASE
<|startcomment|> clarify whether you think this happens after the rewrite or before. If its after, then I expect the example on L109,110 to be in terms of CASE. I'm also fine with omitting the example since its assumed that these rules compose. <|endcomment|>  switch (expr.getFnName().getFunction()) { case "if": return rewriteIfFn(expr); case "coalesce": return rewriteCoalesceFn(expr); case "isnull": case "nvl": case "ifnull": return rewriteIfNullFn(expr); default: return expr; } } /** * Rewrites IF(cond, thenExpr, elseExpr) --> * CASE WHEN cond THEN thenExpr ELSE elseExpr END. * <|startfocus|> * Relies on CASE simplification to perform the * following simplifications: <|endfocus|> * * IF(TRUE, thenExpr, elseExpr) --> thenExpr * IF(FALSE|NULL, thenExpr, elseExpr) --> elseExpr * */ private Expr rewriteIfFn(FunctionCallExpr expr) { Preconditions.checkState(expr.getChildren().size() == 3); return new CaseExpr(null, // CASE Lists.newArrayList( new CaseWhenClause( // WHEN cond THEN thenExpr expr.getChild(0), expr.getChild(1))), expr.getChild(2)); // ELSE elseExpr END } /**
<|startcomment|> The simplest rewrite here would be to not look at the child exprs for the various scenarios listed above and instead simply translate naively to a case statement. From there, we'd get constant folding and case simplification which will find the first when clause that evals to true. preceding when clauses that remain unknown will be retained, but this transform will need to retain them as well. Aggregate handling will result in a brute-force roll-back of the rewrite in case simplification, which will result in falling back to the case rewrite here. Might want to handle that situation by retaining the coalesce for now. So besides that issue, what else do we miss by doing the simple thing and rely on case simplification? <|endcomment|>  * include at least one of them, even if that means adding terms * A special case occurs if the resulting rules remove all * aggregate functions. If so, the rewrite must be done again to include * at least one aggregate, even if that aggregate won't ever be evaluated. * See IMPALA-5125. * * The simplifications are done here because they benefit from knowledge * of the semantics of COALESCE(), and are difficult to do once encoded * as a CASE statement. <|startfocus|> */ <|endfocus|> private Expr rewriteCoalesceFn(FunctionCallExpr expr) { CoalesceRewriteState state = expr.contains(Expr.isAggregatePredicate()) ? CoalesceRewriteState.AWAIT_AGGREGATE : CoalesceRewriteState.STOP_AT_LITERAL; List<Expr> revised = new ArrayList<>(); top: for (Expr childExpr : expr.getChildren()) { // Skip nulls. if (childExpr.isNullLiteral()) continue; // Stop after either first literal (no aggregates) // or first literal after an aggregate (if has aggregates). switch (state) {
<|startcomment|> nit: looks like there's still an extra '*' here. <|endcomment|>  // Negative values always get bytes as unit. // TODO: fix this behaviour if needed. assertEquals("-10B", PrintUtils.printBytesRoundedToMb(-10L)); assertEquals("-123456789B", PrintUtils.printBytesRoundedToMb(-123456789L)); } /** * Wrap length for testWrapText() - less than 80 to make test layout nicer. */ private static final int WRAP_LENGTH = 60; /** * Test for PrintUtils.wrapString(). <|startfocus|> **/ <|endfocus|> @Test public void testWrapText() { // Simple query wrapping. assertWrap( "Analyzed query: SELECT * FROM functional_kudu.alltypestiny WHERE CAST(bigint_col" + " AS DOUBLE) < CAST(10 AS DOUBLE)", "Analyzed query: SELECT * FROM functional_kudu.alltypestiny\n" + "WHERE CAST(bigint_col AS DOUBLE) < CAST(10 AS DOUBLE)"); // Simple query with a hint retains newlines surrounding hint. assertWrap("SELECT \n" + "-- +straight_join\n" + " * FROM tpch_parquet.orders INNER JOIN \n"
<|startcomment|> here and at many other functions: in Impala we generally do not add an empty line at the beginning of functions. <|endcomment|>  "Expr '%s' in select list returns a complex type '%s'.\n" + "Only scalar types are allowed in the select list.", expr.toSql(), expr.getType().toSql())); } <|startfocus|> if (!expr.getType().isSupported() || expr.getType().isInvalid()) { <|endfocus|> throw new AnalysisException("Unsupported type '" + expr.getType().toSql() + "' in '" + expr.toSql() + "'."); } } if (TreeNode.contains(resultExprs_, AnalyticExpr.class)) { if (fromClause_.isEmpty()) { throw new AnalysisException("Analytic expressions require FROM clause."); } // do this here, not after analyzeAggregation(), otherwise the AnalyticExprs // will get substituted away if (selectList_.isDistinct()) { throw new AnalysisException( "cannot combine SELECT DISTINCT with analytic functions"); } } if (whereClause_ != null) { whereClause_.analyze(analyzer); if (whereClause_.contains(Expr.isAggregatePredicate())) {
<|startcomment|> IS_LITERAL? <|endcomment|>  public static ExprRewriteRule INSTANCE = new FoldConstantsRule(); @Override public Expr apply(Expr expr, Analyzer analyzer) throws AnalysisException { // Avoid calling Expr.isConstant() because that would lead to repeated traversals // of the Expr tree. Assumes the bottom-up application of this rule. Constant // children should have been folded at this point. <|startfocus|> for (Expr child: expr.getChildren()) if (!child.isLiteral()) return expr; if (expr.isLiteral() || !expr.isConstant()) return expr; <|endfocus|> // Do not constant fold cast(null as dataType) because we cannot preserve the // cast-to-types and that can lead to query failures, e.g., CTAS if (expr instanceof CastExpr) { CastExpr castExpr = (CastExpr) expr; if (castExpr.getChild(0) instanceof NullLiteral) { return expr; } } // Analyze constant exprs, if necessary. Note that the 'expr' may become non-constant // after analysis (e.g., aggregate functions). if (!expr.isAnalyzed()) {
<|startcomment|> line too long (94 > 90) <|endcomment|>  public static String getPartitionKeyValueString(LiteralExpr literalValue, String nullPartitionKeyValue) { Preconditions.checkNotNull(literalValue); <|startfocus|> if (Expr.IS_NULL_LITERAL.apply(literalValue) || literalValue.getStringValue().isEmpty()) { <|endfocus|> return nullPartitionKeyValue; } return literalValue.getStringValue();
<|startcomment|> line too long (94 > 90) <|endcomment|>  public void testUpdateCatalog() { withAllPrincipalTypes(ctx -> { String principalName = String.format("%s_update", PRINCIPAL_NAME_PREFIX); addCatalogPrincipalPrivileges(ctx.type_, ctx.catalog_, principalName, "functional"); <|startfocus|> addSentryPrincipalPrivileges(ctx.type_, ctx.sentryService_, principalName, "functional", "functional_kudu"); <|endfocus|> SentryProxy.refreshSentryAuthorization(ctx.catalog_, ctx.sentryService_, USER, false); checkCatalogPrincipalPrivileges(ctx.type_, ctx.catalog_, principalName, "server=server1->db=functional->grantoption=false", "server=server1->db=functional_kudu->grantoption=false"); });
<|startcomment|> simpler? String principalName = catalogObject.getPrincipal().getPrincipal_name(); if (catalogObject.getPrincipal().getPrincipal_type() == TPrincipalType.ROLE) { principalName = principalName.toLowerCase(); } <|endcomment|>  switch (catalogObject.getType()) { case DATABASE: return "DATABASE:" + catalogObject.getDb().getDb_name().toLowerCase(); case TABLE: case VIEW: TTable tbl = catalogObject.getTable(); return "TABLE:" + tbl.getDb_name().toLowerCase() + "." + tbl.getTbl_name().toLowerCase(); case FUNCTION: return "FUNCTION:" + catalogObject.getFn().getName() + "(" + catalogObject.getFn().getSignature() + ")"; <|startfocus|> case ROLE: return "ROLE:" + catalogObject.getRole().getRole_name().toLowerCase(); <|endfocus|> case PRIVILEGE: return "PRIVILEGE:" + catalogObject.getPrivilege().getPrivilege_name().toLowerCase() + "." + Integer.toString(catalogObject.getPrivilege().getRole_id()); case HDFS_CACHE_POOL: return "HDFS_CACHE_POOL:" + catalogObject.getCache_pool().getPool_name().toLowerCase(); case DATA_SOURCE: return "DATA_SOURCE:" + catalogObject.getData_source().getName().toLowerCase(); default:
<|startcomment|> why is getUniqueName not used here? if it can't be, this looks ripe for factoring. <|endcomment|>  return "TABLE:" + tbl.getDb_name().toLowerCase() + "." + tbl.getTbl_name().toLowerCase(); case FUNCTION: return "FUNCTION:" + catalogObject.getFn().getName() + "(" + catalogObject.getFn().getSignature() + ")"; case ROLE: return "ROLE:" + catalogObject.getRole().getRole_name().toLowerCase(); case PRIVILEGE: return "PRIVILEGE:" + <|startfocus|> catalogObject.getPrivilege().getPrivilege_name().toLowerCase() + "." + Integer.toString(catalogObject.getPrivilege().getRole_id()); <|endfocus|> case HDFS_CACHE_POOL: return "HDFS_CACHE_POOL:" + catalogObject.getCache_pool().getPool_name().toLowerCase(); case DATA_SOURCE: return "DATA_SOURCE:" + catalogObject.getData_source().getName().toLowerCase(); default: throw new IllegalStateException( "Unsupported catalog object type: " + catalogObject.getType()); }
<|startcomment|> nit: unnecessary/inconsistent vertical whitespace <|endcomment|>  for (SlotDescriptor d: slotsBySize.get(slotSize)) { Preconditions.checkState(d.isMaterialized()); d.setByteSize(slotSize); d.setByteOffset(slotOffset); d.setSlotIdx(slotIdx++); slotOffset += slotSize; // assign null indicator if (d.getIsNullable()) { d.setNullIndicatorByte(nullIndicatorByte); d.setNullIndicatorBit(nullIndicatorBit); nullIndicatorBit = (nullIndicatorBit + 1) % 8; if (nullIndicatorBit == 0) ++nullIndicatorByte; <|startfocus|> } else { // non-nullable slots will have 0 for the byte offset and -1 for the bit mask <|endfocus|> d.setNullIndicatorBit(-1); d.setNullIndicatorByte(0); } } } Preconditions.checkState(slotOffset == totalSlotSize); byteSize_ = totalSlotSize + numNullBytes_;
<|startcomment|> A common practice in Java is to include the enum definition in the interface file if the enum is used only by the interface (and its implementations). <|endcomment|> // specific language governing permissions and limitations // under the License. package org.apache.impala.analysis; import org.apache.impala.common.AnalysisException; public interface ParseNode { /** * Perform semantic analysis of node and all of its children. * Throws exception if any semantic errors were found. */ void analyze(Analyzer analyzer) throws AnalysisException; /** * Returns the SQL string corresponding to this node and its descendants. */ <|startfocus|> String toSql(ToSqlOptions options); <|endfocus|> } 
<|startcomment|> I don't see the reason for replacing TreeNode<NodeType> with TreeNode<?>., especially if TreeNode should always be of NodeType type. Using ? makes the type system weaker. <|endcomment|>  public List<NodeType> getChildren() { return children_; } /** * Return list of all nodes of the tree rooted at 'this', obtained * through pre-order traversal. * * Warning: this method is unsafe: it returns a list of nodes * of the requested type, but does not verify that the actual * nodes are indeed of that type. */ <|startfocus|> @SuppressWarnings("unchecked") public <C extends TreeNode<?>> List<C> getNodesPreOrder() { List<TreeNode<?>> result = new ArrayList<>(); <|endfocus|> getNodesPreOrderAux(result); return (List<C>) result; } protected void getNodesPreOrderAux(List<TreeNode<?>> result) { result.add(this); for (NodeType child: children_) child.getNodesPreOrderAux(result); } /** * Return list of all nodes of the tree rooted at 'this', obtained * through post-order traversal. * * Warning: this method is unsafe: it returns a list of nodes
<|startcomment|> this should be Class<C> <|endcomment|>  } for (NodeType child: children_) child.collect(predicate, matches); } /** * Add all nodes in the tree that are of class 'cl' to the list 'matches'. * This node is checked first, followed by its children in order. If the node * itself is of class 'cl', the children are skipped. */ @SuppressWarnings("unchecked") public <C extends TreeNode<NodeType>, D extends C> void collect( <|startfocus|> Class<?> cl, Collection<D> matches) { <|endfocus|> if (cl.equals(getClass())) { matches.add((D) this); return; } for (NodeType child: children_) child.collect(cl, matches); } /** * Add all nodes in the tree that satisfy 'predicate' to the list 'matches' * This node is checked first, followed by its children in order. All nodes * that match in the subtree are added. */ @SuppressWarnings("unchecked") public <C extends TreeNode<NodeType>, D extends C> void collectAll(
<|startcomment|> this should be Class<C> <|endcomment|>  public static <C extends TreeNode<C>, D extends C> void collect( Collection<C> nodeList, Predicate<? super C> predicate, Collection<D> matches) { for (C node: nodeList) node.collect(predicate, matches); } /** * For each expression in 'nodeList', collect all subexpressions of class 'cl' * into 'matches' */ public static <C extends TreeNode<C>, D extends C> void collect( <|startfocus|> Collection<C> nodeList, Class<?> cl, Collection<D> matches) { <|endfocus|> for (C node: nodeList) node.collect(cl, matches); } /** * Return true if this node or any of its children satisfy 'predicate'. */ @SuppressWarnings("unchecked") public <C extends TreeNode<NodeType>> boolean contains( Predicate<? super C> predicate) { if (predicate.apply((C) this)) return true; for (NodeType child: children_) if (child.contains(predicate)) return true; return false; } /**
<|startcomment|> this should be public <C extends TreeNode<NodeType>> boolean contains(Class<C> cl) <|endcomment|> <|startfocus|> public boolean contains(Class<?> cl) { <|endfocus|> if (cl.equals(getClass())) return true; for (NodeType child: children_) if (child.contains(cl)) return true; return false;
<|startcomment|> this should be Class<C> <|endcomment|>  public static <C extends TreeNode<C>> boolean contains( <|startfocus|> List<C> nodeList, Class<?> cl) { <|endfocus|> for (C node: nodeList) if (node.contains(cl)) return true; return false;
<|startcomment|> What happens when there is no "logical type" in a Parquet file, but only "converted type"? <|endcomment|>  } return new ArrayType(convertParquetType(innerGroup.getType(0))); } /** * Converts a "logical" Parquet type to an Impala column type. * A Parquet type is considered logical when it has an annotation. The annotation is * stored as a "OriginalType". The Parquet documentation refers to these as logical * types, so we use that terminology here. */ private static Type convertLogicalParquetType( <|startfocus|> org.apache.parquet.schema.Type parquetType) throws AnalysisException { <|endfocus|> LogicalTypeAnnotation logicalType = parquetType.getLogicalTypeAnnotation(); if (logicalType instanceof ListLogicalTypeAnnotation) { return convertArray(parquetType.asGroupType()); } if (logicalType instanceof MapLogicalTypeAnnotation || logicalType instanceof MapKeyValueTypeAnnotation) { // MAP_KEY_VALUE annotation should not be used any more. However, according to the // Parquet spec, some existing data incorrectly uses MAP_KEY_VALUE in place of MAP. // For backward-compatibility, a group annotated with MAP_KEY_VALUE that is not
<|startcomment|> I find overloads harder to follow when they have different visibility and such and would call this toThriftInternal(), but I don't feel strongly about it. <|endcomment|>  * Construct a thrift representation of the sink. */ protected final TDataSink toThrift() { TDataSink tsink = new TDataSink(getSinkType()); tsink.setLabel(fragment_.getId() + ":" + getLabel()); TExecStats estimatedStats = new TExecStats(); estimatedStats.setMemory_used(resourceProfile_.getMemEstimateBytes()); tsink.setEstimated_stats(estimatedStats); toThrift(tsink); return tsink; } /** * Add subclass-specific information to the sink. */ <|startfocus|> abstract protected void toThrift(TDataSink tsink); <|endfocus|> /** * Get the sink type of the subclass. */ abstract protected TDataSinkType getSinkType(); public void setFragment(PlanFragment fragment) { fragment_ = fragment; } public PlanFragment getFragment() { return fragment_; } public ResourceProfile getResourceProfile() { return resourceProfile_; } /** * Compute the resource profile for an instance of this DataSink. */ public abstract void computeResourceProfile(TQueryOptions queryOptions); } 
<|startcomment|> line too long (108 > 90) <|endcomment|>  public void testScalarFunctionSql() { { // Can't generate SQL for an unresolved function List<Type> args = new ArrayList<>(); <|startfocus|> Function fn = Function.createFunction("mydb", "fn1", args, Type.INT, false, TFunctionBinaryType.JAVA); <|endfocus|> try { ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); } catch (UnsupportedOperationException e) { // Expected } } { // Java function, leave off location and symbol List<Type> args = new ArrayList<>(); Function fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n"; assertEquals(expected, sql); } { // Java function, with location and symbol List<Type> args = new ArrayList<>();
<|startcomment|> line too long (95 > 90) <|endcomment|>  Function fn = Function.createFunction("mydb", "fn1", args, Type.INT, false, TFunctionBinaryType.JAVA); try { ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); } catch (UnsupportedOperationException e) { // Expected } } { // Java function, leave off location and symbol List<Type> args = new ArrayList<>(); <|startfocus|> Function fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); <|endfocus|> fn.setBinaryType(TFunctionBinaryType.JAVA); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n"; assertEquals(expected, sql); } { // Java function, with location and symbol List<Type> args = new ArrayList<>(); ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); fn.setBinaryType(TFunctionBinaryType.JAVA); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar"));
<|startcomment|> line too long (101 > 90) <|endcomment|>  fn.setBinaryType(TFunctionBinaryType.JAVA); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n"; assertEquals(expected, sql); } { // Java function, with location and symbol List<Type> args = new ArrayList<>(); <|startfocus|> ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); <|endfocus|> fn.setBinaryType(TFunctionBinaryType.JAVA); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn.setSymbolName("MyClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql); } { // Java function, with location and symbol List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN);
<|startcomment|> line too long (101 > 90) <|endcomment|>  String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql); } { // Java function, with location and symbol List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN); <|startfocus|> ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); <|endfocus|> fn.setBinaryType(TFunctionBinaryType.JAVA); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn.setSymbolName("MyClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql); } { // C++ function, with location and symbol
<|startcomment|> line too long (101 > 90) <|endcomment|>  String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass'\n"; assertEquals(expected, sql); } { // C++ function, with location and symbol List<Type> args = new ArrayList<>(); <|startfocus|> ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); <|endfocus|> fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setSymbolName("myClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1()\n" + " RETURNS INT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " SYMBOL='myClass'\n"; assertEquals(expected, sql); } { // C++ function, with location and symbol
<|startcomment|> line too long (101 > 90) <|endcomment|>  String expected = "CREATE FUNCTION mydb.fn1()\n" + " RETURNS INT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " SYMBOL='myClass'\n"; assertEquals(expected, sql); } { // C++ function, with location and symbol List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN); <|startfocus|> ScalarFunction fn = new ScalarFunction(new FunctionName("mydb", "fn1"), args, Type.INT, false); <|endfocus|> fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setSymbolName("myClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE FUNCTION mydb.fn1(VARCHAR(*), BOOLEAN)\n" + " RETURNS INT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " SYMBOL='myClass'\n"; assertEquals(expected, sql); }
<|startcomment|> line too long (110 > 90) <|endcomment|>  public void testAggFnSql() { { // C++ aggregate function, with minimum state List<Type> args = Lists.newArrayList(Type.INT, Type.BOOLEAN); <|startfocus|> AggregateFunction fn = new AggregateFunction(new FunctionName("mydb", "fn1"), args, Type.BIGINT, false); <|endfocus|> fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setUpdateFnSymbol("Update"); fn.setInitFnSymbol("Init"); fn.setMergeFnSymbol("Merge"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE AGGREGATE FUNCTION mydb.fn1(INT, BOOLEAN)\n" + " RETURNS BIGINT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " UPDATE_FN='Update'\n" + " INIT_FN='Init'\n" + " MERGE_FN='Merge'\n"; assertEquals(expected, sql); } { // C++ aggregate function, with full state
<|startcomment|> line too long (110 > 90) <|endcomment|>  " RETURNS BIGINT\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.so'\n" + " UPDATE_FN='Update'\n" + " INIT_FN='Init'\n" + " MERGE_FN='Merge'\n"; assertEquals(expected, sql); } { // C++ aggregate function, with full state List<Type> args = Lists.newArrayList(Type.INT, Type.BOOLEAN); <|startfocus|> AggregateFunction fn = new AggregateFunction(new FunctionName("mydb", "fn1"), args, Type.BIGINT, false); <|endfocus|> fn.setBinaryType(TFunctionBinaryType.NATIVE); fn.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn.setUpdateFnSymbol("Update"); fn.setInitFnSymbol("Init"); fn.setMergeFnSymbol("Merge"); fn.setFinalizeFnSymbol("Finalize"); fn.setSerializeFnSymbol("Serialize"); fn.setIntermediateType(Type.INT); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn)); String expected = "CREATE AGGREGATE FUNCTION mydb.fn1(INT, BOOLEAN)\n" + " RETURNS BIGINT\n" +
<|startcomment|> line too long (115 > 90) <|endcomment|>  public void testCreateFunctionSql() { { // Two functions, one C++, one Java <|startfocus|> ScalarFunction fn1 = new ScalarFunction(new FunctionName("mydb", "fn1"), new ArrayList<>(), Type.INT, false); <|endfocus|> fn1.setBinaryType(TFunctionBinaryType.JAVA); fn1.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn1.setSymbolName("MyClass"); List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN); ScalarFunction fn2 = new ScalarFunction(new FunctionName("mydb", "fn2"), args, Type.INT, false); fn2.setBinaryType(TFunctionBinaryType.NATIVE); fn2.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn2.setSymbolName("myClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn1, fn2)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass';\n" +
<|startcomment|> line too long (102 > 90) <|endcomment|>  ScalarFunction fn1 = new ScalarFunction(new FunctionName("mydb", "fn1"), new ArrayList<>(), Type.INT, false); fn1.setBinaryType(TFunctionBinaryType.JAVA); fn1.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.jar")); fn1.setSymbolName("MyClass"); List<Type> args = Lists.newArrayList(Type.VARCHAR, Type.BOOLEAN); <|startfocus|> ScalarFunction fn2 = new ScalarFunction(new FunctionName("mydb", "fn2"), args, Type.INT, false); <|endfocus|> fn2.setBinaryType(TFunctionBinaryType.NATIVE); fn2.setLocation(new HdfsUri("hdfs://foo:123/fns/myfunc.so")); fn2.setSymbolName("myClass"); String sql = ToSqlUtils.getCreateFunctionSql(Lists.newArrayList(fn1, fn2)); String expected = "CREATE FUNCTION mydb.fn1\n" + " LOCATION 'hdfs://foo:123/fns/myfunc.jar'\n" + " SYMBOL='MyClass';\n" + "CREATE FUNCTION mydb.fn2(VARCHAR(*), BOOLEAN)\n" + " RETURNS INT\n" +
<|startcomment|> Nit: RetryRule() <|endcomment|> <|startfocus|> public RetryRule () { <|endfocus|> this(Integer.getInteger("rerunFailingTestsCount", 0));
<|startcomment|> Package private is stricter and sufficient, I think. <|endcomment|> <|startfocus|> protected RetryRule(int retryCount) { <|endfocus|> this.retryCount = retryCount;
<|startcomment|> nit: I think attempt++ makes the most sense here given there is no need to return the original attempt value before incrementing. <|endcomment|>  return new RetryStatement(base, description, retryCount); } private static class RetryStatement extends Statement { private final Statement base; private final Description description; private final int retryCount; RetryStatement(Statement base, Description description, int retryCount) { this.base = base; this.description = description; this.retryCount = retryCount; } @Override public void evaluate() throws Throwable { Throwable lastException; int attempt = 0; do { <|startfocus|> ++attempt; <|endfocus|> try { base.evaluate(); return; } catch (Throwable t) { // To retry, we catch the exception from evaluate(), log an error, and loop. // We retain and rethrow the last failure if all attempts fail. lastException = t; LOG.error("{}: failed attempt {}", description.getDisplayName(), attempt, t); } } while (attempt <= retryCount); LOG.error("{}: giving up after {} attempts", description.getDisplayName(), attempt); throw lastException; } } } 
<|startcomment|> Maybe use String.format()? "" + ... is a little weird. <|endcomment|>  public void testRetry() { if (failures < MAX_FAILURES) { failures++; <|startfocus|> assertFalse("" + failures + " failures", true); <|endfocus|> } // Fall through and pass the test on the final retry.
<|startcomment|> Could you rename it to BLANK, as per RFC? It does not call this mode automatic. <|endcomment|>  * limitations under the License. */ package com.couchbase.client.core.env; public enum NetworkResolution { /** * Pick whatever the server returns in the config, this is the * old and backwards compatible mode (server default). */ DEFAULT, /** * Based on heuristics discovers if internal or * external resolution will be used. * * This is the default setting (not to be confused with * the default mode)! */ <|startfocus|> AUTOMATIC, <|endfocus|> /** * Pins it to external resolution. */ EXTERNAL } 
<|startcomment|> NIT: with JUnit the expected value comes first, followed by the actual value. (Looks like this test failed on Jenkins with count of -2) <|endcomment|>  OpenBucketRequest request; if (ClusterDependentTest.minClusterVersion()[0] >= 5) { request = new OpenBucketRequest(TestProperties.bucket(), TestProperties.adminUser(), TestProperties.adminPassword()); } else { request = new OpenBucketRequest(TestProperties.bucket(), TestProperties.username(), TestProperties.password()); } core.send(request).toBlocking().single(); BackpressureException exception = RingBufferMonitor.instance().createException(); <|startfocus|> assertEquals(exception.diagostics().totalCount(), 0); <|endfocus|> core.send(new CloseBucketRequest(TestProperties.bucket())).toBlocking().single(); } } 
<|startcomment|> I think you should override the toString here to include the diagnostics if available, so we have it in the logs. <|endcomment|>  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.core; import com.couchbase.client.core.tracing.RingBufferDiagnostics; /** * Identifies the need to back off on the supplier side when using a service, because the consumer is overloaded. * * @author Michael Nitschinger * @since 1.0 */ <|startfocus|> public class BackpressureException extends CouchbaseException { <|endfocus|> public BackpressureException() {} public BackpressureException(RingBufferDiagnostics diagnostics) { this.diagnostics = diagnostics; } /** * Returns a {@link RingBufferDiagnostics} which, if non-null, gives a granular breakdown of the contents of the * ringbuffer at the time of this exception */ public RingBufferDiagnostics getRingBufferDiagnostics() { return diagnostics; } private RingBufferDiagnostics diagnostics; } 
<|startcomment|> an you remove the get? we've been following the "fluent" style in general. .. also might be able to just use diagnostics() here? <|endcomment|> <|startfocus|> public RingBufferDiagnostics getRingBufferDiagnostics() { <|endfocus|> return diagnostics;
<|startcomment|> nit: you are getting the instance twice in the same codepath / hot code path .. might make sense to store it in a local variable <|endcomment|>  requestDisruptor.start(); requestRingBuffer = requestDisruptor.getRingBuffer(); } @Override @SuppressWarnings("unchecked") public <R extends CouchbaseResponse> Observable<R> send(CouchbaseRequest request) { if (request instanceof InternalRequest) { handleInternalRequest(request); return (Observable<R>) request.observable().observeOn(environment.scheduler()); } else if (request instanceof ClusterRequest) { handleClusterRequest(request); return (Observable<R>) request.observable().observeOn(environment.scheduler()); } else { <|startfocus|> RingBufferMonitor.getInstance().addRequest(request); <|endfocus|> if (coreSendHook == null) { boolean published = requestRingBuffer.tryPublishEvent(REQUEST_TRANSLATOR, request); if (!published) { request.observable().onError(RingBufferMonitor.getInstance().createException()); } return (Observable<R>) request.observable(); } else { Subject<CouchbaseResponse, CouchbaseResponse> response = request.observable(); Tuple2<CouchbaseRequest, Observable<CouchbaseResponse>> hook = coreSendHook .beforeSend(request, response); boolean published = requestRingBuffer.tryPublishEvent(REQUEST_TRANSLATOR, hook.value1()); if (!published) {
<|startcomment|> did you consider switching to the static init block as discussed on hipchat a while ago? <|endcomment|> <|startfocus|> public static RingBufferMonitor getInstance() { if (instance == null) { synchronized (RingBufferMonitor.class) { if (instance == null) { instance = new RingBufferMonitor(); } } } <|endfocus|> return instance;
<|startcomment|> . BinaryRequest == KeyValueRequest, I messed up at one point and renamed one but not the other <|endcomment|>  private AtomicInteger getOrAddCount(CouchbaseRequest request) { // instanceof is used instead of a more generic Map-based solution purely to provide lock-free performance <|startfocus|> if (request instanceof AbstractKeyValueRequest) { return countKeyValue; } else if (request instanceof GenericQueryRequest) { <|endfocus|> return countQuery; } else if (request instanceof ClusterRequest) { return countCluster; } else if (request instanceof ConfigRequest) { return countConfig; } else if (request instanceof InternalRequest) { return countInternal; } else if (request instanceof BinaryRequest) { return countBinary; } else if (request instanceof SearchRequest) { return countSearch; } else if (request instanceof ViewRequest) { return countView; } else if (request instanceof AnalyticsRequest) { return countAnalytics; } else { return countOther; }
<|startcomment|> can we do lazy initialization on this hashmap? since we now allocate an empty hash map for every object even if we'll never need it <|endcomment|>  */ private EncryptionConfig encryptionConfig; /** * Encryption prefix */ public static final String ENCRYPTION_PREFIX = "__encrypt_"; /** * Private constructor to create the object. * * The internal map is initialized with the default capacity. */ private JsonObject() { content = new HashMap<String, Object>(); encryptionPathInfo = new HashMap<String, EncryptionInfo>(); } /** * Private constructor to create the object with a custom initial capacity. */ private JsonObject(int initialCapacity) { content = new HashMap<String, Object>(initialCapacity); <|startfocus|> encryptionPathInfo = new HashMap<String, EncryptionInfo>(); <|endfocus|> } /** * Creates a empty {@link JsonObject}. * * @return a empty {@link JsonObject}. */ public static JsonObject empty() { return new JsonObject(); } /** * Creates a empty {@link JsonObject}. * * @return a empty {@link JsonObject}. */
<|startcomment|> should this say cryptoManager= ? <|endcomment|>  sb.append(", viewTimeout=").append(this.viewTimeout); sb.append(", searchTimeout=").append(this.searchTimeout); sb.append(", analyticsTimeout=").append(this.analyticsTimeout); sb.append(", kvTimeout=").append(this.kvTimeout); sb.append(", connectTimeout=").append(this.connectTimeout); sb.append(", dnsSrvEnabled=").append(this.dnsSrvEnabled); if (this.cryptoManager() != null) { <|startfocus|> sb.append(", encryptionConfig=").append(this.cryptoManager.toString()); <|endfocus|> } return sb;
<|startcomment|> I think this needs to be volatile now, right? <|endcomment|>  * allow to store such objects which can be represented by JSON. * * @author Michael Nitschinger * @author Simon Baslé * @since 2.0 */ public class JsonObject extends JsonValue implements Serializable { private static final long serialVersionUID = 8817717605659870262L; /** * The backing {@link Map} for the object. */ private final Map<String, Object> content; /** * Encryption meta information for the Json values */ <|startfocus|> private final Map<String, String> encryptionPathInfo; <|endfocus|> /** * Configuration for decryption, set using the environment */ private EncryptionConfig encryptionConfig; /** * Encryption prefix */ public static final String ENCRYPTION_PREFIX = "__encrypt_"; /** * Private constructor to create the object. * * The internal map is initialized with the default capacity. */ private JsonObject() { content = new HashMap<String, Object>(); encryptionPathInfo = new HashMap<String, String>(); } /**
<|startcomment|> this too? if set from one thread and consumed from another... <|endcomment|>  * @author Simon Baslé * @since 2.0 */ public class JsonObject extends JsonValue implements Serializable { private static final long serialVersionUID = 8817717605659870262L; /** * The backing {@link Map} for the object. */ private final Map<String, Object> content; /** * Encryption meta information for the Json values */ private final Map<String, String> encryptionPathInfo; /** * Configuration for decryption, set using the environment */ <|startfocus|> private EncryptionConfig encryptionConfig; <|endfocus|> /** * Encryption prefix */ public static final String ENCRYPTION_PREFIX = "__encrypt_"; /** * Private constructor to create the object. * * The internal map is initialized with the default capacity. */ private JsonObject() { content = new HashMap<String, Object>(); encryptionPathInfo = new HashMap<String, String>(); } /** * Private constructor to create the object with a custom initial capacity. */ private JsonObject(int initialCapacity) {
<|startcomment|> This could be a CryptoProviderMissingPublicKeyException <|endcomment|>  /** * Decrypt value if the name starts with "__encrypt_" */ private Object decrypt(JsonObject object, String providerName) throws Exception { Object decrypted; String key = object.getString("kid"); String alg = object.getString("alg"); CryptoProvider provider = this.cryptoManager.getProvider(providerName); if (!provider.checkAlgorithmNameMatch(alg)) { <|startfocus|> throw new CryptoProviderDecryptFailedException("The decryption of the field failed for the alias: " + providerName + "(Crypto provider algorithm name mismatch)"); <|endfocus|> } if (!key.contentEquals(provider.getKeyStoreProvider().publicKeyName())) { throw new CryptoProviderDecryptFailedException("The decryption of the field failed for the alias: " + providerName + "(Public key mismatch)"); } byte[] encryptedBytes; String encryptedValueWithConfig; if (object.containsKey("iv")) { encryptedValueWithConfig = object.getString("kid") + object.getString("alg") + object.getString("iv") + object.getString("ciphertext"); 
<|startcomment|> This should be a CryptoProviderSigningFailedException. <|endcomment|>  + object.getString("ciphertext"); encryptedBytes = Base64.decode(object.getString("ciphertext")); } if (object.containsKey("sig")) { byte[] signature = Base64.decode(object.getString("sig")); if (!provider.verifySignature(encryptedValueWithConfig.getBytes(), signature)) { <|startfocus|> throw new CryptoProviderDecryptFailedException("The decryption of the field failed for the alias: " + providerName + " (Signature check for data integrity failed)"); <|endfocus|> } } byte[] decryptedBytes = provider.decrypt(encryptedBytes); String decryptedString = new String(decryptedBytes, Charset.forName("UTF-8")); decrypted = JacksonTransformers.MAPPER.readValue(decryptedString, Object.class); if (decrypted instanceof Map) { decrypted = JsonObject.from((Map<String, ?>) decrypted); } else if (decrypted instanceof List) { decrypted = JsonArray.from((List<?>) decrypted); } return decrypted; } /** * Retrieves the (potential null) content and not casting its type. * * @param name the key of the field.
<|startcomment|> Not here? <|endcomment|>  public String toString() { return "DefaultPortInfo{" + "ports=" + ports + ", sslPorts=" + sslPorts <|startfocus|> + ", hostname='" + hostname <|endfocus|> + '\'' + '}';
<|startcomment|> requires not null <|endcomment|>  public Credentials(String username, String password) { <|startfocus|> this.username = username; this.password = password; <|endfocus|>
<|startcomment|> remove <|endcomment|>  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.dcp; import java.net.InetSocketAddress; public interface CredentialsProvider { /** * Get the username/password pair to use for authentication/authorization * * @param address * @return credentials */ <|startfocus|> Credentials get(InetSocketAddress address) throws RuntimeException; <|endfocus|> } 
<|startcomment|> remove <|endcomment|>  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.dcp; import java.net.InetSocketAddress; public class StaticCredentialsProvider implements CredentialsProvider { private final Credentials credentials; public StaticCredentialsProvider(String username, String password) { credentials = new Credentials(username, password); } @Override <|startfocus|> public Credentials get(InetSocketAddress address) throws RuntimeException { <|endfocus|> return credentials; } } 
<|startcomment|> pass credentials from outside <|endcomment|>  */ private SaslClient saslClient; /** * Stores the selected SASL mechanism in the process. */ private String selectedMechanism; /** * Creates a new auth handler. * * @param address user/bucket name. * @param environment password of the user/bucket. */ <|startfocus|> AuthHandler(final InetSocketAddress address, final ClientEnvironment environment) { Credentials credentials = environment.credentialsProvider().get(address); this.username = credentials.getUsername(); this.password = credentials.getPassword(); <|endfocus|> } /** * Once the channel is active, start the SASL auth negotiation. */ @Override public void channelActive(final ChannelHandlerContext ctx) throws Exception { ByteBuf request = ctx.alloc().buffer(); SaslListMechsRequest.init(request); ctx.writeAndFlush(request); } /** * Every time we recieve a message as part of the negotiation process, handle * it according to the req/res process. */ @Override protected void channelRead0(final ChannelHandlerContext ctx, final ByteBuf msg) throws Exception {
<|startcomment|> NIT: Is this javadoc complete? <|endcomment|>  private String clientContextId; private Map<String, Object> rawParams; private boolean pretty; /** * We are exposing this as a boolean, but internally the server <|startfocus|> * wants it as int. To be forwards compatible <|endfocus|> */ private int priority; private AnalyticsParams() { pretty = false; priority = 0;
<|startcomment|> `priority` argument is ignored. Is that intentional, or did you mean: return priority(priority ? -1 : 0) <|endcomment|>  public AnalyticsParams priority(boolean priority) { <|startfocus|> return priority(-1); <|endfocus|>
<|startcomment|> NIT: Can priority be > 0 in the future? <|endcomment|>  public String toString() { return "AnalyticsParams{" + "serverSideTimeout='" + serverSideTimeout + '\'' + ", clientContextId='" + clientContextId + '\'' + ", rawParams=" + rawParams + ", pretty=" + pretty + <|startfocus|> ", priority=" + (priority != 0 ? "true" : "false") + <|endfocus|> '}';
<|startcomment|> does it make sense to add an index out of bounds safety catch block with a fallback or so? <|endcomment|>  } public static void setOpaque(int opaque, ByteBuf buffer) { buffer.setInt(OPAQUE_OFFSET, opaque); } public static int getOpaque(ByteBuf buffer) { return buffer.getInt(OPAQUE_OFFSET); } public static long getCas(ByteBuf buffer) { return buffer.getLong(CAS_OFFSET); } private static String formatOpcode(byte opcode) { <|startfocus|> String name = OPCODE_NAMES[0xff & opcode]; return String.format("0x%02x (%s)", opcode, name == null ? "?" : name); <|endfocus|> } private static String formatMagic(byte magic) { String name = magic == MAGIC_REQ ? "REQUEST" : (magic == MAGIC_RES) ? "RESPONSE" : "?"; return String.format("0x%02x (%s)", magic, name); } } 
<|startcomment|> you could follow a similar approach right now we do in the sdks. If trace enabled on the log level, include this handler by default. So it is very easy to enable/disable at runtime with just logger settings. <|endcomment|>  } DcpControl control = environment.dcpControl(); Credentials credentials = environment.credentialsProvider().get((InetSocketAddress) ch.remoteAddress()); pipeline.addLast(new AuthHandler(credentials.getUsername(), credentials.getPassword())) .addLast(new DcpConnectHandler(environment.connectionNameGenerator(), environment.bucket(), control)) .addLast(new DcpControlHandler(control)); if (control.noopEnabled()) { pipeline.addLast(new IdleStateHandler(2 * control.noopIntervalSeconds(), 0, 0)); } <|startfocus|> //pipeline.addLast(new DcpLoggingHandler(LogLevel.DEBUG)); <|endfocus|> DcpMessageHandler messageHandler = new DcpMessageHandler(ch, environment, controlHandler); pipeline.addLast(messageHandler); if (environment.persistencePollingEnabled()) { pipeline.addLast(new PersistencePollingHandler(environment, configProvider, messageHandler)); } } } 
<|startcomment|> Debug line. <|endcomment|>  public void shouldSerializeEjectionMethod() { BucketSettings settings = DefaultBucketSettings.builder() .ejectionMethod(EjectionMethod.FULL) .build(); DefaultAsyncClusterManager clusterManager = new DefaultAsyncClusterManager("login", "password", null, null, null); String payload = clusterManager.getConfigureBucketPayload(settings, false); <|startfocus|> System.err.println(payload); <|endfocus|> assertTrue(payload.contains("evictionPolicy=fullEviction"));
<|startcomment|> Are these `author` and `since` tags accurate? <|endcomment|>  * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.java.error; import com.couchbase.client.core.CouchbaseException; /** * An exception denoting that the search engine couldn't parse an FTS request. * * @author Simon Baslé * @since 2.3 */ <|startfocus|> public class FtsServerOverloadException extends CouchbaseException { <|endfocus|> public FtsServerOverloadException(String payload) { super("Search server is overloaded. Details: " + payload); } } 
<|startcomment|> Does it make sense for this to extend `TemporaryFailureException` ? <|endcomment|>  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.java.error; import com.couchbase.client.core.CouchbaseException; /** * An exception denoting that the search engine couldn't parse an FTS request. * * @author Simon Baslé * @since 2.3 */ <|startfocus|> public class FtsServerOverloadException extends CouchbaseException { <|endfocus|> public FtsServerOverloadException(String payload) { super("Search server is overloaded. Details: " + payload); } } 
<|startcomment|> Should this be 9 or we would be retrying for actually a second? <|endcomment|>  return applyTimeout(core.<SearchQueryResponse>send(request), request, environment, timeout, timeUnit); } }) .flatMap(new Func1<SearchQueryResponse, Observable<SearchQueryResponse>>() { @Override public Observable<SearchQueryResponse> call(final SearchQueryResponse r) { if (shouldRetry(r.statusCode())) { return Observable.error(new RetryableException(r)); } return Observable.just(r); } }) .retryWhen(RetryBuilder .anyOf(RetryableException.class) .max(10) <|startfocus|> .delay(Delay.exponential(TimeUnit.MILLISECONDS, 500, 2)) <|endfocus|> .doOnRetry(new Action4<Integer, Throwable, Long, TimeUnit>() { @Override public void call(Integer attempt, Throwable error, Long delay, TimeUnit delayUnit) { LOGGER.debug("Retrying {} because of {} (attempt {}, delay {} {})", query.export(), error.getMessage(), attempt, delay, delayUnit); } }) .build() ) .map(new Func1<SearchQueryResponse, AsyncSearchQueryResult>() { @Override public AsyncSearchQueryResult call(final SearchQueryResponse response) {
<|startcomment|> Please use camelCase naming convention for fields, variables, and arguments. So this would be `clauseFields`. (Same in constructor argument below). <|endcomment|>  public N1qlWriter(N1qlMode mode, boolean createDocuments) { <|startfocus|> this.mode = mode; <|endfocus|> this.createDocuments = createDocuments;
<|startcomment|> Why not use use a min priority queue? It should allow duplicates. <|endcomment|>  * size is respected. * * @param spans the span list to work off of. * @param span the span to store. */ private void updateSpans(final List<ThresholdLogSpan> spans, final ThresholdLogSpan span) { spans.add(span); // We always need to keep the list properly sorted so that the highest // spans by duration are at the top Collections.sort(spans, Collections.<ThresholdLogSpan>reverseOrder()); while(spans.size() > sampleSize) { // Remove the element with the lowest duration, so we only keep // the highest ones consistently <|startfocus|> spans.remove(spans.size() - 1); <|endfocus|> } hasThresholdWritten = true; } } /** * This method is intended to be overridden in test implementations * to assert against the output. */ void logOverThreshold(final List<Map<String, Object>> toLog) { try { String result = pretty ? prettyWriter().writeValueAsString(toLog) : writer().writeValueAsString(toLog);
<|startcomment|> instead of using setFailure and optionally checking if it's not complete, I think we can switch to trySuccess and tryFailure which just return false if it's already completed. .. I've been experimenting with switching to try* instead of set* in some core-io 2.0 and had good success with it. <|endcomment|>  } @Override public void flush(ChannelHandlerContext ctx) throws Exception { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { if (originalPromise != null) { originalPromise.setFailure(cause); } ctx.fireExceptionCaught(cause); } @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception { if (evt instanceof HandshakeDeadlineEvent) { <|startfocus|> originalPromise().setFailure(new ConnectTimeoutException("Handshake did not complete before deadline.")); <|endfocus|> ctx.close(); return; } ctx.fireUserEventTriggered(evt); } @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception { if (!originalPromise().isDone()) { originalPromise().setFailure(new ConnectException("Channel became inactive before handshake completed.")); } ctx.fireChannelInactive(); } } 
<|startcomment|> tabs? <|endcomment|>  } @Override protected Tuple2<ByteBuf, Integer> doEncode(final JsonDocument document) throws Exception { addEncryption(document.content()); return Tuple.create(jsonObjectToByteBuf(document.content()), TranscoderUtils.JSON_COMPAT_FLAGS); } @Override protected JsonDocument doDecode(String id, ByteBuf content, long cas, int expiry, int flags, ResponseStatus status) throws Exception { if (!TranscoderUtils.hasJsonFlags(flags)) { throw new TranscodingException("Flags (0x" + Integer.toHexString(flags) + ") indicate non-JSON document for " + "id " + id + ", could not decode."); } <|startfocus|> JsonObject jsonObject = byteBufToJsonObject(content); jsonObject.setEncryptionConfig(encryptionConfig); return newDocument(id, expiry, jsonObject, cas); <|endfocus|> } @Override public JsonDocument newDocument(String id, int expiry, JsonObject content, long cas) { JsonDocument document = JsonDocument.create(id, expiry, content, cas); document.content().setEncryptionConfig(this.encryptionConfig); return document; } @Override
<|startcomment|> please use { } everywhere <|endcomment|>  public JsonDocument newDocument(String id, int expiry, JsonObject content, long cas) { JsonDocument document = JsonDocument.create(id, expiry, content, cas); <|startfocus|> document.content().setEncryptionConfig(this.encryptionConfig); <|endfocus|> return document;
<|startcomment|> Well this probably shouldn't be here. <|endcomment|>  JsonDocument doc = JsonDocument.create(id, data); Observable<JsonDocument> result; switch (opts.ingestMethod) { case INSERT: result = bucket.async().insert(doc); break; case UPSERT: result = bucket.async().upsert(doc); break; case REPLACE: result = bucket.async().replace(doc); break; default: return Observable.error( new UnsupportedOperationException("Unsupported ingest method") ); } <|startfocus|> bucket.async().upsert(doc); <|endfocus|> result = result.timeout(kvTimeout, TimeUnit.MILLISECONDS); if (opts.retryBuilder != null) { result = result.retryWhen(opts.retryBuilder.build()); } if (opts.ignoreIngestError) { result = result.onErrorResumeNext(Observable.<JsonDocument>empty()); } return result;
<|startcomment|> NIT: is this change intentional? <|endcomment|>  int expiration, long cas) { this(key, path, fragment, bucket, expiration, cas, AsyncSubject.<CouchbaseResponse>create()); } /** * Creates a new {@link AbstractSubdocMutationRequest}. * * @param key the key of the document. * @param path the subdocument path to consider inside the document. * @param fragment the fragment of valid JSON to mutate into at the site denoted by the path. <|startfocus|> * * @param bucket the bucket of the document. <|endfocus|> * @param expiration the TTL of the whole enclosing document. * @param cas the cas value for the operation * @param observable the observable which receives responses. * @throws NullPointerException if the path is null (see {@link #EXCEPTION_NULL_PATH}) */ protected AbstractSubdocMutationRequest(String key, String path, ByteBuf fragment, String bucket, int expiration, long cas, Subject<CouchbaseResponse, CouchbaseResponse> observable) { super(key, path, bucket, observable, fragment); this.expiration = expiration;
<|startcomment|> "Distinct" and "Raw" are two words, so they should be separated by an underscore, like "DISTINCT_RAW" (unless there's some reason we can't follow the usual naming convention, in which case we should document the reason). <|endcomment|>  * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.java.query.dsl.path; /** * . * * @author Michael Nitschinger */ public enum SelectType { DEFAULT(""), ALL("ALL"), DISTINCT("DISTINCT"), RAW("RAW"), <|startfocus|> DISTINCTRAW("DISTINCT RAW"); <|endfocus|> private final String value; SelectType(String value) { this.value = value; } public String value() { return value; } } 
<|startcomment|> Now I see the API in use, this looks quite verbose... But I guess they can import IngestOptions and IngestMethod directly, which'll help. <|endcomment|>  public void shouldNotAllowReplaceAndUUID() { AnalyticsIngester.ingest( null, null, <|startfocus|> AnalyticsIngester.IngestOptions.ingestOptions().ingestMethod(AnalyticsIngester.IngestMethod.REPLACE) <|endfocus|> );
<|startcomment|> Is this line needed? Shouldn't be as of 2.7.0, right? <|endcomment|> kage com.couchbase.client.java; import java.util.Iterator; import com.couchbase.client.java.analytics.AnalyticsDeferredResultHandle; import com.couchbase.client.java.analytics.AnalyticsParams; import com.couchbase.client.java.analytics.AnalyticsQuery; import com.couchbase.client.java.analytics.AnalyticsQueryResult; import com.couchbase.client.java.analytics.AnalyticsQueryRow; /** * Stand alone test for now as it is experimental */ public class AnalyticsDeferredQueryTest { public static void main(String... args) throws Exception { <|startfocus|> System.setProperty("com.couchbase.analyticsEnabled", "true"); <|endfocus|> Cluster cluster = CouchbaseCluster.create(); cluster.authenticate("Administrator", "password"); Bucket bucket = cluster.openBucket("default"); AnalyticsQueryResult result = bucket.query(AnalyticsQuery.simple("SELECT 1=1;", AnalyticsParams.build().deferred(true))); byte[] serialized = bucket.exportAnalyticsDeferredResultHandle(result.handle()); AnalyticsDeferredResultHandle handle = bucket.importAnalyticsDeferredResultHandle(serialized); while(!handle.status().equalsIgnoreCase("success")) { Thread.sleep(100); handle.status(); } Iterator<AnalyticsQueryRow> it = handle.rows();
<|startcomment|> What does this method do if the result URI is not available? <|endcomment|>  import com.couchbase.client.core.annotations.InterfaceAudience; import com.couchbase.client.core.annotations.InterfaceStability; /** * An async handle to fetch the status and results of a deferred * Analytics Query * * @author Subhashni Balakrishnan * @since 2.7.2 */ @InterfaceStability.Experimental @InterfaceAudience.Public public interface AnalyticsDeferredResultHandle { /** * Get the status uri * * @return uri */ @InterfaceAudience.Private String getStatusHandleUri(); /** * Get the result uri if available <|startfocus|> * <|endfocus|> * @return uri */ @InterfaceAudience.Private String getResultHandleUri(); /** * @return the list of all {@link AnalyticsQueryRow}, the results of the query, if successful. */ List<AnalyticsQueryRow> allRows(); /** * @return an iterator over the list of all {@link AnalyticsQueryRow}, the results of the query, if successful. */ Iterator<AnalyticsQueryRow> rows(); /**
<|startcomment|> NIT: don't need explicit `toString()`... it's implicit when appending an ibject to a string. <|endcomment|>  "status='" + status + '\'' + ", finalSuccess=" + finalSuccess + ", parseSuccess=" + parseSuccess + ", allRows=" + allRows + ", signature=" + signature + ", info=" + info + ", errors=" + errors + ", requestId='" + requestId + '\'' + ", clientContextId='" + clientContextId + '\'' + <|startfocus|> ", handle='" + handle.toString() + '\'' + <|endfocus|> '}';
<|startcomment|> I'd think this is actually one of the correct places to use IllegalStateException, right? <|endcomment|>  public String getResultHandleUri() { if (this.resultHandle.length() == 0) { <|startfocus|> throw new RuntimeException("There is no result handle available, retry status until success"); <|endfocus|> } return this.resultHandle;
<|startcomment|> expand method name to "useNestedLoop" ? <|endcomment|> <|startfocus|> public KeysPath useNL() { <|endfocus|> element(new NestedLoopJoinHintElement()); return new DefaultKeysPath(this);
<|startcomment|> Do you mean `this.side.getValue()`? Or do you want to add a HashSide.toString() that returns getValue()? <|endcomment|>  public String export() { <|startfocus|> StringBuilder sb = new StringBuilder(); sb.append("USE HASH("); sb.append(this.side.toString()); sb.append(")"); return sb.toString(); <|endfocus|>
<|startcomment|> NIT: could simplify as: return "USE HASH(" + this.side + ")"; <|endcomment|>  public String export() { <|startfocus|> StringBuilder sb = new StringBuilder(); sb.append("USE HASH("); sb.append(this.side.toString()); sb.append(")"); return sb.toString(); <|endfocus|>
<|startcomment|> NIT: Did you want these to be Javadoc comments? /** instead of /* <|endcomment|>  * See the License for the specific language governing permissions and * limitations under the License. */ package com.couchbase.client.java.query.dsl.path; import com.couchbase.client.core.annotations.InterfaceAudience; import com.couchbase.client.core.annotations.InterfaceStability; /** * Hash side for hash based join * * @author Subhashni Balakrishnan */ @InterfaceStability.Experimental @InterfaceAudience.Public public enum HashSide { /*The PROBE side will use that table to find matches and perform the join*/ PROBE("PROBE"), <|startfocus|> /*The BUILD side of the join will be used to create an in-memory hash table */ <|endfocus|> BUILD("BUILD"); private final String value; HashSide(String value) { this.value = value; } public String getValue() { return this.value; } } 
<|startcomment|> Should this be toString() in order to allow for easy string concatenation? <|endcomment|>  /** * Hash side for hash based join * * @author Subhashni Balakrishnan */ @InterfaceStability.Experimental @InterfaceAudience.Public public enum HashSide { /*The PROBE side will use that table to find matches and perform the join*/ PROBE("PROBE"), /*The BUILD side of the join will be used to create an in-memory hash table */ BUILD("BUILD"); private final String value; HashSide(String value) { this.value = value; } <|startfocus|> public String getValue() { <|endfocus|> return this.value; } } 
<|startcomment|> Should this be mentioned in a @throws tag? Or does that only work if the method is explicitly declared to throw it? <|endcomment|>  * updated or deleted from the repository. * * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of an specific reference * name. * <p> * A number that increases when a reference is updated. Implementations * define its meaning (e.g. version counter or timestamp). When the * implementation doesn't support versioning, it throws an * {@link UnsupportedOperationException}. * <|startfocus|> * @return the update index of this reference. <|endfocus|> */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } } 
<|startcomment|> Missing @since tag for new public method. <|endcomment|>  * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of an specific reference * name. * <p> * A number that increases when a reference is updated. Implementations * define its meaning (e.g. version counter or timestamp). When the * implementation doesn't support versioning, it throws an * {@link UnsupportedOperationException}. * * @return the update index of this reference. */ <|startfocus|> default long getUpdateIndex() { <|endfocus|> throw new UnsupportedOperationException(); } } 
<|startcomment|> "version"? <|endcomment|>  public void testUpdateIndexNotImplemented() throws IOException { Ref exactRef = refdir.exactRef(HEAD); assertNotNull(exactRef); exactRef.getVersion(); // Not implemented on FS } @Test public void testUpdateIndexNotImplemented2() throws Exception { RevCommit C = repo.commit().parent(B).create(); repo.update("master", C); List<Ref> refs = refdir.getRefs(); for (Ref ref: refs) { try { ref.getVersion(); <|startfocus|> fail("FS doesn't implement update index"); <|endfocus|> } catch (UnsupportedOperationException e) { // ok } } } @Test public void testGetRefs_EmptyDatabase() throws IOException { Map<String, Ref> all; all = refdir.getRefs(RefDatabase.ALL); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_HEADS); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_TAGS); assertTrue("no references", all.isEmpty()); } @Test public void testGetRefs_HeadOnOneBranch() throws IOException {
<|startcomment|> Should this be named "version" now? <|endcomment|>  * Decorate a reference adding the update index (version) property. * * Undecorated Refs throw {@link UnsupportedOperationException} on * {@link #getVersion()}, while decorated instances return the expect value. * * The client is responsible to call {@link #getVersion()} only on refs * obtained from {@link RefDatabase} implementations that support versioning * (e.g. reftables) * * @since 5.2 */ public class VersionedRef implements Ref { private Ref ref; <|startfocus|> private long updateIndex; <|endfocus|> /** * @param ref * the Reference * @param updateIndex * its update index */ public VersionedRef(Ref ref, long updateIndex) { this.ref = ref; this.updateIndex = updateIndex; } @Override public String getName() { return ref.getName(); } @Override public boolean isSymbolic() { return ref.isSymbolic(); } @Override public Ref getLeaf() { return ref.getLeaf(); } @Override public Ref getTarget() {
<|startcomment|> can you at least log info or warning for now? [this make me starts smth to push notification when needed] <|endcomment|>  private TmfFilterHelper() { // nothing to do } /** * Build an event filter from the regex string in parameter * * @param regexes * The filter regex * @param trace * The trace this filter applies to * @return An event filter */ public static @Nullable ITmfFilter buildFilterFromRegex(Collection<String> regexes, ITmfTrace trace) { FilterCu compile = FilterCu.compile(IFilterStrings.mergeFilters(regexes)); <|startfocus|> if (compile == null) { <|endfocus|> return null; } return compile.getEventFilter(trace); } /** * Get the regex that corresponds to this filter. The regex should be in the * filter language described in the * {@link org.eclipse.tracecompass.tmf.filter.parser} plugin. And as it may * be used to filter anything, so it may not be the direct string * representing of the original filter. For instance, a ITmfFilter specific * for events will do a smart conversion, so that the parameters of the
<|startcomment|> add another method to find out if this method is supported ? <|endcomment|>  * instantiator of the Ref must override this method (e.g. with the * {@link VersionedRef} decorator) if it can provide a version value. * * @return the version of this reference. * @throws UnsupportedOperationException * if the creator of the instance (e.g. {@link RefDatabase}) * doesn't support versioning and doesn't override this method * @since 5.2 */ <|startfocus|> default long getVersion() { <|endfocus|> throw new UnsupportedOperationException(); } } 
<|startcomment|> add a method on RefDatabase to find out if it supports versioned refs ? <|endcomment|>  * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. */ package org.eclipse.jgit.lib; /** * Decorate a reference adding the update index (version) property. * * Undecorated Refs throw {@link UnsupportedOperationException} on * {@link #getVersion()}, while decorated instances return the expect value. * <|startfocus|> * The client is responsible to call {@link #getVersion()} only on refs * obtained from {@link RefDatabase} implementations that support versioning * (e.g. reftables) <|endfocus|> * * @since 5.2 */ public class VersionedRef implements Ref { private Ref ref; private long updateIndex; /** * @param ref * the Reference * @param updateIndex * its update index */ public VersionedRef(Ref ref, long updateIndex) { this.ref = ref; this.updateIndex = updateIndex; } @Override public String getName() { return ref.getName(); } @Override public boolean isSymbolic() { return ref.isSymbolic(); } @Override
<|startcomment|> missing NLS ? <|endcomment|>  } }; } else { factory = new UMLPropertyEditorFactory(reference); } EClass type = reference.getEReferenceType(); factory.setContainerLabelProvider(new UMLFilteredLabelProvider()); factory.setReferenceLabelProvider(new EMFLabelProvider()); ITreeContentProvider contentProvider = new UMLContainerContentProvider(source, reference); ResourceSet rs = source == null ? null : source.eResource() == null ? null : source.eResource().getResourceSet(); <|startfocus|> EMFGraphicalContentProvider provider = ProviderHelper.encapsulateProvider(contentProvider, rs, HistoryUtil.getHistoryID(source, feature, "container")); <|endfocus|> factory.setContainerContentProvider(provider); factory.setReferenceContentProvider(new FeatureContentProvider(type)); return factory;
<|startcomment|> use the @since (judging by the code base: 1.2.0 - ecd4928b327f5561364c5068c9ff5f1668e92d13) <|endcomment|>  * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation * Christian W. Damus - bug 485220 * *****************************************************************************/ package org.eclipse.papyrus.uml.tools.databinding; import org.eclipse.core.databinding.observable.IObservable; import org.eclipse.emf.edit.domain.EditingDomain; /** <|startfocus|> * @deprecated Use the {@link org.eclipse.papyrus.infra.services.edit.ui.databinding.AggregatedPapyrusObservableValue} API, instead. <|endfocus|> * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated public class AggregatedPapyrusObservableValue extends org.eclipse.papyrus.infra.services.edit.ui.databinding.AggregatedPapyrusObservableValue { public AggregatedPapyrusObservableValue(EditingDomain domain, IObservable... observableValues) { super(domain, observableValues); } } 
<|startcomment|> same here 1.2.0 <|endcomment|>  * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation * Christian W. Damus - bug 485220 * *****************************************************************************/ package org.eclipse.papyrus.uml.tools.databinding; /** <|startfocus|> * @deprecated Use the {@link org.eclipse.papyrus.infra.tools.databinding.CommandBasedObservable} API, instead. <|endfocus|> * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated public interface CommandBasedObservable extends org.eclipse.papyrus.infra.tools.databinding.CommandBasedObservable { // Nothing additional } 
<|startcomment|> 1.2.0 <|endcomment|>  * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation * Christian W. Damus - bug 485220 * *****************************************************************************/ package org.eclipse.papyrus.uml.tools.databinding; /** <|startfocus|> * @deprecated Use the {@link org.eclipse.papyrus.infra.tools.databinding.CommandBasedObservableValue} API, instead. <|endfocus|> * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated public interface CommandBasedObservableValue extends CommandBasedObservable, org.eclipse.papyrus.infra.tools.databinding.CommandBasedObservableValue { // Nothing additional } 
<|startcomment|> 1.2.0 <|endcomment|> import org.eclipse.gmf.runtime.emf.type.core.requests.SetRequest; import org.eclipse.papyrus.infra.emf.gmf.command.GMFtoEMFCommandWrapper; import org.eclipse.papyrus.infra.services.edit.service.ElementEditServiceUtils; import org.eclipse.papyrus.infra.services.edit.service.IElementEditService; import org.eclipse.papyrus.infra.ui.emf.databinding.EMFObservableList; /** * An ObservableList used to edit collections of EObjects through * Papyrus commands * * @author Camille Letavernier <|startfocus|> * @deprecated Use the {@link org.eclipse.papyrus.infra.gmfdiag.common.databinding.GMFObservableList} API, instead <|endfocus|> * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated @SuppressWarnings("unchecked") public class PapyrusObservableList extends EMFObservableList { /** * * Constructor. * * @param wrappedList * The list to be edited when #commit() is called * @param domain * The editing domain on which the commands will be executed * @param source * The EObject from which the list will be retrieved * @param feature
<|startcomment|> 1.2.0 <|endcomment|> import org.eclipse.papyrus.infra.services.edit.service.ElementEditServiceUtils; import org.eclipse.papyrus.infra.services.edit.service.IElementEditService; import org.eclipse.papyrus.infra.tools.databinding.AggregatedObservable; import org.eclipse.papyrus.infra.tools.databinding.ReferenceCountedObservable; import org.eclipse.papyrus.infra.ui.emf.databinding.EMFObservableValue; import org.eclipse.papyrus.uml.tools.Activator; /** * An ObservableValue used to edit EObject properties through * Papyrus commands * * @author Camille Letavernier <|startfocus|> * @deprecated Use the {@link org.eclipse.papyrus.infra.gmfdiag.common.databinding.GMFObservableValue} API, instead <|endfocus|> * * This class Will be removed in Papyrus 5.0, see bug 540829 */ @Deprecated public class PapyrusObservableValue extends EMFObservableValue implements AggregatedObservable, CommandBasedObservableValue, ReferenceCountedObservable { private final ReferenceCountedObservable.Support refCount = new ReferenceCountedObservable.Support(this); /** * * Constructor. * * @param eObject * The EObject to edit * @param eStructuralFeature * The structural feature to edit * @param domain * The editing domain on which the commands will be executed
<|startcomment|> todo ? <|endcomment|>  * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.uml.tools.providers; import org.eclipse.jface.viewers.ILabelProvider; import org.eclipse.papyrus.infra.ui.emf.providers.EMFLabelProvider; import org.eclipse.papyrus.uml.tools.utils.ProfileUtil; import org.eclipse.uml2.uml.Package; import org.eclipse.uml2.uml.Profile; //TODO : To be refactored. Merge this class with UMLLabelProvider <|startfocus|> //should be removed in Papyrus 5.0 (see bug 540821) <|endfocus|> @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage; public static final String TAG_PROFILE_CHANGED = " (has changed, consider re-applying profile)"; public static final String UNKNOWN_PROFILE = "<Unknown>"; public ProfileLabelProvider(Package umlPackage) { this.umlPackage = umlPackage; } @Override public String getText(Object source) { if (source instanceof Profile) { Profile profile = (Profile) source; String name = profile.getQualifiedName();
<|startcomment|> no @since (1.2.0 - aaa0f0a63bf9890ee7911e638a41d8b721d7c2fd) <|endcomment|>  * * Contributors: * Camille Letavernier (CEA LIST) camille.letavernier@cea.fr - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.uml.tools.providers; import org.eclipse.jface.viewers.ILabelProvider; import org.eclipse.papyrus.infra.ui.emf.providers.EMFLabelProvider; import org.eclipse.papyrus.uml.tools.utils.ProfileUtil; import org.eclipse.uml2.uml.Package; import org.eclipse.uml2.uml.Profile; //TODO : To be refactored. Merge this class with UMLLabelProvider <|startfocus|> //should be removed in Papyrus 5.0 (see bug 540821) <|endfocus|> @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage; public static final String TAG_PROFILE_CHANGED = " (has changed, consider re-applying profile)"; public static final String UNKNOWN_PROFILE = "<Unknown>"; public ProfileLabelProvider(Package umlPackage) { this.umlPackage = umlPackage; } @Override public String getText(Object source) { if (source instanceof Profile) { Profile profile = (Profile) source; String name = profile.getQualifiedName(); if (name == null) {
<|startcomment|> nls tags ? <|endcomment|>  import org.eclipse.jface.viewers.ILabelProvider; import org.eclipse.papyrus.infra.ui.emf.providers.EMFLabelProvider; import org.eclipse.papyrus.uml.tools.utils.ProfileUtil; import org.eclipse.uml2.uml.Package; import org.eclipse.uml2.uml.Profile; //TODO : To be refactored. Merge this class with UMLLabelProvider //should be removed in Papyrus 5.0 (see bug 540821) @Deprecated public class ProfileLabelProvider extends EMFLabelProvider implements ILabelProvider { private Package umlPackage; <|startfocus|> public static final String TAG_PROFILE_CHANGED = " (has changed, consider re-applying profile)"; <|endfocus|> public static final String UNKNOWN_PROFILE = "<Unknown>"; public ProfileLabelProvider(Package umlPackage) { this.umlPackage = umlPackage; } @Override public String getText(Object source) { if (source instanceof Profile) { Profile profile = (Profile) source; String name = profile.getQualifiedName(); if (name == null) { name = UNKNOWN_PROFILE; } if (ProfileUtil.isDirty(umlPackage, profile)) { name += TAG_PROFILE_CHANGED; } return name; } return super.getText(source);
<|startcomment|> this is really really cool. <|endcomment|>  long[] stack = new long[1]; stack[0] = 0; return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } long[] stack = new long[userCs.size() + kernelCs.size()]; int i = 0; for (Object call : userCs) { stack[i] = (long) call; i++; } for (Object call : kernelCs) { <|startfocus|> stack[i] = (long) call; <|endfocus|> i++; } return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } /** * @param event */ private ICallStackElement getElement(ITmfEvent event) { // Find a root elements with the same PID Collection<ICallStackElement> rootElements = getRootElements(); String name = event.getName(); Optional<ICallStackElement> events = rootElements.stream() .filter(e -> e.getName().equals(String.valueOf(name))) .findFirst();
<|startcomment|> javadoc? <|endcomment|>  } long[] stack = new long[userCs.size() + kernelCs.size()]; int i = 0; for (Object call : userCs) { stack[i] = (long) call; i++; } for (Object call : kernelCs) { stack[i] = (long) call; i++; } return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } <|startfocus|> /** * @param event */ <|endfocus|> private ICallStackElement getElement(ITmfEvent event) { // Find a root elements with the same PID Collection<ICallStackElement> rootElements = getRootElements(); String name = event.getName(); Optional<ICallStackElement> events = rootElements.stream() .filter(e -> e.getName().equals(String.valueOf(name))) .findFirst(); Integer threadId = TmfTraceUtils.resolveIntEventAspectOfClassForEvent(event.getTrace(), LinuxTidAspect.class, event); int tid = (threadId == null) ? -1 : threadId;
<|startcomment|> can this be a long[]? asking. <|endcomment|>  * The event containing the cpu * * @return the CPU number (null for not set) */ public static @Nullable Integer getCpu(ITmfEvent event) { Integer cpuObj = TmfTraceUtils.resolveIntEventAspectOfClassForEvent(event.getTrace(), TmfCpuAspect.class, event); if (cpuObj == null) { /* We couldn't find any CPU information, ignore this event */ return null; } return cpuObj; } @Override public Map<String, Collection<Object>> getCallStack(ITmfEvent event) { <|startfocus|> <|endfocus|> Map<String, Collection<Object>> map = new HashMap<>(); ITmfEventField content = event.getContent(); ITmfEventField field = content.getField(KERNEL_CALLSTACK_FIELD); if (field != null) { map.put(KERNEL_STACK_NAME, getCallstack(field)); } field = content.getField(USER_CALLSTACK_FIELD); if (field != null) { map.put(USER_STACK_NAME, getCallstack(field)); } return map; } private static Collection<Object> getCallstack(ITmfEventField field) { Object value = field.getValue();
<|startcomment|> more comments please in a later patch <|endcomment|>  } long[] stack = new long[userCs.size() + kernelCs.size()]; int i = 0; for (Object call : userCs) { stack[i] = (long) call; i++; } for (Object call : kernelCs) { stack[i] = (long) call; i++; } return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } <|startfocus|> /** * @param event */ <|endfocus|> private ICallStackElement getElement(ITmfEvent event) { // Find a root elements with the same PID Collection<ICallStackElement> rootElements = getRootElements(); String name = event.getName(); Optional<ICallStackElement> events = rootElements.stream() .filter(e -> e.getName().equals(String.valueOf(name))) .findFirst(); Integer threadId = TmfTraceUtils.resolveIntEventAspectOfClassForEvent(event.getTrace(), LinuxTidAspect.class, event); int tid = (threadId == null) ? -1 : threadId;
<|startcomment|> Instanceof checks here unless you're 100% certain it's long. :) <|endcomment|>  if (userCs == null) { userCs = Collections.emptyList(); } if (kernelCs.size() + userCs.size() == 0) { long[] stack = new long[1]; stack[0] = 0; return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } long[] stack = new long[userCs.size() + kernelCs.size()]; int i = 0; for (Object call : userCs) { <|startfocus|> stack[i] = (long) call; <|endfocus|> i++; } for (Object call : kernelCs) { stack[i] = (long) call; i++; } return new Pair<>(element, getCallSite(element, stack, event.getTimestamp().getValue())); } private ICallStackElement getElement(ITmfEvent event) { // Find a root elements with the same PID Collection<ICallStackElement> rootElements = getRootElements(); String name = event.getName(); Optional<ICallStackElement> events = rootElements.stream()
<|startcomment|> I think it can only throw a RuntimeException <|endcomment|>  // sufficient. //@formatter:off Optional<Resource> representationResource = Optional.ofNullable(resource) .map(rsr -> rsr.getResourceSet()) .filter(resourceSet -> !loadOnDemand || resourceSet.getURIConverter().exists(repResourceURI, new HashMap<>())) //@formatter:on .map(resourceSet -> { Resource res = null; try { res = resourceSet.getResource(repResourceURI, loadOnDemand); // CHECKSTYLE:OFF <|startfocus|> } catch (Exception e) { <|endfocus|> // CHECKSTYLE:ON // an exception may occur if the segment part is malformed or if the resource does not // exists in case the representation is in its own resource. } return res; }); String repId = uri.get().fragment(); if (representationResource.isPresent() && repId != null) { // We look for the representation with the repId (retrieved from // the uri fragment) within the representation resource. return representationResource.get().getContents().stream().filter(DRepresentation.class::isInstance).map(DRepresentation.class::cast)
<|startcomment|> Broken mix of EPL 1.0 and 2.0. <|endcomment|> ***************************************************************************** * Copyright (c) 2017, 2018 THALES GLOBAL SERVICES. <|startfocus|> * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 <|endfocus|> * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - initial API and implementation *******************************************************************************/ package org.eclipse.sirius.business.internal.representation; import java.util.HashMap; import java.util.Optional; import org.eclipse.emf.common.util.URI; import org.eclipse.emf.ecore.resource.Resource; import org.eclipse.emf.ecore.util.ECrossReferenceAdapter; import org.eclipse.sirius.business.api.resource.ResourceDescriptor; import org.eclipse.sirius.viewpoint.DRepresentation; import org.eclipse.sirius.viewpoint.DRepresentationDescriptor; /** * This class is intended to manage the link between the {@link DRepresentationDescriptor} and its * {@link DRepresentation} through the {@link DRepresentationDescriptor#repPath} attribute. * * @author fbarbin * */ public class DRepresentationDescriptorToDRepresentationLinkManager {
<|startcomment|> Create the necessary constant. we can't use CompareConfiguration.MIRRORED directly because of compatibility issues, but you can redefine EMFCompareConfiguration.MIRRORED = "MIRRORED" and mention that this is the same property as what CompareConfiguration defines. <|endcomment|>  } @Test public void testMirrorAcceptAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.ACCEPT, DifferenceState.MERGED); } @Test public void testMirrorRejectAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.REJECT, DifferenceState.DISCARDED); } private IEMFCompareConfiguration createConfiguration(boolean leftEditable, boolean rightEditable) { CompareConfiguration cc = new CompareConfiguration(); <|startfocus|> cc.setProperty("MIRRORED", Boolean.TRUE); //$NON-NLS-1$ <|endfocus|> cc.setLeftEditable(leftEditable); cc.setRightEditable(rightEditable); EMFCompareConfiguration emfCC = new EMFCompareConfiguration(cc); emfCC.setEditingDomain(editingDomain); return emfCC; } class MockMergeAction extends MergeAction { public MockMergeAction(IEMFCompareConfiguration compareConfiguration, Registry mergerRegistry, MergeMode mode, INavigatable navigatable) { super(compareConfiguration, mergerRegistry, mode, navigatable); } @Override public boolean updateSelection(IStructuredSelection selection) { return super.updateSelection(selection); } @Override protected void clearCache() { super.clearCache(); } @Override
<|startcomment|> Same remark about the constant <|endcomment|>  public boolean isMirrored() { <|startfocus|> Object property = getProperty("MIRRORED"); //$NON-NLS-1$ <|endfocus|> return property instanceof Boolean && ((Boolean)property).booleanValue();
<|startcomment|> Likewise <|endcomment|>  public void propertyChange(PropertyChangeEvent event) { <|startfocus|> if ("MIRRORED".equals(event.getProperty())) { //$NON-NLS-1$ <|endfocus|> Object newValue = event.getNewValue(); mirroredPropertyChanged(Boolean.TRUE.equals(newValue)); }
<|startcomment|> Please separate the two lines so that it's readable. boolean isLeft = MergeViewerSide.LEFT == side; if (getCompareConfiguration.isMirrored()) { isLeft = MergeViewerSide.RIGHT == side; } <|endcomment|>  private String getCurrentValueFromViewer(MergeViewerSide side) { <|startfocus|> final boolean isLeft = (MergeViewerSide.LEFT == side) != getCompareConfiguration().isMirrored(); <|endfocus|> final GetContentRunnable runnable = new GetContentRunnable(isLeft); Display.getDefault().syncExec(runnable); return (String)runnable.getResult();
<|startcomment|> EMFCompareConfiguration.MIRRORED <|endcomment|>  } @Test public void testMirrorAcceptAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.ACCEPT, DifferenceState.MERGED); } @Test public void testMirrorRejectAllNonConflictingAction() { // mirrored-> same behavior as not mirrored action testMirrorAllNonConflictingAction(MergeMode.REJECT, DifferenceState.DISCARDED); } private IEMFCompareConfiguration createConfiguration(boolean leftEditable, boolean rightEditable) { CompareConfiguration cc = new CompareConfiguration(); <|startfocus|> cc.setProperty("MIRRORED", Boolean.TRUE); //$NON-NLS-1$ <|endfocus|> cc.setLeftEditable(leftEditable); cc.setRightEditable(rightEditable); EMFCompareConfiguration emfCC = new EMFCompareConfiguration(cc); emfCC.setEditingDomain(editingDomain); return emfCC; } class MockMergeAction extends MergeAction { public MockMergeAction(IEMFCompareConfiguration compareConfiguration, Registry mergerRegistry, MergeMode mode, INavigatable navigatable) { super(compareConfiguration, mergerRegistry, mode, navigatable); } @Override public boolean updateSelection(IStructuredSelection selection) { return super.updateSelection(selection); } @Override protected void clearCache() { super.clearCache(); } @Override
<|startcomment|> shouldn't the check be (flags & SWT.DRAW_TRANSPARENT) != 0) <|endcomment|>  try { int length = string.length(); if (length == 0) return; boolean mode = true; switch (data.textAntialias) { case SWT.DEFAULT: /* Printer is off by default */ if (!handle.isDrawingToScreen()) mode = false; break; case SWT.OFF: mode = false; break; case SWT.ON: mode = true; break; } handle.saveGraphicsState(); handle.setShouldAntialias(mode); <|startfocus|> if (length == 1 && flags == SWT.DRAW_TRANSPARENT) { <|endfocus|> doFastDrawText(string, x, y); } else { doDrawText(string, x, y, flags); } handle.restoreGraphicsState(); } finally { uncheckGC(pool); }
<|startcomment|> nit: I would call this method something like "getChannel". The "open().op()" call in all the following methods, make it look like the channel is closed automatically. <|endcomment|>  } } @Override public void close() { try { ch.close(); } catch (IOException e) { // Ignore read close failures. } } private static final class LazyReadableChannel implements ReadableChannel { private final DfsReader ctx; private final DfsReftable file; private ReadableChannel ch; LazyReadableChannel(DfsReftable file, DfsReader ctx) { this.file = file; this.ctx = ctx; } <|startfocus|> private ReadableChannel open() throws IOException { <|endfocus|> if (ch == null) { ch = ctx.db.openFile(file.desc, file.ext); } return ch; } @Override public int blockSize() { try { return open().blockSize(); } catch (IOException e) { return -1; } } @Override public long position() throws IOException { return open().position(); } @Override public void position(long newPosition) throws IOException { open().position(newPosition); } @Override public void setReadAheadBytes(int bufferSize) throws IOException {
<|startcomment|> please remove the period at the end as it makes URL invalid <|endcomment|> ***************************************************************************** * Copyright (c) 2016 Frank Becker and others. * * This program and the accompanying materials are made available under the * terms of the Eclipse Public License v. 2.0 which is available at <|startfocus|> * https://www.eclipse.org/legal/epl-2.0. <|endfocus|> * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Frank Becker - initial API and implementation *******************************************************************************/ package org.eclipse.mylyn.bugzilla.rest.core.tests; import java.util.List; import org.eclipse.mylyn.commons.sdk.util.CommonTestUtil; import org.eclipse.mylyn.commons.sdk.util.ManagedSuite; import org.eclipse.mylyn.commons.sdk.util.ManagedSuite.SuiteClassProvider; import org.eclipse.mylyn.commons.sdk.util.ManagedSuite.TestConfigurationProperty; import org.eclipse.mylyn.commons.sdk.util.TestConfiguration; import org.junit.runner.RunWith; import org.junit.runners.Suite; @RunWith(ManagedSuite.class) @Suite.SuiteClasses({ RepositoryKeyTest.class, BugzillaRestFlagMapperTest.class, BugzillaRestConnectorNoFixtureTest.class }) @TestConfigurationProperty() public class AllBugzillaRestCoreTests { static { if (CommonTestUtil.fixProxyConfiguration()) {
<|startcomment|> optional: Ref ref? <|endcomment|>  assertTrue(new File(d, "logs/refs/heads").isDirectory()); assertFalse(new File(d, "logs/HEAD").exists()); assertEquals(0, new File(d, "logs/refs/heads").list().length); assertEquals("ref: refs/heads/master\n", read(new File(d, HEAD))); } @Test(expected = UnsupportedOperationException.class) public void testVersioningNotImplemented_exactRef() throws IOException { assertFalse(refdir.hasVersioning()); <|startfocus|> Ref exactRef = refdir.exactRef(HEAD); assertNotNull(exactRef); exactRef.getUpdateIndex(); // Not implemented on FS <|endfocus|> } @Test public void testVersioningNotImplemented_getRefs() throws Exception { assertFalse(refdir.hasVersioning()); RevCommit C = repo.commit().parent(B).create(); repo.update("master", C); List<Ref> refs = refdir.getRefs(); for (Ref ref: refs) { try { ref.getUpdateIndex(); fail("FS doesn't implement ref versioning"); } catch (UnsupportedOperationException e) { // ok } } } @Test
<|startcomment|> style nit: whitespace doesn't look right <|endcomment|>  public void testVersioningNotImplemented_exactRef() throws IOException { assertFalse(refdir.hasVersioning()); Ref exactRef = refdir.exactRef(HEAD); assertNotNull(exactRef); exactRef.getUpdateIndex(); // Not implemented on FS } @Test public void testVersioningNotImplemented_getRefs() throws Exception { assertFalse(refdir.hasVersioning()); RevCommit C = repo.commit().parent(B).create(); repo.update("master", C); List<Ref> refs = refdir.getRefs(); <|startfocus|> for (Ref ref: refs) { <|endfocus|> try { ref.getUpdateIndex(); fail("FS doesn't implement ref versioning"); } catch (UnsupportedOperationException e) { // ok } } } @Test public void testGetRefs_EmptyDatabase() throws IOException { Map<String, Ref> all; all = refdir.getRefs(RefDatabase.ALL); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_HEADS); assertTrue("no references", all.isEmpty()); all = refdir.getRefs(R_TAGS); assertTrue("no references", all.isEmpty()); }
<|startcomment|> If It use getLeaf() on this, will it return an unversioned ref? <|endcomment|>  return ref; } Ref dst = ref.getTarget(); if (MAX_SYMBOLIC_REF_DEPTH <= depth) { return null; // claim it doesn't exist } dst = exactRef(dst.getName()); if (dst == null) { return ref; } dst = resolve(dst, depth + 1); if (dst == null) { return null; // claim it doesn't exist } <|startfocus|> return new VersionedRef(new SymbolicRef(ref.getName(), dst), ref.getUpdateIndex()); <|endfocus|> } /** {@inheritDoc} */ @Override public abstract void close() throws IOException; } 
<|startcomment|> This potentially could have versioning (e.g. using commit timestamp), but I agree it's not worth the engineering effort. <|endcomment|>  } /** * Get namespace used by bootstrap layer. * * @return namespace used by bootstrap layer, e.g. {@code refs/txn/}. Always * ends in {@code '/'}. */ @Nullable public String getTxnNamespace() { return txnNamespace; } /** {@inheritDoc} */ @Override public void create() throws IOException { bootstrap.create(); } /** {@inheritDoc} */ @Override <|startfocus|> public boolean hasVersioning() { return false; } /** {@inheritDoc} */ @Override <|endfocus|> public boolean performsAtomicTransactions() { return true; } /** {@inheritDoc} */ @Override public void refresh() { bootstrap.refresh(); } /** {@inheritDoc} */ @Override public void close() { refs = null; bootstrap.close(); } /** {@inheritDoc} */ @Override public Ref getRef(String name) throws IOException { String[] needle = new String[SEARCH_PATH.length];
<|startcomment|> This is imported only for the sake of javadoc. Could the javadoc use {@code} or the fully qualified name instead? <|endcomment|>  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. */ package org.eclipse.jgit.lib; import org.eclipse.jgit.annotations.NonNull; import org.eclipse.jgit.annotations.Nullable; <|startfocus|> import org.eclipse.jgit.lib.internal.VersionedRef; <|endfocus|> /** * Pairing of a name and the {@link org.eclipse.jgit.lib.ObjectId} it currently * has. * <p> * A ref in Git is (more or less) a variable that holds a single object * identifier. The object identifier can be any valid Git object (blob, tree, * commit, annotated tag, ...). * <p> * The ref name has the attributes of the ref that was asked for as well as the * ref it was resolved to for symbolic refs plus the object id it points to and
<|startcomment|> nit: s/with/by using/ <|endcomment|>  /** * Indicator of the relative order between updates of a specific reference * name. * <p> * A number that increases when a reference is updated. Implementations * define its value (e.g. version counter or timestamp). * <p> * By default this throws an {@link UnsupportedOperationException}. The <|startfocus|> * instantiator of the Ref must override this method (e.g. with the * {@link VersionedRef} decorator) if it can provide a version value. <|endfocus|> * * @return the version of this reference. * @throws UnsupportedOperationException * if the creator of the instance (e.g. {@link RefDatabase}) * doesn't support versioning and doesn't override this method * @since 5.3 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } } 
<|startcomment|> nit: s/version numbers/sequencer numbers/, or update indices, or something like that. <|endcomment|>  /** * Initialize a new reference database at this location. * * @throws java.io.IOException * the database could not be created. */ public abstract void create() throws IOException; /** * Close any resources held by this database. */ public abstract void close(); /** * With versioning, each reference has a version number that increases on * update. * <|startfocus|> * @return true when the implementation assigns version numbers to <|endfocus|> * references. * @since 5.3 */ public abstract boolean hasVersioning(); /** * Determine if a proposed reference name overlaps with an existing one. * <p> * Reference names use '/' as a component separator, and may be stored in a * hierarchical storage such as a directory on the local filesystem. * <p> * If the reference "refs/heads/foo" exists then "refs/heads/foo/bar" must
<|startcomment|> nit: s/when/whether/ <|endcomment|>  /** * Initialize a new reference database at this location. * * @throws java.io.IOException * the database could not be created. */ public abstract void create() throws IOException; /** * Close any resources held by this database. */ public abstract void close(); /** * With versioning, each reference has a version number that increases on * update. * <|startfocus|> * @return true when the implementation assigns version numbers to <|endfocus|> * references. * @since 5.3 */ public abstract boolean hasVersioning(); /** * Determine if a proposed reference name overlaps with an existing one. * <p> * Reference names use '/' as a component separator, and may be stored in a * hierarchical storage such as a directory on the local filesystem. * <p> * If the reference "refs/heads/foo" exists then "refs/heads/foo/bar" must
<|startcomment|> optional: may be easier to avoid the temporary variable: ref = block.readRef(minUpdateIndex + ...); <|endcomment|>  return false; } else if (!block.next()) { long pos = block.endPosition(); if (pos >= scanEnd) { return false; } block = readBlock(pos, scanEnd); continue; } block.parseKey(); if (match != null && !block.match(match, prefix)) { block.skipValue(); return false; } <|startfocus|> long updateIndex = minUpdateIndex + block.readUpdateIndexDelta(); ref = block.readRef(updateIndex); <|endfocus|> if (!includeDeletes && wasDeleted()) { continue; } return true; } } @Override public Ref getRef() { return ref; } @Override public void close() { // Do nothing. } } private class LogCursorImpl extends LogCursor { private final long scanEnd; private final byte[] match; private String refName; private long updateIndex; private ReflogEntry entry; BlockReader block; LogCursorImpl(long scanEnd, byte[] match) { this.scanEnd = scanEnd; this.match = match;
<|startcomment|> Likewise. <|endcomment|>  } else if (!block.next()) { long pos; if (blockPos != null) { if (listIdx >= blockPos.size()) { return false; } pos = blockPos.get(listIdx++); } else { pos = block.endPosition(); } if (pos >= scanEnd) { return false; } block = readBlock(pos, scanEnd); continue; } block.parseKey(); <|startfocus|> long updateIndex = minUpdateIndex + block.readUpdateIndexDelta(); ref = block.readRef(updateIndex); <|endfocus|> ObjectId id = ref.getObjectId(); if (id != null && match.equals(id) && (includeDeletes || !wasDeleted())) { return true; } } } @Override public Ref getRef() { return ref; } @Override public void close() { // Do nothing. } } } 
<|startcomment|> I don't know what this means. Perhaps simpler to point to hasVersioning? Should not be used unless the {@code RefDatabase} that instantiated the ref supports versioning (see {@link RefDatabase#hasVersioning}). <|endcomment|>  * name. A number that increases when a reference is updated. * * In case of symbolic references, the update index refers to the update of * the symbolic reference iself (e.g. if HEAD points to master, the HEAD * update index will only increase when HEAD changes, regarless how many * times master is updated). * <|startfocus|> * The update index and its meaning are usually provided by the * {@code RefDatabase} that instantiates the ref. By default this method * throws an {@link UnsupportedOperationException}. Implementors must * overrride it to return a useful value. <|endfocus|> * * @return the update index (i.e. version) of this reference. * @throws UnsupportedOperationException * if the creator of the instance (e.g. {@link RefDatabase}) * doesn't support versioning and doesn't override this method * @since 5.3 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } } 
<|startcomment|> This list is never used (just filled for nothing). <|endcomment|>  protected Object createElementViewerInput() { List<TracePackageTraceElement> traceElements = new ArrayList<>(); for (TmfTraceElement tmfTraceElement : fSelectedTraces) { TracePackageTraceElement traceElement = new TracePackageTraceElement(null, tmfTraceElement); // Trace files <|startfocus|> List<TracePackageElement> children = new ArrayList<>(); <|endfocus|> TracePackageFilesElement filesElement = new TracePackageFilesElement(traceElement, tmfTraceElement.getResource()); filesElement.setChecked(true); children.add(filesElement); // Supplementary files try { String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); List<TracePackageElement> suppFilesChildren = new ArrayList<>(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) {
<|startcomment|> Does not export files in .properties if there are no other supplementary resources. <|endcomment|>  filesElement.setChecked(true); children.add(filesElement); // Supplementary files try { String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); List<TracePackageElement> suppFilesChildren = new ArrayList<>(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { <|startfocus|> String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); <|endfocus|> } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString();
<|startcomment|> Use the supplementary folder. <|endcomment|>  // Supplementary files try { String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); List<TracePackageElement> suppFilesChildren = new ArrayList<>(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { <|startfocus|> String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); <|endfocus|> } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); }
<|startcomment|> Will throw CoreException if the properties folder does not exist. <|endcomment|>  try { String supplementaryFolder = tmfTraceElement.getResource().getPersistentProperty(TmfCommonConstants.TRACE_SUPPLEMENTARY_FOLDER); IResource[] supplementaryResources = tmfTraceElement.getSupplementaryResources(); List<TracePackageElement> suppFilesChildren = new ArrayList<>(); TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { <|startfocus|> String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); <|endfocus|> } } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } catch (CoreException e) {
<|startcomment|> Alignment fail (Oh, the humanity!) <|endcomment|>  TracePackageSupplFilesElement suppFilesElement = new TracePackageSupplFilesElement(traceElement); children.add(suppFilesElement); if (supplementaryResources.length > 0) { IFolder propertiesFolder = ((IFolder) supplementaryResources[0].getParent()).getFolder(TmfCommonConstants.TRACE_PROPERTIES_FOLDER); for (IResource res : propertiesFolder.members()) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); <|startfocus|> } <|endfocus|> } for (IResource res : supplementaryResources) { String name = supplementaryFolder == null ? res.getName() : res.getLocation().makeRelativeTo(new Path(supplementaryFolder)).toString(); suppFilesChildren.add(new TracePackageSupplFileElement(res, name, suppFilesElement)); } } catch (CoreException e) { // Should not happen Activator.getDefault().logError("Error finding supplementary files", e); //$NON-NLS-1$ } // Bookmarks IFile bookmarksFile = tmfTraceElement.getBookmarksFile();
<|startcomment|> stray blank line? <|endcomment|> import java.io.ByteArrayOutputStream; import java.io.IOException; import java.util.ArrayList; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import org.eclipse.jgit.internal.storage.io.BlockSource; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectIdRef; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefComparator; import org.eclipse.jgit.lib.SymbolicRef; import org.junit.Test; public class MergedReftableTest { <|startfocus|> <|endfocus|> @Test public void noTables() throws IOException { MergedReftable mr = merge(new byte[0][]); try (RefCursor rc = mr.allRefs()) { assertFalse(rc.next()); } try (RefCursor rc = mr.seekRef(HEAD)) { assertFalse(rc.next()); } try (RefCursor rc = mr.seekRefsWithPrefix(R_HEADS)) { assertFalse(rc.next()); } } @Test public void oneEmptyTable() throws IOException { MergedReftable mr = merge(write());
<|startcomment|> s/true whether/true if/ or s/true whether/whether/ <|endcomment|>  /** * Initialize a new reference database at this location. * * @throws java.io.IOException * the database could not be created. */ public abstract void create() throws IOException; /** * Close any resources held by this database. */ public abstract void close(); /** * With versioning, each reference has a version number that increases on * update. <|startfocus|> * * @return true whether the implementation assigns update indices to * references. <|endfocus|> * @since 5.3 */ public abstract boolean hasVersioning(); /** * Determine if a proposed reference name overlaps with an existing one. * <p> * Reference names use '/' as a component separator, and may be stored in a * hierarchical storage such as a directory on the local filesystem. * <p> * If the reference "refs/heads/foo" exists then "refs/heads/foo/bar" must
<|startcomment|> Can this default to false? That would make it easier for implementers (since if they don't want to override that default they would have nothing to do). <|endcomment|>  * * @throws java.io.IOException * the database could not be created. */ public abstract void create() throws IOException; /** * Close any resources held by this database. */ public abstract void close(); /** * With versioning, each reference has a version number that increases on * update. * * @return true whether the implementation assigns update indices to * references. * @since 5.3 */ <|startfocus|> public abstract boolean hasVersioning(); <|endfocus|> /** * Determine if a proposed reference name overlaps with an existing one. * <p> * Reference names use '/' as a component separator, and may be stored in a * hierarchical storage such as a directory on the local filesystem. * <p> * If the reference "refs/heads/foo" exists then "refs/heads/foo/bar" must * not exist, as a reference cannot have a value and also be a container for * other references at the same time.
<|startcomment|> unbalanced parens <|endcomment|>  * * With symbolic references, the update index refers to updates of the * symbolic reference itself. For example, if HEAD points to * refs/heads/master, then the update index for exactRef("HEAD") will only * increase when HEAD changes to point to another ref, regardless of how * many times refs/heads/master is updated. * * Should not be used unless the {@code RefDatabase} that instantiated the <|startfocus|> * ref supports versioning (see {@link RefDatabase#hasVersioning()} <|endfocus|> * * @return the update index (i.e. version) of this reference. * @throws UnsupportedOperationException * if the creator of the instance (e.g. {@link RefDatabase}) * doesn't support versioning and doesn't override this method * @since 5.3 */ default long getUpdateIndex() { throw new UnsupportedOperationException(); } } 
<|startcomment|> optional: add a link to Ref#getUpdateIndex somewhere? <|endcomment|>  * references. */ public static final String ALL = "";//$NON-NLS-1$ /** * Initialize a new reference database at this location. * * @throws java.io.IOException * the database could not be created. */ public abstract void create() throws IOException; /** * Close any resources held by this database. */ public abstract void close(); /** * With versioning, each reference has a version number that increases on <|startfocus|> * update. * <p> <|endfocus|> * @implSpec This method returns false by default. Implementations * supporting versioning must override it to return true. * @return true if the implementation assigns update indices to references. * @since 5.3 */ public boolean hasVersioning() { return false; } /** * Determine if a proposed reference name overlaps with an existing one. * <p> * Reference names use '/' as a component separator, and may be stored in a
<|startcomment|> should use <p> between paragraphs so javadoc can render it correctly. <|endcomment|>  */ boolean isPeeled(); /** * How was this ref obtained? * <p> * The current storage model of a Ref may influence how the ref must be * updated or deleted from the repository. * * @return type of ref. */ @NonNull Storage getStorage(); /** * Indicator of the relative order between updates of a specific reference * name. A number that increases when a reference is updated. <|startfocus|> * <|endfocus|> * With symbolic references, the update index refers to updates of the * symbolic reference itself. For example, if HEAD points to * refs/heads/master, then the update index for exactRef("HEAD") will only * increase when HEAD changes to point to another ref, regardless of how * many times refs/heads/master is updated. * * Should not be used unless the {@code RefDatabase} that instantiated the * ref supports versioning (see {@link RefDatabase#hasVersioning()}) *
<|startcomment|> 2018 <|endcomment|> ***************************************************************************** <|startfocus|> * Copyright (c) 2009, 2017 THALES GLOBAL SERVICES and others. <|endfocus|> * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - initial API and implementation *******************************************************************************/ package org.eclipse.sirius.ui.tools.internal.actions.export; import java.util.Collection; import java.util.Iterator; import java.util.LinkedHashSet; import java.util.Set; import java.util.stream.Collectors; import org.eclipse.emf.ecore.EObject; import org.eclipse.sirius.business.api.dialect.DialectManager; import org.eclipse.sirius.business.api.query.DRepresentationDescriptorQuery; import org.eclipse.sirius.business.api.session.Session; import org.eclipse.sirius.ui.business.api.dialect.DialectUIManager; import org.eclipse.sirius.ui.business.api.dialect.ExportFormat; import org.eclipse.sirius.ui.business.api.dialect.ExportFormat.ExportDocumentFormat; import org.eclipse.sirius.viewpoint.DRepresentationDescriptor; import org.eclipse.sirius.viewpoint.provider.Messages;
<|startcomment|> it now only keep repDesc with representations instead of valid ones <|endcomment|>  public void run() { Collection<DRepresentationDescriptor> repDescriptorsToExport = getRepresentationToExport().stream().filter(Objects::nonNull).collect(Collectors.toList()); <|startfocus|> // keep only the valid representations <|endfocus|> repDescriptorsToExport = repDescriptorsToExport.stream().filter(repDesc -> repDesc.getRepresentation() != null).collect(Collectors.toList()); if (!repDescriptorsToExport.isEmpty()) { DRepresentationDescriptor firstDRepDescriptorToExport = repDescriptorsToExport.iterator().next(); // Make sure the representation is loaded firstDRepDescriptorToExport.getRepresentation(); Session session = getSession(firstDRepDescriptorToExport); if (session != null) { IPath exportPath = getExportPath(firstDRepDescriptorToExport, session); if (exportPath != null) { exportRepresentation(exportPath, repDescriptorsToExport, session); } } } else { MessageDialog.openInformation(Display.getCurrent().getActiveShell(), Messages.ExportRepresentationsAction_noRepresentationsDialog_title, Messages.ExportRepresentationsAction_noRepresentationsDialog_message); }
<|startcomment|> why don't you let this delegate to the new findRef method and remove the implementations in the subclasses ? <|endcomment|>  * * @param name * the name of the reference. May be a short name which must be * searched for using the standard {@link #SEARCH_PATH}. * @return the reference (if it exists); else {@code null}. * @throws IOException * the reference space cannot be accessed. * @deprecated Use {@link #findRef(String)} instead. */ @Deprecated @Nullable <|startfocus|> public abstract Ref getRef(String name) throws IOException; <|endfocus|> /** * Read a single reference. * <p> * Aside from taking advantage of {@link #SEARCH_PATH}, this method may be * able to more quickly resolve a single reference name than obtaining the * complete namespace by {@code getRefs(ALL).get(name)}. * <p> * To read a specific reference without using @{link #SEARCH_PATH}, see * {@link #exactRef(String)}. * * @param name * the name of the reference. May be a short name which must be
<|startcomment|> Previous code was using a Collections.unmodifiableSet(). Any reason to relax that condition? (And if it is immutable, maybe it should be mentioned also in its javadoc) <|endcomment|>  public static FirstCommand fromLine(String line) { int nul = line.indexOf('\0'); if (nul < 0) { return new FirstCommand(line, emptySet()); } Set<String> opts = asList(line.substring(nul + 1).split(" ")) //$NON-NLS-1$ .stream() .collect(toSet()); <|startfocus|> return new FirstCommand(line.substring(0, nul), opts); <|endfocus|>
<|startcomment|> You can't move this to the first place and return. On Linux/Mac "device" part is always null. <|endcomment|>  protected IResource getResource(IPath path) { if (path != null) { IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); <|startfocus|> if (path.getDevice() == null) { // search relative to the workspace if no device present return root.findMember(path); } <|endfocus|> IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (!"jar".equalsIgnoreCase(path.getFileExtension())) { //$NON-NLS-1$ IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } } return null;
<|startcomment|> What if file extension == jar ? <|endcomment|>  protected IResource getResource(IPath path) { if (path != null) { IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); if (path.getDevice() == null) { // search relative to the workspace if no device present return root.findMember(path); } IFile file = root.getFileForLocation(path); if (file != null) { return file; } <|startfocus|> if (!"jar".equalsIgnoreCase(path.getFileExtension())) { //$NON-NLS-1$ <|endfocus|> IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } } return null;
<|startcomment|> Question: why return here? If the path is not found, can't you use findFiles/findContainers? Please note that this "find" should go *below* the if block, because the "if" will work for Windows OR relative paths only. <|endcomment|>  IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); // look for files or folders with the given path IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (getType() != ARCHIVE) { IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } if (path.getDevice() == null) { // search relative to the workspace if no device present return root.findMember(path); <|startfocus|> } <|endfocus|> } return null;
<|startcomment|> static inner class <|endcomment|>  } } static int read(ReadableChannel rc, ByteBuffer buf) throws IOException { int n; do { n = rc.read(buf); } while (0 < n && buf.hasRemaining()); return buf.position(); } static long elapsedMicros(long start) { return (System.nanoTime() - start) / 1000L; } /** * A supplier of readable channel that opens the channel lazily. */ <|startfocus|> private class LazyChannel implements AutoCloseable, DfsBlockCache.ReadableChannelSupplier { final DfsReader ctx; ReadableChannel rc = null; <|endfocus|> LazyChannel(DfsReader ctx) { this.ctx = ctx; } @Override public ReadableChannel get() throws IOException { if (rc == null) { synchronized (this) { if (rc == null) { rc = ctx.db.openFile(desc, ext); } } } return rc; } @Override public void close() throws IOException { if (rc != null) { rc.close(); } } } } 
<|startcomment|> Shouldn't we return here is status != OK ? <|endcomment|> import org.eclipse.osgi.util.NLS; final public class ChecksumVerifier extends MessageDigestProcessingStep { private String expectedChecksum; final private String algorithmName; final private String algorithmId; // public to access from tests public ChecksumVerifier(String digestAlgorithm, String algorithmId) { this.algorithmName = digestAlgorithm; this.algorithmId = algorithmId; basicInitialize(null); } @Override public final void initialize(IProvisioningAgent agent, IProcessingStepDescriptor descriptor, IArtifactDescriptor context) { super.initialize(agent, descriptor, context); <|startfocus|> basicInitialize(descriptor); <|endfocus|> String data = descriptor.getData(); if (IArtifactDescriptor.DOWNLOAD_CHECKSUM.concat(".").concat(algorithmId).equals(data)) //$NON-NLS-1$ expectedChecksum = ChecksumHelper.getChecksums(context, IArtifactDescriptor.DOWNLOAD_CHECKSUM).get(algorithmId); else if (IArtifactDescriptor.ARTIFACT_CHECKSUM.concat(".").concat(algorithmId).equals(data)) //$NON-NLS-1$ expectedChecksum = ChecksumHelper.getChecksums(context, IArtifactDescriptor.ARTIFACT_CHECKSUM).get(algorithmId); else expectedChecksum = data; if (ofNullable(expectedChecksum).orElse("").isEmpty()) { //$NON-NLS-1$
<|startcomment|> For new code I would call it builder instead of buffer. <|endcomment|>  private static String selectionToString(Table table) { <|startfocus|> StringBuilder buffer = new StringBuilder(); <|endfocus|> for (TableItem tableItem : table.getSelection()) { if (buffer.length() > 0) { buffer.append(System.lineSeparator()); } for (int column = 0; column < table.getColumnCount(); column++) { if (column > 0) { buffer.append('\t'); } buffer.append(tableItem.getText(column)); } } return buffer.toString();
<|startcomment|> Why do we save within the loop? Wouldn't it make sense to only save once after the loop? <|endcomment|>  sessionId.toAPI(), userId.toAPI()); authorizationService.checkProjectAdminAccess( sessionId.toAPI(), null, ESProjectAdminPrivileges.DeleteOrgUnit); ACUser userToDelete = null; for (final Iterator<ACUser> iter = getUsers().iterator(); iter.hasNext();) { final ACUser user = iter.next(); /* check if we were created by the deleted user */ if (user.getCreatedBy() != null && user.getCreatedBy().equals(userId.getId())) { user.setCreatedBy(null); <|startfocus|> save(); <|endfocus|> } /* check if we are the deleted user */ if (user.getId().equals(userId)) { userToDelete = user; } } for (final ACGroup group : getGroups()) { if (group.getCreatedBy() != null && group.getCreatedBy().equals(userId.getId())) { group.setCreatedBy(null); save(); } } /* perform deletion */ if (userToDelete != null) { final List<ACGroup> groups = getGroups(sessionId, userId);
<|startcomment|> Same question <|endcomment|>  if (user.getCreatedBy() != null && user.getCreatedBy().equals(userId.getId())) { user.setCreatedBy(null); save(); } /* check if we are the deleted user */ if (user.getId().equals(userId)) { userToDelete = user; } } for (final ACGroup group : getGroups()) { if (group.getCreatedBy() != null && group.getCreatedBy().equals(userId.getId())) { group.setCreatedBy(null); <|startfocus|> save(); <|endfocus|> } } /* perform deletion */ if (userToDelete != null) { final List<ACGroup> groups = getGroups(sessionId, userId); for (final ACGroup acGroup : groups) { removeMember(sessionId, acGroup.getId(), userId); } getAccessControl().getOrgUnitProviderService().removeUser(userToDelete.toAPI()); // TODO: move ecore delete into ServerSpace#deleteUser implementation EcoreUtil.delete(userToDelete); save(); } } /** * {@inheritDoc} */
<|startcomment|> We could break here (applies to findGroup as well) <|endcomment|>  /* act */ adminBroker2.deleteUser(createdUser1.getId()); /* assert */ assertEquals(initialSize - 1, adminBroker.getUsers().size()); assertNull(findUser(USER_NAME_2).getCreatedBy()); } private ACUser findUser(String name) throws ESException { ACUser result = null; for (final ACUser user : adminBroker.getUsers()) { if (user.getName().equals(name)) { <|startfocus|> result = user; <|endfocus|> } } return result; } private ACGroup findGroup(String name) throws ESException { ACGroup result = null; for (final ACGroup group : adminBroker.getGroups()) { if (group.getName().equals(name)) { result = group; } } return result; } @Test(expected = AccessControlException.class) public void testLoginOfCreatedUserWithNoPasswordSet() throws ESException { adminBroker.createUser(USER_NAME); ACUser user = null; for (final ACUser u : adminBroker.getUsers()) { if (u.getName().equals(USER_NAME)) { user = u; } }
<|startcomment|> Only project admins? <|endcomment|>  throw new StorageException(StorageException.NOSAVE, e); } } private void checkForNulls(Object... objects) throws InvalidInputException { for (final Object obj : objects) { if (obj == null) { throw new InvalidInputException(); } } } private <T extends ACOrgUnit<?>> List<T> removeInvisibleOrgUnits(List<T> orgUnits, ESSessionId sessionId) throws AccessControlException { /* <|startfocus|> * regular users can't see any orgunits, while server admins can see all of them. Only server admins have <|endfocus|> * reduced visibility. */ final ESOrgUnitId adminId = getAccessControl().getSessions().resolveToOrgUnitId(sessionId); final Optional<ACOrgUnit<?>> orgUnit = ACHelper.getOrgUnit( getAccessControl().getOrgUnitProviderService(), adminId); if (!orgUnit.isPresent()) { return orgUnits; } final List<Role> allRolesOfAdmin = ACHelper.getAllRoles( getAccessControl().getOrgUnitResolverServive(), orgUnit.get()); if (Iterables.any(allRolesOfAdmin, new HasRolePredicate(ServerAdmin.class))) { return orgUnits; }
<|startcomment|> Outdated header <|endcomment|> ***************************************************************************** * Copyright (c) 2011-2014 EclipseSource Muenchen GmbH and others. * * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: <|startfocus|> * Edgar Mueller - initial API and implementation <|endfocus|> ******************************************************************************/ package org.eclipse.emf.emfstore.server.accesscontrol.test; import static org.eclipse.emf.emfstore.client.test.common.util.ProjectUtil.share; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertTrue; import static org.junit.Assert.fail; import java.util.Arrays; import java.util.LinkedHashSet; import java.util.List; import java.util.Set; import org.eclipse.emf.emfstore.client.ESUsersession; import org.eclipse.emf.emfstore.client.test.common.dsl.Roles; import org.eclipse.emf.emfstore.client.test.common.util.ServerUtil; import org.eclipse.emf.emfstore.internal.server.model.accesscontrol.ACGroup; import org.eclipse.emf.emfstore.internal.server.model.accesscontrol.ACOrgUnit;
<|startcomment|> Why is this change necessary? <|endcomment|>  getAdminBroker().addMember(group, otherGroup); getAdminBroker().addMember(otherGroup, newUser); ProjectUtil.share(getUsersession(), getLocalProject()); final ProjectSpace clonedProjectSpace = cloneProjectSpace(getProjectSpace()); ProjectUtil.share(getSuperUsersession(), clonedProjectSpace.toAPI()); <|startfocus|> getAdminBroker().changeRole(getProjectSpace().getProjectId(), group, Roles.writer()); getAdminBroker().changeRole(getProjectSpace().getProjectId(), otherGroup, Roles.writer()); final int oldSize = getAdminBroker().getGroups().size(); <|endfocus|> getAdminBroker().deleteGroup(group); assertEquals(oldSize - 1, getAdminBroker().getGroups().size()); } /** * @throws ESException */ @Test public void deleteUser() throws ESException { makeUserPA(); final ACOrgUnitId newUser = ServerUtil.createUser(getSuperUsersession(), getNewUsername()); final ACOrgUnitId group = ServerUtil.createGroup(getSuperUsersession(), getNewGroupName()); final ACOrgUnitId otherGroup = ServerUtil.createGroup(getSuperUsersession(), getNewOtherGroupName());
<|startcomment|> Remove m_messageHandler member, I think it's not necessary <|endcomment|> import org.junit.runners.Parameterized.Parameters; import org.mockito.ArgumentCaptor; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @RunWith(ParameterizedPlatformTestRunner.class) public class JmsMomImplementorTest { private static final Logger LOG = LoggerFactory.getLogger(JmsMomImplementorTest.class); @ClassRule public static final ArtemisJmsBrokerTestRule ARTEMIS_RULE = new ArtemisJmsBrokerTestRule(); private IBean<? extends JmsTestMom> m_momBean; private IBean<? extends IJmsMessageHandler> m_messageHandlerBean; <|startfocus|> private IJmsMessageHandler m_messageHandler; <|endfocus|> private List<IDisposable> m_disposables; private String m_testJobExecutionHint; @Rule public TestName m_testName = new TestName(); public long m_t0; private static final AtomicInteger MOM_COUNTER = new AtomicInteger(0); @Parameters public static List<IScoutTestParameter> getParameters() { List<IScoutTestParameter> parametersList = new LinkedList<IScoutTestParameter>(); // We do not need jmx for unit testing. Also we must disable watchTopicAdvisories else some concurrent issues with broker recreation will happen
<|startcomment|> Like above -> uninstallTestMessagehandler() <|endcomment|>  try { Jobs.getJobManager().awaitDone(testJobsFilter, 10, TimeUnit.SECONDS); LOG.info("All jobs have finished after {} ms", StringUtility.formatNanos(System.nanoTime() - t0)); } catch (TimedOutError e) { LOG.warn("Some cancelled jobs are still running after {} ms! Please check their implementation.", StringUtility.formatNanos(System.nanoTime() - t0)); } } <|startfocus|> BeanTestingHelper.get().unregisterBean(m_messageHandlerBean); m_messageHandlerBean = null; <|endfocus|> uninstallTestMom(); // ensure activeMQ is stopped BrokerService brokerService = BrokerRegistry.getInstance().findFirst(); if (brokerService != null) { brokerService.stop(); brokerService.waitUntilStopped(); } LOG.info("Finished test in {} ms", StringUtility.formatNanos(System.nanoTime() - m_t0)); LOG.info("</{}>", m_testName.getMethodName()); } @Test @NonParameterized public void testInstanceScoped() { JmsMomImplementor mom1 = BEANS.get(JmsMomImplementor.class);
<|startcomment|> Could these static methods be of use for other tests? If yes, make public or protected. <|endcomment|>  } })); // Initiate 'request-reply' communication final String request = "hello world"; String testee = MOM.request(JmsTestMom.class, queue, request); // Verify final String expectedReply = "HELLO WORLD"; assertEquals(expectedReply, testee); IMarshaller marshaller = BEANS.get(CONFIG.getPropertyValue(DefaultMarshallerProperty.class)); verifyRequestReplyMessageLogger(queue, marshaller, request, expectedReply); } <|startfocus|> private static <DTO> void verifyRequestReplyMessageLogger(IDestination<DTO> expectedDestination, IMarshaller marshaller, DTO expectedRequest, DTO expectedReply) { <|endfocus|> verify(BEANS.get(IJmsMessageHandler.class), times(2)).handleOutgoing(any(), any(), any()); verifyMessageLoggerHandleOutgoingCalled(expectedDestination, marshaller, expectedRequest); verifyMessageLoggerHandleOutgoingCalled(null, marshaller, expectedReply); // "reply" message is sent only with JMS destination (but without a Scout MOM destination) verify(BEANS.get(IJmsMessageHandler.class), times(2)).handleIncoming(eq(expectedDestination), any(), any()); verifyMessageLoggerHandleIncomingCalled(expectedDestination, marshaller, expectedRequest, expectedReply); } 
<|startcomment|> "This" -> "The" <|endcomment|>  * @param properties * the MOM environment properties provided to the JMS implementor * @see org.eclipse.scout.rt.mom.api.IMomImplementor.init(Map<Object, Object>) */ void init(Map<Object, Object> properties); /** * Handles JMS messages consumed by a {@link javax.jms.MessageConsumer}. * <p> * This method is called directly after a JMS message has been received. * <p> <|startfocus|> * This message has not yet been processed (unmarshalled) by the MOM framework. <|endfocus|> */ void handleIncoming(IDestination<?> destination, Message message, IMarshaller marshaller); /** * Handles JMS messages being sent by a {@link javax.jms.MessageProducer}. * <p> * This method is called directly before a JMS message is "sent" by the <i>MessageProducer</i>. "Sent" means that the * <i>send</i> method of the message producer is called. Therefore it is not guaranteed that the time, at which this
<|startcomment|> "This" -> "The" <|endcomment|>  * <p> * This method is called directly before a JMS message is "sent" by the <i>MessageProducer</i>. "Sent" means that the * <i>send</i> method of the message producer is called. Therefore it is not guaranteed that the time, at which this * method is called, is the <i>sent time</i> of the JMS message (e.g. in a transactional context). * <p> <|startfocus|> * This message has already been processed (marshalled) by the MOM framework. <|endfocus|> * * @param destination * the MOM destination this message is being sent to. <b>Attention:</b> This might be <code>null</code> in * case of a 'request-reply' communication, where the reply message is only sent back through the JMS * destination defined by {@link Message#getJMSReplyTo()} (and not through a MOM destination) */ void handleOutgoing(IDestination<?> destination, Message message, IMarshaller marshaller); } 
<|startcomment|> Maybe add "(never <code>null</code>)" or something similar. <|endcomment|>  */ protected Message createMessage(final int messageType, final Session session) throws JMSException { switch (messageType) { case MESSAGE_TYPE_TEXT: return session.createTextMessage(); case MESSAGE_TYPE_BYTES: return session.createBytesMessage(); case MESSAGE_TYPE_NO_PAYLOAD: return session.createMessage(); default: throw new PlatformException("Unsupported message type '{}'", messageType); } } /** <|startfocus|> * @return the writer's {@link IMarshaller} used to transform the transfer object. <|endfocus|> */ public IMarshaller getMarshaller() { return m_marshaller; } /** * Writes the given transfer object, and uses the writer's {@link IMarshaller} to transform the object into its * transport type. * * @see JmsMessageReader#readTransferObject() */ public JmsMessageWriter writeTransferObject(final Object transferObject) throws JMSException { final Object transportObject = m_marshaller.marshall(transferObject, m_marshallerContext); m_marshallerContext.put(CTX_PROP_NULL_OBJECT, Boolean.valueOf(transferObject == null).toString()); 
<|startcomment|> This method is called for all kinds of messages. I would start the documentation with "If the message is a {@link javax.jms.BytesMessage}, ..." to avoid confusion. <|endcomment|>  * Writes the given {@link Map} as message properties. * * @see JmsMessageReader#readContext(String) */ protected JmsMessageWriter writeContext(final String property, final Map<String, String> context) throws JMSException { if (context.isEmpty()) { return this; } final String json = (String) BEANS.get(JsonMarshaller.class).marshall(context, new HashMap<>()); writeProperty(property, json); return this; } /** * Finish writing and get the message. * <p> <|startfocus|> * The {@link javax.jms.BytesMessage}'s message body is put in read-only mode and repositions the stream of bytes to * the beginning. <|endfocus|> * * @return the JMS message in read-only mode * @see BytesMessage#reset() */ public Message build() throws JMSException { writeContext(JMS_PROP_MARSHALLER_CONTEXT, m_marshallerContext); if (m_message instanceof BytesMessage) { ((BytesMessage) m_message).reset(); } return m_message; } /**
<|startcomment|> Add JavaDoc, especially that this never returns null (API). <|endcomment|>  } /** * @return the identifier to name the {@link Connection}. */ protected String computeClientId(final Map<Object, Object> properties) { final String clientId = ObjectUtility.toString(properties.get(JMS_CLIENT_ID)); if (clientId != null) { return clientId; } final String nodeId = BEANS.get(NodeIdentifier.class).get(); return StringUtility.join(" ", m_symbolicName, StringUtility.box("(", nodeId, ")")); } <|startfocus|> <|endfocus|> public IJmsMessageHandler getMessageHandler() { return m_messageHandler; } /** * Exception Handler used in MOM. */ public static class MomExceptionHandler extends ExceptionHandler { } } 
<|startcomment|> Import this static for consistency with the rest of the code base. <|endcomment|>  public class BundleWriterTest extends SampleDataRepositoryTestCase { @Rule public ExpectedException thrown = ExpectedException.none(); @Test public void testEmptyBundleFails() throws Exception { Repository newRepo = createBareRepository(); thrown.expect(TransportException.class); fetchFromBundle(newRepo, new byte[0]); } @Test public void testNonBundleFails() throws Exception { Repository newRepo = createBareRepository(); thrown.expect(TransportException.class); <|startfocus|> fetchFromBundle(newRepo, "Not a bundle file".getBytes(StandardCharsets.UTF_8)); <|endfocus|> } @Test public void testGarbageBundleFails() throws Exception { Repository newRepo = createBareRepository(); thrown.expect(TransportException.class); fetchFromBundle(newRepo, (TransportBundle.V2_BUNDLE_SIGNATURE + '\n' + "Garbage") .getBytes(StandardCharsets.UTF_8)); } @Test public void testWriteSingleRef() throws Exception { // Create a tiny bundle, (well one of) the first commits only final byte[] bundle = makeBundle("refs/heads/firstcommit",
<|startcomment|> if <|endcomment|>  * key is not specified) * @param credentialsProvider * provider to use when querying for signing key credentials (eg. * passphrase) * @throws CanceledException * when signing was canceled (eg., user aborted when entering * passphrase) */ public abstract void sign(@NonNull CommitBuilder commit, String gpgSigningKey, @NonNull PersonIdent committer, CredentialsProvider credentialsProvider) throws CanceledException; /** <|startfocus|> * Indicates is a signing key is available for the specified committer <|endfocus|> * and/or signing key. * * @param gpgSigningKey * the signing key (passed as is to the GPG signing tool) * @param committer * the signing identity (to help with key lookup in case signing * key is not specified) * @param credentialsProvider * provider to use when querying for signing key credentials (eg. * passphrase) * @return <code>true</code> if a signing key is available, * <code>false</code> otherwise * @throws CanceledException
<|startcomment|> I think you mean the ID of the signing key, right ? <|endcomment|>  * passphrase) * @throws CanceledException * when signing was canceled (eg., user aborted when entering * passphrase) */ public abstract void sign(@NonNull CommitBuilder commit, String gpgSigningKey, @NonNull PersonIdent committer, CredentialsProvider credentialsProvider) throws CanceledException; /** * Indicates is a signing key is available for the specified committer * and/or signing key. * * @param gpgSigningKey <|startfocus|> * the signing key (passed as is to the GPG signing tool) <|endfocus|> * @param committer * the signing identity (to help with key lookup in case signing * key is not specified) * @param credentialsProvider * provider to use when querying for signing key credentials (eg. * passphrase) * @return <code>true</code> if a signing key is available, * <code>false</code> otherwise * @throws CanceledException * when signing was canceled (eg., user aborted when entering * passphrase) */ public abstract boolean canLocateSigningKey(String gpgSigningKey,
<|startcomment|> encoding snaffu <|endcomment|>  protected void doSetValue(Object value) { // value = dataType instance <|startfocus|> super.doSetValue(value); // TODO : type r�el de value ? compatibilit� des types ? <|endfocus|> 
<|startcomment|> then why calling the method isActive? <|endcomment|>  * * @author dlecan */ public class RevealElementsAction extends AbstractRevealElementsAction<Object> { /** * Constructor. */ public RevealElementsAction() { super(Messages.RevealOutlineElementsAction_label); } /** * Constructor. * * @param text the label */ public RevealElementsAction(final String text) { super(text); } /** <|startfocus|> * Tests whether the given {@link IDiagramElementEditPart} is hidden. <|endfocus|> * * @param selectedElement * The current selection * @return true if all selected element is hidden hidden. */ public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } /** * Tests whether the given selection is an hidden diagram graphical element. * * @param selectedElements * The current selection
<|startcomment|> are <|endcomment|>  /** * Constructor. */ public RevealElementsAction() { super(Messages.RevealOutlineElementsAction_label); } /** * Constructor. * * @param text the label */ public RevealElementsAction(final String text) { super(text); } /** * Tests whether the given {@link IDiagramElementEditPart} is hidden. * * @param selectedElement * The current selection <|startfocus|> * @return true if all selected element is hidden hidden. <|endfocus|> */ public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } /** * Tests whether the given selection is an hidden diagram graphical element. * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden. */
<|startcomment|> elements <|endcomment|>  /** * Constructor. */ public RevealElementsAction() { super(Messages.RevealOutlineElementsAction_label); } /** * Constructor. * * @param text the label */ public RevealElementsAction(final String text) { super(text); } /** * Tests whether the given {@link IDiagramElementEditPart} is hidden. * * @param selectedElement * The current selection <|startfocus|> * @return true if all selected element is hidden hidden. <|endfocus|> */ public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } /** * Tests whether the given selection is an hidden diagram graphical element. * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden. */
<|startcomment|> hidden <|endcomment|>  /** * Constructor. */ public RevealElementsAction() { super(Messages.RevealOutlineElementsAction_label); } /** * Constructor. * * @param text the label */ public RevealElementsAction(final String text) { super(text); } /** * Tests whether the given {@link IDiagramElementEditPart} is hidden. * * @param selectedElement * The current selection <|startfocus|> * @return true if all selected element is hidden hidden. <|endfocus|> */ public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } /** * Tests whether the given selection is an hidden diagram graphical element. * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden. */
<|startcomment|> then why calling the method isActive? <|endcomment|>  * * @param selectedElement * The current selection * @return true if all selected element is hidden hidden. */ public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } /** <|startfocus|> * Tests whether the given selection is an hidden diagram graphical element. <|endfocus|> * * @param selectedElements * The current selection * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden. */ public static boolean isActive(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) next);
<|startcomment|> are <|endcomment|>  public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } /** * Tests whether the given selection is an hidden diagram graphical element. * * @param selectedElements * The current selection <|startfocus|> * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden. <|endfocus|> */ public static boolean isActive(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) next); } else { result = false; } } return result; } /** * {@inheritDoc} */ @Override
<|startcomment|> have hidden label <|endcomment|>  public static boolean isActive(IDiagramElementEditPart selectedElement) { boolean result = true; DDiagramElement diagramElement = selectedElement.resolveDiagramElement(); if (diagramElement == null) { result = false; } else { result = !diagramElement.isVisible(); } return result; } /** * Tests whether the given selection is an hidden diagram graphical element. * * @param selectedElements * The current selection <|startfocus|> * @return true if all selected elements is kind of IDiagramElementEditPart and has label hidden. <|endfocus|> */ public static boolean isActive(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) next); } else { result = false; } } return result; } /** * {@inheritDoc} */ @Override
<|startcomment|> selectedElement for better readability <|endcomment|>  public static boolean isActive(IStructuredSelection selectedElements) { boolean result = true; final Iterator<?> iterator = selectedElements.iterator(); if (!iterator.hasNext()) { result = false; } while (iterator.hasNext()) { <|startfocus|> final Object next = iterator.next(); if (next instanceof IDiagramElementEditPart) { result = result && isActive((IDiagramElementEditPart) next); <|endfocus|> } else { result = false; } } return result;
<|startcomment|> diagramElement <|endcomment|>  if (vpe instanceof DDiagramElement && this.selection instanceof DiagramOutlinePage.TreeSelectionWrapper) { final DiagramOutlinePage.TreeSelectionWrapper wrapper = (DiagramOutlinePage.TreeSelectionWrapper) this.selection; final RootEditPart root = wrapper.getRoot(); final DDiagramEditor diagramEditor = (DDiagramEditor) wrapper.getViewer().getProperty(DDiagramEditor.EDITOR_ID); runRevealCommand(root, diagramEditor, (DDiagramElement) vpe); } else if (vpe instanceof IDiagramElementEditPart) { <|startfocus|> Optional<DDiagramElement> optional = Optional.of((IGraphicalEditPart) vpe).map(IGraphicalEditPart::resolveSemanticElement).filter(DDiagramElement.class::isInstance) <|endfocus|> .map(DDiagramElement.class::cast); if (optional.isPresent()) { IDiagramElementEditPart diagramElementEditPart = (IDiagramElementEditPart) vpe; SelectionRequest request = new SelectionRequest(); request.setType(RequestConstants.REQ_OPEN); diagramElementEditPart.performRequest(request); } }
<|startcomment|> we could use the one computed before <|endcomment|>  private void runRevealCommand(final RootEditPart root, final DDiagramEditor editor, final DDiagramElement vpe) { final Object adapter = editor.getAdapter(IDiagramCommandFactoryProvider.class); final IDiagramCommandFactoryProvider cmdFactoryProvider = (IDiagramCommandFactoryProvider) adapter; final TransactionalEditingDomain transactionalEditingDomain = TransactionUtil.getEditingDomain(editor.getEditingDomain().getResourceSet()); final IDiagramCommandFactory emfCommandFactory = cmdFactoryProvider.getCommandFactory(transactionalEditingDomain); final Command cmd = emfCommandFactory.buildRevealCommand(vpe); <|startfocus|> final TransactionalEditingDomain domain = TransactionUtil.getEditingDomain(vpe); <|endfocus|> CompoundCommand allInOne = new CompoundCommand(cmd.getLabel()); allInOne.append(cmd); domain.getCommandStack().execute(allInOne);
<|startcomment|> making it <|endcomment|>  * * Contributors: * Obeo - initial API and implementation *******************************************************************************/ package org.eclipse.sirius.diagram.ui.tools.internal.actions.visibility; import org.eclipse.gef.Disposable; import org.eclipse.gmf.runtime.diagram.ui.parts.IDiagramWorkbenchPart; import org.eclipse.jface.action.IAction; import org.eclipse.jface.viewers.ISelection; import org.eclipse.jface.viewers.IStructuredSelection; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.PlatformUI; /** <|startfocus|> * Extends the {@link RevealElementsAction} to make it compatible with the tabbar by make it disposable and by handling * the selection changes. <|endfocus|> * * @author fbarbin */ public class TabbarRevealElementsAction extends RevealElementsAction implements Disposable { private IDiagramWorkbenchPart representationPart; /** * Constructor. * * @param text the label */ public TabbarRevealElementsAction(final String text) { super(text); } public void setActionPart(IDiagramWorkbenchPart part) { this.representationPart = part; } @Override public void selectionChanged(IAction action, ISelection s) {
<|startcomment|> then call it label lul <|endcomment|> import org.eclipse.jface.viewers.ISelection; import org.eclipse.jface.viewers.IStructuredSelection; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.PlatformUI; /** * Extends the {@link RevealElementsAction} to make it compatible with the tabbar by make it disposable and by handling * the selection changes. * * @author fbarbin */ public class TabbarRevealElementsAction extends RevealElementsAction implements Disposable { private IDiagramWorkbenchPart representationPart; /** * Constructor. * <|startfocus|> * @param text the label <|endfocus|> */ public TabbarRevealElementsAction(final String text) { super(text); } public void setActionPart(IDiagramWorkbenchPart part) { this.representationPart = part; } @Override public void selectionChanged(IAction action, ISelection s) { IWorkbenchPart selectedPart = PlatformUI.getWorkbench().getActiveWorkbenchWindow().getActivePage().getActivePart(); if (representationPart != null && !representationPart.equals(selectedPart)) { return; } super.selectionChanged(action, s); setEnabled(isEnabled()); } @Override public boolean isEnabled() {
<|startcomment|> to remove <|endcomment|> import org.eclipse.sirius.diagram.ui.tools.internal.actions.visibility.RevealElementsAction; /** * Tester to know if all selected elements can be revealed and are not visible. * * @author fbarbin * */ public class CanShowElementTester extends PropertyTester { <|startfocus|> /** * {@inheritDoc} * * @see org.eclipse.core.expressions.IPropertyTester#test(java.lang.Object, java.lang.String, java.lang.Object[], * java.lang.Object) */ <|endfocus|> @Override public boolean test(Object receiver, String property, Object[] args, Object expectedValue) { boolean result = false; if ("canShowElement".equals(property)) { //$NON-NLS-1$ if (receiver instanceof IStructuredSelection) { result = RevealElementsAction.isActive((IStructuredSelection) receiver); } else if (receiver instanceof IDiagramElementEditPart) { result = RevealElementsAction.isActive((IDiagramElementEditPart) receiver); } } return result; } } 
<|startcomment|> to update. <|endcomment|>  activateShowHideModeUsingTabbar(); SWTBotGefEditPart swtBotEditPart = getEditPart("new EClass 4", DNodeNameEditPart.class); hideShow(element, swtBotEditPart, true); } /** * Make a double click on the diagram element and verifies it is hidden. And do a double click again and verifies it * is shown again. * * @param element <|startfocus|> * element to double click <|endfocus|> * @param swtBotEditPart * the corresponding part. */ private void hideShow(DDiagramElement element, SWTBotGefEditPart swtBotEditPart, boolean isLabelHidden) { int count = 1; if (!isLabelHidden) { count = 3; } for (int i = 1; i <= count; i++) { editor.reveal(swtBotEditPart.part()); OperationDoneCondition done = new OperationDoneCondition(); performHideReveal(swtBotEditPart, i, "Hide element"); bot.waitUntil(done); SWTBotUtils.waitAllUiEvents(); if (isLabelHidden) {
<|startcomment|> for each action? <|endcomment|>  bot.waitUntil(done); SWTBotUtils.waitAllUiEvents(); if (isLabelHidden) { assertFalse("The node should not have its label filtered.", element.getGraphicalFilters().stream().anyMatch(HideLabelFilter.class::isInstance)); } else { assertFalse("The node should not be filtered.", element.getGraphicalFilters().stream().anyMatch(HideFilter.class::isInstance)); } } } /** <|startfocus|> * We perform the Show / Hide from each actions according to the i argument: <|endfocus|> * <ul> * <li>Double-click</li> * <li>Contextual menu action</li> * <li>Tabbar action</li> * </ul> * * @param swtBotEditPart * the selected edit part. * @param i * the action to perform: a double click, contextual menu or tabbar. * @param toolTip * the tooltip of the action to perform: Show element or Hide element. */ private void performHideReveal(SWTBotGefEditPart swtBotEditPart, int i, String toolTip) { switch (i) {
<|startcomment|> input could be a standard String <|endcomment|>  pattern.setValue("yyyy/yyyy"); input.setValue("2018/2019"); new SimpleDateFormat(pattern.getValue()).parse(input.getValue()); ScoutAssert.assertThrows(ParseException.class, () -> new StrictSimpleDateFormat(pattern.getValue()).parse(input.getValue())); } @Test public void testJavaScriptJsonString() throws ParseException { <|startfocus|> StringHolder pattern = new StringHolder(); StringHolder input = new StringHolder("2019-01-18T12:42:03.409Z"); <|endfocus|> pattern.setValue(IValueFormatConstants.DEFAULT_DATE_PATTERN); ScoutAssert.assertThrows(ParseException.class, () -> new SimpleDateFormat(pattern.getValue()).parse(input.getValue())); ScoutAssert.assertThrows(ParseException.class, () -> new StrictSimpleDateFormat(pattern.getValue()).parse(input.getValue())); pattern.setValue(IValueFormatConstants.TIMESTAMP_PATTERN); ScoutAssert.assertThrows(ParseException.class, () -> new SimpleDateFormat(pattern.getValue()).parse(input.getValue())); ScoutAssert.assertThrows(ParseException.class, () -> new StrictSimpleDateFormat(pattern.getValue()).parse(input.getValue())); 
<|startcomment|> nit: unnecessary blank line <|endcomment|>  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. */ package org.eclipse.jgit.lib; import static java.util.stream.Collectors.toList; import java.io.IOException; import java.util.ArrayList; import java.util.Collection; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; <|startfocus|> <|endfocus|> import java.util.Set; import java.util.stream.Collectors; import org.eclipse.jgit.annotations.NonNull; import org.eclipse.jgit.annotations.Nullable; /** * Abstraction of name to {@link org.eclipse.jgit.lib.ObjectId} mapping. * <p> * A reference database stores a mapping of reference names to * {@link org.eclipse.jgit.lib.ObjectId}. Every * {@link org.eclipse.jgit.lib.Repository} has a single reference database, * mapping names to the tips of the object graph contained by the
<|startcomment|> of <|endcomment|>  * the reference space cannot be accessed. * @since 5.2 */ @NonNull public List<Ref> getRefsByPrefix(String... prefixes) throws IOException { List<Ref> result = new ArrayList<>(); for (String prefix : prefixes) { result.addAll(getRefsByPrefix(prefix)); } return Collections.unmodifiableList(result); } /** * Returns all refs that resolve directly to the given {@link ObjectId}. <|startfocus|> * Includes peeled {@linkObjectId}s. This is the inverse lookup if <|endfocus|> * {@link #exactRef(String...)}. * * <p> * The default implementation uses a linear scan. Implementors of * {@link RefDatabase} should override this method directly if a better * implementation is possible. * * @param id * {@link ObjectId} to resolve * @return a {@link Set} of {@link Ref}s whose tip points to the provided * id. * @throws java.io.IOException * the reference space cannot be accessed.
<|startcomment|> whose tips point <|endcomment|>  * Includes peeled {@linkObjectId}s. This is the inverse lookup if * {@link #exactRef(String...)}. * * <p> * The default implementation uses a linear scan. Implementors of * {@link RefDatabase} should override this method directly if a better * implementation is possible. * * @param id * {@link ObjectId} to resolve <|startfocus|> * @return a {@link Set} of {@link Ref}s whose tip points to the provided <|endfocus|> * id. * @throws java.io.IOException * the reference space cannot be accessed. * @since 5.3 */ @NonNull public Set<Ref> resolveTipSha1(ObjectId id) throws IOException { return getRefs().stream() .filter(r -> id.equals(r.getObjectId()) || id.equals(r.getPeeledObjectId())) .collect(Collectors.toSet()); } /** * Check if any refs exist in the ref database. * <p>
<|startcomment|> nit: import toSet static for consistency with toList (see L46). <|endcomment|>  * @return a {@link Set} of {@link Ref}s whose tip points to the provided * id. * @throws java.io.IOException * the reference space cannot be accessed. * @since 5.3 */ @NonNull public Set<Ref> resolveTipSha1(ObjectId id) throws IOException { <|startfocus|> return getRefs().stream() .filter(r -> id.equals(r.getObjectId()) || id.equals(r.getPeeledObjectId())) .collect(Collectors.toSet()); <|endfocus|> } /** * Check if any refs exist in the ref database. * <p> * This uses the same definition of refs as {@link #getRefs()}. In * particular, returns {@code false} in a new repository with no refs * under {@code refs/} and {@code HEAD} pointing to a branch yet to be * born, and returns {@code true} in a repository with no refs under * {@code refs/} and a detached {@code HEAD} pointing to history. *
<|startcomment|> Not used <|endcomment|>  *******************************************************************************/ package org.eclipse.tracecompass.analysis.os.linux.core.inputoutput; import org.eclipse.jdt.annotation.Nullable; import org.eclipse.osgi.util.NLS; /** * Externalized message strings from the I/O Analysis * * @author Houssem Daoud */ public class Messages extends NLS { private static final String BUNDLE_NAME = "org.eclipse.linuxtools.lttng2.kernel.core.inputoutput.analysis.messages"; //$NON-NLS-1$ <|startfocus|> /** Help text for the Data provider */ public static @Nullable String DisksIODataProviderFactory_helpText; <|endfocus|> /** Help text for the IO analysis */ public static @Nullable String LttngInputOutputModule_Help; static { // initialize resource bundle NLS.initializeMessages(BUNDLE_NAME, Messages.class); } private Messages() { } } 
<|startcomment|> doc <|endcomment|>  * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.analysis.os.linux.core.threadstatus; import org.eclipse.osgi.util.NLS; /** * Externalized Strings for the {@link ThreadStatusDataProvider} package */ class Messages extends NLS { private static final String BUNDLE_NAME = "org.eclipse.tracecompass.internal.analysis.os.linux.core.threadstatus.messages"; //$NON-NLS-1$ /** attribute cpu name */ public static String ThreadStatusDataProvider_attributeCpuName; <|startfocus|> /** */ <|endfocus|> public static String ThreadStatusDataProviderFactory_title; /** * DataProvider help text */ public static String ThreadStatusDataProviderFactory_descriptionText; static { // initialize resource bundle NLS.initializeMessages(BUNDLE_NAME, Messages.class); } private Messages() { } } 
<|startcomment|> Should work, but we need to be sure that the client and the server are encoding/decoding correctly <|endcomment|>  List<IDataProviderDescriptor> descriptors = new ArrayList<>(); Set<String> existingModules = new HashSet<>(); for (ISegmentStoreProvider module : modules) { IAnalysisModule analysis = (IAnalysisModule) module; // Only add analysis once per trace (which could be an experiment) if (!existingModules.contains(analysis.getId())) { DataProviderDescriptor.Builder builder = new DataProviderDescriptor.Builder(); <|startfocus|> builder.setId(SegmentStoreScatterDataProvider.ID + ':' + analysis.getId()) // TODO check if colon works in the URL <|endfocus|> .setName(Objects.requireNonNull(NLS.bind(Messages.SegmentStoreScatterGraphDataProvider_title, analysis.getName()))) .setDescription(Objects.requireNonNull(NLS.bind(Messages.SegmentStoreScatterGraphDataProvider_description, analysis.getName()))) .setProviderType(ProviderType.TREE_TIME_XY); descriptors.add(builder.build()); } } return descriptors;
<|startcomment|> let's not modify this. looks like the classes that use this method implement buffered writing <|endcomment|>  return Status.OK_STATUS; } public File getPath() { return path; } public boolean isDirty() { return false; } public InputStream read(String item, IProgressMonitor monitor) throws IOException { File file = getFile(item); return new FileInputStream(file); } public void release() { store.release(this); } public OutputStream write(String item, IProgressMonitor monitor) throws IOException { File file = getFile(item); <|startfocus|> return new BufferedOutputStream(new FileOutputStream(file)); <|endfocus|> } private File getFile(String item) { File file = new File(path, item); if (!file.getParentFile().exists()) { file.getParentFile().mkdirs(); } return file; } } 
<|startcomment|> let's revert this to a state before the initial commit, so it is not part of the review <|endcomment|>  * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Tasktop Technologies - initial API and implementation *******************************************************************************/ package org.eclipse.mylyn.monitor.core; import java.io.File; import java.io.FileOutputStream; import java.io.IOException; import org.eclipse.core.runtime.IStatus; import org.eclipse.core.runtime.Status; import org.eclipse.mylyn.commons.core.StatusHandler; import org.eclipse.mylyn.internal.monitor.core.IMonitorCoreConstants; /** * Used for logging interaction events. <|startfocus|> * <|endfocus|> * @author Mik Kersten * @since 2.0 */ public abstract class AbstractMonitorLog { protected File outputFile; protected FileOutputStream outputStream; protected boolean started = false; public AbstractMonitorLog() { super(); } public void startMonitoring() { synchronized (this) { if (started) { return; } else { started = true; } } try { if (!outputFile.exists()) { outputFile.createNewFile(); } outputStream = new FileOutputStream(outputFile, true); } catch (Exception e) {
<|startcomment|> 74-75 this can be just one try for both resources <|endcomment|>  if (!destinationFile.exists()) { destinationFile.mkdirs(); } while (entries.hasMoreElements()) { ZipEntry entry = entries.nextElement(); File outputFile = new File(destinationFile, entry.getName()); if (entry.isDirectory() && !outputFile.exists()) { outputFile.mkdirs(); continue; } if (!outputFile.getParentFile().exists()) { outputFile.getParentFile().mkdirs(); } <|startfocus|> try (InputStream inputStream = new BufferedInputStream(zipFile.getInputStream(entry))) { try (OutputStream outStream = new BufferedOutputStream(new FileOutputStream(outputFile))) { copyStream(inputStream, outStream); } <|endfocus|> } outputFiles.add(outputFile); if (monitor != null) { monitor.worked(1); } } return outputFiles; } } private static void copyStream(InputStream in, OutputStream out) throws IOException { Assert.isNotNull(in); Assert.isNotNull(out); byte[] buffer = new byte[4096]; int readCount;
<|startcomment|> please replace the file with the original version (from before modifications were made). this file should not be part of the review <|endcomment|>  private final CommonStore store; public CommonStorable(CommonStore store, File path) { this.store = store; this.path = path; } public void delete(String item) throws CoreException { getFile(item).delete(); } public void deleteAll() throws CoreException { File[] children = path.listFiles(); if (children != null) { // validate for (File child : children) { if (child.isDirectory()) { <|startfocus|> throw new CoreException(new Status(IStatus.ERROR, CommonsCorePlugin.ID_PLUGIN, NLS.bind("The storage location ''{0}'' contains sub directories", path))); //$NON-NLS-1$ <|endfocus|> } } // delete all files for (File child : children) { child.delete(); } } if (path.exists()) { path.delete(); } } public boolean exists(String handle) { if (!path.exists()) { return false; } return getFile(handle).exists(); } public IStatus flush() { return Status.OK_STATUS; } 
<|startcomment|> wrap FileOutputStream in BufferedOutputStream <|endcomment|>  public static void createZipFile(File zipFile, List<File> files, String rootPath, IProgressMonitor monitor) throws FileNotFoundException, IOException { if (rootPath == null) { rootPath = ""; //$NON-NLS-1$ } else if (!rootPath.endsWith("\\") || !rootPath.endsWith("/")) { //$NON-NLS-1$ //$NON-NLS-2$ rootPath += "/"; //$NON-NLS-1$ } <|startfocus|> try (ZipOutputStream zipOut = new ZipOutputStream(new FileOutputStream(zipFile))) { <|endfocus|> for (File file : files) { try { addZipEntry(zipOut, rootPath, file); if (monitor != null) { monitor.worked(1); } } catch (Exception e) { StatusHandler.log(new Status(IStatus.ERROR, ICommonsCoreConstants.ID_PLUGIN, "Could not add " //$NON-NLS-1$ + file.getName() + " to zip", e)); //$NON-NLS-1$ } } } } /** * @author Shawn Minto */
<|startcomment|> consider using one try block <|endcomment|>  * a path separator character * @return the file path with its separator character changed from the given old separator to the given new * separator */ public static String changeSeparator(String path, char oldSeparator, char newSeparator) { return path.replace(oldSeparator, newSeparator); } /** * Copies the given source file to the given destination file. */ public static void copy(File source, File dest) throws IOException { <|startfocus|> try (InputStream in = new FileInputStream(source)) { try (OutputStream out = new BufferedOutputStream(new FileOutputStream(dest))) { <|endfocus|> transferData(in, out); } } } /** * Copies all files in the current data directory to the specified folder. Will overwrite. */ public static void copyFolder(File sourceFolder, File targetFolder) throws IOException { for (File currFile : sourceFolder.listFiles()) { if (currFile.isFile()) { File destFile = new File(targetFolder, currFile.getName()); copy(currFile, destFile);
<|startcomment|> please replace the file with the original version (from before modifications were made). this file should not be part of the review <|endcomment|>  * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Tasktop Technologies - initial API and implementation *******************************************************************************/ package org.eclipse.mylyn.monitor.core; import java.io.File; import java.io.FileOutputStream; import java.io.IOException; import org.eclipse.core.runtime.IStatus; import org.eclipse.core.runtime.Status; import org.eclipse.mylyn.commons.core.StatusHandler; import org.eclipse.mylyn.internal.monitor.core.IMonitorCoreConstants; /** * Used for logging interaction events. <|startfocus|> * <|endfocus|> * @author Mik Kersten * @since 2.0 */ public abstract class AbstractMonitorLog { protected File outputFile; protected FileOutputStream outputStream; protected boolean started = false; public AbstractMonitorLog() { super(); } public void startMonitoring() { synchronized (this) { if (started) { return; } else { started = true; } } try { if (!outputFile.exists()) { outputFile.createNewFile(); } outputStream = new FileOutputStream(outputFile, true); } catch (Exception e) {
<|startcomment|> ... and here <|endcomment|>  public void dispose() { <|startfocus|> fExpressionHistory.dispose(); fLocalExpressionHistory.clear(); if (fDocumentListener != null && getSourceViewer() != null && getSourceViewer().getDocument() != null) { getSourceViewer().getDocument().removeDocumentListener(fDocumentListener); <|endfocus|> } fListeners.clear(); super.dispose();
<|startcomment|> action <|endcomment|>  DNode element = (DNode) ((Node) part.getModel()).getElement(); assertFalse("The node should not have its label filtered.", element.getGraphicalFilters().stream().anyMatch(HideLabelFilter.class::isInstance)); activateShowHideModeUsingTabbar(); SWTBotGefEditPart swtBotEditPart = getEditPart("new EClass 4", DNodeNameEditPart.class); hideShow(element, swtBotEditPart, true); } /** <|startfocus|> * Performs a hide and show actions on the diagram element by using those three different ways: <|endfocus|> * <ul> * <li>The double-click</li> * <li>The contextual menu action</li> * <li>The tabbar action</li> * </ul> * * @param element * element to hide and reveal * @param swtBotEditPart * the corresponding part. */ private void hideShow(DDiagramElement element, SWTBotGefEditPart swtBotEditPart, boolean isLabelHidden) { int count = 0; if (!isLabelHidden) { count = 2; }
<|startcomment|> Not needed. <|endcomment|>  Diagram data = (Diagram) annotationEntry.getData(); Optional<?> missingNode = data.getChildren().stream().filter(child -> "_Sx9-MCLeEemN0s24dvRntQ".equals(((IdentifiedElement) ((Node) child).getElement()).getUid())).findFirst(); assertFalse("GMF cleaning has not been done while refreshing representation.", missingNode.isPresent()); } <|startfocus|> @Override protected void tearDown() throws Exception { /* Delete the temporary project */ super.tearDown(); } <|endfocus|> } 
<|startcomment|> Convert treeType to TreeType to match coding standard <|endcomment|>  * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Boeing - initial API and implementation *******************************************************************************/ package org.eclipse.osee.framework.jdk.core.type; import java.util.ArrayList; import java.util.Collection; import java.util.List; public class TreeNode<treeType> { private treeType myself; private TreeNode<treeType> parent; private List<TreeNode<treeType>> children; <|startfocus|> protected TreeNode(TreeNode<treeType> parent, treeType myself) { <|endfocus|> this.parent = parent; this.myself = myself; this.children = new ArrayList<>(); } public TreeNode(treeType myself) { this(null, myself); } @SuppressWarnings("null") public TreeNode() { this(null); } public TreeNode<treeType> getParent() { return parent; } public treeType getSelf() { return myself; } public List<TreeNode<treeType>> getChildren() { return children; } 
<|startcomment|> interface <|endcomment|>  import java.util.List; import java.util.Objects; import java.util.function.Function; import java.util.function.Predicate; import org.eclipse.tracecompass.internal.tmf.analysis.xml.core.fsm.model.values.DataDrivenValue; import org.eclipse.tracecompass.internal.tmf.analysis.xml.core.fsm.module.IAnalysisDataContainer; import org.eclipse.tracecompass.statesystem.core.ITmfStateSystem; import org.eclipse.tracecompass.tmf.core.event.ITmfEvent; /** * A data-driven condition. * * @author Geneviève Bastien * @author Florian Wininger */ <|startfocus|> public abstract class DataDrivenCondition implements IDataDrivenRuntimeObject { <|endfocus|> /** * Condition operators used to compare 2 values together */ public enum ConditionOperator implements Predicate<Integer> { /** equal */ EQ(i -> i == 0), /** not equal */ NE(i -> i != 0), /** Greater or equal */ GE(i -> i >= 0), /** Greater than */ GT(i -> i > 0), /** Less or equal */ LE(i -> i <= 0), /** Less than */ LT(i -> i < 0); 
<|startcomment|> This means we will use a weak protocol in case no other protocol is available, right? IMHO we should rather through a fatal exception abort. <|endcomment|>  private static String[] getProtocolsToKeep(final String[] enabledProtocols) { final List<String> remainingProtocols = new ArrayList<String>(); for (final String protocol : enabledProtocols) { if (protocol.equals(SSLV3) || protocol.equals(SSLV2_HELLO)) { continue; } remainingProtocols.add(protocol); } if (remainingProtocols.isEmpty()) { <|startfocus|> /* no other protocol allowed */ return enabledProtocols; <|endfocus|> } return remainingProtocols.toArray(new String[remainingProtocols.size()]);
<|startcomment|> Here we could catch the case if no secure protocol is left. This would force the server to have a secure protocol. Then we would not care what the client wants any more. <|endcomment|>  final SSLContext context = SSLContext.getInstance("TLS"); //$NON-NLS-1$ context.init(ServerKeyStoreManager.getInstance().getKeyManagerFactory().getKeyManagers(), null, null); serverSocketFactory = context.getServerSocketFactory(); } catch (final NoSuchAlgorithmException exception) { shutdown(serverSocketFactory, exception); } catch (final KeyManagementException exception) { shutdown(serverSocketFactory, exception); } catch (final ServerKeyStoreException exception) { shutdown(serverSocketFactory, exception); } <|startfocus|> return disableSSLv3AndReturn(serverSocketFactory.createServerSocket(pPort, backlog, addr)); <|endfocus|> } private void shutdown(SSLServerSocketFactory serverSocketFactory, Exception e) { if (serverSocketFactory == null) { ModelUtil.logException(Messages.XmlRpcBuiltinWebServer_ServerSocketInitFailed, e); EMFStoreController.getInstance().shutdown(new FatalESException()); } } } 
<|startcomment|> Move to fields area? <|endcomment|>  private static final String TAG_SELECTION = "selection"; //$NON-NLS-1$ private static final String TAG_EXPANDED = "expanded"; //$NON-NLS-1$ private static final String TAG_ELEMENT = "element"; //$NON-NLS-1$ private static final String TAG_IS_ENABLED = "isEnabled"; //$NON-NLS-1$ private static final String TAG_PATH = "path"; //$NON-NLS-1$ private static final String TAG_CURRENT_FRAME = "currentFrame"; //$NON-NLS-1$ <|startfocus|> private EmptyWorkspaceHelper emptyWorkspaceHelper; <|endfocus|> private IPartListener partListener = new IPartListener() { @Override public void partActivated(IWorkbenchPart part) { if (part instanceof IEditorPart) { editorActivated((IEditorPart) part); } } @Override public void partBroughtToTop(IWorkbenchPart part) { if (part instanceof IEditorPart) { editorActivated((IEditorPart) part); } } @Override public void partClosed(IWorkbenchPart part) { } @Override public void partDeactivated(IWorkbenchPart part) { } @Override public void partOpened(IWorkbenchPart part) {
<|startcomment|> remove <|endcomment|>  private static final String MEMENTO_REGEXP_FILTER_REGEXP_ATTRIBUTE = "regexp"; //$NON-NLS-1$ private static final String MEMENTO_REGEXP_FILTER_ENABLED_ATTRIBUTE = "enabled"; //$NON-NLS-1$ private int rootMode; /** * Used only in the case of top level = PROJECTS and only when some * working sets are selected. */ private String workingSetLabel; private List<UserFilter> userFilters; <|startfocus|> // private Composite displayArea; <|endfocus|> private EmptyWorkspaceHelper emptyWorkspaceHelper; @Override public void init(IViewSite site, IMemento memento) throws PartInitException { super.init(site, memento); userFilters = new ArrayList<UserFilter>(); if (memento != null) { IMemento[] filters = memento.getChildren(MEMENTO_REGEXP_FILTER_ELEMENT); for (IMemento filterMemento : filters) { String regexp = filterMemento.getString(MEMENTO_REGEXP_FILTER_REGEXP_ATTRIBUTE); Boolean enabled = filterMemento.getBoolean(MEMENTO_REGEXP_FILTER_ENABLED_ATTRIBUTE); userFilters.add(new UserFilter(regexp, enabled)); } } } @Override public void saveState(IMemento aMemento) {
<|startcomment|> remove comment. <|endcomment|>  public void createPartControl(Composite aParent) { <|startfocus|> // displayArea = new Composite(aParent, SWT.NONE); <|endfocus|> emptyWorkspaceHelper = new EmptyWorkspaceHelper(aParent); super.createPartControl(aParent); getCommonViewer().setMapper(new ResourceToItemsMapper(getCommonViewer())); getCommonViewer().setData(NavigatorPlugin.RESOURCE_REGEXP_FILTER_DATA, this.userFilters); if (this.userFilters.stream().anyMatch(UserFilter::isEnabled)) { getCommonViewer().refresh(); }
<|startcomment|> I would sleep better if there was a couple of testcases just for the regex, this would also help to better understand what it does <|endcomment|>  private final Map<EPackage, String> packageToInferedSource = new LinkedHashMap<EPackage, String>(); private final Map<EPackage, Text> packageToSourceText = new LinkedHashMap<EPackage, Text>(); private final Map<EPackage, Text> packageToTargetText = new LinkedHashMap<EPackage, Text>(); private final Map<EPackage, Button> packageToUpdateButton = new LinkedHashMap<EPackage, Button>(); <|startfocus|> private final Pattern VERSION_NUMBER_PATTERN = Pattern.compile("(?<=\\bv?|[-_])\\d+\\b"); //$NON-NLS-1$ <|endfocus|> private final List<EPackage> packages; private final Set<EPackage> changedPackages; /** * Constructs a new {@link ReleaseWizardPage}. * * @param pageName * @param description * @param titleImage * @param packages the packages * @param changedPackages the changed packages */ protected ReleaseWizardPage(String pageName, String description, ImageDescriptor titleImage, List<EPackage> packages, Set<EPackage> changedPackages) { super(pageName, pageName, titleImage); setDescription(description); this.packages = packages;
<|startcomment|> You will hate me, but I meant of course all places where Display.getDefault() is used :) <|endcomment|>  IResourceDelta resourceDelta = event.getDelta(); if (resourceDelta != null) { IResourceDelta[] affectedChildren = resourceDelta.getAffectedChildren(); for (IResourceDelta affectedChildResourceDelta : affectedChildren) { IResource resource = affectedChildResourceDelta.getResource(); int kind = affectedChildResourceDelta.getKind(); if (resource instanceof IProject && (kind == IResourceDelta.ADDED || kind == IResourceDelta.REMOVED)) { PlatformUI.getWorkbench().getDisplay() <|startfocus|> .asyncExec(() -> Display.getDefault().timerExec(200, switchTopControlRunnable)); <|endfocus|> return; } } }
<|startcomment|> this isn't needed on non-API types <|endcomment|>  * contains links to: * <ol> * <li>Project creation wizards specific to the current perspective</li> * <li>The "New Project Wizard" to allow creation of project of any type</li> * </ol> * If no perspective specific project creation wizards are found then a simple * text with a link to the "New Project Wizard" is shown. * * This class also takes care of refreshing these links when the user switches * the perspective. * <|startfocus|> * @since 3.15 * <|endfocus|> */ public final class EmptyWorkspaceHelper implements IResourceChangeListener, IPerspectiveListener, IPropertyChangeListener { private Composite emptyArea; private StackLayout layout; private Control control; private Composite displayArea; private ArrayList<IAction> projectWizardActions = null; private IAction newProjectAction = null; /** * This method should be called at the point in time when the view's controls * are created. * * @param parent The composite where the explanatory text should be put into. */ public EmptyWorkspaceHelper(Composite parent) {
<|startcomment|> Ideally all those interfaces shouldn't be implemented by this class to not expose "unrelated" API to clients, but just use internal anonymous listeners to do the same. <|endcomment|>  * <li>The "New Project Wizard" to allow creation of project of any type</li> * </ol> * If no perspective specific project creation wizards are found then a simple * text with a link to the "New Project Wizard" is shown. * * This class also takes care of refreshing these links when the user switches * the perspective. * * @since 3.15 * */ <|startfocus|> public final class EmptyWorkspaceHelper implements IResourceChangeListener, IPerspectiveListener, IPropertyChangeListener { <|endfocus|> private Composite emptyArea; private StackLayout layout; private Control control; private Composite displayArea; private ArrayList<IAction> projectWizardActions = null; private IAction newProjectAction = null; /** * This method should be called at the point in time when the view's controls * are created. * * @param parent The composite where the explanatory text should be put into. */ public EmptyWorkspaceHelper(Composite parent) { displayArea = parent; layout = new StackLayout(); displayArea.setLayout(layout); createEmptyArea(displayArea); 
<|startcomment|> In Java (in contrast to C/C++) we don't need to set defaults on fields. <|endcomment|>  * If no perspective specific project creation wizards are found then a simple * text with a link to the "New Project Wizard" is shown. * * This class also takes care of refreshing these links when the user switches * the perspective. * * @since 3.15 * */ public final class EmptyWorkspaceHelper implements IResourceChangeListener, IPerspectiveListener, IPropertyChangeListener { private Composite emptyArea; private StackLayout layout; private Control control; private Composite displayArea; <|startfocus|> private ArrayList<IAction> projectWizardActions = null; private IAction newProjectAction = null; <|endfocus|> /** * This method should be called at the point in time when the view's controls * are created. * * @param parent The composite where the explanatory text should be put into. */ public EmptyWorkspaceHelper(Composite parent) { displayArea = parent; layout = new StackLayout(); displayArea.setLayout(layout); createEmptyArea(displayArea); registerListeners(); } /**
<|startcomment|> I would use some other name here. Reading client code I was asking myself: what is the difference between creating the helper with control #1 and setting control #2 here? The name should be something like "setNonEmptyControl" or "setDefaultControl" etc <|endcomment|> <|startfocus|> public void setControl(Control control) { <|endfocus|> this.control = control; emptyArea.setBackground(control.getBackground()); switchTopControl();
<|startcomment|> I think we simply should add SWT dispose listener to the "parent" control given in the constructor and make this method private. Clients never read API javadocs and so the probability of leak is guaranteed. <|endcomment|> <|startfocus|> public void dispose() { PlatformUI.getWorkbench().getActiveWorkbenchWindow().removePerspectiveListener(this); ResourcesPlugin.getWorkspace().removeResourceChangeListener(this); JFaceResources.getColorRegistry().removeListener(this); <|endfocus|>
<|startcomment|> Can we please extract this to variable, it will simplify reading. <|endcomment|>  private void readProjectWizardActions() { IWorkbench wb = PlatformUI.getWorkbench(); IWorkbenchWindow win = wb.getActiveWorkbenchWindow(); IWorkbenchPage page = win.getActivePage(); String[] wizardIds = page.getNewWizardShortcuts(); projectWizardActions.clear(); for (String wizardId : wizardIds) { <|startfocus|> IWizardDescriptor wizardDesc = WorkbenchPlugin.getDefault().getNewWizardRegistry().findWizard(wizardId); if (wizardDesc == null) <|endfocus|> continue; String[] tags = wizardDesc.getTags(); for (String tag : tags) { if (WorkbenchWizardElement.TAG_PROJECT.equals(tag)) { IAction action = getAction(WorkbenchPlugin.getDefault().getNewWizardRegistry(), wizardId); projectWizardActions.add(action); } } }
<|startcomment|> Please use {} braces for conditionals <|endcomment|>  private void readProjectWizardActions() { IWorkbench wb = PlatformUI.getWorkbench(); IWorkbenchWindow win = wb.getActiveWorkbenchWindow(); IWorkbenchPage page = win.getActivePage(); String[] wizardIds = page.getNewWizardShortcuts(); projectWizardActions.clear(); for (String wizardId : wizardIds) { <|startfocus|> IWizardDescriptor wizardDesc = WorkbenchPlugin.getDefault().getNewWizardRegistry().findWizard(wizardId); if (wizardDesc == null) <|endfocus|> continue; String[] tags = wizardDesc.getTags(); for (String tag : tags) { if (WorkbenchWizardElement.TAG_PROJECT.equals(tag)) { IAction action = getAction(WorkbenchPlugin.getDefault().getNewWizardRegistry(), wizardId); projectWizardActions.add(action); } } }
<|startcomment|> This is triggered by an async task. The control may be already disposed, so we must check if it is still alive before we start doing something with it. <|endcomment|> <|startfocus|> private boolean switchTopControl() { <|endfocus|> Control oldTop = layout.topControl; IProject[] projs = ResourcesPlugin.getWorkspace().getRoot().getProjects(); if (projs.length > 0) { layout.topControl = control; } else { layout.topControl = emptyArea; } return oldTop != layout.topControl;
<|startcomment|> Not good. Resource delta's can be huge, and this could flood UI thread with async tasks. Please either add a break to send only one refresh or collect data if you need multiple and schedule one task at the end. I guess here we simply miss a "return". <|endcomment|>  public void resourceChanged(IResourceChangeEvent event) { IResourceDelta resourceDelta = event.getDelta(); if (resourceDelta != null) { IResourceDelta[] affectedChildren = resourceDelta.getAffectedChildren(); for (IResourceDelta affectedChildResourceDelta : affectedChildren) { IResource resource = affectedChildResourceDelta.getResource(); int kind = affectedChildResourceDelta.getKind(); if (resource instanceof IProject && (kind == IResourceDelta.ADDED || kind == IResourceDelta.REMOVED)) { Display.getDefault().asyncExec(() -> Display.getDefault().timerExec(200, switchTopControlRunnable)); } } } <|startfocus|> <|endfocus|>
<|startcomment|> Paranoia: can you please invert order of equals() arguments? <|endcomment|>  public void propertyChange(PropertyChangeEvent event) { if (event.getProperty().equals(JFacePreferences.HYPERLINK_COLOR)) { recreateEmptyArea(); <|startfocus|> } <|endfocus|>
<|startcomment|> Shouldn't be needed <|endcomment|>  IWorkingSetManager workingSetManager = getPlugin().getWorkbench() .getWorkingSetManager(); workingSetManager.removePropertyChangeListener(propertyChangeListener); if (collapseAllHandler != null) { collapseAllHandler.dispose(); } if (getActionGroup() != null) { getActionGroup().dispose(); } Control control = viewer.getControl(); if (dragDetectListener != null && control != null && control.isDisposed() == false) { control.removeListener(SWT.DragDetect, dragDetectListener); } <|startfocus|> emptyWorkspaceHelper.dispose(); <|endfocus|> super.dispose();
<|startcomment|> typo? <|endcomment|>  * content into here?" * * This class uses a stack layout to switch between the "original" composite of * the view and an additional composite given the user the explanatory text. * This text is displayed when no projects are in the workspace. Once projects * are created this class switches back to the "original" composite of the view. * <|startfocus|> * The explanatory text for explains the current situation that no projects are <|endfocus|> * available and provides a list of options to create projects. This list * contains links to: * <ol> * <li>Project creation wizards specific to the current perspective</li> * <li>The "New Project Wizard" to allow creation of project of any type</li> * </ol> * If no perspective specific project creation wizards are found then a simple * text with a link to the "New Project Wizard" is shown. * * This class also takes care of refreshing these links when the user switches * the perspective. * */ public final class EmptyWorkspaceHelper { 
<|startcomment|> I would sleep better if we would "null" the references to actions and parent controls, to avoid unintended memory leaks up to workbench if "badly" disposed clients still have an instance of us after disposal. <|endcomment|>  private void dispose(Listener listener) { PlatformUI.getWorkbench().getActiveWorkbenchWindow().removePerspectiveListener(listener); ResourcesPlugin.getWorkspace().removeResourceChangeListener(listener); JFaceResources.getColorRegistry().removeListener(listener); <|startfocus|> parent.removeDisposeListener(listener); <|endfocus|>
<|startcomment|> should check for null before adding. Sorry, have overlooked before. <|endcomment|>  String[] wizardIds = page.getNewWizardShortcuts(); projectWizardActions.clear(); for (String wizardId : wizardIds) { IWizardRegistry newWizardRegistry = WorkbenchPlugin.getDefault().getNewWizardRegistry(); IWizardDescriptor wizardDesc = newWizardRegistry.findWizard(wizardId); if (wizardDesc == null) { continue; } String[] tags = wizardDesc.getTags(); for (String tag : tags) { if (WorkbenchWizardElement.TAG_PROJECT.equals(tag)) { IAction action = getAction(newWizardRegistry, wizardId); <|startfocus|> projectWizardActions.add(action); <|endfocus|> } } }
<|startcomment|> We should use PlatformUI.getWorkbench().getDisplay() or the display of the control we have, later however could be dangerous if the control is disposed already. <|endcomment|>  public void resourceChanged(IResourceChangeEvent event) { IResourceDelta resourceDelta = event.getDelta(); if (resourceDelta != null) { IResourceDelta[] affectedChildren = resourceDelta.getAffectedChildren(); for (IResourceDelta affectedChildResourceDelta : affectedChildren) { IResource resource = affectedChildResourceDelta.getResource(); int kind = affectedChildResourceDelta.getKind(); if (resource instanceof IProject && (kind == IResourceDelta.ADDED || kind == IResourceDelta.REMOVED)) { <|startfocus|> Display.getDefault() <|endfocus|> .asyncExec(() -> Display.getDefault().timerExec(200, switchTopControlRunnable)); return; } } }
<|startcomment|> I think the sentence is not complete, is 'to sort strings' missing in the beginning? <|endcomment|>  * * Contributors: * Lucas Koehler - initial API and implementation ******************************************************************************/ package org.eclipse.emfforms.spi.common.sort; import java.math.BigInteger; import java.util.Comparator; import java.util.regex.Matcher; import java.util.regex.Pattern; /** * A comparator for strings that compares numbers which are part of compared string as numbers and not as strings. <|startfocus|> * This allows string that are a mixture of numbers and text (e.g. house numbers) in an intuitive fashion. <|endfocus|> * For instance, plain string sorting sorts 200A greater than 1000A. This comparator sorts 1000A greater than 200A. * * @author Lucas Koehler * @since 1.20 * */ public final class NumberAwareStringComparator implements Comparator<String> { // First group matches zero or more non-digits. Second group matches zero or more digits private static final Pattern PATTERN = Pattern.compile("(\\D*)(\\d*)"); //$NON-NLS-1$ private static NumberAwareStringComparator instance; /** * @return the static {@link NumberAwareStringComparator} instance. */
<|startcomment|> The field is not read anymore, can you remove it? <|endcomment|>  private Action fOpenManifestAction; private Action fOpenSchemaAction; private Action fOpenSystemEditorAction; private Action fOpenClassFileAction; private Action fOpenTextEditorAction; private Action fSelectDependentAction; private Action fSelectInJavaSearchAction; private Action fSelectAllAction; private PDERefactoringAction fRefactorAction; private CollapseAllAction fCollapseAllAction; private DisabledFilter fHideExtEnabledFilter = new DisabledFilter(true); private DisabledFilter fHideExtDisabledFilter = new DisabledFilter(false); private WorkspaceFilter fHideWorkspaceFilter = new WorkspaceFilter(); <|startfocus|> private SourcePluginFilter fSourcePluginFilter; <|endfocus|> private JavaFilter fJavaFilter = new JavaFilter(); private CopyToClipboardAction fCopyAction; private Clipboard fClipboard; private Object fRoot = null; class DisabledFilter extends ViewerFilter { boolean fEnabled; DisabledFilter(boolean enabled) { fEnabled = enabled; } @Override public boolean select(Viewer v, Object parent, Object element) { if (element instanceof IPluginModelBase) { IPluginModelBase model = (IPluginModelBase) element; return model.getUnderlyingResource() != null || model.isEnabled() != fEnabled; } return true;
<|startcomment|> was that for testing? <|endcomment|>  boolean hideDisabledExternal = !settings.getBoolean(SHOW_EXDISABLED); if (hideWorkspace) fTreeViewer.addFilter(fHideWorkspaceFilter); if (hideEnabledExternal) fTreeViewer.addFilter(fHideExtEnabledFilter); if (hideDisabledExternal) fTreeViewer.addFilter(fHideExtDisabledFilter); fHideWorkspaceFilterAction.setChecked(!hideWorkspace); fHideExtEnabledFilterAction.setChecked(!hideEnabledExternal); fHideExtDisabledFilterAction.setChecked(!hideDisabledExternal); Job.createSystem("", monitor -> { //$NON-NLS-1$ PDEState state = TargetPlatformHelper.getPDEState(); <|startfocus|> try { Thread.sleep(3000l); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } <|endfocus|> Tree tree = fTreeViewer.getTree(); if (!tree.isDisposed()) { tree.getDisplay().asyncExec(() -> { fSourcePluginFilter = new SourcePluginFilter(state); fTreeViewer.addFilter(fSourcePluginFilter); }); } }).schedule();
<|startcomment|> I think a short note in the else branch that we try to avoid initialization in the UI is enough documentation <|endcomment|>  boolean hideEnabledExternal = settings.getBoolean(HIDE_EXENABLED); boolean hideDisabledExternal = !settings.getBoolean(SHOW_EXDISABLED); if (hideWorkspace) fTreeViewer.addFilter(fHideWorkspaceFilter); if (hideEnabledExternal) fTreeViewer.addFilter(fHideExtEnabledFilter); if (hideDisabledExternal) fTreeViewer.addFilter(fHideExtDisabledFilter); fHideWorkspaceFilterAction.setChecked(!hideWorkspace); fHideExtEnabledFilterAction.setChecked(!hideEnabledExternal); fHideExtDisabledFilterAction.setChecked(!hideDisabledExternal); <|startfocus|> // when TP state is already initialized apply the SourcePluginFilter // directly, // otherwise defer state initialization to a background job and apply // the filter // when it is available. <|endfocus|> if (PDECore.getDefault().getModelManager().isInitialized()) { PDEState state = PDECore.getDefault().getModelManager().getState(); fSourcePluginFilter = new SourcePluginFilter(state); } else { Job.createSystem("", monitor -> { //$NON-NLS-1$ PDEState state = TargetPlatformHelper.getPDEState(); Tree tree = fTreeViewer.getTree(); if (!tree.isDisposed()) { tree.getDisplay().asyncExec(() -> {
<|startcomment|> filter is not added <|endcomment|>  fHideWorkspaceFilterAction.setChecked(!hideWorkspace); fHideExtEnabledFilterAction.setChecked(!hideEnabledExternal); fHideExtDisabledFilterAction.setChecked(!hideDisabledExternal); // when TP state is already initialized apply the SourcePluginFilter // directly, // otherwise defer state initialization to a background job and apply // the filter // when it is available. if (PDECore.getDefault().getModelManager().isInitialized()) { PDEState state = PDECore.getDefault().getModelManager().getState(); <|startfocus|> fSourcePluginFilter = new SourcePluginFilter(state); <|endfocus|> } else { Job.createSystem("", monitor -> { //$NON-NLS-1$ PDEState state = TargetPlatformHelper.getPDEState(); Tree tree = fTreeViewer.getTree(); if (!tree.isDisposed()) { tree.getDisplay().asyncExec(() -> { fSourcePluginFilter = new SourcePluginFilter(state); fTreeViewer.addFilter(fSourcePluginFilter); }); } }).schedule(); }
<|startcomment|> Could you add an nls here too please ? <|endcomment|>  IContainer parent = tpdFile.getParent(); String fileName = tpdFile.getFullPath().removeFileExtension().addFileExtension("target").lastSegment(); //$NON-NLS-1$ IFile portableTargetFile = parent.getFile(new Path(fileName)); IFolder eclipseFolder = parent.getParent().getFolder(new Path(targetSuffix)); if (!eclipseFolder.exists()) { eclipseFolder.create(true, true, new NullProgressMonitor()); } <|startfocus|> IFile eclipseTargetFile = eclipseFolder.getFile(fileName.replaceAll("portable", targetSuffix)); <|endfocus|> InputStream convertedStream = convert(portableTargetFile.getContents(), "http://download.eclipse.org/", "file:/home/data/httpd/download.eclipse.org/"); //$NON-NLS-1$ //$NON-NLS-2$ convertedStream = convert(convertedStream, "https://download.eclipse.org/", "file:/home/data/httpd/download.eclipse.org/"); //$NON-NLS-1$ //$NON-NLS-2$ if (eclipseTargetFile.exists()) { eclipseTargetFile.setContents(convertedStream, IResource.NONE, null); } else { eclipseTargetFile.create(convertedStream, true, null); } 
<|startcomment|> getRefsWithTipSha1? <|endcomment|>  * {@link RefDatabase} should override this method directly if a better * implementation is possible. * * @param id * {@link ObjectId} to resolve * @return a {@link Set} of {@link Ref}s whose tips point to the provided * id. * @throws java.io.IOException * the reference space cannot be accessed. * @since 5.3 */ @NonNull <|startfocus|> public Set<Ref> resolveTipSha1(ObjectId id) throws IOException { <|endfocus|> return getRefs().stream().filter(r -> id.equals(r.getObjectId()) || id.equals(r.getPeeledObjectId())).collect(toSet()); } /** * Check if any refs exist in the ref database. * <p> * This uses the same definition of refs as {@link #getRefs()}. In * particular, returns {@code false} in a new repository with no refs * under {@code refs/} and {@code HEAD} pointing to a branch yet to be
<|startcomment|> so close ! (for consistency's sake I'd prefer it moved to the new class) Anyway thanks for the new message class ! :) <|endcomment|>  protected IStatus run(IProgressMonitor monitor) { Diagnostic result = converter.generateTargetDefinitionFile(tpdURI, new NullProgressMonitor()); if (result.getSeverity() >= Diagnostic.WARNING) { Activator.getDefault().getLog().log(BasicDiagnostic.toIStatus(result)); } try { file.getParent().refreshLocal(IResource.DEPTH_ONE, null); generateEclipseTarget(file); } catch (CoreException ex) { <|startfocus|> return new Status(IStatus.ERROR, Activator.PLUGIN_ID, "Unexpected exception", ex);//$NON-NLS-1$ <|endfocus|> } return BasicDiagnostic.toIStatus(result);
<|startcomment|> Button <|endcomment|>  * buttonFactory.text("Button 1").create(parent); * buttonFactory.text("Button 2").create(parent); * buttonFactory.text("Button 3").create(parent); * </pre> * <p> * The above example creates three buttons using the same instance of * ButtonFactory. * <p> */ public final class WidgetFactory { private WidgetFactory() { } /** <|startfocus|> * @param style SWT style applicable for Text. Refer to <|endfocus|> * {@link Button#Button(Composite, int)} for supported styles. * @return ButtonFactory */ public static ButtonFactory button(int style) { return ButtonFactory.newButton(style); } /** * @param style SWT style applicable for Text. Refer to * {@link Text#Text(Composite, int)} for supported styles. * @return TextFactory */ public static TextFactory text(int style) { return TextFactory.newText(style); } /** * @param style SWT style applicable for Label. Refer to
<|startcomment|> not really needed for test. just keep it simple <|endcomment|>  public void testUniqueLayoutData() { GridDataFactory gridDataFactory = GridDataFactory.fillDefaults().grab(true, false); <|startfocus|> TestFactory factory = TestFactory.newTest().tooltip("toolTip").enabled(false).layoutData(gridDataFactory::create); <|endfocus|> Label label = factory.create(shell); Label label2 = factory.create(shell); assertNotEquals(label.getLayoutData(), label2.getLayoutData());
<|startcomment|> assertNotSame should be sufficient in this case?! actually we just want to ensure this right: layoutData != layoutData2. WDYT? Is it good to just emphasize in the test that they are != <|endcomment|>  public void testUniqueLayoutData() { GridDataFactory gridDataFactory = GridDataFactory.fillDefaults().grab(true, false); TestFactory factory = TestFactory.newTest().tooltip("toolTip").enabled(false).layoutData(gridDataFactory::create); Label label = factory.create(shell); Label label2 = factory.create(shell); <|startfocus|> assertNotEquals(label.getLayoutData(), label2.getLayoutData()); <|endfocus|>
<|startcomment|> It would look better to have the Button in a separate CoolItem instead of adding it to the Indent's Composite and CoolItem. <|endcomment|>  indent.addSelectionListener(widgetSelectedAdapter(event -> { Spinner spinner = (Spinner) event.widget; styledText.setIndent(spinner.getSelection()); })); label = new Label(composite, SWT.NONE); label.setText(getResourceString("Spacing")); //$NON-NLS-1$ Spinner spacing = new Spinner(composite, SWT.BORDER); spacing.addSelectionListener(widgetSelectedAdapter(event -> { Spinner spinner = (Spinner) event.widget; styledText.setLineSpacing(spinner.getSelection()); })); <|startfocus|> // Button to Enable Mouse Navigator in StyledText Button enableMouseNavigator = new Button(composite, SWT.CHECK); enableMouseNavigator.setText(getResourceString("MouseNav")); enableMouseNavigator.addSelectionListener (widgetSelectedAdapter(event -> styledText.setMouseNavigatorEnabled(enableMouseNavigator.getSelection()))); <|endfocus|> coolItem = new CoolItem(coolBar, SWT.NONE); coolItem.setControl(composite); CoolItem[] coolItems = coolBar.getItems(); for (CoolItem item : coolItems) { Control control = item.getControl(); Point size = control.computeSize(SWT.DEFAULT, SWT.DEFAULT); item.setMinimumSize(size);
<|startcomment|> these 'shouldn't' be a problem but maybe just in case ? <|endcomment|>  private static String internalGetString(String key) { try { return RESOURCE_BUNDLE.getString(key); } catch (MissingResourceException e) { <|startfocus|> return '!' + key + '!'; <|endfocus|> }
<|startcomment|> same, chars should be ok but... <|endcomment|>  public String toString() { if (eObject == null) { return "<null>-" + side; //$NON-NLS-1$ } <|startfocus|> return eObject.eClass().getName() + '-' + side.getName(); <|endfocus|>
<|startcomment|> char <|endcomment|>  public String toString() { <|startfocus|> return super.toString() + '-' + side.getName(); <|endfocus|>
<|startcomment|> missing nls <|endcomment|>  shortMessage += "..."; //$NON-NLS-1$ } // Get the author String author = null; if (lastCommit.getFullMessage().contains(Constants.SIGNED_OFF_BY_TAG)) { try { final String subSignedOff = lastCommit.getFullMessage().substring(lastCommit.getFullMessage().indexOf(Constants.SIGNED_OFF_BY_TAG) + Constants.SIGNED_OFF_BY_TAG.length()); <|startfocus|> author = subSignedOff.contains("\n") ? subSignedOff.substring(0, subSignedOff.indexOf("\n")) : subSignedOff; <|endfocus|> } catch (Exception e) { // Do nothing } } if (null == author || author.isEmpty()) { author = lastCommit.getAuthorIdent().getName(); } if (!shortMessage.isEmpty() && !author.isEmpty()) { constructName.append("("); //$NON-NLS-1$ if (!shortMessage.isEmpty()) { constructName.append("\""); //$NON-NLS-1$ constructName.append(shortMessage); constructName.append("\", "); //$NON-NLS-1$ }
<|startcomment|> did you change the taskName - it doesnt seem to need nls anymore ? <|endcomment|>  final String projectName = project.getName(); // Get the branch name final String fullBranchName = branch.getName(); final String shortBranchName = fullBranchName.substring(fullBranchName.indexOf(Constants.R_REMOTES) + Constants.R_REMOTES.length() + Constants.DEFAULT_REMOTE_NAME.length() + 1); final List<IProject> importedProject = new ArrayList<IProject>(1); try { new ProgressMonitorDialog(shell).run(true, false, monitor -> { <|startfocus|> monitor.beginTask(taskName, 6); // $NON-NLS-1$ <|endfocus|> try { // First, reset the current branch monitor.subTask("Reset the branch"); //$NON-NLS-1$ GitUtils.resetHardCurrentBranch(git); monitor.worked(1); // First, checkout the master branch (else we can't delete the other branch) monitor.subTask("Checkout the master"); //$NON-NLS-1$ GitUtils.checkoutExistingBranch(git, Constants.MASTER); monitor.worked(1); // Second, we have to delete local branch if exist monitor.subTask("Delete the local branch"); //$NON-NLS-1$
<|startcomment|> nls's <|endcomment|>  protected Element getRootElement(final Object selectedObject) { Element result = null; // Manage the possible selected file final IFile file = PapyrusFileUtils.getFile(selectedObject); if (null != file) { String fullPath = file.getFullPath().toString(); <|startfocus|> if (fullPath.endsWith("DomainsDefinition.uml")) { fullPath = fullPath.replace("DomainsDefinition.uml", ".uml"); } <|endfocus|> URI modelURI = URI.createPlatformResourceURI(fullPath, false); if (!"uml".equals(modelURI.fileExtension())) { //$NON-NLS-1$ modelURI = modelURI.trimFileExtension().appendFileExtension("uml"); //$NON-NLS-1$ } final ModelSet modelSet = new ModelSet(); final Resource resource = modelSet.getResource(modelURI, true); if (null != resource) { final EObject root = resource.getContents().get(0); if (root instanceof Element) { result = (Element) root; } } } // Manage other possibilities if (null == result && selectedObject instanceof IAdaptable) {
<|startcomment|> nls <|endcomment|>  public String getText(Object element) { if (element instanceof Ref) { final Git git = GitInstance.getInstance().getGit(); final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); PersonIdent authorIdent = lastCommit.getAuthorIdent(); Date authorDate = authorIdent.getWhen(); <|startfocus|> SimpleDateFormat dateFormat = new SimpleDateFormat("dd-MM-yyyy HH:mm:ss"); <|endfocus|> return dateFormat.format(authorDate); } return "Not specified";
<|startcomment|> nls ? message ? <|endcomment|>  public String getText(Object element) { if (element instanceof Ref) { final Git git = GitInstance.getInstance().getGit(); final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); PersonIdent authorIdent = lastCommit.getAuthorIdent(); Date authorDate = authorIdent.getWhen(); SimpleDateFormat dateFormat = new SimpleDateFormat("dd-MM-yyyy HH:mm:ss"); return dateFormat.format(authorDate); } <|startfocus|> return "Not specified"; <|endfocus|>
<|startcomment|> nls <|endcomment|>  final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); String author = null; if (lastCommit.getFullMessage().contains(Constants.SIGNED_OFF_BY_TAG)) { try { final String subSignedOff = lastCommit.getFullMessage().substring(lastCommit.getFullMessage().indexOf(Constants.SIGNED_OFF_BY_TAG) + Constants.SIGNED_OFF_BY_TAG.length()); <|startfocus|> author = subSignedOff.contains("\n") ? subSignedOff.substring(0, subSignedOff.indexOf("\n")) : subSignedOff; <|endfocus|> } catch (Exception e) { // Do nothing } } if (null == author || author.isEmpty()) { author = lastCommit.getAuthorIdent().getName(); } return author; } return "Unknown";
<|startcomment|> message <|endcomment|>  author = subSignedOff.contains("\n") ? subSignedOff.substring(0, subSignedOff.indexOf("\n")) : subSignedOff; } catch (Exception e) { // Do nothing } } if (null == author || author.isEmpty()) { author = lastCommit.getAuthorIdent().getName(); } return author; } <|startfocus|> return "Unknown"; <|endfocus|>
<|startcomment|> message <|endcomment|>  public String getText(Object element) { if (element instanceof Ref) { final Git git = GitInstance.getInstance().getGit(); final RevCommit lastCommit = GitUtils.getLastCommitOfBranch(git, (Ref) element); return lastCommit.getShortMessage(); } <|startfocus|> return "Not specified"; <|endfocus|>
<|startcomment|> nls <|endcomment|>  * Nicolas FAUVERGUE (CEA LIST) nicolas.fauvergue@cea.fr - Initial API and implementation * *****************************************************************************/ package org.eclipse.papyrus.gitlight.git.data; import java.util.NoSuchElementException; import java.util.StringTokenizer; /** * This class represent the catalog version. */ public class CatalogVersion { /** The major version number. */ protected int major; /** The minor version number. */ protected int minor; /** The separator for the version string. */ <|startfocus|> private final static String SEPARATOR = "."; <|endfocus|> /** The empty version "0.0". Equivalent to calling <code>new Version(0,0)</code>. */ public static final CatalogVersion emptyVersion = new CatalogVersion(0, 0); /** * Creates a new Version. * * @param major * The major version value (should be positive). * @param minor * The minor version value (should be positive). */ public CatalogVersion(final int major, final int minor) { updateVersion(major, minor); } /**
<|startcomment|> nls' <|endcomment|>  /** * The 'version' details name key. */ public static final String VERSION_DETAILS_NAME = "current"; //$NON-NLS-1$ /** * The master repository path. */ public static final String MASTER_REPOSITORY_PATH = Constants.DEFAULT_REMOTE_NAME + "/" + Constants.MASTER; //$NON-NLS-1$ /** * The contribution branch name prefix. */ <|startfocus|> public static final String CONTRIBUTION_BRANCH_PREFIX = "Review_"; <|endfocus|> /** * The initial commit message. */ public static final String INITIAL_COMMIT_MESSAGE = "Initial commit"; /** * The git folder. */ public static final String GIT_FOLDER = "\\" + Constants.DOT_GIT; //$NON-NLS-1$ /** * The change id. */ public static final String CHANGE_ID = "Change-Id: I0000000000000000000000000000000000000000"; //$NON-NLS-1$ } 
<|startcomment|> nls <|endcomment|>  public static void copyProject(final Git git, final IProject project) { final Repository repository = git.getRepository(); final URI gitPath = URI.createURI(repository.getWorkTree().toString().replace("\\", "/")); //$NON-NLS-1$ //$NON-NLS-2$ // Copy all project and sub files copySubFolder(project, gitPath); // Add this copied files to git <|startfocus|> addGitFiles(git, repository.getWorkTree(), ""); <|endfocus|>
<|startcomment|> nls' <|endcomment|>  public static void copyFolder(final String source, final String dest) { final File srcFolder = getFolder(source); final File destFolder = getFolder(dest); if (srcFolder.exists()) { if (!destFolder.exists()) { destFolder.mkdir(); } // Copy sub folders and files for (final File subFile : srcFolder.listFiles()) { if (subFile.isDirectory()) { <|startfocus|> copyFolder(subFile.getAbsolutePath(), dest + "/" + subFile.getName()); <|endfocus|> } else { try { copyFile(subFile.getAbsolutePath(), dest + "/" + subFile.getName()); } catch (IOException e) { Activator.getLogHelper().error(e); } } } }
<|startcomment|> generated tags in src. <|endcomment|>  * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Nicolas FAUVERGUE (CEA LIST) nicolas.fauvergue@cea.fr - Initial API and implementation * *****************************************************************************/ package org.eclipse.papyrus.gitlight.review.profile; import org.eclipse.emf.common.EMFPlugin; import org.eclipse.emf.common.util.ResourceLocator; /** * This is the central singleton for the Reviewprofile model plugin. <!-- * begin-user-doc --> <!-- end-user-doc --> <|startfocus|> * * @generated <|endfocus|> */ public final class Activator extends EMFPlugin { /** * Keep track of the singleton. <!-- begin-user-doc --> <!-- end-user-doc * --> * * @generated */ public static final Activator INSTANCE = new Activator(); /** * Keep track of the singleton. <!-- begin-user-doc --> <!-- end-user-doc * --> * * @generated */ private static Implementation plugin; /**
<|startcomment|> the -> that <|endcomment|>  * the display to search for potential controls * @param locationToFind * the position, in display coordinates, to be located * @return the most specific SWT control at the given location */ public static Control findControl(Display displayToSearch, Point locationToFind) { Shell[] shells = displayToSearch.getShells(); fixShellOrder(displayToSearch, shells); return findControl(shells, locationToFind); } /** <|startfocus|> * Finds the active shell and moves it to the end of the given array, so the * findControl() will find the controls from the active shell first <|endfocus|> */ private static void fixShellOrder(Display display, Shell[] shells) { if (shells.length <= 1) { return; } Shell activeShell = display.getActiveShell(); int lastIndex = shells.length - 1; if (activeShell == null || shells[lastIndex] == activeShell) { return; } // find the index of the active shell and exchange last one with active
<|startcomment|> Add a dot. <|endcomment|>  * the position, in display coordinates, to be located * @return the most specific SWT control at the given location */ public static Control findControl(Display displayToSearch, Point locationToFind) { Shell[] shells = displayToSearch.getShells(); fixShellOrder(displayToSearch, shells); return findControl(shells, locationToFind); } /** <|startfocus|> * Finds the active shell and moves it to the end of the given array, so the * findControl() will find the controls from the active shell first <|endfocus|> */ private static void fixShellOrder(Display display, Shell[] shells) { if (shells.length <= 1) { return; } Shell activeShell = display.getActiveShell(); int lastIndex = shells.length - 1; if (activeShell == null || shells[lastIndex] == activeShell) { return; } // find the index of the active shell and exchange last one with active for (int i = 0; i < shells.length; i++) { if (shells[i] == activeShell) {
<|startcomment|> find -> Find <|endcomment|>  private static void fixShellOrder(Display display, Shell[] shells) { if (shells.length <= 1) { return; } Shell activeShell = display.getActiveShell(); int lastIndex = shells.length - 1; if (activeShell == null || shells[lastIndex] == activeShell) { return; } <|startfocus|> // find the index of the active shell and exchange last one with active <|endfocus|> for (int i = 0; i < shells.length; i++) { if (shells[i] == activeShell) { Shell toMove = shells[lastIndex]; shells[i] = toMove; shells[lastIndex] = activeShell; break; } }
<|startcomment|> Should this extend TimeEvent? Do we think we might ever need active properties or metadata? <|endcomment|>  * * All rights reserved. This program and the accompanying materials are * made available under the terms of the Eclipse Public License v1.0 which * accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model; import java.util.ArrayList; import java.util.List; /** * Generic TimeEvent implementation * * @author Matthew Khouzam * @since 4.3 */ <|startfocus|> public class TimeLineEvent implements ITimeEvent { <|endfocus|> private final List<Long> fValues; private final ITimeGraphEntry fEntry; private final long fTime; private final long fDuration; /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event * @param duration * The duration of the event */ public TimeLineEvent(ITimeGraphEntry entry, long time, long duration) { this(entry, time, duration, new ArrayList<>()); } /**
<|startcomment|> Assuming this was temporary? <|endcomment|>  int columns = headers.length; sheetWriter.startSheet(setPrimary.getName(), headers.length); sheetWriter.writeRow((Object[]) headers); for (DispoItem item : items) { Map<String, MCDCCoverageData> mcdcToCoverageData = new HashMap<>(); List<DispoAnnotationData> annotations = item.getAnnotationsList(); for (DispoAnnotationData annotation : annotations) { <|startfocus|> if (item.getName().contains("cmond_scheduler.2.ada.PERIODIC_TASK")) { System.out.println(""); } <|endfocus|> writeRowAnnotation(sheetWriter, columns, item, annotation, setPrimary.getName(), levelToResolutionTypesToCount, leveltoUnitToCovered, mcdcToCoverageData, levelsInSet); } } sheetWriter.endSheet(); // START COVER SHEET sheetWriter.startSheet("Cover Sheet", headers.length); List<String> coverSheetHeadersList = new ArrayList<>(); coverSheetHeadersList.add(" "); if (levelsInSet.contains(CoverageLevel.A)) { coverSheetHeadersList.add("MCDC"); } if (levelsInSet.contains(CoverageLevel.B)) { coverSheetHeadersList.add("Branch");
<|startcomment|> Thank you for the bug fix. Can I ask to get a bugzilla issue and a test case for this? equinox.http.servlet just went through a pretty massive reworking, so I'd appreciate these to keep improving quality. <|endcomment|>  return null; } String contextPath = contextControllers.iterator().next().getContextPath(); requestURI = requestURI.substring(contextPath.length()); int pos = requestURI.lastIndexOf('/'); String servletPath = requestURI; String pathInfo = null; if (match == Match.CONTEXT_ROOT) { pathInfo = Const.SLASH; servletPath = Const.BLANK; } <|startfocus|> else if (match == Match.DEFAULT_SERVLET) { pathInfo = servletPath; servletPath = Const.SLASH; } <|endfocus|> do { for (ContextController contextController : contextControllers) { DispatchTargets dispatchTargets = contextController.getDispatchTargets( null, requestURI, servletPath, pathInfo, extension, queryString, match, requestInfoDTO); if (dispatchTargets != null) { return dispatchTargets; } } if ((match == Match.EXACT) || (match == Match.CONTEXT_ROOT) || (match == Match.DEFAULT_SERVLET)) { break; } if (pos > -1) { String newServletPath = requestURI.substring(0, pos); pathInfo = requestURI.substring(pos);
<|startcomment|> The force flag needs to be propagated down to scanPacks and scanPacksImpl: inside the scanPacks there is a logic that is not reloading the list if the number and names of the files are the same. Additionally, the scanPacks() will recycle existing packs in the packlist, which isn't good because the packfiles are in memory with the wrong checksum and *we have to* reload them forcibly. <|endcomment|>  // check for new pack files. If set to true (default) we use the // lastmodified attribute of the folder and assume that no new // pack files can be in this folder if his modification time has // not changed. boolean trustFolderStat = config.getBoolean( ConfigConstants.CONFIG_CORE_SECTION, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, true); if (force || (!trustFolderStat) || old.snapshot.isModified(packDirectory)) { <|startfocus|> PackList newList = scanPacks(old); <|endfocus|> return old != newList; } return false;
<|startcomment|> use ternary operator and keep this variable final then you don't need to define another variable below. <|endcomment|>  if (mapping != null) { Repository repository = mapping.getRepository(); if (repository != null) { try { createHeadLink(repository, composite); fillValues(repository); } catch (IOException e) { if (GitTraceLocation.UI.isActive()) GitTraceLocation.getTrace().trace( GitTraceLocation.UI.getLocation(), e.getMessage(), e); } } } return composite; } private void createHeadLink(final Repository repository, Composite composite) throws IOException { <|startfocus|> ObjectId objectId = null; <|endfocus|> String fullBranch = repository.getFullBranch(); if (fullBranch != null) { objectId = repository.resolve(fullBranch); } if (objectId == null) { Text headLabel = createLabeledReadOnlyText(composite, UIText.GitProjectPropertyPage_LabelId); if (repository.getRefDatabase().getRefsByPrefix(RefDatabase.ALL) .isEmpty()) headLabel.setText(UIText.GitProjectPropertyPage_ValueEmptyRepository); else headLabel.setText(UIText.GitProjectPropertyPage_ValueUnbornBranch); } else { Hyperlink headLink = createHeadHyperLink(composite, UIText.GitProjectPropertyPage_LabelId);
<|startcomment|> Please keep same names (namespace, name, prev) to reduce the amount of things change and ease reading. <|endcomment|>  private final Map<String, Object> nameMap; public CapabilityIndex(Iterator<IInstallableUnit> itor) { nameMap = new HashMap<>(300); namespaceMap = new HashMap<>(10); while (itor.hasNext()) { IInstallableUnit iu = itor.next(); Collection<IProvidedCapability> pcs = iu.getProvidedCapabilities(); for (IProvidedCapability pc : pcs) { <|startfocus|> namespaceMap.computeIfAbsent(pc.getNamespace(), n -> new HashSet<>()).add(iu); nameMap.compute(pc.getName(), (n, v) -> { if (v == null || v == iu) { <|endfocus|> return iu; } else if (v instanceof IInstallableUnit) { Collection<IInstallableUnit> list = new HashSet<>(); list.add((IInstallableUnit) v); list.add(iu); return list; } else { ((Collection<IInstallableUnit>) v).add(iu); return v; } }); } } } private Object getRequirementIDs(IEvaluationContext ctx, IExpression requirement, Object queriedKeys) { switch (requirement.getExpressionType()) { case IExpression.TYPE_AND :
<|startcomment|> can't this one be made static? And is it actally necessary to keep it is we move to collections everywhere? <|endcomment|> <|startfocus|> private void collectMatchingIUs(Map<String, ?> indexToUse, String name, Collection<IInstallableUnit> collector) { <|endfocus|> Object v = indexToUse.get(name); if (v == null) return; if (v instanceof IInstallableUnit) collector.add((IInstallableUnit) v); else collector.addAll((Collection<IInstallableUnit>) v);
<|startcomment|> Suggestion: Use an else-if for these two and provide the missing braces. And instead of length() == 0 I'd use isEmpty(). <|endcomment|>  private void validatePage() { String message = null; if (userText.getText().trim().length() == 0) message = Messages.CredentialsWizardPage_ErrorUser; <|startfocus|> if (message == null && passwordText.getText().trim().length() == 0) <|endfocus|> message = Messages.CredentialsWizardPage_ErrorPassword; setErrorMessage(message); setPageComplete(message == null); 
<|startcomment|> Is there any risk of duplicate at that point? If not, I suggest using a LinkedList which should be cheaper in term of RAM for the same result. Or, at least, as Andrey often likes to suggest, let's use a LinkedHashSet that provides more deterministic result without performance cost. <|endcomment|>  while (itor.hasNext()) { IInstallableUnit iu = itor.next(); Collection<IProvidedCapability> pcs = iu.getProvidedCapabilities(); for (IProvidedCapability pc : pcs) { namespaceMap.computeIfAbsent(pc.getNamespace(), n -> new HashSet<>()).add(iu); nameMap.compute(pc.getName(), (n, v) -> { if (v == null || v == iu) { return iu; <|startfocus|> } else if (v instanceof IInstallableUnit) { Collection<IInstallableUnit> list = new HashSet<>(); list.add((IInstallableUnit) v); list.add(iu); return list; <|endfocus|> } else { ((Collection<IInstallableUnit>) v).add(iu); return v; } }); } } } private Object getRequirementIDs(IEvaluationContext ctx, IExpression requirement, Object queriedKeys) { switch (requirement.getExpressionType()) { case IExpression.TYPE_AND : // AND is OK if at least one of the branches require the queried key for (IExpression expr : ExpressionUtil.getOperands(requirement)) {
<|startcomment|> If parent can be null, we need to check before setting parent. Or switch to NonNullable <|endcomment|>  public void createArtifact(@Nullable ArtifactToken parent, ArtifactToken artifact) { ArtifactToken art = createArtifact(artifact); <|startfocus|> addChild(parent, art); <|endfocus|>
<|startcomment|> We can move this block into the new initializeSystemColorsLink(), above of initializeSystemColorsTooltip()? This would further improve the diff to original version. <|endcomment|> public boolean post (Event event) { /* * Get the operating system lock before synchronizing on the device * lock so that the device lock will not be held should another * thread already be in the operating system. This avoids deadlock * should the other thread need the device lock. */ Lock lock = OS.lock; lock.lock(); try { synchronized (Device.class) { if (isDisposed ()) error (SWT.ERROR_DEVICE_DISPOSED); if (event == null) error (SWT.ERROR_NULL_ARGUMENT); <|startfocus|> if (!OS.IS_X11) { return false; } long /*int*/ xDisplay = OS.gdk_x11_display_get_xdisplay(OS.gdk_display_get_default()); <|endfocus|> int type = event.type; switch (type) { case SWT.KeyDown: case SWT.KeyUp: { int keyCode = 0; long /*int*/ keysym = untranslateKey (event.keyCode); if (keysym != 0) keyCode = OS.XKeysymToKeycode (xDisplay, keysym); if (keyCode == 0) { char key = event.character;
<|startcomment|> could be replaced by org.eclipse.papyrus.uml.tools.model.UmlModel.UML_FILE_EXTENSION <|endcomment|> import org.eclipse.uml2.uml.Type; import org.eclipse.uml2.uml.UMLFactory; import org.eclipse.uml2.uml.UMLPackage; /** * Utility class for <code>org.eclipse.uml2.uml.Package</code><BR> */ public class PackageUtil { /** * Extension of UML models (also declared in class UmlModel. This class is not accessible here, * since oep.uml.tools depends on oep.uml.tools.utils, but not vice versa */ <|startfocus|> public static final String UML_EXT = "uml"; //$NON-NLS-1$ <|endfocus|> /** * Apply a profile and every subprofiles to a package. Also import types defined in profile * * @param profileToApply * profile to apply on package * @param package_ * on which profiles are applied * @param withSubProfiles * true if subprofiles must be automatically imported */ public static boolean applyProfile(org.eclipse.uml2.uml.Package package_, org.eclipse.uml2.uml.Profile profileToApply, boolean withSubProfiles) { // Returns�true if the model was modified
<|startcomment|> you should create a variable for ModelSet... <|endcomment|>  public static Package getUserModel(ExecutionEvent event) { ServiceUtilsForHandlers serviceUtils = ServiceUtilsForHandlers.getInstance(); try { <|startfocus|> URI uri = serviceUtils.getModelSet(event).getURIWithoutExtension().appendFileExtension(UML_EXT); Resource userResource = serviceUtils.getModelSet(event).getResource(uri, false); <|endfocus|> if (userResource != null && userResource.getContents().size() > 0) { EObject topEObj = userResource.getContents().get(0); if ((topEObj instanceof Package) && (!(topEObj instanceof Profile))) { return (Package) topEObj; } } } catch (ServiceException e) { Activator.log.error(e); } return null;
<|startcomment|> Are we not getting the statement end from the compiler ast? <|endcomment|>  breakStatement.setSourceRange(statement.sourceStart, statement.sourceEnd - statement.sourceStart + 1); } if (statement.label != null) { final SimpleName name = new SimpleName(this.ast); name.internalSetIdentifier(new String(statement.label)); retrieveIdentifierAndSetPositions(statement.sourceStart, statement.sourceEnd, name); breakStatement.setLabel(name); } else if (statement.expression != null && this.ast.apiLevel >= AST.JLS12_INTERNAL) { final Expression expression= convert(statement.expression); breakStatement.setExpression(expression); <|startfocus|> int sourceEnd = retrieveSemiColonPosition(expression); <|endfocus|> if (sourceEnd == -1) { breakStatement.setSourceRange(statement.sourceStart, statement.sourceEnd - statement.sourceStart + 2); } else { breakStatement.setSourceRange(statement.sourceStart, sourceEnd - statement.sourceStart + 1); } } return breakStatement;
<|startcomment|> spacing <|endcomment|>  private void disposeIfExited(final Control control, MouseEvent e) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); <|startfocus|> if(bounds.x == 0 && bounds.y== 0) { <|endfocus|> Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; if(!bounds.contains(pt)) { tipShell.dispose(); } }
<|startcomment|> spacing <|endcomment|>  Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if(bounds.x == 0 && bounds.y== 0) { Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; <|startfocus|> if(!bounds.contains(pt)) { <|endfocus|> tipShell.dispose(); } }
<|startcomment|> Is this comment still valid? <|endcomment|>  imgData.type = getImageFormat(loader); imgDataList.add(imgData); } else { // Image with multiple frames, iterate through each frame and convert // each frame to ImageData long /*int*/ start_time = OS.g_malloc(8); OS.g_get_current_time(start_time); long /*int*/ animation_iter = GDK.gdk_pixbuf_animation_get_iter (pixbuf_animation, start_time); int delay_time = 0; int time_offset = 0; <|startfocus|> // TODO: How to determine number of frames in GIF? <|endfocus|> int num_frames = 32; for (int i = 0; i < num_frames; i++) { // Calculate time offset from start_time to next frame delay_time = GDK.gdk_pixbuf_animation_iter_get_delay_time (animation_iter); time_offset += delay_time; OS.g_time_val_add(start_time, time_offset * 1000); boolean update = GDK.gdk_pixbuf_animation_iter_advance (animation_iter, start_time); if (update) { long /*int*/ curr_pixbuf = GDK.gdk_pixbuf_animation_iter_get_pixbuf (animation_iter);
<|startcomment|> This needs to be freed, hover over the "transfer-full" section on the doc: https://developer.gnome.org/gdk-pixbuf/stable/gdk-pixbuf-Image-Data-in-Memory.html#gdk-pixbuf-copy This can probably be done in the method that pixbuf_copy gets fed to. <|endcomment|>  delay_time = GDK.gdk_pixbuf_animation_iter_get_delay_time (animation_iter); time_offset += delay_time; OS.g_time_val_add(start_time, time_offset * 1000); boolean update = GDK.gdk_pixbuf_animation_iter_advance (animation_iter, start_time); if (update) { <|startfocus|> long /*int*/ curr_pixbuf = GDK.gdk_pixbuf_animation_iter_get_pixbuf (animation_iter); long /*int*/ pixbuf_copy = GDK.gdk_pixbuf_copy(curr_pixbuf); // copy because curr_pixbuf might get disposed on next advance <|endfocus|> ImageData imgData = pixbufToImageData(pixbuf_copy); if (this.logicalScreenHeight == 0 && this.logicalScreenWidth == 0) { this.logicalScreenHeight = imgData.height; this.logicalScreenWidth = imgData.width; } imgData.type = getImageFormat(loader); imgData.delayTime = delay_time; imgDataList.add(imgData); } else { break; } } } ImageData [] imgDataArray = new ImageData [imgDataList.size()];
<|startcomment|> Can this line be removed? <|endcomment|> public ImageData[] load(String filename) { if (filename == null) SWT.error(SWT.ERROR_NULL_ARGUMENT); InputStream stream = null; try { stream = new FileInputStream(filename); return load(stream); } catch (IOException e) { SWT.error(SWT.ERROR_IO, e); } finally { try { if (stream != null) stream.close(); } catch (IOException e) { // Ignore error } } return null; <|startfocus|> // return loadFromFile(filename); <|endfocus|>
<|startcomment|> This can be combined into one line. <|endcomment|>  } } return imgData; } /** * Returns GdkPixbuf pointer by loading an image from filename (Java string) * @param filename * @return */ static long /*int*/ gdk_pixbuf_new_from_file(String filename) { int length = filename.length (); char [] chars = new char [length]; filename.getChars (0, length, chars, 0); byte [] buffer = Converter.wcsToMbcs(chars, true); <|startfocus|> long /*int*/ pixbuf = GDK.gdk_pixbuf_new_from_file(buffer, null); return pixbuf; <|endfocus|> } /** * Convert java object ImageData to a new GdkPixbuf for saving * @param imgData * @return */ static long /*int*/ imageDataToPixbuf(ImageData imgData) { int colorspace = GDK.GDK_COLORSPACE_RGB; boolean has_alpha = imgData.alphaData != null; int width = imgData.width; int height = imgData.height; int rowstride = imgData.scanlinePad; long /*int*/ buffer_ptr = OS.g_malloc(imgData.data.length); C.memmove(buffer_ptr, imgData.data, imgData.data.length);
<|startcomment|> Unneeded? <|endcomment|>  long /*int*/ [] len = new long /*int*/ [1]; if (type == null) SWT.error(SWT.ERROR_UNSUPPORTED_FORMAT); GDK.gdk_pixbuf_save_to_bufferv(pixbuf, buffer, len, type, null, null, null); byte[] byteArray = new byte[(int) len[0]]; C.memmove(byteArray, buffer[0], byteArray.length); try { stream.write(byteArray); } catch (IOException e) { SWT.error(SWT.ERROR_IO); } <|startfocus|> // FileFormat.save(stream, format, this); <|endfocus|>
<|startcomment|> To have a single, guaranteed way to remove the listener, do it in a DisposeListener of the tool tip shell. <|endcomment|>  /** * Abstract tool tip handler. * * @since 3.2 * @author Loic Prieur-Drevon - extracted from {@link TimeGraphTooltipHandler} */ public abstract class TmfAbstractToolTipHandler { private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; /** * Important note: this is being added to a display filter, this may leak, * make sure it is removed when not needed. */ <|startfocus|> private final Listener fListener = event -> { Shell tipShell = fTipShell; if (tipShell != null) { disposeIfExited(tipShell, event); } }; <|endfocus|> private void disposeIfExited(final Control control, Event e) { if (!control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) {
<|startcomment|> If tipShell is a Shell, getBounds() always returns display coordinates. <|endcomment|>  private void disposeIfExited(final Control control, Event e) { if (!control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); <|startfocus|> if (bounds.x == 0 && bounds.y == 0) { Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } <|endfocus|> bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; if (!bounds.contains(pt) && !fInitialDeadzone.contains(pt)) { tipShell.dispose(); Display.getDefault().removeFilter(SWT.MouseExit, fListener); } } else { Display.getDefault().removeFilter(SWT.MouseExit, fListener); } } else { Display.getDefault().removeFilter(SWT.MouseExit, fListener); }
<|startcomment|> I think the first check is enough? The tool tip is OFFSET away from the mouse hover location. So as long as you move towards the tool tip it should not dispose? <|endcomment|>  Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); if (bounds.x == 0 && bounds.y == 0) { Point offset = tipShell.toDisplay(bounds.x, bounds.y); bounds.x = offset.x; bounds.y = offset.y; } bounds.x -= OFFSET; bounds.y -= OFFSET; bounds.height += 2 * OFFSET; bounds.width += 2 * OFFSET; <|startfocus|> <|endfocus|> if (!bounds.contains(pt) && !fInitialDeadzone.contains(pt)) { tipShell.dispose(); Display.getDefault().removeFilter(SWT.MouseExit, fListener); } } else { Display.getDefault().removeFilter(SWT.MouseExit, fListener); } } else { Display.getDefault().removeFilter(SWT.MouseExit, fListener); }
<|startcomment|> The dead zone is not always respected, because you never dispose on MouseMove event. <|endcomment|>  createTooltipShell(timeGraphControl.getShell()); for (Control child : fTipComposite.getChildren()) { child.dispose(); } fill(control, event, pt); if (fTipComposite.getChildren().length == 0) { // avoid displaying empty tool tips. return; } fTipShell.pack(); Point tipPosition = control.toDisplay(pt); setHoverLocation(fTipShell, tipPosition); fTipShell.setVisible(true); <|startfocus|> Display.getDefault().addFilter(SWT.MouseExit, fListener); <|endfocus|>
<|startcomment|> prepareWorkspace is important <|endcomment|>  public static void beforeClass() { SWTBotUtils.initialize(); Thread.currentThread().setName("SWTBotTest"); /* set up for swtbot */ SWTBotPreferences.TIMEOUT = 60000; /* 60 second timeout */ SWTBotPreferences.KEYBOARD_LAYOUT = "EN_US"; SWTWorkbenchBot bot = new SWTWorkbenchBot(); <|startfocus|> SWTBotUtils.closeView("welcome", bot); <|endfocus|> /* Finish waiting for eclipse to load */ WaitUtils.waitForJobs(); /* Create project */ SWTBotUtils.createProject(PROJECT_NAME);
<|startcomment|> You can remove this -- see comment below. <|endcomment|>  checkWidget (); if (listener == null) error (SWT.ERROR_NULL_ARGUMENT); if (eventTable == null) return; eventTable.unhook (SWT.Verify, listener); } @Override GdkRGBA getContextBackgroundGdkRGBA () { if (background != null && (state & BACKGROUND) != 0) { return background; } return defaultBackground(); } @Override void setBackgroundGdkRGBA (long /*int*/ context, long /*int*/ handle, GdkRGBA rgba) { if (GTK.GTK4) { <|startfocus|> background = rgba; <|endfocus|> super.setBackgroundGdkRGBA(context, handle, rgba); } else { if (rgba == null) { background = defaultBackground(); } else { background = rgba; } String css; String properties; String name; name = GTK.GTK_VERSION >= OS.VERSION(3, 20, 0) ? "spinbutton" : "GtkSpinButton"; String color = display.gtk_rgba_to_css_string (background);
<|startcomment|> Is it because the test fail that you call this? <|endcomment|>  assertNotNull(testFile); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, testFile.getAbsolutePath(), TRACE_TYPE); fEditorBot = SWTBotUtils.activateEditor(fBot, testFile.getName()); fAbsolutePath = TmfTraceManager.getTemporaryDirPath() + File.separator + "exportToTsvTest.tsv"; TmfFileDialogFactory.setOverrideFiles(fAbsolutePath); } /** * Test full export * * @throws IOException * File not found or such */ @Test public void testExport() throws IOException { <|startfocus|> setup(); <|endfocus|> SWTBotEditor editorBot = fEditorBot; assertNotNull(editorBot); final SWTBotTable tableBot = editorBot.bot().table(); tableBot.getTableItem(1).contextMenu(EXPORT_TO_TSV).click(); File file = new File(fAbsolutePath); fBot.waitUntil(new FileLargerThanZeroCondition(file)); try (BufferedReader br = new BufferedReader(new FileReader(file))) { long lines = br.lines().count(); assertEquals("Line count", 23, lines); } finally { new File(fAbsolutePath).delete(); } } /**
<|startcomment|> Is it because the test fail if you don't call this? It look like the tests need to be runned in a specific order with your change. Test should be independent <|endcomment|>  assertNotNull(editorBot); final SWTBotTable tableBot = editorBot.bot().table(); tableBot.getTableItem(0).click(3); SWTBotText textBot = editorBot.bot().text(); textBot.typeText("LoggerA|LoggerB|LoggerC"); textBot.pressShortcut(Keystrokes.CTRL, Keystrokes.CR); fBot.waitUntil(Conditions.tableHasRows(tableBot, 6), 5000); tableBot.getTableItem(1).contextMenu(EXPORT_TO_TSV).click(); assertTsvContentsEquals(ImmutableList.of(HEADER_TEXT, EVENT1_TEXT, EVENT2_TEXT, EVENT3_TEXT)); <|startfocus|> fBot.closeAllEditors(); <|endfocus|> } private static void assertTsvContentsEquals(final List<String> expected) throws FileNotFoundException, IOException { File file = new File(fAbsolutePath); fBot.waitUntil(new FileLargerThanZeroCondition(file)); try (BufferedReader br = new BufferedReader(new FileReader(file))) { List<String> lines = br.lines().collect(Collectors.toList()); assertEquals("File content", expected, lines); } finally { file.delete(); } } } 
<|startcomment|> change <|endcomment|> import org.eclipse.sirius.viewpoint.Messages; import com.google.common.base.Preconditions; /** * A class providing useful methods for refresh. * * @author mbats */ public final class RefreshHelper { private static List<Predicate<Notification>> impactingNotificationPredicates = new ArrayList<>(); /** * Prevent instantiation. */ private RefreshHelper() { } /** <|startfocus|> * Checks whether at least one changes of which we are notified, concern a semantic model or a specific graphical <|endfocus|> * change (registered through {@link #registerImpactingNotification(Predicate)}). * * @param notifications * the model changes. * @return <code>true</code> if the changes impact a semantic model or a specific graphical change. */ public static boolean isImpactingNotification(final Collection<Notification> notifications) { boolean isImpactingNotification = false; Set<EObject> alreadyDoneNotifiers = new HashSet<>(); for (Notification notification : notifications) { Object notifier = notification.getNotifier(); if (notifier instanceof EObject) { EObject eObjectNotifier = (EObject) notifier;
<|startcomment|> concerns <|endcomment|> import org.eclipse.sirius.viewpoint.Messages; import com.google.common.base.Preconditions; /** * A class providing useful methods for refresh. * * @author mbats */ public final class RefreshHelper { private static List<Predicate<Notification>> impactingNotificationPredicates = new ArrayList<>(); /** * Prevent instantiation. */ private RefreshHelper() { } /** <|startfocus|> * Checks whether at least one changes of which we are notified, concern a semantic model or a specific graphical <|endfocus|> * change (registered through {@link #registerImpactingNotification(Predicate)}). * * @param notifications * the model changes. * @return <code>true</code> if the changes impact a semantic model or a specific graphical change. */ public static boolean isImpactingNotification(final Collection<Notification> notifications) { boolean isImpactingNotification = false; Set<EObject> alreadyDoneNotifiers = new HashSet<>(); for (Notification notification : notifications) { Object notifier = notification.getNotifier(); if (notifier instanceof EObject) { EObject eObjectNotifier = (EObject) notifier;
<|startcomment|> bad english <|endcomment|>  } } } return false; } /** * Checks whether this notification concerns a semantic model change or a specific graphical change (registered * through {@link #registerImpactingNotification(Predicate)}). * * @param notification * the model change. * @param notifier * the EObject which is concerned by this notification * @param alreadyDoneNotifiers * list of notifiers that have already been checked before * @param notifierWithResource <|startfocus|> * map cache that for a notifier has its resource <|endfocus|> * @param notifierIsInAirdOrSrmResource * map cache that for a notifier has the result of the method * <code>ResourceQuery(Resource).isAirdOrSrmResource()</code> * @return <code>true</code> if the change impact a semantic model or a specific graphical change. */ protected static boolean isImpactingNotification(Notification notification, EObject notifier, Set<EObject> alreadyDoneNotifiers, Map<EObject, Resource> notifierWithResource, Map<EObject, Boolean> notifierIsInAirdOrSrmResource) { Resource notifierResource = notifierWithResource.get(notifier);
<|startcomment|> remove <|endcomment|>  private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; /** * Important note: this is being added to a display filter, this may leak, * make sure it is removed when not needed. */ private final Listener fListener = this::disposeIfExited; /** <|startfocus|> * Dispose the shell if we exit the range. Also deregister the filter from * display if the tooltip is disposed OR if it should be disposed <|endfocus|> * * @param e * The event which occurred */ private void disposeIfExited(Event e) { if (!(e.widget instanceof Control)) { return; } Control control = (Control) e.widget; if (control != null && !control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell; if (tipShell != null && !tipShell.isDisposed()) { Rectangle bounds = tipShell.getBounds(); bounds.x -= OFFSET; bounds.y -= OFFSET;
<|startcomment|> The StickyHoverManager also added a filter for SWT.FocusOut, I wasn't sure why, but now I figured it out: If you move out of the tool tip but into another non-Eclipse application, the tool tip does not close. But worst, if you click or Alt-Tab to another application to make it go to the front, the tool tip remains 'always on top' and hides the other application. You have to go back to Eclipse and mouse move on it to make it go away. <|endcomment|>  createTooltipShell(timeGraphControl.getShell()); for (Control child : fTipComposite.getChildren()) { child.dispose(); } fill(control, event, pt); if (fTipComposite.getChildren().length == 0) { // avoid displaying empty tool tips. return; } fTipShell.pack(); Point tipPosition = control.toDisplay(pt); setHoverLocation(fTipShell, tipPosition); fTipShell.setVisible(true); <|startfocus|> Display.getDefault().addFilter(SWT.MouseMove, fListener); <|endfocus|>
<|startcomment|> e.display <|endcomment|>  private void createTooltipShell(Shell parent) { final Display display = parent.getDisplay(); if (fTipShell != null && !fTipShell.isDisposed()) { fTipShell.dispose(); } fTipShell = new Shell(parent, SWT.ON_TOP | SWT.TOOL); <|startfocus|> fTipShell.addDisposeListener(e -> Display.getDefault().removeFilter(SWT.MouseMove, fListener)); <|endfocus|> GridLayout gridLayout = new GridLayout(); gridLayout.numColumns = 2; gridLayout.marginWidth = 2; gridLayout.marginHeight = 2; fTipShell.setLayout(gridLayout); fTipShell.setBackground(display.getSystemColor(SWT.COLOR_INFO_BACKGROUND)); fTipComposite = new Composite(fTipShell, SWT.NONE); fTipComposite.setLayout(new GridLayout(3, false)); setupControl(fTipComposite);
<|startcomment|> By remove the tearDown() the project is never deleted and editors are still open. I think it should be part of the cleanUp() <|endcomment|>  public static void cleanUp() { SWTBotUtils.closeViewById(UML2DVIEW_ID, fBot); <|startfocus|> fFileLocation.delete(); <|endfocus|> fLogger.removeAllAppenders();
<|startcomment|> By removing tearDown() the project is never deleted <|endcomment|>  public static void cleanUp() { fLogger.removeAllAppenders(); <|startfocus|> fFileLocation.delete(); <|endfocus|>
<|startcomment|> If the Eclipse application does not have focus, then you can still get a tool tip by hovering on the time graph. Even after clicking the tool tip shell, the Eclipse does not gain focus, so while the tool tip has focus from OS point of view, it does not have it from Eclipse point of view. So when clicking on another application, there is no SWT.FocusOut event sent in Eclipse, and the tool tip shell remains on top. Possible solution would be to give focus to the tool tip when it is created (or when it is entered?) but I don't know if this will disrupt the user... keyboard shortcuts on the time graph will no longer work). What I would suggest is to dispose on MouseExit. But you would need to have it happen as soon as you exit the shell bounds without any offset (in case you MouseExit outside of Eclipse application. But you can also have FocusOut without any MouseExit if you Alt-Tab to another application. <|endcomment|>  for (Control child : fTipComposite.getChildren()) { child.dispose(); } fill(control, event, pt); if (fTipComposite.getChildren().length == 0) { // avoid displaying empty tool tips. return; } fTipShell.pack(); Point tipPosition = control.toDisplay(pt); setHoverLocation(fTipShell, tipPosition); fTipShell.setVisible(true); Display display = Display.getDefault(); display.addFilter(SWT.MouseMove, fListener); <|startfocus|> display.addFilter(SWT.FocusOut, fListener); <|endfocus|>
<|startcomment|> This isn't used anywhere. Can it be removed ? <|endcomment|>  import org.eclipse.jdt.core.IJavaElement; import org.eclipse.jdt.core.IMethod; import org.eclipse.jdt.core.JavaModelException; import org.eclipse.jdt.core.dom.CompilationUnit; import org.eclipse.jdt.core.dom.ConstructorInvocation; import org.eclipse.jdt.core.dom.Expression; import org.eclipse.jdt.core.dom.IMethodBinding; import org.eclipse.jdt.core.dom.MethodInvocation; import org.eclipse.jdt.internal.corext.dom.HierarchicalASTVisitor; import org.eclipse.jdt.internal.ui.JavaPlugin; public class CalleeJavaMethodParameterVisitor extends HierarchicalASTVisitor { <|startfocus|> private final CompilationUnit cu; <|endfocus|> private final List<ICodeMining> minings; private final ICodeMiningProvider provider; public CalleeJavaMethodParameterVisitor(CompilationUnit cu, List<ICodeMining> minings, ICodeMiningProvider provider) { this.cu= cu; this.minings= minings; this.provider= provider; } @Override public boolean visit(ConstructorInvocation constructorInvocation) { List<?> arguments= constructorInvocation.arguments(); if (!arguments.isEmpty()) { IMethod method = resolveMethodBinding(constructorInvocation.resolveConstructorBinding()); collectParameterNamesCodeMinings(method, arguments); } return super.visit(constructorInvocation); } @Override
<|startcomment|> Move the code here and add comment /* Create project and open the trace */ <|endcomment|>  String targets[] = { "peer1", "peer2" }; try (BufferedRandomAccessFile braf = new BufferedRandomAccessFile(fFileLocation, "rw")) { braf.writeBytes(TRACE_START); for (int i = 0; i < 20000; i++) { braf.writeBytes(makeEvent(i * 100, eventNames[i % 2], targets[i % 2], targets[(i + 1) % 2], Integer.toString(i % 2 + 1000))); } braf.writeBytes(TRACE_END); } <|startfocus|> beforeTest(); } <|endfocus|> /** * Open a trace in an editor */ public static void beforeTest() { SWTBotUtils.createProject(PROJECT_NAME); SWTBotTreeItem treeItem = SWTBotUtils.selectTracesFolder(fBot, PROJECT_NAME); assertNotNull(treeItem); SWTBotUtils.openTrace(PROJECT_NAME, fFileLocation.getAbsolutePath(), XMLSTUB_ID); SWTBotUtils.openView(UML2DVIEW_ID); } /** * Delete the file */ @AfterClass public static void cleanUp() { SWTBotUtils.closeViewById(UML2DVIEW_ID, fBot); fFileLocation.delete();
<|startcomment|> This part should be move to cleanUp(). Right now the project is deleted after each test and never created again <|endcomment|>  public void tearDown() { fBot.closeAllEditors(); <|startfocus|> SWTBotUtils.deleteProject(PROJECT_NAME, fBot); <|endfocus|>
<|startcomment|> instead of calling this juste move the code here and add a comment like: /* Creating project and open the trace */ <|endcomment|>  fBot = new SWTWorkbenchBot(); /* finish waiting for eclipse to load */ WaitUtils.waitForJobs(); fFileLocation = File.createTempFile("sample", ".xml"); try (BufferedRandomAccessFile braf = new BufferedRandomAccessFile(fFileLocation, "rw")) { braf.writeBytes(TRACE_START); for (int i = 0; i < 100; i++) { braf.writeBytes(makeEvent(i * 100, i % 4)); } braf.writeBytes(TRACE_END); } <|startfocus|> beforeTest(); } /** * Open a trace in an editor */ public static void beforeTest() { <|endfocus|> SWTBotUtils.createProject(PROJECT_NAME); SWTBotTreeItem treeItem = SWTBotUtils.selectTracesFolder(fBot, PROJECT_NAME); assertNotNull(treeItem); SWTBotUtils.openTrace(PROJECT_NAME, fFileLocation.getAbsolutePath(), XMLSTUB_ID); SWTBotUtils.openView(ColorsView.ID); } /** * Delete the file */ @AfterClass public static void cleanUp() { fLogger.removeAllAppenders(); fFileLocation.delete(); tearDown(); } /** * Close the editor
<|startcomment|> same here, move the code here <|endcomment|>  public static void cleanUp() { fLogger.removeAllAppenders(); fFileLocation.delete(); <|startfocus|> tearDown(); <|endfocus|>
<|startcomment|> the goal is to stress test the trace opening. I don't think you should change these value or keep 10 iteration and reduce the delay to 500. The test will teake 5sec instead of 10sec <|endcomment|>  mgr.addJobChangeListener(changeListener); for (int i = 0; i < 5; i++) { SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); SWTBotUtils.openTrace(TRACE_PROJECT_NAME, path, TRACE_TYPE, false); // Add little delay so that treads have a chance to start <|startfocus|> SWTBotUtils.delay(50); <|endfocus|> workbenchbot.closeAllEditors(); if (!status.isOK()) { SWTBotUtils.deleteProject(TRACE_PROJECT_NAME, workbenchbot); fail(handleErrorStatus(status)); } } SWTBotUtils.deleteProject(TRACE_PROJECT_NAME, workbenchbot);
<|startcomment|> "this" instead of null <|endcomment|>  IKernelTrace trace = new TmfXmlKernelTraceStub(); IPath filePath = Activator.getAbsoluteFilePath(CPU_USAGE_FILE); IStatus status = trace.validate(null, filePath.toOSString()); if (!status.isOK()) { fail(status.getException().getMessage()); } try { trace.initTrace(null, filePath.toOSString(), TmfEvent.class); } catch (TmfTraceException e) { fail(e.getMessage()); } deleteSuppFiles(trace); <|startfocus|> ((TmfTrace) trace).traceOpened(new TmfTraceOpenedSignal(null, trace, null)); <|endfocus|> /* * FIXME: Make sure this analysis is finished before running the CPU * analysis. This block can be removed once analysis dependency and * request precedence is implemented */ IAnalysisModule module = null; for (IAnalysisModule mod : TmfTraceUtils.getAnalysisModulesOfClass(trace, TidAnalysisModule.class)) { module = mod; } assertNotNull(module); module.schedule(); module.waitForCompletion(); /* End of the FIXME block */ fModule = TmfTraceUtils.getAnalysisModuleOfClass(trace, KernelCpuUsageAnalysis.class, KernelCpuUsageAnalysis.ID);
<|startcomment|> "this" instead of null <|endcomment|>  public static void setUp() { ITmfTrace trace = KERNEL_TEST_CASE.getKernelTrace(); deleteSuppFiles(trace); <|startfocus|> ((TmfTrace) trace).traceOpened(new TmfTraceOpenedSignal(null, trace, null)); <|endfocus|> IAnalysisModule module = null; for (IAnalysisModule mod : TmfTraceUtils.getAnalysisModulesOfClass(trace, KernelAnalysisModule.class)) { module = mod; } assertNotNull(module); module.schedule(); module.waitForCompletion(); fModule = TmfTraceUtils.getAnalysisModuleOfClass(trace, KernelAnalysisModule.class, KernelAnalysisModule.ID); fTrace = trace;
<|startcomment|> Is this change needed ? It seems redundant from my reading of the code. You intend to add a listener to CompilationUnitEditor for compilation unit changes (eg. user edits) to update code mining statistics. However, even without this change, modifying a source file already updates the code minings, so I'm not sure which special case this is attempting to cover. There is already a JavaCodeMiningsReconciler that is installed to every JavaEditor in createPartControl(), and every CompilationUnitEditor's createPartControl() also calls it's parent, so this change should not be needed. <|endcomment|>  * for a description of the problem. * <p> * XXX remove once the underlying problem (https://bugs.eclipse.org/bugs/show_bug.cgi?id=66176) is solved. * </p> */ private final Object fReconcilerLock= new Object(); /** * The templates page. * @since 3.4 */ private JavaTemplatesPage fTemplatesPage; /** * The Java reconciling listener used to update code minings */ private IJavaReconcilingListener fCodeMiningsReconcilingListener; <|startfocus|> <|endfocus|> /** * Creates a new compilation unit editor. */ public CompilationUnitEditor() { setDocumentProvider(JavaPlugin.getDefault().getCompilationUnitDocumentProvider()); setEditorContextMenuId("#CompilationUnitEditorContext"); //$NON-NLS-1$ setRulerContextMenuId("#CompilationUnitRulerContext"); //$NON-NLS-1$ setOutlinerContextMenuId("#CompilationUnitOutlinerContext"); //$NON-NLS-1$ // don't set help contextId, we install our own help context fSavePolicy= null; fJavaEditorErrorTickUpdater= new JavaEditorErrorTickUpdater(this); fCorrectionCommands= null;
<|startcomment|> This can be removed. <|endcomment|>  * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * IBM Corporation - initial API and implementation *******************************************************************************/ package org.eclipse.jdt.ui.tests.activation; import java.util.Arrays; import java.util.HashSet; import java.util.Set; import org.junit.Assert; <|startfocus|> //import org.junit.Assert; <|endfocus|> import org.osgi.framework.Bundle; import org.eclipse.jdt.testplugin.JavaProjectHelper; import org.eclipse.core.runtime.Platform; import org.eclipse.ui.IWorkbench; import org.eclipse.ui.IWorkbenchPage; import org.eclipse.ui.PlatformUI; import org.eclipse.jdt.core.ICompilationUnit; import org.eclipse.jdt.core.IJavaProject; import org.eclipse.jdt.core.IPackageFragment; import org.eclipse.jdt.core.IPackageFragmentRoot; import org.eclipse.jdt.internal.ui.javaeditor.EditorUtility; import junit.framework.TestCase; public class JavaActivationTest extends TestCase { private IJavaProject project; 
<|startcomment|> I would remove the extranous whitespaces in the file. <|endcomment|> //import org.junit.Assert; import org.osgi.framework.Bundle; import org.eclipse.jdt.testplugin.JavaProjectHelper; import org.eclipse.core.runtime.Platform; import org.eclipse.ui.IWorkbench; import org.eclipse.ui.IWorkbenchPage; import org.eclipse.ui.PlatformUI; import org.eclipse.jdt.core.ICompilationUnit; import org.eclipse.jdt.core.IJavaProject; import org.eclipse.jdt.core.IPackageFragment; import org.eclipse.jdt.core.IPackageFragmentRoot; import org.eclipse.jdt.internal.ui.javaeditor.EditorUtility; import junit.framework.TestCase; public class JavaActivationTest extends TestCase { <|startfocus|> <|endfocus|> private IJavaProject project; private static final String[] inactiveBundles= new String[] { "org.apache.xerces", "org.eclipse.jdt.astview", "org.eclipse.jdt.jeview", "org.eclipse.reftracker", "org.eclipse.swt.sleak", "org.eclipse.swt.spy", "com.jcraft.jsch", "javax.servlet", "javax.servlet.jsp", "org.apache.ant", "org.apache.commons.el", "org.apache.commons.logging", "org.apache.jasper", "org.apache.lucene", "org.apache.lucene.analysis",
<|startcomment|> HashSet can take a collection like Arrays.asList(inactiveBundles) in the constructor. Not the end of the world though either way. <|endcomment|>  IPackageFragment pack= sourceFolder.createPackageFragment("pack0", false, null); StringBuffer buf= new StringBuffer(); buf.append("package pack0;\n"); buf.append("public class List1 {\n}\n"); return pack.createCompilationUnit("List1.java", buf.toString(), false, null); } public void testOpenJavaEditor() throws Exception { ICompilationUnit unit= createTestCU(); EditorUtility.openInEditor(unit); <|startfocus|> Set set= new HashSet(); set.addAll(Arrays.asList(inactiveBundles)); <|endfocus|> checkNotLoaded(set); } public void checkNotLoaded(Set inactiveBundles) { Bundle bundle= Platform.getBundle("org.eclipse.jdt.ui.tests"); Bundle[] bundles= bundle.getBundleContext().getBundles(); for (int i= 0; i < bundles.length; i++) { if (bundles[i].getState() == Bundle.ACTIVE && inactiveBundles.contains(bundles[i].getSymbolicName())) { Assert.fail ("plugin should not be activated: "+bundles[i].getSymbolicName()) ; } } } } 
<|startcomment|> v.numberValue() could return null if the value is dependent or unknown. <|endcomment|>  private static IType createAutoType(ICPPASTInitializerClause initClause, IASTDeclSpecifier declSpec, IASTDeclarator declarator) { // C++0x: 7.1.6.4 <|startfocus|> if (initClause == null) { return new ProblemType(ISemanticProblem.TYPE_CANNOT_DEDUCE_AUTO_TYPE); } <|endfocus|> IType type = AutoTypeResolver.AUTO_TYPE; IType initType = null; ValueCategory valueCat= null; ICPPClassTemplate initializer_list_template = null; if (initClause instanceof ICPPASTInitializerList) { initializer_list_template = get_initializer_list(declSpec); if (initializer_list_template == null) { return new ProblemType(ISemanticProblem.TYPE_CANNOT_DEDUCE_AUTO_TYPE); } type = (IType) CPPTemplates.instantiate(initializer_list_template, new ICPPTemplateArgument[] { new CPPTemplateTypeArgument(type) }, initClause); if (type instanceof IProblemBinding) { return new ProblemType(ISemanticProblem.TYPE_CANNOT_DEDUCE_AUTO_TYPE); } } type = decorateType(type, declSpec, declarator); final ICPPEvaluation evaluation = initClause.getEvaluation(); initType= evaluation.getTypeOrFunctionSet(declarator); valueCat= evaluation.getValueCategory(declarator);
<|startcomment|> optional: import static? <|endcomment|>  } return recreate(ref, newLeaf, hasVersioning()); } Ref doPeel(Ref leaf) throws MissingObjectException, IOException { try (RevWalk rw = new RevWalk(repository)) { RevObject obj = rw.parseAny(leaf.getObjectId()); if (obj instanceof RevTag) { return new ObjectIdRef.PeeledTag( leaf.getStorage(), leaf.getName(), leaf.getObjectId(), rw.peel(obj).copy(), hasVersioning() ? leaf.getUpdateIndex() <|startfocus|> : Ref.UNDEFINED_UPDATE_INDEX); <|endfocus|> } else { return new ObjectIdRef.PeeledNonTag( leaf.getStorage(), leaf.getName(), leaf.getObjectId(), hasVersioning() ? leaf.getUpdateIndex() : Ref.UNDEFINED_UPDATE_INDEX); } } } static Ref recreate(Ref old, Ref leaf, boolean hasVersioning) { if (old.isSymbolic()) { Ref dst = recreate(old.getTarget(), leaf, hasVersioning); return new SymbolicRef(old.getName(), dst, hasVersioning ? old.getUpdateIndex()
<|startcomment|> When you click on the tool tip shell, the time graph loses focus, this gets called and the tool tip is disposed. <|endcomment|>  */ public abstract class TmfAbstractToolTipHandler { private static final int MOUSE_DEADZONE = 5; private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; /** * Important note: this is being added to a display filter, this may leak, * make sure it is removed when not needed. */ private final Listener fListener = this::disposeIfExited; private final Listener fFocusLostListener = event -> { Shell tipShell = fTipShell; <|startfocus|> if(tipShell!= null) { <|endfocus|> tipShell.dispose(); } }; /** * Dispose the shell if we exit the range. * * @param e * The event which occurred */ private void disposeIfExited(Event e) { if (!(e.widget instanceof Control)) { return; } Control control = (Control) e.widget; if (control != null && !control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell;
<|startcomment|> space <|endcomment|>  private static final int MOUSE_DEADZONE = 5; private static final int OFFSET = 16; private Composite fTipComposite; private Shell fTipShell; private Rectangle fInitialDeadzone; /** * Important note: this is being added to a display filter, this may leak, * make sure it is removed when not needed. */ private final Listener fListener = this::disposeIfExited; private final Listener fFocusLostListener = event -> { Shell tipShell = fTipShell; <|startfocus|> if(tipShell!= null) { <|endfocus|> tipShell.dispose(); } }; /** * Dispose the shell if we exit the range. * * @param e * The event which occurred */ private void disposeIfExited(Event e) { if (!(e.widget instanceof Control)) { return; } Control control = (Control) e.widget; if (control != null && !control.isDisposed()) { Point pt = control.toDisplay(e.x, e.y); Shell tipShell = fTipShell;
<|startcomment|> I would just change this to 'category'. <|endcomment|>  } return result; } /** * Sets the completion proposal categories which are excluded from the * default proposal list and reloads the registry. * * @param categories the array with the IDs of the excluded categories * @see #CODEASSIST_EXCLUDED_CATEGORIES * @since 3.4 */ public static void setExcludedCompletionProposalCategories(String[] categories) { Assert.isLegal(categories != null); StringBuilder buf= new StringBuilder(50 * categories.length); <|startfocus|> for (String categorie : categories) { buf.append(categorie); <|endfocus|> buf.append('\0'); } getPreferenceStore().setValue(CODEASSIST_EXCLUDED_CATEGORIES, buf.toString()); CompletionProposalComputerRegistry.getDefault().reload(); } /** * Returns the value for the given key in the given context. * @param key The preference key * @param project The current context or <code>null</code> if no context is available and the * workspace setting should be taken. Note that passing <code>null</code> should * be avoided.
<|startcomment|> The same thing as mentioned below can also happen here. <|endcomment|>  public boolean visit(ConstructorInvocation constructorInvocation) { List<?> arguments= constructorInvocation.arguments(); if (!arguments.isEmpty()) { IMethodBinding constructorBinding= constructorInvocation.resolveConstructorBinding(); <|startfocus|> IMethod method = resolveMethodBinding(constructorBinding); collectParameterNamesCodeMinings(method, arguments, constructorBinding.isVarargs()); <|endfocus|> } return super.visit(constructorInvocation);
<|startcomment|> methodBinding.isVarargs() will NPE if the line in question can't resolve its bindings. MethodInvocation.resolveMethodBinding() can return null, especially if there's plenty of errors. Your local resolveMethodBinding() checks that, so it's fine but methodBinding.isVarargs() would fail. <|endcomment|>  public boolean visit(MethodInvocation methodInvocation) { List<?> arguments= methodInvocation.arguments(); if (!arguments.isEmpty()) { IMethodBinding methodBinding= methodInvocation.resolveMethodBinding(); <|startfocus|> IMethod method = resolveMethodBinding(methodBinding); collectParameterNamesCodeMinings(method, arguments, methodBinding.isVarargs()); <|endfocus|> } return super.visit(methodInvocation);
<|startcomment|> A missing word <|endcomment|> ***************************************************************************** * Copyright (c) 2010-2019, Tamas Szabo, itemis AG, Gabor Bergmann, IncQuery Labs Ltd. * This program and the accompanying materials are made available under the * terms of the Eclipse Public License v. 2.0 which is available at * http://www.eclipse.org/legal/epl-v20.html. * * SPDX-License-Identifier: EPL-2.0 *******************************************************************************/ package org.eclipse.viatra.query.runtime.matchers.memories; /** <|startfocus|> * Represents that a replacement between timestamps. * Either old or new can be null, but not at the same time. <|endfocus|> * * @author Tamas Szabo */ public class TimestampReplacement<Timestamp extends Comparable<Timestamp>> { public final Timestamp oldValue; public final Timestamp newValue; public TimestampReplacement(final Timestamp oldValue, final Timestamp newValue) { if (oldValue == null && newValue == null) { throw new IllegalArgumentException("Old and new cannot be both null at the same time!"); } this.oldValue = oldValue; this.newValue = newValue; } } 
<|startcomment|> Extra . <|endcomment|>  * This program and the accompanying materials are made available under the * terms of the Eclipse Public License v. 2.0 which is available at * http://www.eclipse.org/legal/epl-v20.html. * * SPDX-License-Identifier: EPL-2.0 *******************************************************************************/ package org.eclipse.viatra.query.runtime.matchers.memories; /** <|startfocus|> * Represents that a replacement between timestamps. * Either old or new can be null, but not at the same time. <|endfocus|> * * @author Tamas Szabo */ public class TimestampReplacement<Timestamp extends Comparable<Timestamp>> { public final Timestamp oldValue; public final Timestamp newValue; public TimestampReplacement(final Timestamp oldValue, final Timestamp newValue) { if (oldValue == null && newValue == null) { throw new IllegalArgumentException("Old and new cannot be both null at the same time!"); } this.oldValue = oldValue; this.newValue = newValue; } } 
<|startcomment|> You should put your name <|endcomment|> *************************************************************************** * Copyright (c) 2019 CEA LIST and others. * * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: <|startfocus|> * CEA LIST - Initial API and implementation * <|endfocus|> *****************************************************************************/ package org.eclipse.papyrus.model2doc.core.generatorconfiguration.operations; import org.eclipse.emf.common.util.URI; import org.eclipse.osgi.util.NLS; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentStructureGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.internal.Activator; /** * utility class for the operations of GeneratorConfiguration metamodel */ public class GeneratorConfigurationOperations { /** * * @param generatorConfiguration * a generatorConfiguration element * @param uriKind * the kind of expected URI * @param fileExtension
<|startcomment|> Capital letter :-) <|endcomment|>  * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * CEA LIST - Initial API and implementation * *****************************************************************************/ package org.eclipse.papyrus.model2doc.core.generatorconfiguration.operations; import org.eclipse.emf.common.util.URI; import org.eclipse.osgi.util.NLS; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.DefaultDocumentStructureGeneratorConfiguration; import org.eclipse.papyrus.model2doc.core.generatorconfiguration.internal.Activator; /** <|startfocus|> * utility class for the operations of GeneratorConfiguration metamodel <|endfocus|> */ public class GeneratorConfigurationOperations { /** * * @param generatorConfiguration * a generatorConfiguration element * @param uriKind * the kind of expected URI * @param fileExtension * the extension file * @return * the path of the file build from the paramaters */ public static final String getDocumentStructureFileEcoreURI(final DefaultDocumentStructureGeneratorConfiguration generatorConfiguration, final String fileExtension) { final String folderName = generatorConfiguration.getStructureFolder(); final String documentName = generatorConfiguration.getDocumentName();
<|startcomment|> Externalize string ? <|endcomment|>  return newURI.toString(); } if (false == uri.isPlatform()) { // we convert a local URI as platform resource URI final String projectName = generatorConfiguration.eResource().getURI().segment(1); uri = URI.createPlatformResourceURI(projectName, true).appendSegment(folderName); } if (uri.isPlatform()) { if (uri.isPlatformPlugin()) { <|startfocus|> Activator.log.warn(NLS.bind("The path {0} must not be a platform path", uri.toString())); <|endfocus|> return null; } return uri.appendSegment(documentName).appendFileExtension(fileExtension).toString(); } return null; } /** * TODO : check if used! * * @param configuration * @param fileExtension * @return */ public static final String getDocumentFileOSURI(final DefaultDocumentGeneratorConfiguration configuration, final String fileExtension) { final String folderName = configuration.getDocumentFolder(); final String documentName = configuration.getDocumentName(); URI uri = URI.createURI(folderName);
<|startcomment|> Externalize string ? <|endcomment|>  return newURI.toString(); } if (false == uri.isPlatform()) { // we convert a local URI as platform resource URI final String projectName = configuration.eResource().getURI().segment(1); uri = URI.createPlatformResourceURI(projectName, true).appendSegment(folderName); } if (uri.isPlatform()) { if (uri.isPlatformPlugin()) { <|startfocus|> Activator.log.warn(NLS.bind("The path {0} must not be a platform path", uri.toString())); <|endfocus|> return null; } uri = uri.appendSegment(documentName).appendFileExtension(fileExtension); } return null; } } 
<|startcomment|> It doesn't accelerate tests, this is the time before the swtbot decides if the the waiting time for an operation should timeout <|endcomment|>  private static ITmfTrace fNewExperiment; // ------------------------------------------------------------------------ // Test instance maintenance // ------------------------------------------------------------------------ /** * Default constructor */ public CtfTmfExperimentTrimmingTest() { // do nothing } /** * Setup before the test suite * * @throws IOException * failed to load the file */ @BeforeClass public static void beforeClass() throws IOException { SWTBotUtils.initialize(); /* set up for swtbot */ <|startfocus|> SWTBotPreferences.TIMEOUT = 20000; /* 20 second timeout */ <|endfocus|> fLogger.removeAllAppenders(); fLogger.addAppender(new NullAppender()); File parentDir = FileUtils.toFile(FileLocator.toFileURL(CtfTestTrace.TRACE_EXPERIMENT.getTraceURL())); File[] traceFiles = parentDir.listFiles(); ITmfTrace traceValidator = new CtfTmfTrace(); fBot = new SWTWorkbenchBot(); SWTBotUtils.createProject(PROJECT_NAME); int openedTraces = 0; for (File traceFile : traceFiles) { String absolutePath = traceFile.getAbsolutePath(); if (traceValidator.validate(null, absolutePath).isOK()) {
<|startcomment|> We should not leave this in the code. <|endcomment|>  protected boolean hasJREInClassPath(IJavaProject javaProject) { if (javaProject != null) { try { IClasspathEntry[] oldClasspaths= javaProject.getRawClasspath(); for (int i= 0; i < oldClasspaths.length; i++) { if (isJREContainer(oldClasspaths[i].getPath())) { return true; } } } catch (JavaModelException e) { <|startfocus|> // TODO Auto-generated catch block e.printStackTrace(); <|endfocus|> } } return false;
<|startcomment|> This will use the Bundle.compareTo implementation which will sort by bundle ID which is not what you want here. Should be something like this (untested, may not compile): .sorted((b1, b2)-> b2.getVersion().compareTo(b1.getVersion)) <|endcomment|>  getRequirementFilter(symbolicName, versionRange)); Collection<BundleCapability> matchingBundleCapabilities = fwkWiring.findProviders(ModuleContainer .createRequirement(IdentityNamespace.IDENTITY_NAMESPACE, directives, Collections.emptyMap())); if (matchingBundleCapabilities.isEmpty()) { return null; } Bundle[] results = matchingBundleCapabilities.stream().map(c -> c.getRevision().getBundle()) // Remove all the bundles that are installed or uninstalled .filter(bundle -> (bundle.getState() & (Bundle.INSTALLED | Bundle.UNINSTALLED)) == 0) <|startfocus|> .sorted() // highest version first <|endfocus|> .toArray(Bundle[]::new); return results.length > 0 ? results : null;
<|startcomment|> This condition is not useful anymore because of your first added condition <|endcomment|>  try { XMultiServiceFactory xMultiServiceFactory = odtEditor.getXMultiServiceFactory(); // create a text table Object obj = xMultiServiceFactory.createInstance("com.sun.star.text.TextTable"); // $NON-NLS-1$ XTextTable textTable = UnoRuntime.queryInterface(XTextTable.class, obj); // Default background color Object backColor = 0x6AA84F; // // If defined style then update backColor if (style != null) { backColor = style; } <|startfocus|> if (numRows > 0 && numCols > 0) { <|endfocus|> // Verify if there are row titles if (table.getRowTitles() != null && !table.getRowTitles().isEmpty()) { // update column counters numCols++; } // Verify if there are column titles if (table.getColumnTitles() != null && !table.getColumnTitles().isEmpty()) { // update row counter numRows++; } // Initialize and add table textTable.initialize(numRows, numCols); addTextContent(xTextCursor, textTable); endParagraph(xTextCursor); 
<|startcomment|> Fixing your API documentation TODOs before submitting a patch for review, helps your reviewer understand the patch :) <|endcomment|>  /** * Returns {@code true} if the value of the expression depends on template parameters. */ boolean isValueDependent(); /** * Returns {@code true} if the expression is a compile-time constant expression. * * @param point the point of instantiation, determines the scope for name lookups */ boolean isConstantExpression(); /** * Return the result of the noexcept-operator applied to the expression. * [expr.unary.noexcept] <|startfocus|> * @param inCalledContext TODO <|endfocus|> */ boolean isNoexcept(boolean inCalledContext); /** * Returns {@code true} if this expression is equivalent to 'other' for * declaration matching purposes. */ boolean isEquivalentTo(ICPPEvaluation other); /** * Returns the type of the expression. * * If the expression evaluates to a function set, a {@code FunctionSetType} is returned. */ IType getType(); /** * Returns the value of the expression. */ IValue getValue(); /**
<|startcomment|> A binary type-id expression is evaluated at compile time, so it can never throw. <|endcomment|>  public boolean isNoexcept(boolean inCalledContext) { <|startfocus|> // TODO Auto-generated method stub return false; <|endfocus|>
<|startcomment|> As we don't know which branch will be taken, we need to assume that this can throw if any of the condition, positive, or negative expressions can throw. <|endcomment|>  public boolean isNoexcept(boolean inCalledContext) { <|startfocus|> // TODO Auto-generated method stub return false; <|endfocus|>
<|startcomment|> This can never throw. (It actually should never exist outside of a dependent context, and we shouldn't try to evaluate noexcept in a dependent context, so feel free to add an "assert false" as well.) <|endcomment|>  public boolean isNoexcept(boolean inCalledContext) { <|startfocus|> // TODO Auto-generated method stub <|endfocus|> return true;
<|startcomment|> This could throw if e.g. evaluation of fFieldOwner can, but this also shouldn't exist outside of a dependent context, so let's also "assert false" and "return true". <|endcomment|>  public boolean isNoexcept(boolean inCalledContext) { <|startfocus|> // TODO Auto-generated method stub return false; <|endfocus|>
<|startcomment|> Evaluated at compile time, cannot throw. <|endcomment|>  public boolean isNoexcept(boolean inCalledContext) { <|startfocus|> // TODO Auto-generated method stub return false; <|endfocus|>
<|startcomment|> Shouldn't exist outside of a dependent context, "assert false". <|endcomment|>  public boolean isNoexcept(boolean inCalledContext) { <|startfocus|> // TODO Auto-generated method stub return false; <|endfocus|>
<|startcomment|> Defeats the purpose? Will still fill up the list... <|endcomment|>  private void ensureSize(int index) { List<@Nullable IEventDeclaration> list = fEvents; if (list instanceof ArrayList) { if (index > 50000) { fEvents = new SparseList(fEvents); } ((ArrayList<@Nullable IEventDeclaration>) list).ensureCapacity(index); while (list.size() <= index) { list.add(null); <|startfocus|> } <|endfocus|> }
<|startcomment|> space <|endcomment|>  public SparseList(List<@Nullable IEventDeclaration> events) { <|startfocus|> for(int i = 0; i < events.size(); i++) { <|endfocus|> IEventDeclaration event = events.get(i); if(event!= null) { add(i, event); } }
<|startcomment|> Then it's really next added, not last added? <|endcomment|>  public boolean add(@Nullable IEventDeclaration e) { synchronized (this) { <|startfocus|> fInnerEvents.put(fLastAdded, e); fLastAdded++; <|endfocus|> } return true;
<|startcomment|> space <|endcomment|>  public boolean addAll(int index, Collection<? extends @Nullable IEventDeclaration> c) { int key= index; <|startfocus|> for(IEventDeclaration event : c) { if(event!= null) { <|endfocus|> add(key, event); } key++; } return true;
<|startcomment|> space <|endcomment|>  public void add(int index, @Nullable IEventDeclaration element) { <|startfocus|> if(index > fLastAdded) { fLastAdded = index; <|endfocus|> } add(element);
<|startcomment|> typo cancel <|endcomment|>  */ public class Text extends Scrollable { int tabs, oldStart, oldEnd; boolean doubleClick, ignoreModify, ignoreVerify, ignoreCharacter, allowPasswordChar; String message; int[] segments; int clearSegmentsCount = 0; RECT searchRect, cancelRect; boolean mouseInSearch, mouseInCancel; static final char LTR_MARK = '\u200e'; static final char RTL_MARK = '\u200f'; static final int IDI_SEARCH = 101; <|startfocus|> static final int IDI_CACNEL = 102; <|endfocus|> static final int SEARCH_ICON_MARGIN = 4; /** * The maximum number of characters that can be entered * into a text widget. * <p> * Note that this value is platform dependent, based upon * the native widget implementation. * </p> */ public static final int LIMIT; /** * The delimiter used by multi-line text widgets. When text * is queried and from the widget, it will be delimited using * this delimiter. */ public static final String DELIMITER; /* * This code is intentionally commented.
<|startcomment|> This part of the javadoc is redundant. <|endcomment|>  * header until end of trailer. * * @return time in milliseconds spent writing the pack output, from start of * header until end of trailer. The transfer speed can be * approximated by dividing {@link #getTotalBytes()} by this value. */ public long getTimeWriting() { return statistics.timeWriting; } /** <|startfocus|> * Get Number of trees traversed in the walk when writing the pack. * <|endfocus|> * @return number of trees traversed in the walk when writing the pack. * @since 5.4 */ public long getTreesTraversed() { return statistics.treesTraversed; } /** * Get total time spent processing this pack. * * @return total time spent processing this pack. */ public long getTimeTotal() { return statistics.timeCounting + statistics.timeSearchingForReuse + statistics.timeSearchingForSizes + statistics.timeCompressing + statistics.timeWriting; } /** * Get the average output speed in terms of bytes-per-second. *
<|startcomment|> 2019 <|endcomment|> ***************************************************************************** <|startfocus|> * Copyright (c) 2017 Ericsson <|endfocus|> * * All rights reserved. This program and the accompanying materials are * made available under the terms of the Eclipse Public License v1.0 which * accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.tmf.ui.viewers; import org.eclipse.swt.SWT; import org.eclipse.swt.events.MouseEvent; import org.eclipse.swt.events.MouseTrackAdapter; import org.eclipse.swt.graphics.Point; import org.eclipse.swt.graphics.Rectangle; import org.eclipse.swt.layout.GridData; import org.eclipse.swt.layout.GridLayout; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Control; import org.eclipse.swt.widgets.Display; import org.eclipse.swt.widgets.Event; import org.eclipse.swt.widgets.Label; import org.eclipse.swt.widgets.Listener; import org.eclipse.swt.widgets.Shell; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.widgets.TimeGraphTooltipHandler; /** * Abstract tool tip handler. * * @since 3.2
<|startcomment|> Why do it twice? <|endcomment|>  final Display display = parent.getDisplay(); if (fTipShell != null && !fTipShell.isDisposed()) { fTipShell.dispose(); } fTipShell = new Shell(parent, SWT.ON_TOP | SWT.TOOL); // Deregister display filters on dispose fTipShell.addDisposeListener(e -> e.display.removeFilter(SWT.MouseMove, fListener)); fTipShell.addDisposeListener(e -> e.display.removeFilter(SWT.FocusOut, fFocusLostListener)); fTipShell.addListener(SWT.Deactivate, e -> { <|startfocus|> if (fTipShell.isDisposed()) { <|endfocus|> fTipShell.dispose(); } }); GridLayout gridLayout = new GridLayout(); gridLayout.numColumns = 2; gridLayout.marginWidth = 2; gridLayout.marginHeight = 2; fTipShell.setLayout(gridLayout); fTipShell.setBackground(display.getSystemColor(SWT.COLOR_INFO_BACKGROUND)); fTipComposite = new Composite(fTipShell, SWT.NONE); fTipComposite.setLayout(new GridLayout(3, false)); setupControl(fTipComposite);
<|startcomment|> You're using this here, and below (in createInvocation) to avoid replacing field references/assignment with get/set. However it's still valid to replace the field with its getter even if the setter is not enabled, or to replace an assignment of the field with the setter even if the getter is not enabled. <|endcomment|>  private boolean considerBinding(IBinding binding, ASTNode node) { if (!(binding instanceof IVariableBinding)) return false; boolean result= Bindings.equals(fFieldBinding, ((IVariableBinding)binding).getVariableDeclaration()); <|startfocus|> if (!result || (fEncapsulateDeclaringClass && !fGetter.isEmpty() && !fSetter.isEmpty())) <|endfocus|> return result; AbstractTypeDeclaration type= ASTNodes.getParent(node, AbstractTypeDeclaration.class); if (type != null) { ITypeBinding declaringType= type.resolveBinding(); return !Bindings.equals(fDeclaringClassBinding, declaringType); } return true;
<|startcomment|> Unless this is needed for usage sooner, it doesn't make sense to move it here. It was easier to read the code having the 2 fields set together at the bottom. <|endcomment|>  invocation.setName(ast.newSimpleName(fSetter)); if (receiver != null) invocation.setExpression((Expression)fRewriter.createCopyTarget(receiver)); invocation.arguments().add(argument); if ("++".equals(operator)) { //$NON-NLS-1$ argument.setOperator(InfixExpression.Operator.PLUS); } else if ("--".equals(operator)) { //$NON-NLS-1$ argument.setOperator(InfixExpression.Operator.MINUS); } else { Assert.isTrue(false, "Should not happen"); //$NON-NLS-1$ } <|startfocus|> fReferencingSetter= true; <|endfocus|> MethodInvocation getter= ast.newMethodInvocation(); getter.setName(ast.newSimpleName(fGetter)); if (receiver != null) getter.setExpression((Expression)fRewriter.createCopyTarget(receiver)); argument.setLeftOperand(getter); argument.setRightOperand(ast.newNumberLiteral("1")); //$NON-NLS-1$ fReferencingGetter= true; return invocation;
<|startcomment|> Is changing this necessary ? I would keep it as it was. <|endcomment|>  if (fEncapsulateDeclaringClass) comment.addSetting(RefactoringCoreMessages.SelfEncapsulateField_use_accessors); else comment.addSetting(RefactoringCoreMessages.SelfEncapsulateField_do_not_use_accessors); if (fGenerateJavadoc) comment.addSetting(RefactoringCoreMessages.SelfEncapsulateField_generate_comments); final EncapsulateFieldDescriptor descriptor= RefactoringSignatureDescriptorFactory.createEncapsulateFieldDescriptor(project, description, comment.asString(), arguments, flags); arguments.put(JavaRefactoringDescriptorUtil.ATTRIBUTE_INPUT, JavaRefactoringDescriptorUtil.elementToHandle(project, fField)); <|startfocus|> arguments.put(ATTRIBUTE_VISIBILITY, Integer.valueOf(JdtFlags.getVisibilityCode(visibility)).toString()); <|endfocus|> arguments.put(ATTRIBUTE_INSERTION, Integer.valueOf(fInsertionIndex).toString()); if (fCreateSetter) { arguments.put(ATTRIBUTE_SETTER, fSetterName); } if (fCreateGetter) { arguments.put(ATTRIBUTE_GETTER, fGetterName); } arguments.put(ATTRIBUTE_COMMENTS, Boolean.valueOf(fGenerateJavadoc).toString()); arguments.put(ATTRIBUTE_DECLARING, Boolean.valueOf(fEncapsulateDeclaringClass).toString()); final DynamicValidationRefactoringChange result= new DynamicValidationRefactoringChange(descriptor, getName()); TextChange[] changes= fChangeManager.getAllChanges(); pm.beginTask(NO_NAME, changes.length);
<|startcomment|> The assertFormatterResult(); is lost from here. <|endcomment|>  //extern "C"{ //void func(); //} public void testLinkage2_Bug299482() throws Exception { fOptions.put(DefaultCodeFormatterConstants.FORMATTER_INSERT_SPACE_BEFORE_OPENING_BRACE_IN_LINKAGE_DECLARATION, DefaultCodeFormatterConstants.FALSE); assertFormatterResult(); } //extern "C" { //void func(); //} //extern "C" //{ //void func(); //} public void testLinkage3_Bug299482() throws Exception { fOptions.put(DefaultCodeFormatterConstants.FORMATTER_BRACE_POSITION_FOR_LINKAGE_DECLARATION, <|startfocus|> DefaultCodeFormatterConstants.NEXT_LINE); <|endfocus|> } //#define EMPTY1(x) //#define EMPTY2(x) //int main() { // EMPTY1(bool x = true); // EMPTY2(bool x = true); // return 0; //} //#define EMPTY1(x) //#define EMPTY2(x) //int main() { // EMPTY1(bool x = true); // EMPTY2(bool x = true); // return 0; //} public void testEmptyMacros_Bug361768() throws Exception { assertFormatterResult(); } 
<|startcomment|> 2015, 2019 (Ahah) <|endcomment|> ***************************************************************************** <|startfocus|> * Copyright (c) 2015 Obeo. <|endfocus|> * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - initial API and implementation *******************************************************************************/ package org.eclipse.sirius.tests.sample.component.service; import java.util.ArrayList; import java.util.Collection; import java.util.HashSet; import java.util.List; import java.util.function.Predicate; import org.eclipse.emf.common.notify.Notification; import org.eclipse.emf.ecore.EObject; import org.eclipse.gmf.runtime.notation.DrawerStyle; import org.eclipse.gmf.runtime.notation.Node; import org.eclipse.gmf.runtime.notation.NotationPackage; import org.eclipse.sirius.diagram.DDiagram; import org.eclipse.sirius.diagram.DDiagramElement; import org.eclipse.sirius.diagram.DNodeContainer; import org.eclipse.sirius.diagram.business.api.query.EObjectQuery; import org.eclipse.sirius.diagram.ui.business.api.view.SiriusGMFHelper; import org.eclipse.sirius.ext.base.Option;
<|startcomment|> missing argument description <|endcomment|>  components.addAll(component.getReferences2()); for (Component child : component.getChildren()) { components.addAll(getReference2Hierarchy(child)); } return components; } /** * A reference is to display if: * <UL> * <LI>the source is not collapsed and the target is not collapsed and there is no "shortest reference" to * display</LI> * <LI></LI> * <LI></LI> * </UL> * <|startfocus|> * @param source <|endfocus|> * @param sourceView * @param targetView * @return */ public boolean isReferenceToDisplay(Component source, DNodeContainer sourceView, DNodeContainer targetView) { if (!isIndirectlyCollapsed(sourceView) && !isIndirectlyCollapsed(targetView)) { for (DDiagramElement child : sourceView.getOwnedDiagramElements()) { if (child instanceof DNodeContainer) { if (((DNodeContainer) child).getActualMapping().getName().equals("ComponentRegion")) { for (DDiagramElement child2 : ((DNodeContainer) child).getOwnedDiagramElements()) {
<|startcomment|> missing blank line between method (ok je chipote) <|endcomment|>  if (isReferenceDisplayByChild((Component) child2.getTarget(), (DNodeContainer) child2, targetView)) { return true; } } } } } return true; } return false; } protected boolean isIndirectlyCollapsed(DNodeContainer container) { if (isContainerCollapsed(container)) { return true; } else if (container.eContainer() instanceof DNodeContainer && isContainerCollapsed((DNodeContainer) container.eContainer())) { return true; } else { return false; } <|startfocus|> } <|endfocus|> protected boolean isContainerCollapsed(DNodeContainer container) { Node gmfNode = SiriusGMFHelper.getGmfNode(container); if (gmfNode != null) { for (Object subNode : gmfNode.getChildren()) { if (subNode instanceof Node) { for (Object style : ((Node) subNode).getStyles()) { if (style instanceof DrawerStyle) { return ((DrawerStyle) style).isCollapsed(); } } } } } return false; } private void appendChildren(Component component, Collection<Component> allChildren) {
<|startcomment|> that the original <|endcomment|>  SWTBotGefEditPart parentEdgeTargetEditPart = editor.getEditPart("DC.2.1", AbstractDiagramElementContainerEditPart.class); DEdgeEditPart edgeEditPart = (DEdgeEditPart) ((AbstractDiagramElementContainerEditPart) edgeSourceEditPart.part()).getSourceConnections().get(0); assertTrue("The edge should be visible after diagram opening.", edgeEditPart.getFigure().isVisible()); collapseOrExpandContainer(parentEdgeSourceEditPart); <|startfocus|> // Check that original edge is no longer visible but is always here <|endfocus|> assertFalse("The edge should be hidden after collapsing the container of the target of the edge.", edgeEditPart.getFigure().isVisible()); assertEquals("The edge already exists, even if it is not visible.", 1, ((AbstractDiagramElementContainerEditPart) edgeSourceEditPart.part()).getSourceConnections().size()); // Check that no other edge appears (because the collapse notification has not yet been registered) assertEquals("No edge from the collapsed container should appear because the collapse notification has not yet been registered.", 0,
<|startcomment|> Your waiting condition triggers a modification. Shouldn't this only check if there is a "toggle" figure and then the test click on it? That would also avoid having 2 consecutive waiting conditions which "looks strange". <|endcomment|>  private void collapseOrExpandContainer(SWTBotGefEditPart container) { ICondition editPartResizedCondition = new CheckEditPartResized(container); // Select the region contained in the container AbstractDiagramElementContainerEditPart part = (AbstractDiagramElementContainerEditPart) container.part(); GraphicalHelper.getAbsoluteBoundsIn100Percent(part); Point top = GraphicalHelper.getAbsoluteBoundsIn100Percent(part).getTop(); editor.click(top.getTranslated(0, 40)); // Collapse the region // Add a wait condition to have the collapse button displayed and click on it <|startfocus|> bot.waitUntil(new ICondition() { <|endfocus|> @Override public boolean test() throws Exception { IFigure handleLayer = LayerManager.Helper.find(part).getLayer(LayerConstants.HANDLE_LAYER); Point toggleFigureLocation; if (handleLayer != null) { for (Object figure : handleLayer.getChildren()) { if (figure instanceof CompartmentCollapseHandle) { toggleFigureLocation = ((CompartmentCollapseHandle) figure).getLocation(); if (toggleFigureLocation.x != 0 && toggleFigureLocation.y != 0) { // Use the center of the figure and click on it
<|startcomment|> add missing braces while you are changing this <|endcomment|>  private Repository remoteRepository; private URIish remoteURI; @Override @Before public void setUp() throws Exception { super.setUp(); final TestRepository<Repository> src = createTestRepository(); final String srcName = src.getRepository().getDirectory().getName(); ServletContextHandler app = server.addContext("/git"); GitServlet gs = new GitServlet(); gs.setRepositoryResolver((HttpServletRequest req, String name) -> { <|startfocus|> if (!name.equals(srcName)) throw new RepositoryNotFoundException(name); final Repository db = src.getRepository(); db.incrementOpen(); return db; }); <|endfocus|> gs.setReceivePackFactory(new DefaultReceivePackFactory() { @Override public ReceivePack create(HttpServletRequest req, Repository db) throws ServiceNotEnabledException, ServiceNotAuthorizedException { ReceivePack rp = super.create(req, db); rp.sendError("message line 1"); rp.sendError("no soup for you!"); rp.sendError("come back next year!"); return rp; } }); app.addServlet(new ServletHolder(gs), "/*"); 
<|startcomment|> trailing whitespace, tabs replaced by spaces <|endcomment|>  private URIish remoteURI; @Override @Before public void setUp() throws Exception { super.setUp(); final TestRepository<Repository> src = createTestRepository(); final String srcName = src.getRepository().getDirectory().getName(); ServletContextHandler app = server.addContext("/git"); GitServlet gs = new GitServlet(); gs.setRepositoryResolver((HttpServletRequest req, String name) -> { <|startfocus|> if (!name.equals(srcName)) throw new RepositoryNotFoundException(name); final Repository db = src.getRepository(); db.incrementOpen(); return db; }); <|endfocus|> gs.setReceivePackFactory(new DefaultReceivePackFactory() { @Override public ReceivePack create(HttpServletRequest req, Repository db) throws ServiceNotEnabledException, ServiceNotAuthorizedException { ReceivePack rp = super.create(req, db); rp.sendError("message line 1"); rp.sendError("no soup for you!"); rp.sendError("come back next year!"); return rp; } }); app.addServlet(new ServletHolder(gs), "/*"); server.setUp(); 
<|startcomment|> line is too wide <|endcomment|>  private void verifyObjectsOrder(ObjectId objectsOrder[]) { final List<PackIndex.MutableEntry> entries = new ArrayList<>(); for (MutableEntry me : pack) { entries.add(me.cloneEntry()); } <|startfocus|> Collections.sort(entries, (MutableEntry o1, MutableEntry o2) -> Long.signum(o1.getOffset() - o2.getOffset())); <|endfocus|> int i = 0; for (MutableEntry me : entries) { assertEquals(objectsOrder[i++].toObjectId(), me.toObjectId()); }
<|startcomment|> getResult() unnecessary creates the empty list. I'd suggest writing if(result != null) { return result.stream().findFirst(); } return Optional.empty(); <|endcomment|>  public Optional<T> getFirstResult() { <|startfocus|> Collection<T> list = getResult(); Iterator<T> iterator = list.iterator(); if (iterator.hasNext()) { return Optional.of(iterator.next()); <|endfocus|> } return Optional.empty();
<|startcomment|> The if and else blocks are unnecessary, you could just write "result = newUserSelection" <|endcomment|>  protected void setResult(Collection<T> newUserSelection) { <|startfocus|> if (newUserSelection == null) { result = null; } else { result = newUserSelection; } <|endfocus|>
<|startcomment|> Setting an empty initial selection is not necessary any more. <|endcomment|>  if (name1 == null) { name1 = ""; //$NON-NLS-1$ } if (name2 == null) { name2 = ""; //$NON-NLS-1$ } return coll.compare(name1, name2); } }); // Find primary feature for (AboutInfo feature : features) { if (feature.getFeatureId().equals(primaryFeatureId)) { setInitialSelection(feature); return; } } <|startfocus|> // set a safe default setInitialSelection(Collections.emptyList()); <|endfocus|>
<|startcomment|> I'd prefer to do lazy initialization here by keeping private Collection<T> result; and updating the getResult() like this public Collection<T> getResult() { return result != null ? result : Collections.emptyList(); } <|endcomment|>  * selection (via <code>getResult</code>) after completion. * <p> * Clients may subclass this dialog to inherit its selection facilities. * </p> * * @param <T> * which declares the type of the elements in the * {@link AbstractSelectionDialog}. * @since 3.11 * */ public abstract class AbstractSelectionDialog<T> extends TrayDialog { // the final collection of selected elements <|startfocus|> private Collection<T> result = Collections.emptyList(); <|endfocus|> // a list of the initially-selected elements private List<T> initialSelection; // title of dialog private String title; // message to show user private String message = ""; //$NON-NLS-1$ // dialog bounds strategy private int dialogBoundsStrategy = Dialog.DIALOG_PERSISTLOCATION | Dialog.DIALOG_PERSISTSIZE; // dialog settings for storing bounds private IDialogSettings dialogBoundsSettings = null; /** * Creates a dialog instance. * * @param parentShell * the parent shell */ protected AbstractSelectionDialog(Shell parentShell) { super(parentShell); }
<|startcomment|> For new API I'd prefer to return an java.util.Optional<T> instead of null to avoid potential NPEs. <|endcomment|> <|startfocus|> public T getFirstResult() { <|endfocus|> Collection<T> list = getResult(); if (list == null) { return null; } Iterator<T> iterator = list.iterator(); if (iterator.hasNext()) { return iterator.next(); } return null;
<|startcomment|> simply do "result = newUserSelection" here because the changed getResult() mehtod, which will manage the null <|endcomment|>  protected void setResult(Collection<T> newUserSelection) { if (newUserSelection == null) { <|startfocus|> result = Collections.emptyList(); <|endfocus|> } else { result = newUserSelection; }
<|startcomment|> Simply set the result to null here <|endcomment|>  protected void setResult(T... newUserSelection) { if (newUserSelection == null) { <|startfocus|> result = Collections.emptyList(); <|endfocus|> } else { result = Arrays.asList(newUserSelection); }
<|startcomment|> nit: too many blank lines <|endcomment|> import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.NullProgressMonitor; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; <|startfocus|> <|endfocus|> @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(true, false); } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory() throws Exception { ExecutorService e = Executors.newCachedThreadPool(); for (int i=0; i < 100; ++i) { ObjectDirectory dir = createBareRepository().getObjectDatabase(); for (Future f : e.invokeAll(blobInsertersForTheSameFanOutDir(dir))) { f.get(); } } } @Test
<|startcomment|> "timestamps are ... "? <|endcomment|>  ObjectDirectory dir = createBareRepository().getObjectDatabase(); for (Future f : e.invokeAll(blobInsertersForTheSameFanOutDir(dir))) { f.get(); } } } @Test public void testShouldNotSearchPacksAgainTheSecondTime() throws Exception { FileRepository bareRepository = newTestRepositoryWithOnePackfile(); ObjectDirectory dir = bareRepository.getObjectDatabase(); assertTrue(dir.searchPacksAgain(dir.packList.get())); <|startfocus|> // Make sure that the modified and read timestamps so that a full <|endfocus|> // file snapshot check is performed Thread.sleep(3000L); assertFalse(dir.searchPacksAgain(dir.packList.get())); } private FileRepository newTestRepositoryWithOnePackfile() throws Exception { FileRepository repository = createBareRepository(); TestRepository<FileRepository> testRepository = new TestRepository(repository); testRepository.commit(); testRepository.packAndPrune(); FileBasedConfig repoConfig = repository.getConfig(); repoConfig.setBoolean(ConfigConstants.CONFIG_CORE_SECTION,null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, trustFolderStats); repoConfig.save(); return repository; } private Collection<Callable<ObjectId>> blobInsertersForTheSameFanOutDir(
<|startcomment|> space <|endcomment|>  assertNotNull(fIterator); assertEquals(fIterator, fIterator); try (CtfIterator obj = (CtfIterator) fTrace.createIterator();) { assertNotNull(obj); assertNotEquals(fIterator, obj); CtfLocation ctfLocation1 = new CtfLocation(new CtfLocationInfo(1, 0)); obj.setLocation(ctfLocation1); obj.increaseRank(); assertEquals(fIterator, obj); } CtfTmfTrace trace = CtfTmfTestTraceUtils.getTrace(CtfTestTrace.FUNKY_TRACE); assertNotNull(trace); <|startfocus|> try(CtfIterator funky = (CtfIterator) trace.createIterator()){ <|endfocus|> assertNotEquals(fIterator, funky); } try(CtfIterator iter = (CtfIterator) fTrace.createIterator();){ CTFTrace otherTrace = new CTFTrace(fTrace.getPath()); try(CTFTraceReader tr = new CTFTraceReader(otherTrace)){ assertNotEquals(iter, tr); } } trace.dispose(); try(CtfIterator iter1 = (CtfIterator) fTrace.createIterator(); CtfIterator iter2 = (CtfIterator) fTrace.createIterator()){ assertEquals(iter1, iter2); iter2.setRank(2); assertNotEquals(iter1, iter2); } } /**
<|startcomment|> space <|endcomment|>  assertNotNull(obj); assertNotEquals(fIterator, obj); CtfLocation ctfLocation1 = new CtfLocation(new CtfLocationInfo(1, 0)); obj.setLocation(ctfLocation1); obj.increaseRank(); assertEquals(fIterator, obj); } CtfTmfTrace trace = CtfTmfTestTraceUtils.getTrace(CtfTestTrace.FUNKY_TRACE); assertNotNull(trace); try(CtfIterator funky = (CtfIterator) trace.createIterator()){ assertNotEquals(fIterator, funky); } <|startfocus|> try(CtfIterator iter = (CtfIterator) fTrace.createIterator();){ <|endfocus|> CTFTrace otherTrace = new CTFTrace(fTrace.getPath()); try(CTFTraceReader tr = new CTFTraceReader(otherTrace)){ assertNotEquals(iter, tr); } } trace.dispose(); try(CtfIterator iter1 = (CtfIterator) fTrace.createIterator(); CtfIterator iter2 = (CtfIterator) fTrace.createIterator()){ assertEquals(iter1, iter2); iter2.setRank(2); assertNotEquals(iter1, iter2); } } /** * Run the boolean equals(Object) method test. Compare with an empty object. */ @Test public void testEquals_empty() {
<|startcomment|> space <|endcomment|>  assertNotNull(trace); try(CtfIterator funky = (CtfIterator) trace.createIterator()){ assertNotEquals(fIterator, funky); } try(CtfIterator iter = (CtfIterator) fTrace.createIterator();){ CTFTrace otherTrace = new CTFTrace(fTrace.getPath()); try(CTFTraceReader tr = new CTFTraceReader(otherTrace)){ assertNotEquals(iter, tr); } } trace.dispose(); <|startfocus|> try(CtfIterator iter1 = (CtfIterator) fTrace.createIterator(); CtfIterator iter2 = (CtfIterator) fTrace.createIterator()){ <|endfocus|> assertEquals(iter1, iter2); iter2.setRank(2); assertNotEquals(iter1, iter2); } } /** * Run the boolean equals(Object) method test. Compare with an empty object. */ @Test public void testEquals_empty() { assertNotEquals(new Object(), fIterator); } /** * Run the CtfTmfTrace getCtfTmfTrace() method test. */ @Test public void testGetCtfTmfTrace() { CtfTmfTrace result = fIterator.getCtfTmfTrace(); assertNotNull(result); } /**
<|startcomment|> When the too large index makes you go to the event at the next timestamp, the location info should be at that timestamp, index 0. <|endcomment|>  // if ret == true, then currentEvent is non-null if (seekToTimestamp >= Objects.requireNonNull(currentEvent).getTimestamp().getValue()) { index++; } else { break; } ret = advance(); previousEvent = currentEvent; currentEvent = getCurrentEvent(); } /* Update the current location accordingly */ if (ret) { <|startfocus|> fCurLocation = new CtfLocation(new CtfLocationInfo(Objects.requireNonNull(previousEvent).getTimestamp().getValue(), index)); <|endfocus|> } else { fCurLocation = NULL_LOCATION; } return ret;
<|startcomment|> unused import <|endcomment|>  * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. */ package org.eclipse.jgit.internal.storage.file; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.concurrent.Callable; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.Future; <|startfocus|> import org.eclipse.jgit.internal.storage.pack.PackWriter; <|endfocus|> import org.eclipse.jgit.junit.RepositoryTestCase; import org.eclipse.jgit.junit.TestRepository; import org.eclipse.jgit.lib.ConfigConstants; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.NullProgressMonitor; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase {
<|startcomment|> unused import <|endcomment|>  */ package org.eclipse.jgit.internal.storage.file; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.concurrent.Callable; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.Future; import org.eclipse.jgit.internal.storage.pack.PackWriter; import org.eclipse.jgit.junit.RepositoryTestCase; import org.eclipse.jgit.junit.TestRepository; import org.eclipse.jgit.lib.ConfigConstants; import org.eclipse.jgit.lib.Constants; <|startfocus|> import org.eclipse.jgit.lib.NullProgressMonitor; <|endfocus|> import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(true, false);
<|startcomment|> we use standard Eclipse formatter, use Ctrl-Shift-O to organise imports, this sorts static imports at the top <|endcomment|> import org.eclipse.jgit.junit.RepositoryTestCase; import org.eclipse.jgit.junit.TestRepository; import org.eclipse.jgit.lib.ConfigConstants; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.NullProgressMonitor; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; <|startfocus|> import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; <|endfocus|> @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { return Arrays.asList(true, false); } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory() throws Exception { ExecutorService e = Executors.newCachedThreadPool(); for (int i=0; i < 100; ++i) { ObjectDirectory dir = createBareRepository().getObjectDatabase();
<|startcomment|> this yields 2 boxing warnings, either suppress them or use Boolean.TRUE and FALSE <|endcomment|> import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.Parameterized; import org.junit.runners.Parameterized.Parameters; import org.junit.runners.Parameterized.Parameter; import static org.junit.Assert.assertFalse; import static org.junit.Assert.assertTrue; @RunWith(Parameterized.class) public class ObjectDirectoryTest extends RepositoryTestCase { @Parameter public Boolean trustFolderStats; @Parameters(name= "core.trustfolderstat={0}") public static Iterable<? extends Object> data() { <|startfocus|> return Arrays.asList(true, false); <|endfocus|> } @Test public void testConcurrentInsertionOfBlobsToTheSameNewFanOutDirectory() throws Exception { ExecutorService e = Executors.newCachedThreadPool(); for (int i=0; i < 100; ++i) { ObjectDirectory dir = createBareRepository().getObjectDatabase(); for (Future f : e.invokeAll(blobInsertersForTheSameFanOutDir(dir))) { f.get(); } } } @Test public void testShouldNotSearchPacksAgainTheSecondTime() throws Exception { FileRepository bareRepository = newTestRepositoryWithOnePackfile(); ObjectDirectory dir = bareRepository.getObjectDatabase(); 
<|startcomment|> missing type argument: TestRepository<FileRepository>(repository) <|endcomment|>  FileRepository bareRepository = newTestRepositoryWithOnePackfile(); ObjectDirectory dir = bareRepository.getObjectDatabase(); assertTrue(dir.searchPacksAgain(dir.packList.get())); // Make sure that the modified and read timestamps so that a full // file snapshot check is performed Thread.sleep(3000L); assertFalse(dir.searchPacksAgain(dir.packList.get())); } private FileRepository newTestRepositoryWithOnePackfile() throws Exception { FileRepository repository = createBareRepository(); <|startfocus|> TestRepository<FileRepository> testRepository = new TestRepository(repository); <|endfocus|> testRepository.commit(); testRepository.packAndPrune(); FileBasedConfig repoConfig = repository.getConfig(); repoConfig.setBoolean(ConfigConstants.CONFIG_CORE_SECTION,null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, trustFolderStats); repoConfig.save(); return repository; } private Collection<Callable<ObjectId>> blobInsertersForTheSameFanOutDir( final ObjectDirectory dir) { Callable<ObjectId> callable = new Callable<ObjectId>() { public ObjectId call() throws Exception { return dir.newInserter().insert(Constants.OBJ_BLOB, new byte[0]); } };
<|startcomment|> needs to be unboxed <|endcomment|>  // file snapshot check is performed Thread.sleep(3000L); assertFalse(dir.searchPacksAgain(dir.packList.get())); } private FileRepository newTestRepositoryWithOnePackfile() throws Exception { FileRepository repository = createBareRepository(); TestRepository<FileRepository> testRepository = new TestRepository(repository); testRepository.commit(); testRepository.packAndPrune(); FileBasedConfig repoConfig = repository.getConfig(); repoConfig.setBoolean(ConfigConstants.CONFIG_CORE_SECTION,null, <|startfocus|> ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, trustFolderStats); <|endfocus|> repoConfig.save(); return repository; } private Collection<Callable<ObjectId>> blobInsertersForTheSameFanOutDir( final ObjectDirectory dir) { Callable<ObjectId> callable = new Callable<ObjectId>() { public ObjectId call() throws Exception { return dir.newInserter().insert(Constants.OBJ_BLOB, new byte[0]); } }; return Collections.nCopies(4, callable); } } 
<|startcomment|> Variable name should start with a lower case letter. <|endcomment|>  assertTrue(traceAdapter.isThereATraceBetween(_A, _B, upDatedTraceModel)); // Clear selection view SelectionView.getOpenedView().clearSelection(); // create a selection with class A List<Object> selection = new ArrayList<>(); selection.add(_A); // test that internal links show for direct elements ToggleTransitivityHandler.setTraceViewTransitive(false); DisplayInternalLinksHandler.showInternalLinks(true); DiagramTextProviderHandler provider = new DiagramTextProviderHandler(); <|startfocus|> String DirectlyConnectedElements = provider.getDiagramText(selection); assertTrue(DirectlyConnectedElements.equals(EXPECTED_TEXT_FOR_INTERNAL_LINKS)); <|endfocus|> } } 
<|startcomment|> Add this: assertEquals(new CtfLocationInfo(1331668247328921944L, 1L), iterator.getLocation().getLocationInfo()); <|endcomment|>  assertEquals(1331668250328561095L, middleEvent.getTimestamp().toNanos()); assertEquals(1331668250328561095L, iterator.getCurrentTimestamp()); // double timestamp at 15:50:47.328921944 assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 1L))); CtfTmfEvent doubleEvent = iterator.getCurrentEvent(); assertNotNull(doubleEvent); assertEquals(1331668247328921944L, doubleEvent.getTimestamp().toNanos()); assertEquals(1331668247328921944L, iterator.getCurrentTimestamp()); // test that events will be in cpu order <|startfocus|> assertEquals("sched_switch", doubleEvent.getName()); <|endfocus|> assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 9001000000L))); CtfTmfEvent overNineThousandEvent = iterator.getCurrentEvent(); assertNotNull(overNineThousandEvent); assertEquals(1331668247328925363L, overNineThousandEvent.getTimestamp().toNanos()); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", overNineThousandEvent.getName()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 4L))); CtfTmfEvent quadEvent = iterator.getCurrentEvent(); assertNotNull(quadEvent);
<|startcomment|> a bit overkill, index 3L would be good enough... <|endcomment|>  assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 1L))); CtfTmfEvent doubleEvent = iterator.getCurrentEvent(); assertNotNull(doubleEvent); assertEquals(1331668247328921944L, doubleEvent.getTimestamp().toNanos()); assertEquals(1331668247328921944L, iterator.getCurrentTimestamp()); // test that events will be in cpu order assertEquals("sched_switch", doubleEvent.getName()); <|startfocus|> assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 9001000000L))); CtfTmfEvent overNineThousandEvent = iterator.getCurrentEvent(); assertNotNull(overNineThousandEvent); assertEquals(1331668247328925363L, overNineThousandEvent.getTimestamp().toNanos()); <|endfocus|> assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", overNineThousandEvent.getName()); assertTrue(iterator.seek(new CtfLocationInfo(1331668247328921944L, 4L))); CtfTmfEvent quadEvent = iterator.getCurrentEvent(); assertNotNull(quadEvent); assertEquals(1331668247328925363L, quadEvent.getTimestamp().toNanos()); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", quadEvent.getName()); assertFalse(iterator.seek(CtfLocation.INVALID_LOCATION));
<|startcomment|> If you seek with an index exactly one more than the number of events at the seek timestamp, the resulting location should be the next timestamp, index 0. It does not because we break out of the loop on the index condition, and we don't have a chance to reset the index to 0. <|endcomment|>  } } catch (CTFException e) { Activator.getDefault().logError(e.getMessage(), e); return false; } /* * Check if there is already one or more events for that timestamp, and * assign the location index correctly */ long index = 0; ITmfEvent currentEvent = getCurrentEvent(); ret &= (currentEvent != null); <|startfocus|> ITmfEvent previousEvent = currentEvent; for (long i = 0; ret && i < ctfLocationData.getIndex(); i++) { // if ret == true, then currentEvent is non-null <|endfocus|> if (seekToTimestamp >= Objects.requireNonNull(currentEvent).getTimestamp().getValue()) { index++; } else { index = 0; break; } ret = advance(); previousEvent = currentEvent; currentEvent = getCurrentEvent(); } /* Update the current location accordingly */ if (ret) { fCurLocation = new CtfLocation(new CtfLocationInfo(Objects.requireNonNull(previousEvent).getTimestamp().getValue(), index)); } else { fCurLocation = NULL_LOCATION; } 
<|startcomment|> Should be currentEvent? <|endcomment|>  // if ret == true, then currentEvent is non-null if (seekToTimestamp >= Objects.requireNonNull(currentEvent).getTimestamp().getValue()) { index++; } else { index = 0; break; } ret = advance(); previousEvent = currentEvent; currentEvent = getCurrentEvent(); } /* Update the current location accordingly */ if (ret) { <|startfocus|> fCurLocation = new CtfLocation(new CtfLocationInfo(Objects.requireNonNull(previousEvent).getTimestamp().getValue(), index)); <|endfocus|> } else { fCurLocation = NULL_LOCATION; } return ret;
<|startcomment|> I suppose this is same as the one in SwitchExpression, in which case we don't need the latter? In any case, we should consider in-lining the check to avoid a method call as well as reduce the byte code footprint. <|endcomment|>  block.scope = this.scope; // (upper scope) see Block.resolve() for similar } else { Statement[] newArray = new Statement[l + 1]; System.arraycopy(block.statements, 0, newArray, 0, l); newArray[l] = breakStatement; block.statements = newArray; } return BREAKING; } } return FALLTHROUGH; } protected void completeNormallyCheck(BlockScope blockScope) { // do nothing } protected boolean checkNullDefaultFlow() { <|startfocus|> return !this.switchLabeledRules; <|endfocus|> } @Override public FlowInfo analyseCode(BlockScope currentScope, FlowContext flowContext, FlowInfo flowInfo) { try { flowInfo = this.expression.analyseCode(currentScope, flowContext, flowInfo); if ((this.expression.implicitConversion & TypeIds.UNBOXING) != 0 || (this.expression.resolvedType != null && (this.expression.resolvedType.id == T_JavaLangString || this.expression.resolvedType.isEnum()))) { this.expression.checkNPE(currentScope, flowContext, flowInfo, 1); } SwitchFlowContext switchContext =
<|startcomment|> Have you set the right code formatter? We are using tabs instead of spaces. Your first line in modified areas also does so, but the following lines use spaces? Please review also the rest of your changes regarding this. Other than that: we are down from >2000 lines to 700 lines changed just by removing unrelated changes. Great! <|endcomment|>  ServletContext ctx = config.getServletContext(); filter.init(new NoParameterFilterConfig(name, ctx)); } /** {@inheritDoc} */ @Override public void destroy() { filter.destroy(); } /** {@inheritDoc} */ @Override protected void service(HttpServletRequest req, HttpServletResponse res) throws ServletException, IOException { <|startfocus|> filter.doFilter(req, res, (ServletRequest request, ServletResponse response) -> { ((HttpServletResponse) response).sendError(SC_NOT_FOUND); }); <|endfocus|> } /** * Configure a newly created binder. * * @param b * the newly created binder. * @return binder for the caller, potentially after adding one or more * filters into the pipeline. */ protected ServletBinder register(ServletBinder b) { return filter.register(b); } } 
<|startcomment|> Describe? <|endcomment|>  * made available under the terms of the Eclipse Public License v1.0 which * accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.tmf.ui.views; /** * Interface with a method for time navigation in time-based views. * * @author Bernd Hufmann * */ public interface ITmfTimeNavigationProvider { /** * Method to implement to scroll left or right * <|startfocus|> * @param left <|endfocus|> */ void horizontalScroll(boolean left); } 
<|startcomment|> Should it have a method, even if it does not have any parameters? <|endcomment|> ***************************************************************************** * Copyright (c) 2019 Ericsson * * All rights reserved. This program and the accompanying materials are * made available under the terms of the Eclipse Public License v1.0 which * accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.tmf.ui.views; /** * Interface for a view to support zoom to selection. * * @author Bernd Hufmann * */ <|startfocus|> public interface ITmfZoomToSelectionProvider { <|endfocus|> } 
<|startcomment|> Now it's make sure if a TmfView is the active part? But why is even that a requirement, we only need getAdapter() which comes from IWorkbenchPart? <|endcomment|>  * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.tmf.ui.views.handler; import org.eclipse.core.commands.AbstractHandler; import org.eclipse.core.commands.ExecutionEvent; import org.eclipse.core.commands.ExecutionException; import org.eclipse.tracecompass.tmf.ui.views.TmfView; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.IWorkbenchWindow; import org.eclipse.ui.PlatformUI; import org.eclipse.ui.handlers.HandlerUtil; /** <|startfocus|> * Base handler, makes sure we have a timegraph control selected <|endfocus|> * * @author Matthew Khouzam * */ abstract class TmfViewBaseHandler extends AbstractHandler { @Override public Object execute(ExecutionEvent event) throws ExecutionException { // Check if we are closing down IWorkbenchWindow window = PlatformUI.getWorkbench().getActiveWorkbenchWindow(); if (window == null) { return null; } IWorkbenchPart part = HandlerUtil.getActivePart(event); if (part instanceof TmfView) { execute((TmfView) part); } return null; } public abstract void execute(TmfView timegraph); } 
<|startcomment|> rename to view <|endcomment|>  * * @author Matthew Khouzam * */ abstract class TmfViewBaseHandler extends AbstractHandler { @Override public Object execute(ExecutionEvent event) throws ExecutionException { // Check if we are closing down IWorkbenchWindow window = PlatformUI.getWorkbench().getActiveWorkbenchWindow(); if (window == null) { return null; } IWorkbenchPart part = HandlerUtil.getActivePart(event); if (part instanceof TmfView) { execute((TmfView) part); } return null; } <|startfocus|> public abstract void execute(TmfView timegraph); <|endfocus|> } 
<|startcomment|> All the other ones have a blank line after <|endcomment|>  * accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.tmf.ui.views.handler; import org.eclipse.tracecompass.internal.tmf.ui.views.ITmfTimeZoomProvider; import org.eclipse.tracecompass.tmf.ui.views.TmfView; /** * Zoom-in handler for TMF views. * * @author Matthew Khouzam * @author Bernd Hufmann */ <|startfocus|> public class TmfViewZoomInHandler extends TmfViewBaseHandler { <|endfocus|> @Override public void execute(TmfView view) { ITmfTimeZoomProvider zoomer = view.getAdapter(ITmfTimeZoomProvider.class); if (zoomer != null) { zoomer.zoom(true); } } } 
<|startcomment|> bad formatter <|endcomment|> import org.eclipse.sirius.tests.swtbot.support.api.editor.SWTBotSiriusDiagramEditor; import org.eclipse.sirius.tests.swtbot.support.utils.SWTBotUtils; import org.eclipse.swt.SWT; import org.eclipse.swtbot.eclipse.gef.finder.widgets.SWTBotGefEditPart; /** * Tests to check the behavior of the editor when selecting a node or edge edit * part. * * @author lfasani */ public class EditPartSelectionTest extends AbstractSiriusSwtBotGefTestCase { <|startfocus|> private static final String DATA_UNIT_DIR = "/data/unit/selection/"; <|endfocus|> private static final String MODEL = "TestSelection.ecore"; private static final String SESSION_FILE = "TestSelection.aird"; private static final String VSM_FILE = "My.odesign"; private static final String REPRESENTATION_DECRIPTION_NAME = "Entities"; private static final String REPRESENTATION_NAME = "diagram"; private static final PrecisionPoint INITIAL_NODE_CENTER_POSITION = new PrecisionPoint(856.0, 412.0); private Session session; @Override protected void onSetUpBeforeClosingWelcomePage() throws Exception {
<|startcomment|> I would put that in gerrit comments instead... <|endcomment|>  } /** * Run the void setRank() method test. */ @Test public void testSetRank() { long rank = fIterator.getRank(); fIterator.increaseRank(); assertEquals(rank + 1, fIterator.getRank()); fIterator.setRank(rank); assertEquals(rank, fIterator.getRank()); } /** * Run the boolean seek(long) method test. */ @Test public void testSeek() { <|startfocus|> // Good old trace 2. You may just be perfect! <|endfocus|> CtfTmfTrace trace = CtfTmfTestTraceUtils.getTrace(CtfTestTrace.TRACE2); try (CtfIterator iterator = (CtfIterator) trace.createIterator()) { assertTrue(iterator.seek(1L)); CtfTmfEvent event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247314038062L, getTimestampInNanos(event)); assertEquals(1331668247314038062L, iterator.getCurrentTimestamp()); assertFalse(iterator.seek(Long.MAX_VALUE)); assertNull(getCurrentEvent(iterator)); assertEquals(0L, iterator.getCurrentTimestamp()); assertFalse(iterator.advance()); // seek to a time after trace start.
<|startcomment|> Indexed ? <|endcomment|>  assertNull(getCurrentEvent(iterator)); assertEquals(0L, iterator.getCurrentTimestamp()); assertFalse(iterator.advance()); // seek to a time after trace start. CtfLocationInfo middleLocation = new CtfLocationInfo(1331668250328561095L, 0L); assertTrue(iterator.seek(middleLocation)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668250328561095L, getTimestampInNanos(event)); assertEquals(1331668250328561095L, iterator.getCurrentTimestamp()); <|startfocus|> CtfLocationInfo middleLocationIndexeOne = new CtfLocationInfo(1331668250328561095L, 1L); assertTrue(iterator.seek(middleLocationIndexeOne)); event = getCurrentEvent(iterator); <|endfocus|> assertNotNull(event); assertEquals(1331668250328561761L, getTimestampInNanos(event)); assertEquals(1331668250328561761L, iterator.getCurrentTimestamp()); assertEquals(new CtfLocationInfo(1331668250328561761L, 0L), iterator.getLocation().getLocationInfo()); // double timestamp at 15:50:47.328921944 CtfLocationInfo duplicateLocationIndexedOne = new CtfLocationInfo(1331668247328921944L, 1L); assertTrue(iterator.seek(duplicateLocationIndexedOne)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247328921944L, getTimestampInNanos(event));
<|startcomment|> to be consistent with below // next event location <|endcomment|>  assertTrue(iterator.seek(middleLocation)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668250328561095L, getTimestampInNanos(event)); assertEquals(1331668250328561095L, iterator.getCurrentTimestamp()); CtfLocationInfo middleLocationIndexeOne = new CtfLocationInfo(1331668250328561095L, 1L); assertTrue(iterator.seek(middleLocationIndexeOne)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668250328561761L, getTimestampInNanos(event)); <|startfocus|> assertEquals(1331668250328561761L, iterator.getCurrentTimestamp()); <|endfocus|> assertEquals(new CtfLocationInfo(1331668250328561761L, 0L), iterator.getLocation().getLocationInfo()); // double timestamp at 15:50:47.328921944 CtfLocationInfo duplicateLocationIndexedOne = new CtfLocationInfo(1331668247328921944L, 1L); assertTrue(iterator.seek(duplicateLocationIndexedOne)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247328921944L, getTimestampInNanos(event)); assertEquals(1331668247328921944L, iterator.getCurrentTimestamp()); // test that events will be in cpu order assertEquals("sched_switch", event.getName()); assertEquals(duplicateLocationIndexedOne, iterator.getLocation().getLocationInfo()); 
<|startcomment|> Yes 9001000000 > 9000 but is that what you're trying to say? <|endcomment|>  CtfLocationInfo duplicateLocationOutOfBounds = new CtfLocationInfo(1331668247328921944L, 4L); assertTrue(iterator.seek(duplicateLocationOutOfBounds)); event = getCurrentEvent(iterator); assertNotNull(event); assertEquals(1331668247328925363L, getTimestampInNanos(event)); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", event.getName()); // next event location assertEquals(new CtfLocationInfo(1331668247328925363L, 0L), iterator.getLocation().getLocationInfo()); <|startfocus|> CtfLocationInfo duplicateLocationIndexedOver9000 = new CtfLocationInfo(1331668247328921944L, 9001000000L); assertTrue(iterator.seek(duplicateLocationIndexedOver9000)); event = getCurrentEvent(iterator); <|endfocus|> assertNotNull(event); assertEquals(1331668247328925363L, getTimestampInNanos(event)); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", event.getName()); // next event location assertEquals(new CtfLocationInfo(1331668247328925363L, 0L), iterator.getLocation().getLocationInfo()); assertFalse(iterator.seek(CtfLocation.INVALID_LOCATION)); // last valid seek location assertEquals(event, getCurrentEvent(iterator)); } trace.dispose(); } 
<|startcomment|> ? <|endcomment|>  assertEquals(1331668247328925363L, getTimestampInNanos(event)); assertEquals(1331668247328925363L, iterator.getCurrentTimestamp()); assertEquals("sys_poll", event.getName()); // next event location assertEquals(new CtfLocationInfo(1331668247328925363L, 0L), iterator.getLocation().getLocationInfo()); assertFalse(iterator.seek(CtfLocation.INVALID_LOCATION)); // last valid seek location assertEquals(event, getCurrentEvent(iterator)); } trace.dispose(); } <|startfocus|> private static CtfTmfEvent getCurrentEvent(CtfIterator iterator) { return iterator.getCurrentEvent(); } private static long getTimestampInNanos(CtfTmfEvent event) { return event.getTimestamp().toNanos(); } <|endfocus|> /** * Run the void setLocation(ITmfLocation<?>) method test. */ @Test public void testSetLocation() { CtfLocation location = new CtfLocation(new CtfLocationInfo(1, 0)); fIterator.setLocation(location); } } 
<|startcomment|> less ? than above but still ? a little bit <|endcomment|>  assertEquals("sys_poll", event.getName()); // next event location assertEquals(new CtfLocationInfo(1331668247328925363L, 0L), iterator.getLocation().getLocationInfo()); assertFalse(iterator.seek(CtfLocation.INVALID_LOCATION)); // last valid seek location assertEquals(event, getCurrentEvent(iterator)); } trace.dispose(); } <|startfocus|> private static CtfTmfEvent getCurrentEvent(CtfIterator iterator) { return iterator.getCurrentEvent(); } private static long getTimestampInNanos(CtfTmfEvent event) { return event.getTimestamp().toNanos(); } <|endfocus|> /** * Run the void setLocation(ITmfLocation<?>) method test. */ @Test public void testSetLocation() { CtfLocation location = new CtfLocation(new CtfLocationInfo(1, 0)); fIterator.setLocation(location); } } 
<|startcomment|> to remove? <|endcomment|>  public boolean isReferenceToDisplay(Component source, DNodeContainer sourceView, DNodeContainer targetView) { <|startfocus|> // if (!isIndirectlyCollapsed(sourceView) && !isIndirectlyCollapsed(targetView)) { <|endfocus|> for (DDiagramElement child : sourceView.getOwnedDiagramElements()) { if (child instanceof DNodeContainer && (((DNodeContainer) child).getActualMapping().getName().equals("ComponentRegion"))) { for (DDiagramElement grandchild : ((DNodeContainer) child).getOwnedDiagramElements()) { if (isReferenceDisplayedByChild((DNodeContainer) grandchild, targetView)) { return false; } } } } return true; // } // return false;
<|startcomment|> to remove? <|endcomment|>  // if (!isIndirectlyCollapsed(sourceView) && !isIndirectlyCollapsed(targetView)) { for (DDiagramElement child : sourceView.getOwnedDiagramElements()) { if (child instanceof DNodeContainer && (((DNodeContainer) child).getActualMapping().getName().equals("ComponentRegion"))) { for (DDiagramElement grandchild : ((DNodeContainer) child).getOwnedDiagramElements()) { if (isReferenceDisplayedByChild((DNodeContainer) grandchild, targetView)) { return false; } } } } return true; <|startfocus|> // } // return false; <|endfocus|>
<|startcomment|> 2019 <|endcomment|>  <|startfocus|> * Copyright (c) 2010, 2017 THALES GLOBAL SERVICES <|endfocus|> * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - Initial API and implementation */ package org.eclipse.sirius.tests.swtbot.support.api.editor; import java.util.Iterator; import java.util.List; import java.util.concurrent.atomic.AtomicBoolean; import org.eclipse.core.runtime.IAdaptable; import org.eclipse.draw2d.FigureCanvas; import org.eclipse.draw2d.IFigure; import org.eclipse.draw2d.Label; import org.eclipse.draw2d.LightweightSystem; import org.eclipse.draw2d.geometry.Point; import org.eclipse.draw2d.text.TextFlow; import org.eclipse.gef.EditPart; import org.eclipse.gef.GraphicalEditPart; import org.eclipse.gef.GraphicalViewer; import org.eclipse.sirius.ext.gmf.runtime.gef.ui.figures.SiriusWrapLabel; import org.eclipse.sirius.tests.swtbot.support.api.widget.SWTBotSiriusFigureCanvas;
<|startcomment|> 2019 <|endcomment|>  <|startfocus|> * Copyright (c) 2012, 2017 THALES GLOBAL SERVICES <|endfocus|> * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - Initial API and implementation */ package org.eclipse.sirius.tests.swtbot.support.api.widget; import java.util.concurrent.atomic.AtomicBoolean; import org.eclipse.draw2d.FigureCanvas; import org.eclipse.draw2d.LightweightSystem; import org.eclipse.swt.SWT; import org.eclipse.swt.events.KeyEvent; import org.eclipse.swt.widgets.Canvas; import org.eclipse.swt.widgets.Event; import org.eclipse.swt.widgets.Text; import org.eclipse.swtbot.eclipse.gef.finder.widgets.SWTBotGefFigureCanvas; import org.eclipse.swtbot.swt.finder.exceptions.WidgetNotFoundException; import org.eclipse.swtbot.swt.finder.finders.UIThreadRunnable; import org.eclipse.swtbot.swt.finder.results.Result; import org.eclipse.swtbot.swt.finder.results.VoidResult; import org.eclipse.swtbot.swt.finder.utils.SWTUtils; /**
<|startcomment|> 2017, 2019 <|endcomment|> ***************************************************************************** <|startfocus|> * Copyright (c) 2017 THALES GLOBAL SERVICES. <|endfocus|> * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Obeo - initial API and implementation *******************************************************************************/ package org.eclipse.sirius.tests.swtbot; import org.eclipse.draw2d.IFigure; import org.eclipse.draw2d.geometry.PrecisionPoint; import org.eclipse.draw2d.geometry.Rectangle; import org.eclipse.gef.GraphicalEditPart; import org.eclipse.gef.LayerConstants; import org.eclipse.gef.editparts.LayerManager; import org.eclipse.gmf.runtime.diagram.ui.editparts.AbstractBorderedShapeEditPart; import org.eclipse.gmf.runtime.diagram.ui.editparts.ConnectionEditPart; import org.eclipse.gmf.runtime.diagram.ui.editparts.IGraphicalEditPart; import org.eclipse.gmf.runtime.draw2d.ui.figures.PolylineConnectionEx; import org.eclipse.sirius.business.api.session.Session; import org.eclipse.sirius.diagram.DDiagram; import org.eclipse.sirius.diagram.ui.edit.api.part.AbstractDiagramBorderNodeEditPart;
<|startcomment|> I think this is too obvious for unit tests. I'd prefer to remove this for all test cases. <|endcomment|>  } @Override protected void tearDown() throws Exception { assertEquals("Test triggered errors.", 0, loggedErrors.get()); Platform.removeLogListener(errorLogListener); super.tearDown(); } /** * Test if two byte UTF-8 characters get disrupted on there way from process * console to the runtime process. * <p> * This test starts every two byte character on an even byte offset. * </p> <|startfocus|> * * @throws Exception if the test gets in trouble <|endfocus|> */ public void testUTF8InputEven() throws Exception { // 5000 characters result in 10000 bytes which should be more than most // common buffer sizes. processConsoleUTF8Input("", 5000); } /** * Test if two byte UTF-8 characters get disrupted on there way from process * console to the runtime process. * <p> * This test starts every two byte character on an odd byte offset. * </p> * * @throws Exception if the test gets in trouble
<|startcomment|> again, not worth to document <|endcomment|> import org.eclipse.debug.tests.AbstractDebugTest; /** * Tests the {@link StreamsProxy}. */ public class StreamsProxyTests extends AbstractDebugTest { public StreamsProxyTests() { super(StreamsProxyTests.class.getSimpleName()); } public StreamsProxyTests(String name) { super(name); } /** * Test console receiving UTF-8 output from process where two-byte UTF-8 * characters start at even offsets. <|startfocus|> * * @throws Exception if the test gets in trouble <|endfocus|> */ public void testReceiveUTF8Even() throws Exception { // 4500 characters results in 9000 byte of output which should be more // than most common buffer sizes. receiveUTF8Test("", 4500); } /** * Test console receiving UTF-8 output from process where two-byte UTF-8 * characters start at odd offsets. * * @throws Exception if the test gets in trouble */ public void testReceiveUTF8Odd() throws Exception { // 4500 characters results in 9000 byte of output which should be more
<|startcomment|> Same as above <|endcomment|>  public void testSet() { List<String> reference = Arrays.asList("Pomme", "Peche", "Poire", "Banane"); List<String> test = createList(reference); assertEquals(reference, test); <|startfocus|> assertEquals(reference, test); <|endfocus|> test.set(0, "pomme"); assertNotEquals(reference, test); try { test.set(-1, "pomme"); fail("Should not get here"); } catch (IndexOutOfBoundsException e) { // correct flow } try { test.set(5, "pomme"); fail("Should not get here"); } catch (IndexOutOfBoundsException e) { // correct flow }
<|startcomment|> Shouldn't the next be 4 (or previous 1)? <|endcomment|>  assertEquals("yo", iterator.next()); iterator.previous(); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.next(); iterator.next(); iterator.next(); iterator.next(); try { iterator.next(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.previous(); <|startfocus|> assertEquals(2, iterator.previousIndex()); assertEquals(3, iterator.nextIndex()); <|endfocus|> try { iterator.remove(); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow } try { iterator.set("hej"); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow } try { iterator.add("hi"); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow }
<|startcomment|> Could you define what a sparse list is? <|endcomment|>  * accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.ctf.core.utils; import java.util.Collection; import java.util.Iterator; import java.util.LinkedHashMap; import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; /** <|startfocus|> * Sparse list, a list that supports <|endfocus|> * <ul> * <li>{@link #add(Object)}</li> * <li>{@link #contains(Object)}</li> * <li>{@link #clear()}</li> * <li>{@link #iterator()} , {@link #isEmpty()}</li> * <li>{@link #toArray()}</li> * <li>{@link #toArray(Object[])}</li> * <li>{@link #set(int, Object)}</li> * <li>{@link #lastIndexOf(Object)}</li> * </ul> *
<|startcomment|> If this is the only usage why not make it private so we don't expose it as API? <|endcomment|> <|startfocus|> protected int getThreshold() { <|endfocus|> if (!selectFeedbackEnabled) { if (getViewer().getControl() instanceof Table) return ((Table) getViewer().getControl()).getItemHeight() / 2; if (getViewer().getControl() instanceof Tree) return ((Tree) getViewer().getControl()).getItemHeight() / 2; if (getViewer().getControl() instanceof List) return ((List) getViewer().getControl()).getItemHeight() / 2; } // fixed default threshold return 5;
<|startcomment|> You can probably refactor so that cursor is the current position (initialized to index). <|endcomment|>  public GenericReadOnlyListIterator(List<E> list, int start, int end) { fList = list; <|startfocus|> fStart = start; fEnd = end; <|endfocus|> fCursor = start - 1;
<|startcomment|> What about 87%, should I use this one or a normal ArrayList then? (I just wouldn't put a number) <|endcomment|>  * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.ctf.core.utils; import java.util.Collection; import java.util.HashMap; import java.util.Iterator; import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; /** <|startfocus|> * Sparse list, a list optimized for when most (> 90%) of the data is * <code>null</code>. <|endfocus|> * * Note: this iterates in the sorted order. * * This implementation supports: * <ul> * <li>{@link #add(Object)}</li> * <li>{@link #contains(Object)}</li> * <li>{@link #clear()}</li> * <li>{@link #iterator()}</li> * <li>{@link #isEmpty()}</li> * <li>{@link #toArray()}</li> * <li>{@link #toArray(Object[])}</li>
<|startcomment|> I would remove that comment. Who knows, maybe this one would be more efficient than the eventual public one... <|endcomment|>  * <li>{@link #clear()}</li> * <li>{@link #iterator()}</li> * <li>{@link #isEmpty()}</li> * <li>{@link #toArray()}</li> * <li>{@link #toArray(Object[])}</li> * <li>{@link #set(int, Object)}</li> * <li>{@link #lastIndexOf(Object)}</li> * </ul> * <|startfocus|> * TODO: remove when a public (open source) sparselist is available. <|endfocus|> * * @author Matthew Khouzam * @param <E> * the element type */ public class SparseList<E> implements List<E> { private final Map<Integer, E> fInnerEvents = new HashMap<>(); private int fSize = 0; /** * Copy constructor * * @param events * list of events */ public SparseList(List<E> events) { ensureSize(events.size()); for (int i = 0; i < events.size(); i++) { E element = events.get(i);
<|startcomment|> What's an event? I suggest fElements. <|endcomment|>  * <li>{@link #toArray(Object[])}</li> * <li>{@link #set(int, Object)}</li> * <li>{@link #lastIndexOf(Object)}</li> * </ul> * * TODO: remove when a public (open source) sparselist is available. * * @author Matthew Khouzam * @param <E> * the element type */ public class SparseList<E> implements List<E> { <|startfocus|> private final Map<Integer, E> fInnerEvents = new HashMap<>(); <|endfocus|> private int fSize = 0; /** * Copy constructor * * @param events * list of events */ public SparseList(List<E> events) { ensureSize(events.size()); for (int i = 0; i < events.size(); i++) { E element = events.get(i); if (element != null) { set(i, element); } } } /** * default constructor */ public SparseList() { // Do nothing } @Override public int size() {
<|startcomment|> What about null, if null was added as an element at a certain index? <|endcomment|>  public boolean contains(Object o) { <|startfocus|> return fInnerEvents.containsValue(o); <|endfocus|>
<|startcomment|> I'm not sure that all other methods are thread-safe (those that access any method from the inner map)? <|endcomment|>  public boolean add(E e) { <|startfocus|> synchronized (this) { fInnerEvents.put(fSize, e); fSize++; <|endfocus|> } return true;
<|startcomment|> See contains(). <|endcomment|>  public boolean containsAll(Collection<?> c) { <|startfocus|> return fInnerEvents.values().containsAll(c); <|endfocus|>
<|startcomment|> The size can be increased by elements that are not added (due to being null). <|endcomment|>  public boolean addAll(Collection<? extends E> c) { int key = fSize; fSize += c.size(); for (E event : c) { <|startfocus|> if (event != null) { set(key, event); } <|endfocus|> key++; } return true;
<|startcomment|> Null is allowed in add() but not addAll()? <|endcomment|>  public boolean addAll(Collection<? extends E> c) { int key = fSize; fSize += c.size(); for (E event : c) { <|startfocus|> if (event != null) { set(key, event); } <|endfocus|> key++; } return true;
<|startcomment|> Returns <|endcomment|>  } @Override public boolean containsAll(Collection<?> c) { return fInnerEvents.values().containsAll(c); } @Override public boolean addAll(Collection<? extends E> c) { int key = fSize; fSize += c.size(); for (E event : c) { if (event != null) { set(key, event); } key++; } return true; } /** * {@inheritDoc} * <|startfocus|> * returns null if there is no element found at that index. <|endfocus|> */ @Override public E get(int index) { if (index < 0 || index >= fSize) { throw new IndexOutOfBoundsException("Tried to access index " + index + " Sparse list size " + fSize); //$NON-NLS-1$ //$NON-NLS-2$ } return fInnerEvents.get(index); } @Override public E set(int index, E element) { if (index < 0 || index >= fSize) {
<|startcomment|> next element returns at index fCursor++ <|endcomment|>  public ELEMENT next() { if (!hasNext()) { throw new NoSuchElementException(); } fCursor++; <|startfocus|> ELEMENT element = fList.get(fCursor); return element; <|endfocus|>
<|startcomment|> nextIndex, returns the cursor <|endcomment|>  public int nextIndex() { <|startfocus|> return fCursor; <|endfocus|>
<|startcomment|> Why is this not noexcept? <|endcomment|>  // constexpr bool comma_is_not_noexcept = noexcept(fun(), fun_noexcept()); // constexpr bool ctor_is_noexcept = noexcept(myclass{}); // constexpr bool ctor_is_not_noexcept = noexcept(myclass{1}); // constexpr bool constexpr_ctor_is_noexcept = noexcept(myclass{1, 1}); // constexpr bool aggregate_init_is_noexcept = noexcept(myaggregate{{1}}); // constexpr bool aggregate_init_is_not_noexcept = noexcept(myaggregate{{my_int}}); // constexpr bool aggregate_access_is_noexcept = noexcept(agg.a); // constexpr bool not_noexcept_conditional = noexcept(condition() ? fun() : fun_noexcept()); // constexpr bool is_noexcept_conditional = noexcept(condition() ? fun_noexcept() : fun_noexcept()); // constexpr bool throw_is_not_noexcept = noexcept(throw fun_noexcept()); <|startfocus|> public void testNoexceptOperator_545021() throws Exception { <|endfocus|> BindingAssertionHelper helper = getAssertionHelper(); helper.assertVariableValue("fun_is_not_noexcept", 0); helper.assertVariableValue("unevaluated_fun_is_noexcept", 1); helper.assertVariableValue("fun_noexcept_is_noexcept", 1);
<|startcomment|> Is this even valid given that there are two overloads? <|endcomment|>  helper.assertVariableValue("constexpr_ctor_is_noexcept", 1); helper.assertVariableValue("aggregate_init_is_noexcept", 1); helper.assertVariableValue("not_noexcept_conditional", 0); helper.assertVariableValue("is_noexcept_conditional", 1); helper.assertVariableValue("throw_is_not_noexcept", 0); } // int fun(); // int fun(int); // template<typename T> // int funt(T); // template<typename T> // int funt_noexcept(T) noexcept; // <|startfocus|> // constexpr bool unevaluated_fun_is_noexcept = noexcept(fun); <|endfocus|> // constexpr bool funt_is_not_noexcept = noexcept(funt(1)); // constexpr bool funt_noexcept_is_noexcept = noexcept(funt_noexcept(1)); public void testNoexceptOperator2_545021() throws Exception { BindingAssertionHelper helper = getAssertionHelper(); helper.assertVariableValue("unevaluated_fun_is_noexcept", 1); helper.assertVariableValue("funt_is_not_noexcept", 0); helper.assertVariableValue("funt_noexcept_is_noexcept", 1); } // struct type1{ // void operator=(int); // bool operator!(); // }; // type1 t1;
<|startcomment|> Presumably that's intended to be `noexcept(!t2)` <|endcomment|>  // void operator=(int); // bool operator!(); // }; // type1 t1; // struct type2{ // void operator=(int) noexcept; // bool operator!() noexcept; // }; // type2 t2; // constexpr bool binaryop_is_not_noexcept = noexcept(t1 = 1); // constexpr bool unaryop_is_not_noexcept = noexcept(!t1); // constexpr bool noexcept_binaryop_is_noexcept = noexcept(t2 = 1); <|startfocus|> // constexpr bool noexcept_unaryop_is_noexcept = noexcept(t2 = 1); public void testNoexceptOperator3_545021() throws Exception { <|endfocus|> BindingAssertionHelper helper = getAssertionHelper(); helper.assertVariableValue("binaryop_is_not_noexcept", 0); helper.assertVariableValue("unaryop_is_not_noexcept", 0); helper.assertVariableValue("noexcept_binaryop_is_noexcept", 1); helper.assertVariableValue("noexcept_unaryop_is_noexcept", 1); } // void fun(); // void fun_taking_funptr(void(*ptr)()) noexcept; // // constexpr bool is_noexcept = noexcept(fun_taking_funptr(fun));
<|startcomment|> We'll need to go through the call sites of this constructor as well and provide a noexcept evaluation where possible. <|endcomment|>  private final boolean isRValueReference; private final boolean takesVarargs; private final ICPPEvaluation noexceptSpecifier; <|startfocus|> public CPPFunctionType(IType returnType, IType[] types) { this(returnType, types, false, false, false, false, false, null); <|endfocus|>
<|startcomment|> If there's an overload the result should be (overload is noexcept) && (arg1 is noexcept) && (arg2 is noexcept). <|endcomment|>  public boolean isNoexcept(boolean inCalledContext) { ICPPFunction overload = getOverload(); if (overload != null) { <|startfocus|> return EvalUtil.evaluateNoexceptSpecifier(overload.getType().getNoexceptSpecifier()); <|endfocus|> } return fArg1.isNoexcept(inCalledContext) && fArg2.isNoexcept(inCalledContext);
<|startcomment|> The condition expression could throw as well. <|endcomment|>  public boolean isNoexcept(boolean inCalledContext) { <|startfocus|> return fPositive.isNoexcept(inCalledContext) && fNegative.isNoexcept(inCalledContext); <|endfocus|>
<|startcomment|> It's possible you can't. I think that, like EvalReference, EvalConstructor is only created as an intermediate result during constexpr evaluation. <|endcomment|>  public boolean isNoexcept(boolean inCalledContext) { <|startfocus|> // TODO how can I trigger this? <|endfocus|> return EvalUtil.evaluateNoexceptSpecifier(fConstructor.getType().getNoexceptSpecifier());
<|startcomment|> Would be interesting to see a test case that triggers this assert. <|endcomment|>  public boolean isNoexcept(boolean inCalledContext) { <|startfocus|> // assert false; // TODO this assert is hit <|endfocus|> return true;
<|startcomment|> Likewise. <|endcomment|>  public boolean isNoexcept(boolean inCalledContext) { <|startfocus|> //assert false; // TODO assert hit by original bug report <|endfocus|> return true;
<|startcomment|> We need to check fOwnerEval as well. Test case: struct S { int mem; }; S foo(); // could throw constexpr bool n = noexcept(foo().mem); // should be false <|endcomment|> <|startfocus|> public boolean isNoexcept(boolean inCalledContext) { <|endfocus|> if (inCalledContext) { return EvalUtil.bindingIsNoexcept(getMember()); } else return true; // in unevaluated context
<|startcomment|> It would be good to give a justification for the assert in a comment. (I mentioned what they are in my comments on Patch Set 3.) <|endcomment|>  public boolean isNoexcept(boolean inCalledContext) { <|startfocus|> assert false; <|endfocus|> return true;
<|startcomment|> (overload is noexcept) && (argument is noexcept) <|endcomment|>  public boolean isNoexcept(boolean inCalledContext) { if (fOperator == op_throw) return false; ICPPFunction overload = getOverload(); if (overload != null) { <|startfocus|> return EvalUtil.evaluateNoexceptSpecifier(overload.getType().getNoexceptSpecifier()); <|endfocus|> } return fArgument.isNoexcept(inCalledContext);
<|startcomment|> Test with nulls <|endcomment|>  public void testToString() { <|startfocus|> List<String> reference = Arrays.asList("Pomme", "Peche", "Poire", "Banane"); <|endfocus|> List<String> test = createList(reference); assertEquals("[0:Pomme, 1:Peche, 2:Poire, 3:Banane]", test.toString());
<|startcomment|> Could you assert the return value of all successful next() and previous()? <|endcomment|>  private static void testListIterator(List<String> test) { ListIterator<String> iterator = test.listIterator(0); assertTrue(iterator.hasNext()); assertFalse(iterator.hasPrevious()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.next(); assertEquals("yo", iterator.next()); <|startfocus|> iterator.previous(); <|endfocus|> try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.next(); iterator.next(); iterator.next(); iterator.next(); try { iterator.next(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } iterator.previous(); assertEquals(3, iterator.previousIndex()); assertEquals(4, iterator.nextIndex()); try { iterator.remove(); fail("Should not get here"); } catch (UnsupportedOperationException e) { // correct flow } try { iterator.set("hej"); fail("Should not get here");
<|startcomment|> Use <p> to break paragraphs. <|endcomment|> import java.util.HashMap; import java.util.Iterator; import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; import org.eclipse.jdt.annotation.Nullable; /** * Sparse list, a list optimized for when most of the data is <code>null</code>. <|startfocus|> * Nulls will increment the size of the datastructure but not stored as null * means the data is not present. * * Note: this iterates in the sorted order. * <|endfocus|> * This implementation supports: * <ul> * <li>{@link #add(Object)}</li> * <li>{@link #contains(Object)}</li> * <li>{@link #clear()}</li> * <li>{@link #iterator()}</li> * <li>{@link #isEmpty()}</li> * <li>{@link #toArray()}</li> * <li>{@link #toArray(Object[])}</li> * <li>{@link #set(int, Object)}</li>
<|startcomment|> I understand this to mean the sorted order of values, but is it really the case? I would expect a List to iterate in the list order? (as per List Javadoc: 'in proper sequence'). In that case it's not worth noting. What would be worth mentioning is that nulls are returned by the iterators, and what happens with toArray(). <|endcomment|> import java.util.List; import java.util.ListIterator; import java.util.Map; import java.util.Map.Entry; import java.util.Objects; import java.util.Spliterator; import org.eclipse.jdt.annotation.NonNull; import org.eclipse.jdt.annotation.Nullable; /** * Sparse list, a list optimized for when most of the data is <code>null</code>. <|startfocus|> * Nulls will increment the size of the datastructure but not stored as null * means the data is not present. * * Note: this iterates in the sorted order. * <|endfocus|> * This implementation supports: * <ul> * <li>{@link #add(Object)}</li> * <li>{@link #contains(Object)}</li> * <li>{@link #clear()}</li> * <li>{@link #iterator()}</li> * <li>{@link #isEmpty()}</li> * <li>{@link #toArray()}</li> * <li>{@link #toArray(Object[])}</li> * <li>{@link #set(int, Object)}</li>
<|startcomment|> If I understand correctly, the hash map will only contain non-null values. Shall we make it official? <|endcomment|>  * <li>{@link #lastIndexOf(Object)}</li> * </ul> * * TODO: Keep an eye out for a better datastructure... this is fine, but if it * can be replaced by an externally maintained datastructure, that would be * better. * * @author Matthew Khouzam * @param <E> * the element type */ public class SparseList<E> implements List<E> { <|startfocus|> private final Map<Integer, E> fInnerElements = new HashMap<>(); <|endfocus|> private int fSize = 0; /** * Copy constructor * * @param events * list of events */ public SparseList(List<E> events) { ensureSize(events.size()); for (int i = 0; i < events.size(); i++) { E element = events.get(i); if (element != null) { set(i, element); } } } /** * default constructor */ public SparseList() { // Do nothing } @Override public int size() {
<|startcomment|> I think super implementation is correct (size == 0). Nulls are still considered part of the list, they just take no memory in internal structure. <|endcomment|>  public boolean isEmpty() { <|startfocus|> return fInnerElements.isEmpty(); <|endfocus|>
<|startcomment|> Should we make special code for null (maybe by comparing size of this vs. size of hash map). <|endcomment|>  public boolean contains(Object o) { <|startfocus|> return fInnerElements.containsValue(o); <|endfocus|>
<|startcomment|> That is true of all List implementations, not worth mentioning here (there's already a @throws tag for it). But need to add same description as toArray(). <|endcomment|>  int size = fInnerElements.size(); Object[] retVal = new Object[size]; Iterator<E> iterator = iterator(); for (int i = 0; i < size; i++) { Object next = null; while (iterator.hasNext() && next == null) { next = iterator.next(); } retVal[i] = next; } return retVal; } <|startfocus|> /** * {@inheritDoc} * * Warning, will throw exceptions if a[] is the wrong type. */ <|endfocus|> @Override public <T> T[] toArray(T[] a) { int size = Math.min(a.length, fInnerElements.size()); Iterator<E> iterator = iterator(); for (int i = 0; i < size; i++) { @Nullable E next = null; while (iterator.hasNext() && next == null) { next = iterator.next(); } a[i] = (T) next; } return a; } @Override public boolean add(E e) { if (e != null) {
<|startcomment|> Special case for null? <|endcomment|> <|startfocus|> public int indexOf(Object o) { <|endfocus|> for (Entry<Integer, E> entry : fInnerElements.entrySet()) { if (Objects.equals(entry.getValue(), o)) { return entry.getKey(); } } return -1;
<|startcomment|> Special case for null? <|endcomment|>  public int lastIndexOf(Object o) { <|startfocus|> int last = -1; <|endfocus|> for (Entry<Integer, E> entry : fInnerElements.entrySet()) { if (Objects.equals(entry.getValue(), o)) { last = Math.max(last, entry.getKey()); } } return last;
<|startcomment|> Shouldn't requestLayout be called on the perspSwitcherToolbar Control directly, instead of the Shell? <|endcomment|>  private void fixSize() { perspSwitcherToolbar.pack(); perspSwitcherToolbar.getParent().pack(); <|startfocus|> perspSwitcherToolbar.getShell().requestLayout(); <|endfocus|>
<|startcomment|> Here's an heretic thought I'm experimenting with. How about the TimeGraphEntry does not require a TimeGraphEntryModel, but any tree model? Technically, there's no reason to require TimeGraphEntryModel to get the start and end time. We create new models when there is a change in end time/name anyway. I think the ITmfTreeDataModel should be the base of everything: simple tables/tree viewers, xy charts, time graph views. If we have more specialized classes for some use cases, it's good and all, but it should not be required, or else it's too limiting, or the data provider is too linked with the view that displays it. Any objection? I'll try to propose something not too API-disruptive. <|endcomment|>  public TimeGraphEntry(@NonNull TimeGraphEntryModel model) { <|startfocus|> setModel(model); <|endfocus|>
<|startcomment|> formatting <|endcomment|>  public boolean equals(Object obj) { if(!super.equals(obj)) { return false; } <|startfocus|> if(obj instanceof TimeLineEvent) { <|endfocus|> TimeLineEvent lineEvent = (TimeLineEvent) obj; return Objects.equals(getValues(), lineEvent.getValues()); } return false;
<|startcomment|> After some thinking I think I would skip this if completely and let it be the last one, like it was done before. Rationale: for non-Windows systems this condition is always true, independently if the path is absolute or relative to the workspace, so probably this could lead to false positives and behavior change, compared to current code. So path like /tmp/libs/hello.jar could be either located in the project "tmp" somewhere on the earth or in the /tmp root directory in the local file system. Original code would try first the later one, new code will prefer workspace one. <|endcomment|>  protected IResource getResource(IPath path) { if (path != null) { IWorkspaceRoot root = ResourcesPlugin.getWorkspace().getRoot(); <|startfocus|> if (path.getDevice() == null) { // search relative to the workspace if no device present IResource member = root.findMember(path); if (member != null) { return member; } <|endfocus|> } // look for files or folders with the given path IFile file = root.getFileForLocation(path); if (file != null) { return file; } if (getType() != ARCHIVE) { IContainer container = root.getContainerForLocation(path); if (container != null) { return container; } } @SuppressWarnings("deprecation") IFile[] files = root.findFilesForLocation(path); if (files.length > 0) { return files[0]; } if (getType() != ARCHIVE) { @SuppressWarnings("deprecation") IContainer[] containers = root.findContainersForLocation(path); if (containers.length > 0) { return containers[0]; } } } return null;
<|startcomment|> Is the @since needed here ? This is internal anyways. If it is, it would need to be 1.11 as jdt.core.manipulation hasn't been bumped to 1.12. <|endcomment|>  import org.eclipse.jdt.core.IMember; import org.eclipse.jdt.core.search.IJavaSearchConstants; /** * This class represents the general parts of a method call (either to or from a * method). * */ public abstract class MethodWrapper extends PlatformObject { public static IMethodWrapperDynamic fMethodWrapperCore= new MethodWrapperDynamicCore(); /** * Set the IMethodWrapperCore class to use in MethodWrapper * * @param core the IMethodWrapperCore class to store <|startfocus|> * @since 1.12 <|endfocus|> */ public static final void setMethodWrapperDynamic(IMethodWrapperDynamic core) { fMethodWrapperCore= core; } private Map<String, MethodCall> fElements = null; /* * A cache of previously found methods. This cache should be searched * before adding a "new" method object reference to the list of elements. * This way previously found methods won't be searched again. */ private Map<String, Map<String, MethodCall>> fMethodCache; private final MethodCall fMethodCall; private final MethodWrapper fParent; private int fLevel;
<|startcomment|> assert Hola <|endcomment|>  private static void testListIterator(List<String> test) { ListIterator<String> iterator = test.listIterator(0); assertTrue(iterator.hasNext()); assertFalse(iterator.hasPrevious()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } <|startfocus|> iterator.next(); <|endfocus|> assertEquals("yo", iterator.next()); assertEquals("yo", iterator.previous()); assertEquals("Hola", iterator.previous()); try { iterator.previous(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } assertEquals("Hola", iterator.next()); assertEquals("yo", iterator.next()); assertEquals("quiero", iterator.next()); assertEquals("un", iterator.next()); assertEquals("UNSUPPORTEDOPERATIONEXCEPTION!", iterator.next()); try { iterator.next(); fail("Should not get here"); } catch (NoSuchElementException e) { // correct flow } assertEquals("UNSUPPORTEDOPERATIONEXCEPTION!", iterator.previous()); assertEquals(3, iterator.previousIndex());
<|startcomment|> ListIterator should not have a start and end, just a starting index. If you want a partial ListIterator that starts at the beginning of this partial range, use List.subList(start, end).listIterator(). <|endcomment|>  public GenericReadOnlyListIterator(List<E> list, int start, int end) { fList = list; <|startfocus|> fStart = start; fEnd = end; <|endfocus|> fCursor = start - 1;
<|startcomment|> It works, but I think it would be more understandable if fCursor was the next index instead of the previous index. <|endcomment|>  public GenericReadOnlyListIterator(List<E> list, int start, int end) { fList = list; <|startfocus|> fStart = start; fEnd = end; <|endfocus|> fCursor = start - 1;
<|startcomment|> It should test against the list size. Probably more understandable using fCursor. <|endcomment|>  public boolean hasNext() { <|startfocus|> return nextIndex() < fEnd; <|endfocus|>
<|startcomment|> It should test against 0. Probably more understandable using fCursor. <|endcomment|>  public boolean hasPrevious() { <|startfocus|> return previousIndex() >= fStart; <|endfocus|>
<|startcomment|> Should use ?: operator instead, otherwise might needlessly check map for null. <|endcomment|>  public boolean contains(Object o) { <|startfocus|> return (o == null && size() > fInnerElements.size()) || fInnerElements.containsValue(o); <|endfocus|>
<|startcomment|> Is this better than catching ClassCastException? <|endcomment|>  @Nullable E next = null; while (iterator.hasNext() && next == null) { next = iterator.next(); } if (next != null) { Class<? extends @NonNull Object> elementClass = next.getClass(); if (!Objects.equals(elementClass, componentType) && !elementClass.isInstance(componentType)) { throw new ArrayStoreException("Cannot convert from (" + elementClass + " to " + newArray.getClass().getComponentType()); //$NON-NLS-1$ //$NON-NLS-2$ } } <|startfocus|> newArray[i] = (T) next; <|endfocus|>
<|startcomment|> Need to find the first, similar to lastIndexOf(). <|endcomment|>  public int indexOf(Object o) { if (o == null && contains(null)) { for (int i = 0; i < size(); i++) { if (!fInnerElements.containsKey(i)) { return i; } } } for (Entry<Integer, E> entry : fInnerElements.entrySet()) { if (Objects.equals(entry.getValue(), o)) { <|startfocus|> return entry.getKey(); <|endfocus|> } } return -1;
<|startcomment|> I think this might be incorrectly ordered, and also missing the nulls? But I'm not sure what a Spliterator does. <|endcomment|>  public Spliterator<E> spliterator() { <|startfocus|> return fInnerElements.values().spliterator(); <|endfocus|>
<|startcomment|> This doesn't respect the API, because it does not allow to go previous() from the index. See comments on the iterator class. Please add tests for this. <|endcomment|>  public ListIterator<E> listIterator(int index) { <|startfocus|> return new GenericReadOnlyListIterator<>(this, index, size()); <|endfocus|>
<|startcomment|> add(int, E) <|endcomment|>  public void add(int index, E element) { <|startfocus|> throw new UnsupportedOperationException("No add(index) in " + this.getClass().getName()); //$NON-NLS-1$ <|endfocus|>
<|startcomment|> remove(int) <|endcomment|>  public E remove(int index) { <|startfocus|> throw new UnsupportedOperationException("No delete in " + this.getClass().getName()); //$NON-NLS-1$ <|endfocus|>
<|startcomment|> remove(Object) <|endcomment|>  public boolean remove(Object o) { <|startfocus|> throw new UnsupportedOperationException("No remove in " + this.getClass().getName()); //$NON-NLS-1$ <|endfocus|>
<|startcomment|> addAll(int, Collection) <|endcomment|>  public boolean addAll(int index, Collection<? extends E> c) { <|startfocus|> throw new UnsupportedOperationException("No addAll(index) in " + this.getClass().getName()); //$NON-NLS-1$ <|endfocus|>
<|startcomment|> Should be easy enough and fun to implement... but maybe only if the returned list is not backed by the original list (read-only). <|endcomment|>  throw new UnsupportedOperationException("No removeAll in " + this.getClass().getName()); //$NON-NLS-1$ } @Override public boolean retainAll(Collection<?> c) { throw new UnsupportedOperationException("No retainAll in " + this.getClass().getName()); //$NON-NLS-1$ } @Override public @NonNull List<E> subList(int fromIndex, int toIndex) { <|startfocus|> throw new UnsupportedOperationException("No subList(fromIndex, toIndex) in " + this.getClass().getName()); //$NON-NLS-1$ <|endfocus|> } } 
<|startcomment|> Copyright 2019 <|endcomment|> ***************************************************************************** <|startfocus|> * Copyright (c) 2017 vogella GmbH and others. <|endfocus|> * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * Simon Scholz <simon.scholz@vogella.com> - initial API and implementation ******************************************************************************/ package org.eclipse.e4.ui.tests.workbench; import org.eclipse.e4.core.di.annotations.Evaluate; import org.eclipse.e4.ui.model.application.ui.MImperativeExpression; public class ImperativeExpressionTestEvaluationPersistedState { public static final String PERSISTED_STATE_TEST = "persisted-state-test"; @Evaluate public boolean isVisible(MImperativeExpression exp) { return exp.getPersistedState().containsKey(PERSISTED_STATE_TEST); } } 
<|startcomment|> I'm a bit confused about this hook - this seems to say that it is run upon every non-bitmap commit visited, but from reading the code, it seems that it is run exactly once in the good case (and in the bad case, it is run once on every commit in "start"). Can you document this in a more specific way? The other issue is that if this is run only exactly once, couldn't whatever code is necessary be run by the caller before and after this calculator (instead of passing hooks)...but that's a question for another time - as it is, I can see that this patch just rearranges the logic of BitmapWalker (without adding or removing anything), which makes it much easier to see that it is correct. <|endcomment|>  * {@link BitmapWalker}. * * @since 5.5 */ final class BitmapCalculator { private final RevWalk walk; private final BitmapIndex bitmapIndex; private final ProgressMonitor pm; private long countOfBitmapIndexMisses; private final BitmapWalkHook preWalkHook; private final BitmapWalkHook postWalkHook; /** <|startfocus|> * Hook that can be invoked before or after the walk building the bitmap of * a commit that doesn't have one. * <p> <|endfocus|> * This is intended to be used only by {@link BitmapWalker}. */ interface BitmapWalkHook { /** * Hooked invoked before and after traversing the tree building a commit * bitmap. * * @param walk * revwalk in use. * @param bitmapResult * bitmap calculated so far. * @param pm * progress monitor * @throws IOException */ void run(RevWalk walk, BitmapBuilder bitmapResult, ProgressMonitor pm) throws IOException; } 
<|startcomment|> If you're already creating a new interface, it's probably clearer to have the same interface have both pre- and post-, instead of asking the caller to make 2 classes with the same signature. <|endcomment|>  private final RevWalk walk; private final BitmapIndex bitmapIndex; private final ProgressMonitor pm; private long countOfBitmapIndexMisses; private final BitmapWalkHook preWalkHook; private final BitmapWalkHook postWalkHook; /** * Hook that can be invoked before or after the walk building the bitmap of * a commit that doesn't have one. * <p> * This is intended to be used only by {@link BitmapWalker}. */ interface BitmapWalkHook { /** <|startfocus|> * Hooked invoked before and after traversing the tree building a commit * bitmap. <|endfocus|> * * @param walk * revwalk in use. * @param bitmapResult * bitmap calculated so far. * @param pm * progress monitor * @throws IOException */ void run(RevWalk walk, BitmapBuilder bitmapResult, ProgressMonitor pm) throws IOException; } private static final BitmapWalkHook NULL_BITMAP_HOOK = new BitmapWalkHook() { @Override public void run(RevWalk walk, BitmapBuilder bitmapResult, ProgressMonitor pm) {
<|startcomment|> Reset these 2 lines to what they were (i.e., don't include unnecessary whitespace changes). <|endcomment|>  BitmapBuilder seen, boolean ignoreMissing) throws MissingObjectException, IncorrectObjectTypeException, IOException { return this.bitmapCalculator.getBitmapFor(start, seen, ignoreMissing); } /** * Filter that excludes objects already in the given bitmap. */ static class BitmapObjectFilter extends ObjectFilter { private final BitmapBuilder bitmap; BitmapObjectFilter(BitmapBuilder bitmap) { this.bitmap = bitmap; } @Override public final boolean include(ObjectWalk walker, AnyObjectId objid) <|startfocus|> throws MissingObjectException, IncorrectObjectTypeException, IOException { <|endfocus|> return !bitmap.contains(objid); } } } 
<|startcomment|> Inconsistent indentation. <|endcomment|>  public void set(Object[] newContents) { Assert.isNotNull(newContents); data.clear(); data.addAll(Arrays.asList(newContents)); <|startfocus|> IConcurrentModelListener[] listeners = getListeners(); for (IConcurrentModelListener listener : listeners) { <|endfocus|> listener.setContents(newContents); }
<|startcomment|> Inconsistent indentation. <|endcomment|>  // copy only linked resource children (267173) if (source.isLinked() && source.getLocation().equals(existing.getLocation())) children = filterNonLinkedResources(children); ResourceDescription[] overwritten = copy(children, destinationPath, resourcesAtDestination, iterationProgress, uiInfo, false, createVirtual, createLinks, relativeToVariable); <|startfocus|> // We don't record the copy since this recursive call will // do so. Just record the overwrites. overwrittenResources.addAll(Arrays.asList(overwritten)); <|endfocus|> } else { // delete the destination folder, copying a linked folder // over an unlinked one or vice versa. Fixes bug 28772. ResourceDescription[] deleted = delete(new IResource[] { existing }, iterationProgress.split(1), uiInfo, false); iterationProgress.setWorkRemaining(100); if ((createLinks || createVirtual) && (source.isLinked() == false) && (source.isVirtual() == false)) { IFolder folder = workspaceRoot.getFolder(destinationPath); if (createVirtual) { folder.create(IResource.VIRTUAL, true, iterationProgress.split(1));
<|startcomment|> Inconsistent indentation. <|endcomment|>  if (mapping == null) continue; ResourceTraversal[] traversals = null; try { traversals = mapping.getTraversals( ResourceMappingContext.LOCAL_CONTEXT, new NullProgressMonitor()); } catch (CoreException e) { StatusManager.getManager().handle(e, IDEWorkbenchPlugin.IDE_WORKBENCH); } if (traversals != null) { IResource[] resources = null; for (ResourceTraversal traversal : traversals) { resources = traversal.getResources(); if (resources != null) { <|startfocus|> result.addAll(Arrays.asList(resources)); <|endfocus|> } } } } else result.add(resource); } // all that can be converted are done, answer new selection if (result.isEmpty()) { return StructuredSelection.EMPTY; } return new StructuredSelection(result.toArray());
<|startcomment|> Inconsistent indentation. <|endcomment|>  static Set<IResource> getResourcesForFilter(MarkerFieldFilterGroup group, IResource[] selectedResources, IWorkspaceRoot root) { HashSet<IResource> resourceSet = new HashSet<>(); switch (group.getScope()) { case MarkerFieldFilterGroup.ON_ANY: { resourceSet.add(root); break; } case MarkerFieldFilterGroup.ON_SELECTED_ONLY: case MarkerFieldFilterGroup.ON_SELECTED_AND_CHILDREN: { <|startfocus|> resourceSet.addAll(Arrays.asList(selectedResources)); <|endfocus|> break; } case MarkerFieldFilterGroup.ON_ANY_IN_SAME_CONTAINER: { for (IResource resource : getProjects(selectedResources)) { resourceSet.add(resource); } break; } case MarkerFieldFilterGroup.ON_WORKING_SET: { group.refresh(); resourceSet.addAll(Arrays.asList(group.getResourcesInWorkingSet())); break; } } return resourceSet;
<|startcomment|> one or more continuous lines that change over time <|endcomment|>  * * @author Alvaro Sanchez-Leon * @author Patrick Tasse */ public interface ITimeGraphEntry extends ISelection { /** * An enumeration of the display style of the time graph entries * * @author Geneviève Bastien * @since 5.0 */ public enum DisplayStyle { /** * Display states, ie rectangle representing a discrete state that has a * beginning and an end */ STATE, /** <|startfocus|> * Display XY lines for this entry, ie continuous values that changes <|endfocus|> * over time */ LINE } /** * Returns the parent of this entry, or <code>null</code> if it has none. * * @return the parent element, or <code>null</code> if it has none */ ITimeGraphEntry getParent(); /** * Returns whether this entry has children. * * @return <code>true</code> if the given element has children, * and <code>false</code> if it has no children */ boolean hasChildren(); 
<|startcomment|> Should there be a ITimeLineEvent interface? <|endcomment|>  public void addEvent(ITimeEvent event) { if (!(event instanceof TimeLineEvent)) { <|startfocus|> throw new IllegalArgumentException("Need to be a TimeLineEvent"); //$NON-NLS-1$ <|endfocus|> } super.addEvent(event);
<|startcomment|> Needs <|endcomment|>  public void addEvent(ITimeEvent event) { if (!(event instanceof TimeLineEvent)) { <|startfocus|> throw new IllegalArgumentException("Need to be a TimeLineEvent"); //$NON-NLS-1$ <|endfocus|> } super.addEvent(event);
<|startcomment|> The duration is not used for a TimeLineEvent, it shouldn't be a parameter (pass 0 to super). <|endcomment|> <|startfocus|> public TimeLineEvent(ITimeGraphEntry entry, long time, long duration) { this(entry, time, duration, new ArrayList<>()); <|endfocus|>
<|startcomment|> No duration <|endcomment|> <|startfocus|> public TimeLineEvent(ITimeGraphEntry entry, long time, long duration, List<Long> values) { super(entry, time, duration); <|endfocus|> fValues = values;
<|startcomment|> space <|endcomment|>  public boolean equals(Object obj) { <|startfocus|> if(!super.equals(obj)) { <|endfocus|> return false; } if(obj instanceof TimeLineEvent) { TimeLineEvent lineEvent = (TimeLineEvent) obj; return Objects.equals(getValues(), lineEvent.getValues()); } return false;
<|startcomment|> space <|endcomment|>  public boolean equals(Object obj) { if(!super.equals(obj)) { return false; } <|startfocus|> if(obj instanceof TimeLineEvent) { <|endfocus|> TimeLineEvent lineEvent = (TimeLineEvent) obj; return Objects.equals(getValues(), lineEvent.getValues()); } return false;
<|startcomment|> The format of the names is inconsistent, also remove duration. <|endcomment|>  public String toString() { StringBuilder builder = new StringBuilder(); builder.append("[TimeLineEvent Values=").append(getValues()) //$NON-NLS-1$ .append(", Entry=").append(getEntry()) //$NON-NLS-1$ .append(", fTime=").append(getTime()) //$NON-NLS-1$ .append(", Duration=").append(getDuration()) //$NON-NLS-1$ <|startfocus|> .append(']'); return builder.toString(); <|endfocus|>
<|startcomment|> refs is a list of *all* TimeLineEvent to be drawn, but you only use the first 'n' where 'n' is the number of series. This could be optimized... <|endcomment|>  private void drawLineGraphEntry(GC gc, long time0, Rectangle rect, double pixelsPerNanoSec, Iterator<ITimeEvent> iterator) { // clamp 0 - max positive long max = Long.MIN_VALUE; long min = 0; List<@Nullable TimeLineEvent> refs = new ArrayList<>(); <|startfocus|> List<List<LongPoint>> toDraw = new ArrayList<>(); <|endfocus|> List<RGBA> colors = new ArrayList<>(); // todo: update when we want mutliple series ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = 1; for (int i = 0; i < nbSeries; i++) { toDraw.add(new ArrayList<>()); } while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec));
<|startcomment|> series ? <|endcomment|>  private void drawLineGraphEntry(GC gc, long time0, Rectangle rect, double pixelsPerNanoSec, Iterator<ITimeEvent> iterator) { // clamp 0 - max positive long max = Long.MIN_VALUE; long min = 0; List<@Nullable TimeLineEvent> refs = new ArrayList<>(); <|startfocus|> List<List<LongPoint>> toDraw = new ArrayList<>(); <|endfocus|> List<RGBA> colors = new ArrayList<>(); // todo: update when we want mutliple series ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = 1; for (int i = 0; i < nbSeries; i++) { toDraw.add(new ArrayList<>()); } while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec));
<|startcomment|> Remove this loop. <|endcomment|>  // clamp 0 - max positive long max = Long.MIN_VALUE; long min = 0; List<@Nullable TimeLineEvent> refs = new ArrayList<>(); List<List<LongPoint>> toDraw = new ArrayList<>(); List<RGBA> colors = new ArrayList<>(); // todo: update when we want mutliple series ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); <|startfocus|> int nbSeries = 1; for (int i = 0; i < nbSeries; i++) { toDraw.add(new ArrayList<>()); } <|endfocus|> while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds
<|startcomment|> The previous and next points should be included so that the line doesn't disappear at bounds. <|endcomment|>  } while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); <|startfocus|> int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width || xEnd < rect.x) { <|endfocus|> // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; }
<|startcomment|> A bit weird since event is a ITimeEvent... Should it be lineEvent? <|endcomment|>  if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; <|startfocus|> List<Long> values = timeEvent.getValues(); <|endfocus|> for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) {
<|startcomment|> timeEvent.getValues().size() <|endcomment|>  } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; <|startfocus|> List<Long> values = timeEvent.getValues(); <|endfocus|> for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i));
<|startcomment|> The min is always zero because it's initialized to 0. <|endcomment|>  if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); <|startfocus|> toDraw.get(i).add(new LongPoint(x, val)); <|endfocus|> refs.add(timeEvent); } } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
<|startcomment|> Before this line, add an ArrayList to toDraw if i >= size. <|endcomment|>  if (x >= rect.x + rect.width || xEnd < rect.x) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); <|startfocus|> toDraw.get(i).add(new LongPoint(x, val)); <|endfocus|> refs.add(timeEvent); } } if (refs.isEmpty()) { return; } for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
<|startcomment|> toDraw.size() <|endcomment|>  List<Long> values = timeEvent.getValues(); for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; } <|startfocus|> for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); <|endfocus|> int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < nbSeries; i++) { RGBA rgba = colors.get(i);
<|startcomment|> The style of the first TimeLineEvent in a series decides the style of the whole line, the other styles are ignored. At least this should be mentioned in a comment. <|endcomment|>  long val = values.get(i); max = Math.max(Math.abs(val), max); min = Math.min(Math.abs(val), min); toDraw.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; } <|startfocus|> for (int i = 0; i < nbSeries; i++) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); <|endfocus|> int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < nbSeries; i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha(); gc.setAlpha(rgba.alpha);
<|startcomment|> toDraw.size() <|endcomment|>  Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(refs.get(i)); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); <|startfocus|> for (int i = 0; i < nbSeries; i++) { <|endfocus|> RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha(); gc.setAlpha(rgba.alpha); gc.setForeground(color); List<LongPoint> series = toDraw.get(i); int[] points = new int[series.size() * 2]; for (int point = 0; point < series.size(); point++) { LongPoint longPoint = series.get(point); points[point * 2] = longPoint.x;
<|startcomment|> Please update the copyright year and if you wish you may add yourself as contributor. <|endcomment|> ***************************************************************************** <|startfocus|> * Copyright (c) 2000, 2015 IBM Corporation and others. <|endfocus|> * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * IBM Corporation - initial API and implementation *******************************************************************************/ package org.eclipse.jface.viewers; import org.eclipse.core.runtime.Assert; import org.eclipse.swt.dnd.DND; import org.eclipse.swt.dnd.DropTargetAdapter; import org.eclipse.swt.dnd.DropTargetEvent; import org.eclipse.swt.dnd.TransferData; import org.eclipse.swt.graphics.Point; import org.eclipse.swt.graphics.Rectangle; import org.eclipse.swt.widgets.Item; import org.eclipse.swt.widgets.List; import org.eclipse.swt.widgets.Table; import org.eclipse.swt.widgets.TableItem; import org.eclipse.swt.widgets.Tree; import org.eclipse.swt.widgets.TreeItem; /** * This adapter class provides generic drag-and-drop support for a viewer. * <p>
<|startcomment|> Should be TABs. <|endcomment|>  for (int i = 0; i < resources.length; i++) { // Copy the resources and record the overwrites that would // be restored if this operation were reversed ResourceDescription[] overwrites; overwrites = WorkspaceUndoUtil.copy(new IResource[] { resources[i] }, getDestinationPath(resources[i], i), resourcesAtDestination, subMonitor.split(1), uiInfo, true, fCreateGroups, fCreateLinks, fRelativeToVariable); <|startfocus|> // Accumulate the overwrites into the full list overwrittenResources.addAll(Arrays.asList(overwrites)); <|endfocus|> } // Are there any previously overwritten resources to restore now? if (resourceDescriptions != null) { for (ResourceDescription resourceDescription : resourceDescriptions) { if (resourceDescription != null) { resourceDescription.createResource(subMonitor.split(1)); } } } // Reset resource descriptions to the just overwritten resources setResourceDescriptions(overwrittenResources .toArray(new ResourceDescription[overwrittenResources.size()])); // Reset the target resources to refer to the resources in their new // location. setTargetResources(resourcesAtDestination
<|startcomment|> Should be TABs. <|endcomment|>  for (int i = 0; i < resources.length; i++) { // Move the resources and record the overwrites that would // be restored if this operation were reversed ResourceDescription[] overwrites; overwrites = WorkspaceUndoUtil.move(new IResource[] { resources[i] }, getDestinationPath(resources[i], i), resourcesAtDestination, undoDestinationPaths, subMonitor.split(1), uiInfo, true); <|startfocus|> // Accumulate the overwrites into the full list overwrittenResources.addAll(Arrays.asList(overwrites)); <|endfocus|> } // Are there any previously overwritten resources to restore now? if (resourceDescriptions != null) { for (ResourceDescription resourceDescription : resourceDescriptions) { if (resourceDescription != null) { resourceDescription.createResource(subMonitor.split(1)); } } } // Reset resource descriptions to the just overwritten resources setResourceDescriptions(overwrittenResources .toArray(new ResourceDescription[overwrittenResources.size()])); // Reset the target resources to refer to the resources in their new // location. setTargetResources(resourcesAtDestination .toArray(new IResource[resourcesAtDestination.size()]));
<|startcomment|> Should be TABs. <|endcomment|>  // copy only linked resource children (267173) if (source.isLinked() && source.getLocation().equals(existing.getLocation())) children = filterNonLinkedResources(children); ResourceDescription[] overwritten = copy(children, destinationPath, resourcesAtDestination, iterationProgress, uiInfo, false, createVirtual, createLinks, relativeToVariable); <|startfocus|> // We don't record the copy since this recursive call will // do so. Just record the overwrites. overwrittenResources.addAll(Arrays.asList(overwritten)); <|endfocus|> } else { // delete the destination folder, copying a linked folder // over an unlinked one or vice versa. Fixes bug 28772. ResourceDescription[] deleted = delete(new IResource[] { existing }, iterationProgress.split(1), uiInfo, false); iterationProgress.setWorkRemaining(100); if ((createLinks || createVirtual) && (source.isLinked() == false) && (source.isVirtual() == false)) { IFolder folder = workspaceRoot.getFolder(destinationPath); if (createVirtual) { folder.create(IResource.VIRTUAL, true, iterationProgress.split(1));
<|startcomment|> Should be TABs. <|endcomment|>  IResource[] children = ((IContainer) resource).members(); // move only linked resource children (267173) if (resource.isLinked() && resource.getLocation().equals(existing.getLocation())) children = filterNonLinkedResources(children); ResourceDescription[] overwritten = move(children, destinationPath, resourcesAtDestination, reverseDestinations, iterationProgress.split(90), uiInfo, false); <|startfocus|> // We don't record the moved resources since the recursive // call has done so. Just record the overwrites. overwrittenResources.addAll(Arrays.asList(overwritten)); <|endfocus|> // Delete the source. No need to record it since it // will get moved back. delete(resource, iterationProgress.split(10), uiInfo, false, false); } else { // delete the destination folder, moving a linked folder // over an unlinked one or vice versa. Fixes bug 28772. ResourceDescription[] deleted = delete(new IResource[] { existing }, iterationProgress.split(10), uiInfo, false); // Record the original path reverseDestinations.add(resource.getFullPath());
<|startcomment|> Should be TABs. <|endcomment|>  if (mapping == null) continue; ResourceTraversal[] traversals = null; try { traversals = mapping.getTraversals( ResourceMappingContext.LOCAL_CONTEXT, new NullProgressMonitor()); } catch (CoreException e) { StatusManager.getManager().handle(e, IDEWorkbenchPlugin.IDE_WORKBENCH); } if (traversals != null) { IResource[] resources = null; for (ResourceTraversal traversal : traversals) { resources = traversal.getResources(); if (resources != null) { <|startfocus|> result.addAll(Arrays.asList(resources)); <|endfocus|> } } } } else result.add(resource); } // all that can be converted are done, answer new selection if (result.isEmpty()) { return StructuredSelection.EMPTY; } return new StructuredSelection(result.toArray());
<|startcomment|> Should be TABs. <|endcomment|>  Map<MarkerQueryResult, Collection<IConfigurationElement>> resultsTable = entry.getValue(); if (resultsTable.containsKey(result)) { Iterator<IConfigurationElement> elements = resultsTable.get(result).iterator(); while (elements.hasNext()) { IConfigurationElement element = elements.next(); IMarkerResolutionGenerator generator = null; try { generator = (IMarkerResolutionGenerator) element.createExecutableExtension(ATT_CLASS); IMarkerResolution[] res = generator.getResolutions(marker); if (res != null) { <|startfocus|> resolutions.addAll(Arrays.asList(res)); <|endfocus|> } else { StatusManager.getManager() .handle(new Status(IStatus.ERROR, IDEWorkbenchPlugin.IDE_WORKBENCH, IStatus.ERROR, "Failure in " + generator.getClass().getName() + //$NON-NLS-1$ " from plugin " + element.getContributor().getName() + //$NON-NLS-1$ ": getResolutions(IMarker) must not return null", //$NON-NLS-1$ null), StatusManager.LOG); } } catch (CoreException e) { Policy.handle(e); } } } } }
<|startcomment|> Should be TABs. <|endcomment|>  IPath location = resources[i].getLocation(); // location may be null. See bug 29491. if (location != null) { fileNames[actualLength++] = location.toOSString(); } } if (actualLength > 0) { // was one or more of the locations null? if (actualLength < length) { String[] tempFileNames = fileNames; fileNames = new String[actualLength]; <|startfocus|> System.arraycopy(tempFileNames, 0, fileNames, 0, actualLength); <|endfocus|> } anEvent.data = fileNames; if (Policy.DEBUG_DND) System.out .println("ResourceDragAdapterAssistant.dragSetData set FileTransfer"); //$NON-NLS-1$ return true; } } } return false; 
<|startcomment|> Should be TABs. <|endcomment|>  private INavigatorContentDescriptor contributor; private INavigatorContentDescriptor firstClassContributor; private NavigatorContentService contentService; /** * Construct a tracking set. * * @param aContentService */ public ContributorTrackingSet(NavigatorContentService aContentService) { contentService = aContentService; } /** * Construct a tracking set. * * @param aContentService * @param elements */ public ContributorTrackingSet(NavigatorContentService aContentService, Object[] elements) { <|startfocus|> super.addAll(Arrays.asList(elements)); <|endfocus|> contentService = aContentService; } @Override public boolean add(Object o) { if (contributor != null) { contentService.rememberContribution(contributor, firstClassContributor, o); } return super.add(o); } @Override public boolean remove(Object o) { contentService.forgetContribution(o); return super.remove(o); } @Override public void clear() { Iterator it = iterator(); while (it.hasNext()) contentService.forgetContribution(it.next()); super.clear(); } /** *
<|startcomment|> Should be TABs. <|endcomment|>  updateFilterActivation = true; } // We don't turn of non-UI visible filters here, they have to be manipulated explicitly if (!visibleFilterDescriptors[i].isVisibleInUi()) { if (nonUiVisible == null) nonUiVisible = new ArrayList<String>(); nonUiVisible.add(visibleFilterDescriptors[i].getId()); } } /* If so, update */ if (updateFilterActivation) { if (nonUiVisible != null) { <|startfocus|> nonUiVisible.addAll(Arrays.asList(filterIdsToActivate)); <|endfocus|> filterIdsToActivate = nonUiVisible.toArray(new String[]{}); } setActiveFilterIds(filterIdsToActivate); persistFilterActivationState(); updateViewer(); // the action providers may no longer be enabled, so we // reset the selection. StructuredViewer commonViewer = (StructuredViewer) contentService.getViewer(); commonViewer.setSelection(StructuredSelection.EMPTY); }
<|startcomment|> Should be TABs. <|endcomment|>  new WizardPatternFilter(), true); viewer = filteredTree.getViewer(); filteredTree.setFont(parent.getFont()); filteredTree.setQuickSelectionMode(true); viewer.setContentProvider(new WizardContentProvider()); viewer.setLabelProvider(new WorkbenchLabelProvider()); viewer.setComparator(DataTransferWizardCollectionComparator.INSTANCE); ArrayList inputArray = new ArrayList(); boolean expandTop = false; if (wizardCategories != null) { if (wizardCategories.getParent() == null) { <|startfocus|> inputArray.addAll(Arrays.asList(wizardCategories.getCategories())); <|endfocus|> } else { expandTop = true; inputArray.add(wizardCategories); } } // ensure the category is expanded. If there is a remembered expansion it will // be set later. if (expandTop) { viewer.setAutoExpandLevel(2); } AdaptableList input = new AdaptableList(inputArray); // filter wizard list according to capabilities that are enabled viewer.addFilter(new WizardActivityFilter()); viewer.setInput(input);
<|startcomment|> Should be TABs. <|endcomment|>  filterTree.setQuickSelectionMode(true); final TreeViewer treeViewer = filterTree.getViewer(); treeViewer.setContentProvider(new WizardContentProvider()); treeViewer.setLabelProvider(new WorkbenchLabelProvider()); treeViewer.setComparator(NewWizardCollectionComparator.INSTANCE); treeViewer.addSelectionChangedListener(this); ArrayList inputArray = new ArrayList(); inputArray.addAll(Arrays.asList(primaryWizards)); boolean expandTop = false; if (wizardCategories != null) { if (wizardCategories.getParent() == null) { <|startfocus|> inputArray.addAll(Arrays.asList(wizardCategories.getCategories())); <|endfocus|> } else { expandTop = true; inputArray.add(wizardCategories); } } // ensure the category is expanded. If there is a remembered expansion it will // be set later. if (expandTop) { treeViewer.setAutoExpandLevel(2); } AdaptableList input = new AdaptableList(inputArray); treeViewer.setInput(input); filterTree.setBackground(parent.getDisplay().getSystemColor(SWT.COLOR_WIDGET_BACKGROUND)); treeViewer.getTree().setFont(parent.getFont()); treeViewer.addDoubleClickListener(event -> {
<|startcomment|> Should be TABs. <|endcomment|>  queuedEvents.add(prefId); return; } if (listeners != null) { listeners.firePropertyChange(prefId); } } @Override public final void addListener(String[] eventsOfInterest, IPropertyMapListener listener) { if (listeners == null) { listeners = new PropertyListenerList(); attachListener(); } listeners.add(eventsOfInterest, listener); } protected final void firePropertyChange(String[] prefIds) { if (ignoreCount > 0) { <|startfocus|> queuedEvents.addAll(Arrays.asList(prefIds)); <|endfocus|> return; } if (listeners != null) { listeners.firePropertyChange(prefIds); } } public final void startTransaction() { ignoreCount++; } public final void endTransaction() { ignoreCount--; if (ignoreCount == 0 && !queuedEvents.isEmpty()) { if (listeners != null) { listeners.firePropertyChange((String[]) queuedEvents.toArray(new String[queuedEvents.size()])); } queuedEvents.clear(); } } @Override public boolean equals(Object toCompare) {
<|startcomment|> Should be TABs. <|endcomment|>  package org.eclipse.e4.ui.tests.workbench; import java.util.ArrayList; import java.util.Arrays; /** * Class used to capture the SWT structure expected when rendering a partuclar * UI model. */ public class SWTResult { public Class clazz; public String text; public ArrayList kids = new ArrayList(); public SWTResult(Class theClass, String theText, SWTResult[] children) { clazz = theClass; text = theText; if (children != null) { <|startfocus|> kids.addAll(Arrays.asList(children)); <|endfocus|> } } } 
<|startcomment|> Should be TABs. <|endcomment|>  public void setSize(int size) { currentElements = new TestElement[size]; <|startfocus|> System.arraycopy(allElements, 0, currentElements, 0, currentElements.length); <|endfocus|> 
<|startcomment|> Should be TABs. <|endcomment|>  public void addMember(String person){ TeamMember newMember = new TeamMember(person, this); TeamMember[] newMembers = new TeamMember[members.length + 1]; <|startfocus|> System.arraycopy(members, 0, newMembers, 0, members.length); <|endfocus|> newMembers[newMembers.length - 1] = newMember; members = null; members = newMembers; newMembers = null; fireModelChanged(new ComparatorModelChange(TestModelChange.INSERT, this, newMember));
<|startcomment|> Variable and member should have the same name as the setter (connectionPool instead of smtpConnectionPool) <|endcomment|> <|startfocus|> protected LeasedSmtpConnection withConnectionPool(SmtpConnectionPool smtpConnectionPool) { m_smtpConnectionPool = smtpConnectionPool; <|endfocus|> return this;
<|startcomment|> Please add getters for m_connectionPool and m_closed <|endcomment|>  protected Transport getTransport() { return m_transport; <|startfocus|> <|endfocus|>
<|startcomment|> I propose making all variables protected. Otherwise, it is very hard for sublasses to access them (e.g. when you need a small fix in your project and want to @Replace this bean). Alternatively, protected getters/setters could be added, but I think protected members are easier (while still being consistent with the Scout code style). <|endcomment|>  * which causes them to return to step 1 and recheck for idle connections or space left in the pool.<br> * As soon as a connection is created, a background job is started which monitors idle connections. If they reach the * max idle time ({@link SmtpPoolMaxIdleTimeProperty}) or max connection lifetime, they are closed and removed from the * pool. */ @ApplicationScoped public class SmtpConnectionPool { private static final Logger LOG = LoggerFactory.getLogger(SmtpConnectionPool.class); <|startfocus|> private static final String JOB_NAME_CLOSE_IDLE_CONNECTIONS = "smtp-close-idle-connections"; <|endfocus|> private final Object m_poolLock = new Object(); private final Set<SmtpConnectionPoolEntry> m_idleEntries = new HashSet<>(); private final Set<SmtpConnectionPoolEntry> m_leasedEntries = new HashSet<>(); private final String m_jobExecutionHint = "smtp-connection-pool." + UUID.randomUUID().toString(); private long m_lastPoolEntryNo = 0; private long m_maxIdleTime; private long m_maxConnectionLifetime; private boolean m_destroyed; /**
<|startcomment|> Split into multiple lines for better readbility? <|endcomment|>  protected void destroy() { if (m_destroyed) { return; } synchronized (m_poolLock) { if (m_destroyed) { return; } Jobs.getJobManager().cancel(Jobs.newFutureFilterBuilder() .andMatchExecutionHint(m_jobExecutionHint) .toFilter(), true); <|startfocus|> Stream.of(m_idleEntries, m_leasedEntries).flatMap(Collection::stream).forEach(this::safeCloseTransport); <|endfocus|> m_idleEntries.clear(); m_leasedEntries.clear(); m_destroyed = true; }
<|startcomment|> Please describe what those longs are (seconds, milliseconds, nanoseconds?) <|endcomment|> kage org.eclipse.scout.rt.mail.smtp; import javax.mail.Session; import javax.mail.Transport; import org.eclipse.scout.rt.platform.Bean; @Bean public class SmtpConnectionPoolEntry { private String m_name; private SmtpServerConfig m_smtpServerConfig; private Session m_session; <|startfocus|> private Transport m_transport; <|endfocus|> private long m_createTime; private long m_idleSince; public SmtpConnectionPoolEntry withName(String name) { m_name = name; return this; } public SmtpConnectionPoolEntry withSmtpServerConfig(SmtpServerConfig smtpServerConfig) { m_smtpServerConfig = smtpServerConfig; return this; } public SmtpConnectionPoolEntry withSession(Session session) { m_session = session; return this; } public SmtpConnectionPoolEntry withTransport(Transport transport) { m_transport = transport; return this; } public SmtpConnectionPoolEntry withCreateTime(long createTime) { m_createTime = createTime; return this; } public SmtpConnectionPoolEntry withIdleSince(long idleSince) { m_idleSince = idleSince; return this; } public Session getSession() {
<|startcomment|> Getter should also have a JavaDoc <|endcomment|>  } public Map<String, String> getAdditionalSessionProperties() { return m_additionalSessionProperties; } /** * These properties are added after the other properties, thus can override predefined properties such as host, port * or user. * * @param additionalSessionProperties * Additional properties used to create {@link Session} for SMTP server connection. */ public SmtpServerConfig withAdditionalSessionProperties(Map<String, String> additionalSessionProperties) { m_additionalSessionProperties = additionalSessionProperties; return this; } <|startfocus|> <|endfocus|> public int getPoolSize() { return m_poolSize; } /** * @param poolSize * Specifies the size of the connection pool to use with this {@link SmtpServerConfig#}. If 0, smtp * connection pooling is disabled. */ public SmtpServerConfig withPoolSize(int poolSize) { m_poolSize = poolSize; return this; } @Override public int hashCode() { final int prime = 31; int result = 1;
<|startcomment|> Don't need to calculate xEnd <|endcomment|>  ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = -1; while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); <|startfocus|> int xEnd = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() + event.getDuration() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width || xEnd < rect.x) { <|endfocus|> // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } for (int i = 0; i < nbSeries; i++) { seriesModel.add(new ArrayList<>()); } for (int i = 0; i < nbSeries; i++) { long val = values.get(i);
<|startcomment|> IndexOutOfBounds exception if subsequent event has less values than the first? <|endcomment|>  // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } for (int i = 0; i < nbSeries; i++) { seriesModel.add(new ArrayList<>()); } for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); <|startfocus|> min = Math.min(Math.abs(val), min); <|endfocus|> seriesModel.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; } for (TimeLineEvent ref : refs) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(ref); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
<|startcomment|> If min is useless, just use 0 as min? <|endcomment|>  } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); } for (int i = 0; i < nbSeries; i++) { seriesModel.add(new ArrayList<>()); } for (int i = 0; i < nbSeries; i++) { long val = values.get(i); max = Math.max(Math.abs(val), max); <|startfocus|> min = Math.min(Math.abs(val), min); <|endfocus|> seriesModel.get(i).add(new LongPoint(x, val)); refs.add(timeEvent); } } if (refs.isEmpty()) { return; } for (TimeLineEvent ref : refs) { Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(ref); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); }
<|startcomment|> This should be your name or Bachmann whoever has the copyright. See https://wiki.eclipse.org/Platform_UI/How_to_Contribute#Coding_Conventions <|endcomment|> ***************************************************************************** <|startfocus|> * Copyright (c) 2019 IBM Corporation and others. <|endfocus|> * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * IBM Corporation - initial API and implementation ******************************************************************************/ package org.eclipse.e4.ui.tests.workbench; import org.eclipse.e4.core.contexts.IEclipseContext; import org.eclipse.e4.ui.internal.workbench.E4Workbench; import org.eclipse.e4.ui.internal.workbench.swt.E4Application; import org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine; import org.eclipse.e4.ui.model.application.MApplication; import org.eclipse.e4.ui.model.application.ui.advanced.MArea; import org.eclipse.e4.ui.model.application.ui.basic.MCompositePart; import org.eclipse.e4.ui.model.application.ui.basic.MPart; import org.eclipse.e4.ui.model.application.ui.basic.MPartStack; import org.eclipse.e4.ui.model.application.ui.basic.MWindow;
<|startcomment|> Your Company or your name <|endcomment|> ***************************************************************************** * Copyright (c) 2019 IBM Corporation and others. * * This program and the accompanying materials * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: <|startfocus|> * IBM Corporation - initial API and implementation <|endfocus|> ******************************************************************************/ package org.eclipse.e4.ui.tests.workbench; import org.eclipse.e4.core.contexts.IEclipseContext; import org.eclipse.e4.ui.internal.workbench.E4Workbench; import org.eclipse.e4.ui.internal.workbench.swt.E4Application; import org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine; import org.eclipse.e4.ui.model.application.MApplication; import org.eclipse.e4.ui.model.application.ui.advanced.MArea; import org.eclipse.e4.ui.model.application.ui.basic.MCompositePart; import org.eclipse.e4.ui.model.application.ui.basic.MPart; import org.eclipse.e4.ui.model.application.ui.basic.MPartStack; import org.eclipse.e4.ui.model.application.ui.basic.MWindow;
<|startcomment|> Two PartStacks <|endcomment|>  public void testMultipleStacksUnderTheAreaCreateACTabFolder() { MWindow window = ems.createModelElement(MWindow.class); MArea area = ems.createModelElement(MArea.class); <|startfocus|> // Create two sash containers with MParts inside <|endfocus|> MPartStack stack1 = ems.createModelElement(MPartStack.class); stack1.getChildren().add(ems.createModelElement(MPart.class)); stack1.getChildren().add(ems.createModelElement(MPart.class)); MPartStack stack2 = ems.createModelElement(MPartStack.class); stack2.getChildren().add(ems.createModelElement(MPart.class)); stack2.getChildren().add(ems.createModelElement(MPart.class)); // Place the containers in the area area.getChildren().add(stack1); area.getChildren().add(stack2); // Add area to the window window.getChildren().add(area); MApplication application = ems.createModelElement(MApplication.class); application.getChildren().add(window); application.setContext(appContext); appContext.set(MApplication.class, application); wb = new E4Workbench(application, appContext); wb.createAndRunUI(window); // Make sure the widget is now a CTabFolder
<|startcomment|> a CompositePart, and remove white-line <|endcomment|>  public void testStackInsideMCompositePartDoesNotCreateACTabFolder() { MWindow window = ems.createModelElement(MWindow.class); MArea area = ems.createModelElement(MArea.class); <|startfocus|> // Create a sash container with MParts inside <|endfocus|> MCompositePart composite = ems.createModelElement(MCompositePart.class); MPartStack stack1 = ems.createModelElement(MPartStack.class); stack1.getChildren().add(ems.createModelElement(MPart.class)); stack1.getChildren().add(ems.createModelElement(MPart.class)); MPartStack stack2 = ems.createModelElement(MPartStack.class); stack2.getChildren().add(ems.createModelElement(MPart.class)); stack2.getChildren().add(ems.createModelElement(MPart.class)); composite.getChildren().add(stack1); composite.getChildren().add(stack2); // Place the container in the area area.getChildren().add(composite); // Add area to the window window.getChildren().add(area); MApplication application = ems.createModelElement(MApplication.class); application.getChildren().add(window); application.setContext(appContext); appContext.set(MApplication.class, application); wb = new E4Workbench(application, appContext);
<|startcomment|> is not <|endcomment|>  composite.getChildren().add(stack1); composite.getChildren().add(stack2); // Place the container in the area area.getChildren().add(composite); // Add area to the window window.getChildren().add(area); MApplication application = ems.createModelElement(MApplication.class); application.getChildren().add(window); application.setContext(appContext); appContext.set(MApplication.class, application); wb = new E4Workbench(application, appContext); wb.createAndRunUI(window); <|startfocus|> // Make sure the widget is now a CTabFolder <|endfocus|> Assert.assertFalse(area.getWidget() instanceof CTabFolder);
<|startcomment|> It makes sense to use assertEquals here and below, to see the actual value in the failing case <|endcomment|>  public void testDynamicItem_AddOne() { contextRule.createAndRunWorkbench(window); ToolBarManager tbm = getManager(toolBar); <|startfocus|> assertTrue(tbm.getSize() == 0); <|endfocus|> MToolItem toolItem1 = ems.createModelElement(MDirectToolItem.class); toolBar.getChildren().add(toolItem1); assertTrue(tbm.getSize() == 1);
<|startcomment|> a last wish: restore the old comment. It gives at least a hint why it's just 5 <|endcomment|> <|startfocus|> protected int getThreshold() { <|endfocus|> return 5;
<|startcomment|> Is this necessary? It causes the tree to collapse. <|endcomment|>  public void refresh() { <|startfocus|> fCategoryViewer.setInput(fModel); <|endfocus|> super.refresh();
<|startcomment|> It's a bit strange to call this class "virtual method call" since it also checks for "throw" in destructors. I'm not sure what to call it though... UnsafeOperationInCtorDtorChecker? Urg... I guess it would also be inconvenient to split it in two checkers? Because of code duplication? <|endcomment|> import org.eclipse.cdt.core.dom.ast.cpp.ICPPConstructor; import org.eclipse.cdt.core.dom.ast.cpp.ICPPMethod; import org.eclipse.cdt.core.dom.ast.cpp.SemanticQueries; import org.eclipse.cdt.internal.core.dom.parser.ASTQueries; import org.eclipse.cdt.internal.core.dom.parser.cpp.ClassTypeHelper; import org.eclipse.cdt.internal.core.dom.parser.cpp.ICPPDeferredClassInstance; @SuppressWarnings("restriction") public class VirtualMethodCallChecker extends AbstractIndexAstChecker { public static final String VIRTUAL_CALL_ID = "org.eclipse.cdt.codan.internal.checkers.VirtualMethodCallProblem"; //$NON-NLS-1$ <|startfocus|> public static final String THROW_ID = "org.eclipse.cdt.codan.internal.checkers.ThrowInDestructorProblem"; //$NON-NLS-1$ <|endfocus|> @Override public void processAst(IASTTranslationUnit ast) { ast.accept(new OnEachClass()); } private enum DECL_TYPE { CTOR, DTOR } class OnEachClass extends ASTVisitor { // NOTE: Classes can be nested and even can be declared in constructors of the other classes private final Stack<DECL_TYPE> ctorDtorStack = new Stack<>(); OnEachClass() { shouldVisitDeclarations = true;
<|startcomment|> You should probably return here, or change the if to file.exists() and return the file read. <|endcomment|>  private static SyscallLookup create() { try { IPath path = Activator.getDefault().getAbsolutePath(new Path(SYSCALL_TSV_PATH)); if (path != null) { File file = path.toFile(); if (!file.exists()) { <|startfocus|> Activator.getDefault().logError("Syscall names not available!"); //$NON-NLS-1$ <|endfocus|> } return new SyscallLookup(FileUtils.readLines(file, "UTF-8")); //$NON-NLS-1$ } } catch (IOException e) { Activator.getDefault().logError("Failed to read file", e); //$NON-NLS-1$ } return new SyscallLookup(Collections.emptyList());
<|startcomment|> remove new spaces <|endcomment|>  * the provider is an instance of {@link IAnalysisModule}, analysis is also * scheduled. * <p> * If the trace has multiple analysis modules with the same secondary ID, * <code>null</code> is returned so the caller can try to make a * {@link TmfTreeXYCompositeDataProvider} for all the traces instead * * @param trace <|startfocus|> * A trace on which we are interested to fetch a model <|endfocus|> * @param secondaryId * The ID of the analysis to use for this provider * @return An instance of SegmentStoreDataProvider. Returns a null if the * ISegmentStoreProvider is null. * @since 4.0 */ public static @Nullable ITmfTreeDataProvider<? extends ITmfTreeDataModel> create(ITmfTrace trace, String secondaryId) { // The trace can be an experiment, so we need to know if there are multiple // analysis modules with the same ID Iterable<ISegmentStoreProvider> modules = TmfTraceUtils.getAnalysisModulesOfClass(trace, ISegmentStoreProvider.class);
<|startcomment|> This can be null according to the new API, see https://git.eclipse.org/r/#/c/141316/4/org.eclipse.jdt.core/dom/org/eclipse/jdt/core/dom/IMethodBinding.java. Personally I would prefer that the new API would return empty array, but if not, we will have few NPE's below. <|endcomment|>  public boolean visit(LambdaExpression lambdaExpression) { IMethodBinding binding = lambdaExpression.resolveMethodBinding(); <|startfocus|> IVariableBinding[] synVars = binding.getSyntheticOuterLocals(); <|endfocus|> List<Field> allFields = underlyingThisObject.referenceType().fields(); ListIterator<Field> listIterator = allFields.listIterator(); int i = 0; if (getUnderlyingMethod().isStatic()) { if (synVars.length == allFields.size()) { while (listIterator.hasNext()) { FieldImpl field = (FieldImpl) listIterator.next(); String newName = synVars[i].getName(); FieldImpl newField = new FieldImpl((VirtualMachineImpl) field.virtualMachine(), (ReferenceTypeImpl) field.declaringType(), field.getFieldID(), newName, field.signature(), field.genericSignature(), field.modifiers()); listIterator.set(newField); } } } else { if (synVars.length + 1 == allFields.size()) { while (listIterator.hasNext()) { FieldImpl field = (FieldImpl) listIterator.next(); String newName = field.name();
<|startcomment|> Why take a snapshot before the move, not after? <|endcomment|>  int auto = repo.getConfig().getInt(ConfigConstants.CONFIG_GC_SECTION, ConfigConstants.CONFIG_KEY_AUTO, DEFAULT_AUTOLIMIT); if (auto <= 0) { return false; } int n = 0; int threshold = (auto + 255) / 256; Path dir = repo.getObjectsDirectory().toPath().resolve("17"); //$NON-NLS-1$ if (!Files.exists(dir)) { return false; } try (DirectoryStream<Path> stream = Files.newDirectoryStream(dir, new DirectoryStream.Filter<Path>() { <|startfocus|> <|endfocus|> public boolean accept(Path file) throws IOException { return Files.isRegularFile(file) && PATTERN_LOOSE_OBJECT .matcher(file.getFileName().toString()) .matches(); } })) { Iterator<Path> iter = stream.iterator(); while (iter.hasNext()) { if (n++ > threshold) { return true; } } } catch (IOException e) { LOG.error(e.getMessage(), e); } return false;
<|startcomment|> tab <|endcomment|>  public void setAllChecked(boolean state) { for (TreeItem item: super.getTree().getItems()) item.setChecked(state); if (state) { // Find all visible children, add only the visible leaf nodes to the check state cache Object[] visible = getFilteredChildren(getRoot()); ITreeContentProvider contentProvider = null; if (getContentProvider() instanceof ITreeContentProvider) { contentProvider = (ITreeContentProvider) getContentProvider(); } if (contentProvider == null) { <|startfocus|> checkState.addAll(Arrays.asList(visible)); <|endfocus|> } else { Set<Object> toCheck = new HashSet<>(); for (Object element : visible) { addFilteredChildren(element, contentProvider, toCheck); } checkState.addAll(toCheck); } } else { // Remove any item in the check state that is visible (passes the filters) if (checkState != null) { Object[] visible = filter(checkState.toArray()); for (Object element : visible) { checkState.remove(element); } } } } /**
<|startcomment|> tab <|endcomment|>  * return the token. * * @return the {@link IToken}, or {@code null} if none. */ protected IToken scanToken() { return null; } private @NonNull Set<IHyperlinkDetector> getHyperlinkDetectors() { Set<IHyperlinkDetector> allDetectors = new LinkedHashSet<>(); IHyperlinkDetector[] configuredDetectors = configuration .getHyperlinkDetectors(viewer); if (configuredDetectors != null && configuredDetectors.length > 0) { <|startfocus|> allDetectors.addAll(Arrays.asList(configuredDetectors)); <|endfocus|> if (preferenceStore.getBoolean(URL_HYPERLINK_DETECTOR_KEY) || !preferenceStore.getBoolean( AbstractTextEditor.PREFERENCE_HYPERLINKS_ENABLED)) { return allDetectors; } // URLHyperlinkDetector can only detect hyperlinks at the start of // the range. We need one that can detect all hyperlinks in a given // region. allDetectors.add(new MultiURLHyperlinkDetector()); } return allDetectors; } /** * A {@link URLHyperlinkDetector} that returns all hyperlinks in a region. * <p> * This internal class assumes that the region is either empty or else spans
<|startcomment|> Do we know it will be an IntegralValue? (Could we get here if it's dependent, in which case it could be a DependentValue?) <|endcomment|>  public static boolean evaluateNoexceptSpecifier(ICPPEvaluation noexceptSpecifier) { <|startfocus|> if (noexceptSpecifier != null) { <|endfocus|> IntegralValue v = (IntegralValue) noexceptSpecifier.getValue(); if (v.numberValue() != null) return v.numberValue().longValue() == 1; } return false;
<|startcomment|> Usage count should also be checked. SMTP servers may limit the number of messages sent in a single connection. <|endcomment|>  candidate = entry; it.remove(); break; } } if (candidate != null && !candidate.getTransport().isConnected()) { LOG.debug("Releasing pooled SMTP connection {}; transport is already closed, not returning to idle pool.", candidate); candidate = null; } if (candidate != null) { IDateProvider dateProvider = BEANS.get(IDateProvider.class); <|startfocus|> if (dateProvider.currentMillis().getTime() - candidate.getCreateTime() < m_maxConnectionLifetime) { <|endfocus|> LOG.debug("Releasing pooled SMTP connection {}; returning to idle pool.", candidate); candidate.withIdleSince(dateProvider.currentMillis().getTime()); m_idleEntries.add(candidate); } else { LOG.debug("Releasing pooled SMTP connection {}; pooled connection reached max lifetime of {}s, not returning to idle pool.", candidate, m_maxConnectionLifetime / 1000d); } } m_poolLock.notifyAll(); }
<|startcomment|> A more meaningful comment would be: @return the size of the connection pool to use with this {@link SmtpServerConfig}. If 0, smtp connection pooling is disabled. (similar to setter) <|endcomment|>  } /** * These properties are added after the other properties, thus can override predefined properties such as host, port * or user. * * @param additionalSessionProperties * Additional properties used to create {@link Session} for SMTP server connection. */ public SmtpServerConfig withAdditionalSessionProperties(Map<String, String> additionalSessionProperties) { m_additionalSessionProperties = additionalSessionProperties; return this; } /** <|startfocus|> * @return Returns the poolSize specified for this {@link SmtpServerConfig} object. <|endfocus|> */ public int getPoolSize() { return m_poolSize; } /** * @param poolSize * Specifies the size of the connection pool to use with this {@link SmtpServerConfig#}. If 0, smtp * connection pooling is disabled. */ public SmtpServerConfig withPoolSize(int poolSize) { m_poolSize = poolSize; return this; } @Override public int hashCode() { final int prime = 31; int result = 1;
<|startcomment|> Add a space after core <|endcomment|>  int cpusNode = cpuSs.getQuarkAbsolute(Attributes.CPUS); final @NonNull List<@NonNull Integer> subAttributes = cpuSs.getSubAttributes(cpusNode, false); int cpus = Integer.MIN_VALUE; for (Integer quark : subAttributes) { cpus = Math.max(Integer.parseInt(cpuSs.getAttributeName(quark)), cpus); } return Math.max(subAttributes.size(), cpus); } catch (AttributeNotFoundException e) { <|startfocus|> Activator.getDefault().logError("Error: getting number of core" + e.getMessage(), e); //$NON-NLS-1$ <|endfocus|> } } return -1; 
<|startcomment|> The space is still missing after core <|endcomment|>  if (cpuSs != null) { try { int cpusNode = cpuSs.getQuarkAbsolute(Attributes.CPUS); final @NonNull List<@NonNull Integer> subAttributes = cpuSs.getSubAttributes(cpusNode, false); int cpus = Integer.MIN_VALUE; for (Integer quark : subAttributes) { cpus = Math.max(Integer.parseInt(cpuSs.getAttributeName(quark)), cpus); } return Math.max(subAttributes.size(), cpus); } catch (AttributeNotFoundException e) { <|startfocus|> Activator.getDefault().logError(e.getMessage(), e); <|endfocus|> } } return -1; 
<|startcomment|> Not a huge fan of flow handling via exceptions but I don't see good alternatives here. Add an exception message in case this approach backfires at some point (e.g. due to some future changes)? <|endcomment|>  if (url == null) { return false; } if (WORKSPACE_CHECK_REFERENCE_BUNDLE_VERSION == null) { // no reference bundle installed, no check possible return true; } Version version = readWorkspaceVersion(url); // if the version could not be read, then there is not any existing // workspace data to trample, e.g., perhaps its a new directory that // is just starting to be used as a workspace if (version == null) { return true; } <|startfocus|> final Version ide_version = toMajorMinorVersion(WORKSPACE_CHECK_REFERENCE_BUNDLE_VERSION); Version workspace_version = toMajorMinorVersion(version); int versionCompareResult = workspace_version.compareTo(ide_version); <|endfocus|> // equality test is required since any version difference (newer // or older) may result in data being trampled if (versionCompareResult == 0) { return true; } // At this point workspace has been detected to be from a version // other than the current ide version -- find out if the user wants // to use it anyhow.
<|startcomment|> This one could be null if the image is absent, so here, the return value should be @Nullable, ie the method signature is public @Nullable ImageDescriptor getImageDescripterFromPath(String path) Then, where this method is called, if you are sure the image exists, that's where you put the Objects.requireNonNull <|endcomment|> <|startfocus|> public ImageDescriptor getImageDescripterFromPath(String path) { return Objects.requireNonNull(AbstractUIPlugin.imageDescriptorFromPlugin(PLUGIN_ID, path)); <|endfocus|>
<|startcomment|> Remove String.valueOf call <|endcomment|>  } else if (columnIndex == 1) { try { return attribute.getDisplayableString(); } catch (OseeCoreException ex) { return Lib.exceptionToString(ex); } } else if (columnIndex == 2) { try { return String.valueOf(attribute.getId()); } catch (OseeCoreException ex) { return Lib.exceptionToString(ex); } } else if (columnIndex == 3) { try { <|startfocus|> return String.valueOf(attribute.getAttributeType().getIdString()); <|endfocus|> } catch (OseeCoreException ex) { return Lib.exceptionToString(ex); } } else { return String.valueOf(attribute.getGammaId()); }
<|startcomment|> Shouldn't we check for null here? <|endcomment|>  super.applyId(value); onUrlDependencyChanged(value); } @Override protected void applyVersion(String value) throws CoreException { super.applyVersion(value); onUrlDependencyChanged(value); } private void onUrlDependencyChanged(String dependencyValue) throws CoreException { boolean includeUrl = (dependencyValue != null) && fIncludeUrlCheckbox.getSelection(); applyUrl(includeUrl); updateUrlEnablement(); } private void applyUrl(boolean include) throws CoreException { <|startfocus|> String value = include ? recomputeUrl() : null; getCurrentItem().setURL(value); <|endfocus|> } private String recomputeUrl() { ISiteFeature feature = getCurrentItem(); if (feature == null) { return null; } StringBuilder sb = new StringBuilder(); sb.append("features/").append(feature.getId()).append("_"); //$NON-NLS-1$ //$NON-NLS-2$ try { sb.append(new Version(feature.getVersion())); } catch (Exception e) { sb.append("0.0.0"); //$NON-NLS-1$ } sb.append(".jar"); //$NON-NLS-1$
<|startcomment|> missing white space :( <|endcomment|>  public static SyscallLookup getInstance() { <|startfocus|> SyscallLookup instance = INSTANCE; <|endfocus|> if(instance == null) { instance = create(); INSTANCE = instance; } return instance;
<|startcomment|> If you're going to push another patch, maybe just logWarning, not really an error, right? <|endcomment|>  private static SyscallLookup create() { try { IPath path = Activator.getDefault().getAbsolutePath(new Path(SYSCALL_TSV_PATH)); if (path != null) { File file = path.toFile(); if (!file.exists()) { <|startfocus|> Activator.getDefault().logError("Syscall names not available!"); //$NON-NLS-1$ <|endfocus|> return new SyscallLookup(Collections.emptyList()); } return new SyscallLookup(FileUtils.readLines(file, "UTF-8")); //$NON-NLS-1$ } } catch (IOException e) { Activator.getDefault().logError("Failed to read file", e); //$NON-NLS-1$ } return new SyscallLookup(Collections.emptyList());
<|startcomment|> Please do not change any code under the felix/ source folder. We get this source from the Apache Felix project and it is much easier to maintain the source from that project and consume unchanged source into Equinox. <|endcomment|>  dependentSelector.getCurrentCandidate())) { // return false since we do not want to allow this requirement // to substitute the capability return false; } } } } } } return candidates.getRemainingCandidateCount() > 1 || Util.isOptional(req); } return false; } static class DynamicImportFailed extends ResolutionError { private final Requirement requirement; public DynamicImportFailed(Requirement requirement) { this.requirement = requirement; } <|startfocus|> @Override <|endfocus|> public String getMessage() { return "Dynamic import failed."; } @Override public Collection<Requirement> getUnresolvedRequirements() { return Collections.singleton(requirement); } @Override public ResolutionException toException() { return new ReasonException(ReasonException.Reason.DynamicImport, getMessage(), null, getUnresolvedRequirements()); } } static class FragmentNotSelectedError extends ResolutionError { private final Resource resource; public FragmentNotSelectedError(Resource resource) { this.resource = resource; } @Override public String getMessage() {
<|startcomment|> Unneeded change <|endcomment|>  if (type == null) { return value; } IJavaStackFrame stackFrame = getStackFrame(javaValue); if (stackFrame == null) { return value; } IJavaProject project = JavaDebugUtils.resolveJavaProject(stackFrame); if (project == null) { return value; } IAstEvaluationEngine evaluationEngine = JDIDebugPlugin.getDefault() .getEvaluationEngine(project, (IJavaDebugTarget) stackFrame.getDebugTarget()); EvaluationBlock evaluationBlock = new EvaluationBlock(javaValue, type, (IJavaThread) stackFrame.getThread(), evaluationEngine); <|startfocus|> <|endfocus|> if (fValue == null) { // evaluate each variable IJavaVariable[] variables = new IJavaVariable[fVariables.length]; for (int i = 0; i < fVariables.length; i++) { variables[i] = new JDIPlaceholderVariable(fVariables[i][0], evaluationBlock.evaluate(fVariables[i][1]), javaValue); } return new LogicalObjectStructureValue(javaValue, variables); } // evaluate the logical value IJavaValue logicalValue = evaluationBlock.evaluate(fValue); if (logicalValue instanceof JDIValue) {
<|startcomment|> Unneeded change <|endcomment|>  .getEvaluationEngine(project, (IJavaDebugTarget) stackFrame.getDebugTarget()); EvaluationBlock evaluationBlock = new EvaluationBlock(javaValue, type, (IJavaThread) stackFrame.getThread(), evaluationEngine); if (fValue == null) { // evaluate each variable IJavaVariable[] variables = new IJavaVariable[fVariables.length]; for (int i = 0; i < fVariables.length; i++) { <|startfocus|> variables[i] = new JDIPlaceholderVariable(fVariables[i][0], evaluationBlock.evaluate(fVariables[i][1]), javaValue); <|endfocus|> } return new LogicalObjectStructureValue(javaValue, variables); } // evaluate the logical value IJavaValue logicalValue = evaluationBlock.evaluate(fValue); if (logicalValue instanceof JDIValue) { ((JDIValue) logicalValue).setLogicalParent(javaValue); } return logicalValue; } catch (CoreException e) { if (e.getStatus().getCode() == IJavaThread.ERR_THREAD_NOT_SUSPENDED) { throw e; } JDIDebugPlugin.log(e); } return value; } /** * Returns the <code>IJavaReferenceType</code> from the specified
<|startcomment|> line 86, it's already a teamWf I'd just send the teamWf as a separate parameter and then use it in your method <|endcomment|>  private void createLink(String prefix, final Artifact art, String action, Artifact thisArt, RelationTypeSide relation) { try { <|startfocus|> Label label = editor.getToolkit().createLabel(this, prefix + " \"" + getTeamName( thisArt) + "\" " + action + getCompletedCancelledString(art) + " \"" + getTeamName(art) + "\" "); <|endfocus|> Hyperlink link = editor.getToolkit().createHyperlink(this, String.format("\"%s\" - %s", art.getName().length() < 60 ? art.getName() : art.getName().substring(0, 60), AtsClientService.get().getAtsId(art)), SWT.NONE); if (art.equals(thisArt)) { artAndRelToHyperlink.put(thisArt, relation, link); artAndRelToLabel.put(thisArt, relation, label); } else { artAndRelToHyperlink.put(art, relation, link); artAndRelToLabel.put(art, relation, label); } link.addHyperlinkListener(new IHyperlinkListener() { @Override public void linkEntered(HyperlinkEvent e) { // do nothing
<|startcomment|> redundant null check <|endcomment|>  IASTExpression fNameExp = fCall.getFunctionNameExpression(); IBinding fBinding = null; if (fNameExp instanceof IASTIdExpression) { IASTIdExpression fName = (IASTIdExpression) fNameExp; fBinding = fName.getName().resolveBinding(); } else if (fNameExp instanceof IASTFieldReference) { IASTFieldReference fName = (IASTFieldReference) fNameExp; if (referencesThis(fName.getFieldOwner())) fBinding = fName.getFieldName().resolveBinding(); } <|startfocus|> if (fBinding != null && fBinding instanceof ICPPMethod) { <|endfocus|> ICPPMethod method = (ICPPMethod) fBinding; if (method.isPureVirtual() || ClassTypeHelper.isVirtual(method)) { reportProblem(VIRTUAL_CALL_ID, expression); } } } } return PROCESS_CONTINUE;
<|startcomment|> Maybe it would be nice to only report the problem on the field name in the case of: this->func(); Right now, the whole thing is underlined in red but it could be only "func" instead. You would only need to use the result of getFieldName() above instead of 'expression'. Maybe a new local variable would do it: IASTNode problemNode = expression; ... if (/*idExpressionCase */) //No change if (/*fieldReferenceCase */) Â IASTName name = fName.getFieldName(); fBinding = name.resolveBinding(); problemNode = name; ... Â reportProblem(VIRTUAL_CALL_ID, problemNode; <|endcomment|>  fBinding = fName.getName().resolveBinding(); } else if (fNameExp instanceof IASTFieldReference) { IASTFieldReference fName = (IASTFieldReference) fNameExp; if (referencesThis(fName.getFieldOwner())) fBinding = fName.getFieldName().resolveBinding(); } if (fBinding != null && fBinding instanceof ICPPMethod) { ICPPMethod method = (ICPPMethod) fBinding; if (method.isPureVirtual() || ClassTypeHelper.isVirtual(method)) { <|startfocus|> reportProblem(VIRTUAL_CALL_ID, expression); <|endfocus|> } } } } return PROCESS_CONTINUE;
<|startcomment|> What is this condition for? <|endcomment|>  if (functionDefinition.isDefaulted() && SemanticQueries.isCopyOrMoveConstructor(constructor)) return null; if (constructor.getClassOwner().getKey() == ICompositeType.k_union) return null; // Skip delegating constructors. for (ICPPASTConstructorChainInitializer memberInitializer : functionDefinition .getMemberInitializers()) { IASTName memberName = memberInitializer.getMemberInitializerId(); if (memberName != null) { IBinding memberBinding = memberName.resolveBinding(); ICPPClassType classType = null; <|startfocus|> if (memberBinding instanceof ICPPClassType) { classType = (ICPPClassType) memberBinding; } else if (memberBinding instanceof ICPPConstructor) { <|endfocus|> classType = ((ICPPConstructor) memberBinding).getClassOwner(); } if (classType instanceof ICPPDeferredClassInstance) { classType = ((ICPPDeferredClassInstance) classType).getClassTemplate(); } if (classType != null && classType.isSameType(constructor.getClassOwner())) return null; } } return constructor; } } return null;
<|startcomment|> ArrayList is usually preferred to LinkedList for performance reason unless you really need the LinkedList, which you don't here. <|endcomment|>  * {@link org.eclipse.tracecompass.tmf.ui.viewers.events.TmfEventsTable#TmfEventsTable(org.eclipse.swt.widgets.Composite, int, java.util.Collection)} * * @author Alexandre Montplaisir * @noextend This class should not be extended directly. You should instead * implement an {@link ITmfEventAspect}. */ @NonNullByDefault public class TmfEventTableColumn { // ------------------------------------------------------------------------ // Fields // ------------------------------------------------------------------------ <|startfocus|> private final ITmfEventAspect<?> fAspect; private final List<ITmfEventAspect<?>> fAspectDuplicate = new LinkedList<>(); <|endfocus|> // ------------------------------------------------------------------------ // Constructors // ------------------------------------------------------------------------ /** * Constructor * * @param aspect * The {@link ITmfEventAspect} to be used to populate this * column. */ public TmfEventTableColumn(ITmfEventAspect<?> aspect) { fAspect = aspect; fAspectDuplicate.add(aspect); } // ------------------------------------------------------------------------ // adders // ------------------------------------------------------------------------ /** * Add another Aspect with the same name * * @param duplicate * the aspect with the same name * @since 5.0 */
<|startcomment|> Either you put all the aspects in the list (in which case, you may want to change the name of the field), or just the duplicates. <|endcomment|>  public TmfEventTableColumn(ITmfEventAspect<?> aspect) { <|startfocus|> fAspect = aspect; fAspectDuplicate.add(aspect); <|endfocus|>
<|startcomment|> if all aspects are in the list, just do for (ITmfEventAspect<?> aspect : fAspectDuplicate) { String eventString = aspect.resolve(event); ... } and return whenever string non-empty. <|endcomment|>  public String getItemString(ITmfEvent event) { final String EMPTY_STRING = ""; //$NON-NLS-1$ String s = NonNullUtils.nullToEmptyString(fAspect.resolve(event)); if (fAspectDuplicate.size() > 1 && s.equals(EMPTY_STRING)) { for (int i = 1; i < fAspectDuplicate.size(); i++) { String eventString = NonNullUtils.nullToEmptyString(fAspectDuplicate.get(i).resolve(event)); if (eventString != EMPTY_STRING) { s = eventString; } } } <|startfocus|> return s; <|endfocus|>
<|startcomment|> This should be a private static final String field of the class. Please put it on top of the class, before the fAspect field declaration. <|endcomment|>  public String getItemString(ITmfEvent event) { <|startfocus|> final String EMPTY_STRING = ""; //$NON-NLS-1$ <|endfocus|> for (ITmfEventAspect<?> aspect : fAspects) { String eventString = NonNullUtils.nullToEmptyString(aspect.resolve(event)); if(eventString != EMPTY_STRING) { return eventString; } } return EMPTY_STRING;
<|startcomment|> formatting here, there's a white space missing after the if <|endcomment|>  public String getItemString(ITmfEvent event) { final String EMPTY_STRING = ""; //$NON-NLS-1$ for (ITmfEventAspect<?> aspect : fAspects) { String eventString = NonNullUtils.nullToEmptyString(aspect.resolve(event)); <|startfocus|> if(eventString != EMPTY_STRING) { <|endfocus|> return eventString; } } return EMPTY_STRING;
<|startcomment|> I missed this one before, but if (!eventString.isEmpty()) <|endcomment|>  public String getItemString(ITmfEvent event) { for (ITmfEventAspect<?> aspect : fAspects) { String eventString = NonNullUtils.nullToEmptyString(aspect.resolve(event)); <|startfocus|> if (eventString != EMPTY_STRING) { <|endfocus|> return eventString; } } return EMPTY_STRING;
<|startcomment|> Outdated header <|endcomment|> ***************************************************************************** <|startfocus|> * Copyright (c) 2011-2013 EclipseSource Muenchen GmbH and others. <|endfocus|> * * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Johannes Faltermeier - initial API and implementation ******************************************************************************/ package org.eclipse.emf.emfstore.client.test.ui.controllers; import java.io.IOException; import org.eclipse.emf.emfstore.common.ESObserver; import org.eclipse.emf.emfstore.internal.client.model.ESWorkspaceProviderImpl; import org.eclipse.emf.emfstore.internal.client.ui.controller.UIShowHistoryController; import org.eclipse.emf.emfstore.internal.common.observer.ObserverExceptionListener; import org.eclipse.emf.emfstore.server.exceptions.ESException; import org.eclipse.swtbot.eclipse.finder.widgets.SWTBotView; import org.eclipse.swtbot.swt.finder.finders.UIThreadRunnable; import org.eclipse.swtbot.swt.finder.results.VoidResult; import org.junit.Test; public class UIHistoryViewCloseTest extends AbstractUIControllerTestWithCommit { @Override @Test public void testController() throws ESException { 
<|startcomment|> First of all, the string should be externalized to a constant. Second of all, I wonder if we could have a better name for this. "Eclipse Capra UI Preferences", maybe? <|endcomment|>  public void init(IWorkbench workbench) { <|startfocus|> setDescription("Capra Generic Preferences"); <|endfocus|> setPreferenceStore(new ScopedPreferenceStore(InstanceScope.INSTANCE, CAPRA_PREFERENCE_PAGE_ID));
<|startcomment|> localize <|endcomment|>  * side * * MasterDetailRenderer implements IEditingDomainProvider to allow Undo/Redo/Copy/Cut/Paste actions to be performed * externally. * * MasterDetailRenderer provides an ISelectionProvider to get the currently selected items in the tree * */ @SuppressWarnings("restriction") public class TreeMasterDetailComposite extends Composite implements IEditingDomainProvider { <|startfocus|> private static final String SELECT_A_NODE = "Select a node in the tree to edit it"; private static final String LOADING = "Loading ..."; <|endfocus|> /** The input. */ private final Object input; /** The editing domain. */ private final EditingDomain editingDomain; /** The tree viewer. */ private TreeViewer treeViewer; /** The selection provider. */ private IMasterDetailSelectionProvider selectionProvider; /** The vertical sash. */ private Sash verticalSash; /** The detail scrollable composite. */ private Composite detailComposite; /** Manager of the currently rendered ECPSWTView with caching. */ private DetailViewManager detailManager; private Object lastRenderedObject; private final TreeMasterDetailSWTCustomization customization; 
<|startcomment|> This is very implicit, it will be much better to do some explicit check here like ALL_OS.equials() <|endcomment|>  public static boolean containsMatchingProperty(Set<IConfigurationProperty> existingProperties, String name, String os, String arch) { boolean result = false; for (IConfigurationProperty property : existingProperties) { if (name.equals(property.getName().trim())) { // check if os/arch is different String propOs = property.getOs().trim(); <|startfocus|> // length zero means all OS versions if (propOs.length() == 0 || os.length() == 0) { result = true; break; <|endfocus|> } else if (os.equals(propOs)) { String propArch = property.getArch(); // length zero means all architecture versions if (arch.length() == 0 || propArch.length() == 0) { result = true; break; } } else { continue; } } } return result;
<|startcomment|> Why not to just return value from here? <|endcomment|>  public static boolean containsMatchingProperty(Set<IConfigurationProperty> existingProperties, String name, String os, String arch) { boolean result = false; for (IConfigurationProperty property : existingProperties) { if (name.equals(property.getName().trim())) { // check if os/arch is different String propOs = property.getOs().trim(); <|startfocus|> // length zero means all OS versions if (propOs.length() == 0 || os.length() == 0) { result = true; break; <|endfocus|> } else if (os.equals(propOs)) { String propArch = property.getArch(); // length zero means all architecture versions if (arch.length() == 0 || propArch.length() == 0) { result = true; break; } } else { continue; } } } return result;
<|startcomment|> This is very implicit, it will be much better to do some explicit check here like ALL_ARCH.equials() <|endcomment|>  if (name.equals(property.getName().trim())) { // check if os/arch is different String propOs = property.getOs().trim(); // length zero means all OS versions if (propOs.length() == 0 || os.length() == 0) { result = true; break; } else if (os.equals(propOs)) { String propArch = property.getArch(); <|startfocus|> // length zero means all architecture versions if (arch.length() == 0 || propArch.length() == 0) { result = true; break; <|endfocus|> } } else { continue; } } } return result;
<|startcomment|> Why not to just return value from here? <|endcomment|>  // check if os/arch is different String propOs = property.getOs().trim(); // length zero means all OS versions if (propOs.length() == 0 || os.length() == 0) { result = true; break; } else if (os.equals(propOs)) { String propArch = property.getArch(); <|startfocus|> // length zero means all architecture versions if (arch.length() == 0 || propArch.length() == 0) { result = true; break; <|endfocus|> } } else { continue; } } } return result;
<|startcomment|> It will continue here anyway, right? <|endcomment|>  String propOs = property.getOs().trim(); // length zero means all OS versions if (propOs.length() == 0 || os.length() == 0) { result = true; break; } else if (os.equals(propOs)) { String propArch = property.getArch(); // length zero means all architecture versions if (arch.length() == 0 || propArch.length() == 0) { result = true; break; } <|startfocus|> } else { continue; <|endfocus|> } } } return result;
<|startcomment|> This new constant makes code less clear as it hides 3 semantic values: ALL_ARCH ALL_OS EMPTY_MESSAGE In general using EMPTY_STRING as a name is not good for a constant. The constant should have semantic name, otherwise it is better to just keep "" <|endcomment|>  IConfigurationProperty configuration = (IConfigurationProperty) obj; switch (index) { case 0 : return configuration.getName(); //return super.getColumnText(PluginRegistry.findModel(configuration.getId()), index); case 1 : return configuration.getValue(); case 2 : return configuration.getOs(); case 3 : return configuration.getArch(); } return null; } } private class PropertyDialog extends StatusDialog { <|startfocus|> private static final String EMPTY_STRING = ""; //$NON-NLS-1$ <|endfocus|> private Text fName; private Text fValue; private Combo fOS; private Combo fArch; private IConfigurationProperty fEdit; private Set<IConfigurationProperty> fExistingProperties; private String[] COMBO_OSLABELS = new String[] { PDEUIMessages.PropertiesSection_All, Platform.OS_LINUX, Platform.OS_MACOSX, Platform.OS_WIN32 }; private String[] COMBO_ARCHLABELS = new String[] { PDEUIMessages.PropertiesSection_All, Platform.ARCH_X86, Platform.ARCH_X86_64 }; public PropertyDialog(Shell shell, IConfigurationProperty property, Set<IConfigurationProperty> existingProperties) { super(shell); fEdit = property;
<|startcomment|> Does this work for you? <|endcomment|>  public void addEvent(ITimeEvent event) { if (isValidEvent(event)) { <|startfocus|> isValidEvent(event); <|endfocus|> } super.addEvent(event);
<|startcomment|> Should we be filtering out non-matching events instead of discarding the whole list? <|endcomment|>  public void setEventList(List<ITimeEvent> eventList) { <|startfocus|> if (eventList != null && eventList.stream().allMatch(TimeGraphLineEntry::isValidEvent)) { super.setEventList(eventList); <|endfocus|> }
<|startcomment|> This has no effect. <|endcomment|>  public void updateZoomedEvent(ITimeEvent event) { <|startfocus|> isValidEvent(event); super.updateZoomedEvent(event); <|endfocus|>
<|startcomment|> I'm not sure we need NullTimeEvent in the list, I was just worried about runtime exceptions. They for sure won't be used for drawing code. The only purpose they could have is for navigation (to go to next/previous point at the bounds of the window range). But for a line entry, it would probably be better to have the real next/previous point instead, so that the line is not broken at the bounds. If we can figure out its time from a null state in the state system, we can add a TimeLineEvent for it, and if we don't have the values it could default to the values of the first/last visible point, that would still be better than no line at all? <|endcomment|>  private static boolean isValidEvent(ITimeEvent event) { <|startfocus|> return (event instanceof TimeLineEvent) || (event instanceof NullTimeEvent); <|endfocus|>
<|startcomment|> If you get here, seriesModel is not empty. You don't need to check isEmpty, you're already iterating on seriesModel size below. <|endcomment|>  // add style Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } long val = values.get(i); max = Math.max(Math.abs(val), max); min = 0; <|startfocus|> seriesModel.get(i).add(new LongPoint(x, val)); isEmpty = false; <|endfocus|> } } if (isEmpty) { return; } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha(); gc.setAlpha(rgba.alpha); gc.setForeground(color); List<LongPoint> series = seriesModel.get(i);
<|startcomment|> This never prints the value because hasValue() is always false (NOVALUE in base class). I think we should override hasValue() in this class. Also, getLabel() returns something like: 1,339,077,333,139,181,050, 1,339,077,333,139,211,912, 1,339,077,333,143,145,217 I wonder if this is less readable than fValues.toString()? <|endcomment|>  public String toString() { <|startfocus|> return getClass().getSimpleName() + " time=" + fTime + (hasValue() ? (" value=" + getLabel()) : ""); //$NON-NLS-1$ //$NON-NLS-2$ //$NON-NLS-3$ <|endfocus|>
<|startcomment|> Remove this comment. <|endcomment|>  seriesModel.add(new ArrayList<>()); // add style Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } /* * In the case of missing data, (WHICH SHOULD NOT HAPPEN, just * persist the current value. */ <|startfocus|> if (values.size() < i) { long val = values.get(i); <|endfocus|> // get max and min, this is a relative scale. max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); } } } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i);
<|startcomment|> No need for this check if loop is bound by values.size(). Also, this is always false if the number of series is constant... <|endcomment|>  // add style Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } /* * In the case of missing data, (WHICH SHOULD NOT HAPPEN, just * persist the current value. */ <|startfocus|> if (values.size() < i) { long val = values.get(i); <|endfocus|> // get max and min, this is a relative scale. max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); } } } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i);
<|startcomment|> Although, I think it would be cool to support null values in the list. So you could have something like: t1: [ 1, null] t2: [null, 5000] t3: [ 3, 5200] t4: [null, 5100] t5: [ 2, null] Mapping to 2 independent series: (t1,1), (t3,3), (t5,2) (t2,5000), (t3,5200), (t4,5100) <|endcomment|>  Map<String, Object> eventStyle = timeGraphProvider.getEventStyle(timeEvent); int color = (int) eventStyle.getOrDefault(ITimeEventStyleStrings.fillColor(), 0xff); RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } /* * In the case of missing data, (WHICH SHOULD NOT HAPPEN, just * persist the current value. */ <|startfocus|> if (values.size() < i) { long val = values.get(i); <|endfocus|> // get max and min, this is a relative scale. max = Math.max(Math.abs(val), max); min = 0; seriesModel.get(i).add(new LongPoint(x, val)); } } } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString());
<|startcomment|> I'm a bit worried about how gaps will be handled, with this implementation we have to make sure that no dummy event is added for gaps. Also no NullTimeEvent allowed. Maybe that is OK? Or better to just ignore them? <|endcomment|>  public void addEvent(ITimeEvent event) { <|startfocus|> if (!(event instanceof TimeLineEvent)) { throw new IllegalArgumentException("Needs to be a TimeLineEvent"); //$NON-NLS-1$ } <|endfocus|> super.addEvent(event);
<|startcomment|> Why do all this, just don't add the point? <|endcomment|>  RGBA rgba = RGBAUtil.fromInt(color); COLOR_REGISTRY.put(rgba.toString(), rgba.rgb); colors.add(rgba); } /* * In the case of missing data, (WHICH SHOULD NOT HAPPEN, just * persist the current value. */ <|startfocus|> List<LongPoint> seriesToAdd = seriesModel.get(i); long val = values.size() >= nbSeries ? values.get(i) : seriesToAdd.get(seriesToAdd.size() - 1).y; <|endfocus|> // get max and min, this is a relative scale. max = Math.max(Math.abs(val), max); min = 0; seriesToAdd.add(new LongPoint(x, val)); } } double scale = (max - min) == 0 ? 1.0 : (double) rect.height / (max - min); for (int i = 0; i < seriesModel.size(); i++) { RGBA rgba = colors.get(i); Color color = COLOR_REGISTRY.get(rgba.toString()); Color prev = gc.getForeground(); int prevAlpha = gc.getAlpha();
<|startcomment|> remove <|endcomment|>  throw new IllegalArgumentException("Needs to be a TimeLineEvent"); //$NON-NLS-1$ } super.setEventList(eventList); } @Override public void updateZoomedEvent(ITimeEvent event) { if (!(event instanceof TimeLineEvent)) { throw new IllegalArgumentException("Needs to be a TimeLineEvent"); //$NON-NLS-1$ } super.updateZoomedEvent(event); } @Override public DisplayStyle getStyle() { return DisplayStyle.LINE; } <|startfocus|> <|endfocus|> } 
<|startcomment|> Not really <|endcomment|>  * accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html *******************************************************************************/ package org.eclipse.tracecompass.internal.tmf.ui.widgets.timegraph.model; import java.text.NumberFormat; import java.util.ArrayList; import java.util.List; import java.util.Locale; import java.util.Objects; import java.util.StringJoiner; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.ITimeGraphEntry; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.TimeEvent; /** <|startfocus|> * Generic TimeEvent implementation <|endfocus|> * * @author Matthew Khouzam */ public class TimeLineEvent extends TimeEvent { private final List<Long> fValues; private String fLabel = null; /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent(ITimeGraphEntry entry, long time) { this(entry, time, new ArrayList<>()); } /** * Standard constructor * * @param entry * The entry matching this event
<|startcomment|> Is there one TimeLineEvent for the whole row? If so, please mention so in the javadoc <|endcomment|>  *******************************************************************************/ package org.eclipse.tracecompass.internal.tmf.ui.widgets.timegraph.model; import java.text.NumberFormat; import java.util.ArrayList; import java.util.List; import java.util.Locale; import java.util.Objects; import java.util.StringJoiner; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.ITimeGraphEntry; import org.eclipse.tracecompass.tmf.ui.widgets.timegraph.model.TimeEvent; /** * Generic TimeEvent implementation * * @author Matthew Khouzam */ public class TimeLineEvent extends TimeEvent { <|startfocus|> <|endfocus|> private final List<Long> fValues; private String fLabel = null; /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent(ITimeGraphEntry entry, long time) { this(entry, time, new ArrayList<>()); } /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event * @param values
<|startcomment|> Or rather multiple values for one single time? So an entry can have many lines? <|endcomment|>  /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event */ public TimeLineEvent(ITimeGraphEntry entry, long time) { this(entry, time, new ArrayList<>()); } /** * Standard constructor * * @param entry * The entry matching this event * @param time * The timestamp of this event * @param values <|startfocus|> * The values to display <|endfocus|> */ public TimeLineEvent(ITimeGraphEntry entry, long time, List<Long> values) { super(entry, time, 0); fValues = values; } /** * Add a value * * @param value * the value to add, it will be displayed as a line */ public void addValue(long value) { fValues.add(value); } @Override public String getLabel() { String label = fLabel; if (label == null) {
<|startcomment|> What is empty? To me, here isEmpty should be true and set to false below, no? Unless I'm mistaken in what is empty. <|endcomment|>  private void drawLineGraphEntry(GC gc, long time0, Rectangle rect, double pixelsPerNanoSec, Iterator<ITimeEvent> iterator) { // clamp 0 - max positive long max = Long.MIN_VALUE; long min = 0; List<List<LongPoint>> seriesModel = new ArrayList<>(); List<RGBA> colors = new ArrayList<>(); ITimeGraphPresentationProvider timeGraphProvider = getTimeGraphProvider(); int nbSeries = -1; <|startfocus|> boolean isEmpty = false; <|endfocus|> while (iterator.hasNext()) { ITimeEvent event = iterator.next(); if (!(event instanceof TimeLineEvent)) { continue; } int x = SaturatedArithmetic.add(rect.x, (int) ((event.getTime() - time0) * pixelsPerNanoSec)); if (x >= rect.x + rect.width) { // event is out of bounds continue; } TimeLineEvent timeEvent = (TimeLineEvent) event; List<Long> values = timeEvent.getValues(); if (nbSeries == -1) { nbSeries = values.size(); }
<|startcomment|> Do you see a benefit of using map to null vs. filter invalid events? By the way, I think that invalid events will just be ignored by the drawing code. So it could be a possibility to do nothing special in this class to validate events. <|endcomment|>  public void setEventList(List<ITimeEvent> eventList) { <|startfocus|> if (eventList != null) { // Sets a filtered list super.setEventList(eventList.stream().map(timeEvent -> isValidEvent(timeEvent) ? timeEvent : null).collect(Collectors.toList())); } <|endfocus|>
<|startcomment|> Throws an exception for null values. Sorry ;( <|endcomment|>  public String getLabel() { String label = fLabel; if (label == null) { StringJoiner sj = new StringJoiner(", "); //$NON-NLS-1$ <|startfocus|> getValues().forEach((Long value) -> sj.add(NumberFormat.getNumberInstance(Locale.getDefault()).format(value))); <|endfocus|> label = sj.toString(); fLabel = label; } return label;
<|startcomment|> Do you think it's an issue that the caller can then modify the list? I don't mind but maybe Sonar does... <|endcomment|>  public List<Long> getValues() { <|startfocus|> return fValues; <|endfocus|>
<|startcomment|> remove <|endcomment|>  public void register() { Chart chart = getChart(); <|startfocus|> chart.getPlotArea().addMouseTrackListener(this); <|endfocus|> chart.getPlotArea().addMouseMoveListener(this); chart.getPlotArea().addPaintListener(this); fTooltipHandler.activateHoverHelp(chart.getPlotArea());
<|startcomment|> remove <|endcomment|>  public void deregister() { Chart chart = getChart(); if ((chart != null) && !chart.isDisposed()) { <|startfocus|> chart.getPlotArea().removeMouseTrackListener(this); <|endfocus|> chart.getPlotArea().removeMouseMoveListener(this); chart.getPlotArea().removePaintListener(this); fTooltipHandler.deactivateHoverHelp(chart.getPlotArea()); }
<|startcomment|> unrelated change ? <|endcomment|>  for (int i = 0; i < 10; i++) { appendRandomLine(f); git.add().addFilepattern("file").call(); git.commit().setMessage("message" + i).call(); } FileBasedConfig c = db.getConfig(); c.setInt(ConfigConstants.CONFIG_GC_SECTION, null, ConfigConstants.CONFIG_KEY_AUTOPACKLIMIT, 1); c.save(); Collection<PackFile> packs = gc(Deflater.NO_COMPRESSION); assertEquals("expected 1 packfile after gc", 1, packs.size()); <|startfocus|> <|endfocus|> PackFile p1 = packs.iterator().next(); PackFileSnapshot snapshot = p1.getFileSnapshot(); packs = gc(Deflater.BEST_COMPRESSION); assertEquals("expected 1 packfile after gc", 1, packs.size()); PackFile p2 = packs.iterator().next(); File pf = p2.getPackFile(); // changing compression level with aggressive gc may change size, // fileKey (on *nix) and checksum. Hence FileSnapshot.isModified can // return true already based on size or fileKey.
<|startcomment|> This does not guarantee that the list is mutable, which is required by addEvent(). There's an inconsistency because setZoomedEventList() is not overridden. Although, I'm leaning towards doing no check at all in this class... <|endcomment|>  public void setEventList(List<ITimeEvent> eventList) { <|startfocus|> if (eventList != null) { // Sets a filtered list super.setEventList(eventList.stream().map(timeEvent -> isValidEvent(timeEvent) ? timeEvent : null).collect(Collectors.toList())); } <|endfocus|>
<|startcomment|> Reset fLabel to null to clear invalid cache? <|endcomment|>  public void addValue(@Nullable Long value) { <|startfocus|> fValues.add(value); <|endfocus|>
<|startcomment|> Could we extract a helper for this pattern? "Wait for the shell XXX to be active and give me it's bot when ready" <|endcomment|>  protected SWTBotTreeItem[] getPaneBasedSelectionWizardTreeitems() { SWTBotSiriusDiagramEditor representation = (SWTBotSiriusDiagramEditor) openRepresentation(localSession.getOpenedSession(), REPRESENTATION_DESCRIPTION_NAME, REPRESENTATION_NAME, DDiagram.class); representation.setFocus(); representation.activateTool("Pane Based Selection"); representation.click(50, 100); <|startfocus|> bot.waitUntil(Conditions.shellIsActive("Pane Based")); SWTBot wizardBot = bot.shell("Pane Based").bot(); <|endfocus|> SWTBotTree tree = wizardBot.tree().select(0); SWTBotTreeItem swtBotTreeItem = tree.getAllItems()[0]; SWTBotTreeItem[] items = swtBotTreeItem.getItems(); return items;
<|startcomment|> Typo? <|endcomment|>  assertEquals(session.getStatus(), SessionStatus.SYNC); session.close(new NullProgressMonitor()); } /** * Test the cancel on the first wizard. * */ public void testCancelFirstWizard() { cancelFirstWizard(); Session session = localSession.getOpenedSession(); assertNotNull(THERE_IS_NO_SESSION, session); assertEquals(session.getStatus(), SessionStatus.SYNC); session.close(new NullProgressMonitor()); } /** <|startfocus|> * Test the cbotancel on the first wizard. <|endfocus|> * */ public void testCancelSecondWizard() { cancelSecondWizard(TREE_NAME); Session session = localSession.getOpenedSession(); assertNotNull(THERE_IS_NO_SESSION, session); assertEquals(session.getStatus(), SessionStatus.SYNC); session.close(new NullProgressMonitor()); } /** * Test that empty viewpoint are not displayed */ public void testEmptySirius() { // create representation createOnContextMenu(); // select representation to create bot.waitUntil(Conditions.shellIsActive("Create Representation Wizard")); SWTBotShell shell = bot.shell("Create Representation Wizard");
<|startcomment|> Do you mean ALL_OS here? <|endcomment|>  public static boolean containsMatchingProperty(Set<IConfigurationProperty> existingProperties, String name, String os, String arch) { for (IConfigurationProperty property : existingProperties) { if (name.equals(property.getName().trim())) { // check if os/arch is different <|startfocus|> String propOs = property.getOs() != null ? property.getOs().trim() : ""; //$NON-NLS-1$ <|endfocus|> if (ALL_OS.equals(propOs) || ALL_OS.equals(os) || propOs.equals(os)) { String propArch = property.getArch() != null ? property.getArch().trim() : ""; //$NON-NLS-1$ if (propArch.equals(arch) || ALL_ARCH.equals(arch) || ALL_ARCH.equals(propArch)) { return true; } } } } return false;
<|startcomment|> This is not mentioned explicitly in https://www.eclipse.org/projects/handbook/#ip-copyright-headers but I assume that all the information regarding authors should go to the license header. Please check the link above and the source base for more examples. <|endcomment|>  * * SPDX-License-Identifier: EPL-2.0 * * Contributors: * AixpertSoft GmbH - initial API and implementation *******************************************************************************/ package org.eclipse.pde.core.tests.internal.util; import java.util.HashSet; import java.util.Set; import junit.framework.TestCase; import org.eclipse.core.runtime.Platform; import org.eclipse.pde.internal.core.iproduct.IConfigurationProperty; import org.eclipse.pde.internal.core.product.ProductModel; import org.eclipse.pde.internal.core.product.ProductModelFactory; import org.eclipse.pde.internal.core.util.PDESchemaHelper; <|startfocus|> /** * @author alexander * */ <|endfocus|> public class PDESchemaHelperTest extends TestCase { private ProductModelFactory fProductModelFactory; Set<IConfigurationProperty> fConfigurationProperties = new HashSet<>(); public PDESchemaHelperTest() { initConfigurationProperties(); } private void initConfigurationProperties() { ProductModel productModel = new ProductModel(); fProductModelFactory = new ProductModelFactory(productModel); // create a single property for win32 / all architectures IConfigurationProperty property = fProductModelFactory.createConfigurationProperty(); property.setName("org.osgi.instance.area");
<|startcomment|> Still not sure what is benefit of adding null vs. not adding anything? At least for a normal time graph entry, having null in the event list could cause NPE in some cases. <|endcomment|>  private static void sanitizeList(List<ITimeEvent> sourceList, Consumer<List<ITimeEvent>> listConsumer) { if (sourceList != null) { // Sets a filtered list List<ITimeEvent> events = new ArrayList<>(); for (ITimeEvent event : sourceList) { if (isValidEvent(event)) { events.add(event); <|startfocus|> } else { events.add(null); <|endfocus|> } } listConsumer.accept(events); }
<|startcomment|> 32 is a space ' ' and 126 is a tilde '~' <|endcomment|>  } private void appendRandomLine(File f, int length, Random r) throws IOException { try (Writer w = Files.newBufferedWriter(f.toPath(), StandardOpenOption.APPEND)) { appendRandomLine(w, length, r); } } private void appendRandomLine(File f) throws IOException { appendRandomLine(f, 5, new Random()); } private void appendRandomLine(Writer w, int len, Random r) throws IOException { <|startfocus|> final int a = 32; // 'a' int e = 126; // 'e' <|endfocus|> for (int i = 0; i < len; i++) { w.append((char) (a + r.nextInt(1 + e - a))); } } private Git createTestRepo(int testDataSeed, int testDataLength) throws IOException, GitAPIException, NoFilepatternException, NoHeadException, NoMessageException, UnmergedPathsException, ConcurrentRefUpdateException, WrongRepositoryStateException, AbortedByHookException { // Create a repo with two commits and one file. Each commit adds // testDataLength number of bytes. Data are random bytes. Since the
<|startcomment|> modification <|endcomment|>  appendRandomLine(f, testDataLength, r); git.add().addFilepattern("file").call(); git.commit().setMessage("message2").call().getId(); return git; } // Try repacking so fast that you get two new packs which differ only in // content/chksum but have same name, size and lastmodified. // Since this is done with standard gc (which creates new tmp files and // renames them) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test <|startfocus|> public void testDetetctModificationAlthoughtSameSizeAndModificationtime() <|endfocus|> throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); // tell JGit not to used mtime of the parent folder to detect file // modifications. config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile PackFile pf = repackAndCheck(5, null, null, null);
<|startcomment|> Although <|endcomment|>  git.commit().setMessage("message2").call().getId(); return git; } // Try repacking so fast that you get two new packs which differ only in // content/chksum but have same name, size and lastmodified. // Since this is done with standard gc (which creates new tmp files and // renames them) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test <|startfocus|> public void testDetetctModificationAlthoughtSameSizeAndModificationtime() <|endfocus|> throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); // tell JGit not to used mtime of the parent folder to detect file // modifications. config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum();
<|startcomment|> Detect <|endcomment|>  git.commit().setMessage("message2").call().getId(); return git; } // Try repacking so fast that you get two new packs which differ only in // content/chksum but have same name, size and lastmodified. // Since this is done with standard gc (which creates new tmp files and // renames them) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test <|startfocus|> public void testDetetctModificationAlthoughtSameSizeAndModificationtime() <|endfocus|> throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); // tell JGit not to used mtime of the parent folder to detect file // modifications. config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum();
<|startcomment|> don't use <|endcomment|>  // content/chksum but have same name, size and lastmodified. // Since this is done with standard gc (which creates new tmp files and // renames them) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); <|startfocus|> // tell JGit not to used mtime of the parent folder to detect file // modifications. <|endfocus|> config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum(); String name = pf.getPackName(); Long length = Long.valueOf(pf.getPackFile().length()); long m1 = packFilePath.toFile().lastModified(); 
<|startcomment|> modification <|endcomment|>  // content/chksum but have same name, size and lastmodified. // Since this is done with standard gc (which creates new tmp files and // renames them) the filekeys of the new packfiles differ helping jgit // to detect the fast modifications @Test public void testDetetctModificationAlthoughtSameSizeAndModificationtime() throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); <|startfocus|> // tell JGit not to used mtime of the parent folder to detect file // modifications. <|endfocus|> config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); AnyObjectId chk1 = pf.getPackChecksum(); String name = pf.getPackName(); Long length = Long.valueOf(pf.getPackFile().length()); long m1 = packFilePath.toFile().lastModified(); 
<|startcomment|> Although <|endcomment|>  .getPackChecksum()); assumeTrue(m3 == m2); } // Try repacking so fast that you get two new packs which differ only in // content/chksum but have same name, size and lastmodified. // To avoid that JGit detects modifications by checking the filekey create // two new packfiles upfront and create copies of them. Then modify the // packfiles inplace by opening them for write and copy content. @Test <|startfocus|> public void testDetetctModificationAlthoughtSameSizeAndModificationtimeAndFileKey() <|endfocus|> throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile. Make a copy of it PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); Path packFileBasePath = packFilePath.resolveSibling(
<|startcomment|> Detect <|endcomment|>  .getPackChecksum()); assumeTrue(m3 == m2); } // Try repacking so fast that you get two new packs which differ only in // content/chksum but have same name, size and lastmodified. // To avoid that JGit detects modifications by checking the filekey create // two new packfiles upfront and create copies of them. Then modify the // packfiles inplace by opening them for write and copy content. @Test <|startfocus|> public void testDetetctModificationAlthoughtSameSizeAndModificationtimeAndFileKey() <|endfocus|> throws Exception { int testDataSeed = 1; int testDataLength = 100; FileBasedConfig config = db.getConfig(); config.setBoolean(ConfigConstants.CONFIG_CORE_SECTION, null, ConfigConstants.CONFIG_KEY_TRUSTFOLDERSTAT, false); config.save(); createTestRepo(testDataSeed, testDataLength); // Pack to create initial packfile. Make a copy of it PackFile pf = repackAndCheck(5, null, null, null); Path packFilePath = pf.getPackFile().toPath(); Path packFileBasePath = packFilePath.resolveSibling(
<|startcomment|> differently <|endcomment|>  Long oldLength, AnyObjectId oldChkSum) throws IOException, ParseException { PackFile p = getSinglePack(gc(compressionLevel)); File pf = p.getPackFile(); // The following two assumptions should not cause the test to fail. If // on a certain platform we get packfiles where the lengths differ or // the checksums don't differ we just skip this test. A reason for that // could be that compression works differently or random number <|startfocus|> // generator works different. Then we have to search for more consistent <|endfocus|> // test data or checkin these packfiles as test resources assumeTrue(oldLength == null || pf.length() == oldLength.longValue()); assumeTrue(oldChkSum == null || !p.getPackChecksum().equals(oldChkSum)); assertTrue(oldName == null || p.getPackName().equals(oldName)); return p; } // private void printFilesMetaData(Path... paths) throws IOException { // for (Path p : paths) { // System.out.println(describe(p)); // } // } 
<|startcomment|> With the proposed change: updateStyleBits(image == null) <|endcomment|> public void setImage (Image image) { checkWidget (); if ((style & SWT.SEPARATOR) != 0) return; if (image != null && image.isDisposed()) error(SWT.ERROR_INVALID_ARGUMENT); this.image = image; <|startfocus|> updateStyleBits(false); <|endfocus|> OS.InvalidateRect (handle, null, true);
<|startcomment|> With the proposed change: updateStyleBits(true), unconditional, because text can't be null. <|endcomment|> public void setText (String string) { checkWidget (); if (string == null) error (SWT.ERROR_NULL_ARGUMENT); if ((style & SWT.SEPARATOR) != 0) return; <|startfocus|> if (image == null || !IMAGE_AND_TEXT) { updateStyleBits(true); } <|endfocus|> /* * Feature in Windows. For some reason, SetWindowText() for * static controls redraws the control, even when the text has * has not changed. The fix is to check for this case and do * nothing. */ if (string.equals (text)) return; text = string; string = Display.withCrLf (string); TCHAR buffer = new TCHAR (getCodePage (), string, true); OS.SetWindowText (handle, buffer); if ((state & HAS_AUTO_DIRECTION) != 0) { updateTextDirection (AUTO_TEXT_DIRECTION); }
<|startcomment|> entry? <|endcomment|>  protected List<ISourceContainer> getEntriesAsList() { ISourceContainer[] entries = getViewer().getEntries(); List<ISourceContainer> list = new ArrayList<>(entries.length); <|startfocus|> for (ISourceContainer entrie : entries) { list.add(entrie); <|endfocus|> } return list;
<|startcomment|> entry <|endcomment|>  public void setEntries(ISourceContainer[] entries) { fEntries.clear(); <|startfocus|> for (ISourceContainer entrie : entries) { if (entrie != null) { fEntries.add(entrie); <|endfocus|> } } if (getInput() == null) { setInput(fEntries); //select first item in list if(!fEntries.isEmpty() && fEntries.get(0)!=null) { setSelection(new StructuredSelection(fEntries.get(0))); } } else { refresh(); } fPanel.setDirty(true); fPanel.updateLaunchConfigurationDialog();
<|startcomment|> entry <|endcomment|>  public void addEntries(ISourceContainer[] entries) { int index = 0; IStructuredSelection sel = getStructuredSelection(); if (!sel.isEmpty()) { <|startfocus|> index = fEntries.indexOf(sel.getFirstElement()); } for (ISourceContainer entrie : entries) { if (!fEntries.contains(entrie)) { fEntries.add(index, entrie); <|endfocus|> index++; } } refresh(); if(entries.length > 0) { setSelection(new StructuredSelection(entries)); } fPanel.setDirty(true); fPanel.updateLaunchConfigurationDialog();
<|startcomment|> organizer, it's not a field <|endcomment|>  public void setOrganizers(IBreakpointOrganizer[] organizers) { // remove previous listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.removePropertyChangeListener(this); } <|startfocus|> } <|endfocus|> fOrganizers = organizers; if (organizers != null && organizers.length == 0) { fOrganizers = null; } // add listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.addPropertyChangeListener(this); } } if (!fDisposed) { fViewer.getControl().setRedraw(false); // maintain expansion based on visible breakpoints IBreakpoint[] breakpoints = null; if (isShowingGroups()) { breakpoints = fViewer.getVisibleBreakpoints(); } reorganize(); if (isShowingGroups() && breakpoints != null) { // restore expansion for (Object fElement : fElements) { BreakpointContainer container = (BreakpointContainer) fElement; for (IBreakpoint breakpoint : breakpoints) { if (container.contains(breakpoint)) { fViewer.expandToLevel(container, AbstractTreeViewer.ALL_LEVELS); fViewer.updateCheckedState(container);
<|startcomment|> ditto <|endcomment|>  public void setOrganizers(IBreakpointOrganizer[] organizers) { // remove previous listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.removePropertyChangeListener(this); } } fOrganizers = organizers; if (organizers != null && organizers.length == 0) { fOrganizers = null; } <|startfocus|> // add listeners if (fOrganizers != null) { for (IBreakpointOrganizer fOrganizer : fOrganizers) { fOrganizer.addPropertyChangeListener(this); <|endfocus|> } } if (!fDisposed) { fViewer.getControl().setRedraw(false); // maintain expansion based on visible breakpoints IBreakpoint[] breakpoints = null; if (isShowingGroups()) { breakpoints = fViewer.getVisibleBreakpoints(); } reorganize(); if (isShowingGroups() && breakpoints != null) { // restore expansion for (Object fElement : fElements) { BreakpointContainer container = (BreakpointContainer) fElement; for (IBreakpoint breakpoint : breakpoints) { if (container.contains(breakpoint)) { fViewer.expandToLevel(container, AbstractTreeViewer.ALL_LEVELS); fViewer.updateCheckedState(container);
<|startcomment|> filter <|endcomment|>  public boolean isValidProperty(String property) { if (fFilters == null) { return true; } <|startfocus|> for (String fFilter : fFilters) { if (fFilter.equals(property)) { <|endfocus|> return true; } } return false;
<|startcomment|> memoryByte? <|endcomment|>  } return ret.toArray(new MemoryByte[ret.size()]); } public String getRawMemoryString() { if (fStrRep == null) { StringBuffer buffer = new StringBuffer(); fStrRep = RenderingsUtil.convertByteArrayToHexString(getByteArray()); fStrRep = fStrRep.toUpperCase(); buffer = buffer.append(fStrRep); // pad unavailable bytes with padded string from memory block String paddedString = null; int bufferCounter = 0; <|startfocus|> for (MemoryByte fByte : fBytes) { <|endfocus|> // if byte is invalid if (!fByte.isReadable()) { if (paddedString == null) { paddedString = fPaddedString; if (paddedString.length() > TableRenderingLine.numCharPerByteForHex) { paddedString = paddedString.substring(0, TableRenderingLine.numCharPerByteForHex); } } buffer.replace(bufferCounter, bufferCounter+TableRenderingLine.numCharPerByteForHex, paddedString); } bufferCounter += TableRenderingLine.numCharPerByteForHex; } fStrRep = buffer.toString(); } return fStrRep; } 
<|startcomment|> toggleDetailPaneAction <|endcomment|>  fSashForm.setMaximizedControl(variablesViewer.getControl()); fDetailsAnchor = SWTFactory.createComposite(fSashForm, parent.getFont(), 1, 1, GridData.FILL_BOTH, 0, 0); fSashForm.setWeights(getLastSashWeights()); fSelectionProvider = new SelectionProviderWrapper(variablesViewer); getSite().setSelectionProvider(fSelectionProvider); createOrientationActions(variablesViewer); IPreferenceStore prefStore = DebugUIPlugin.getDefault().getPreferenceStore(); String orientation = prefStore.getString(getDetailPanePreferenceKey()); <|startfocus|> for (ToggleDetailPaneAction fToggleDetailPaneAction : fToggleDetailPaneActions) { fToggleDetailPaneAction.setChecked(fToggleDetailPaneAction.getOrientation().equals(orientation)); <|endfocus|> } fDetailPane = new DetailPaneProxy(this); fDetailPane.addProperyListener(new IPropertyListener() { @Override public void propertyChanged(Object source, int propId) { firePropertyChange(propId); } }); setDetailPaneOrientation(orientation); IMemento memento = getMemento(); if (memento != null) { variablesViewer.initState(memento); } variablesViewer.addModelChangedListener(this); variablesViewer.addViewerUpdateListener(this); initDragAndDrop(variablesViewer); return variablesViewer;
<|startcomment|> contributionItem, it's not an interface, it's an object <|endcomment|>  protected void saveAllCheckedActionStates() { IToolBarManager tbm= getViewSite().getActionBars().getToolBarManager(); IContributionItem[] items= tbm.getItems(); <|startfocus|> for (IContributionItem iContributionItem : items) { <|endfocus|> if (iContributionItem instanceof ActionContributionItem) { ActionContributionItem item= (ActionContributionItem)iContributionItem; IAction action= item.getAction(); if (action.getStyle() == IAction.AS_CHECK_BOX && action.isEnabled()) { saveCheckedActionState(action); } } }
<|startcomment|> breakpoint <|endcomment|>  * * @param breakpoints the breakpoints to export * @since 3.5 */ public ExportBreakpointsOperation(IBreakpoint[] breakpoints) { fBreakpoints = breakpoints; fWriter = new StringWriter(); } @Override public void run(IProgressMonitor monitor) throws InvocationTargetException { SubMonitor localmonitor = SubMonitor.convert(monitor, ImportExportMessages.ExportOperation_0, fBreakpoints.length); XMLMemento memento = XMLMemento.createWriteRoot(IImportExportConstants.IE_NODE_BREAKPOINTS); try (Writer writer = fWriter;) { <|startfocus|> for (IBreakpoint fBreakpoint : fBreakpoints) { <|endfocus|> if (localmonitor.isCanceled()) { return; } IBreakpoint breakpoint = fBreakpoint; //in the event we are in working set view, we can have multiple selection of the same breakpoint //so do a simple check for it IMarker marker = breakpoint.getMarker(); IMemento root = memento.createChild(IImportExportConstants.IE_NODE_BREAKPOINT); root.putString(IImportExportConstants.IE_BP_ENABLED, Boolean.toString(breakpoint.isEnabled())); root.putString(IImportExportConstants.IE_BP_REGISTERED, Boolean.toString(breakpoint.isRegistered()));
<|startcomment|> then remove this <|endcomment|>  */ public ExportBreakpointsOperation(IBreakpoint[] breakpoints) { fBreakpoints = breakpoints; fWriter = new StringWriter(); } @Override public void run(IProgressMonitor monitor) throws InvocationTargetException { SubMonitor localmonitor = SubMonitor.convert(monitor, ImportExportMessages.ExportOperation_0, fBreakpoints.length); XMLMemento memento = XMLMemento.createWriteRoot(IImportExportConstants.IE_NODE_BREAKPOINTS); try (Writer writer = fWriter;) { for (IBreakpoint fBreakpoint : fBreakpoints) { if (localmonitor.isCanceled()) { return; } <|startfocus|> IBreakpoint breakpoint = fBreakpoint; <|endfocus|> //in the event we are in working set view, we can have multiple selection of the same breakpoint //so do a simple check for it IMarker marker = breakpoint.getMarker(); IMemento root = memento.createChild(IImportExportConstants.IE_NODE_BREAKPOINT); root.putString(IImportExportConstants.IE_BP_ENABLED, Boolean.toString(breakpoint.isEnabled())); root.putString(IImportExportConstants.IE_BP_REGISTERED, Boolean.toString(breakpoint.isRegistered())); root.putString(IImportExportConstants.IE_BP_PERSISTANT, Boolean.toString(breakpoint.isPersisted())); //write out the resource information
<|startcomment|> editor <|endcomment|>  if (scroll != null && !scroll.isDisposed()) { scroll.removeSelectionListener(fScrollbarSelectionListener); } if (!fTableCursor.isDisposed()) { fTableCursor.removeTraverseListener(fCursorTraverseListener); fTableCursor.removeKeyListener(fCursorKeyAdapter); fTableCursor.removeMouseListener(fCursorMouseListener); } fCursorEditor.dispose(); fTextViewer = null; fTableViewer = null; fTableCursor = null; // clean up cell editors <|startfocus|> for (CellEditor fEditor : fEditors) { fEditor.dispose(); <|endfocus|> } // remove font change listener when the view tab is disposed JFaceResources.getFontRegistry().removeListener(this); // remove the view tab from the synchronizer IMemoryRenderingSynchronizationService syncService = getMemoryRenderingContainer().getMemoryRenderingSite().getSynchronizationService(); if (syncService != null) { syncService.removePropertyChangeListener(this); } DebugUIPlugin.getDefault().getPreferenceStore().removePropertyChangeListener(this); fToolTipShell.dispose(); if (getPopupMenuManager() != null) { getPopupMenuManager().removeMenuListener(fMenuListener); } super.dispose(); 
<|startcomment|> This should be 1.22 if it's needed at all (this class is not public API). <|endcomment|> import org.eclipse.emf.edit.provider.ComposedAdapterFactory; import org.eclipse.emf.edit.provider.ReflectiveItemProviderAdapterFactory; import org.eclipse.jface.databinding.swt.WidgetValueProperty; import org.eclipse.jface.viewers.CellEditor; import org.eclipse.swt.SWT; import org.eclipse.swt.events.FocusEvent; import org.eclipse.swt.events.FocusListener; import org.eclipse.swt.graphics.Image; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Control; /** * Single reference cell editor implementation. * * @author Mat Hansen <mhansen@eclipsesource.com> <|startfocus|> * @since 1.21 <|endfocus|> * */ @SuppressWarnings("restriction") public class SingleReferenceCellEditor extends CellEditor implements ECPCellEditor, ECPElementAwareCellEditor { private EObject rowElement; private ReferenceService referenceService; private EReference eReference; private Composite composite; private ComposedAdapterFactory composedAdapterFactory; private AdapterFactoryItemDelegator adapterFactoryItemDelegator; /** * The constructor. * * @param parent the parent composite */ public SingleReferenceCellEditor(Composite parent) { super(parent); } /** * Alternate constructor with SWT style bits. *
<|startcomment|> As a user, I would expect an unset value in a table cell simply to be blank. There should be text only if a cell has a value. <|endcomment|>  public String getFormatedString(Object value) { if (value == null) { <|startfocus|> return Messages.SingleReferenceCellEditor_noReferenceSet; <|endfocus|> } return adapterFactoryItemDelegator.getText(value);
<|startcomment|> Similar comment as on the cell editor class. <|endcomment|>  * * Contributors: * EclipseSource Munich - initial API and implementation */ package org.eclipse.emf.ecp.view.internal.table.swt.cell; import org.eclipse.emf.ecore.EObject; import org.eclipse.emf.ecore.EReference; import org.eclipse.emf.ecore.EStructuralFeature; import org.eclipse.emf.ecp.edit.spi.swt.table.ECPCellEditorTester; import org.eclipse.emf.ecp.view.spi.context.ViewModelContext; /** * Single reference cell editor tester. * * @author Mat Hansen <mhansen@eclipsesource.com> <|startfocus|> * @since 1.21 <|endfocus|> * */ public class SingleReferenceCellEditorTester implements ECPCellEditorTester { @Override public int isApplicable(EObject eObject, EStructuralFeature eStructuralFeature, ViewModelContext viewModelContext) { if (!EReference.class.isInstance(eStructuralFeature)) { return NOT_APPLICABLE; } final EReference eReference = EReference.class.cast(eStructuralFeature); if (eReference.getUpperBound() == 1) { return 10; } return NOT_APPLICABLE; } } 
<|startcomment|> should be renamed, is also used for opens. <|endcomment|>  private void analyseSomeReferencedPackages(PackageVisibilityStatement[] stats, CompilationUnitScope skope) { <|startfocus|> for (PackageVisibilityStatement export : stats) { PackageBinding pb = export.resolvedPackage; <|endfocus|> if (pb == null) continue; pb = pb.getIncarnation(this.binding); if (pb != null && pb.hasCompilationUnit(true)) continue; skope.problemReporter().invalidPackageReference(IProblem.PackageDoesNotExistOrIsEmpty, export); }
<|startcomment|> In theory getVisibleFor could return a SplitPackageBinding, so this would break the invariant that declaredPackages doesn't contain them. But the surrounding packageBinding.isDeclaredIn(this) ensures that this doesn't happen (assuming the bug in SPB.getVisibleFor is fixed). But to make it obvious, packageBinding.getIncarnation(this) could be used here instead, which never returns a SBP and always returns a non-null result because of surrounding if(...) <|endcomment|>  if (checkForSplit && this.environment.useModuleSystem) { char[][] declaringModuleNames = null; if (isUnnamed()) { IModuleAwareNameEnvironment moduleEnv = (IModuleAwareNameEnvironment) this.environment.nameEnvironment; declaringModuleNames = moduleEnv.getUniqueModulesDeclaringPackage(new char[][] {packageName}, ANY); } packageBinding = combineWithPackagesFromOtherRelevantModules(packageBinding, packageBinding.compoundName, declaringModuleNames); } <|startfocus|> this.declaredPackages.put(packageName, packageBinding.getVisibleFor(this, true, true/*need to see empty parent packages, too*/)); <|endfocus|> if (packageBinding.parent == null) { this.environment.knownPackages.put(packageName, packageBinding); } } return packageBinding; } private PackageBinding combineWithPackagesFromOtherRelevantModules(PackageBinding currentBinding, char[][] compoundName, char[][] declaringModuleNames) { boolean save = this.isPackageLookupActive; this.isPackageLookupActive = true; try { for (ModuleBinding moduleBinding : otherRelevantModules(declaringModuleNames)) { if (!moduleBinding.isPackageLookupActive) { PackageBinding nextBinding = moduleBinding.getDeclaredPackage(CharOperation.concatWith(compoundName, '.'));
<|startcomment|> childPackage can never be null here. <|endcomment|>  PackageBinding combineWithSiblings(PackageBinding childPackage, char[] name, ModuleBinding module) { <|startfocus|> ModuleBinding primaryModule = childPackage != null ? childPackage.enclosingModule : this.enclosingModule; <|endfocus|> // see if other incarnations contribute to the child package, too: boolean activeSave = primaryModule.isPackageLookupActive; primaryModule.isPackageLookupActive = true; try { char[] flatName = CharOperation.concatWith(childPackage.compoundName, '.'); for (PackageBinding incarnation : this.incarnations) { ModuleBinding moduleBinding = incarnation.enclosingModule; if (moduleBinding == module) continue; if (childPackage.isDeclaredIn(moduleBinding)) continue; PackageBinding next = moduleBinding.getDeclaredPackage(flatName); childPackage = combine(next, childPackage, primaryModule); } return childPackage; } finally { primaryModule.isPackageLookupActive = activeSave; }
<|startcomment|> Thanks :-) <|endcomment|>  final Object image = adapterFactoryItemDelegator.getImage(value); return SWTImageHelper.getImage(image); } @Override public int getColumnWidthWeight() { return 0; } @Override public UpdateValueStrategy getTargetToModelStrategy(DataBindingContext databindingContext) { return null; } @Override public UpdateValueStrategy getModelToTargetStrategy(DataBindingContext databindingContext) { return null; } @Override public void setEditable(boolean editable) { } @Override public int getMinWidth() { return 100; } <|startfocus|> /** * {@inheritDoc} * * @see org.eclipse.jface.viewers.CellEditor#createControl(org.eclipse.swt.widgets.Composite) */ <|endfocus|> @Override protected Control createControl(Composite parent) { composite = new Composite(parent, SWT.NONE); composite.addFocusListener(new FocusListener() { private boolean focused; @Override public void focusLost(FocusEvent e) { } @Override public void focusGained(FocusEvent e) { if (focused) { return; } focused = true; try {
<|startcomment|> NON-NLS ? <|endcomment|>  * * Contributors: * Vincent Lorenzo (CEA LIST) vincent.lorenzo@cea.fr - Initial API and implementation *****************************************************************************/ package org.eclipse.papyrus.model2doc.odt.internal.transcription; /** * This class contains the custom fields used to generate LibreOffice document */ public class CustomFields { /** * Constructor. * */ private CustomFields() { // to prevent instanciation } /** * The custom field Authors */ <|startfocus|> public static final String AUTHORS = "Authors"; <|endfocus|> /** * The custom field Version */ public static final String VERSION = "Version"; } 
<|startcomment|> NON-NLS ? <|endcomment|>  *****************************************************************************/ package org.eclipse.papyrus.model2doc.odt.internal.transcription; /** * This class contains the custom fields used to generate LibreOffice document */ public class CustomFields { /** * Constructor. * */ private CustomFields() { // to prevent instanciation } /** * The custom field Authors */ public static final String AUTHORS = "Authors"; /** * The custom field Version */ <|startfocus|> public static final String VERSION = "Version"; <|endfocus|> } 
<|startcomment|> NON-NLS ? <|endcomment|>  public void writeAuthors(final Collection<IAuthor> authors) { if (authors.size() > 0) { final XTextDocument document = odtEditor.getXTextDocument(); final XDocumentPropertiesSupplier xsDocProp = UnoRuntime.queryInterface(XDocumentPropertiesSupplier.class, document); XDocumentProperties props = xsDocProp.getDocumentProperties(); final Iterator<IAuthor> iterator = authors.iterator(); <|startfocus|> String allAuthorsLabel = ""; <|endfocus|> if (iterator.hasNext()) { final IAuthor firstAuthor = iterator.next(); allAuthorsLabel = firstAuthor.buildMultiAuthorLabel(ECollections.toEList(authors)); props.setAuthor(firstAuthor.buildAuthorLabel()); } XPropertyContainer userDefined = props.getUserDefinedProperties(); // we need to remove the property if it already exist, in order to be change its value try { userDefined.removeProperty(CustomFields.AUTHORS); } catch (UnknownPropertyException | NotRemoveableException e) { // nothing to do } try { userDefined.addProperty(CustomFields.AUTHORS, com.sun.star.beans.PropertyAttribute.REMOVABLE, allAuthorsLabel); } catch (IllegalArgumentException | PropertyExistException | IllegalTypeException e) { Activator.log.error(e); }
<|startcomment|> are you really sure you do nothing on this catch ? <|endcomment|>  String allAuthorsLabel = ""; if (iterator.hasNext()) { final IAuthor firstAuthor = iterator.next(); allAuthorsLabel = firstAuthor.buildMultiAuthorLabel(ECollections.toEList(authors)); props.setAuthor(firstAuthor.buildAuthorLabel()); } XPropertyContainer userDefined = props.getUserDefinedProperties(); // we need to remove the property if it already exist, in order to be change its value try { userDefined.removeProperty(CustomFields.AUTHORS); <|startfocus|> } catch (UnknownPropertyException | NotRemoveableException e) { // nothing to do <|endfocus|> } try { userDefined.addProperty(CustomFields.AUTHORS, com.sun.star.beans.PropertyAttribute.REMOVABLE, allAuthorsLabel); } catch (IllegalArgumentException | PropertyExistException | IllegalTypeException e) { Activator.log.error(e); } }
<|startcomment|> remove <|endcomment|>  @NonNull ITmfStateInterval interval = stateSystem.querySingleState(END_TIME, quark); long count1 = interval.getStateValue().unboxLong(); quark = stateSystem.getQuarkAbsolute("fsm2"); interval = stateSystem.querySingleState(END_TIME, quark); long count2 = interval.getStateValue().unboxLong(); assertEquals("Test the count value", count1, count2); } catch (AttributeNotFoundException | StateSystemDisposedException e) { fail("Failed to query the state system"); } } <|startfocus|> <|endfocus|> /** * Compare the execution of two state machines doing the same job, the tid * condition is ignored with the initial element and used with the * initialState element. The result should be different. */ @Test public void testInitialStateWithCondition() { ITmfStateSystem stateSystem = fModule.getStateSystem(fModule.getId()); assertNotNull("state system exist", stateSystem); try { int quark = stateSystem.getQuarkAbsolute("fsm1"); @NonNull ITmfStateInterval interval = stateSystem.querySingleState(END_TIME, quark);
<|startcomment|> If I am correct, this causes a resource leak, if there is already a adornedImage, it is replaced, without cleaning resources. If not, there is no need to 'cache' the image here. <|endcomment|>  if (!isPinned) { // Remove and dispose any previous adorned image Image previouslyAdornedImage = (Image) element.getTransientData().get("previouslyAdorned"); //$NON-NLS-1$ if (previouslyAdornedImage != null && !previouslyAdornedImage.isDisposed()) previouslyAdornedImage.dispose(); element.getTransientData().remove(IPresentationEngine.ADORNMENT_PIN); } else { adornedImage = resUtils.adornImage(image, pinImage); if (adornedImage != image) element.getTransientData().put( "previouslyAdorned", adornedImage); //$NON-NLS-1$ } <|startfocus|> return adornedImage; <|endfocus|>
<|startcomment|> WBWRenderer#getImage overrides this method; I am pretty sure that WBWRenderer#getImage(element) should be changed to WBWRenderer#getImage(element, changed) too. @Lars should this method be changed to public final to prevent errors? <|endcomment|>  public Image getImage(MUILabel element) { <|startfocus|> return getImage(element, false); <|endfocus|>
<|startcomment|> The imageChanged check is not necessary in this block <|endcomment|>  private Image adornImage(MUIElement element, Image image, boolean imageChanged) { if (element.getTags().contains(IPresentationEngine.ADORNMENT_PIN)) {// Only if Pinned Image previousImage = (Image) element.getTransientData().get(ADORN_ICON_IMAGE_KEY); boolean exist = previousImage != null && !previousImage.isDisposed(); // Cached image exist <|startfocus|> if (imageChanged || !exist) { if (imageChanged && exist) { disposeAdornedImage(element);// Need to dispose old image.If image changed } <|endfocus|> Image adornedImage = resUtils.adornImage(image, pinImage); if (adornedImage != image) { element.getTransientData().put(ADORN_ICON_IMAGE_KEY, adornedImage); } return adornedImage; } return previousImage; } return image;
<|startcomment|> Avoid using final, we don't do that in platfrom code <|endcomment|> <|startfocus|> protected void showTab(final MUIElement tabElement) { <|endfocus|> MPerspective persp = (MPerspective) tabElement; Control ctrl = (Control) persp.getWidget(); if (ctrl == null) { ctrl = (Control) renderer.createGui(persp); } else if (ctrl.getParent() != persp.getParent().getWidget()) { Composite parent = (Composite) persp.getParent().getWidget(); ctrl.setParent(parent); } super.showTab(persp); // relayout the perspective final Composite psComp = ctrl.getParent(); StackLayout sl = (StackLayout) psComp.getLayout(); if (sl != null) { sl.topControl = ctrl; psComp.layout(); } ctrl.moveAbove(null); // Force a context switch final IEclipseContext context = persp.getContext(); context.get(EPartService.class).switchPerspective(persp); // Move any other controls to 'limbo' Control[] kids = psComp.getChildren(); Shell limbo = (Shell) context.get("limbo"); //$NON-NLS-1$ for (Control child : kids) { if (child != ctrl) {
<|startcomment|> Lost the file deletion, which must happen after 'input' is closed. <|endcomment|>  private boolean loadMappingsFromOldWorkspace(Map<String, Integer> map) { // File name of the persisted file type information String STATE_FILE = ".fileTypes"; //$NON-NLS-1$ IPath pluginStateLocation = TeamPlugin.getPlugin().getStateLocation().append(STATE_FILE); File f = pluginStateLocation.toFile(); if (!f.exists()) return false; <|startfocus|> try (DataInputStream input = new DataInputStream(new FileInputStream(f))) { map.putAll(readOldFormatExtensionMappings(input)); <|endfocus|> } catch (IOException ex) { TeamPlugin.log(IStatus.ERROR, ex.getMessage(), ex); return false; } return true;
<|startcomment|> JGit CI detected this typo in the Javadoc tag. I fixed it also upstream and sent ghis PR: [1]. * [1] https://github.com/eclipse/smarthome/pull/6902 <|endcomment|>  } return bytes; } /** * Converts an hex string (in format "0123456789ABCDEF") into a byte array * * @param hexString the hex string * @return the corresponding byte array */ public static byte[] hexToBytes(String hexString) { return hexToBytes(hexString, "(?<=\\G.{2})"); } /** * Convert an upper case hex character to a byte * <|startfocus|> * @param chacacter an upper case hex character <|endfocus|> * @return the byte value of the character * @throws IllegalArgumentException if a value is found which is not an upper case hex character */ private static byte hexCharacterToBin(char character) { if ('0' <= character && character <= '9') { return (byte) (character - ASCII_DIGITS_START_POSITION); } else if ('A' <= character && character <= 'F') { return (byte) (character - ASCII_UPPERCASE_LETTERS_START_POSITION + 10); } else {
<|startcomment|> This creates a new dependency to IPage, is this really necessary? Can't we do it in a more generic way and just set the container as in AbstractAction? <|endcomment|>  public TableUserFilterManager getUserFilterManager() { return (TableUserFilterManager) propertySupport.getProperty(PROP_USER_FILTER_MANAGER); } @Override public void setUserFilterManager(TableUserFilterManager m) { propertySupport.setProperty(PROP_USER_FILTER_MANAGER, m); } @Override public ITableCustomizer getTableCustomizer() { return (ITableCustomizer) propertySupport.getProperty(PROP_TABLE_CUSTOMIZER); } @Override public void setTableCustomizer(ITableCustomizer c) { propertySupport.setProperty(PROP_TABLE_CUSTOMIZER, c); } @Override <|startfocus|> public IPage<?> getParentPage() { return (IPage<?>) propertySupport.getProperty(PROP_PARENT_PAGE); } @Override <|endfocus|> public ITypeWithClassId getContainer() { IWidget parentWidget = getParent(); if (parentWidget != null) { return parentWidget; } return getParentPage(); } /** * do not use this internal method */ public void setParentPageInternal(IPage<?> container) { propertySupport.setProperty(PROP_PARENT_PAGE, container); } @Override public boolean isSortEnabled() { return propertySupport.getPropertyBool(PROP_SORT_ENABLED); } @Override
<|startcomment|> `+ System.currentTimeMillis()` should be enough. <|endcomment|>  * drop can be aborted if appropriate. * * This class is not intended to be subclassed. * * @since 3.2 */ public class LocalSelectionTransfer extends ByteArrayTransfer { // First attempt to create a UUID for the type name to make sure that // different Eclipse applications use different "types" of // <code>LocalSelectionTransfer</code> <|startfocus|> private static final String TYPE_NAME = "local-selection-transfer-format" + Long.valueOf(System.currentTimeMillis()); //$NON-NLS-1$; <|endfocus|> private static final int TYPEID = registerType(TYPE_NAME); private static final LocalSelectionTransfer INSTANCE = new LocalSelectionTransfer(); private ISelection selection; private long selectionSetTime; /** * Only the singleton instance of this class may be used. */ protected LocalSelectionTransfer() { // do nothing } /** * Returns the singleton. * * @return the singleton */ public static LocalSelectionTransfer getTransfer() { return INSTANCE; } /** * Returns the local transfer data. *
<|startcomment|> When one of the arguments is a numeric and none of the arguments is a string literal I don't mind the redundant toString call. That makes it clearer that the operation is not an addition. But that's a matter of preference, of course. <|endcomment|>  private String convertToEditableTimeInterval(String string) { if (string.length() == 0) return string; long value; try { value = Long.parseLong(string); } catch (NumberFormatException e) { value = 0; } if (value == 0) return Long.toString(0); for (int i = 0; i < timeIntervalPrefixes.length - 1; i++) { if (value % timeIntervalScale[i] != 0) <|startfocus|> return value + timeIntervalPrefixes[i]; <|endfocus|> value /= timeIntervalScale[i]; } return value + timeIntervalPrefixes[timeIntervalPrefixes.length - 1]; } private String convertFromEditableTimeInterval(String string) { if (string.length() == 0) return string; for (int i = 1; i < timeIntervalPrefixes.length; i++) { if (string.endsWith(timeIntervalPrefixes[i])) { long value = Long.parseLong(string.substring(0, string.length() - 1)); for (int j = 0; j < i; j++) value *= timeIntervalScale[j]; return Long.toString(value); } }
<|startcomment|> The cast is unnecessary when only toString is used on the object. <|endcomment|>  public String toString() { String rv = "Item "; <|startfocus|> if( parent != null ) { rv = parent.toString() + "."; <|endfocus|> } rv += counter; return rv;
<|startcomment|> Should this check occur earlier? Suppose I have commits C and D (C is a parent of D) and M (M is a merge of D and C). With the code here, when visiting M's parents, we'll 1. Add D to pending 2. Mark C as SEEN, parse it, and skip it. Then when visiting D's parents, we'll 1. Encounter C, which is SEEN, so skip it Thus the first-parent history would look like "M, D" instead of "M, D, C". Intended? (Noticed at https://git.eclipse.org/r/c/143231/6/org.eclipse.jgit/src/org/eclipse/jgit/revwalk/PendingGenerator.java#146) <|endcomment|>  produce = false; else { if (filter.requiresCommitBody()) c.parseBody(walker); produce = filter.include(walker, c); } for (int i = 0; i < c.parents.length; i++) { RevCommit p = c.parents[i]; if ((p.flags & SEEN) != 0) continue; if ((p.flags & PARSED) == 0) p.parseHeaders(walker); p.flags |= SEEN; <|startfocus|> if (firstParent && i > 0) { continue; } <|endfocus|> pending.add(p); } walker.carryFlagsImpl(c); if ((c.flags & UNINTERESTING) != 0) { if (pending.everbodyHasFlag(UNINTERESTING)) { final RevCommit n = pending.peek(); if (n != null && n.commitTime >= last.commitTime) { // This is too close to call. The next commit we // would pop is dated after the last one produced. // We have to keep going to ensure that we carry // flags as much as necessary. //
<|startcomment|> should we move the query adapter types also to the connect? <|endcomment|>  setTypes(queryResp.getQueryResult()); } catch (Exception e) { logger.error(MessageFormat.format(Messages.DTL_QueryFailed, "FB Types")); //$NON-NLS-1$ } } @Override public void createFBInstance(final FBDeploymentData fbData, final Resource res) throws DeploymentException { // check first if FBType exists Map<String, AdapterType> adapters = getAdapterTypes(fbData.getFb().getType().getInterfaceList()); if (!adapters.isEmpty()) { queryAdapterTypes(adapters, res); <|startfocus|> createAdapterTypes(adapters, res); <|endfocus|> } // if the FPType does not exist create it if (!getTypes().contains(fbData.getFb().getType().getName())) { try { createFBType(fbData.getFb().getType(), res); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fbData.getFb().getType().getName())); } } super.createFBInstance(fbData, res); } private static Map<String, AdapterType> getAdapterTypes(InterfaceList interfaceList) {
<|startcomment|> nit: stray whitespace <|endcomment|>  RevCommit a = commit(); RevCommit b1 = commit(a); RevCommit b2 = commit(a); RevCommit c1 = commit(b1); RevCommit c2 = commit(b2); RevCommit d = commit(c1, c2); rw.reset(); rw.setFirstParent(true); markStart(d); assertCommit(d, rw.next()); assertCommit(c1, rw.next()); assertCommit(b1, rw.next()); assertCommit(a, rw.next()); assertNull(rw.next()); } <|startfocus|> <|endfocus|> @Test public void testSecondParentAncestorOfFirstParent() throws Exception { RevCommit a = commit(); RevCommit b = commit(a); RevCommit c = commit(b, a); rw.reset(); rw.setFirstParent(true); markStart(c); assertCommit(c, rw.next()); assertCommit(b, rw.next()); assertCommit(a, rw.next()); assertNull(rw.next()); } @Test public void testFirstParentMultipleOccurrences() throws Exception { RevCommit a = commit(); RevCommit b = commit(a); RevCommit c = commit(b);
<|startcomment|> Should this be final? <|endcomment|>  /** Output may have {@link RevWalk#REWRITE} marked on it. */ static final int HAS_REWRITE = 1 << 1; /** Output needs {@link RewriteGenerator}. */ static final int NEEDS_REWRITE = 1 << 2; /** Topological ordering is enforced (all children before parents). */ static final int SORT_TOPO = 1 << 3; /** Output may have {@link RevWalk#UNINTERESTING} marked on it. */ static final int HAS_UNINTERESTING = 1 << 4; <|startfocus|> protected boolean firstParent; <|endfocus|> protected Generator(boolean firstParent) { this.firstParent = firstParent; } /** * Connect the supplied queue to this generator's own free list (if any). * * @param q * another FIFO queue that wants to share our queue's free list. */ void shareFreeList(BlockRevQueue q) { // Do nothing by default. } /** * Obtain flags describing the output behavior of this generator. *
<|startcomment|> Should it be the responsibility of this method or of the caller to dispose the removed data provider? Whichever option is chosen, perhaps the Javadoc should state the expected behavior. <|endcomment|>  } } return list; } /** * Remove a data provider from the instances * * @param <T> * The type of data provider * @param trace * The trace for which to remove the data provider * @param provider * The data provider to remove * @since 5.1 */ <|startfocus|> public <T extends ITmfTreeDataProvider<? extends ITmfTreeDataModel>> void removeDataProvider(ITmfTrace trace, T provider) { fInstances.remove(trace, provider); <|endfocus|> } } 
<|startcomment|> with my comment below this param can be removed. <|endcomment|> <|startfocus|> private void checkCreateFBType(FB fb, Resource res) { <|endfocus|> // if the FPType does not exist create it if (!getTypes().contains(fb.getType().getName())) { try { createFBType(fb.getType(), res); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fb.getType().getName())); } } 
<|startcomment|> the base class of this class has a getDevice() with that you can remove the res parameter. the same is possible with creatFBTypesOfCFB <|endcomment|>  // if the FPType does not exist create it if (!getTypes().contains(fb.getType().getName())) { try { createFBType(fb.getType(), res); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fb.getType().getName())); } } } <|startfocus|> public void createFBType(final FBType fbType, final Resource res) throws DeploymentException { setAttribute(res.getDevice(), "FBType", getTypes()); //$NON-NLS-1$ <|endfocus|> if (fbType instanceof BasicFBType || fbType instanceof CompositeFBType) { if (fbType instanceof CompositeFBType) { createFBTypesOfCFB(fbType, res); } String request = createLuaRequestMessage(fbType); sendCreateFBTypeREQ(fbType, request); } } private void sendCreateFBTypeREQ(final FBType fbType, String request) throws DeploymentException { try { String result = sendREQ("", request); //$NON-NLS-1$ if (result.contains("Reason")) { //$NON-NLS-1$
<|startcomment|> I think that you should check for fFormatterOptions being null and if true, call rewrite.rewriteAST() as the old code did. Otherwise, make the new call. That may explain your catch below. <|endcomment|>  addLocalDeclarationSplit(rewrite); else addLocalDeclarationRemoval(rewrite); if (fInitializeIn == INITIALIZE_IN_CONSTRUCTOR) addInitializersToConstructors(rewrite); addTempRenames(rewrite); addFieldDeclaration(rewrite); CompilationUnitChange result= new CompilationUnitChange(RefactoringCoreMessages.PromoteTempToFieldRefactoring_name, fCu); result.setDescriptor(new RefactoringChangeDescriptor(getRefactoringDescriptor())); TextEdit resultingEdits; <|startfocus|> Map<String, String> formatter= (this.fFormatterOptions == null) ? fCu.getJavaProject().getOptions(true) : this.fFormatterOptions; try { resultingEdits= rewrite.rewriteAST(new Document(fCu.getSource()), formatter); } catch (JavaModelException e) { <|endfocus|> resultingEdits= rewrite.rewriteAST(); } TextChangeCompatibility.addTextEdit(result, RefactoringCoreMessages.PromoteTempToFieldRefactoring_editName, resultingEdits); return result; } finally { pm.done(); } } private void addTempRenames(ASTRewrite rewrite) { boolean noNameChange= fFieldName.equals(fTempDeclarationNode.getName().getIdentifier()); if (fLinkedProposalModel == null && noNameChange) { return; // no changes needed }
<|startcomment|> The ASTRewrite.rewriteAST(document, options) method is not marked as throwing JavaModelException while rewriteAST() is. Why do you reattempt after failure and not simply let the exception occur? <|endcomment|>  addInitializersToConstructors(rewrite); addTempRenames(rewrite); addFieldDeclaration(rewrite); CompilationUnitChange result= new CompilationUnitChange(RefactoringCoreMessages.PromoteTempToFieldRefactoring_name, fCu); result.setDescriptor(new RefactoringChangeDescriptor(getRefactoringDescriptor())); TextEdit resultingEdits; Map<String, String> formatter= (this.fFormatterOptions == null) ? fCu.getJavaProject().getOptions(true) : this.fFormatterOptions; try { resultingEdits= rewrite.rewriteAST(new Document(fCu.getSource()), formatter); } catch (JavaModelException e) { <|startfocus|> resultingEdits= rewrite.rewriteAST(); <|endfocus|> } TextChangeCompatibility.addTextEdit(result, RefactoringCoreMessages.PromoteTempToFieldRefactoring_editName, resultingEdits); return result; } finally { pm.done(); } } private void addTempRenames(ASTRewrite rewrite) { boolean noNameChange= fFieldName.equals(fTempDeclarationNode.getName().getIdentifier()); if (fLinkedProposalModel == null && noNameChange) { return; // no changes needed } TempOccurrenceAnalyzer analyzer= new TempOccurrenceAnalyzer(fTempDeclarationNode, false); analyzer.perform();
<|startcomment|> curly brackets not needed here @SuppressWarnings("rawtypes") <|endcomment|>  * <code>ILabelProvider</code>. If it is an * <code>ITableLabelProvider</code>, then it provides a separate label * text and image for each column. If it is an <code>ILabelProvider</code>, * then it provides only the label text and image for the first column, and * any remaining columns are blank. */ @Override public IBaseLabelProvider getLabelProvider() { return super.getLabelProvider(); } <|startfocus|> @SuppressWarnings({ "rawtypes" }) <|endfocus|> @Override protected List getSelectionFromWidget() { if (virtualManager != null) { return getVirtualSelection(); } Widget[] items = doGetSelection(); List<Object> list = new ArrayList<>(items.length); for (Widget item : items) { Object e = item.getData(); if (e != null) { list.add(e); } } return list; } /** * Get the virtual selection. Avoid calling SWT whenever possible to prevent * extra widget creation. * * @return List of Object */ 
<|startcomment|> curly brackets not needed here @SuppressWarnings("rawtypes") <|endcomment|>  Policy.getLog().log( new Status(IStatus.WARNING, Policy.JFACE, message, new RuntimeException())); return; } } } } /** * Returns all selected items for the given SWT control. * * @param control * the control * @return the list of selected items */ protected abstract Item[] getSelection(Control control); <|startfocus|> @SuppressWarnings({ "rawtypes" }) <|endfocus|> @Override protected List getSelectionFromWidget() { Widget[] items = getSelection(getControl()); List<Object> list = new ArrayList<>(items.length); for (Widget item : items) { Object e = item.getData(); if (e != null) { list.add(e); } } return list; } /* * Overridden in AbstractTreeViewer to fix bug 108102 (code copied from * StructuredViewer to avoid introducing new API) */ @Override protected void handleDoubleSelect(SelectionEvent event) { // handle case where an earlier selection listener disposed the control. Control control = getControl();
<|startcomment|> this change does not seem to be needed it would create 2 lists, where just an array-to-list conversion is needed <|endcomment|>  protected void setSelectionToWidget(ISelection selection, boolean reveal) { if (selection instanceof ITreeSelection) { ITreeSelection treeSelection = (ITreeSelection) selection; <|startfocus|> setSelectionToWidget(new ArrayList<Object>(Arrays.asList(treeSelection.getPaths())), reveal); <|endfocus|> } else { super.setSelectionToWidget(selection, reveal); }
<|startcomment|> this file does not contain a real change disappeared by rebase? please remove this file from the change set <|endcomment|>  * are made available under the terms of the Eclipse Public License 2.0 * which accompanies this distribution, and is available at * https://www.eclipse.org/legal/epl-2.0/ * * SPDX-License-Identifier: EPL-2.0 * * Contributors: <|startfocus|> * IBM Corporation - initial API and implementation * Oakland Software (Francis Upton - francisu@ieee.org) * bug 197113 Project Explorer drag and drop selection not working properly * Alexander Fedorov <alexander.fedorov@arsysop.ru> - Bug 548314 <|endfocus|> *******************************************************************************/ package org.eclipse.ui.navigator; import java.util.ArrayList; import java.util.Iterator; import java.util.List; import org.eclipse.jface.viewers.IBaseLabelProvider; import org.eclipse.jface.viewers.ISelection; import org.eclipse.jface.viewers.IStructuredSelection; import org.eclipse.jface.viewers.LabelProviderChangedEvent; import org.eclipse.jface.viewers.StructuredSelection; import org.eclipse.jface.viewers.TreeViewer; import org.eclipse.jface.viewers.ViewerSorter; import org.eclipse.swt.dnd.DND; import org.eclipse.swt.events.DisposeEvent; import org.eclipse.swt.events.MouseAdapter; import org.eclipse.swt.events.MouseEvent;
<|startcomment|> sorry for bothering again but I think here you could already use FBType here. <|endcomment|> <|startfocus|> private void checkCreateFBType(FB fb) { <|endfocus|> // if the FPType does not exist create it if (!getTypes().contains(fb.getType().getName())) { try { createFBType(fb.getType()); } catch (DeploymentException ce) { logger.error(MessageFormat.format(Messages.DTL_CreateTypeFailed, fb.getType().getName())); } } 
<|startcomment|> same question here: is this limitation to AutomationSystem wanted nad/or necessary? What if a user has also other types of projects open, e.g. as part of a research prototype? <|endcomment|>  private static List<IProject> getSelectedProjects(ISelection selection) { List<IProject> projectSelection = new ArrayList<>(); if (selection instanceof IStructuredSelection) { for (Object element : ((StructuredSelection) selection).toList()) { if (element instanceof AutomationSystem) { <|startfocus|> projectSelection.add(((AutomationSystem) element).getProject()); <|endfocus|> } } } return projectSelection;
<|startcomment|> do we need this? <|endcomment|>  public void reveal() { <|startfocus|> // resolved.ifPresent(RevealStep::reveal); <|endfocus|>
<|startcomment|> I'd rather see this method return a Collection<LSBasedHyperlink> <|endcomment|> <|startfocus|> private static void collectHyperlinks(final IDocument document, final IRegion linkRegion, Either<List<? extends Location>, List<? extends LocationLink>> locations, Collection<LSBasedHyperlink> allLinks) { <|endfocus|> if (locations == null) { return; } else if (locations.isLeft()) { allLinks.addAll(locations.getLeft().stream().filter(Objects::nonNull).map(location -> new LSBasedHyperlink(location, linkRegion)).collect(Collectors.toList())); } else { allLinks.addAll( locations.getRight().stream().filter(Objects::nonNull).map(locationLink -> { IRegion selectionRegion = linkRegion; Range originSelectionRange = locationLink.getOriginSelectionRange(); if (originSelectionRange != null) { try { int offset = LSPEclipseUtils .toOffset(originSelectionRange.getStart(), document); int endOffset = LSPEclipseUtils .toOffset(originSelectionRange.getEnd(), document); selectionRegion = new Region(offset, endOffset - offset); } catch (BadLocationException e) { LanguageServerPlugin.logError(e.getMessage(), e); } }
<|startcomment|> remove <|endcomment|>  protected void addChildVisual(final EditPart childEditPart, final int index) { boolean visible = true; if (childEditPart instanceof InterfaceEditPart) { IInterfaceElement iElement = ((InterfaceEditPart) childEditPart).getModel(); if (iElement instanceof AdapterDeclaration){ //if we are in a subapptype we want to show the adapter as type interface element visible = isVarVisible(); } } EditPart refEditPart = null; <|startfocus|> if(index < getChildren().size()){ refEditPart = (EditPart)getChildren().get(index); <|endfocus|> } if (childEditPart instanceof InterfaceEditPart) { IFigure child = ((GraphicalEditPart) childEditPart).getFigure(); if (((InterfaceEditPart) childEditPart).getModel().isIsInput()) { if (((InterfaceEditPart) childEditPart).isEvent()) { insertChild(getLeftEventInterfaceContainer(), refEditPart, child); } else { if (visible) { // add adapter interface elemetns directly to the container and set them to visible = false insertChild(getLeftVarInterfaceContainer(), refEditPart, child);
<|startcomment|> it would be better readable if this would be as whole moved to the isVarVisible function. <|endcomment|>  protected void removeChildVisual(final EditPart childEditPart) { boolean visible = true; if (childEditPart.getModel() instanceof AdapterDeclaration) { visible = isVarVisible(); <|startfocus|> } <|endfocus|> if (childEditPart instanceof InterfaceEditPart){ if (((InterfaceEditPart) childEditPart).getModel().isIsInput()) { IFigure child = ((GraphicalEditPart) childEditPart).getFigure(); if (((InterfaceEditPart) childEditPart).isEvent()) { getLeftEventInterfaceContainer().remove(child); } else { if (visible) { getLeftVarInterfaceContainer().remove(child); } else{ getLeftInterfaceContainer().remove(child); } } } else { IFigure child = ((GraphicalEditPart) childEditPart).getFigure(); if (((InterfaceEditPart) childEditPart).isEvent()) { getRightEventInterfaceContainer().remove(child); } else { if (visible) { getRightVarInterfaceContainer().remove(child); } else { getRightInterfaceContainer().remove(child); } } } } else { super.removeChildVisual(childEditPart); }
<|startcomment|> Should be private with a synchronized setter. The setter should clear the cache when it is disabled. <|endcomment|> import org.eclipse.emf.ecore.EObject; import org.eclipse.emf.ecore.EStructuralFeature; import org.eclipse.emf.ecore.InternalEObject; import org.eclipse.emf.ecore.resource.Resource; import com.google.common.base.Objects; /** * An helper to check EObject equality.</br> * It extends and override EcoreUtil.EqualityHelper so that equals methods ignore EAttribute that are ID=true. * * @author mchauvin */ public final class EqualityHelper extends org.eclipse.emf.ecore.util.EcoreUtil.EqualityHelper { <|startfocus|> public static boolean enableUriFragmentCache = false; <|endfocus|> private static final Map<EObject, String> eUriFragmentCache = new HashMap<>(); private static final Map<EObject, EObject> eUriFragmentContainerCache = new HashMap<>(); private static final Map<EObject, EStructuralFeature> eUriFragmentContainingFeatureCache = new HashMap<>(); @Override protected boolean haveEqualAttribute(EObject eObject1, EObject eObject2, EAttribute attribute) { boolean isID = attribute.isID(); return isID || super.haveEqualAttribute(eObject1, eObject2, attribute); } /**
<|startcomment|> known <|endcomment|>  } /** * Check if a diagram element is in an activated layer or not and visible. * * @param session * the current session. * @param element * the diagram element. * @param parentDiagram * the parent diagram of the diagram element. This information can be retrieved from the diagram element <|startfocus|> * but sometimes it is already kown by the caller or it can be null (during drag'n'drop of element with <|endfocus|> * bordered nodes for example : PortLocationAfterDragAndDropTest. * testPortLocationFromParentDnDFromModelExplorerView()) this method is called before setting all parents * hierarchy of diagram element. * @return <code>true</code> if it is, <code>false</code> otherwise */ public static boolean isInActivatedLayer(DiagramMappingsManager session, final DDiagramElement element, final DDiagram parentDiagram) { final DiagramElementMapping mapping = element.getDiagramElementMapping(); if (!LayerHelper.withoutLayersMode(mapping)) { final DDiagram diagram; if (parentDiagram != null) { diagram = parentDiagram;
<|startcomment|> non-boolean return type <|endcomment|>  */ boolean reveal(EObject object, EStructuralFeature feature); /** * Attempt to reveal an {@code object} in the most appropriate (by best effort) * control within the given {@code scope}. * * @param object an object to reveal * @param scope a control within which to attempt to reveal the {@code object} * <|startfocus|> * @return {@code true} if the {@code object} was revealed; {@code false}, otherwise <|endfocus|> */ RevealStep reveal(EObject object, VElement scope); /** * Attempt to reveal a {@code feature} of an {@code object} in the most appropriate * (by best effort) control within the given {@code scope}. * * @param object an object to reveal * @param feature a specific feature (implying a detail control) to reveal * @param scope a control within which to attempt to reveal the {@code object} *
<|startcomment|> non-boolean return type <|endcomment|>  /** * Attempt to reveal a {@code feature} of an {@code object} in the most appropriate * (by best effort) control within the given {@code scope}. * * @param object an object to reveal * @param feature a specific feature (implying a detail control) to reveal * @param scope a control within which to attempt to reveal the {@code object} * <|startfocus|> * @return {@code true} if the {@code object} was revealed; {@code false}, otherwise <|endfocus|> */ RevealStep reveal(EObject object, EStructuralFeature feature, VElement scope); /** * Register a reveal provider. * * @param provider the reveal provider to register */ void addRevealProvider(EMFFormsRevealProvider provider); /** * Unregister a reveal provider. * * @param provider the reveal provider to unregister */ void removeRevealProvider(EMFFormsRevealProvider provider); } 
<|startcomment|> I suggest to make a comment here, referring to '_cairo_color_double_to_short' and 'color_to_pixel' in Cairo <|endcomment|> public int getRed() { <|startfocus|> if (isDisposed()) SWT.error(SWT.ERROR_GRAPHIC_DISPOSED); <|endfocus|> int r = (((int)(handle.red * 65535.0 + 0.5)) >> 8); return Math.min(r, 255);
<|startcomment|> In "Red vs Blue", fans of Blue will sue you for discrimination :) <|endcomment|> public int getRed() { <|startfocus|> if (isDisposed()) SWT.error(SWT.ERROR_GRAPHIC_DISPOSED); <|endfocus|> int r = (((int)(handle.red * 65535.0 + 0.5)) >> 8); return Math.min(r, 255);
<|startcomment|> Is there a reason for using stringbuffer instead of stringbuilder? <|endcomment|>  buf.append(" System.out.println(list.get(i));\n"); buf.append(" }\n"); buf.append(" }\n"); buf.append("}\n"); ICompilationUnit cu= pack1.createCompilationUnit("A.java", buf.toString(), false, null); List<IJavaCompletionProposal> proposals= fetchConvertingProposal(buf, cu); assertNotNull(fConvertLoopProposal); String preview1= getPreviewContent(fConvertLoopProposal); <|startfocus|> buf= new StringBuffer(); <|endfocus|> buf.append("package test1;\n"); buf.append("public class A {\n"); buf.append(" public void foo() {\n"); buf.append(" java.util.List list = new ArrayList();\n"); buf.append(" list.add(null);\n"); buf.append(" for (Object element : list) {\n"); buf.append(" System.out.println(element);\n"); buf.append(" }\n"); buf.append(" }\n"); buf.append("}\n"); String expected= buf.toString(); assertEqualString(preview1, expected); assertCorrectLabels(proposals); assertCorrectLabels(proposals); } 
<|startcomment|> no need for this commenting out <|endcomment|>  StaticProfileTest.class, DynamicProfileTest.class, StaticStereotypeTest.class, StaticStereotypedElementChangeTests.class, DynamicStereotypeTest.class, DynamicStereotypedElementChangeTests.class, ImplicationsAssociationTest.class, ImplicationsTransitionTest.class, ImplicationsInterfaceRealizationTest.class, StaticStereotypedElementItemProviderTest.class, DynamicStereotypedElementItemProviderTest.class, OpaqueElementBodyChangeDiffTest.class, OpaqueElementBodyChangeMergeTest.class, DanglingStereotypeApplicationTest.class, TestNonRegPseudoConflict_484576.class, RemoveStereotypeApplicationPseudoConflictTest.class, MultiplicityElementChangesTest.class, InstanceSpecificationClassifiersMergeTest.class, AddMessageSubDiffTest.class, <|startfocus|> StereotypeApplicationConflictTests.class, // }) <|endfocus|> public class AllTests { /** * Standalone launcher for all of compare's tests. * * @generated */ public static void main(String[] args) { TestRunner.run(suite()); } /** * This will return a suite populated with all tests available through this class. * * @generated */ public static Test suite() { return new JUnit4TestAdapter(AllTests.class); } } 
<|startcomment|> Let's try and avoid guava <|endcomment|> ***************************************************************************** * Copyright (c) 2014, 2017 Obeo and others. * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Obeo - initial API and implementation * Christian W. Damus - bug 522080 *******************************************************************************/ package org.eclipse.emf.compare.uml2.internal.postprocessor; <|startfocus|> import com.google.common.collect.Maps; <|endfocus|> import java.util.Iterator; import java.util.Map; import org.eclipse.emf.common.util.Monitor; import org.eclipse.emf.common.util.URI; import org.eclipse.emf.compare.Comparison; import org.eclipse.emf.compare.ComparisonCanceledException; import org.eclipse.emf.compare.Diff; import org.eclipse.emf.compare.Match; import org.eclipse.emf.compare.diff.DefaultDiffEngine; import org.eclipse.emf.compare.diff.FeatureFilter; import org.eclipse.emf.compare.postprocessor.IPostProcessor; import org.eclipse.emf.compare.uml2.internal.postprocessor.extension.stereotype.UMLStereotypedElementChangeFactory;
<|startcomment|> private <|endcomment|> <|startfocus|> static URI getStereotypeURI(EObject stereotypeApplication) { <|endfocus|> return EcoreUtil.getURI(stereotypeApplication.eClass());
<|startcomment|> likewise <|endcomment|>  * the second level key * @param value * the value * @return the previous value for these keys, if or {@code null} if there was none * @param <K> * the top level key type * @param <L> * the second level key type * @param <V> * the value type */ <|startfocus|> static <K, L, V> V put(Map<K, Map<L, V>> mapOfMaps, K key1, L key2, V value) { <|endfocus|> Map<L, V> map = mapOfMaps.get(key1); if (map == null) { map = Maps.newHashMap(); mapOfMaps.put(key1, map); } return map.put(key2, value); } /** * Queries whether an {@code object} is a stereotype application. * * @param object * an object * @return {@code true} if it is a stereotype application; {@code false}, otherwise */ protected boolean isStereotypeApplication(EObject object) {
<|startcomment|> Author? <|endcomment|>  * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Boeing - initial API and implementation *******************************************************************************/ package org.eclipse.ote.simple.oteide.product.load; import java.io.IOException; import java.net.URL; import java.util.ArrayList; import java.util.List; import java.util.logging.Level; import org.eclipse.osee.framework.jdk.core.util.Lib; import org.eclipse.osee.framework.logging.OseeLog; import org.eclipse.ote.services.core.BundleUtility; import org.eclipse.ote.services.core.LoadBundleProvider; <|startfocus|> <|endfocus|> public class FileProvider implements LoadBundleProvider { @Override public List<String> getBundleSymbolicNames() { List<String> names = new ArrayList<String>(); try { URL entry = BundleUtility.findEntry("org.eclipse.ote.simple.oteide.product.load", "data/precompiledServerBundleList.txt"); String fileContent = Lib.inputStreamToString(entry.openStream()); String[] strNames = fileContent.split("\n"); for(int i = 0; i < strNames.length; i++){
<|startcomment|> Author? <|endcomment|>  import java.util.Dictionary; import java.util.logging.Level; import java.util.regex.Matcher; import java.util.regex.Pattern; import org.eclipse.core.runtime.Platform; import org.eclipse.core.runtime.preferences.IEclipsePreferences; import org.eclipse.core.runtime.preferences.InstanceScope; import org.eclipse.osee.framework.logging.OseeLog; import org.eclipse.ote.services.core.ServiceUtility; import org.eclipse.swt.widgets.Display; import org.eclipse.ui.IStartup; import org.osgi.framework.Bundle; import org.osgi.framework.BundleEvent; import org.osgi.framework.BundleListener; <|startfocus|> <|endfocus|> public class SetTitleBar implements IStartup { @Override public void earlyStartup() { String title = getTitle(); if(title != null) { setTitle(title); } else if(ServiceUtility.getContext() != null){ ServiceUtility.getContext().addBundleListener(new BundleListener() { @Override public void bundleChanged(BundleEvent event) { if(event.getType() == Bundle.ACTIVE){ if(event.getBundle().getSymbolicName().equals("bundle.to.base.off.here")){ String t = getTitle(); if(t != null){
<|startcomment|> Author? <|endcomment|>  import java.io.File; import org.eclipse.core.resources.ResourcesPlugin; import org.eclipse.jface.action.Action; import org.eclipse.jface.action.IContributionItem; import org.eclipse.swt.program.Program; import org.eclipse.swt.widgets.Display; import org.eclipse.ui.IPartListener; import org.eclipse.ui.IViewPart; import org.eclipse.ui.IViewReference; import org.eclipse.ui.IWorkbenchPage; import org.eclipse.ui.IWorkbenchPart; import org.eclipse.ui.IWorkbenchWindow; import org.eclipse.ui.PlatformUI; import org.eclipse.ui.part.ViewPart; import org.eclipse.ui.texteditor.StatusLineContributionItem; <|startfocus|> <|endfocus|> public class WorkspaceStatusLineContributionItem { private static String ID = "org.eclipse.ote.simple.oteide.product.load"; private String shortText; private StatusLineContributionItem item; private String path; public WorkspaceStatusLineContributionItem() { path = ResourcesPlugin.getWorkspace().getRoot().getLocation().toString(); shortText = getShortPath(path); item = new StatusLineContributionItem(ID, true, shortText.length()); } private static String getShortPath(String path) {
<|startcomment|> called to <|endcomment|>  } } else { uriFragment = container.eURIFragmentSegment(eContainingFeature, eObj); } return uriFragment; } private static boolean sameType(EObject eObj1, EObject eObj2) { return eObj1 != null && eObj2 != null && eObj1.getClass() == eObj2.getClass(); } /** <|startfocus|> * Enable or disable the ability to cache the computed values. The cache is cleared when this method is calle dot <|endfocus|> * disable the cache. * * @param enable * <code>true</code> to allow this helper to put the computed values in a cache, <code>false</code> * otherwise. */ public static synchronized void setUriFragmentCacheEnabled(boolean enable) { enableUriFragmentCache = enable; if (!enable) { E_URI_FRAGMENT_CACHE.clear(); } } private static class Record { private final String uriFragment; private final EObject eContainer; private final EStructuralFeature containingFeature; Record(String uriFragment, EObject container, EStructuralFeature containingFeature) { this.uriFragment = uriFragment;
<|startcomment|> The system property depends on the server's system, not on the client's. I think it would be better to explicitly use "\n" to provide a defined and stable API. <|endcomment|>  * return BEANS.get(ApiDocGenerator.class).getWebContent(staticResource); * } * </pre> */ @ApplicationScoped public class ApiDocGenerator { /** * Query parameter for static resource file names. This is used by HTML content generated by * {@link #getWebContent(String)}. */ public static final String STATIC_RESOURCE_PARAM = "r"; protected static final String TEXT_ELEMENT_SEPARATOR = "\t"; <|startfocus|> protected static final String TEXT_LINE_SEPARATOR = System.getProperty("line.separator"); <|endfocus|> public List<ResourceDescriptor> getResourceDescriptors() { return BEANS.all(IRestResource.class).stream() .filter(this::acceptRestResource) .sorted(Comparator.comparing(res -> res.getClass().getSimpleName())) .sorted(Comparator.comparing(res -> "/" + getPath(res))) .map(this::toResourceDescriptor) .filter(Objects::nonNull) .collect(Collectors.toList()); } protected ResourceDescriptor toResourceDescriptor(IRestResource resource) { String resourcePath = "/" + getPath(resource);
<|startcomment|> It would be nice if we didn't need two pre-computed strings on this descriptor. Maybe some kind of lambda-based mechanism could be used? I think of a method getDescription(boolean asHtml) that then passes this boolean to a function. (Didn't think it through yet.) <|endcomment|>  sb.append(TEXT_ELEMENT_SEPARATOR); sb.append(StringUtility.emptyIfNull(m.getProduces())); sb.append(TEXT_ELEMENT_SEPARATOR); sb.append(m.getDescriptionText()); sb.append(TEXT_LINE_SEPARATOR); }); }); return sb.toString(); } public static class ResourceDescriptor { private IRestResource m_resource; private String m_path; private String m_basePath; // first segment of "path" private String m_name; private String m_anchor; <|startfocus|> private String m_descriptionHtml; private String m_descriptionText; <|endfocus|> private List<MethodDescriptor> m_methods; public IRestResource getResource() { return m_resource; } public ResourceDescriptor withResource(IRestResource resource) { m_resource = resource; return this; } public String getPath() { return m_path; } public ResourceDescriptor withPath(String path) { m_path = path; return this; } public String getBasePath() { return m_basePath; } public ResourceDescriptor withBasePath(String basePath) { m_basePath = basePath;
<|startcomment|> Members should be private. Provide getter/setters if needed. You could also implement a protected handleTableEvent method and call it in the tableChanged method, so a subclass could override the default implementation. <|endcomment|> import org.eclipse.scout.rt.shared.AbstractIcons; import org.eclipse.scout.rt.shared.data.basic.FontSpec; import org.eclipse.scout.rt.shared.services.lookup.ILookupCall; import org.eclipse.scout.rt.shared.services.lookup.ILookupRow; import org.eclipse.scout.rt.shared.services.lookup.LocalLookupCall; import org.eclipse.scout.rt.shared.services.lookup.LookupRow; @ClassId("c6ee18fd-e630-4d92-81b1-cd0147c902d4") public class DefaultTileTableHeaderBox extends AbstractGroupBox implements ITileTableHeaderBox { <|startfocus|> protected TableListener m_tableListener; protected boolean m_isGrouping; protected boolean m_isSorting; <|endfocus|> protected TableListener createTableListener() { return new TableAdapter() { @Override public void tableChanged(TableEvent e) { switch (e.getType()) { case TableEvent.TYPE_COLUMN_HEADERS_UPDATED: syncSortingGroupingFields(); break; } } }; } protected void syncSortingGroupingFields() { try { // don't call execChangedValue since it would trigger sort/group again getSortByField().setValueChangeTriggerEnabled(false);
<|startcomment|> Same two lines for if/else case, move out of if/else statement <|endcomment|>  protected void execChangedValue() { try { m_isGrouping = true; if (getValue() == null) { getTable().getColumnSet().removeGroupColumn(CollectionUtility.firstElement(getTable().getColumnSet().getGroupedColumns())); <|startfocus|> ClientUIPreferences.getInstance().setAllTableColumnPreferences(getTable()); getTable().sort(); <|endfocus|> } else { getTable().getColumnSet().handleGroupingEvent(getValue(), false, true); ClientUIPreferences.getInstance().setAllTableColumnPreferences(getTable()); getTable().sort(); } } finally { m_isGrouping = false; }
<|startcomment|> See comment above <|endcomment|>  protected void execChangedValue() { try { m_isSorting = true; if (getValue() == null) { getTable().getColumnSet().removeSortColumn(CollectionUtility.firstElement(getTable().getColumnSet().getSortColumns())); <|startfocus|> ClientUIPreferences.getInstance().setAllTableColumnPreferences(getTable()); getTable().sort(); <|endfocus|> } else { getTable().getColumnSet().handleSortEvent(getValue().getLeft(), false, getValue().getRight()); ClientUIPreferences.getInstance().setAllTableColumnPreferences(getTable()); getTable().sort(); } } finally { m_isSorting = false; }
<|startcomment|> rename to m_httpStatus <|endcomment|>  * BSI Business Systems Integration AG - initial API and implementation ******************************************************************************/ package org.eclipse.scout.rt.rest.error; import javax.ws.rs.core.MediaType; import javax.ws.rs.core.Response; import javax.ws.rs.core.Response.Status; import org.eclipse.scout.rt.platform.BEANS; import org.eclipse.scout.rt.platform.Bean; import org.eclipse.scout.rt.platform.context.CorrelationId; /** * Builder for {@link ErrorDo} and {@link ErrorResponse} objects. */ @Bean public class ErrorResponseBuilder { <|startfocus|> private int m_status; private String m_code; <|endfocus|> private String m_title; private String m_message; public ErrorResponseBuilder withStatus(int status) { m_status = status; return this; } public ErrorResponseBuilder withStatus(Status status) { m_status = status.getStatusCode(); return this; } public ErrorResponseBuilder withTitle(String title) { m_title = title; return this; } public ErrorResponseBuilder withMessage(String message) { m_message = message; return this; } public ErrorResponseBuilder withCode(int code) {
<|startcomment|> rename to m_errorCode <|endcomment|>  ******************************************************************************/ package org.eclipse.scout.rt.rest.error; import javax.ws.rs.core.MediaType; import javax.ws.rs.core.Response; import javax.ws.rs.core.Response.Status; import org.eclipse.scout.rt.platform.BEANS; import org.eclipse.scout.rt.platform.Bean; import org.eclipse.scout.rt.platform.context.CorrelationId; /** * Builder for {@link ErrorDo} and {@link ErrorResponse} objects. */ @Bean public class ErrorResponseBuilder { <|startfocus|> private int m_status; private String m_code; <|endfocus|> private String m_title; private String m_message; public ErrorResponseBuilder withStatus(int status) { m_status = status; return this; } public ErrorResponseBuilder withStatus(Status status) { m_status = status.getStatusCode(); return this; } public ErrorResponseBuilder withTitle(String title) { m_title = title; return this; } public ErrorResponseBuilder withMessage(String message) { m_message = message; return this; } public ErrorResponseBuilder withCode(int code) { m_code = String.valueOf(code); return this; }
<|startcomment|> rename to withHttpStatus <|endcomment|> <|startfocus|> public ErrorResponseBuilder withStatus(int status) { m_status = status; <|endfocus|> return this;
<|startcomment|> rename to withErrorCode <|endcomment|> <|startfocus|> public ErrorResponseBuilder withCode(int code) { m_code = String.valueOf(code); <|endfocus|> return this;
<|startcomment|> rename to withErrorCode <|endcomment|> <|startfocus|> public ErrorResponseBuilder withCode(String code) { m_code = code; <|endfocus|> return this;
<|startcomment|> I think this string should also be externalized. <|endcomment|>  @Override public Object execute(ExecutionEvent event) throws ExecutionException { Shell activeShell= HandlerUtil.getActiveShell(event); Object newNameValue= HandlerUtil.getVariable(event, LTK_RENAME_COMMAND_NEWNAME_PARAMETER_KEY); String newName= null; if (newNameValue instanceof String) { newName= (String) newNameValue; <|startfocus|> } else { RefactoringUIPlugin.logErrorMessage("Rename refactoring command new name parameter, expected String but got a " + newNameValue.getClass().getName()); //$NON-NLS-1$ <|endfocus|> } ISelection sel= HandlerUtil.getCurrentSelection(event); if (sel instanceof IStructuredSelection) { IResource resource= getCurrentResource((IStructuredSelection) sel); if (resource != null) { RenameResourceWizard refactoringWizard; if (newName != null) { refactoringWizard= new RenameResourceWizard(resource, newName); } else { refactoringWizard= new RenameResourceWizard(resource); } RefactoringWizardOpenOperation op= new RefactoringWizardOpenOperation(refactoringWizard); try { op.run(activeShell, RefactoringUIMessages.RenameResourceHandler_title); } catch (InterruptedException e) { // do nothing } } } return null; } 
<|startcomment|> Is this change necessary? Seems like you're just breaking it up but it's not any different in functionality from how it was before. <|endcomment|>  protected void addUserInputPages() { RenameResourceProcessor processor= getRefactoring().getAdapter(RenameResourceProcessor.class); <|startfocus|> RenameResourceRefactoringConfigurationPage page= new RenameResourceRefactoringConfigurationPage(processor); addPage(page); <|endfocus|>
<|startcomment|> Also here. <|endcomment|>  @Override public Object execute(ExecutionEvent event) throws ExecutionException { Shell activeShell= HandlerUtil.getActiveShell(event); Object newNameValue= HandlerUtil.getVariable(event, LTK_RENAME_COMMAND_NEWNAME_PARAMETER_KEY); String newName= null; if (newNameValue instanceof String) { newName= (String) newNameValue; } else if (newNameValue != null) { <|startfocus|> RefactoringUIPlugin.logErrorMessage(RefactoringUIMessages.RenameResourceHandler_ERROR_EXPECTED_STRING + newNameValue.getClass().getName()); <|endfocus|> } ISelection sel= HandlerUtil.getCurrentSelection(event); if (sel instanceof IStructuredSelection) { IResource resource= getCurrentResource((IStructuredSelection) sel); if (resource != null) { RenameResourceWizard refactoringWizard; if (newName != null) { refactoringWizard= new RenameResourceWizard(resource, newName); } else { refactoringWizard= new RenameResourceWizard(resource); } RefactoringWizardOpenOperation op= new RefactoringWizardOpenOperation(refactoringWizard); try { op.run(activeShell, RefactoringUIMessages.RenameResourceHandler_title); } catch (InterruptedException e) { // do nothing } } } return null; } 
<|startcomment|> a More descriptive name what kind of cell modifier it is would be nice <|endcomment|>  inputViewer.setInput(getType()); commandStack = commandStackBuffer; } }); } } private ChangeNameCommand getRenameCommand(String newValue) { INamedElement element = getType(); if (element instanceof FBNetworkElement) { return new ChangeFBNetworkElementName((FBNetworkElement) element, newValue); } return new ChangeNameCommand(getType(), nameText.getText()); } <|startfocus|> private class CellModifier implements ICellModifier { <|endfocus|> @Override public boolean canModify(final Object element, final String property) { return (VALUE_PROPERTY.equals(property) || COMMENT_PROPERTY.equals(property)); } @Override public Object getValue(final Object element, final String property) { switch (property) { case VALUE_PROPERTY: return getVarDeclarationValue((VarDeclaration) element); case COMMENT_PROPERTY: return ((INamedElement) element).getComment() != null ? ((INamedElement) element).getComment() : ""; //$NON-NLS-1$ default: return null; } } @Override public void modify(final Object element, final String property, final Object value) {
<|startcomment|> would it make sense to move this class to the org.eclipse.fordiac.ide.gef.properties to have all the properties together in one place? <|endcomment|> import org.eclipse.fordiac.ide.model.commands.change.ChangeCommentCommand; import org.eclipse.fordiac.ide.model.commands.change.ChangeNameCommand; import org.eclipse.fordiac.ide.model.libraryElement.Device; import org.eclipse.gef.EditPart; import org.eclipse.swt.SWT; import org.eclipse.swt.events.SelectionAdapter; import org.eclipse.swt.events.SelectionEvent; import org.eclipse.swt.layout.GridData; import org.eclipse.swt.layout.GridLayout; import org.eclipse.swt.widgets.Button; import org.eclipse.swt.widgets.Combo; import org.eclipse.swt.widgets.Composite; <|startfocus|> <|endfocus|> public class DeviceSection extends AbstractDevResInterfaceSection { protected static String[] profileNames = null; protected Combo profile; protected Button getResources; @Override public void refresh() { super.refresh(); if (null != type) { setProfile(); getResources.setEnabled("DynamicTypeLoad".equals(((Device) getType()).getProfile())); } } private void setProfile() { int i = 0; for (String p : profile.getItems()) { if (p.equals(((Device) getType()).getProfile())) { profile.select(i); break;
<|startcomment|> should be Committing branch, not creating <|endcomment|>  teamArt.getAtsId()); } // Confirm that all blocking reviews are completed // Loop through this state's blocking reviews to confirm complete if (teamArt.isTeamWorkflow()) { for (IAtsAbstractReview review : ReviewManager.getReviewsFromCurrentState(teamArt)) { AbstractReviewArtifact reviewArt = (AbstractReviewArtifact) AtsClientService.get().getQueryService().getArtifact(review); if (reviewArt.getReviewBlockType() == ReviewBlockType.Commit && !reviewArt.isCompletedOrCancelled()) { <|startfocus|> AWorkbench.popup("Create Branch Error!", "All blocking reviews must be completed before creating a new branch. Please complete all blocking reviews in order to continue."); <|endfocus|> return; } } } if (!overrideStateValidation) { final MutableBoolean adminOverride = new MutableBoolean(false); // Check extension points for valid commit for (IAtsStateItem item : AtsStateItemManager.getStateItems()) { final Result tempResult = item.committing(teamArt); if (tempResult.isFalse()) { // Allow Admin to override state validation
<|startcomment|> Richard, what about this call during construction, do we still need it? <|endcomment|>  null); // private Collection derivedEntities; @Override public String getMarkingTag() { return ManagedEntityArtifact.MARKING_TAG; } @Override public IAbstractArtifactInternal getModel() { return MODEL; } public String getLabel() { return getMetadata().getLabel(this); } // public Collection getDerivedEntities() { // return this.derivedEntities; // } // public ManagedEntityArtifact(ArtifactManager artifactMgr) { super(artifactMgr); <|startfocus|> // this.derivedEntities = new ArrayList(); <|endfocus|> setIStandardSpecifics(new OssjEntitySpecifics(this)); } @Override public IAbstractArtifactInternal extractFromClass(JavaClass javaClass, ArtifactManager artifactMgr, IProgressMonitor monitor) { ManagedEntityArtifact result = new ManagedEntityArtifact(javaClass, artifactMgr, monitor); return result; } public ManagedEntityArtifact(JavaClass javaClass, ArtifactManager artifactMgr, IProgressMonitor monitor) { super(javaClass, artifactMgr, monitor); // this.derivedEntities = new ArrayList(); OssjEntitySpecifics specifics = new OssjEntitySpecifics(this); specifics.build(); setIStandardSpecifics(specifics); } // @Override // public void resolveReferences(IProgressMonitor monitor)
<|startcomment|> I understand that this is copy&pasted from other places. 'RegQueryValueEx' is usually called two times to measure the amount of memory needed, then allocate and query actual contents. We already know we're expecting a DWORD here, so just set lpcbData[0] to 4 and remove highlighted code. PS: It's a good idea to extract a function from this, like OS.readRegistryDword(OS.HKEY_CURRENT_USER, "Software\\Microsoft\\Windows\\CurrentVersion\\Themes\\Personalize", "AppsUseLightTheme") <|endcomment|>  } else if (OS.RegOpenKeyEx(OS.HKEY_LOCAL_MACHINE, key, 0, OS.KEY_READ, phkResult) == 0) { // Try reading from HKLM regKeyFound = true; } if (regKeyFound) { int [] lpcbData = new int [1]; TCHAR buffer = new TCHAR (0, "AppsUseLightTheme", true); //$NON-NLS-1$ int result = OS.RegQueryValueEx (phkResult [0], buffer, 0, null, (TCHAR)null, lpcbData); if (result == 0) { <|startfocus|> int[] lpData = new int[1]; result = OS.RegQueryValueEx(phkResult[0], buffer, 0, null, lpData, lpcbData); if (result == 0) { isDarkTheme = (lpData[0] == 0); } <|endfocus|> } OS.RegCloseKey (phkResult [0]); } } return isDarkTheme;
<|startcomment|> Would it be worthy to mark it already as deprecated? or create already a method with better name? The TODO is easy to miss when we eventually clean up deprecated APIs. <|endcomment|>  * instance is modified to represent a different object name. */ public abstract class AnyObjectId implements Comparable<AnyObjectId> { /** * Compare to object identifier byte sequences for equality. * * @param firstObjectId * the first identifier to compare. Must not be null. * @param secondObjectId * the second identifier to compare. Must not be null. * @return true if the two identifiers are the same. */ <|startfocus|> // TODO (ms): rename in next major release <|endfocus|> @SuppressWarnings("AmbiguousMethodReference") public static boolean equals(final AnyObjectId firstObjectId, final AnyObjectId secondObjectId) { if (firstObjectId == secondObjectId) return true; // We test word 3 first since the git file-based ODB // uses the first byte of w1, and we use w2 as the // hash code, one of those probably came up with these // two instances which we are comparing for equality. // Therefore the first two words are very likely to be
<|startcomment|> IProject.close looks simple bit in fact it involves file system operations and may require some time. So, all the UI event processing will wait for it. Can we do this somewhere outside of UI thread after extracting IProject instance? May be you can open ProgressMonitorDialog using Display.asyncExec? <|endcomment|>  handleMiddleClick(event); }); } private void handleMiddleClick(MouseEvent event) throws CoreException { if (event.button == 2 && event.widget instanceof Tree) { TreeItem item = ((Tree) event.widget).getItem(new Point(event.x, event.y)); if (item == null) { return; } Object data = item.getData(); if (data instanceof IProject) { IProject project = (IProject) data; <|startfocus|> if (project.isOpen()) { project.close(new NullProgressMonitor()); } <|endfocus|> } } } });
<|startcomment|> we could fix this by testing symlink support using a temporary file underneath the .git folder instead of under java.io.tmpdir <|endcomment|>  } @Override public boolean isHidden(File path) throws IOException { return FileUtil.isHidden(path); } @Override public void setHidden(File path, boolean hidden) throws IOException { FileUtil.setHidden(path, hidden); } @Override public String readSymLink(File path) throws IOException { return FileUtil.readSymlink(path); } @Override public void createSymLink(File path, String target) throws IOException { FileUtil.createSymLink(path, target); } /** * @since 3.3 */ @Override public Attributes getAttributes(File path) { <|startfocus|> return FileUtil.getFileAttributesBasic(this, path); <|endfocus|> } } 
<|startcomment|> Should this comment be inside the if-block? <|endcomment|>  RebaseTodoLine line = null; String commentString = RawParseUtils.decode(buf, tokenBegin, lineEnd + 1); try { int skip = tokenBegin + 1; // skip '#' skip = nextParsableToken(buf, skip, lineEnd); if (skip != -1) { // try to parse the line as non-comment line = parseLine(buf, skip, lineEnd); // successfully parsed as non-comment line // mark this line as a comment explicitly <|startfocus|> if (line != null) { <|endfocus|> line.setAction(Action.COMMENT); // use the read line as comment string line.setComment(commentString); } } } catch (Exception e) { // parsing as non-comment line failed line = null; } finally { if (line == null) line = new RebaseTodoLine(commentString); r.add(line); }
<|startcomment|> pls. remove this dead whitespace <|endcomment|>  * @param treeStyle the style bits for the <code>Tree</code> * @param filter the filter to be used * * @deprecated As of 3.116, replaced by * {@link #FilteredTree(Composite, int, PatternFilter, boolean, boolean)} * * */ @Deprecated public FilteredTree(Composite parent, int treeStyle, PatternFilter filter) { super(parent, SWT.NONE); this.parent = parent; init(treeStyle, filter); } <|startfocus|> <|endfocus|> /** * Create a new instance of the receiver. * * <p> * <b>WARNING:</b> Using this constructor results in a slow performing tree and * should not be used if the underlying data model uses a stable and correct * hashCode and equals implementation. Prefer the usage of * {@link #FilteredTree(Composite, int, PatternFilter, boolean, boolean)} if * possible * </p> * * @param parent the parent <code>Composite</code>
<|startcomment|> had the same idea but for me pattern included some kind of wildcard <|endcomment|> <|startfocus|> private void addPatterns(String... searchStrings) { if (searchStrings == null) { return; } for (String searchString : searchStrings) { if (searchString == null || searchString.isEmpty()) { continue; <|endfocus|> } Node node= root; for (char c : searchString.toCharArray()) { node= node.add(c); } node.match= searchString; }
<|startcomment|> btw. I think this line is outdated? <|endcomment|>  * * @since 3.9 */ public class MultiStringMatcher { // An implementation of the Aho-Corasick algorithm (without the DFA construction from section 6 of the // paper; just the failure and output links). // // See Aho, Alfred A.; Corasick, Margaret J.: "Efficient String Matching: An Aid to Bibliographic Search", // CACM 18(6), 1975. // <|startfocus|> // The algorithm has been modified to support reporting leftmost longest matches only. <|endfocus|> /** * Describes a match result of {@link MultiStringMatcher#indexOf(String, int)}, giving access to * the matched string and the offset in the text it was matched at. */ public static interface Match { /** * Obtains the matched string. * * @return the text matched */ String getText(); /** * Obtains the offset the {@link #getText() text} was matched at. * * @return the offset */ int getOffset(); } 
<|startcomment|> correct me if it is actually possible <|endcomment|>  * <p> * Performs a simultaneous search for all the strings, returning the leftmost match. If multiple * search strings match at the same index, the longest match is returned. * </p> * * @param text to search * @param offset to start searching at * @return the leftmost longest match found, or {@code null} if no match was found. <|startfocus|> * @throws IllegalStateException if no strings to search for have been added to this matcher <|endfocus|> */ public Match indexOf(String text, int offset) { List<Match> matches= find(text, offset, true); if (matches.isEmpty()) { return null; } // Find the leftmost longest match. Maybe there's an awfully clever way to keep only // one match? Iterator<Match> m= matches.iterator(); Match result= m.next(); while (m.hasNext()) { Match cand= m.next(); int cmp= Integer.compare(cand.getOffset(), result.getOffset()); if (cmp < 0) { result= cand;
<|startcomment|> For the bug I think it is enough to remove this clear (and the last line of the comment above) <|endcomment|>  // we have a full match. Standard Aho-Corasick would take the fail link on // the next character, which may or may not take us to root, and keep on // looking for more matches. We stop instead if we are looking only for the <|startfocus|> // first match. Note that we _do_ have a match at least from this node itself, // since terminal nodes in the trie always match, and it is by definition // also the longest match. matches.clear(); <|endfocus|> matches.add(new MatchResult(node.match, i - node.match.length() + 1)); break; } if (node.match != null) { matches.add(new MatchResult(node.match, i - node.match.length() + 1)); } if (!firstOnly || matches.isEmpty()) { Node out= node.output; while (out != null) { matches.add(new MatchResult(out.match, i - out.match.length() + 1)); out= out.output; } } } } return matches;
<|startcomment|> this test was copy&paste before <|endcomment|>  testList(matches, "[[x, 2]]"); } @Test public void noStrings001() throws Exception { thrown.expect(IllegalStateException.class); MultiStringMatcher.builder().build(); } @Test public void noStrings002() throws Exception { thrown.expect(IllegalStateException.class); MultiStringMatcher.builder().add("").build(); } @Test public void noStrings003() throws Exception { <|startfocus|> thrown.expect(IllegalStateException.class); MultiStringMatcher.builder().add((String[]) null).build(); <|endfocus|> } @Test public void fluent001() throws Exception { MultiStringMatcher m = MultiStringMatcher.builder().add("he", "she", "his", "hers").build(); test(m.indexOf("ushers", 0), "she", 1); } @Test public void fluent002() throws Exception { MultiStringMatcher m = MultiStringMatcher.builder().add("he", "she").add("his", "hers").build(); testList(m.find("ushers", 0), "[[she, 1], [he, 2], [hers, 2]]"); } 
<|startcomment|> if I understand correct the matches are always sorted by offset so we can optimize the search here. Thee old if(cmp<0) was also the only line without test coverage. <|endcomment|>  public Match indexOf(String text, int offset) { List<Match> matches= find(text, offset, true); if (matches.isEmpty()) { return null; } // Find the leftmost longest match. Maybe there's an awfully clever way to keep only // one match? Iterator<Match> m= matches.iterator(); Match result= m.next(); while (m.hasNext()) { Match cand= m.next(); if (cand.getOffset() > result.getOffset()) { <|startfocus|> // Results are ordered by offset. There will be no leftmost match as all we checked. <|endfocus|> break; } if (cand.getText().length() > result.getText().length()) { result= cand; } } return result;
<|startcomment|> maybe let's just reuse the packaging type "eclipse-target-definition" <|endcomment|> package org.eclipse.tycho.pomless; import java.io.File; import java.io.FileFilter; import java.io.IOException; import org.apache.maven.model.Model; import org.apache.maven.model.io.ModelParseException; import org.codehaus.plexus.component.annotations.Component; import org.sonatype.maven.polyglot.mapping.Mapping; import org.w3c.dom.Element; @Component(role = Mapping.class, hint = TychoTargetMapping.ROLE) public class TychoTargetMapping extends AbstractXMLTychoMapping { private static final String TARGET_EXTENSION = ".target"; <|startfocus|> public static final String ROLE = "tycho-target"; <|endfocus|> @Override public String getFlavour() { return TychoTargetMapping.ROLE; } @Override protected boolean isValidLocation(String location) { return location.endsWith(TARGET_EXTENSION); } @Override protected File getPrimaryArtifact(File dir) { File file = new File(dir, dir.getName() + TARGET_EXTENSION); if (file.exists()) { return file; } File[] listFiles = dir.listFiles(new FileFilter() { @Override public boolean accept(File file) {
<|startcomment|> add | FileUtils.RETRY this may be necessary on Windows <|endcomment|>  @Override public void checkPermission(Permission requested) { for (Permission permission : permissions) { if (permission.implies(requested)) { return; } } super.checkPermission(requested); } }); } @After public void tearDown() throws Exception { System.setSecurityManager(originalSecurityManager); // Note: don't use this method before security manager is replaced in // setUp() method. The method uses FS.DETECTED internally and can affect // the test. <|startfocus|> FileUtils.delete(root, FileUtils.RECURSIVE); <|endfocus|> } @Test public void testInitAndClone() throws IOException, GitAPIException { File remote = new File(root, "remote"); File local = new File(root, "local"); try (Git git = Git.init().setDirectory(remote).call()) { JGitTestUtil.write(new File(remote, "hello.txt"), "Hello world!"); git.add().addFilepattern(".").call(); git.commit().setMessage("Initial commit").call(); } 
<|startcomment|> externalize the message using JGitText <|endcomment|>  protected static File searchPath(String path, String... lookFor) { if (path == null) return null; for (String p : path.split(File.pathSeparator)) { for (String command : lookFor) { final File file = new File(p, command); try { if (file.isFile()) { return file.getAbsoluteFile(); } } catch (SecurityException e) { <|startfocus|> LOG.warn("The path '{}' isn't accessible. Skip it", file.getPath()); //$NON-NLS-1$ <|endfocus|> } } } return null;
<|startcomment|> externalize messages <|endcomment|>  } catch (InterruptedException ie) { // Stop bothering me, I have a zombie to reap. } } } catch (IOException e) { LOG.error("Caught exception in FS.readPipe()", e); //$NON-NLS-1$ } catch (AccessControlException e) { LOG.warn( "FS.readPipe() isn't allowed for command '{}'. Working directory: '{}'. Required permission: {}", //$NON-NLS-1$ command, dir, e.getPermission()); } catch (SecurityException e) { <|startfocus|> LOG.warn( "FS.readPipe() isn't allowed for command '{}'. Working directory: '{}'", //$NON-NLS-1$ command, dir); <|endfocus|> } if (debug) { LOG.debug("readpipe returns null"); //$NON-NLS-1$ } return null; } private static class GobblerThread extends Thread { /* The process has 5 seconds to exit after closing stderr */ private static final int PROCESS_EXIT_TIMEOUT = 5; private final Process p; private final String desc;
<|startcomment|> I recommend moving this code to the listener, if possible, because the rest of the logic that decides whether a change (delta) should trigger a sync lives there. <|endcomment|>  * (non-Javadoc) * @see org.eclipse.ptp.rdt.sync.core.services.ISynchronizeService#synchronize(org.eclipse.core.resources.IProject, * org.eclipse.ptp.rdt.sync.core.RemoteLocation, org.eclipse.core.resources.IResourceDelta, * org.eclipse.core.runtime.IProgressMonitor, java.util.EnumSet) */ @Override public void synchronize(final IProject project, RemoteLocation rl, IResourceDelta delta, IProgressMonitor monitor, Set<SyncFlag> syncFlags) throws CoreException { if (project == null || rl == null) { throw new NullPointerException(); } <|startfocus|> if (project != null && delta != null && project.getFile(gitDir).getFullPath().isPrefixOf(delta.getFullPath())) { // ignore deltas prefixed by gitDir <|endfocus|> return; } // Make a copy to protect against the remote location // being changed by another thread. RemoteLocation remoteLoc = new RemoteLocation(rl); ProjectAndRemoteLocationPair syncTarget = new ProjectAndRemoteLocationPair(project, remoteLoc); if(syncFlags.contains(SyncFlag.WAIT_FOR_LR)) { try { SyncInt si = syncLRPending.get(syncTarget);
<|startcomment|> minor nit: move comment to top of if block <|endcomment|>  * org.eclipse.core.runtime.IProgressMonitor, java.util.EnumSet) */ @Override public void synchronize(final IProject project, RemoteLocation rl, IResourceDelta delta, IProgressMonitor monitor, Set<SyncFlag> syncFlags) throws CoreException { if (project == null || rl == null) { throw new NullPointerException(); } <|startfocus|> if (project != null && delta != null && project.getFile(gitDir).getFullPath().isPrefixOf(delta.getFullPath())) { // ignore deltas prefixed by gitDir <|endfocus|> return; } // Make a copy to protect against the remote location // being changed by another thread. RemoteLocation remoteLoc = new RemoteLocation(rl); ProjectAndRemoteLocationPair syncTarget = new ProjectAndRemoteLocationPair(project, remoteLoc); if(syncFlags.contains(SyncFlag.WAIT_FOR_LR)) { try { SyncInt si = syncLRPending.get(syncTarget); if (si != null) { si.waitForZero(); } } catch (InterruptedException e) { // This shouldn't happen. Activator.log(e); } return; } 
<|startcomment|> typo <|endcomment|>  * </ul> * * @since 2.1 */ public void paste () { checkWidget (); if ((style & SWT.READ_ONLY) != 0) return; OS.SendMessage (handle, OS.WM_PASTE, 0, 0); } void stateFlagsAdd(int flags) { final long tagCBoxPtr = OS.GetWindowLongPtr(handle, 0); /* * Bug 550423: When non-XP-theme COMMCTL32.DLL gets loaded, undocumented <|startfocus|> * internal data is not there. We do not support that and is such case <|endfocus|> * GetWindowLongPtr function fails and return zero. */ if (tagCBoxPtr == 0) return; final long stateFlagsPtr = tagCBoxPtr + stateFlagsOffset; int stateFlags[] = new int[1]; OS.MoveMemory(stateFlags, stateFlagsPtr, 4); stateFlags[0] |= flags; OS.MoveMemory(stateFlagsPtr, stateFlags, 4); } /* * Verify that undocumented internal data is in expected location. * The test is performed at creation time, when the value of state flags is predictable.
<|startcomment|> typo <|endcomment|> } /* * Verify that undocumented internal data is in expected location. * The test is performed at creation time, when the value of state flags is predictable. * For simplicity, only SWT.READ_ONLY combos are handled. */ boolean stateFlagsTest() { final long tagCBoxPtr = OS.GetWindowLongPtr(handle, 0); /* * Bug 550423: When non-XP-theme COMMCTL32.DLL gets loaded, undocumented <|startfocus|> * internal data is not there. We do not support that and is such case <|endfocus|> * GetWindowLongPtr function fails and return zero. */ if (tagCBoxPtr == 0) return false; final long stateFlagsPtr = tagCBoxPtr + stateFlagsOffset; int stateFlags[] = new int[1]; OS.MoveMemory(stateFlags, stateFlagsPtr, 4); /* * 0x00000002 is unknown * 0x00002000 is set in WM_NCCREATE * 0x00004000 means CBS_DROPDOWNLIST (SWT.READ_ONLY) * 0x02000000 is set in WM_NCCREATE and reset after first WM_PAINT */ return (stateFlags[0] == 0x02006002); }
<|startcomment|> I suggest this comment wording: Bug 550423: When non-XP-theme COMMCTL32.DLL gets loaded, undocumented internal data is not there. We do not support that. <|endcomment|>  } } /* * Verify that undocumented internal data is in expected location. * The test is performed at creation time, when the value of state flags is predictable. * For simplicity, only SWT.READ_ONLY combos are handled. */ boolean stateFlagsTest() { final long tagCBoxPtr = OS.GetWindowLongPtr(handle, 0); /* <|startfocus|> * If the GetWindowLongPtr function fails, the return value is zero. Hence the * state-flags test doesn't pass and should return false. <|endfocus|> */ if (tagCBoxPtr != 0) { final long stateFlagsPtr = tagCBoxPtr + stateFlagsOffset; int stateFlags[] = new int[1]; OS.MoveMemory(stateFlags, stateFlagsPtr, 4); /* * 0x00000002 is unknown * 0x00002000 is set in WM_NCCREATE * 0x00004000 means CBS_DROPDOWNLIST (SWT.READ_ONLY) * 0x02000000 is set in WM_NCCREATE and reset after first WM_PAINT */ return (stateFlags[0] == 0x02006002); } return false; } @Override void register () {
<|startcomment|> Will be safe to add same check in stateFlagsAdd() <|endcomment|>  if (length == OS.CB_ERR) { int count = (int)/*64*/OS.SendMessage (handle, OS.CB_GETCOUNT, 0, 0); if (0 <= index && index < count) error (SWT.ERROR_ITEM_NOT_REMOVED); error (SWT.ERROR_INVALID_RANGE); } buffer = new TCHAR (getCodePage (), length + 1); int result = (int)/*64*/OS.SendMessage (handle, OS.CB_GETLBTEXT, index, buffer); if (result == OS.CB_ERR) { <|startfocus|> int count = (int)/*64*/OS.SendMessage (handle, OS.CB_GETCOUNT, 0, 0); <|endfocus|> if (0 <= index && index < count) error (SWT.ERROR_ITEM_NOT_REMOVED); error (SWT.ERROR_INVALID_RANGE); } } int length = OS.GetWindowTextLength (handle); int code = (int)/*64*/OS.SendMessage (handle, OS.CB_DELETESTRING, index, 0); if (code == OS.CB_ERR) { int count = (int)/*64*/OS.SendMessage (handle, OS.CB_GETCOUNT, 0, 0);
<|startcomment|> delete commented code. <|endcomment|>  private static final String pageName = "Scripts"; private ToolItem abortButton; private ToolItem abortBatchButton; private CoolBar coolBar; private ToolItem deleteButton; private Label hostConnectLabel; private LoadWidget loadWidget; protected ToolItem runButton; private SaveWidget saveWidget; private ScriptTableViewer scriptTable; private StatusWindowWidget statusWindow; private final TestManagerEditor testManagerEditor; private ProgramButtonProviderService programButtonProviderService; <|startfocus|> //private LibraryLinkerProviderService libraryLinkerProviderService; //private LaunchAndKillProviderService launchAndKillProviderService; <|endfocus|> public ScriptPage(Composite parent, int style, TestManagerEditor parentTestManager) { super(parent, style, parentTestManager); this.testManagerEditor = parentTestManager; } public void addFile(String fullPath) { scriptTable.addFile(fullPath); } @Override public void createPage() { super.createPage(); Composite parent = (Composite) getContent(); coolBar = new CoolBar(parent, SWT.FLAT); createControlsToolBar(coolBar); createConfigurationToolBar(coolBar); packCoolBar(); 
<|startcomment|> How come formatter off? <|endcomment|>  } // Example: As above, but to be moved to the appropriate class/location. ILibraryLinkerProviderService libraryLinkerProviderService = OsgiUtil.getService(ILibraryLinkerProvider.class, LibraryLinkerProviderService.class); for (ILibraryLinkerProvider provider : libraryLinkerProviderService.getLibraryLinkerProviders()) { provider.getLibraryLinkers(); } // Example: As above, but to be moved to the appropriate class/location. ILaunchAndKillProviderService launchAndKillProviderService = OsgiUtil.getService(ILaunchAndKillProvider.class, LaunchAndKillProviderService.class); <|startfocus|> // @formatter:off <|endfocus|> // Example to launch and kill processes: for (ILaunchAndKillProvider provider : launchAndKillProviderService.getLaunchAndKillProviders()) { Collection<ILaunchAndKill> launchers = provider.getLaunchers(); Collection<ILaunchAndKill> killers = provider.getKillers(); for (ILaunchAndKill launcher : launchers) { Process launchProcess; // To access Process methods //launchProcess = launcher.executeProcess(); // Launches the process break; } for (ILaunchAndKill killer : killers) { Process killProcess; // To access Process methods
<|startcomment|> add it into the message <|endcomment|>  if (selection.getFirstElement() instanceof Table) { this.exportedTable = (Table) selection.getFirstElement(); } else if (selection instanceof TableStructuredSelection) { final TableStructuredSelection tss = (TableStructuredSelection) selection; final INattableModelManager tableModelManager = (INattableModelManager) tss.getAdapter(INattableModelManager.class); if (null != tableModelManager) { this.exportedTable = tableModelManager.getTable(); } } <|startfocus|> Assert.isNotNull(this.exportedTable, "We can't found the table to export"); //$NON-NLS-1$ <|endfocus|> IStatus status = TableChecker.checkTable(this.exportedTable); if (false == status.isOK()) { addPage(new WarningOnCurrentTableWizardPage(status)); } this.outputPage = new DefineOutputPluginWizardPage(); this.tableDataPage = new DefineTableConfigurationDataWizardPage(); this.outputPage.setExportedTable(this.exportedTable); this.tableDataPage.setExportedTable(this.exportedTable); addPage(outputPage); addPage(tableDataPage);
<|startcomment|> The null check can be removed now. <|endcomment|>  if (field != null) { return new JDIFieldVariable(debugTarget, field, getUnderlyingObject(), fLogicalParent); } // Check possible references of variables defined in outer class for (Field outer : synteticFields) { // retrieve the reference to the "outer" object JDIFieldVariable syntVariable = new JDIFieldVariable(debugTarget, outer, getUnderlyingObject(), fLogicalParent); IValue value = syntVariable.getValue(); if (value instanceof JDIObjectValue) { JDIObjectValue outerObject = (JDIObjectValue) value; <|startfocus|> if (outerObject != null) { // ask "outer" object about field probably declared within return outerObject.getField(name, outer.signature()); } <|endfocus|> } } } catch (RuntimeException e) { targetRequestFailed( MessageFormat.format( JDIDebugModelMessages.JDIObjectValue_exception_retrieving_field, e.toString()), e); } // it is possible to return null return null; } static List<ReferenceType> superTypes(ReferenceType type) { List<ReferenceType> superTypes = new ArrayList<>(); ReferenceType t = type;
<|startcomment|> organize imports <|endcomment|> import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VppInterfaceAugmentation; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.Routing; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.RoutingBuilder; <|startfocus|> import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.fib.table.management.rev180521.VniReference; <|endfocus|> import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public class InterfaceRoutingCustomizerTest extends WriterCustomizerTest { private static final String IFACE_CTX_NAME = "interface-ctx"; private static final String IF_NAME = "eth1"; private static final int IF_INDEX = 1; private static final InstanceIdentifier<Routing> IID = InstanceIdentifier.create(Interfaces.class).child(Interface.class, new InterfaceKey(IF_NAME)) .augmentation(VppInterfaceAugmentation.class).child(Routing.class); private InterfaceRoutingCustomizer customizer; @Override protected void setUpTest() throws Exception { customizer = new InterfaceRoutingCustomizer(api, new NamingContext("ifacePrefix", IFACE_CTX_NAME));
<|startcomment|> organize imports <|endcomment|> import java.util.Collections; import java.util.Set; import org.junit.Test; import org.mockito.ArgumentCaptor; import org.mockito.Captor; import org.opendaylight.yang.gen.v1.urn.ietf.params.xml.ns.yang.ietf.interfaces.rev140508.Interfaces; import org.opendaylight.yang.gen.v1.urn.ietf.params.xml.ns.yang.ietf.interfaces.rev140508.interfaces.Interface; import org.opendaylight.yang.gen.v1.urn.ietf.params.xml.ns.yang.ietf.interfaces.rev140508.interfaces.InterfaceKey; <|startfocus|> import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.fib.table.management.rev180521.VniReference; <|endfocus|> import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.SubinterfaceAugmentation; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.interfaces._interface.SubInterfaces; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.interfaces._interface.sub.interfaces.SubInterface; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.vpp.vlan.rev180319.interfaces._interface.sub.interfaces.SubInterfaceBuilder;
<|startcomment|> organize imports <|endcomment|> import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VppInterfaceAugmentation; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VxlanVni; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.Vxlan; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces._interface.VxlanBuilder; <|startfocus|> import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.fib.table.management.rev180521.VniReference; <|endfocus|> import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public class VxlanCustomizerTest extends WriterCustomizerTest implements AddressTranslator { private static final byte ADD_VXLAN = 1; private static final byte DEL_VXLAN = 0; @Mock private DisabledInterfacesManager disableContext; private VxlanCustomizer customizer; private String ifaceName; private InstanceIdentifier<Vxlan> id; private static Vxlan generateVxlan(long vni) { final VxlanBuilder builder = new VxlanBuilder(); builder.setSrc(new IpAddressNoZone(new Ipv4AddressNoZone("192.168.20.10")));
<|startcomment|> organize imports <|endcomment|> import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.VppInterfaceStateAugmentationBuilder; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces.state._interface.Routing; import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.v3po.rev181008.interfaces.state._interface.RoutingBuilder; <|startfocus|> import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.fib.table.management.rev180521.VniReference; <|endfocus|> import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; public class InterfaceRoutingCustomizerTest extends ReaderCustomizerTest<Routing, RoutingBuilder> { private static final String IFC_CTX_NAME = "ifc-test-instance"; private static final String IF_NAME = "local0"; private static final int IF_ID = 1; private static final Long IP4_VRF_ID = 1L; private static final Long IP6_VRF_ID = 2L; private NamingContext interfacesContext; public InterfaceRoutingCustomizerTest() { super(Routing.class, VppInterfaceStateAugmentationBuilder.class); } @Override public void setUp() {
<|startcomment|> sometimes the order is swapped. we can use containsInAnyOrder() to avoid test failures. <|endcomment|>  namingContext.removeChild(PARENT_1, CHILD_1, mappingContext); verify(mappingContext, times(1)) .put(instanceIdentifierArgumentCaptor.capture(), mappingArgumentCaptor.capture()); assertEquals(instanceIdentifierArgumentCaptor.getValue(), parentKey(PARENT_1)); final Mapping mapping = mappingArgumentCaptor.getValue(); final List<Value> values = mapping.getValue(); assertEquals(PARENT_1, mapping.getName()); assertThat(values, hasSize(2)); <|startfocus|> assertThat(values, contains(valueFor(CHILD_2, 2), valueFor(CHILD_3, 3))); <|endfocus|> } @Test public void removeChildNonExistingParent() { namingContext.removeChild(NON_EXISTING_PARENT, CHILD_1, mappingContext); // if parent doest not exist, do nothing verify(mappingContext, times(0)).put(Mockito.any(), Mockito.any()); } private Value valueFor(final String name, final int index) { return new ValueBuilder().setName(name).setIndex(index).withKey(new ValueKey(name)).build(); } } 
<|startcomment|> private <|endcomment|> import io.fd.hc2vpp.ipsec.read.IpsecReaderFactory; import io.fd.hc2vpp.ipsec.write.IpsecWriterFactory; import io.fd.honeycomb.translate.read.ReaderFactory; import io.fd.honeycomb.translate.write.WriterFactory; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * Module class instantiating nat plugin components. */ public class IpsecModule extends AbstractModule { private static final Logger LOG = LoggerFactory.getLogger(IpsecModule.class); <|startfocus|> public static final String SAD_ENTRIES_MAPPING = "sad-entries-mapping"; <|endfocus|> @Override protected void configure() { LOG.info("Installing IPSec module"); bind(MultiNamingContext.class).toInstance(new MultiNamingContext(SAD_ENTRIES_MAPPING, 1)); LOG.info("Injecting writers factories"); final Multibinder<WriterFactory> writerFactoryBinder = Multibinder.newSetBinder(binder(), WriterFactory.class); writerFactoryBinder.addBinding().to(IpsecWriterFactory.class).in(Singleton.class); LOG.info("Injecting readers factories"); final Multibinder<ReaderFactory> readerFactoryBinder = Multibinder.newSetBinder(binder(), ReaderFactory.class); readerFactoryBinder.addBinding().to(IpsecReaderFactory.class).in(Singleton.class); 
<|startcomment|> copy paste error. should be IpSec <|endcomment|> import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecStateSpdAugmentationBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.Spd; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.spd.SpdEntries; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; /** <|startfocus|> * Factory producing writers for DHCP plugin's data. <|endfocus|> */ public final class IpsecReaderFactory implements ReaderFactory { private static final InstanceIdentifier<IpsecState> IPSEC_STATE_ID = InstanceIdentifier.create(IpsecState.class); private FutureJVppCore vppApi; @Inject public IpsecReaderFactory(final FutureJVppCore vppApi) { this.vppApi = vppApi; } @Override public void init(@Nonnull final ModifiableReaderRegistryBuilder registry) { registry.subtreeAdd(Sets .newHashSet(InstanceIdentifier.create(IpsecState.class).child(Sa.class), InstanceIdentifier.create(IpsecState.class).augmentation(IpsecStateSpdAugmentation.class).child(Spd.class)), new GenericReader<>(IPSEC_STATE_ID, new IpsecStateCustomizer(vppApi))); 
<|startcomment|> readers <|endcomment|> import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecStateSpdAugmentationBuilder; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.Spd; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.ipsec.state.spd.SpdEntries; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; /** <|startfocus|> * Factory producing writers for DHCP plugin's data. <|endfocus|> */ public final class IpsecReaderFactory implements ReaderFactory { private static final InstanceIdentifier<IpsecState> IPSEC_STATE_ID = InstanceIdentifier.create(IpsecState.class); private FutureJVppCore vppApi; @Inject public IpsecReaderFactory(final FutureJVppCore vppApi) { this.vppApi = vppApi; } @Override public void init(@Nonnull final ModifiableReaderRegistryBuilder registry) { registry.subtreeAdd(Sets .newHashSet(InstanceIdentifier.create(IpsecState.class).child(Sa.class), InstanceIdentifier.create(IpsecState.class).augmentation(IpsecStateSpdAugmentation.class).child(Spd.class)), new GenericReader<>(IPSEC_STATE_ID, new IpsecStateCustomizer(vppApi))); 
<|startcomment|> format please. <|endcomment|>  InstanceIdentifier.create(IpsecState.class).augmentation(IpsecStateSpdAugmentation.class).child(Spd.class)), new GenericReader<>(IPSEC_STATE_ID, new IpsecStateCustomizer(vppApi))); registry.addStructuralReader(IPSEC_STATE_ID.augmentation(IpsecStateSpdAugmentation.class), IpsecStateSpdAugmentationBuilder.class); registry.subtreeAdd(Sets <|startfocus|> .newHashSet(InstanceIdentifier.create(Spd.class).child(SpdEntries.class)), new GenericInitListReader<>(IPSEC_STATE_ID.augmentation(IpsecStateSpdAugmentation.class).child(Spd.class), new IpsecStateSpdCustomizer(vppApi))); <|endfocus|>
<|startcomment|> format <|endcomment|>  public IpsecStateCustomizer(final FutureJVppCore vppApi) { super(vppApi); <|startfocus|> this.ipsecSaDetailsReplyDumpManager = new DumpCacheManager.DumpCacheManagerBuilder<IpsecSaDetailsReplyDump, Void>() .withExecutor(new IpsecStateCustomizer.IpsecStateSaDetailsDumpExecutor(vppApi)) .acceptOnly(IpsecSaDetailsReplyDump.class) .build(); <|endfocus|>
<|startcomment|> format <|endcomment|>  return Initialized.create(id, readValue); } @Nonnull @Override public IpsecStateBuilder getBuilder(@Nonnull final InstanceIdentifier<IpsecState> id) { return new IpsecStateBuilder(); } @Override public void readCurrentAttributes(@Nonnull final InstanceIdentifier<IpsecState> id, @Nonnull final IpsecStateBuilder builder, @Nonnull final ReadContext ctx) throws ReadFailedException { <|startfocus|> final Optional<IpsecSaDetailsReplyDump> dumpSa = ipsecSaDetailsReplyDumpManager.getDump(id, ctx.getModificationCache()); <|endfocus|> if (dumpSa.isPresent()) { LinkedList<Sa> listSa = new LinkedList<>(); IpsecSaDetailsReplyDump reply = dumpSa.get(); for (IpsecSaDetails details : reply.ipsecSaDetails) { SaBuilder saBuilder = new SaBuilder(); saBuilder.setSpi(Integer.toUnsignedLong(details.spi)); saBuilder.setAntiReplayWindow(Long.valueOf(details.replayWindow).intValue()); saBuilder.setAuthenticationAlgorithm(IkeIntegrityAlgorithmT.forValue(details.integAlg)); saBuilder.setEncryptionAlgorithm(IkeEncryptionAlgorithmT.forValue(details.cryptoAlg)); listSa.add(saBuilder.build()); } builder.setSa(listSa); } } @Override
<|startcomment|> builder style can be used here <|endcomment|>  if (dumpSa.isPresent()) { LinkedList<Sa> listSa = new LinkedList<>(); IpsecSaDetailsReplyDump reply = dumpSa.get(); for (IpsecSaDetails details : reply.ipsecSaDetails) { SaBuilder saBuilder = new SaBuilder(); <|startfocus|> saBuilder.setSpi(Integer.toUnsignedLong(details.spi)); saBuilder.setAntiReplayWindow(Long.valueOf(details.replayWindow).intValue()); saBuilder.setAuthenticationAlgorithm(IkeIntegrityAlgorithmT.forValue(details.integAlg)); saBuilder.setEncryptionAlgorithm(IkeEncryptionAlgorithmT.forValue(details.cryptoAlg)); <|endfocus|> listSa.add(saBuilder.build()); } builder.setSa(listSa); } } @Override public void merge(@Nonnull final Builder<? extends DataObject> parentBuilder, @Nonnull final IpsecState readValue) { IpsecStateBuilder ipsecParentBuilder = (IpsecStateBuilder)parentBuilder; ipsecParentBuilder.setHoldDown(readValue.getHoldDown()); ipsecParentBuilder.setPolicy(readValue.getPolicy()); ipsecParentBuilder.setProposal(readValue.getProposal()); ipsecParentBuilder.setRedundancy(readValue.getRedundancy()); ipsecParentBuilder.setSa(readValue.getSa());
<|startcomment|> unnecessary reply variable, please return getReplyForRead... <|endcomment|>  implements EntityDumpExecutor<IpsecSaDetailsReplyDump, Void>, JvppReplyConsumer { private final FutureJVppCore jvpp; IpsecStateSaDetailsDumpExecutor(final FutureJVppCore jvpp) { this.jvpp = jvpp; } @Nonnull @Override public IpsecSaDetailsReplyDump executeDump(final InstanceIdentifier<?> identifier, final Void params) throws ReadFailedException { IpsecSaDump dump = new IpsecSaDump(); dump.saId = -1; <|startfocus|> IpsecSaDetailsReplyDump reply = getReplyForRead(jvpp.ipsecSaDump(dump).toCompletableFuture(), identifier); return reply; <|endfocus|> } } } 
<|startcomment|> is the implementation missing? at least write a comment why this method is empty. <|endcomment|>  } } } @Override public void updateCurrentAttributes(@Nonnull final InstanceIdentifier<IkeGlobalConfiguration> id, @Nonnull final IkeGlobalConfiguration dataBefore, @Nonnull final IkeGlobalConfiguration dataAfter, @Nonnull final WriteContext writeContext) throws WriteFailedException { writeCurrentAttributes(id, dataAfter, writeContext); } @Override public void deleteCurrentAttributes(@Nonnull final InstanceIdentifier<IkeGlobalConfiguration> id, @Nonnull final IkeGlobalConfiguration dataBefore, @Nonnull final WriteContext writeContext) throws WriteFailedException { <|startfocus|> <|endfocus|> } } 
<|startcomment|> is this intentionally empty or the implementation is missing? add comment or implement. <|endcomment|>  String name = id.firstKeyOf(Policy.class).getName(); if (dataAfter.getLocal() != null) { setProfileId(id, name, dataAfter.getLocal().getIdentity(), true); } if (dataAfter.getRemote() != null) { setProfileId(id, name, dataAfter.getRemote().getIdentity(), false); } } @Override <|startfocus|> public void deleteCurrentAttributes(@Nonnull final InstanceIdentifier<Identity> id, @Nonnull final Identity dataBefore, @Nonnull final WriteContext writeContext) throws WriteFailedException { } @Override <|endfocus|> public void updateCurrentAttributes(@Nonnull final InstanceIdentifier<Identity> id, @Nonnull final Identity dataBefore, @Nonnull final Identity dataAfter, @Nonnull final WriteContext writeContext) throws WriteFailedException { writeCurrentAttributes(id, dataAfter, writeContext); } private void setProfileId(final InstanceIdentifier<Identity> id, final String profileName, final org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.identity.grouping.Identity data, final boolean isLocalId) throws WriteFailedException {
<|startcomment|> can be simplified entry.useAntiReplay = dataAfter.getAntiReplayWindow() > 0 ? BYTE_TRUE : BYTE_FALSE; <|endcomment|>  IpsecSadEntriesAugmentation augment = dataAfter.augmentation(IpsecSadEntriesAugmentation.class); if (augment != null && augment.getSaId() != null) { entry.sadId = augment.getSaId(); } if (dataAfter.getSpi() != null) { entry.spi = dataAfter.getSpi().intValue(); } if (dataAfter.getAntiReplayWindow() != null) { <|startfocus|> if (dataAfter.getAntiReplayWindow() > 0) { entry.useAntiReplay = BYTE_TRUE; } else { entry.useAntiReplay = BYTE_FALSE; } <|endfocus|> } if (dataAfter.getSaMode() != null) { entry.isTunnel = Integer.valueOf(dataAfter.getSaMode().getIntValue()).byteValue(); } entry.isAdd = adding ? ByteDataTranslator.BYTE_TRUE : ByteDataTranslator.BYTE_FALSE; if (dataAfter.getEsp() != null) { entry.protocol = 1; fillEspAuthentication(entry, dataAfter.getEsp()); fillEspEncryption(entry, dataAfter.getEsp()); } else if (dataAfter.getAh() != null) { entry.protocol = 0;
<|startcomment|> IpSec <|endcomment|> import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecIkeGlobalConfAugmentation; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecSadEntriesAugmentation; import org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.vpp.vpp.ipsec.rev181213.IpsecSpdEntriesAugmentation; import org.opendaylight.yangtools.yang.binding.InstanceIdentifier; /** <|startfocus|> * Factory producing writers for DHCP plugin's data. <|endfocus|> */ public final class IpsecWriterFactory implements WriterFactory { private static final InstanceIdentifier<Ikev2> IKE2_ID = InstanceIdentifier.create(Ikev2.class); private static final InstanceIdentifier<Ipsec> IPSEC_ID = InstanceIdentifier.create(Ipsec.class); private static final InstanceIdentifier<Sad> SAD_ID = IPSEC_ID.child(Sad.class); private static final InstanceIdentifier<SadEntries> SAD_ENTRIES_ID = SAD_ID.child(SadEntries.class); private static final InstanceIdentifier<Spd> SPD_ID = IPSEC_ID.child(Spd.class); private final FutureJVppCore vppApi; private MultiNamingContext sadEntriesMapping; @Inject
<|startcomment|> format, there are five spaces instead of four <|endcomment|>  public void init(@Nonnull final ModifiableWriterRegistryBuilder registry) { <|startfocus|> registry.subtreeAdd(Sets.newHashSet(InstanceIdentifier.create(SadEntries.class).child(SourceAddress.class), <|endfocus|> InstanceIdentifier.create(SadEntries.class).child(DestinationAddress.class), InstanceIdentifier.create(SadEntries.class).child(Ah.class) .child(org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.ipsec.sa.ah.grouping.ah.authentication.algorithm.hmac.sha1._96.HmacSha196.class), InstanceIdentifier.create(SadEntries.class).child(Ah.class) .child(org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.ipsec.sa.ah.grouping.ah.authentication.algorithm.hmac.md5._96.HmacMd596.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Authentication.class).child(HmacSha196.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Authentication.class).child(HmacMd596.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Encryption.class).child(Aes128Cbc.class), InstanceIdentifier.create(SadEntries.class).child(Esp.class).child(Encryption.class).child(Aes192Cbc.class),
<|startcomment|> format please <|endcomment|>  org.opendaylight.yang.gen.v1.http.fd.io.hc2vpp.yang.hc2vpp.ipsec.rev181214.ikev2.policy.profile.grouping.Authentication.class), InstanceIdentifier.create(Policy.class).child(TrafficSelectors.class)), new GenericListWriter<>(IKE2_ID.child(Policy.class), new Ikev2PolicyCustomizer(vppApi))); registry.subtreeAdd(Sets.newHashSet(InstanceIdentifier.create(Identity.class).child(Local.class), InstanceIdentifier.create(Identity.class).child(Remote.class)), <|startfocus|> new GenericWriter<>(IKE2_ID.child(Policy.class).child(Identity.class), new Ikev2PolicyIdentityCustomizer(vppApi))); <|endfocus|>
<|startcomment|> Ipsec <|endcomment|>  */ package io.fd.hc2vpp.ipsec; import com.google.inject.AbstractModule; import com.google.inject.Singleton; import com.google.inject.multibindings.Multibinder; import io.fd.hc2vpp.common.translate.util.MultiNamingContext; import io.fd.hc2vpp.ipsec.read.IpsecReaderFactory; import io.fd.hc2vpp.ipsec.write.IpsecWriterFactory; import io.fd.honeycomb.translate.read.ReaderFactory; import io.fd.honeycomb.translate.write.WriterFactory; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** <|startfocus|> * Module class instantiating nat plugin components. <|endfocus|> */ public class IpsecModule extends AbstractModule { private static final Logger LOG = LoggerFactory.getLogger(IpsecModule.class); private static final String SAD_ENTRIES_MAPPING = "sad-entries-mapping"; @Override protected void configure() { LOG.info("Installing IPSec module"); bind(MultiNamingContext.class).toInstance(new MultiNamingContext(SAD_ENTRIES_MAPPING, 1)); LOG.info("Injecting writers factories"); final Multibinder<WriterFactory> writerFactoryBinder = Multibinder.newSetBinder(binder(), WriterFactory.class); writerFactoryBinder.addBinding().to(IpsecWriterFactory.class).in(Singleton.class); 
<|startcomment|> remove empty line <|endcomment|>  super(vppApi); IpsecStateSpdsReplyDumpExecutor spdsExecutor = new IpsecStateSpdCustomizer.IpsecStateSpdsReplyDumpExecutor(vppApi); this.ipsecSpdsReplyDumpManager = new DumpCacheManager.DumpCacheManagerBuilder<IpsecSpdsDetailsReplyDump, Void>() .withExecutor(spdsExecutor) .acceptOnly(IpsecSpdsDetailsReplyDump.class) .build(); this.ipsecSpdDetailsReplyDumpManager = new DumpCacheManager.DumpCacheManagerBuilder<IpsecSpdDetailsReplyDump, Void>() .withExecutor( new IpsecStateSpdCustomizer.IpsecStateSpdDetailsDumpExecutor(vppApi, spdsExecutor)) .acceptOnly(IpsecSpdDetailsReplyDump.class) .build(); <|startfocus|> <|endfocus|>
<|startcomment|> long line, format please <|endcomment|>  public void init(@Nonnull final ModifiableWriterRegistryBuilder registry) { InstanceIdentifier<Policer> IID = InstanceIdentifier.create(Policer.class); registry.subtreeAdd( <|startfocus|> Sets.newHashSet(IID.child(ConformAction.class), IID.child(ExceedAction.class), IID.child(ViolateAction.class)), new GenericListWriter<>(POLICER_IID, new PolicerCustomizer(vppApi, policerContext), new PolicerValidator(policerContext))); <|endfocus|>
<|startcomment|> wrong copyright <|endcomment|> <|startfocus|> * Copyright (c) 2017 Cisco and/or its affiliates. <|endfocus|> * * Licensed under the Apache License, Version 2.0 (the "License"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at: * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package io.fd.hc2vpp.l3.write.ipv4; import static com.google.common.base.Preconditions.checkNotNull; import io.fd.hc2vpp.common.translate.util.NamingContext; import io.fd.honeycomb.translate.write.DataValidationFailedException; import io.fd.honeycomb.translate.write.Validator; import io.fd.honeycomb.translate.write.WriteContext; import javax.annotation.Nonnull;
<|startcomment|> extra line <|endcomment|>  */ public static final class StatsConnectionInfo { public final long queueAddress; public final int clientIndex; public final int status; // FIXME throw exception instead public final int pid; public StatsConnectionInfo(long queueAddress, int clientIndex, int status, int pid) { this.queueAddress = queueAddress; this.clientIndex = clientIndex; this.status = status; this.pid = pid; } } private static native StatsConnectionInfo statsConnect(String clientName); private static native void statsDisconnect(); <|startfocus|> <|endfocus|> } 
<|startcomment|> extra line <|endcomment|>  public void onInterfaceStatisticsDetails(final io.fd.jvpp.stats.dto.InterfaceStatisticsDetails reply) { io.fd.jvpp.stats.callback.InterfaceStatisticsDetailsCallback callback; final int replyId = reply.context; if (LOG.isLoggable(java.util.logging.Level.FINE)) { LOG.fine(String.format("Received InterfaceStatisticsDetails event message: %s", reply)); } synchronized (requests) { callback = (io.fd.jvpp.stats.callback.InterfaceStatisticsDetailsCallback) requests.remove(replyId); } if (callback != null) { callback.onInterfaceStatisticsDetails(reply); } } <|startfocus|> <|endfocus|> } 
<|startcomment|> remove line <|endcomment|>  * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package io.fd.jvpp.stats.dto; /** * <p>This class represents request DTO. */ public final class InterfaceStatisticsDump implements io.fd.jvpp.dto.JVppDump { <|startfocus|> <|endfocus|> @Override @io.fd.jvpp.coverity.SuppressFBWarnings("UWF_UNWRITTEN_PUBLIC_OR_PROTECTED_FIELD") public int hashCode() { return java.util.Objects.hash(); } @Override public boolean equals(final Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } return true; } @Override public String toString() { return "InterfaceStatisticsDump{}"; } @Override
<|startcomment|> remove line <|endcomment|>  } synchronized(requests) { CompletableFuture<? extends JVppReply<?>> replyFuture = requests.get(contextId); if (replyFuture == null) { // reply not received yet, put new future to map replyDumpFuture = new CompletableDumpFuture<>(contextId, emptyReplyDump); requests.put(contextId, replyDumpFuture); } else { // reply already received, save existing future replyDumpFuture = (CompletableDumpFuture<DUMP>) replyFuture; } } <|startfocus|> <|endfocus|> synchronized (requests) { // reply already received, complete future replyDumpFuture.complete(replyDumpFuture.getReplyDump()); requests.remove(contextId); } // TODO in case of timeouts/missing replies, requests from the map are not removed // consider adding cancel method, that would remove requests from the map and cancel // associated replyCompletableFuture return replyDumpFuture; } catch (VppInvocationException ex) { final CompletableFuture<DUMP> replyCompletableFuture = new CompletableFuture<>(); replyCompletableFuture.completeExceptionally(ex); return replyCompletableFuture; } } 
<|startcomment|> extra line <|endcomment|>  .get(replyId); if (completableFuture == null) { // reply received before writer created future, // create new future, and put into map to notify sender that reply is already received, // following details replies will add information to this future completableFuture = new io.fd.jvpp.stats.future.AbstractFutureJVppInvoker.CompletableDumpFuture<>(replyId, new InterfaceStatisticsDetailsReplyDump()); requests.put(replyId, completableFuture); } completableFuture.getReplyDump().interfaceStatisticsDetails = reply; } } <|startfocus|> <|endfocus|> } 
<|startcomment|> remove <|endcomment|>  public InterfaceStatisticsCustomizer(final NamingContext ifcNamingCtx, final FutureJVppStatsFacade jvppStats, final InterfaceStatisticsCollectionManager statisticsManager) { this.ifcNamingCtx = checkNotNull(ifcNamingCtx, "Naming context should not be null"); this.jvppStats = checkNotNull(jvppStats, "JVpp Stats facade should not be null"); <|startfocus|> this.statisticsManager = checkNotNull(statisticsManager, "Statistics Collection Manager should not be null"); <|endfocus|>
<|startcomment|> debug <|endcomment|>  .setInMulticastPkts(new Counter64(BigInteger.valueOf(detail.inMulticastPkts))) .setInBroadcastPkts(new Counter64(BigInteger.valueOf(detail.inBroadcastPkts))) .setInErrors(new Counter32(new Long(detail.inErrors))); } } } @Override public void merge(@Nonnull final Builder<? extends DataObject> builder, @Nonnull final Statistics statistics) { ((InterfaceBuilder) builder).setStatistics(statistics); } private InterfaceStatisticsDetails getStatisticsDump(InstanceIdentifier<Statistics> id) throws ReadFailedException { <|startfocus|> LOG.info("Sending InterfaceStatisticsDump request..."); <|endfocus|> final InterfaceStatisticsDump request = new InterfaceStatisticsDump(); final Future<InterfaceStatisticsDetailsReplyDump> replyFuture = jvppStats.interfaceStatisticsDump(request).toCompletableFuture(); final InterfaceStatisticsDetailsReplyDump reply; try { reply = replyFuture.get(); } catch (Exception e) { throw new ReadFailedException(id, e); } if (reply == null || reply.interfaceStatisticsDetails == null) { throw new ReadFailedException(id, new IllegalStateException("Received null response for empty dump: " + reply)); } return reply.interfaceStatisticsDetails; } }
<|startcomment|> bridgedomaincontext <|endcomment|>  public L2Validator(final NamingContext interfaceContext, final NamingContext bridgeDomainContext) { checkNotNull(interfaceContext, "interfaceContext should not be null"); <|startfocus|> checkNotNull(bridgeDomainContext, "interfaceContext should not be null"); <|endfocus|>
<|startcomment|> bridgedomaincontext <|endcomment|>  public SubInterfaceL2Validator(final NamingContext interfaceContext, final NamingContext bridgeDomainContext) { checkNotNull(interfaceContext, "interfaceContext should not be null"); <|startfocus|> checkNotNull(bridgeDomainContext, "interfaceContext should not be null"); <|endfocus|>
<|startcomment|> you can change variable name to match type name disabledInterfacesManager <|endcomment|>  public VxlanValidator(@Nonnull final NamingContext interfaceNamingContext, @Nonnull final DisabledInterfacesManager interfaceDisableContext) { checkNotNull(interfaceNamingContext, "interfaceContext should not be null"); <|startfocus|> checkNotNull(interfaceDisableContext, "DisabledInterfacesManager should not be null"); <|endfocus|>
<|startcomment|> validateVxlan <|endcomment|> <|startfocus|> private void validateGre(final Vxlan data) { <|endfocus|> checkNotNull(data.getSrc(), "Source cannot be null"); checkNotNull(data.getDst(), "Destination cannot be null"); if (data.getSrc().getIpv4AddressNoZone() == null) { checkArgument(data.getDst().getIpv4AddressNoZone() == null, "Inconsistent ip addresses: %s, %s", data.getSrc(), data.getDst()); } else { checkArgument(data.getDst().getIpv6AddressNoZone() == null, "Inconsistent ip addresses: %s, %s", data.getSrc(), data.getDst()); } checkArgument(data.getEncapVrfId() != null && data.getEncapVrfId().getValue() != null, "encap-vrf-id is mandatory but was not given"); checkNotNull(data.getVni(), "VNI cannot be null");
<|startcomment|> Trying to call this when the dialog is disposed (which is likely the only time we would need to) causes an "SWTException: Widget is disposed". Could you add a ModifyHandler to these text fields and have them set a String member (e.g. mProjectNameResult) that we can return here? (TizenDialogPath has example code that does the same.) <|endcomment|> <|startfocus|> public String getTxtProjectName() { return mTxtProjectName.getText(); <|endfocus|>
<|startcomment|> same <|endcomment|> <|startfocus|> public String getTxtProjectID() { return mTxtProjectID.getText(); <|endfocus|>
<|startcomment|> same <|endcomment|> <|startfocus|> public String getTxtProjectPath() { return mTxtProjectPath.getText(); <|endfocus|>
<|startcomment|> bad merge, fix underway. <|endcomment|>  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * */ import javax.annotation.PostConstruct; import org.eclipse.jface.viewers.TreeViewer; import org.eclipse.swt.SWT; import org.eclipse.swt.layout.FormAttachment; import org.eclipse.swt.layout.FormData; import org.eclipse.swt.layout.FormLayout; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Tree; <|startfocus|> import com.samsung.dali.modelconverter.view.dialogs.TizenPathDialog; <|endfocus|> public class SceneGraphPart { @PostConstruct public void createComposite(Composite parent) { TizenPathDialog.VerifyTizenPath(parent.getShell(), false); parent.setLayout(new FormLayout()); TreeViewer treeViewer = new TreeViewer(parent, SWT.BORDER); Tree tree = treeViewer.getTree(); FormData fd_tree = new FormData(); fd_tree.bottom = new FormAttachment(100, -10); fd_tree.right = new FormAttachment(100, -5); fd_tree.top = new FormAttachment(0, 5);
<|startcomment|> Trailing whitespace <|endcomment|>  * See the License for the specific language governing permissions and * limitations under the License. * */ package com.ibm.disni.nvmef; import java.io.IOException; import java.net.URI; import java.nio.ByteBuffer; import com.ibm.disni.DiSNIEndpoint; import com.ibm.disni.nvmef.spdk.*; public class NvmeEndpoint implements DiSNIEndpoint { private final NvmeEndpointGroup group; private NvmeQueuePair queuePair; private NvmeNamespace namespace; private NvmeController controller; private volatile boolean open; private NvmeControllerOptions controllerOptions; <|startfocus|> <|endfocus|> public NvmeEndpoint(NvmeEndpointGroup group, NvmfConnection newConnection) { this.group = group; this.queuePair = null; this.namespace = null; this.open = newConnection != null; } //rdma://<host>:<port> //nvmef:://<host>:<port>/controller/namespace" public synchronized void connect(URI uri) throws IOException { if (open){ return; } NvmeResourceIdentifier nvmeResource = NvmeResourceIdentifier.parse(uri); NvmeTransportId transportId = nvmeResource.toTransportId(); this.controller = group.probe(transportId, nvmeResource.getController());
<|startcomment|> Trailing whitespace <|endcomment|>  return namespace; } NvmeQueuePair getQueuePair() { return queuePair; } public boolean isOpen() { return open; } public synchronized void close() throws IOException, InterruptedException { queuePair.free(); open = false; } public synchronized int processCompletions(long[] completed) throws IOException { return queuePair.processCompletions(completed); } public int getSectorSize() { return namespace.getSectorSize(); } public long getNamespaceSize() { return namespace.getSize(); } <|startfocus|> <|endfocus|> public int getMaxTransferSize() { return namespace.getMaxIOTransferSize(); } public int getIOQueueSize() { return controllerOptions.getIOQueueSize(); } public void keepAlive() throws IOException { controller.keepAlive(); } } 
<|startcomment|> Trailing whitespaces (also at other palces) <|endcomment|>  this.open = false; } //rdma://<host>:<port> //nvmef:://<host>:<port>/controller/namespace" public synchronized void connect(URI uri) throws IOException { if (open){ return; } NvmeResourceIdentifier nvmeResource = NvmeResourceIdentifier.parse(uri); NvmeTransportId transportId = nvmeResource.toTransportId(); NvmeController nvmecontroller = group.probe(transportId, nvmeResource.getController()); this.namespace = nvmecontroller.getNamespace(nvmeResource.getNamespace()); this.queuePair = nvmecontroller.allocQueuePair(); this.open = true; <|startfocus|> this.controllerOptions = nvmecontroller.getOptions(); <|endfocus|> } private enum Operation { READ, WRITE } private NvmeCommand op(Operation op, ByteBuffer buffer, long linearBlockAddress) throws IOException { if (open){ throw new IOException("endpoint is closed"); } if (buffer.remaining() % namespace.getSectorSize() != 0){ throw new IOException("Remaining buffer a multiple of sector size"); } IOCompletion completion = new IOCompletion(); return new NvmeCommand(this, buffer, linearBlockAddress, completion, op == Operation.WRITE); } 
<|startcomment|> Don't want to write id, it's something we use to help the user distinguish between cameras. <|endcomment|> kage com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonIgnore; public class Camera { <|startfocus|> @JsonIgnore <|endfocus|> public int getId() { return mId; } public void setId(int id) { mId = id; } @Override public String toString() { return "Camera " + mId; } public double getFov() { return mFov; } public void setFov(double fov) { mFov = fov; } public double getNear() { return mNear; } public void setNear(double near) { mNear = near; } public double getFar() { return mFar; } public void setFar(double far) { mFar = far; } public double[] getMatrix() { return mMatrix; } public void setMatrix(double[] mtx) { assert mtx == null || mtx.length == 16; mMatrix = mtx; } private double mFov; private double mNear; private double mFar;
<|startcomment|> has to be the singular <|endcomment|>  } public ArrayList<Mesh> getMeshes() { return mMeshes; } public void setMeshes(ArrayList<Mesh> meshes) { mMeshes = meshes; } public ArrayList<Material> getMaterials() { return mMaterials; } public void setMaterials(ArrayList<Material> materials) { mMaterials = materials; } public ArrayList<Shader> getShaders() { return mShaders; } public void setShaders(ArrayList<Shader> shaders) { mShaders = shaders; } <|startfocus|> @JsonProperty("environment") <|endfocus|> public ArrayList<Environment> getEnvironments() { return mEnvironments; } public void setEnvironments(ArrayList<Environment> environments) { mEnvironments = environments; } public void setNodeParents() { for (Node n : mNodes) { for (Integer i : n.getChildIds()) { mNodes.get(i.intValue()).setParent(n); } } } public void setIds() { int id = 1; for (Scene s : mScenes) { s.setId(id); ++id; } 
<|startcomment|> aliasing the getter also works. <|endcomment|> kage com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonProperty; public class Environment { <|startfocus|> @JsonProperty("cubeSpecular") <|endfocus|> public String getSpecularPath() { return mSpecularPath; } public void setSpecularPath(String path) { mSpecularPath = path; } @JsonProperty("cubeDiffuse") public String getDiffusePath() { return mDiffusePath; } public void setDiffusePath(String path) { mDiffusePath = path; } private String mSpecularPath; private String mDiffusePath; } 
<|startcomment|> there's no easy way to have Jackson2 omit members based on whatever criteria; we need to understand a null matrix member as identity. <|endcomment|>  public void setMatrix(double[] data) { <|startfocus|> if(data != null) { mMatrix = MatrixHelper.createMatrix(data); } else { // Null matrix means identity. mMatrix = MatrixHelper.createMatrix(); } <|endfocus|>
<|startcomment|> It turns out that Jackson 2 can pick up everything there's a getter for that satisfies the following criteria: - has a non-void return type, - takes 0 arguments. Therefore, variables don't need to be explicitly ignored, however as we'll see later, getters that meets these criteria, will. The name it will use for writing is what follows "get", camelCased. <|endcomment|> kage com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonProperty; public class Asset { public String getVersion() { return mVersion; } public void setVersion(String version) { mVersion = version; } <|startfocus|> @JsonProperty("version") <|endfocus|> private String mVersion; } 
<|startcomment|> got getters that Jackson can recognise, no need for these. <|endcomment|>  } public double getNear() { return mNear; } public void setNear(double near) { mNear = near; } public double getFar() { return mFar; } public void setFar(double far) { mFar = far; } public double[] getMatrix() { return mMatrix; } public void setMatrix(double[] mtx) { assert mtx == null || mtx.length == 16; mMatrix = mtx; } <|startfocus|> @JsonProperty("fov") <|endfocus|> private double mFov; @JsonProperty("near") private double mNear; @JsonProperty("far") private double mFar; @JsonProperty("matrix") private double[] mMatrix = MatrixHelper.createMatrix(); @JsonIgnore private int mId; } 
<|startcomment|> got getters for all of these. <|endcomment|>  if (rootId != null) { Node n = getNodes().get(rootId.intValue()); n.collect(this, "", map); } } return map; } public List<Node> getNodeChildren(Node n) { ArrayList<Node> kids = new ArrayList<Node>(); for (Integer i : n.getChildIds()) { kids.add(getNodes().get(i.intValue())); } return kids; } @JsonIgnoreProperties(ignoreUnknown = true) <|startfocus|> @JsonProperty("asset") <|endfocus|> private Asset mAsset = new Asset(); @JsonProperty("scene") private int mDefaultSceneId = 0; @JsonProperty("scenes") private ArrayList<Scene> mScenes = new ArrayList<Scene>(); @JsonProperty("nodes") private ArrayList<Node> mNodes = new ArrayList<Node>(); @JsonProperty("cameras") private ArrayList<Camera> mCameras = new ArrayList<Camera>(); @JsonProperty("skybox") private Skybox mSkybox; @JsonProperty("meshes") private ArrayList<Mesh> mMeshes = new ArrayList<Mesh>(); 
<|startcomment|> it's the getters that need to be @JsonIgnored <|endcomment|>  } @JsonSetter("nodes") public void setNodes(ArrayList<Integer> nodes) { if (nodes.size() != 1) { throw new IllegalArgumentException("Scene.nodes must be an array of a single node index. Sorry about that."); } mRootId = nodes.get(0).intValue(); } @JsonGetter("nodes") public ArrayList<Integer> getNodes() { ArrayList<Integer> nodes = new ArrayList<Integer>(); nodes.add(new Integer(mRootId)); return nodes; } <|startfocus|> @JsonIgnore <|endfocus|> private int mId = -1; @JsonIgnore private boolean mIsOrphan = false; @JsonIgnore // custom setter / getter provided -- json representation is an array of a // single integer element. private Integer mRootId = -1; } 
<|startcomment|> this was resulting in duplication of data [in json] that was already obtained via the getter (and under the wrong name). <|endcomment|>  } } else { throw new IllegalArgumentException("Unknown type: " + value.getClass().getName()); } } @JsonAnyGetter public Map<String, Object> get() { Map<String, Object> values = new TreeMap<String, Object>(); for (Entry<String, Uniform> u : mUniforms.entrySet()) { values.put(u.getKey(), u.getValue().getValue()); } return values; } <|startfocus|> @JsonProperty("vertex") <|endfocus|> private String mVertexPath; @JsonProperty("fragment") private String mFragmentPath; @JsonProperty("renderMode") private int mRenderMode; @JsonIgnore // custom any getter / setter provided - uniforms may be arbitrary sibling // elements to vertex path / fragment path / render mode. private Map<String, Uniform> mUniforms; } 
<|startcomment|> getters are the future. <|endcomment|> kage com.samsung.dali.modelconverter.data.document; import com.fasterxml.jackson.annotation.JsonProperty; public class Skybox { public String getTexture() { return mTexture; } public void setTexture(String mTexture) { this.mTexture = mTexture; } <|startfocus|> @JsonProperty("texture") <|endfocus|> private String mTexture; } 
<|startcomment|> is this variable necessary? <|endcomment|>  * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * */ public class ModelExporter { private static boolean sInitialised = false; public static void initialise() { <|startfocus|> if(!sInitialised) { System.loadLibrary("model-exporter-jni"); sInitialised = true; } <|endfocus|> } /** * @brief Performs model export, loading a .dae file, and writing .bin and * .dli files. * @param inputFile - path to the .dae file to process. Required. * @param outputName - the name and path to save the .dli and .bin files to. * Optional. Will use the input path and name if omitted.
<|startcomment|> parameter names in doc doesn't match with the ones in the header <|endcomment|>  * See the License for the specific language governing permissions and * limitations under the License. * */ public class ModelExporter { static { System.loadLibrary("model-exporter-jni"); } /** * @brief Performs model export, loading a .dae file, and writing .bin and * .dli files. <|startfocus|> * @param inputFile - path to the .dae file to process. Required. * @param outputName - the name and path to save the .dli and .bin files to. <|endfocus|> * Optional. Will use the input path and name if omitted. * @return 0 on success, 1 on failure. */ public static native int nativeExport(String inputPath, String outputPath); /** * @brief Performs model conversion, loading a .dae file, and converting * it to the DLI format. In case of success, the dli and binary * contents can be retrieved by calling nativeGetDli/BinContents(). * @param inputFile - path to the .dae file to process. Required.
<|startcomment|> white spaces <|endcomment|>  import com.fasterxml.jackson.annotation.JsonIgnore; import com.samsung.dali.modelconverter.data.document.property.Property; public class Camera implements Property.Provider { @JsonIgnore public int getId() { return mId; } public void setId(int id) { mId = id; } @Override public String toString() { return "Camera " + mId; } public double getFov() { return mFov; } public void setFov(Number fov) { mFov = fov.doubleValue(); } <|startfocus|> <|endfocus|> public double getNear() { return mNear; } public void setNear(Number near) { mNear = near.doubleValue(); } public double getFar() { return mFar; } public void setFar(Number far) { mFar = far.doubleValue(); } public double[] getMatrix() { return mMatrix; } public void setMatrix(double[] mtx) { assert mtx == null || mtx.length == 16; mMatrix = mtx; } @Override
<|startcomment|> white spaces <|endcomment|>  for (int i = 0; i < 3; ++i) { matrix[12 + i] = translation[i]; } } public static double[] getRotation(double[] matrix) { double[] rotation = new double[] { Math.atan2(matrix[6], matrix[10]), Math.atan2(-matrix[2], Math.sqrt(matrix[6] * matrix[6] + matrix[10] * matrix[10])), Math.atan2(matrix[1], matrix[0]) }; return rotation; } <|startfocus|> // TODO: public static void setRotation(double[] rotation, double[] matrix) <|endfocus|> public static double[] getScale(double[] matrix) { double[] scale = new double[] { getColumnMagnitude(matrix, 0), getColumnMagnitude(matrix, 1), getColumnMagnitude(matrix, 2) }; return scale; } public static void setScale(double[] scale, double[] matrix) { double[] scaleCurr = getScale(matrix); for (int i = 0; i < 3; ++i) { scale[i] /= scaleCurr[i]; } 
<|startcomment|> white space <|endcomment|>  } public static SceneGraphPart getSceneGraphPart() { if (SceneGraphPart.sActiveInstance == null) { createPart("com.samsung.dali.modelconverter.part.scenegraph"); assert SceneGraphPart.sActiveInstance != null; } return SceneGraphPart.sActiveInstance; } public static NodePropertiesPart getNodePropertiesPart() { if (NodePropertiesPart.sActiveInstance == null) { createPart("com.samsung.dali.modelconverter.part.nodeproperties"); assert NodePropertiesPart.sActiveInstance != null; } return NodePropertiesPart.sActiveInstance; } <|startfocus|> static void createPart(String id) { <|endfocus|> Bundle bundle = FrameworkUtil.getBundle(EPartService.class); BundleContext bundleContext = bundle.getBundleContext(); IEclipseContext eclipseContext = EclipseContextFactory.getServiceContext(bundleContext); EPartService partService = (EPartService)eclipseContext.get(EPartService.class); partService.showPart(id, PartState.CREATE); } } 
<|startcomment|> white space <|endcomment|>  public void createComposite(Composite parent) { parent.setLayout(new GridLayout(1, false)); mParent = parent; resetProperties(); <|startfocus|> <|endfocus|> sActiveInstance = this;
<|startcomment|> White spaces <|endcomment|>  public void populate(SceneGraphContentProvider provider, SceneGraphSelectionChangedListener selectionChangedListener) { mTree.removeAll(); if(mSelectionChangedListener != null) { mTreeViewer.removeSelectionChangedListener(mSelectionChangedListener); } mTreeViewer.addSelectionChangedListener(selectionChangedListener); <|startfocus|> <|endfocus|> mTreeViewer.setContentProvider(provider); mTreeViewer.setInput(provider.getDocument()); mTreeViewer.refresh();
<|startcomment|> white space <|endcomment|>  GridData gd_mOptions = new GridData(SWT.LEFT, SWT.CENTER, false, false, 1, 1); gd_mOptions.widthHint = 240; mOptions.setLayoutData(gd_mOptions); } public IdPropertyWidget setRange(Collection<?> values) { mOptions.removeAll(); for(Object o: values) { mOptions.add(o.toString()); } return this; } public IdPropertyWidget setWritable(boolean isWritable) { mOptions.setEnabled(isWritable); return this; } <|startfocus|> <|endfocus|> public IdPropertyWidget setSelection(int i) { mOptions.select(i); mOptions.update(); return this; } private Combo mOptions; } 
<|startcomment|> white space <|endcomment|> kage com.samsung.dali.modelconverter.view.widgets; import org.eclipse.swt.SWT; import org.eclipse.swt.layout.GridData; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Text; /* <|startfocus|> * A widget for a property whose value can be presented as a text entry. <|endfocus|> */ public class TextPropertyWidget extends PropertyWidgetBase { public TextPropertyWidget(Composite parent, int style) { super(parent, style); mText = new Text(parent, SWT.BORDER); GridData gd_mText = new GridData(SWT.LEFT, SWT.CENTER, false, false, 1, 1); gd_mText.widthHint = 200; mText.setLayoutData(gd_mText); } public TextPropertyWidget setWritable(boolean isWritable) { mText.setEnabled(isWritable); return this; } public TextPropertyWidget setValue(String value) { mText.setText(value); return this; } private Text mText; } 
<|startcomment|> white space <|endcomment|>  mRx.setText(df.format(rotation[0])); mRy.setText(df.format(rotation[1])); mRz.setText(df.format(rotation[2])); return this; } public TransformPropertyWidget setWritable(boolean isWritable) { mTx.setEnabled(isWritable); mTy.setEnabled(isWritable); mTz.setEnabled(isWritable); mSx.setEnabled(isWritable); mSy.setEnabled(isWritable); mSz.setEnabled(isWritable); mRx.setEnabled(isWritable); mRy.setEnabled(isWritable); mRz.setEnabled(isWritable); return this; } <|startfocus|> <|endfocus|> private Text mTx; private Text mTy; private Text mTz; private Text mSx; private Text mSy; private Text mSz; private Text mRx; private Text mRy; private Text mRz; } 
<|startcomment|> white spaces <|endcomment|> public class Document { static public Document fromDli(String dli) throws JsonParseException, JsonMappingException, IOException { ObjectMapper mapper = new ObjectMapper(); mapper.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES); Document d = mapper.readValue(dli, Document.class); // TODO: the following could perhaps be on an option to fromDli(). d.setNodeParents(); d.setIds(); d.organizeOrphans(); return d; } public String toDliString() throws JsonProcessingException { ObjectMapper mapper = new ObjectMapper(); <|startfocus|> <|endfocus|> DefaultPrettyPrinter.Indenter indenter = new DefaultIndenter(" ", DefaultIndenter.SYS_LF); DefaultPrettyPrinter printer = new DefaultPrettyPrinter(); printer.indentObjectsWith(indenter); return mapper.writer(printer).writeValueAsString(this); } public Asset getAsset() { return mAsset; } public void setAsset(Asset asset) { mAsset = asset; } @JsonProperty("scene") public int getDefaultSceneId() { return mDefaultSceneId; } public void setDefaultSceneId(int defaultSceneId) { mDefaultSceneId = defaultSceneId;
<|startcomment|> This addCommand( ... { } ).run() line is difficult to read and in the middle of the definition it declares and defines a parseLine() method. It may be java style which I'm not used to but I find it difficult to read and follow. <|endcomment|>  public static void execute(Shell shell, List<String> outProfiles) { assert outProfiles != null; OutputPart op = GlobalParts.getOutputPart(); LoggingProcessRunner lpr = LoggingProcessRunner.create(shell.getDisplay(), op.getText()); <|startfocus|> lpr.addCommand(GlobalData.get().getTizenPath() + " security-profiles list", new LoggingProcessRunner.Parser() { <|endfocus|> @Override public void parseLine(String line) { if (mCare) { if (!line.isEmpty()) { int iSpace = line.indexOf(' '); if (iSpace != -1) { line = line.substring(0, iSpace); } outProfiles.add(line); } } else { mCare = line.startsWith("[Profile Name]"); } } private boolean mCare = false; }).run();
<|startcomment|> a given list of resources <|endcomment|> kage com.samsung.dali.modelconverter.controller; import java.util.ArrayList; import org.eclipse.jface.viewers.ITreeContentProvider; import com.samsung.dali.modelconverter.data.document.Document; /* <|startfocus|> * Provides descriptions of the meshes. <|endfocus|> */ public class ResourceContentProvider implements ITreeContentProvider { public ResourceContentProvider(Document doc, Class<?> type) { mDocument = doc; mType = type; } public Object getDocument() { return mDocument; } /* * Get the top level nodes from an element, which should only be the Document * that the provider was created with. The nodes are meshes. */ @Override public Object[] getElements(Object inputElement) { assert inputElement == mDocument; ArrayList<Object> kids = new ArrayList<Object>(); return kids.toArray(); } @Override public Object[] getChildren(Object parentElement) { return null; } @Override public Object getParent(Object element) { return null; } @Override public boolean hasChildren(Object element) { return false; } private Document mDocument;
<|startcomment|> This doesn't apply here - should just return the array of resources that it was created with. <|endcomment|>  import org.eclipse.jface.viewers.ITreeContentProvider; import com.samsung.dali.modelconverter.data.document.Document; /* * Provides descriptions of the meshes. */ public class ResourceContentProvider implements ITreeContentProvider { public ResourceContentProvider(Document doc, Class<?> type) { mDocument = doc; mType = type; } public Object getDocument() { return mDocument; } /* <|startfocus|> * Get the top level nodes from an element, which should only be the Document * that the provider was created with. The nodes are meshes. <|endfocus|> */ @Override public Object[] getElements(Object inputElement) { assert inputElement == mDocument; ArrayList<Object> kids = new ArrayList<Object>(); return kids.toArray(); } @Override public Object[] getChildren(Object parentElement) { return null; } @Override public Object getParent(Object element) { return null; } @Override public boolean hasChildren(Object element) { return false; } private Document mDocument; private Class<?> mType; } 
<|startcomment|> This introduces a dependency of the View on the Model, which we want to avoid at all costs. <|endcomment|>  * See the License for the specific language governing permissions and * limitations under the License. * */ import javax.annotation.PostConstruct; import org.eclipse.jface.viewers.ISelectionChangedListener; import org.eclipse.jface.viewers.TreeViewer; import org.eclipse.swt.SWT; import org.eclipse.swt.widgets.Composite; import org.eclipse.swt.widgets.Tree; import com.samsung.dali.modelconverter.controller.PropertyProviderSelectionChangedListener; <|startfocus|> import com.samsung.dali.modelconverter.controller.ResourceContentProvider; import com.samsung.dali.modelconverter.data.document.Animation; <|endfocus|> public class AnimationPart { public static final String sId = "com.samsung.dali.modelconverter.part.animations"; @PostConstruct public void createComposite(Composite parent) { mTreeViewer = new TreeViewer(parent, SWT.BORDER); mTree = mTreeViewer.getTree(); } public void populate(ResourceContentProvider<Animation> provider, PropertyProviderSelectionChangedListener listener) { mTree.removeAll(); if (mSelectionChangedListener != null) { mTreeViewer.removeSelectionChangedListener(mSelectionChangedListener); } mTreeViewer.addSelectionChangedListener(listener); mTreeViewer.setContentProvider(provider); mTreeViewer.setInput(null); mTreeViewer.refresh();
<|startcomment|> See above; this could be just ITreeContentProvider. In SceneGraphPart we only use a more concrete class because we get the input object from it (since it already had it), however note that it's an an object (so as to avoid the dependency on Model). <|endcomment|> <|startfocus|> public void populate(ResourceContentProvider<Animation> provider, PropertyProviderSelectionChangedListener listener) { <|endfocus|> mTree.removeAll(); if (mSelectionChangedListener != null) { mTreeViewer.removeSelectionChangedListener(mSelectionChangedListener); } mTreeViewer.addSelectionChangedListener(listener); mTreeViewer.setContentProvider(provider); mTreeViewer.setInput(null); mTreeViewer.refresh();
<|startcomment|> Unless I've missed something, these annotations are not necessary, JACKSON 2 should pick the correct property names up from public getters / setters (that return / take objects of the correct type). <|endcomment|>  mAttributes = a; } public String getAttributeFlags() { String flags = ""; if (mIndices != null) { flags += "I"; } if (mUvs != null) { flags += "U"; } if (mNormals != null) { flags += "N"; } if (mTangents != null) { flags += "T"; } if (mBitangents != null) { flags += "B"; } return flags; } <|startfocus|> @JsonGetter("indices") <|endfocus|> public BufferRef getIndices() { return mIndices; } @JsonSetter("indices") public void setIndices(BufferRef br) { mIndices = br; } @JsonGetter("positions") public BufferRef getPositions() { return mPositions; } @JsonSetter("positions") public void setPositions(BufferRef br) { mPositions = br; } @JsonGetter("normals") public BufferRef getNormals() { return mNormals; } @JsonSetter("normals") public void setNormals(BufferRef br) {
<|startcomment|> (index + 1) -- the Json property is called Texture1-4 <|endcomment|>  public void provideProperties(Document context, Property.IReceiver receiver) { try { for( int index = 0; index < mTextures.length; index++ ) { <|startfocus|> receiver.register("Texture" + index, new Property(this, "TextureArray", Property.Type.String, true, null, new ArrayElementSetter(index), String[].class)); <|endfocus|> } } catch (NoSuchFieldException | NoSuchMethodException e) { // TODO Auto-generated catch block e.printStackTrace(); }
<|startcomment|> same <|endcomment|>  Collection<?> values = property.getRange(); try { switch (property.getType()) { case Integer: { // TODO: enable editing Integer number = 0; Object object = property.get(); if( null != object ) { number = (Integer)object; } new TextPropertyWidget(mPart.getComposite(), style).setWritable(false) .setValue(Integer.toString( number )).setName(name); break; } case Number: { // TODO: enable editing <|startfocus|> Double number = 0.0; <|endfocus|> Object object = property.get(); if( null != object ) { number = (Double)object; } new TextPropertyWidget(mPart.getComposite(), style).setWritable(false) .setValue(Double.toString( number )).setName(name); break; } case String: { // TODO: enable editing String string = ""; Object object = property.get(); if( null != object ) { string = (String)object; } new TextPropertyWidget(mPart.getComposite(), style).setWritable(false)
<|startcomment|> It's not necessary to wrap the original exception with a new exception, unless you want to prepend "Unable to login" to the original exception message. The following code would work just fine since there's already a try-catch block in line 203: Password password = new Password(tokenPassword.toCharArray()); token.login(password); If there's a problem in token.login() the exception probably would have provided detailed information about the problem already. <|endcomment|>  String issuanceProtCertNick = cmd.getOptionValue("n"); String output = cmd.getOptionValue("o"); try { CryptoManager.initialize(databaseDir); CryptoManager manager = CryptoManager.getInstance(); CryptoToken token = CryptoUtil.getKeyStorageToken(tokenName); tokenName = token.getName(); manager.setThreadToken(token); Password password = new Password(tokenPassword.toCharArray()); <|startfocus|> try { token.login(password); } catch (Exception e) { throw new Exception("Unable to login: " + e, e); } <|endfocus|> X509Certificate issuanceProtCert = null; if (issuanceProtCertFilename != null) { if (verbose) System.out.println("Loading issuance protection certificate"); String encoded = new String(Files.readAllBytes(Paths.get(issuanceProtCertFilename))); byte[] issuanceProtCertData = Cert.parseCertificate(encoded); issuanceProtCert = manager.importCACertPackage(issuanceProtCertData); if (verbose) System.out.println("issuance protection certificate imported"); } else { // must have issuance protection cert nickname if file not provided
<|startcomment|> do we need to put this into a finally like for handleReadEvent <|endcomment|>  } } public void handleWriteEvent() throws IOException { for (int i = 0; i < maxBatchIoOps; i++) { final NetlinkRequest request = writeQueue.poll(); if (request == null) break; final int ret = processWriteToChannel(request); if (ret <= 0) { if (ret < 0) { log.warn("NETLINK write() error: {}", CLibrary.strerror(Native.getLastError())); } break; } } <|startfocus|> expireOldRequests(); dispatcher.endBatch(); <|endfocus|> } private int processWriteToChannel(final NetlinkRequest request) { if (request == null) return 0; ByteBuffer outBuf = request.releaseRequestPayload(); if (outBuf == null) return 0; int seq = writeSeqToNetlinkRequest(request, outBuf); if (request.hasCallback()) { pendingRequests.put(seq, request); } log.trace("Sending message for id {}", seq); int bytes = 0; try { bytes = channel.write(outBuf); if (request.hasCallback()) expirationQueue.add(request);
<|startcomment|> Are these lines not needed anymore? Would you please remove them in that case? <|endcomment|>  wrList_recv.add(recvWR); //it's important to post those receive operations before connecting //otherwise the server may issue a send operation and which cannot be received //this class wraps soem of the RDMA data operations VerbsTools commRdma = new VerbsTools(context, compChannel, qp, cq); commRdma.initSGRecv(wrList_recv); //now let's connect to the server RdmaConnParam connParam = new RdmaConnParam(); <|startfocus|> //connParam.setInitiator_depth((byte) 5); //connParam.setResponder_resources((byte) 5); <|endfocus|> connParam.setRetry_count((byte) 2); ret = idPriv.connect(connParam); if (ret < 0){ System.out.println("VerbsClient::connect failed"); return; } //wait until we are really connected cmEvent = cmChannel.getCmEvent(-1); if (cmEvent == null){ System.out.println("VerbsClient::cmEvent null"); return; } else if (cmEvent.getEvent() != RdmaCmEvent.EventType.RDMA_CM_EVENT_ESTABLISHED .ordinal()) {
<|startcomment|> Will you take an action based on the outcome of the query? <|endcomment|>  RdmaCmId connId = cmEvent.getConnIdPriv(); if (connId == null){ System.out.println("VerbsServer::connId null"); return; } //get the device context of the new connection, typically the same as with the server id IbvContext context = connId.getVerbs(); if (context == null){ System.out.println("VerbsServer::context null"); return; } <|startfocus|> // Query for on demand paging memory prefecth support int rcOdpCaps = context.queryOdpSupport(); if (rcOdpCaps == -1){ System.out.println("VerbsServer::On demand paging is not supported for this device"); } <|endfocus|> //create a new protection domain, we will use the pd later when registering memory IbvPd pd = context.allocPd(); if (pd == null){ System.out.println("VerbsServer::pd null"); return; } //the comp channel is used to get CQ notifications IbvCompChannel compChannel = context.createCompChannel(); if (compChannel == null){ System.out.println("VerbsServer::compChannel null"); return; } 
<|startcomment|> Same here <|endcomment|>  if (qp == null){ System.out.println("VerbsServer::qp null"); return; } int buffercount = 3; int buffersize = 100; ByteBuffer buffers[] = new ByteBuffer[buffercount]; IbvMr mrlist[] = new IbvMr[buffercount]; int access = IbvMr.IBV_ACCESS_LOCAL_WRITE | IbvMr.IBV_ACCESS_REMOTE_WRITE | IbvMr.IBV_ACCESS_REMOTE_READ; RdmaConnParam connParam = new RdmaConnParam(); <|startfocus|> //connParam.setInitiator_depth((byte) 5); //connParam.setResponder_resources((byte) 5); <|endfocus|> connParam.setRetry_count((byte) 2); //once the client id is set up, accept the connection ret = connId.accept(connParam); if (ret < 0){ System.out.println("VerbsServer::accept failed"); return; } //wait until the connection is officially switched into established mode cmEvent = cmChannel.getCmEvent(-1); if (cmEvent.getEvent() != RdmaCmEvent.EventType.RDMA_CM_EVENT_ESTABLISHED .ordinal()) { System.out.println("VerbsServer::wrong event received: " + cmEvent.getEvent()); return; }
<|startcomment|> I assume that this is just an example of how to query for odp support and you want to keep it in this server. <|endcomment|>  System.out.println("VerbsServer::connId null"); return; } //get the device context of the new connection, typically the same as with the server id IbvContext context = connId.getVerbs(); if (context == null){ System.out.println("VerbsServer::context null"); return; } <|startfocus|> // Query for on demand paging memory prefecth support int rcOdpCaps = context.queryOdpSupport(); if (rcOdpCaps == -1){ System.out.println("VerbsServer::On demand paging is not supported for this device"); } <|endfocus|> //create a new protection domain, we will use the pd later when registering memory IbvPd pd = context.allocPd(); if (pd == null){ System.out.println("VerbsServer::pd null"); return; } //the comp channel is used to get CQ notifications IbvCompChannel compChannel = context.createCompChannel(); if (compChannel == null){ System.out.println("VerbsServer::compChannel null"); return; } //create a completion queue IbvCQ cq = context.createCQ(compChannel, 50, 0);
<|startcomment|> Peter, I think that if we would like to demonstrate how to use ODP, we should implement it all the way - e.g. register the entire process address space, avoid per buffer registrations and use prefetches instead. <|endcomment|>  return; } //get the device context of the new connection, typically the same as with the server id IbvContext context = connId.getVerbs(); if (context == null){ System.out.println("VerbsServer::context null"); return; } <|startfocus|> // Query for on demand paging memory prefecth support int rcOdpCaps = context.queryOdpSupport(); if (rcOdpCaps == -1){ System.out.println("VerbsServer::On demand paging is not supported for this device"); } <|endfocus|> //create a new protection domain, we will use the pd later when registering memory IbvPd pd = context.allocPd(); if (pd == null){ System.out.println("VerbsServer::pd null"); return; } //the comp channel is used to get CQ notifications IbvCompChannel compChannel = context.createCompChannel(); if (compChannel == null){ System.out.println("VerbsServer::compChannel null"); return; } //create a completion queue IbvCQ cq = context.createCQ(compChannel, 50, 0); if (cq == null){
<|startcomment|> Do something with this exception, don't jus swallow. This seems to have undefined action at this point. <|endcomment|>  // have a chance to capture user identification info if (issuerANY != null) { try { byte[] issuerBytes = issuerANY.getEncoded(); X500Name issuerName = new X500Name(issuerBytes); CMS.debug(method + "revRequest issuer name = " + issuerName.toString()); // capture issuer principal to be checked against // cert issuer principal later in CMCOutputTemplate auditContext.put(SessionContext.CMC_ISSUER_PRINCIPAL, issuerName); <|startfocus|> } catch (Exception e) { <|endfocus|> } } //authToken.set("uid", uid); //authToken.set("userid", userid); } } } } } else { CMS.debug(method + "numReqs not 0, assume enrollment request"); // enrollment request // reset value of auditReqType auditReqType = SIGNED_AUDIT_ENROLLMENT_REQUEST_TYPE; X509CertInfo[] certInfoArray = new X509CertInfo[numReqs]; String[] reqIdArray = new String[numReqs]; 
<|startcomment|> Change this line to `new PasswordConverter(),`. It will make OpenSSL happy, so hopefully Tomcat/Java too. <|endcomment|>  encSafeContents.addElement(safeBag); } public ASN1Value create_EPKI_with_PBE_SHA1_DES3_CBC(CryptoToken token, PrivateKey privateKey, Password password) throws Exception { // The salt size and number of iterations are selected to match pk12util. byte[] salt = new byte[16]; random.nextBytes(salt); return EncryptedPrivateKeyInfo.createPBE( PBEAlgorithm.PBE_SHA1_DES3_CBC, password, salt, 100000, // iterations <|startfocus|> null, // password converter <|endfocus|> privateKey, token); } public ASN1Value create_EPKI_with_PBE_PKCS5_PBES2(CryptoToken token, PrivateKey privateKey, Password password) throws Exception { CryptoStore store = token.getCryptoStore(); byte[] bytes = store.getEncryptedPrivateKeyInfo( // For compatibility with OpenSSL and NSS >= 3.31, // do not BMPString-encode the passphrase when using // non-PKCS #12 PBE scheme such as PKCS #5 PBES2. // // The resulting PKCS #12 is not compatible with // NSS < 3.31. null, // password converter password,
<|startcomment|> unnecessary empty line <|endcomment|>  public void performCollectionAndGetResult(String requestId, JsonObject feature, Handler<AsyncResult<CollectorJobResult>> resultHandler) { dcs.performCollectionAndGetResult(requestId, feature, res -> resultHandler.handle(checkForError(res))); <|startfocus|> <|endfocus|>
<|startcomment|> empty line <|endcomment|> kage info.pascalkrause.vertx.datacollector.client.error; import info.pascalkrause.vertx.datacollector.client.error.DataCollectorError; public class QueueLimitReached extends DataCollectorError { private static final long serialVersionUID = 1L; <|startfocus|> <|endfocus|> } 
<|startcomment|> inside the future. <|endcomment|> kage info.pascalkrause.vertx.datacollector.job; import io.vertx.core.AsyncResult; import io.vertx.core.Future; import io.vertx.core.Handler; import io.vertx.core.json.JsonObject; /** * A generic interface which must be implemented to run the collection job inside the CollectorJobExecutor worker pool. */ public interface CollectorJob { /** * This method should be used to create a Future that contains the collection logic. The Future will be executed in <|startfocus|> * a worker thread pool, which allows blocking operations inside. <|endfocus|> * * @param requestId A request id to identify the collection request. * @param feature A JSON object to pass attributes and properties which are needed for the collection process. * @return A Handler with the Future which contains the collection logic. */ public Handler<Future<CollectorJobResult>> collect(String requestId, JsonObject feature); /** * This method will be called after the {@link #collect(String, JsonObject)} and returns a Future which can be used
<|startcomment|> logic <|endcomment|>  * to do some post collect stuff like rough parsing or saving the result into a database. The Future will be * executed in a worker thread pool, which allows blocking operations inside. * * @param result The {@link CollectorJobResult} from the previous called {@link #collect(String, JsonObject)} * method. <|startfocus|> * @return A Handler with the Future which contains the post collection action. <|endfocus|> */ public Handler<Future<CollectorJobResult>> postCollectAction(AsyncResult<CollectorJobResult> result); } 
<|startcomment|> empty line <|endcomment|>  } public Optional<Error> getError() { return Error.fromJson(data.getJsonObject(KEY_ERROR)); } public JsonObject toJson() { return data; } @Override public int hashCode() { return data.hashCode(); } @Override public boolean equals(Object obj) { if ((obj instanceof CollectorJobResult) && (hashCode() == obj.hashCode())) { return true; } return false; } @Override public String toString() { return data.toString(); } <|startfocus|> <|endfocus|> } 
<|startcomment|> private final? <|endcomment|>  public static final String METRIC_TOTAL_JOBS_COUNT = "totalJobsCount"; private final Counter totalJobsCounter; public static final String METRIC_TOTAL_JOBS_FAILED = "totalJobsFailed"; private final Counter totalJobsFailed; public static final String METRIC_TOTAL_JOBS_SUCCEEDED = "totalJobsSucceeded"; private final Counter totalJobsSucceeded; public static final String METRIC_TOTAL_JOBS_EXCEPTION = "totalJobsException"; private final Counter totalJobsException; private final MetricRegistry metricRegistry; <|startfocus|> Map<String, AtomicLong> qualityMap = new ConcurrentHashMap<>(); Map<String, AtomicLong> errorMap = new ConcurrentHashMap<>(); <|endfocus|> private Map<String, Object> sortDescendingAndSlice(Map<String, AtomicLong> unsorted, long maxEntries) { return unsorted.entrySet().stream().map(e -> new SimpleEntry<String, Long>(e.getKey(), e.getValue().get())) .sorted(Map.Entry.comparingByValue()).limit(maxEntries).collect(Collectors.toMap(e -> e.getKey(), e -> e.getValue(), (oldValue, newValue) -> oldValue, LinkedHashMap::new)); } 
<|startcomment|> registerQueueMetrics <|endcomment|> <|startfocus|> public void addQueueMetrics(AtomicInteger currentQueueSize, int queueSize) { <|endfocus|> metricRegistry.register(MetricRegistry.name(METRIC_QUEUE_MAX_SIZE), (Gauge<Integer>) () -> queueSize); metricRegistry.register(MetricRegistry.name(METRIC_QUEUE_FREE), (Gauge<Integer>) () -> queueSize - currentQueueSize.get()); metricRegistry.register(MetricRegistry.name(METRIC_QUEUE_OCCUPIED), (Gauge<Integer>) () -> currentQueueSize.get());
<|startcomment|> registerTotalMetrics <|endcomment|> <|startfocus|> public void addTotalMetricsCounters(AsyncResult<CollectorJobResult> postResult) { <|endfocus|> totalJobsCounter.inc(); if (postResult.succeeded()) { final Optional<Error> e = postResult.result().getError(); if (e.isPresent()) { totalJobsFailed.inc(); addOrIncrease(errorMap, e.get().getName()); } else { totalJobsSucceeded.inc(); addOrIncrease(qualityMap, postResult.result().getQuality()); } } else { totalJobsException.inc(); }
<|startcomment|> space <|endcomment|>  metricFactory.addTotalMetricsCounters(postResult); } resultHandler.handle(postResult); }); }); } else { resultHandler.handle(Future.failedFuture(ERROR_QUEUE_LIMIT_REACHED)); } } @Override public void performCollection(String requestId, JsonObject feature, Handler<AsyncResult<Void>> resultHandler) { performCollectionAndGetResult(requestId, feature, res -> { resultHandler.handle(res.failed() ? Future.failedFuture(res.cause()) : Future.succeededFuture()); }); } /** * Visible for Testing <|startfocus|> * * @return <|endfocus|> */ public JsonObject getMetricsSnapshot() { return Objects.isNull(metricFactory) ? new JsonObject().put("Error", "Metrics are not enabled") : metricFactory.getMetricsSnapshot(); } @Override public void getMetricsSnapshot(Handler<AsyncResult<JsonObject>> resultHandler) { resultHandler.handle(Future.succeededFuture(getMetricsSnapshot())); } @Override public void close() { // Needed for generated Client } } 
<|startcomment|> really? <|endcomment|>  private CollectorJobResult generateResult(String requestId, CollectorJobResult.Error error) { <|startfocus|> return new CollectorJobResult(requestId, "test-source", "test-quality", "test-created", new JsonObject(), error); <|endfocus|>
<|startcomment|> empty line <|endcomment|>  } catch (final InterruptedException e) { e.printStackTrace(); } } if (Objects.nonNull(stopper) && feature.containsKey(KEY_STOP)) { stopper.await(TimeUnit.SECONDS.toMillis(1)); } if (feature.containsKey(KEY_UNHANDLED_EXCEPTION)) { throw new RuntimeException("Some unhandled excpetion"); } else if (feature.containsKey(KEY_HANDLED_EXCEPTION)) { fut.fail(new RuntimeException("Some handled exception")); } else { fut.complete(jobResult); } }; } <|startfocus|> <|endfocus|> } 
<|startcomment|> Do we care if certs has nothing in it or null? First the log won't happen and then below it will try to reference certs[0]. Maybe it's assured not to happen. Same in the checkServerTrusted method. <|endcomment|> import java.util.Collection; import java.util.logging.Logger; import javax.net.ssl.X509TrustManager; import org.mozilla.jss.CryptoManager; import org.mozilla.jss.CryptoManager.NotInitializedException; import netscape.security.x509.X509CertImpl; public class PKITrustManager implements X509TrustManager { final static Logger logger = Logger.getLogger(PKITrustManager.class.getName()); @Override public void checkClientTrusted(X509Certificate[] certs, String authType) throws CertificateException { logger.fine("PKITrustManager: checkClientTrusted(" + authType + "):"); <|startfocus|> for (X509Certificate cert : certs) { logger.fine("PKITrustManager: - " + cert.getSubjectDN()); <|endfocus|> } try { CryptoManager manager = CryptoManager.getInstance(); X509Certificate cert = certs[0]; if (!manager.isCertValid(cert.getEncoded(), true, CryptoManager.CertUsage.SSLClient)) { throw new CertificateException("Missing SSLClient certificate usage: " + cert.getSubjectDN()); } logger.fine("PKITrustManager: certificate is valid"); } catch (CertificateException e) { throw e; } catch (Exception e) {
<|startcomment|> Looks like the two methods are nearly the same. MAYBE we could make a common one that is called from both places? <|endcomment|>  } try { CryptoManager manager = CryptoManager.getInstance(); X509Certificate cert = certs[0]; if (!manager.isCertValid(cert.getEncoded(), true, CryptoManager.CertUsage.SSLClient)) { throw new CertificateException("Missing SSLClient certificate usage: " + cert.getSubjectDN()); } logger.fine("PKITrustManager: certificate is valid"); } catch (CertificateException e) { throw e; } catch (Exception e) { throw new CertificateException(e); } } @Override <|startfocus|> public void checkServerTrusted(X509Certificate[] certs, String authType) throws CertificateException { <|endfocus|> logger.fine("PKITrustManager: checkServerTrusted(" + authType + "):"); for (X509Certificate cert : certs) { logger.fine("PKITrustManager: - " + cert.getSubjectDN()); } try { CryptoManager manager = CryptoManager.getInstance(); X509Certificate cert = certs[0]; if (!manager.isCertValid(cert.getEncoded(), true, CryptoManager.CertUsage.SSLServer)) { throw new CertificateException("Missing SSLServer certificate usage: " + cert.getSubjectDN()); } 
<|startcomment|> Please add a space before the curly bracket. <|endcomment|>  } } if (aid != null && adn != null) { throw new Exception("--issuer-id and --issuer-dn options are mutually exclusive"); } MainCLI mainCLI = (MainCLI)parent.getParent(); File certDatabase = mainCLI.certDatabase; String password = mainCLI.config.getCertPassword(); if (password == null) { throw new Exception("Missing security database password."); } String csr; PKIClient client; if ("pkcs10".equals(requestType)) { <|startfocus|> if ("rsa".equals(algorithm)){ <|endfocus|> csr = generatePkcs10Request(certDatabase, password, algorithm, Integer.toString(length), subjectDN); } else if ("ecc".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, curve, subjectDN); } else{ throw new Exception("Invalid algorithm specified."); } // initialize database after PKCS10Client to avoid conflict mainCLI.init(); client = getClient(); } else if ("crmf".equals(requestType)) { // initialize database before CRMFPopClient to load transport certificate
<|startcomment|> Please use spaces instead of tab. <|endcomment|>  } MainCLI mainCLI = (MainCLI)parent.getParent(); File certDatabase = mainCLI.certDatabase; String password = mainCLI.config.getCertPassword(); if (password == null) { throw new Exception("Missing security database password."); } String csr; PKIClient client; if ("pkcs10".equals(requestType)) { if ("rsa".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, Integer.toString(length), subjectDN); } <|startfocus|> else if ("ecc".equals(algorithm)){ <|endfocus|> csr = generatePkcs10Request(certDatabase, password, algorithm, curve, subjectDN); } else{ throw new Exception("Invalid algorithm specified."); } // initialize database after PKCS10Client to avoid conflict mainCLI.init(); client = getClient(); } else if ("crmf".equals(requestType)) { // initialize database before CRMFPopClient to load transport certificate mainCLI.init(); client = getClient(); String encoded; if (transportCertFilename == null) {
<|startcomment|> Specify the invalid algorithm in the exception message: throw new Exception("Invalid algorithm: " + algorithm); <|endcomment|>  if (password == null) { throw new Exception("Missing security database password."); } String csr; PKIClient client; if ("pkcs10".equals(requestType)) { if ("rsa".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, Integer.toString(length), subjectDN); } else if ("ecc".equals(algorithm)){ csr = generatePkcs10Request(certDatabase, password, algorithm, curve, subjectDN); <|startfocus|> } else{ throw new Exception("Invalid algorithm specified."); } <|endfocus|> // initialize database after PKCS10Client to avoid conflict mainCLI.init(); client = getClient(); } else if ("crmf".equals(requestType)) { // initialize database before CRMFPopClient to load transport certificate mainCLI.init(); client = getClient(); String encoded; if (transportCertFilename == null) { SystemCertClient certClient = new SystemCertClient(client, "ca"); encoded = certClient.getTransportCert().getEncoded(); } else { encoded = new String(Files.readAllBytes(Paths.get(transportCertFilename)));
<|startcomment|> In this patch the length parameter is used to pass either an RSA key length or an EC curve name, and both are passed to PKCS10Client using -l parameter. However, according to PKCS10Client help message, the EC curve name should be passed using -c parameter. I'd suggest adding a separate parameter for the EC curve name like this: if ("rsa".equals(algorithm)) { csr = generatePkcs10Request( certDatabase, password, algorithm, length, null, subjectDN); } else if ("ecc".equals(algorithm)) { csr = generatePkcs10Request( certDatabase, password, algorithm, null, curve, subjectDN); } And the generatePkcs10Request() can be defined like this: public String generatePkcs10Request( File certDatabase, String password, String algorithm, Integer length, String curve, String subjectDN ) throws Exception { } You will need to construct the commands array dynamically (e.g. with ArrayList) and add the -l or -c parameter only if the value is not null. <|endcomment|>  CACertCLI.printCertRequestInfos(infos); } public String generatePkcs10Request( File certDatabase, String password, String algorithm, String length, String subjectDN ) throws Exception { File csrFile = File.createTempFile("pki-client-cert-request-", ".csr", certDatabase); csrFile.deleteOnExit(); String[] commands = { "/usr/bin/PKCS10Client", "-d", certDatabase.getAbsolutePath(), "-p", password, "-a", algorithm, <|startfocus|> "-l", "" + length, <|endfocus|> "-o", csrFile.getAbsolutePath(), "-n", subjectDN }; try { runExternal(commands); } catch (Exception e) { throw new Exception("CSR generation failed", e); } if (verbose) { System.out.println("CSR generated: " + csrFile); } return new String(Files.readAllBytes(csrFile.toPath())); } public String generateCrmfRequest( X509Certificate transportCert, String subjectDN, boolean attributeEncoding, String algorithm, int length, String curve, boolean sslECDH, boolean temporary,
<|startcomment|> did you mean to replace profileId with the actualProfileId you just captured? <|endcomment|>  int sd_ee_port = config.getInteger("securitydomain.httpseeport", -1); MultivaluedMap<String, String> content = new MultivaluedHashMap<String, String>(); content.putSingle("requestor_name", sysType + "-" + machineName + "-" + securePort); logger.debug("configRemoteCert: subsystemCert: setting profileId to: " + profileId); String actualProfileId = request.getSystemCertProfileID(certTag, profileId); logger.debug("configRemoteCert: subsystemCert: calculated profileId: " + actualProfileId); <|startfocus|> content.putSingle("profileId", profileId); <|endfocus|> content.putSingle("cert_request_type", "pkcs10"); content.putSingle("cert_request", b64Request); content.putSingle("xmlOutput", "true"); content.putSingle("sessionID", session_id); cert = CertUtil.createRemoteCert(sd_hostname, sd_ee_port, content, response); if (cert == null) { throw new IOException("Error: remote certificate is null"); } } else if (v.equals("sdca")) { String ca_hostname = ""; int ca_port = -1; try {
<|startcomment|> You could move up this private method to just below where it is used the first time (line 155) <|endcomment|>  try (InputStream in = new BufferedInputStream(getInputStream())) { // TODO: expose XStream the driver from XStream if (nullOut) { return ((XStream2) xs).unmarshal(DEFAULT_DRIVER.createReader(in), o, null, true); } else { return xs.unmarshal(DEFAULT_DRIVER.createReader(in), o); } } catch (RuntimeException | Error e) { throw new IOException("Unable to read "+file,e); } } <|startfocus|> private InputStream getInputStream() throws IOException { InputStream is = Files.newInputStream(file.toPath()); if (file.getName().toLowerCase().endsWith(".gz")) { is = new GZIPInputStream(is); } return is; } <|endfocus|> public void write( Object o ) throws IOException { mkdirs(); AtomicFileWriter w = new AtomicFileWriter(file); try { w.write("<?xml version='1.1' encoding='UTF-8'?>\n"); beingWritten.put(o, null); writing.set(file); try { xs.toXML(o, w); } finally { beingWritten.remove(o);
<|startcomment|> Can serial ever be null, if so we can blow up the server with a debug log message? <|endcomment|>  * from CA's internal certificate db based on serial number to revoke shared * secret based revocation * Note that unlike the shared token attribute for enrollment, the metaInfo * attribute for shared token in revocatoiin is not configurable. * * Note: caller should clear the memory for the returned token * after each use */ public char[] getSharedToken(BigInteger serial) throws EBaseException { String method = "SharedSecret.getSharedToken(BigInteger serial): "; <|startfocus|> String msg = ""; <|endfocus|> CMS.debug(method + serial.toString()); ICertRecord record = null; try { record = certRepository.readCertificateRecord(serial); } catch (EBaseException ee) { CMS.debug(method + "Exception: " + ee.toString()); msg = method + "cert record not found"; CMS.debug(msg); throw ee; } MetaInfo metaInfo = (MetaInfo) record.get(ICertRecord.ATTR_META_INFO); if (metaInfo == null) { msg = "cert record metaInfo not found"; CMS.debug(method + msg);
<|startcomment|> I think we should chain the original exception to PKIException, or simply let it bubble up. <|endcomment|>  * * But we do still want to check that the input looks something * like a profile configuration. So we use java.util.Properties * to do that. */ public static void checkConfiguration( byte[] in, boolean requireProfileId, boolean requireDisabled) throws PKIException { Properties p = new Properties(); try { p.load(new ByteArrayInputStream(in)); } catch (IOException e) { <|startfocus|> throw new PKIException("Failed to parse profile configuration: " + e.toString()); <|endfocus|> } if (requireProfileId && p.getProperty("profileId") == null) throw new PKIException("Missing profileId property in profile data."); String enabled = p.getProperty("enable"); if (requireDisabled && Boolean.valueOf(enabled)) { throw new PKIException("Cannot edit profile. Profile must be disabled."); } } public static void saveEnrollmentTemplateToFile(String filename, CertEnrollmentRequest request) throws JAXBException, FileNotFoundException { JAXBContext context = JAXBContext.newInstance(CertEnrollmentRequest.class); Marshaller marshaller = context.createMarshaller();
<|startcomment|> nit: just concat the strings. I don't think it really helps readability to separate them by groups <|endcomment|>  * easier to tell if a config name represents a plugin permission or not. Note "-" isn't clear * enough for this purpose since some core permissions, e.g. "label-", also contain "-". */ private static final Pattern PLUGIN_PERMISSION_NAME_IN_CONFIG_PATTERN = <|startfocus|> Pattern.compile("^" + "plugin-" + PLUGIN_NAME_PATTERN_STRING + "-[a-zA-Z]+" + "$"); <|endfocus|> /** Name pattern for a Gerrit plugin. */ private static final Pattern PLUGIN_NAME_PATTERN = Pattern.compile("^" + PLUGIN_NAME_PATTERN_STRING + "$"); private final DynamicMap<CapabilityDefinition> capabilityDefinitions; private final DynamicMap<PluginProjectPermissionDefinition> pluginProjectPermissionDefinitions; @Inject private PluginPermissionsUtil( DynamicMap<CapabilityDefinition> capabilityDefinitions, DynamicMap<PluginProjectPermissionDefinition> pluginProjectPermissionDefinitions) { this.capabilityDefinitions = capabilityDefinitions; this.pluginProjectPermissionDefinitions = pluginProjectPermissionDefinitions; } /** * Collects all the plugin declared capabilities. *
<|startcomment|> nit: injected constructors should be package-private <|endcomment|> <|startfocus|> private PluginPermissionsUtil( <|endfocus|> DynamicMap<CapabilityDefinition> capabilityDefinitions, DynamicMap<PluginProjectPermissionDefinition> pluginProjectPermissionDefinitions) { this.capabilityDefinitions = capabilityDefinitions; this.pluginProjectPermissionDefinitions = pluginProjectPermissionDefinitions;
<|startcomment|> TODO(xchangcheng) <|endcomment|>  } public boolean testOrFalse(ProjectPermission perm) { try { return test(perm); } catch (PermissionBackendException e) { logger.warn("Cannot test " + perm + "; assuming false", e); return false; } } public BooleanCondition testCond(ProjectPermission perm) { return new PermissionBackendCondition.ForProject(this, perm); } /** * @return a partition of the provided refs that are visible to the user that this instance is <|startfocus|> * scoped to. <|endfocus|> */ public abstract Map<String, Ref> filter( Map<String, Ref> refs, Repository repo, RefFilterOptions opts) throws PermissionBackendException; } /** Options for filtering refs using {@link ForProject}. */ @AutoValue public abstract static class RefFilterOptions { /** Remove all NoteDb refs (refs/changes/*, refs/users/*, edit refs) from the result. */ public abstract boolean filterMeta(); /** Separately add reachable tags. */ public abstract boolean filterTagsSeparately(); public abstract Builder toBuilder(); 
<|startcomment|> TODO(xchangcheng) <|endcomment|>  public Map<String, Ref> filter(Map<String, Ref> refs, Repository repo, RefFilterOptions opts) throws PermissionBackendException { if (refFilter == null) { refFilter = refFilterFactory.create(ProjectControl.this); } return refFilter.filter(refs, repo, opts); } private boolean can(CoreOrPluginProjectPermission perm) throws PermissionBackendException { if (perm instanceof ProjectPermission) { return can((ProjectPermission) perm); } else if (perm instanceof PluginProjectPermission) { <|startfocus|> // TODO: implement for plugin defined project permissions. <|endfocus|> return false; } throw new PermissionBackendException(perm.describeForException() + " unsupported"); } private boolean can(ProjectPermission perm) throws PermissionBackendException { switch (perm) { case ACCESS: return user.isInternalUser() || isOwner() || canPerformOnAnyRef(Permission.READ); case READ: return allRefsAreVisible(Collections.emptySet()); case CREATE_REF: return canAddRefs(); case CREATE_TAG_REF: return canAddTagRefs(); case CREATE_CHANGE: return canCreateChanges(); 
<|startcomment|> Maybe reword this as: "Average delay per updated change for a push (calculated as duration_of_push / number_of_changes_in_push)." Because that's what I think is happening now. If that's not what's happening, then a rewording would be even better. <|endcomment|>  private final Timer1<String> latencyPerPush; private final Counter0 timeouts; @Inject Metrics(MetricMaker metricMaker) { changes = metricMaker.newHistogram( "receivecommits/changes", new Description("number of changes uploaded in a single push.").setCumulative(), Field.ofEnum( ResultChangeIds.Key.class, "type", "type of update (replace, create, autoclose)")); latencyPerChange = metricMaker.newTimer( "receivecommits/latency", <|startfocus|> new Description("average delay per updated change") <|endfocus|> .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of update (create/replace, autoclose)")); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("delay for a processing single batch of pushes") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)")); timeouts = metricMaker.newCounter( "receivecommits/timeout", new Description("rate of push timeouts").setRate());
<|startcomment|> Should "batch of pushes" be "a single push (which may consist of multiple changes)"? <|endcomment|>  Field.ofEnum( ResultChangeIds.Key.class, "type", "type of update (replace, create, autoclose)")); latencyPerChange = metricMaker.newTimer( "receivecommits/latency", new Description("average delay per updated change") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of update (create/replace, autoclose)")); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", <|startfocus|> new Description("delay for a processing single batch of pushes") <|endfocus|> .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)")); timeouts = metricMaker.newCounter( "receivecommits/timeout", new Description("rate of push timeouts").setRate()); } } private final Metrics metrics; private final ReceiveCommits receiveCommits; private final ResultChangeIds resultChangeIds; private final PermissionBackend.ForProject perm; private final ReceivePack receivePack; private final ExecutorService executor; private final RequestScopePropagator scopePropagator;
<|startcomment|> According to our off-line discussion, shouldn't this list include NORMAL? <|endcomment|>  metricMaker.newTimer( "receivecommits/latency", new Description("average delay per updated change") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of update (create/replace, autoclose)")); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("delay for a processing single batch of pushes") .setUnit(Units.MILLISECONDS) .setCumulative(), <|startfocus|> Field.ofString("type", "type of push (create/replace, autoclose)")); <|endfocus|> timeouts = metricMaker.newCounter( "receivecommits/timeout", new Description("rate of push timeouts").setRate()); } } private final Metrics metrics; private final ReceiveCommits receiveCommits; private final ResultChangeIds resultChangeIds; private final PermissionBackend.ForProject perm; private final ReceivePack receivePack; private final ExecutorService executor; private final RequestScopePropagator scopePropagator; private final ReceiveConfig receiveConfig; private final ContributorAgreementsChecker contributorAgreements; private final long timeoutMillis; private final ProjectState projectState; private final IdentifiedUser user;
<|startcomment|> Now that the concept of NORMAL as separate from CREATE/REPLACE/CLOSE has been defined, I think it makes sense to avoid incrementing this metric for NORMAL-type pushes. I know it's a bit asymmetric, but given that it's impossible to "subtract" data from a histogram I think it's more useful that way. I imagine plotting this alongside the latency per change and the latency per push to see a pattern in whether the number of changes per push suddenly changed et cetera. The signal is much clearer if it isn't muddied by the 99% (which are NORMAL pushes). If you agree, the description of the "changes" metric would need to be amended to state that it no longer contains NORMAL pushes. <|endcomment|>  List<Change.Id> created = resultChangeIds.get(ResultChangeIds.Key.CREATED); metrics.changes.record(ResultChangeIds.Key.CREATED, created.size()); List<Change.Id> replaced = resultChangeIds.get(ResultChangeIds.Key.REPLACED); metrics.changes.record(ResultChangeIds.Key.REPLACED, replaced.size()); totalChanges += replaced.size() + created.size(); } else { List<Change.Id> autoclosed = resultChangeIds.get(ResultChangeIds.Key.AUTOCLOSED); <|startfocus|> metrics.changes.record(ResultChangeIds.Key.AUTOCLOSED, autoclosed.size()); totalChanges += autoclosed.size(); <|endfocus|> } String pushType; if (resultChangeIds.isMagicPush()) { pushType = "CREATE_REPLACE"; } else if (totalChanges > 0) { pushType = ResultChangeIds.Key.AUTOCLOSED.name(); } else { pushType = "NORMAL"; } if (totalChanges > 0) { metrics.latencyPerChange.record(pushType, deltaNanos / totalChanges, NANOSECONDS); } metrics.latencyPerPush.record(pushType, deltaNanos, NANOSECONDS);
<|startcomment|> Nice. <|endcomment|>  Optional<Checker> checker = getChecker(checkerUuid); checkState(checker.isPresent(), "Tried to get a non-existing test checker as CheckerInfo"); return checkerJson.format(checker.get()); } public TestCheckerUpdate.Builder forUpdate() { return TestCheckerUpdate.builder(this::updateChecker); } private void updateChecker(TestCheckerUpdate testCheckerUpdate) throws Exception { CheckerUpdate checkerUpdate = toCheckerUpdate(testCheckerUpdate); checkersUpdate.updateChecker(checkerUuid, checkerUpdate); <|startfocus|> if (testCheckerUpdate.forceInvalidConfig().orElse(false)) { <|endfocus|> try (Repository repo = repoManager.openRepository(allProjectsName)) { new TestRepository<>(repo) .branch(CheckerRef.refsCheckers(checkerUuid)) .commit() .add(CheckerConfig.CHECKER_CONFIG_FILE, "invalid-config") .create(); } } } private CheckerUpdate toCheckerUpdate(TestCheckerUpdate checkerUpdate) { CheckerUpdate.Builder builder = CheckerUpdate.builder(); checkerUpdate.name().ifPresent(builder::setName); checkerUpdate.description().ifPresent(builder::setDescription); checkerUpdate.url().ifPresent(builder::setUrl);
<|startcomment|> Optional: this doesn't have to be an Optional, it can be a boolean that is initialized to false by default in builder(...) <|endcomment|> import com.google.gerrit.reviewdb.client.Project; import java.util.Arrays; import java.util.Optional; import java.util.stream.Stream; @AutoValue public abstract class TestCheckerUpdate { public abstract Optional<String> name(); public abstract Optional<String> description(); public abstract Optional<String> url(); public abstract Optional<Project.NameKey> repository(); public abstract Optional<CheckerStatus> status(); public abstract Optional<ImmutableSortedSet<BlockingCondition>> blockingConditions(); public abstract Optional<String> query(); <|startfocus|> public abstract Optional<Boolean> forceInvalidConfig(); <|endfocus|> abstract ThrowingConsumer<TestCheckerUpdate> checkerUpdater(); public static Builder builder(ThrowingConsumer<TestCheckerUpdate> checkerUpdater) { return new AutoValue_TestCheckerUpdate.Builder().checkerUpdater(checkerUpdater); } @AutoValue.Builder public abstract static class Builder { public abstract Builder name(String name); public abstract Builder description(String description); public Builder clearDescription() { return description(""); } public abstract Builder url(String url); public Builder clearUrl() { return url(""); } public abstract Builder repository(Project.NameKey repository); 
<|startcomment|> Please add a test for syntactically invalid checker UUIDs. <|endcomment|>  checkOperations.newCheck(key).setState(CheckState.RUNNING).upsert(); checkerOperations.checker(checkerUuid).forUpdate().forceInvalidConfig().update(); exception.expect(RestApiException.class); exception.expectMessage("Cannot retrieve checker " + checkerUuid); checksApiFactory.revision(patchSetId).id(checkerUuid.toString()).get(); } @Test public void getNonExistingCheckFails() throws Exception { exception.expect(ResourceNotFoundException.class); exception.expectMessage("Not found: non-existing"); checksApiFactory.revision(patchSetId).id("non-existing").get(); <|startfocus|> } <|endfocus|> } 
<|startcomment|> you can avoid checking this and just use instead Optional.ofNullable() at L376 <|endcomment|>  parseTag(commit); if (branch == null) { branch = parseBranch(commit); } PatchSet.Id psId = parsePatchSetId(commit); PatchSetState psState = parsePatchSetState(commit); if (psState != null) { if (!patchSetStates.containsKey(psId)) { patchSetStates.put(psId, psState); } if (psState == PatchSetState.DELETED) { deletedPatchSets.add(psId); } } Account.Id accountId = parseIdent(commit); if (accountId != null) { <|startfocus|> ownerId = Optional.of(accountId); <|endfocus|> } Account.Id realAccountId = parseRealAccountId(commit, accountId); if (changeId == null) { changeId = parseChangeId(commit); } String currSubject = parseSubject(commit); if (currSubject != null) { if (subject == null) { subject = currSubject; } originalSubject = currSubject; } parseChangeMessage(psId, accountId, realAccountId, commit, ts); if (topic == null) { topic = parseTopic(commit); } 
<|startcomment|> "Number of changes of each type (create, replace, autoclose) uploaded in a single push. If a push has changes of multiple types, multiple events will be added to the histogram (one for each type)." <--- which also shows that we don't have a metric which tracks the number of changes in a push regardless of type. Despite the loss of information, WDYT about joining CREATE and REPLACE in this metric to make it more comparable to receivecommits/latency? <|endcomment|>  } @Override public void flush() { receiveCommits.getMessageSender().flush(); } } } @Singleton private static class Metrics { private final Histogram1<ResultChangeIds.Key> changes; private final Timer1<String> latencyPerChange; private final Timer1<String> latencyPerPush; private final Counter0 timeouts; @Inject Metrics(MetricMaker metricMaker) { changes = metricMaker.newHistogram( "receivecommits/changes", new Description("number of changes uploaded in a single push.").setCumulative(), <|startfocus|> Field.ofEnum( ResultChangeIds.Key.class, "type", "type of push (replace, create, autoclose)")); <|endfocus|> latencyPerChange = metricMaker.newTimer( "receivecommits/latency", new Description( "processing delay per push, averaged over the updated changes in a push.") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)")); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency",
<|startcomment|> This is OK. What sounds even clearer to me is: Processing delay per push divided by the number of changes in said push. (Only includes pushes which contain changes.) <|endcomment|>  private final Counter0 timeouts; @Inject Metrics(MetricMaker metricMaker) { changes = metricMaker.newHistogram( "receivecommits/changes", new Description("number of changes uploaded in a single push.").setCumulative(), Field.ofEnum( ResultChangeIds.Key.class, "type", "type of push (replace, create, autoclose)")); latencyPerChange = metricMaker.newTimer( "receivecommits/latency", new Description( <|startfocus|> "processing delay per push, averaged over the updated changes in a push.") <|endfocus|> .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose)")); latencyPerPush = metricMaker.newTimer( "receivecommits/push_latency", new Description("processing delay for a processing single push") .setUnit(Units.MILLISECONDS) .setCumulative(), Field.ofString("type", "type of push (create/replace, autoclose, normal)")); timeouts = metricMaker.newCounter( "receivecommits/timeout", new Description("rate of push timeouts").setRate());
<|startcomment|> Why not just 'permissionName'? I'm not sure which Config is meant here. <|endcomment|> <|startfocus|> private static ProjectAccessInput createAccessInput( String accessSection, String permissionNameInConfig) { <|endfocus|> ProjectAccessInput accessInput = new ProjectAccessInput(); PermissionRuleInfo ruleInfo = new PermissionRuleInfo(PermissionRuleInfo.Action.ALLOW, false); PermissionInfo email = new PermissionInfo(null, null); email.rules = ImmutableMap.of(SystemGroupBackend.REGISTERED_USERS.get(), ruleInfo); AccessSectionInfo accessSectionInfo = new AccessSectionInfo(); accessSectionInfo.permissions = ImmutableMap.of(permissionNameInConfig, email); accessInput.add = ImmutableMap.of(accessSection, accessSectionInfo); return accessInput;
<|startcomment|> isPluginPermissionNameValid? <|endcomment|> <|startfocus|> public void isPluginPermissionValidNameReturnTrue() { <|endfocus|> // "-" is allowed for a plugin name. Here "foo-a" should be the name of the plugin. ImmutableList<String> validPluginPermissions = ImmutableList.of("plugin-foo-a", "plugin-foo-a-b"); for (String permission : validPluginPermissions) { assertThat(isPluginPermission(permission)) .named("valid plugin permission: %s", permission) .isTrue(); }
<|startcomment|> isPluginPermissionNameInvalid? <|endcomment|> <|startfocus|> public void isPluginPermissionInvalidNameReturnFalse() { ImmutableList<String> validPluginPermissions = <|endfocus|> ImmutableList.of( "create", "label-Code-Review", "plugin-foo", "plugin-foo", "plugin-foo-a-", "plugin-foo-a1"); for (String permission : validPluginPermissions) { assertThat(isPluginPermission(permission)) .named("invalid plugin permission: %s", permission) .isFalse(); }
<|startcomment|> invalidPluginPermissions? <|endcomment|> <|startfocus|> public void isPluginPermissionInvalidNameReturnFalse() { ImmutableList<String> validPluginPermissions = <|endfocus|> ImmutableList.of( "create", "label-Code-Review", "plugin-foo", "plugin-foo", "plugin-foo-a-", "plugin-foo-a1"); for (String permission : validPluginPermissions) { assertThat(isPluginPermission(permission)) .named("invalid plugin permission: %s", permission) .isFalse(); }
<|startcomment|> nit: typically we don't use underscores in method names. <|endcomment|>  .annotatedWith(Exports.named(TEST_PLUGIN_CAPABILITY)) .toInstance( new CapabilityDefinition() { @Override public String getDescription() { return "A Plugin Capability"; } }); bind(PluginProjectPermissionDefinition.class) .annotatedWith(Exports.named(TEST_PLUGIN_PROJECT_PERMISSION)) .toInstance( new PluginProjectPermissionDefinition() { @Override public String getDescription() { return "A Plugin Project Permission"; } }); } }; } @Test <|startfocus|> public void setAccess_addPluginCapability_succeed() throws Exception { <|endfocus|> String pluginCapability = TEST_PLUGIN_NAME + "-" + TEST_PLUGIN_CAPABILITY; ProjectAccessInput accessInput = createAccessInput(AccessSection.GLOBAL_CAPABILITIES, pluginCapability); ProjectAccessInfo projectAccessInfo = gApi.projects().name(allProjects.get()).access(accessInput); Set<String> capabilities = projectAccessInfo.local.get(AccessSection.GLOBAL_CAPABILITIES).permissions.keySet(); assertThat(capabilities).contains(pluginCapability); // Verifies the plugin defined capability could be listed. assertThat(pluginPermissionsUtil.collectPluginCapabilities()).containsKey(pluginCapability); } @Test
<|startcomment|> Still deserves a comment on why we are returning null. <|endcomment|>  } @Override public void addRelatedLink(String issueKey, URL relatedUrl, String description) throws IOException { addComment( issueKey, "Related URL: " + createLinkForWebui(relatedUrl.toExternalForm(), description)); } @Override public void addValueToField(String issueKey, String value, String fieldId) throws IOException { execute( () -> { log.debug("Adding value {} to field {} on issue {}", value, fieldId, issueKey); <|startfocus|> jiraClient.addValueToField(issueKey, value, fieldId); <|endfocus|> return null; }); } @Override public void performAction(String issueKey, String actionName) throws IOException { execute( () -> { log.debug("Performing action {} on issue {}", actionName, issueKey); doPerformAction(issueKey, actionName); return issueKey; }); } private void doPerformAction(String issueKey, String actionName) throws IOException, InvalidTransitionException { log.debug("Trying to perform action: {} on issue {}", actionName, issueKey);
<|startcomment|> As commented on UpdateCheck, this may just be: if (input == null) { input = new CheckInput(); } Not sure if it's everywhere consistent, but I believe that is what we do in most of the places. <|endcomment|>  private final Checks checks; private final Provider<ChecksUpdate> checksUpdate; private final CheckJson checkJson; @Inject PostCheck( Checks checks, @UserInitiated Provider<ChecksUpdate> checksUpdate, CheckJson checkJson) { this.checks = checks; this.checksUpdate = checksUpdate; this.checkJson = checkJson; } @Override public CheckInfo apply(RevisionResource rsrc, CheckInput input) throws OrmException, IOException, RestApiException { if (input == null) { <|startfocus|> throw new BadRequestException("input is required"); <|endfocus|> } if (input.checkerUuid == null) { throw new BadRequestException("checkerUuid is required"); } CheckKey key = CheckKey.create( rsrc.getProject(), rsrc.getPatchSet().getId(), CheckerUuid.parse(input.checkerUuid)); Optional<Check> check = checks.getCheck(key); if (!check.isPresent()) { if (input.state == null) { throw new BadRequestException("state is required on creation"); } Check updatedCheck = checksUpdate.get().createCheck(key, toCheckUpdate(input));
<|startcomment|> I think under some conditions input may be null, this is why it a lot of places we have: if (input == null) { input = new CheckInput(); } you may add this code here too. <|endcomment|> import com.google.gerrit.extensions.restapi.RestModifyView; import com.google.gerrit.plugins.checks.PostCheck; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; @Singleton public class UpdateCheck implements RestModifyView<CheckResource, CheckInput> { private final PostCheck postCheck; @Inject UpdateCheck(PostCheck postCheck) { this.postCheck = postCheck; } @Override public CheckInfo apply(CheckResource checkResource, CheckInput input) <|startfocus|> throws RestApiException, IOException, OrmException { <|endfocus|> if (input.checkerUuid == null) { input.checkerUuid = checkResource.getCheckerUuid().toString(); } else if (!checkResource.getCheckerUuid().toString().equals(input.checkerUuid)) { throw new BadRequestException( String.format( "checkerUuid must either be null or the same as on the resource:\n" + "the check resource belongs to checker %s," + " but in the input checker %s was specified", checkResource.getCheckerUuid(), input.checkerUuid)); } 
<|startcomment|> This also should stay in the error_log <|endcomment|>  private static int getInt(Config cfg, String section, String name, int defaultValue) { try { return cfg.getInt(section, name, defaultValue); } catch (IllegalArgumentException e) { <|startfocus|> multisiteLog.error("invalid value for {}; using default value {}", name, defaultValue); multisiteLog.debug("Failed to retrieve integer value: {}", e.getMessage(), e); <|endfocus|> return defaultValue; }
<|startcomment|> This should stay in error_log <|endcomment|>  for (String name : config.getNames(KAFKA_SECTION, section, true)) { if (name.startsWith(KAFKA_PROPERTY_PREFIX)) { Object value = config.getString(KAFKA_SECTION, subsectionName, name); String configProperty = name.replaceFirst(KAFKA_PROPERTY_PREFIX, ""); String propName = CaseFormat.LOWER_CAMEL .to(CaseFormat.LOWER_HYPHEN, configProperty) .replaceAll("-", "."); <|startfocus|> multisiteLog.info( "[{}] Setting kafka property: {} = {}", subsectionName, propName, value); <|endfocus|> target.put(propName, value); } } } } target.put( "bootstrap.servers", getString( config, KAFKA_SECTION, null, "bootstrapServers", DEFAULT_KAFKA_BOOTSTRAP_SERVERS));
<|startcomment|> Same as above <|endcomment|>  private static boolean getBoolean( Config cfg, String section, String name, boolean defaultValue) { try { return cfg.getBoolean(section, name, defaultValue); } catch (IllegalArgumentException e) { <|startfocus|> multisiteLog.error("invalid value for {}; using default value {}", name, defaultValue); multisiteLog.debug("Failed to retrieve boolean value: {}", e.getMessage(), e); <|endfocus|> return defaultValue; }
<|startcomment|> This should be a LifecycleModule <|endcomment|> import com.googlesource.gerrit.plugins.multisite.forwarder.ForwarderModule; import com.googlesource.gerrit.plugins.multisite.forwarder.broker.BrokerForwarderModule; import com.googlesource.gerrit.plugins.multisite.index.IndexModule; import com.googlesource.gerrit.plugins.multisite.kafka.consumer.KafkaConsumerModule; import com.googlesource.gerrit.plugins.multisite.kafka.router.ForwardedEventRouterModule; import java.io.BufferedReader; import java.io.BufferedWriter; import java.io.FileReader; import java.io.IOException; import java.nio.file.Files; import java.nio.file.Paths; import java.util.UUID; <|startfocus|> public class Module extends AbstractModule { <|endfocus|> private final Configuration config; @Inject public Module(Configuration config) { this.config = config; } @Override protected void configure() { bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(MultiSiteLogFile.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } 
<|startcomment|> this becomes: listener(). <|endcomment|>  protected void configure() { <|startfocus|> bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(MultiSiteLogFile.class); <|endfocus|> install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } if (config.kafkaSubscriber().enabled()) { install(new KafkaConsumerModule(config.kafkaSubscriber())); install(new ForwardedEventRouterModule()); } if (config.kafkaPublisher().enabled()) { install(new BrokerForwarderModule(config.kafkaPublisher())); } bind(Gson.class).toProvider(GsonProvider.class).in(Singleton.class);
<|startcomment|> This would be best named as 'msgLog' <|endcomment|> // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.broker.kafka; <|startfocus|> import static com.googlesource.gerrit.plugins.multisite.MultiSiteLogFile.multisiteLog; <|endfocus|> import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.Configuration; import com.googlesource.gerrit.plugins.multisite.InstanceId; import com.googlesource.gerrit.plugins.multisite.broker.BrokerSession; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.util.UUID; import java.util.concurrent.ExecutionException; import java.util.concurrent.Future; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.Producer; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; public class KafkaSession implements BrokerSession { private final Configuration properties;
<|startcomment|> This should stay in error_log as all the others below. <|endcomment|>  public void connect() { if (isOpen()) { <|startfocus|> multisiteLog.debug("Already connected."); <|endfocus|> return; } multisiteLog.info("Connect to {}...", properties.getKafka().getBootstrapServers()); /* Need to make sure that the thread of the running connection uses * the correct class loader otherwize you can endup with hard to debug * ClassNotFoundExceptions */ setConnectionClassLoader(); producer = new KafkaProducer<>(properties.kafkaPublisher()); multisiteLog.info("Connection established.");
<|startcomment|> Stay in error_log <|endcomment|>  public void evict(CacheEntry entry) throws CacheNotFoundException { Cache<?, ?> cache = cacheMap.get(entry.getPluginName(), entry.getCacheName()); if (cache == null) { throw new CacheNotFoundException(entry.getPluginName(), entry.getCacheName()); } try { Context.setForwardedEvent(true); if (Constants.PROJECT_LIST.equals(entry.getCacheName())) { // One key is holding the list of projects cache.invalidateAll(); <|startfocus|> multisiteLog.debug("Invalidated cache {}", entry.getCacheName()); <|endfocus|> } else { cache.invalidate(entry.getKey()); multisiteLog.debug("Invalidated cache {}[{}]", entry.getCacheName(), entry.getKey()); } } finally { Context.unsetForwardedEvent(); } } } 
<|startcomment|> Stay in error_log <|endcomment|>  if (cache == null) { throw new CacheNotFoundException(entry.getPluginName(), entry.getCacheName()); } try { Context.setForwardedEvent(true); if (Constants.PROJECT_LIST.equals(entry.getCacheName())) { // One key is holding the list of projects cache.invalidateAll(); multisiteLog.debug("Invalidated cache {}", entry.getCacheName()); } else { cache.invalidate(entry.getKey()); <|startfocus|> multisiteLog.debug("Invalidated cache {}[{}]", entry.getCacheName(), entry.getKey()); <|endfocus|> } } finally { Context.unsetForwardedEvent(); } } } 
<|startcomment|> This is the *most precious info* we want in the multi-site log, what's coming through :-) Not a debug data, but rather a runtime info. <|endcomment|>  SourceAwareEventWrapper event = valueDeserializer.deserialize(consumerRecord.topic(), consumerRecord.value()); if (event.getHeader().getSourceInstanceId().equals(instanceId)) { multisiteLog.debug( "Dropping event {} produced by our instanceId {}", event.toString(), instanceId.toString()); droppedEventListeners.forEach(l -> l.onEventDropped(event)); } else { try { <|startfocus|> multisiteLog.debug("Header[{}] Body[{}]", event.getHeader(), event.getBody()); <|endfocus|> eventRouter.route(event.getEventBody(gsonProvider)); } catch (IOException e) { multisiteLog.error( "Malformed event '{}': [Exception: {}]", event.getHeader().getEventType(), e); } catch (PermissionBackendException | OrmException e) { multisiteLog.error( "Cannot handle message {}: [Exception: {}]", event.getHeader().getEventType(), e); } } } catch (Exception e) { multisiteLog.error( "Malformed event '{}': [Exception: {}]", new String(consumerRecord.value()), e);
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2018 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. // Copyright (C) 2018 The Android Open Source Project // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software
<|startcomment|> actually, instead of using regex here we could do the same as at L24-26. In fact that code could be extracted out to this method. <|endcomment|> <|startfocus|> public static String stripEndSlash(String name) { name = name.replaceAll("/$", ""); <|endfocus|> return name;
<|startcomment|> This could be declared static. <|endcomment|> <|startfocus|> private String strip(String name) { <|endfocus|> projectName = ProjectUtil.stripGitSuffix(name); projectName = ProjectUtil.stripEndSlash(projectName); return projectName;
<|startcomment|> Missing @Test annotation <|endcomment|>  } @Test public void createProjectWithGitSuffix() throws Exception { String newProjectName = name("newProject"); ProjectInfo p = gApi.projects().create(newProjectName + ".git").get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } <|startfocus|> <|endfocus|> public void createProjectThatEndsWithSlash() throws Exception { String newProjectName = name("newProject"); ProjectInfo p = gApi.projects().create(newProjectName + "/").get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } public void createProjectThatContainsSlash() throws Exception { String newProjectName = name("newProject/newProject");
<|startcomment|> Missing @Test annotation <|endcomment|>  assertHead(newProjectName, "refs/heads/master"); } public void createProjectThatEndsWithSlash() throws Exception { String newProjectName = name("newProject"); ProjectInfo p = gApi.projects().create(newProjectName + "/").get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } <|startfocus|> <|endfocus|> public void createProjectThatContainsSlash() throws Exception { String newProjectName = name("newProject/newProject"); ProjectInfo p = gApi.projects().create(newProjectName).get(); assertThat(p.name).isEqualTo(newProjectName); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertProjectInfo(projectState.getProject(), p); assertHead(newProjectName, "refs/heads/master"); } @Test public void createProjectWithProperties() throws Exception { String newProjectName = name("newProject");
<|startcomment|> Long line? <|endcomment|>  adminSshSession.assertFailure(); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNull(); } @Test public void withDotGit() throws Exception { String newGroupName = "newGroup"; adminRestSession.put("/groups/" + newGroupName); String newProjectName = "newProject"; adminSshSession.exec( <|startfocus|> "gerrit create-project --branch master --owner " + newGroupName + " " + newProjectName + ".git"); <|endfocus|> adminSshSession.assertSuccess(); ProjectState projectState = projectCache.get(new Project.NameKey(newProjectName)); assertThat(projectState).isNotNull(); assertThat(projectState.getName()).isEqualTo(newProjectName); } @Test public void withEndSlash() throws Exception { String newGroupName = "newGroup"; adminRestSession.put("/groups/" + newGroupName); String newProjectName = "newProject"; adminSshSession.exec( "gerrit create-project --branch master --owner " + newGroupName + " " + newProjectName + "/"); adminSshSession.assertSuccess();
<|startcomment|> Is this for gerrit.config or also for project.config? Please use config parameter naming convention in line 27 to 35. <|endcomment|>  } @VisibleForTesting void setReportSyntaxError(boolean value) { reportSyntaxError = value; } int getMinOwnerVoteLevel(ProjectState projectState, ChangeData c) { if (projectState == null) { logger.atSevere().log("Null projectState for change %s", getChangeId(c)); return minOwnerVoteLevel; } return getPluginConfig(projectState).getInt(MIN_OWNER_VOTE_LEVEL, minOwnerVoteLevel); } } <|startfocus|> enum EnforcementLevel { DISABLED, WARN, ENFORCE; static final String CONFIG_NAME = "ENFORCE_LEVEL"; } <|endfocus|> 
<|startcomment|> nit: usually we put the assisted parameters at the end. <|endcomment|>  protected Destination( Injector injector, <|startfocus|> @Assisted DestinationConfiguration cfg, <|endfocus|> RemoteSiteUser.Factory replicationUserFactory, PluginUser pluginUser, GitRepositoryManager gitRepositoryManager, PermissionBackend permissionBackend, Provider<CurrentUser> userProvider, ProjectCache projectCache, GroupBackend groupBackend, ReplicationStateListener stateLog, GroupIncludeCache groupIncludeCache, DynamicItem<EventDispatcher> eventDispatcher) { config = cfg; this.eventDispatcher = eventDispatcher; gitManager = gitRepositoryManager; this.permissionBackend = permissionBackend; this.userProvider = userProvider; this.projectCache = projectCache; this.stateLog = stateLog; CurrentUser remoteUser; if (!cfg.getAuthGroupNames().isEmpty()) { ImmutableSet.Builder<AccountGroup.UUID> builder = ImmutableSet.builder(); for (String name : cfg.getAuthGroupNames()) { GroupReference g = GroupBackends.findExactSuggestion(groupBackend, name); if (g != null) { builder.add(g.getUUID()); addRecursiveParents(g.getUUID(), builder, groupIncludeCache); } else {
<|startcomment|> These should not be hardcoded in the ValidationModule but rather injected in the InMemoryDfsRefDatabase. Just use a bind(DfsRefDatabase.class).to(InMemoryDfsRefDatabase.class) and then rely on Guice to make it a singleton and inject the parameters. <|endcomment|>  protected void configure() { DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class); <|startfocus|> bind(DfsRefDatabase.class) .toInstance( new InMemoryDfsRefDatabase( Executors.newSingleThreadScheduledExecutor(), InMemoryDfsRefDatabaseCleaner.cleanIfNotTouchedFor(Duration.ofDays(7)), 300)); <|endfocus|>
<|startcomment|> Please see the previous comment: we should exclude the '/meta' ref name. <|endcomment|>  private boolean isImmutableRef(String refName) { <|startfocus|> return refName.startsWith("refs/changes"); <|endfocus|>
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2018 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import com.google.gerrit.extensions.registration.DynamicSet; import com.google.gerrit.server.git.validators.RefOperationValidationListener; import com.google.inject.AbstractModule; import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.NoOpDfsRefDatabase; import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.SharedRefDatabase; public class ValidationModule extends AbstractModule { @Override protected void configure() { DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class);
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2018 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import static com.google.common.truth.Truth.assertThat; import static org.hamcrest.CoreMatchers.nullValue; import static org.hamcrest.CoreMatchers.sameInstance; import static org.mockito.Mockito.any; import static org.mockito.Mockito.argThat; import static org.mockito.Mockito.doReturn; import static org.mockito.Mockito.doThrow; import static org.mockito.Mockito.eq; import static org.mockito.Mockito.verify; import static org.mockito.Mockito.verifyZeroInteractions; 
<|startcomment|> Leftover? <|endcomment|>  .when(dfsRefDatabase) .compareAndPut(any(), eq(null), any()); doThrow(new NullPointerException("newRef is null")) .when(dfsRefDatabase) .compareAndPut(any(), any(), eq(null)); doThrow(new NullPointerException("project name is null")) .when(dfsRefDatabase) .compareAndPut(eq(null), any(), any()); <|startfocus|> // doReturn(false).when(dfsRefDatabase).compareAndPut(eq(PROJECT_NAME), eqRef(REF_NAME, // REF_OBJID_OLD), eqRef(REF_NAME, REF_OBJID)); <|endfocus|> validator = new InSyncChangeValidator(dfsRefDatabase, repoManager); repoManager.createRepository(PROJECT_NAMEKEY); } @Test public void shouldNotVerifyStatusOfImmutablePatchSetRefs() throws Exception { testRefReceivedEvent.command = RECEIVE_COMMAND_CREATE_PATCHSET_REF; final List<ValidationMessage> validationMessages = validator.onRefOperation(testRefReceivedEvent); assertThat(validationMessages).isEmpty(); verifyZeroInteractions(dfsRefDatabase); } @Test public void shouldInsertNewRefInDfsDatabaseWhenHandlingRefCreationEvents() throws Exception { testRefReceivedEvent.command = RECEIVE_COMMAND_CREATE_REF; 
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2018 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import com.google.common.flogger.FluentLogger; import com.google.gerrit.acceptance.LightweightPluginDaemonTest; import com.google.gerrit.acceptance.LogThreshold; import com.google.gerrit.acceptance.NoHttpd; import com.google.gerrit.acceptance.PushOneCommit; import com.google.gerrit.acceptance.TestPlugin; import com.google.inject.AbstractModule; import org.junit.Test; @NoHttpd @LogThreshold(level = "INFO") @TestPlugin( name = "multi-site",
<|startcomment|> nit: 'in the storage' <|endcomment|>  * Starts the fluent chain for querying or modifying a check. Please see the methods of {@link * PerCheckOperations} for details on possible operations. * * @param key key of the check * @return an aggregation of operations on a specific check */ PerCheckOperations check(CheckKey key); /** * Starts the fluent chain to create a check. The returned builder can be used to specify the <|startfocus|> * attributes of the new check. To create the check for real, {@link <|endfocus|> * TestCheckUpdate.Builder#upsert()} must be called. * * <p>Example: * * <pre> * checkOperations * .newCheck(checkKey) * .setState(CheckState.RUNNING) * .upsert(); * </pre> * * <p><strong>Note:</strong> If a check with the provided key already exists, the check creation * fails. * * @return a builder to create the new check */ TestCheckUpdate.Builder newCheck(CheckKey key); 
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2015 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import com.google.gerrit.server.notedb.NotesMigration; import com.google.inject.Inject; public class GerritNoteDbStatus implements NoteDbStatus { private final NotesMigration notesMigration; @Inject public GerritNoteDbStatus(NotesMigration notesMigration) { this.notesMigration = notesMigration; } @Override public boolean enabled() { return notesMigration.commitChangeWrites(); } } 
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2015 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; /** Returns the status of changes migration. */ public interface NoteDbStatus { /** * Status of NoteDb migration. * * @return true if Gerrit has been migrated to NoteDb */ boolean enabled(); } 
<|startcomment|> nit:remove <|endcomment|>  // Name of plugin and namespace. static final String PLUGIN_NAME = "find-owners"; static final String PROLOG_NAMESPACE = "find_owners"; private final PluginConfigFactory configFactory; // Global/plugin config parameters. private boolean addDebugMsg = false; private int minOwnerVoteLevel = 1; private int maxCacheAge = 0; private int maxCacheSize = 1000; private boolean reportSyntaxError = false; private boolean alwaysShowButton = false; private String ownersFileName = OWNERS; <|startfocus|> <|endfocus|> private static final FluentLogger logger = FluentLogger.forEnclosingClass(); Config(PluginConfigFactory configFactory) { this.configFactory = configFactory; if (configFactory == null) { // When called from integration tests. return; } PluginConfig gc = configFactory.getFromGerritConfig(PLUGIN_NAME); // Get config variables from the plugin section of gerrit.config addDebugMsg = gc.getBoolean(ADD_DEBUG_MSG, false); reportSyntaxError = gc.getBoolean(REPORT_SYNTAX_ERROR, false); alwaysShowButton = gc.getBoolean(ALWAYS_SHOW_BUTTON, false);
<|startcomment|> @Inject missing <|endcomment|>  private final DestinationConfiguration config; private final DynamicItem<EventDispatcher> eventDispatcher; protected enum RetryReason { TRANSPORT_ERROR, COLLISION, REPOSITORY_MISSING; } public static class QueueInfo { public final Map<URIish, PushOne> pending; public final Map<URIish, PushOne> inFlight; public QueueInfo(Map<URIish, PushOne> pending, Map<URIish, PushOne> inFlight) { this.pending = ImmutableMap.copyOf(pending); this.inFlight = ImmutableMap.copyOf(inFlight); } } <|startfocus|> <|endfocus|> protected Destination( Injector injector, RemoteSiteUser.Factory replicationUserFactory, PluginUser pluginUser, GitRepositoryManager gitRepositoryManager, PermissionBackend permissionBackend, Provider<CurrentUser> userProvider, ProjectCache projectCache, GroupBackend groupBackend, ReplicationStateListener stateLog, GroupIncludeCache groupIncludeCache, DynamicItem<EventDispatcher> eventDispatcher, @Assisted DestinationConfiguration cfg) { this.eventDispatcher = eventDispatcher; gitManager = gitRepositoryManager; this.permissionBackend = permissionBackend; this.userProvider = userProvider; this.projectCache = projectCache; this.stateLog = stateLog; config = cfg;
<|startcomment|> This is not needed: all the tests are run serialized and do the proper drain of events. <|endcomment|> import com.googlesource.gerrit.plugins.multisite.forwarder.events.ChangeIndexEvent; import java.util.ArrayList; import java.util.List; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.TimeUnit; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; import org.junit.Before; import org.junit.Test; import org.testcontainers.containers.KafkaContainer; @NoHttpd @LogThreshold(level = "INFO") <|startfocus|> @Sandboxed <|endfocus|> @TestPlugin( name = "multi-site", sysModule = "com.googlesource.gerrit.plugins.multisite.kafka.consumer.EventConsumerIT$KafkaTestContainerModule") public class EventConsumerIT extends LightweightPluginDaemonTest { private static final int QUEUE_POLL_TIMEOUT_MSECS = 30000; static { System.setProperty("gerrit.notedb", "READ_WRITE"); } public static class KafkaTestContainerModule extends LifecycleModule { public class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka; public KafkaStopAtShutdown(KafkaContainer kafka) { this.kafka = kafka; } @Override
<|startcomment|> Here we expects 4 elements, but then below we check only 3 of them. Which one is the last element we don't care about? <|endcomment|>  super.setUpTestPlugin(); if (!notesMigration.commitChangeWrites()) { throw new IllegalStateException("NoteDb is mandatory for running the multi-site plugin"); } } @Test public void createChangeShouldPropagateChangeIndexAndRefUpdateStreamEvent() throws Exception { LinkedBlockingQueue<SourceAwareEventWrapper> droppedEventsQueue = captureDroppedEvents(); drainQueue(droppedEventsQueue); PushOneCommit.Result r = createChange(); <|startfocus|> List<Event> createdChangeEvents = receiveFromQueue(droppedEventsQueue, 4); assertThat(createdChangeEvents).hasSize(4); <|endfocus|> ChangeData change = r.getChange(); assertThat( createdChangeEvents .stream() .filter(e -> e.type.equals("change-index")) .collect(toSet())) .containsExactlyElementsIn( ImmutableList.of( createChangeIndexEvent( change.project().get(), change.getId().get(), getParentCommit(change)))); assertThat( createdChangeEvents .stream() .filter(e -> e.type.equals("ref-updated")) .map(RefUpdatedEvent.class::cast) .map(e -> e.getRefName()) .collect(toSet())) .containsExactlyElementsIn(
<|startcomment|> This is wrong, we should expect the ref-update of the '/meta' ref also <|endcomment|>  .collect(toSet())) .containsExactlyElementsIn( ImmutableList.of( createChangeIndexEvent( change.project().get(), change.getId().get(), getParentCommit(change)))); assertThat( createdChangeEvents .stream() .filter(e -> e.type.equals("ref-updated")) .map(RefUpdatedEvent.class::cast) .map(e -> e.getRefName()) .collect(toSet())) <|startfocus|> .containsExactlyElementsIn( ImmutableList.of("refs/sequences/changes", change.currentPatchSet().getRefName())); <|endfocus|> PatchSetCreatedEvent patchSetCreated = createdChangeEvents .stream() .filter(e -> e.type.equals("patchset-created")) .map(PatchSetCreatedEvent.class::cast) .findFirst() .get(); PatchSetAttribute patchSetAttribute = patchSetCreated.patchSet.get(); PatchSet currentPatchSet = change.currentPatchSet(); assertThat(patchSetAttribute.number).isEqualTo(currentPatchSet.getPatchSetId()); assertThat(patchSetAttribute.revision).isEqualTo(currentPatchSet.getRevision().get()); assertThat(patchSetAttribute.ref).isEqualTo(currentPatchSet.getRefName()); } @Test
<|startcomment|> This is a workaround to not pass this property from the CI side? Why the check, if it never can be false? <|endcomment|> import com.google.inject.TypeLiteral; import com.googlesource.gerrit.plugins.multisite.Configuration; import com.googlesource.gerrit.plugins.multisite.Module; import com.googlesource.gerrit.plugins.multisite.broker.GsonProvider; import com.googlesource.gerrit.plugins.multisite.forwarder.events.ChangeIndexEvent; import java.util.ArrayList; import java.util.List; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.TimeUnit; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; <|startfocus|> import org.eclipse.jgit.revwalk.RevWalk; <|endfocus|> import org.junit.Test; import org.testcontainers.containers.KafkaContainer; @NoHttpd @LogThreshold(level = "INFO") @TestPlugin( name = "multi-site", sysModule = "com.googlesource.gerrit.plugins.multisite.kafka.consumer.EventConsumerIT$KafkaTestContainerModule") public class EventConsumerIT extends LightweightPluginDaemonTest { private static final int QUEUE_POLL_TIMEOUT_MSECS = 30000; public static class KafkaTestContainerModule extends LifecycleModule { public class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka; public KafkaStopAtShutdown(KafkaContainer kafka) {
<|startcomment|> nit: line too long <|endcomment|>  protected void configure() { if (!noteDb.enabled()) { throw new ProvisionException( <|startfocus|> "Gerrit is still running on ReviewDb: please migrate to NoteDb and then reload the multi-site plugin."); <|endfocus|> } listener().to(Log4jMessageLogger.class); bind(MessageLogger.class).to(Log4jMessageLogger.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } if (config.kafkaSubscriber().enabled()) { install(new KafkaConsumerModule(config.kafkaSubscriber())); install(new ForwardedEventRouterModule()); } if (config.kafkaPublisher().enabled()) { install(new BrokerForwarderModule(config.kafkaPublisher())); } install(new ValidationModule()); bind(Gson.class).toProvider(GsonProvider.class).in(Singleton.class);
<|startcomment|> Would it make sense to have another method #list(CheckerUuid, CheckState...) and then move this parse step into a default impl in the PendingChecks interface? <|endcomment|> import com.google.inject.Inject; import com.google.inject.Provider; import com.google.inject.Singleton; import java.util.List; import java.util.stream.Stream; @Singleton public class PendingChecksImpl implements PendingChecks { private final Provider<ListPendingChecks> listPendingChecksProvider; @Inject PendingChecksImpl(Provider<ListPendingChecks> listPendingChecksProvider) { this.listPendingChecksProvider = listPendingChecksProvider; } @Override public List<PendingChecksInfo> list(String checkerUuidString, CheckState... checkStates) throws RestApiException { <|startfocus|> CheckerUuid checkerUuid = CheckerUuid.tryParse(checkerUuidString) .orElseThrow( () -> new BadRequestException( String.format("invalid checker UUID: %s", checkerUuidString))); <|endfocus|> try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setChecker(checkerUuid); if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks", e); } } @Override
<|startcomment|> checkStates should never be null since it's varargs. <|endcomment|>  this.listPendingChecksProvider = listPendingChecksProvider; } @Override public List<PendingChecksInfo> list(String checkerUuidString, CheckState... checkStates) throws RestApiException { CheckerUuid checkerUuid = CheckerUuid.tryParse(checkerUuidString) .orElseThrow( () -> new BadRequestException( String.format("invalid checker UUID: %s", checkerUuidString))); try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setChecker(checkerUuid); <|startfocus|> if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } <|endfocus|> return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks", e); } } @Override public List<PendingChecksInfo> listForScheme(String scheme, CheckState... checkStates) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setScheme(scheme); if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); }
<|startcomment|> checkStates should never be null since it's varargs. <|endcomment|>  if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks", e); } } @Override public List<PendingChecksInfo> listForScheme(String scheme, CheckState... checkStates) throws RestApiException { try { ListPendingChecks listPendingChecks = listPendingChecksProvider.get(); listPendingChecks.setScheme(scheme); <|startfocus|> if (checkStates != null) { Stream.of(checkStates).forEach(listPendingChecks::addState); } <|endfocus|> return listPendingChecks.apply(TopLevelResource.INSTANCE); } catch (Exception e) { throw asRestApiException("Cannot list pending checks for scheme", e); } } } 
<|startcomment|> Avoid wildcard imports. <|endcomment|> // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.its.jira; <|startfocus|> import static com.googlesource.gerrit.plugins.its.jira.JiraConfig.*; <|endfocus|> import com.google.gerrit.extensions.annotations.Exports; import com.google.gerrit.extensions.annotations.PluginName; import com.google.gerrit.server.config.PluginConfigFactory; import com.google.gerrit.server.config.ProjectConfigEntry; import com.google.inject.AbstractModule; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.its.base.ItsHookModule; import com.googlesource.gerrit.plugins.its.base.its.ItsConfig; import com.googlesource.gerrit.plugins.its.base.its.ItsFacade; import com.googlesource.gerrit.plugins.its.base.its.ItsFacadeFactory; import com.googlesource.gerrit.plugins.its.base.workflow.CustomAction;
<|startcomment|> Should errors come before warnings? I guess most people skip to the bottom, but I think perhaps a comment here would clarify that this is the intent (so people don't come along later and reorder it). <|endcomment|>  String email = preferredEmails.get(owner); for (String path : result.owner2paths.get(owner)) { addOwnerPathPair(email, path); } } for (String glob : result.noParentGlobs) { add2dir2Globs(Util.getDirName(glob) + "/", glob); } if (config.getReportSyntaxError()) { Ordering.natural().sortedCopy(result.warnings).forEach(w -> logger.atWarning().log(w)); <|startfocus|> Ordering.natural().sortedCopy(result.errors).forEach(e -> logger.atSevere().log(e)); <|endfocus|> }
<|startcomment|> Abstract this out as something like "private static String includedFileKey(project, file) { return ... }". It's used in findReadFile above too. <|endcomment|>  private static void saveReadFile( Map<String, String> readFiles, String project, String file, String content) { if (readFiles != null) { <|startfocus|> readFiles.put(project + ":" + file, content); <|endfocus|> }
<|startcomment|> that it has <|endcomment|>  private static void checkIncludeOrFile( List<CommitValidationMessage> messages, String path, int num, String line) { <|startfocus|> // TODO: Check if an included file exists and with valid syntax. <|endfocus|> // An included file could be a new file added by a CL and not in the repository yet add(messages, "unchecked: " + path + ":" + num + ": " + Parser.getIncludeOrFile(line), false);
<|startcomment|> recursive <|endcomment|>  private GitRepositoryManager repoManager; private String branch; // All owners files are read from the same branch. private IncludeStack stack; // a stack of including files. private List<String> logs; // Keeps debug/trace messages. private Map<String, Result> savedResults; // projectName:filePath => Parser.Result static class IncludeStack { Deque<String> projectName; // project/repository name of included file Deque<String> filePath; // absolute or relative path of included file <|startfocus|> Set<String> allFiles; // to detect recurisve inclusion quickly <|endfocus|> IncludeStack(String project, String file) { projectName = new ArrayDeque<>(); filePath = new ArrayDeque<>(); allFiles = new HashSet<>(); push(project, file); } void push(String project, String file) { projectName.push(project); filePath.push(file); allFiles.add(project + ":" + file); } void pop() { allFiles.remove(currentProject() + ":" + currentFile()); projectName.pop(); filePath.pop(); } 
<|startcomment|> More reuse for the helper function. <|endcomment|>  void push(String project, String file) { projectName.push(project); filePath.push(file); <|startfocus|> allFiles.add(project + ":" + file); <|endfocus|>
<|startcomment|> Ditto <|endcomment|>  void pop() { <|startfocus|> allFiles.remove(currentProject() + ":" + currentFile()); <|endfocus|> projectName.pop(); filePath.pop();
<|startcomment|> Ditto <|endcomment|>  boolean contains(String project, String file) { <|startfocus|> return allFiles.contains(project + ":" + file); <|endfocus|>
<|startcomment|> Can this just be an enum? <|endcomment|>  rp.sendError("internal error while processing changes"); // ReceiveCommits has tried its best to catch errors, so anything at this // point is very bad. for (ReceiveCommand c : commands) { if (c.getResult() == Result.NOT_ATTEMPTED) { c.setResult(Result.REJECTED_OTHER_REASON, "internal error"); } } } finally { w.sendMessages(); } long deltaNanos = System.nanoTime() - startNanos; int totalChanges = 0; <|startfocus|> String pushType; <|endfocus|> if (resultChangeIds.isMagicPush()) { pushType = "CREATE_REPLACE"; List<Change.Id> created = resultChangeIds.get(ResultChangeIds.Key.CREATED); List<Change.Id> replaced = resultChangeIds.get(ResultChangeIds.Key.REPLACED); metrics.changes.record(pushType, created.size() + replaced.size()); totalChanges += replaced.size() + created.size(); } else { List<Change.Id> autoclosed = resultChangeIds.get(ResultChangeIds.Key.AUTOCLOSED); if (!autoclosed.isEmpty()) { pushType = ResultChangeIds.Key.AUTOCLOSED.name();
<|startcomment|> Maybe s/+=/=/, same for the autoclosed branch below. It's easier on the brain stack machine as I don't have to think about what totalChanges was before. <|endcomment|>  } finally { w.sendMessages(); } long deltaNanos = System.nanoTime() - startNanos; int totalChanges = 0; String pushType; if (resultChangeIds.isMagicPush()) { pushType = "CREATE_REPLACE"; List<Change.Id> created = resultChangeIds.get(ResultChangeIds.Key.CREATED); List<Change.Id> replaced = resultChangeIds.get(ResultChangeIds.Key.REPLACED); metrics.changes.record(pushType, created.size() + replaced.size()); <|startfocus|> totalChanges += replaced.size() + created.size(); <|endfocus|> } else { List<Change.Id> autoclosed = resultChangeIds.get(ResultChangeIds.Key.AUTOCLOSED); if (!autoclosed.isEmpty()) { pushType = ResultChangeIds.Key.AUTOCLOSED.name(); metrics.changes.record(ResultChangeIds.Key.AUTOCLOSED.name(), autoclosed.size()); totalChanges += autoclosed.size(); } else { pushType = "NORMAL"; } } if (totalChanges > 0) { metrics.latencyPerChange.record(pushType, deltaNanos / totalChanges, NANOSECONDS); } metrics.latencyPerPush.record(pushType, deltaNanos, NANOSECONDS);
<|startcomment|> Should we add a comment here, that events for other refs, like refs/sequences/changes are skipped? <|endcomment|>  String patchsetRevision = change.currentPatchSet().getRevision().get(); String patchsetRef = change.currentPatchSet().getRefName(); Map<String, List<Event>> eventsByType = receiveEventsByType(droppedEventsQueue); assertThat(eventsByType.get("change-index")) .containsExactly(createChangeIndexEvent(project, changeNum, getParentCommit(change))); assertThat( eventsByType .get("ref-updated") .stream() .map(e -> ((RefUpdatedEvent) e).getRefName()) .collect(toSet())) <|startfocus|> .containsAllOf(changeNotesRef, patchsetRef); <|endfocus|> List<Event> patchSetCreatedEvents = eventsByType.get("patchset-created"); assertThat(patchSetCreatedEvents).hasSize(1); assertPatchSetAttributes( (PatchSetCreatedEvent) patchSetCreatedEvents.get(0), patchsetNum, patchsetRevision, patchsetRef); } private void assertPatchSetAttributes( PatchSetCreatedEvent patchSetCreated, int patchsetNum, String patchsetRevision, String patchsetRef) { PatchSetAttribute patchSetAttribute = patchSetCreated.patchSet.get(); assertThat(patchSetAttribute.number).isEqualTo(patchsetNum); assertThat(patchSetAttribute.revision).isEqualTo(patchsetRevision);
<|startcomment|> Left over diagnostic statement. <|endcomment|>  .collect(Collectors.groupingBy(e -> e.type)); } private List<Event> drainQueue(LinkedBlockingQueue<SourceAwareEventWrapper> queue) throws InterruptedException { GsonProvider gsonProvider = plugin.getSysInjector().getInstance(Key.get(GsonProvider.class)); SourceAwareEventWrapper event; List<Event> eventsList = new ArrayList<>(); while ((event = queue.poll(QUEUE_POLL_TIMEOUT_MSECS, TimeUnit.MILLISECONDS)) != null) { <|startfocus|> System.out.println("Received event: " + event.getHeader() + " / " + event.getBody()); <|endfocus|> eventsList.add(event.getEventBody(gsonProvider)); } return eventsList; } } 
<|startcomment|> retrieve <|endcomment|>  private final CheckResource checkResource; @Inject CheckApiImpl(GetCheck getCheck, UpdateCheck updateCheck, @Assisted CheckResource checkResource) { this.getCheck = getCheck; this.updateCheck = updateCheck; this.checkResource = checkResource; } @Override public CheckInfo get(ListChecksOption... options) throws RestApiException { try { Arrays.stream(options).forEach(getCheck::addOption); return getCheck.apply(checkResource); } catch (Exception e) { <|startfocus|> throw asRestApiException("Cannot update check", e); <|endfocus|> } } @Override public CheckInfo update(CheckInput input) throws RestApiException { try { return updateCheck.apply(checkResource, input); } catch (Exception e) { throw asRestApiException("Cannot update check", e); } } } 
<|startcomment|> Why 'O'? Don't we usually use 'T' to represent generic types? <|endcomment|> // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.client; import java.lang.reflect.InvocationTargetException; import java.util.EnumSet; /** Enum that can be expressed as a bitset in query parameters. */ public interface ListOption { int getValue(); <|startfocus|> static <O extends Enum<O> & ListOption> EnumSet<O> fromBits(Class<O> clazz, int v) { EnumSet<O> r = EnumSet.noneOf(clazz); O[] values; <|endfocus|> try { @SuppressWarnings("unchecked") O[] tmp = (O[]) clazz.getMethod("values").invoke(null); values = tmp; } catch (IllegalAccessException | NoSuchMethodException | InvocationTargetException e) { throw new IllegalStateException(e); } for (O o : values) { if ((v & (1 << o.getValue())) != 0) { r.add(o); v &= ~(1 << o.getValue()); }
<|startcomment|> Shouldn't we rather avoid using objects of our REST API in an internal server class? I think we could just return a boolean value here and wrap it in PureRevertInfo in GetPureRevert. <|endcomment|> import com.google.gerrit.server.git.PureRevertCache; import com.google.gerrit.server.notedb.ChangeNotes; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import org.eclipse.jgit.errors.InvalidObjectIdException; import org.eclipse.jgit.lib.ObjectId; @Singleton public class PureRevert { private final PureRevertCache pureRevertCache; @Inject PureRevert(PureRevertCache pureRevertCache) { this.pureRevertCache = pureRevertCache; } <|startfocus|> public PureRevertInfo get(ChangeNotes notes, @Nullable String claimedOriginal) <|endfocus|> throws OrmException, IOException, BadRequestException, ResourceConflictException { PatchSet currentPatchSet = notes.getCurrentPatchSet(); if (currentPatchSet == null) { throw new ResourceConflictException("current revision is missing"); } if (claimedOriginal == null) { return new PureRevertInfo(pureRevertCache.isPureRevert(notes)); } ObjectId claimedOriginalObjectId; try { claimedOriginalObjectId = ObjectId.fromString(claimedOriginal); } catch (InvalidObjectIdException e) { throw new BadRequestException("invalid object ID"); } 
<|startcomment|> Should be a primitive boolean. <|endcomment|>  PatchSet currentPatchSet = notes.getCurrentPatchSet(); if (currentPatchSet == null) { throw new ResourceConflictException("current revision is missing"); } if (claimedOriginal == null) { return new PureRevertInfo(pureRevertCache.isPureRevert(notes)); } ObjectId claimedOriginalObjectId; try { claimedOriginalObjectId = ObjectId.fromString(claimedOriginal); } catch (InvalidObjectIdException e) { throw new BadRequestException("invalid object ID"); } <|startfocus|> Boolean result = pureRevertCache.isPureRevert( notes.getProjectName(), ObjectId.fromString(notes.getCurrentPatchSet().getRevision().get()), claimedOriginalObjectId); return new PureRevertInfo(result); <|endfocus|> } } 
<|startcomment|> Is this constant package private on purpose? <|endcomment|> import org.eclipse.jgit.diff.DiffFormatter; import org.eclipse.jgit.errors.InvalidObjectIdException; import org.eclipse.jgit.errors.MissingObjectException; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectInserter; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.merge.ThreeWayMerger; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; /** Computes and caches if a change is a pure revert of another change. */ @Singleton public class PureRevertCache { <|startfocus|> static final String ID_CACHE = "pure_revert"; <|endfocus|> public static class Module extends CacheModule { @Override protected void configure() { persist(ID_CACHE, Cache.PureRevertKeyProto.class, Boolean.class) .maximumWeight(100) .loader(Loader.class) .version(1) .keySerializer(new ProtobufSerializer<>(Cache.PureRevertKeyProto.parser())) .valueSerializer(BooleanCacheSerializer.INSTANCE); } } private final LoadingCache<PureRevertKeyProto, Boolean> cache; private final PatchSetUtil psUtil; private final ChangeNotes.Factory notesFactory; @Inject PureRevertCache(
<|startcomment|> This method doesn't have a 'claimedOriginal'. Hence, the Javadoc description is a bit confusing. <|endcomment|>  private final LoadingCache<PureRevertKeyProto, Boolean> cache; private final PatchSetUtil psUtil; private final ChangeNotes.Factory notesFactory; @Inject PureRevertCache( @Named(ID_CACHE) LoadingCache<PureRevertKeyProto, Boolean> cache, PatchSetUtil psUtil, ChangeNotes.Factory notesFactory) { this.cache = cache; this.psUtil = psUtil; this.notesFactory = notesFactory; } /** <|startfocus|> * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. <|endfocus|> * * @return {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. * @throws IOException if there was a priblem with the storage layer * @throws OrmException if there was a priblem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ChangeNotes} */ public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException {
<|startcomment|> Do you happen to know whether it's better to use ChangeNotes#getCurrentPatchSet or PatchSetUtil#current(ChangeNotes)? Why I'm asking: Within the isPureRevert() method, both are currently used (here and line 1010). It would be better to be consistent. <|endcomment|>  */ public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException { if (claimedRevert.getChange().getRevertOf() == null) { throw new BadRequestException("revertOf not set"); } PatchSet ps = psUtil.current( notesFactory.createChecked( claimedRevert.getProjectName(), claimedRevert.getChange().getRevertOf())); return isPureRevert( claimedRevert.getProjectName(), ObjectId.fromString(claimedRevert.getCurrentPatchSet().getRevision().get()), <|startfocus|> ObjectId.fromString(ps.getRevision().get())); <|endfocus|> } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. * * @return {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. * @throws IOException if there was a priblem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ObjectId}s */ public boolean isPureRevert(
<|startcomment|> nit: problem <|endcomment|>  ObjectId.fromString(claimedRevert.getCurrentPatchSet().getRevision().get()), ObjectId.fromString(ps.getRevision().get())); } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. * * @return {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. <|startfocus|> * @throws IOException if there was a priblem with the storage layer <|endfocus|> * @throws BadRequestException if there is a problem with the provided {@link ObjectId}s */ public boolean isPureRevert( Project.NameKey project, ObjectId claimedRevert, ObjectId claimedOriginal) throws IOException, BadRequestException { try { return cache.get(key(project, claimedRevert, claimedOriginal)); } catch (ExecutionException e) { Throwables.throwIfInstanceOf(e.getCause(), BadRequestException.class); throw new IOException(e); } } @VisibleForTesting static PureRevertKeyProto key(
<|startcomment|> How can this be safely false? Can't a repository have only two commits, the second being the pure revert of the first? (I understand that we might have an issue with some computation because of which we originally threw an exception but switching to the value 'false' makes a statement and I'm not sure it is true.) <|endcomment|>  Project.NameKey project = new Project.NameKey(key.getProject()); try (Repository repo = repoManager.openRepository(project); ObjectInserter oi = repo.newObjectInserter(); RevWalk rw = new RevWalk(repo)) { RevCommit claimedOriginalCommit; try { claimedOriginalCommit = rw.parseCommit(original); } catch (InvalidObjectIdException | MissingObjectException e) { throw new BadRequestException("invalid object ID"); } if (claimedOriginalCommit.getParentCount() == 0) { <|startfocus|> return false; <|endfocus|> } RevCommit claimedRevertCommit = rw.parseCommit(revert); if (claimedRevertCommit.getParentCount() == 0) { return false; } // Rebase claimed revert onto claimed original ThreeWayMerger merger = mergeUtilFactory .create(projectCache.checkedGet(project)) .newThreeWayMerger(oi, repo.getConfig()); merger.setBase(claimedRevertCommit.getParent(0)); boolean success = merger.merge(claimedRevertCommit, claimedOriginalCommit); if (!success || merger.getResultTreeId() == null) { // Merge conflict during rebase return false; } 
<|startcomment|> Why is this changed directly to the PureRevertCache? Don't we want to benefit from the additional logic in PureRevert? <|endcomment|>  } starsOf = StarsOf.create(accountId, starredChangesUtil.getLabels(accountId, legacyId)); } } return starsOf.stars(); } /** * @return {@code null} if {@code revertOf} is {@code null}; true if the change is a pure revert; * false otherwise. */ @Nullable public Boolean isPureRevert() throws OrmException { if (change().getRevertOf() == null) { return null; } try { <|startfocus|> return pureRevertCache.isPureRevert(notes()); } catch (IOException | BadRequestException e) { <|endfocus|> throw new OrmException("could not compute pure revert", e); } } @Override public String toString() { MoreObjects.ToStringHelper h = MoreObjects.toStringHelper(this); if (change != null) { h.addValue(change); } else { h.addValue(legacyId); } return h.toString(); } public static class ChangedLines { public final int insertions; public final int deletions; public ChangedLines(int insertions, int deletions) {
<|startcomment|> Please adjust the name of the test. This test isn't doing a round trip. <|endcomment|> <|startfocus|> public void testRoundTrip() { <|endfocus|> ObjectId revert = ObjectId.zeroId(); ObjectId original = ObjectId.fromString("deadbeefdeadbeefdeadbeefdeadbeefdeadbeef"); byte[] serializedRevert = new byte[20]; byte[] serializedOriginal = new byte[20]; revert.copyRawTo(serializedRevert, 0); original.copyRawTo(serializedOriginal, 0); Cache.PureRevertKeyProto key = PureRevertCache.key(new Project.NameKey("test"), revert, original); assertThat(key) .isEqualTo( Cache.PureRevertKeyProto.newBuilder() .setProject("test") .setClaimedRevert(ByteString.copyFrom(serializedRevert)) .setClaimedOriginal(ByteString.copyFrom(serializedOriginal)) .build());
<|startcomment|> combine is what this is doing, but I still would prefer something more descriptive here. getFileID(...) or maybe getFileKey() could work. In general these are just the singular internal representation of this information that uniquely identifies an OWNERS file. <|endcomment|> <|startfocus|> static String combine(String project, String file) { <|endfocus|> return project + ":" + file;
<|startcomment|> Copyright (C) 2019 The Android Open Source Project <|endcomment|> <|startfocus|> Copyright(C)2012The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper; import static com.google.common.base.Preconditions.checkArgument; import java.io.IOException; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.retry.ExponentialBackoffRetry; public class CuratorFrameworkBuilder { private ZkConfig config = null; public CuratorFrameworkBuilder config(ZkConfig config) { this.config = config; return this; } public CuratorFramework build() throws IOException {
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2012 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper; import com.google.common.base.MoreObjects; import java.io.Serializable; import org.apache.curator.framework.CuratorFrameworkFactory; import org.eclipse.jgit.lib.Config; /** Configuration for a Zookeeper setup. */ public class ZkConfig implements Serializable { private static final long serialVersionUID = 1L; public static final int DEFAULT_SESSION_TIMEOUT_MS; public static final int DEFAULT_CONNECTION_TIMEOUT_MS; static {
<|startcomment|> Do we need the retry policy in this change? Can we remove this and create a follow-up change? <|endcomment|>  public static final int DEFAULT_CONNECTION_TIMEOUT_MS; static { CuratorFrameworkFactory.Builder b = CuratorFrameworkFactory.builder(); DEFAULT_SESSION_TIMEOUT_MS = b.getSessionTimeoutMs(); DEFAULT_CONNECTION_TIMEOUT_MS = b.getConnectionTimeoutMs(); } private static final String SECTION = "zookeeper"; private static final String KEY_CONNECT_STRING = "connectString"; private static final String KEY_SESSION_TIMEOUT = "sessionTimeout"; <|startfocus|> private static final String KEY_CONNECTION_TIMEOUT = "connectionTimeout"; // TODO(dborowitz): Configure RetryPolicy. <|endfocus|> private final String connectString; private final int sessionTimeoutMs; private final int connectionTimeoutMs; private final String zookeeperRoot; ZkConfig( final String connectString, final String zookeeperRoot, final int sessionTimeoutMs, final int connectionTimeoutMs) { this.connectString = connectString; this.sessionTimeoutMs = sessionTimeoutMs; this.connectionTimeoutMs = connectionTimeoutMs; this.zookeeperRoot = zookeeperRoot; } public static ZkConfig fromConfig(Config cfg) { return new ZkConfig( cfg.getString(SECTION, null, KEY_CONNECT_STRING),
<|startcomment|> is this a Tobstone reference for deletion, as defined in cassandra? Perhaps we should explain what it is and why is needed <|endcomment|>  return true; } private boolean doCreate( ZkRefInfoMarshaller marshaller, Optional<ZkRefInfo> infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo) throws Exception { if (infoCurrentlyInZkMaybe.isPresent()) { logger.atWarning().log( "Asked to create ref %s but it is already in ZK at path %s", newRefInfo.refName(), ZkRefInfoMarshaller.pathFor(newRefInfo)); return false; } marshaller.create(newRefInfo); return true; } <|startfocus|> <|endfocus|> static class TombstoneRef implements Ref { static TombstoneRef forRef(final Ref targetRef) { return new TombstoneRef(targetRef.getName()); } private final String name; private TombstoneRef(String name) { this.name = name; } @Override public String getName() { return name; } @Override public boolean isSymbolic() { return false; } @Override public Ref getLeaf() { return null; } @Override public Ref getTarget() { return null; } @Override
<|startcomment|> What is the chance they are equals? Even if they were, this shouldn't fail the test imho, but a new zkref should perhaps be generated. we could make sure that they are not the same by creating updateRefInfo based on some modified newRefInfo values. <|endcomment|>  assertThat(marshaller.read(aProjectName(), aChangeRefName())).isEqualTo(Optional.empty()); } @Test public void shouldUpdateAZrefInfo() throws Exception { ZkRefInfo newRefInfo = aZkRefInfo(); ZkRefInfo updateRefInfo = new ZkRefInfo( newRefInfo.projectName(), newRefInfo.refName(), anObjectId(), Instant.now(), UUID.randomUUID()); <|startfocus|> // Make sure new refInfo and updateRefInfo are never the same assertThat(newRefInfo).isNotEqualTo(updateRefInfo); <|endfocus|> marshaller.create(newRefInfo); marshaller.update(updateRefInfo); Optional<ZkRefInfo> readUpdatedRefInfo = marshaller.read(updateRefInfo.projectName(), updateRefInfo.refName()); assertThat(readUpdatedRefInfo).isEqualTo(Optional.of(updateRefInfo)); } @Test public void shouldFailToReadZkRefInfoIfSomeOfTheInfoIsMissing() throws Exception { String projectName = aProjectName(); String refName = aChangeRefName(); curator.createContainers(ZkRefInfoMarshaller.pathFor(projectName, refName)); expectedException.expect(CorruptedZkStorageException.class);
<|startcomment|> Best to call it 'other' <|endcomment|> <|startfocus|> public boolean equals(Object o) { if (this == o) { <|endfocus|> return true; } if (o == null || getClass() != o.getClass()) { return false; } ZkRefInfo zkRefInfo = (ZkRefInfo) o; return Objects.equal(refName, zkRefInfo.refName) && Objects.equal(projectName, zkRefInfo.projectName) && Objects.equal(objectId, zkRefInfo.objectId) && Objects.equal(lastWriterInstanceId, zkRefInfo.lastWriterInstanceId) && Objects.equal(lastUpdatedAt, zkRefInfo.lastUpdatedAt);
<|startcomment|> Is this really needed? We throw the exception anyway that would record this point in its stacktrace. The exception will be eventually traced with the error message and the stack point. <|endcomment|>  marshaller.read(projectName, newRef.getName()); final ZkRefInfo newRefInfo = new ZkRefInfo(projectName, newRef, instanceId); if (isCreate) { return doCreate(marshaller, infoCurrentlyInZkMaybe, newRefInfo); } else { return doUpdate(oldRef, marshaller, infoCurrentlyInZkMaybe, newRefInfo); } } catch (Exception e) { logger.atWarning().withCause(e).log( <|startfocus|> "Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)); <|endfocus|> throw new IOException( String.format( "Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)), e); } } private boolean doUpdate( Ref oldRef, ZkRefInfoMarshaller marshaller, Optional<ZkRefInfo> infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo) throws Exception { if (!infoCurrentlyInZkMaybe.isPresent()) { logger.atWarning().log( "Asked to update ref %s but it is not in ZK at path %s",
<|startcomment|> We do not really want an optional here, isn't it? If we pass an Optional.empty() then we return a runtime error. <|endcomment|>  } } catch (Exception e) { logger.atWarning().withCause(e).log( "Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)); throw new IOException( String.format( "Error trying to perform CAS at path %s", ZkRefInfoMarshaller.pathFor(projectName, newRef)), e); } } private boolean doUpdate( Ref oldRef, <|startfocus|> ZkRefInfoMarshaller marshaller, <|endfocus|> Optional<ZkRefInfo> infoCurrentlyInZkMaybe, ZkRefInfo newRefInfo) throws Exception { if (!infoCurrentlyInZkMaybe.isPresent()) { logger.atWarning().log( "Asked to update ref %s but it is not in ZK at path %s", newRefInfo.refName(), ZkRefInfoMarshaller.pathFor(newRefInfo)); return false; } if (!infoCurrentlyInZkMaybe.get().objectId().equals(oldRef.getObjectId())) { logger.atWarning().log(
<|startcomment|> StartStop? (it looks like it is starting zookeeper also) <|endcomment|> import java.io.IOException; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.test.TestingServer; import org.junit.Test; @NoHttpd @LogThreshold(level = "INFO") @TestPlugin( name = "multi-site", sysModule = "com.googlesource.gerrit.plugins.multisite.validation.ValidationIT$Module") public class ValidationIT extends LightweightPluginDaemonTest { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); CuratorFramework framework; public static class Module extends LifecycleModule { public class ZookeeperStopAtShutdown implements LifecycleListener { <|startfocus|> private final TestingServer zookeeper; <|endfocus|> public ZookeeperStopAtShutdown(TestingServer zookeeper) { this.zookeeper = zookeeper; } @Override public void stop() { try { zookeeper.stop(); } catch (IOException e) { logger.atWarning().withCause(e).log("Cannot start zookeeper"); throw new RuntimeException("Cannot start zookeeper", e); } } @Override public void start() { try { zookeeper.start(); } catch (Exception e) {
<|startcomment|> Throw a Guice Binding failure exception <|endcomment|>  protected void configure() { TestingServer zookeeper = null; try { zookeeper = new TestingServer(); } catch (Exception e) { throw new RuntimeException("Cannot init zookeeper", e); } install(new ValidationModule()); <|startfocus|> super.configure(); listener().toInstance(new ZookeeperStopAtShutdown(zookeeper)); <|endfocus|>
<|startcomment|> No random please. <|endcomment|> import org.junit.Ignore; @Ignore public interface RefFixture { String ALLOWED_CHARS = "abcdefghilmnopqrstuvz"; String ALLOWED_DIGITS = "1234567890"; String ALLOWED_NAME_CHARS = ALLOWED_CHARS + ALLOWED_CHARS.toUpperCase() + ALLOWED_DIGITS; static ZkRefInfo aZkRefInfo() { return new ZkRefInfo( aProjectName(), aChangeRefName(), anObjectId(), Instant.now(), UUID.randomUUID()); } <|startfocus|> static String aProjectName() { return RandomStringUtils.random(20, ALLOWED_NAME_CHARS); <|endfocus|> } static ObjectId anObjectId() { return ObjectId.fromString(RandomStringUtils.randomNumeric(40)); } static String aChangeRefName() { return "refs/for/" + RandomStringUtils.random(10, ALLOWED_NAME_CHARS); } static Ref aRefObject(String refName, ObjectId objectId) { return new TestRef(refName, objectId); } static Ref aRefObject(String refName) { return aRefObject(refName, anObjectId()); } static Ref aRefObject() { return aRefObject(aChangeRefName(), anObjectId()); }
<|startcomment|> Import static RefFixture.<methods you need> <|endcomment|>  public void shouldCreateANewRef() { <|startfocus|> ObjectId objectId = RefFixture.anObjectId(); String refName = RefFixture.aChangeRefName(); <|endfocus|> Ref aNewRef = zkSharedRefDatabase.newRef(refName, objectId); assertThat(aNewRef.getName()).isEqualTo(refName); assertThat(aNewRef.getObjectId()).isEqualTo(objectId); assertThat(aNewRef.getStorage()).isEqualTo(Storage.NETWORK);
<|startcomment|> Why random again? <|endcomment|>  Ref aNewRef = zkSharedRefDatabase.newRef(refName, objectId); assertThat(aNewRef.getName()).isEqualTo(refName); assertThat(aNewRef.getObjectId()).isEqualTo(objectId); assertThat(aNewRef.getStorage()).isEqualTo(Storage.NETWORK); } @Test public void shouldCompareAndPutSuccessfully() throws Exception { Ref oldRef = aRefObject(); String projectName = RefFixture.aProjectName(); <|startfocus|> marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID())); <|endfocus|> assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRef, aRefObject(oldRef.getName()))) .isTrue(); } @Test public void compareAndPutShouldFailIfTheObjectionHasNotTheExpectedValue() throws Exception { String projectName = RefFixture.aProjectName(); Ref oldRef = aRefObject(); Ref expectedRef = aRefObject(oldRef.getName()); marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID())); assertThat( zkSharedRefDatabase.compareAndPut( projectName, expectedRef, aRefObject(oldRef.getName()))) .isFalse(); } 
<|startcomment|> The Tombstone should be a singleton right? Can we just assert for equality? <|endcomment|>  marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID())); assertThat(zkSharedRefDatabase.compareAndRemove(projectName, oldRef)).isTrue(); Optional<ZkRefInfo> inZk = marshaller.read(projectName, oldRef.getName()); assertThat(inZk.isPresent()).isTrue(); <|startfocus|> assertThat(inZk.get().projectName()).isEqualTo(projectName); assertThat(inZk.get().refName()).isEqualTo(oldRef.getName()); assertThat(inZk.get().objectId()).isEqualTo(ObjectId.zeroId()); <|endfocus|> } @Test public void shouldNotCompareAndPutSuccessfullyAfterACompareAndRemove() throws Exception { Ref oldRef = aRefObject(); String projectName = RefFixture.aProjectName(); marshaller.create(new ZkRefInfo(projectName, oldRef, UUID.randomUUID())); zkSharedRefDatabase.compareAndRemove(projectName, oldRef); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRef, aRefObject(oldRef.getName()))) .isFalse(); } } 
<|startcomment|> Can we just make readObjectIdAt throwing an exception? We are returning an option but not doing much with it <|endcomment|>  return "/" + projectName + "/" + refName; } private final CuratorFramework client; public ZkRefInfoDAO(CuratorFramework client) { this.client = client; } public Optional<ZkRefInfo> read(String projectName, String refName) throws Exception { final String rootPath = pathFor(projectName, refName); if (!exists(rootPath)) return Optional.empty(); <|startfocus|> final Optional<ObjectId> objectId = readObjectIdAt(rootPath + "/" + OBJECT_ID_PATH); <|endfocus|> if (!(objectId.isPresent())) { throw new CorruptedZkStorageException( String.format( "Corrupted content for ref %s, missing some of the sub info, %s present: %b", refName, OBJECT_ID_PATH, objectId.isPresent())); } return Optional.of(new ZkRefInfo(projectName, refName, objectId.get())); } public void update(ZkRefInfo info) throws Exception { writeInTransaction(info, () -> client.transactionOp().setData()); } public void create(ZkRefInfo info) throws Exception {
<|startcomment|> Looks like this is not used <|endcomment|> import org.apache.curator.framework.recipes.locks.InterProcessMutex; import org.apache.curator.framework.recipes.locks.Locker; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; public class ZkSharedRefDatabase implements SharedRefDatabase { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final CuratorFramework client; private final Duration lockTimeout; private final UUID instanceId; @Inject public ZkSharedRefDatabase( CuratorFramework client, <|startfocus|> @Named("ZkLockTimeout") Duration lockTimeout, @InstanceId UUID instanceId) { <|endfocus|> this.client = client; this.lockTimeout = lockTimeout; this.instanceId = instanceId; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, TombstoneRef.forRef(oldRef)); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { boolean isCreate = oldRef == NULL_REF; final ZkRefInfoDAO marshaller = new ZkRefInfoDAO(client); final InterProcessMutex refPathMutex =
<|startcomment|> Please don't use any API classes here as this is internal code. If there is something you need in these classes, check if it fits into Checkers or Checks (the interfaces we have in the top-level package) <|endcomment|> import com.google.gerrit.extensions.annotations.Exports; import com.google.gerrit.extensions.config.FactoryModule; import com.google.gerrit.plugins.checks.Checker; import com.google.gerrit.plugins.checks.Checkers; import com.google.gerrit.plugins.checks.api.BlockingCondition; import com.google.gerrit.plugins.checks.api.CheckInfo; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.plugins.checks.api.CheckerStatus; import com.google.gerrit.plugins.checks.api.CombinedCheckState; import com.google.gerrit.plugins.checks.api.ListChecks; <|startfocus|> import com.google.gerrit.reviewdb.client.Change; <|endfocus|> import com.google.gerrit.reviewdb.client.Project; import com.google.gerrit.server.project.SubmitRuleOptions; import com.google.gerrit.server.query.change.ChangeData; import com.google.gerrit.server.rules.SubmitRule; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import java.util.Collection; import java.util.Map; @Singleton public class ChecksSubmitRule implements SubmitRule { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final SubmitRequirement DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS = SubmitRequirement.builder()
<|startcomment|> This can be omitted because there are separate tests that ensure change creation works as intended. <|endcomment|> import com.google.gerrit.plugins.checks.api.CheckerStatus; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.reviewdb.client.Project; import org.junit.Before; import org.junit.Test; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private String testChangeId; private PatchSet.Id testPatchSetId; private CheckerUuid testCheckerUuid; @Before public void setUp() throws Exception { PushOneCommit.Result result = createChange(); result.assertOkStatus(); <|startfocus|> testChangeId = result.getChangeId(); <|endfocus|> testPatchSetId = result.getPatchSetId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); // Creates a test Checker which is enabled and required for the test repository. testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.ENABLED);
<|startcomment|> nit: The PS-ID contains the change ID, so storing the change ID can be omitted <|endcomment|> import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.reviewdb.client.Project; import org.junit.Before; import org.junit.Test; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private String testChangeId; private PatchSet.Id testPatchSetId; private CheckerUuid testCheckerUuid; @Before public void setUp() throws Exception { PushOneCommit.Result result = createChange(); result.assertOkStatus(); testChangeId = result.getChangeId(); <|startfocus|> testPatchSetId = result.getPatchSetId(); <|endfocus|> // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); // Creates a test Checker which is enabled and required for the test repository. testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.ENABLED); assertThat(checkerOperations.checker(testCheckerUuid).get().getBlockingConditions()) .containsExactly(BlockingCondition.STATE_NOT_PASSING);
<|startcomment|> This can be removed since the CheckerOperations are well tested in other places <|endcomment|>  // about checks. approve(testChangeId); // Creates a test Checker which is enabled and required for the test repository. testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); <|startfocus|> assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.ENABLED); assertThat(checkerOperations.checker(testCheckerUuid).get().getBlockingConditions()) .containsExactly(BlockingCondition.STATE_NOT_PASSING); <|endfocus|> } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); // Updates the checker so that it isn't applicable to the change any more. Project.NameKey otherRepo = new Project.NameKey("other-project"); gApi.projects().create(otherRepo.get()); checkerOperations.checker(testCheckerUuid).forUpdate().repository(otherRepo).update(); assertThat(checkerOperations.checker(testCheckerUuid).get().getRepository()) .isEqualTo(otherRepo); gApi.changes().id(testChangeId).current().submit(); 
<|startcomment|> nit: disabledCheckerDoesNotBlockSubmit (here and below) <|endcomment|>  Project.NameKey otherRepo = new Project.NameKey("other-project"); gApi.projects().create(otherRepo.get()); checkerOperations.checker(testCheckerUuid).forUpdate().repository(otherRepo).update(); assertThat(checkerOperations.checker(testCheckerUuid).get().getRepository()) .isEqualTo(otherRepo); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); } @Test <|startfocus|> public void disabledCheckerNotBlockingSubmit() throws Exception { <|endfocus|> postCheckResult(testCheckerUuid, CheckState.FAILED); checkerOperations.checker(testCheckerUuid).forUpdate().disable().update(); assertThat(checkerOperations.checker(testCheckerUuid).get().getStatus()) .isEqualTo(CheckerStatus.DISABLED); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); } @Test public void enabledCheckerNotBlockingSubmitIfNoBlockingCondition() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); checkerOperations .checker(testCheckerUuid) .forUpdate()
<|startcomment|> Sandboxed is really slow, is it possible to rewrite this test so that it is not required anymore? <|endcomment|>  gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); } @Test public void enabledCheckerBlockingSubmitIfInBlockingState() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); exception.expect(ResourceConflictException.class); exception.expectMessage("Passing all blocking checks required"); gApi.changes().id(testChangeId).current().submit(); } @Test @Sandboxed <|startfocus|> public void multipleCheckerBlockingSubmit() throws Exception { <|endfocus|> // Two enabled and required checkers. They are blocking if any of them isn't passing. CheckerUuid testCheckerUuid2 = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .create(); postCheckResult(testCheckerUuid, CheckState.SUCCESSFUL); postCheckResult(testCheckerUuid2, CheckState.FAILED); exception.expect(ResourceConflictException.class); exception.expectMessage("Passing all blocking checks required"); gApi.changes().id(testChangeId).current().submit(); } @Test @Sandboxed public void multipleCheckerNotBlockingSubmit() throws Exception {
<|startcomment|> Remove 's'. <|endcomment|>  if (path.isEmpty() || addAll) { Util.addToMap(owner2paths, key, dir + path); } } } } } /** * Parse given lines of an OWNERS files; return parsed Result. * It can recursively call itself to parse included files. * * @param dir is the directory that contains "changed files" of a CL, * not necessarily the OWNERS or included file directory. <|startfocus|> * "owners" found in lines controls changed files in 'dir'. <|endfocus|> * 'dir' ends with '/' or is empty when parsing an included file. * @param lines are the source lines of the file to be parsed. * @return the parsed data */ Result parseFile(String dir, String[] lines) { Result result = new Result(); int n = 0; for (String line : lines) { parseLine(result, dir, line, ++n); } return result; } Result parseFile(String dir, String content) {
<|startcomment|> appended <|endcomment|>  } } } else if ((parsedKPF = parseInclude(stack.currentProject(), line)) != null) { includeFile(result, dir, num, parsedKPF, parsedKPF[0].equals("include")); } else { result.errors.add(errorMsg(stack.currentFile(), num, "ignored unknown line", line)); } } /** * Find and parse an included file and append data to the 'result'. <|startfocus|> * For an 'include' statement, parsed data is all append to the given result parameter. <|endfocus|> * For a 'file:' statement or directive, only owner emails are appended. * If the project+file name is found in the stored result set, the stored result is reused. * The inclusion is skipped if to be included file is already on the including file stack. * * @param result to where the included file data should be added. * @param dir the including file's directory or glob. * @param num source code line number
<|startcomment|> the <|endcomment|>  } } /** * Find and parse an included file and append data to the 'result'. * For an 'include' statement, parsed data is all append to the given result parameter. * For a 'file:' statement or directive, only owner emails are appended. * If the project+file name is found in the stored result set, the stored result is reused. <|startfocus|> * The inclusion is skipped if to be included file is already on the including file stack. <|endfocus|> * * @param result to where the included file data should be added. * @param dir the including file's directory or glob. * @param num source code line number * @param parsedKPF the parsed line of include or file directive. * @param addAll to add all parsed data into result or not. */ private void includeFile(Result result, String dir, int num, String[] parsedKPF, boolean addAll) { String keyword = parsedKPF[0]; String project = parsedKPF[1];
<|startcomment|> Exactly <|endcomment|>  assertThat(r2.owner2paths).isEmpty(); assertThat(r2.warnings).containsExactly(w2, w1); assertThat(r2.noParentGlobs).containsExactly(b2, b1); assertThat(r1.noParentGlobs).containsExactly(b1); assertThat(r2.errors).containsExactly(e2, e1); r1.append(r2, "", true); assertThat(r1.owner2paths).isEmpty(); assertThat(r2.owner2paths).isEmpty(); // warnings, errors, and noParentGlobs are sets of strings. <|startfocus|> // containsExctly does not check order of elements. <|endfocus|> assertThat(r1.warnings).containsExactly(w1, w2); assertThat(r1.warnings).containsExactly(w2, w1); assertThat(r1.noParentGlobs).containsExactly(b2, b1); assertThat(r1.errors).containsExactly(e1, e2); assertThat(r1.errors).containsExactly(e2, e1);
<|startcomment|> I'm working on setting up some integration tests before I add more configuration features but I'm stuck on something that seems simple: This line errors with the commit status REJECTED_OTHER_REASON and the message "no common ancestry". Am I setting up my test repository contents wrong? <|endcomment|> import org.eclipse.jgit.treewalk.filter.PathFilterGroup; import org.junit.Test; @TestPlugin(name = "find-owners", sysModule = "com.googlesource.gerrit.plugins.findowners.Module") public class OwnersFileSubmitRuleIT extends AbstractDaemonTest { @Test public void TestChangeWithoutPermissions() throws Exception { createTestRepositoryContent(); <|startfocus|> setProjectConfig("enforceLevel", "ENFORCE"); PushOneCommit.Result r = createCommitAndPush(testRepo, "refs/for/master", "test message", "A/1/foo.c", "void main()\n"); <|endfocus|> approve(r.getChangeId()); ChangeInfo result = gApi.changes().id(r.getChangeId()).get(); assertThat(result.submittable).isFalse(); } private void createTestRepositoryContent() throws Exception { grant(project, "refs/for/master", Permission.PUSH); TestRepository<InMemoryRepository>.CommitBuilder cb = testRepo.branch("master").commit(); cb.add("OWNERS", "alice@example.com\nbob@example.com\n"); cb.add("A/1/foo.c", "int main()\n");
<|startcomment|> Nit: The current recommendation is to rather add an import (except if a new dependency would need to be added to a BUILD rule). <|endcomment|>  } } private final LoadingCache<PureRevertKeyProto, Boolean> cache; private final ChangeNotes.Factory notesFactory; @Inject PureRevertCache( @Named(ID_CACHE) LoadingCache<PureRevertKeyProto, Boolean> cache, ChangeNotes.Factory notesFactory) { this.cache = cache; this.notesFactory = notesFactory; } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of the change that is <|startfocus|> * referenced in {@link com.google.gerrit.reviewdb.client.Change#getRevertOf()}. <|endfocus|> * * @return {@code true} if {@code claimedRevert} is a pure (clean) revert. * @throws IOException if there was a problem with the storage layer * @throws OrmException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ChangeNotes} */ public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException { if (claimedRevert.getChange().getRevertOf() == null) {
<|startcomment|> Nit: Using a name which indicates that this is the original or claimed revert might really be helpful when reading this method. <|endcomment|>  * @throws IOException if there was a problem with the storage layer * @throws OrmException if there was a problem with the storage layer * @throws BadRequestException if there is a problem with the provided {@link ChangeNotes} */ public boolean isPureRevert(ChangeNotes claimedRevert) throws OrmException, IOException, BadRequestException { if (claimedRevert.getChange().getRevertOf() == null) { throw new BadRequestException("revertOf not set"); } <|startfocus|> ChangeNotes changeNotes = <|endfocus|> notesFactory.createChecked( claimedRevert.getProjectName(), claimedRevert.getChange().getRevertOf()); return isPureRevert( claimedRevert.getProjectName(), ObjectId.fromString(claimedRevert.getCurrentPatchSet().getRevision().get()), ObjectId.fromString(changeNotes.getCurrentPatchSet().getRevision().get())); } /** * Returns {@code true} if {@code claimedRevert} is a pure (clean) revert of {@code * claimedOriginal}. *
<|startcomment|> You need to push this to the server after calling cb.create(): GitUtil.pushHead(testRepo, "refs/heads/master", false); testRepo is just a local clone of the repo on the server. It would be easier to just open the server repo and do a commit there: try (Repository repo = repoManager.openRepository(project)) { // Setup the repo the way you want } // Update your clone testRepo.git().fetch().setRemote("origin").call(); <|endcomment|>  cb.add("A/1/info.txt", "information\n"); cb.add("A/1/OWNERS", "xyz@example.com\n"); cb.add("A/no_inherit/spam.py", "def main()\n"); cb.add("A/no_inherit/ham.py", "def func()\n"); cb.add("A/no_inherit/info.txt", "python information\n"); cb.add("A/no_inherit/OWNERS", "set noparent\nabc@example.com\n"); cb.message("initial commit"); cb.insertChangeId(); cb.create(); } <|startfocus|> private org.eclipse.jgit.lib.Config readProjectConfig() throws Exception { git().fetch().setRefSpecs(new RefSpec(REFS_CONFIG + ":" + REFS_CONFIG)).call(); testRepo.reset(RefNames.REFS_CONFIG); <|endfocus|> RevWalk rw = testRepo.getRevWalk(); RevTree tree = rw.parseTree(testRepo.getRepository().resolve("HEAD")); try (TreeWalk treeWalk = new TreeWalk(rw.getObjectReader())) { treeWalk.setFilter(PathFilterGroup.createFromStrings("project.config")); treeWalk.reset(tree);
<|startcomment|> Please reformat with Google Java Format (available on Github) (To be frank I don't know if the plugin's code base is formatted with gjf, but if not, it should be and we could do a single reformatting change) <|endcomment|>  public Collection<SubmitRecord> evaluate(ChangeData cd, SubmitRuleOptions options) { ProjectState projectState = projectCache.get(cd.project()); <|startfocus|> PluginConfig pluginConfig = pluginConfigFactory.getFromProjectConfigWithInheritance( projectState, pluginName ); <|endfocus|> EnforcementLevel enforce_level = pluginConfig .getEnum(EnforcementLevel.CONFIG_NAME, EnforcementLevel.DISABLED); if (enforce_level == EnforcementLevel.DISABLED) { return ImmutableList.of(); } Checker checker = new Checker(repoManager, pluginConfigFactory, projectState, cd, 1); int result; try { OwnersDb db = Cache.getInstance(pluginConfigFactory, repoManager) .get(true, projectState, accounts, emails, repoManager, pluginConfigFactory, cd); result = checker.findApproval(accounts, db); } catch (OrmException | IOException e) { this.logger.atSevere().withCause(e).log("Exception for %s", Config.getChangeId(cd)); SubmitRecord rec = new SubmitRecord(); rec.status = SubmitRecord.Status.RULE_ERROR; rec.errorMessage = LOOKUP_ERROR_MSG; return ImmutableList.of(rec); } 
<|startcomment|> If you want, you can have an info log here. It never logs except when we enable tracing for a request. Then it is super-helpful to figure out what went wrong. <|endcomment|>  public Collection<SubmitRecord> evaluate(ChangeData cd, SubmitRuleOptions options) { ProjectState projectState = projectCache.get(cd.project()); PluginConfig pluginConfig = pluginConfigFactory.getFromProjectConfigWithInheritance( projectState, pluginName ); EnforcementLevel enforce_level = pluginConfig .getEnum(EnforcementLevel.CONFIG_NAME, EnforcementLevel.DISABLED); <|startfocus|> if (enforce_level == EnforcementLevel.DISABLED) { <|endfocus|> return ImmutableList.of(); } Checker checker = new Checker(repoManager, pluginConfigFactory, projectState, cd, 1); int result; try { OwnersDb db = Cache.getInstance(pluginConfigFactory, repoManager) .get(true, projectState, accounts, emails, repoManager, pluginConfigFactory, cd); result = checker.findApproval(accounts, db); } catch (OrmException | IOException e) { this.logger.atSevere().withCause(e).log("Exception for %s", Config.getChangeId(cd)); SubmitRecord rec = new SubmitRecord(); rec.status = SubmitRecord.Status.RULE_ERROR; rec.errorMessage = LOOKUP_ERROR_MSG; return ImmutableList.of(rec); } 
<|startcomment|> Not related to this change, but it would be better if this returned an enum instead of an int. <|endcomment|>  public Collection<SubmitRecord> evaluate(ChangeData cd, SubmitRuleOptions options) { ProjectState projectState = projectCache.get(cd.project()); PluginConfig pluginConfig = pluginConfigFactory.getFromProjectConfigWithInheritance( projectState, pluginName ); EnforcementLevel enforce_level = pluginConfig .getEnum(EnforcementLevel.CONFIG_NAME, EnforcementLevel.DISABLED); if (enforce_level == EnforcementLevel.DISABLED) { return ImmutableList.of(); } Checker checker = new Checker(repoManager, pluginConfigFactory, projectState, cd, 1); int result; try { <|startfocus|> OwnersDb db = Cache.getInstance(pluginConfigFactory, repoManager) .get(true, projectState, accounts, emails, repoManager, pluginConfigFactory, cd); <|endfocus|> result = checker.findApproval(accounts, db); } catch (OrmException | IOException e) { this.logger.atSevere().withCause(e).log("Exception for %s", Config.getChangeId(cd)); SubmitRecord rec = new SubmitRecord(); rec.status = SubmitRecord.Status.RULE_ERROR; rec.errorMessage = LOOKUP_ERROR_MSG; return ImmutableList.of(rec); } 
<|startcomment|> nit: better readable as: if (result >= 0) { sr.status = OK; return sr; } sr.stats = enforceLevel == ENFORCE ? Status.NOT_READY : Status.OK; return sr; <|endcomment|>  pluginConfigFactory, cd); result = checker.findApproval(accounts, db); } catch (OrmException | IOException e) { this.logger.atSevere().withCause(e).log("Exception for %s", Config.getChangeId(cd)); SubmitRecord rec = new SubmitRecord(); rec.status = SubmitRecord.Status.RULE_ERROR; rec.errorMessage = LOOKUP_ERROR_MSG; return ImmutableList.of(rec); } SubmitRecord sr = new SubmitRecord(); sr.requirements = SUBMIT_REQUIREMENTS; <|startfocus|> switch (enforce_level) { case WARN: sr.status = (result >= 0) ? Status.OK : Status.FORCED; break; case ENFORCE: sr.status = (result >= 0) ? Status.OK : Status.NOT_READY; break; <|endfocus|> } return ImmutableList.of(sr);
<|startcomment|> nit: remove "test" and start with lower-case character <|endcomment|> import com.google.gerrit.extensions.api.changes.SubmitInput; import com.google.gerrit.extensions.common.ChangeInfo; import com.google.gerrit.server.config.PluginConfig; import org.eclipse.jgit.lib.ObjectLoader; import org.eclipse.jgit.revwalk.RevObject; import org.eclipse.jgit.revwalk.RevTree; import org.eclipse.jgit.revwalk.RevWalk; import org.junit.Test; @TestPlugin(name = "find-owners", sysModule = "com.googlesource.gerrit.plugins.findowners.Module") public class OwnersFileSubmitRuleIT extends LightweightPluginDaemonTest { @Test <|startfocus|> public void TestChangeWithoutPermissions() throws Exception { <|endfocus|> createTestRepositoryContent(); configurePlugin("enforceLevel", "ENFORCE"); PushOneCommit.Result r = createChange("test message", "A/1/foo.c", "void main()\n"); approve(r.getChangeId()); ChangeInfo result = gApi.changes().id(r.getChangeId()).get(); assertThat(result.submittable).isFalse(); } private void createTestRepositoryContent() throws Exception { addFile("init", "OWNERS", "per-file *.c = alice@example.com, bob@example.com\n"); 
<|startcomment|> This is not Gerrit project's code style. I guess that neither of the changed files in this change are formatted with the google-java-format? <|endcomment|>  return pathFor(projectName, ref.getName()); } public static String pathFor(String projectName, String refName) { return "/" + projectName + "/" + refName; } private final CuratorFramework client; public ZkRefInfoDAO(CuratorFramework client) { this.client = client; } public Optional<ZkRefInfo> read(String projectName, String refName) throws Exception { final String rootPath = pathFor(projectName, refName); <|startfocus|> if (!exists(rootPath)) return Optional.empty(); <|endfocus|> final ObjectId objectId = readObjectIdAt(rootPath + "/" + OBJECT_ID_PATH); return Optional.of(new ZkRefInfo(projectName, refName, objectId)); } public void update(ZkRefInfo info) throws Exception { writeInTransaction(info, () -> client.transactionOp().setData()); } public void create(ZkRefInfo info) throws Exception { client.createContainers(pathFor(info)); writeInTransaction(info, () -> client.transactionOp().create().withMode(PERSISTENT)); } private void writeInTransaction(
<|startcomment|> This is difficult to parse. How about something like "All required checks must pass" <|endcomment|> import com.google.gerrit.server.query.change.ChangeData; import com.google.gerrit.server.rules.SubmitRule; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import java.util.Collection; @Singleton public class ChecksSubmitRule implements SubmitRule { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final SubmitRequirement DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS = SubmitRequirement.builder() <|startfocus|> .setFallbackText("Passing all blocking checks required") .setType("passing_all_blocking_checks") <|endfocus|> .build(); public static class Module extends FactoryModule { @Override public void configure() { bind(SubmitRule.class) .annotatedWith(Exports.named("ChecksSubmitRule")) .to(ChecksSubmitRule.class); } } private final Checks checks; @Inject public ChecksSubmitRule(Checks checks) { this.checks = checks; } @Override public Collection<SubmitRecord> evaluate(ChangeData changeData, SubmitRuleOptions options) { Project.NameKey project = changeData.project(); Change.Id changeId = changeData.getId(); 
<|startcomment|> This is also difficult to parse, and perhaps longer than it needs to be. How about "checks_pass" <|endcomment|> import com.google.gerrit.server.rules.SubmitRule; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import java.util.Collection; @Singleton public class ChecksSubmitRule implements SubmitRule { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private static final SubmitRequirement DEFAULT_SUBMIT_REQUIREMENT_FOR_CHECKS = SubmitRequirement.builder() <|startfocus|> .setFallbackText("Passing all blocking checks required") .setType("passing_all_blocking_checks") <|endfocus|> .build(); public static class Module extends FactoryModule { @Override public void configure() { bind(SubmitRule.class) .annotatedWith(Exports.named("ChecksSubmitRule")) .to(ChecksSubmitRule.class); } } private final Checks checks; @Inject public ChecksSubmitRule(Checks checks) { this.checks = checks; } @Override public Collection<SubmitRecord> evaluate(ChangeData changeData, SubmitRuleOptions options) { Project.NameKey project = changeData.project(); Change.Id changeId = changeData.getId(); PatchSet.Id currentPathSetId; try {
<|startcomment|> The body of createChange() already calls assertOkStatus. <|endcomment|> import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.plugins.checks.api.CheckerStatus; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.reviewdb.client.Project; import org.junit.Before; import org.junit.Test; public class ChecksSubmitRuleIT extends AbstractCheckersTest { private String testChangeId; private PatchSet.Id testPatchSetId; private CheckerUuid testCheckerUuid; @Before public void setUp() throws Exception { PushOneCommit.Result result = createChange(); <|startfocus|> result.assertOkStatus(); <|endfocus|> testPatchSetId = result.getPatchSetId(); testChangeId = result.getChangeId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); // Creates a test Checker which is enabled and required for the test repository. testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception {
<|startcomment|> No need to create a new repo for this, just point it at allProjects <|endcomment|>  testCheckerUuid = checkerOperations .newChecker() .repository(project) .blockingConditions(BlockingCondition.STATE_NOT_PASSING) .status(CheckerStatus.ENABLED) .create(); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); // Updates the checker so that it isn't applicable to the change any more. <|startfocus|> Project.NameKey otherRepo = new Project.NameKey("other-project"); gApi.projects().create(otherRepo.get()); checkerOperations.checker(testCheckerUuid).forUpdate().repository(otherRepo).update(); <|endfocus|> gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); } @Test public void disabledCheckerDoesNotBlockingSubmit() throws Exception { postCheckResult(testCheckerUuid, CheckState.FAILED); checkerOperations.checker(testCheckerUuid).forUpdate().disable().update(); gApi.changes().id(testChangeId).current().submit(); assertThat(gApi.changes().id(testChangeId).get().status).isEqualTo(ChangeStatus.MERGED); } 
<|startcomment|> this can be made private <|endcomment|>  } } public static String pathFor(String projectName, Ref ref) { return pathFor(projectName, ref.getName()); } public static String pathFor(String projectName, String refName) { return "/" + projectName + "/" + refName; } public static ObjectId readObjectId(byte[] value) { return ObjectId.fromRaw(value); } <|startfocus|> public static byte[] writeObjectId(ObjectId value) throws IOException { <|endfocus|> final ByteArrayOutputStream out = new ByteArrayOutputStream(); final DataOutputStream stream = new DataOutputStream(out); value.copyRawTo(stream); return out.toByteArray(); } } 
<|startcomment|> We now use use google-java-format version 1.7 for formatting. <|endcomment|>  ListChecks( CheckBackfiller checkBackfiller, CheckJson.Factory checkJsonFactory, Checkers checkers, Checks checks) { this.checkBackfiller = checkBackfiller; this.checkJsonFactory = checkJsonFactory; this.checkers = checkers; this.checks = checks; } @Override public ImmutableList<CheckInfo> apply(RevisionResource resource) throws AuthException, BadRequestException, ResourceConflictException, OrmException, IOException { CheckJson checkJson = checkJsonFactory.create(options); Map<CheckerUuid, Checker> checkersByUuid = <|startfocus|> checkers .checkersOf(resource.getProject()) .stream() <|endfocus|> .collect(toMap(Checker::getUuid, c -> c)); ImmutableList.Builder<CheckInfo> result = ImmutableList.builderWithExpectedSize(checkersByUuid.size()); for (Check check : checks.getChecks(resource.getProject(), resource.getPatchSet().getId())) { checkersByUuid.remove(check.key().checkerUuid()); result.add(checkJson.format(check)); } for (Check check : checkBackfiller.getBackfilledChecksForRelevantCheckers( checkersByUuid.values(), resource.getNotes(), resource.getPatchSet().getId())) {
<|startcomment|> I don't see why this added complexity is necessary. For submit rules, just allow SUCCESSFUL, WARNING, or NOT_RELEVANT. <|endcomment|>  * not exist. */ Optional<Check> getCheck(CheckKey checkKey) throws OrmException, IOException; @AutoValue abstract class GetChecksOptions { /** Backfills checks for relevant checkers with default when they don't exist yet. */ public abstract boolean backfillChecks(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_Checks_GetChecksOptions.Builder().setBackfillChecks(false); } public static GetChecksOptions defaults() { return builder().build(); } <|startfocus|> @AutoValue.Builder public abstract static class Builder { public abstract Builder setBackfillChecks(boolean backfillChecks); public abstract GetChecksOptions build(); } <|endfocus|> } } 
<|startcomment|> We need to think a bit deeper about this compareAndPut signature. If a normal change is pushed, then I think the logic holds: the reference will be refs/heads/somebranch and zookeper can coordinate access to it. However, in case of a magic change, the reference will be always `refs/for/master`, for all changes, regardless they are, in fact different changes. Targed information is possible not enough for zookeper to coordinate this particular change, since _all_ changes for master, will share the same magic reference. I think a way for zookeper to discriminate one change from another would be to have access to the change-id, perhaps we can do some more thinking on how to achieve this. <|endcomment|>  private final CuratorFramework client; private final RetryPolicy retryPolicy; @Inject public ZkSharedRefDatabase( CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { final DistributedAtomicValue distributedRefValue = <|startfocus|> new DistributedAtomicValue(client, pathFor(projectName, oldRef), retryPolicy); <|endfocus|> try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } else { final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet( writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); }
<|startcomment|> It seems this is not going to work in the case where oldRef == NULL_REF, as zookeeper will keep generating the same path (specifically `repository/null`), for all these changes which will keep clobbering each other. <|endcomment|>  @Inject public ZkSharedRefDatabase( CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { final DistributedAtomicValue distributedRefValue = <|startfocus|> new DistributedAtomicValue(client, pathFor(projectName, oldRef), retryPolicy); <|endfocus|> try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } else { final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet( writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); } } catch (Exception e) { logger.atWarning().withCause(e).log(
<|startcomment|> @Inject <|endcomment|> import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.server.config.AllProjectsName; import org.junit.Before; import org.junit.Test; /** * TODO(xchangcheng): add more tests after figuring out the expecting behavior of {@code * CombinedCheckState}. */ public class ChecksSubmitRuleIT extends AbstractCheckersTest { private static final SubmitRequirementInfo SUBMIT_REQUIREMENT_INFO = new SubmitRequirementInfo( "NOT_READY", "All required checks must pass", "checks_pass", ImmutableMap.of()); <|startfocus|> private AllProjectsName allProjects; <|endfocus|> private String testChangeId; private PatchSet.Id testPatchSetId; @Before public void setUp() throws Exception { allProjects = plugin.getSysInjector().getInstance(AllProjectsName.class); PushOneCommit.Result result = createChange(); testPatchSetId = result.getPatchSetId(); testChangeId = result.getChangeId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception {
<|startcomment|> You only need to do this for types which are bound in the plugin modules, not for core Gerrit classes. <|endcomment|>  * CombinedCheckState}. */ public class ChecksSubmitRuleIT extends AbstractCheckersTest { private static final SubmitRequirementInfo SUBMIT_REQUIREMENT_INFO = new SubmitRequirementInfo( "NOT_READY", "All required checks must pass", "checks_pass", ImmutableMap.of()); private AllProjectsName allProjects; private String testChangeId; private PatchSet.Id testPatchSetId; @Before public void setUp() throws Exception { <|startfocus|> allProjects = plugin.getSysInjector().getInstance(AllProjectsName.class); <|endfocus|> PushOneCommit.Result result = createChange(); testPatchSetId = result.getPatchSetId(); testChangeId = result.getChangeId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); // Updates the checker so that it isn't applicable to the change any more. checkerOperations.checker(checkerUuid).forUpdate().repository(allProjects).update(); 
<|startcomment|> I would like to avoid adding this utility method to AbstractCheckersTest. We very much do not want AbstractCheckersTest to turn into AbstractDaemonTest, with dozens of protected methods and no rhyme or reason. Either add this just in the IT where you need it, or modify the CheckerOperations interface to make this operation simpler. <|endcomment|>  } @Before public void setUpCheckersPlugin() throws Exception { checkerOperations = plugin.getSysInjector().getInstance(CheckerOperations.class); checkOperations = plugin.getSysInjector().getInstance(CheckOperations.class); checkersApi = plugin.getHttpInjector().getInstance(Checkers.class); checksApiFactory = plugin.getHttpInjector().getInstance(ChecksFactory.class); pendingChecksApi = plugin.getHttpInjector().getInstance(PendingChecks.class); allowGlobalCapabilities(group("Administrators").getGroupUUID(), "checks-administrateCheckers"); } <|startfocus|> protected TestCheckerCreation.Builder newRequiredChecker() { return checkerOperations .newChecker() .repository(project) .status(CheckerStatus.ENABLED) .blockingConditions(BlockingCondition.STATE_NOT_PASSING); } <|endfocus|> } 
<|startcomment|> This seems like a bug that needs to be understood and fixed before submitting this change. If there is a checker that is not required and we don't update the check state for it, it really needs to not block submission. Why do other tests not exhibit this behavior? Is this problem reproducible in a test, using a repo other than All-Projects? <|endcomment|>  fetch(repo, checkerRef + ":checkerRef"); repo.reset("checkerRef"); grant(allProjects, CheckerRef.REFS_CHECKERS + "*", Permission.PUSH); PushOneCommit.Result r = pushFactory.create(admin.getIdent(), repo).to(checkerRef); r.assertErrorStatus(); r.assertMessage("direct update of checker ref not allowed"); } @Test public void submitToCheckerRefsIsDisabled() throws Exception { <|startfocus|> // TODO(xchangcheng): remove the "disable" after figuring out the expecting behavior of // CombinedCheckState. Currently, this **not-required** checker is blocking submission but // it shouldn't. <|endfocus|> CheckerUuid checkerUuid = checkerOperations.newChecker().status(CheckerStatus.DISABLED).create(); String checkerRef = checkerUuid.toRefName(); String changeId = createChangeWithoutCommitValidation(checkerRef); grantLabel( "Code-Review", -2, 2, allProjects, CheckerRef.REFS_CHECKERS + "*", false, adminGroupUuid(), false); approve(changeId); grant(allProjects, CheckerRef.REFS_CHECKERS + "*", Permission.SUBMIT); exception.expect(ResourceConflictException.class);
<|startcomment|> @Inject private AllProjectsName allProjects <|endcomment|>  testChangeId = result.getChangeId(); // Approves "Code-Review" label so that the change only needs to meet the submit requirements // about checks. approve(testChangeId); } @Test public void nonApplicableCheckerNotBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); // Updates the checker so that it isn't applicable to the change any more. <|startfocus|> Project.NameKey otherRepo = new Project.NameKey("All-Projects"); checkerOperations.checker(checkerUuid).forUpdate().repository(otherRepo).update(); <|endfocus|> ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); } @Test public void disabledCheckerDoesNotBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); checkerOperations.checker(checkerUuid).forUpdate().disable().update(); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); } // @Test
<|startcomment|> assertThat(changeInfo.requirements).isEmpty(); <|endcomment|>  checkerOperations.checker(checkerUuid).forUpdate().repository(otherRepo).update(); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); } @Test public void disabledCheckerDoesNotBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); checkerOperations.checker(checkerUuid).forUpdate().disable().update(); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); <|startfocus|> assertThat(changeInfo.submittable).isTrue(); <|endfocus|> } // @Test // public void enabledCheckerNotBlockingSubmitIfNotRequired() throws Exception { // CheckerUuid checkerUuid = newRequiredChecker().create(); // postCheckResult(checkerUuid, CheckState.FAILED); // checkerOperations // .checker(checkerUuid) // .forUpdate() // .blockingConditions(ImmutableSortedSet.of()) // .update(); // // ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); // // assertThat(changeInfo.submittable).isTrue(); // } @Test
<|startcomment|> assertThat(changeInfo.requirements).containsExactly(...) <|endcomment|>  CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.SUCCESSFUL); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isTrue(); } @Test public void enabledCheckerBlockingSubmitIfInBlockingState() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.FAILED); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); <|startfocus|> assertThat(changeInfo.submittable).isFalse(); <|endfocus|> } @Test public void multipleCheckerBlockingSubmit() throws Exception { CheckerUuid checkerUuid = newRequiredChecker().create(); // Two enabled and required checkers. They are blocking if any of them isn't passing. CheckerUuid testCheckerUuid2 = newRequiredChecker().create(); postCheckResult(checkerUuid, CheckState.SUCCESSFUL); postCheckResult(testCheckerUuid2, CheckState.FAILED); ChangeInfo changeInfo = gApi.changes().id(testChangeId).get(); assertThat(changeInfo.submittable).isFalse(); } // @Test // public void multipleCheckerNotBlockingSubmit() throws Exception {
<|startcomment|> We should not force the notedb mode, but just honor the one that is currently used. <|endcomment|>  return Collections.emptyList(); } public int getCount() { return count; } public void reset() { count = 0; } } @Override public Module createModule() { return new AbstractModule() { @Override protected void configure() { testRefOperationListener = new TestRefOperationValidationListener(); DynamicSet.bind(binder(), RefOperationValidationListener.class) .toInstance(testRefOperationListener); } }; } <|startfocus|> static { System.setProperty("gerrit.notedb", "ON"); <|endfocus|> } @After public void cleanup() { testRefOperationListener.reset(); } @Test public void aNormalPushShouldTriggerARefOperationValidation() throws Exception { PushOneCommit.Result r = createCommitAndPush(testRepo, "refs/heads/master", "msg", "file", "content"); assertThat(testRefOperationListener.getCount()).isEqualTo(1); } @Test public void aMagicRefUpdateShouldTriggerARefOperationValidationOnChangesBranch() throws Exception { PushOneCommit.Result r = createChange("refs/for/master"); 
<|startcomment|> Without looking at the implementation, I was not sure what this method is doing, especially since line 130 already contains a "queryMatchingChangesFor" method with a checker as input. Would "getPostFilteredPendingChecks" (or something similar without "matching") also work for you? <|endcomment|>  String.format("checker %s not found", checkerUuid))); if (checker.getStatus() == CheckerStatus.DISABLED) { return ImmutableList.of(); } // The query system can only match against the current patch set; ignore non-current patch sets // for now. List<ChangeData> changes = queryMatchingChangesFor(checker); List<PendingChecksInfo> pendingChecks = new ArrayList<>(changes.size()); for (ChangeData cd : changes) { <|startfocus|> getMatchingPendingChecks(cd.project(), cd.currentPatchSet().getId()) <|endfocus|> .ifPresent(pendingChecks::add); } return pendingChecks; } private List<ChangeData> queryMatchingChangesFor(Checker checker) throws ConfigInvalidException, OrmException { Predicate<ChangeData> predicate = new ProjectPredicate(checker.getRepository().get()); if (checker.getQuery().isPresent()) { String query = checker.getQuery().get(); try { predicate = Predicate.and(predicate, queryBuilderProvider.get().parse(query)); } catch (QueryParseException e) { logger.atWarning().withCause(e).log(
<|startcomment|> Here and above: The new, better way of doing this is check("pendingChecks()").that(pendingChecks).isNotNull(); This new approach has the benefit that it retains the FailureStrategy and can lead to a more helpful failure message (e.g. combines 'name' parts for a several chained subjects and hence provides more context). We are using the pattern of Truth.assertThat(..) everywhere else in custom Truth subjects as the check() method didn't exist in the past. I'll try to migrate those occurrences. <|endcomment|>  CheckablePatchSetInfo patchSet = actual().patchSet; <|startfocus|> Truth.assertThat(patchSet).named("patch set").isNotNull(); <|endfocus|> return patchSet; } 
<|startcomment|> Should this be DynamicSet.bind(binder(), ChangeCheckAttributeFactory.class) now? <|endcomment|>  install(new NoteDbCheckersModule()); bind(CapabilityDefinition.class) .annotatedWith(Exports.named(AdministrateCheckersCapability.NAME)) .to(AdministrateCheckersCapability.class); DynamicSet.bind(binder(), CommitValidationListener.class) .to(CheckerCommitValidator.class) .in(SINGLETON); DynamicSet.bind(binder(), MergeValidationListener.class) .to(CheckerMergeValidator.class) .in(SINGLETON); DynamicSet.bind(binder(), RefOperationValidationListener.class) .to(CheckerRefOperationValidator.class) .in(SINGLETON); <|startfocus|> bind(ChangeAttributeFactory.class) .annotatedWith(Exports.named("checks")) <|endfocus|> .to(ChangeCheckAttributeFactory.class); bind(DynamicOptions.DynamicBean.class) .annotatedWith(Exports.named(GetChange.class)) .to(GetChangeOptions.class); install(new ApiModule());
<|startcomment|> Optional: you could add another test with something like: assertThat(BlockingCondition.values()).containsExactly(STATE_NOT_PASSING); That way if someone forgets to adapt the implementation of isRequired when adding a new BlockingCondition, we will find out early due to a test failure, rather than at runtime with an ISE. <|endcomment|> import org.eclipse.jgit.lib.ObjectId; import org.junit.Test; public class CheckerDefinitionTest { @Test public void notRequiredIfNoBlockingCondition() { Checker checker = newChecker().setBlockingConditions(ImmutableSortedSet.of()).build(); assertThat(checker.isRequired()).isFalse(); } @Test public void requiredIfHasBlockingConditionStateNotPassing() { Checker checker = newChecker().setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)).build(); assertThat(checker.isRequired()).isTrue(); } <|startfocus|> <|endfocus|> private Checker.Builder newChecker() { return Checker.builder() .setRepository(new NameKey("test-repo")) .setStatus(CheckerStatus.ENABLED) .setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)) .setUuid(CheckerUuid.parse("schema:any-id")) .setCreatedOn(TimeUtil.nowTs()) .setUpdatedOn(TimeUtil.nowTs()) .setRefState(ObjectId.zeroId()); } } 
<|startcomment|> You can remove this, it's always overridden in test methods. <|endcomment|>  assertThat(checker.isRequired()).isFalse(); } @Test public void requiredIfHasBlockingConditionStateNotPassing() { Checker checker = newChecker().setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)).build(); assertThat(checker.isRequired()).isTrue(); } private Checker.Builder newChecker() { return Checker.builder() .setRepository(new NameKey("test-repo")) .setStatus(CheckerStatus.ENABLED) <|startfocus|> .setBlockingConditions(ImmutableSortedSet.of(STATE_NOT_PASSING)) <|endfocus|> .setUuid(CheckerUuid.parse("schema:any-id")) .setCreatedOn(TimeUtil.nowTs()) .setUpdatedOn(TimeUtil.nowTs()) .setRefState(ObjectId.zeroId()); } } 
<|startcomment|> Do we have a test which ensures that we don't do too many writes? <|endcomment|>  * * @param project project containing the change. * @param psId patch set to which the state corresponds. * @return combined check state. */ public CombinedCheckState reload(Project.NameKey project, PatchSet.Id psId) throws OrmException { CombinedCheckStateCacheKeyProto key = key(project, psId); CombinedCheckState newState = loader.load(key); CombinedCheckState oldState = cache.getIfPresent(key); if (newState != oldState) { cache.put(key, newState); } <|startfocus|> return newState; <|endfocus|> } /** * Directly put a state into the cache. * * @param project project containing the change. * @param psId patch set to which the state corresponds. * @param state combined check state. */ @VisibleForTesting public void putForTest(Project.NameKey project, PatchSet.Id psId, CombinedCheckState state) { cache.put(key(project, psId), state); } @VisibleForTesting public CacheStats getStats() { return cache.stats(); } 
<|startcomment|> Optional: opts can never be null as line 56 would already catch it. <|endcomment|>  } throw new IllegalStateException("unexpected options type: " + opts); } private ChangeCheckInfo forGetChange(ChangeData cd, GetChangeOptions opts) throws OrmException { if (opts == null || !opts.combined) { return null; } return new ChangeCheckInfo( combinedCheckStateCache.reload(cd.project(), cd.change().currentPatchSetId())); } private ChangeCheckInfo forQueryChanges(ChangeData cd, QueryChangesOptions opts) throws OrmException { <|startfocus|> if (opts == null || !opts.combined) { <|endfocus|> return null; } return new ChangeCheckInfo( combinedCheckStateCache.get(cd.project(), cd.change().currentPatchSetId())); } } 
<|startcomment|> Do you think that this is fast enough (even for a high rate of updates), so that 1) we can do in synchronously as currently and that 2) we always recompute the combined state from scratch? (Alternatively, we could compare the state of the check with the old combined check state and only do the reload if something would change.) <|endcomment|>  RefUpdate refUpdate = repo.updateRef(refName); refUpdate.setExpectedOldObjectId(parent); refUpdate.setNewObjectId(newCommitId); refUpdate.setRefLogIdent(personIdent); refUpdate.setRefLogMessage(message, false); refUpdate.update(); RefUpdateUtil.checkResult(refUpdate); try { combinedCheckStateCache.reload(checkKey.project(), checkKey.patchSet()); } catch (OrmException e) { logger.atWarning().withCause(e).log("failed to reload CombinedCheckState for %s", checkKey); } gitRefUpdated.fire( <|startfocus|> checkKey.project(), refUpdate, currentUser.map(user -> user.state()).orElse(null)); <|endfocus|> return readSingleCheck(checkKey, repo, rw, newCommitId); } } private void assertCheckerIsPresent(CheckerUuid checkerUuid) throws ConfigInvalidException, IOException { checkers.getChecker(checkerUuid).orElseThrow(() -> new IOException(checkerUuid + " missing")); } private boolean updateNotesMap( CheckKey checkKey, CheckUpdate checkUpdate, Repository repo, RevWalk rw, ObjectInserter ins, ObjectId curr,
<|startcomment|> Updates <|endcomment|>  stats = cache.getStats().minus(start); // Incurs a cache hit during read-then-write. assertThat(stats.hitCount()).isEqualTo(2); assertThat(stats.missCount()).isEqualTo(0); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.NOT_RELEVANT)); stats = cache.getStats().minus(start); assertThat(stats.hitCount()).isEqualTo(3); assertThat(stats.missCount()).isEqualTo(0); } @Test <|startfocus|> public void updatingCheckStateUpatesCache() throws Exception { <|endfocus|> CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); cache.putForTest(project, psId, CombinedCheckState.IN_PROGRESS); CacheStats start = clone(cache.getStats()); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.IN_PROGRESS)); CacheStats stats = cache.getStats().minus(start); assertThat(stats.hitCount()).isEqualTo(1); assertThat(stats.missCount()).isEqualTo(0); // Set non-required checker to FAILED, updating combined check state to WARNING.
<|startcomment|> Format as a proper Javadoc: - headline - body - return value config <|endcomment|>  long expiresAt, String sessionId, String auth) { this.accountId = accountId; this.refreshCookieAt = refreshCookieAt; this.persistentCookie = persistentCookie; this.externalId = externalId; this.expiresAt = expiresAt; this.sessionId = sessionId; this.auth = auth; } public long getExpiresAt() { return expiresAt; } /** * This is public so that plugins that implement a web session, <|startfocus|> * can also implement a way to clear per user sessions. <|endfocus|> */ public Account.Id getAccountId() { return accountId; } ExternalId.Key getExternalId() { return externalId; } String getSessionId() { return sessionId; } String getAuth() { return auth; } boolean needsCookieRefresh() { return refreshCookieAt <= nowMs(); } boolean isPersistentCookie() { return persistentCookie; } private void writeObject(ObjectOutputStream out) throws IOException { writeVarInt32(out, 1);
<|startcomment|> Just comment out this method (JavaDoc) and specify the way that it could be used. Otherwise, it would risk to be put as private again because it won't be accessible anyway. <|endcomment|>  private transient String auth; Val( Account.Id accountId, long refreshCookieAt, boolean persistentCookie, ExternalId.Key externalId, long expiresAt, String sessionId, String auth) { this.accountId = accountId; this.refreshCookieAt = refreshCookieAt; this.persistentCookie = persistentCookie; this.externalId = externalId; this.expiresAt = expiresAt; this.sessionId = sessionId; this.auth = auth; } public long getExpiresAt() { return expiresAt; } <|startfocus|> <|endfocus|> public Account.Id getAccountId() { return accountId; } ExternalId.Key getExternalId() { return externalId; } String getSessionId() { return sessionId; } String getAuth() { return auth; } boolean needsCookieRefresh() { return refreshCookieAt <= nowMs(); } boolean isPersistentCookie() { return persistentCookie; } private void writeObject(ObjectOutputStream out) throws IOException { writeVarInt32(out, 1); writeVarInt32(out, accountId.get()); 
<|startcomment|> Validation module should not have any direct references to Zookeeper. <|endcomment|> // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation; import com.google.gerrit.extensions.registration.DynamicSet; import com.google.gerrit.server.git.validators.RefOperationValidationListener; import com.google.inject.AbstractModule; import com.google.inject.name.Names; import com.googlesource.gerrit.plugins.multisite.Configuration; import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.SharedRefDatabase; <|startfocus|> import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper.ZkSharedRefDatabase; import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; <|endfocus|> public class ValidationModule extends AbstractModule { private Configuration cfg; public ValidationModule(Configuration cfg) { this.cfg = cfg; } @Override protected void configure() { DynamicSet.bind(binder(), RefOperationValidationListener.class).to(InSyncChangeValidator.class); bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class); bind(CuratorFramework.class).toInstance(cfg.getSplitBrain().getZookeeper().buildCurator()); bind(RetryPolicy.class) .annotatedWith(Names.named("ZkLockRetryPolicy"))
<|startcomment|> This is wrong: the new ref in zookeeper should be written by the ZkSharedRefDatabase and not by the test itself. The test passes only because the test is testing itself, rather than verifying that the code works, which isn't the case, because it is broken :-( Fixing it now. <|endcomment|>  ZookeeperTestContainerSupport zookeeperContainer; ZkSharedRefDatabase zkSharedRefDatabase; @Before public void setup() { zookeeperContainer = new ZookeeperTestContainerSupport(); zkSharedRefDatabase = new ZkSharedRefDatabase(zookeeperContainer.getCurator(), new RetryNTimes(5, 30)); } @After public void cleanup() { zookeeperContainer.cleanup(); } @Test public void shouldCompareAndCreateSuccessfully() throws Exception { Ref ref = refOf(AN_OBJECT_ID_1); <|startfocus|> zookeeperContainer.createRefInZk(A_TEST_PROJECT_NAME, ref); <|endfocus|> assertThat(zkSharedRefDatabase.compareAndCreate(A_TEST_PROJECT_NAME, ref)).isTrue(); assertThat(zookeeperContainer.readRefValueFromZk(A_TEST_PROJECT_NAME, ref)) .isEqualTo(ref.getObjectId()); } @Test public void shouldCompareAndPutSuccessfully() throws Exception { Ref oldRef = refOf(AN_OBJECT_ID_1); Ref newRef = refOf(AN_OBJECT_ID_2); String projectName = A_TEST_PROJECT_NAME; zookeeperContainer.createRefInZk(projectName, oldRef); 
<|startcomment|> Optional; here and above: Doing the assertion on the complete message is a bit fragile. Could we assert only on parts of the message (e.g. that it contains 'unsupported' irrespective of case and possibly the violating operator)? Example: assertInvalidQuery(CheckerTestData.INVALID_QUERY, "invalid", CheckerTestData.INVALID_QUERY); <other lines> for (String part : expectedMessageParts) { assertThat(e).hasMessageThat().ignoringCase().contains(part); } <|endcomment|>  private static void assertInvalidQuery(String query, String expectedMessage) { try { CheckerQuery.clean(query); assert_().fail("expected BadRequestException"); } catch (BadRequestException e) { <|startfocus|> assertThat(e).hasMessageThat().isEqualTo(expectedMessage); <|endfocus|> }
<|startcomment|> here and below In Alice's change that starts using the check methods [1] the names are always without the 'get' prefix. Should we be consistent and change it to 'type()' here? [1] https://gerrit-review.googlesource.com/c/gerrit/+/218745 <|endcomment|>  public void hasType(int expectedType) { isNotNull(); <|startfocus|> int actualType = actual().getType(); check("getType()") .that(actualType) .named("expected %s, actual %s", typeName(expectedType), typeName(actualType)) .isEqualTo(expectedType); <|endfocus|>
<|startcomment|> ChangeData is a pretty heavyweight dependency, can this just take a Project.NameKey? <|endcomment|> <|startfocus|> public static Check newBackfilledCheck(ChangeData cd, PatchSet ps, Checker checker) { return Check.builder(CheckKey.create(cd.project(), ps.getId(), checker.getUuid())) <|endfocus|> .setState(CheckState.NOT_STARTED) .setCreated(ps.getCreatedOn()) .setUpdated(ps.getCreatedOn()) .build();
<|startcomment|> Nit: reflow lines. <|endcomment|>  } if (checkerUuid == null) { throw new BadRequestException("checker UUID is required"); } Checker checker = checkers .getChecker(checkerUuid) .orElseThrow( () -> new UnprocessableEntityException( String.format("checker %s not found", checkerUuid))); if (checker.getStatus() == CheckerStatus.DISABLED) { return ImmutableList.of(); } // The query system can only match against the current patch set; ignore non-current patch sets // for now. List<ChangeData> changes = <|startfocus|> checker.queryMatchingChanges(retryHelper, queryBuilderProvider.get(), changeQueryProvider); <|endfocus|> List<PendingChecksInfo> pendingChecks = new ArrayList<>(changes.size()); for (ChangeData cd : changes) { getPostFilteredPendingChecks(cd.project(), cd.currentPatchSet().getId()) .ifPresent(pendingChecks::add); } return pendingChecks; } private Optional<PendingChecksInfo> getPostFilteredPendingChecks( Project.NameKey project, PatchSet.Id patchSetId) throws OrmException, IOException { CheckState checkState = getCheckState(project, patchSetId);
<|startcomment|> I would expect this to match the semantics for ChangeStatusPredicate. Ok, maybe we don't need to do the prefix tree thing, but at the very least support lowercase values. <|endcomment|> // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.plugins.checks.index; import static com.google.common.base.Preconditions.checkNotNull; import com.google.gerrit.index.query.QueryParseException; import com.google.gerrit.plugins.checks.Check; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gwtorm.server.OrmException; public class CheckStatePredicate extends CheckPredicate { public static CheckStatePredicate parse(String value) throws QueryParseException { return new CheckStatePredicate( <|startfocus|> CheckState.tryParse(value) <|endfocus|> .orElseThrow( () -> new QueryParseException(String.format("invalid check state: %s", value)))); } private final CheckState checkState; public CheckStatePredicate(CheckState checkState) { super(CheckQueryBuilder.FIELD_STATE, checkState.name()); this.checkState = checkNotNull(checkState, "checkState"); } @Override public boolean match(Check check) throws OrmException { return checkState.equals(check.state()); } } 
<|startcomment|> requireNonNull <|endcomment|>  public CheckerPredicate(CheckerUuid checkerUuid) { super(CheckQueryBuilder.FIELD_CHECKER, checkerUuid.toString()); <|startfocus|> this.checkerUuid = checkNotNull(checkerUuid, "checkerUuid"); <|endfocus|>
<|startcomment|> Should this variable be renamed now, since it is no longer matched against the request URI? <|endcomment|>  boolean isRest(ServletRequest req) { return req instanceof HttpServletRequest <|startfocus|> && resturi.matcher(((HttpServletRequest) req).getServletPath()).matches(); <|endfocus|>
<|startcomment|> Same here <|endcomment|>  public void containsMessages(String... expectedLines) { checkArgument(expectedLines.length > 0, "use hasNoMessages()"); isNotNull(); Iterable<String> got = Splitter.on("\n").split(trimMessages()); <|startfocus|> check("trimmedMessages()").that(got).containsAllIn(expectedLines).inOrder(); <|endfocus|>
<|startcomment|> Check that the commit didn't change? <|endcomment|>  } @Test public void insertCheckerTwice() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); CheckerUuid checkerUuid = CheckerUuid.parse("foo:bar"); Project.NameKey project = new Project.NameKey("some-project"); checkersByRepositoryNotes.insert(checkerUuid, project); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project)).containsExactly(checkerUuid); checkersByRepositoryNotes.insert(checkerUuid, project); commit(checkersByRepositoryNotes); <|startfocus|> assertThat(checkersByRepositoryNotes.get(project)).containsExactly(checkerUuid); <|endfocus|> } @Test public void removeCheckers() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); Project.NameKey project = new Project.NameKey("some-project"); CheckerUuid checkerUuid1 = CheckerUuid.parse("bar:baz"); CheckerUuid checkerUuid2 = CheckerUuid.parse("foo:bar"); CheckerUuid checkerUuid3 = CheckerUuid.parse("foo:baz"); checkersByRepositoryNotes.insert(checkerUuid1, project); checkersByRepositoryNotes.insert(checkerUuid2, project); checkersByRepositoryNotes.insert(checkerUuid3, project); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project))
<|startcomment|> Check that commit didn't change? <|endcomment|>  CheckerUuid checkerUuid2 = CheckerUuid.parse("foo:baz"); checkersByRepositoryNotes.insert(checkerUuid1, project1); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project1)).containsExactly(checkerUuid1); assertThat(checkersByRepositoryNotes.get(project2)).isEmpty(); checkersByRepositoryNotes.remove(checkerUuid2, project1); checkersByRepositoryNotes.remove(checkerUuid1, project2); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project1)).containsExactly(checkerUuid1); <|startfocus|> assertThat(checkersByRepositoryNotes.get(project2)).isEmpty(); <|endfocus|> } @Test public void updateCheckers() throws Exception { CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); Project.NameKey project1 = new Project.NameKey("some-project"); Project.NameKey project2 = new Project.NameKey("other-project"); CheckerUuid checkerUuid1 = CheckerUuid.parse("foo:bar"); CheckerUuid checkerUuid2 = CheckerUuid.parse("foo:baz"); checkersByRepositoryNotes.insert(checkerUuid1, project1); checkersByRepositoryNotes.insert(checkerUuid2, project1); commit(checkersByRepositoryNotes); assertThat(checkersByRepositoryNotes.get(project1))
<|startcomment|> See above; I'm not convinced this makes sense as a standalone test rather than just adding an assertion to the tests that are already testing no-op behavior. If you remove this, you would need to add a separate test for a no-op update. <|endcomment|>  CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); CheckerUuid checkerUuid = CheckerUuid.parse("foo:bar"); Project.NameKey project = new Project.NameKey("some-project"); checkersByRepositoryNotes.insert(checkerUuid, project); commit(checkersByRepositoryNotes); assertThatCommitMessage() .isEqualTo( "Update checkers by repository\n\nChecker: " + checkerUuid.toString() + "\nRepository: " + project.get()); } @Test <|startfocus|> public void noNewCommitOnNoOp() throws Exception { <|endfocus|> CheckersByRepositoryNotes checkersByRepositoryNotes = loadCheckersByRepositoryNotes(); Project.NameKey project = new Project.NameKey("some-project"); CheckerUuid checkerUuid1 = CheckerUuid.parse("foo:bar"); checkersByRepositoryNotes.insert(checkerUuid1, project); commit(checkersByRepositoryNotes); ObjectId commitId = getRefsMetaCheckersState(); checkersByRepositoryNotes.insert(checkerUuid1, project); commit(checkersByRepositoryNotes); assertThat(getRefsMetaCheckersState()).isEqualTo(commitId); checkersByRepositoryNotes.update(checkerUuid1, project, project); commit(checkersByRepositoryNotes); assertThat(getRefsMetaCheckersState()).isEqualTo(commitId); 
<|startcomment|> atWarning <|endcomment|>  List<SQLEntry> entries = new ArrayList<>(); for (Entry<String, Collection<SQLEntry>> entry : eventsDb.getEvents(query).asMap().entrySet()) { String projectName = entry.getKey(); try { permissionBackend .currentUser() .project(new Project.NameKey(projectName)) .check(ProjectPermission.ACCESS); entries.addAll(entry.getValue()); } catch (AuthException e) { // Ignore } catch (PermissionBackendException e) { <|startfocus|> log.atFine().withCause(e).log("Cannot check project access permission"); <|endfocus|> } } return entries.stream().sorted().map(SQLEntry::getEvent).collect(toList()); } /** * {@inheritDoc} If storing the event fails due to a connection problem, storage will be * re-attempted as specified in gerrit.config. After failing the maximum amount of times, the * event will be stored in a local h2 database. */ @Override public void storeEvent(ProjectEvent event) { Project.NameKey projectName = event.getProjectNameKey();
<|startcomment|> final? <|endcomment|>  } } }.doFilter(req, res); } } private final ListMultimap<GitilesView.Type, Filter> filters = LinkedListMultimap.create(); private final Map<GitilesView.Type, HttpServlet> servlets = Maps.newHashMap(); private Config config; private Renderer renderer; private GitilesUrls urls; private Linkifier linkifier; private GitilesAccess.Factory accessFactory; private RepositoryResolver<HttpServletRequest> resolver; private VisibilityCache visibilityCache; private TimeCache timeCache; private BlameCache blameCache; private GitwebRedirectFilter gitwebRedirect; <|startfocus|> private Filter errorHandler; <|endfocus|> private boolean initialized; GitilesFilter() {} GitilesFilter( Config config, Renderer renderer, GitilesUrls urls, GitilesAccess.Factory accessFactory, final RepositoryResolver<HttpServletRequest> resolver, VisibilityCache visibilityCache, TimeCache timeCache, BlameCache blameCache, GitwebRedirectFilter gitwebRedirect, Filter errorHandler) { this.config = checkNotNull(config, "config"); this.renderer = renderer; this.urls = urls; this.accessFactory = accessFactory; this.visibilityCache = visibilityCache; this.timeCache = timeCache;
<|startcomment|> Gerrit's equivalent of this is RestApiException, which has subclasses for each HTTP code. What do you think of that approach? Please also add a few words of comparison to ServiceMayNotContinueException. <|endcomment|> kage com.google.gitiles; import javax.annotation.Nullable; import javax.servlet.http.HttpServletResponse; /** Indicates the request should be failed. */ <|startfocus|> public class RequestFailureException extends RuntimeException { <|endfocus|> private final FailureReason reason; private String publicErrorMessage = null; public RequestFailureException(FailureReason reason) { super(); this.reason = reason; } public RequestFailureException(FailureReason reason, Throwable cause) { super(cause); this.reason = reason; } public RequestFailureException withPublicErrorMessage(String format, Object... params) { this.publicErrorMessage = String.format(format, params); return this; } public FailureReason getReason() { return reason; } @Nullable public String getPublicErrorMessage() { return publicErrorMessage; } /** The request failure reason. */ public enum FailureReason { AMBIGUOUS_OBJECT(HttpServletResponse.SC_BAD_REQUEST), BLAME_REGION_NOT_FOUND(HttpServletResponse.SC_NOT_FOUND), CANNOT_PARSE_GITILES_VIEW(HttpServletResponse.SC_NOT_FOUND), INCORECT_PARAMETER(HttpServletResponse.SC_BAD_REQUEST), INCORRECT_OBJECT_TYPE(HttpServletResponse.SC_NOT_FOUND),
<|startcomment|> Why is this injected also? You would risk a circular dependency with MultiSiteGitRepositoryManager. What is the expected implementation of it? <|endcomment|>  public MultiSiteGitRepositoryManager( <|startfocus|> MultiSiteRepository.Factory multiSiteRepoFactory, GitRepositoryManager gitRepositoryManager) { <|endfocus|> this.gitRepositoryManager = gitRepositoryManager; this.multiSiteRepoFactory = multiSiteRepoFactory;
<|startcomment|> This is not a DynamicSet but a simple Guice binding <|endcomment|>  protected void configure() { factory(MultiSiteRepository.Factory.class); factory(MultiSiteRefDatabase.Factory.class); factory(MultiSiteRefUpdate.Factory.class); <|startfocus|> DynamicSet.bind(binder(), GitRepositoryManager.class).to(MultiSiteGitRepositoryManager.class); DynamicSet.bind(binder(), SharedRefDatabase.class).to(ZkSharedRefDatabase.class); <|endfocus|> install(new ZkValidationModule(cfg));
<|startcomment|> This should be in a zookeeper-specific module <|endcomment|>  protected void configure() { factory(MultiSiteRepository.Factory.class); factory(MultiSiteRefDatabase.Factory.class); factory(MultiSiteRefUpdate.Factory.class); <|startfocus|> DynamicSet.bind(binder(), GitRepositoryManager.class).to(MultiSiteGitRepositoryManager.class); DynamicSet.bind(binder(), SharedRefDatabase.class).to(ZkSharedRefDatabase.class); <|endfocus|> install(new ZkValidationModule(cfg));
<|startcomment|> Use A_TEST_PROJECT_NAME from RefFixture for all "ProjectName" strings in this file. <|endcomment|>  doReturn(oldRef).when(refUpdate).getRef(); doReturn("refs/heads/master").when(refUpdate).getName(); doReturn(AN_OBJECT_ID_2).when(refUpdate).getNewObjectId(); doReturn(newRef).when(sharedRefDb).newRef("refs/heads/master", AN_OBJECT_ID_2); } @Test public void newUpdateShouldValidateAndSucceed() throws IOException { setMockRequiredReturnValues(); // When compareAndPut succeeds <|startfocus|> doReturn(true).when(sharedRefDb).compareAndPut("ProjectName", oldRef, newRef); <|endfocus|> doReturn(Result.NEW).when(refUpdate).update(); MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate(sharedRefDb, "ProjectName", refUpdate); assertThat(multiSiteRefUpdate.update()).isEqualTo(Result.NEW); } @Test(expected = IOException.class) public void newUpdateShouldValidateAndFailWithIOException() throws IOException { setMockRequiredReturnValues(); // When compareAndPut fails doReturn(false).when(sharedRefDb).compareAndPut("ProjectName", oldRef, newRef); MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate(sharedRefDb, "ProjectName", refUpdate);
<|startcomment|> Why is this needed? We are not creating here real repositories but just delegate the calls to an existing one. <|endcomment|>  public MultiSiteRepository( MultiSiteRefDatabase.Factory multiSiteRefDbFactory, @Assisted String projectName, <|startfocus|> @Assisted Repository repository, @Assisted BaseRepositoryBuilder repositoryBuilder) { super(repositoryBuilder); <|endfocus|> this.multiSiteRefDbFactory = multiSiteRefDbFactory; this.projectName = projectName; this.repository = repository;
<|startcomment|> This can be inlined at L74 <|endcomment|>  public RefDatabase getRefDatabase() { <|startfocus|> RefDatabase refDatabase = repository.getRefDatabase(); return multiSiteRefDbFactory.create(projectName, refDatabase); <|endfocus|>
<|startcomment|> The default value of primitive boolean is false. Remove "= false" part. <|endcomment|> import com.googlecode.prolog_cafe.lang.SymbolTerm; import java.io.File; import java.io.IOException; import java.util.ArrayList; import java.util.List; import org.kohsuke.args4j.Option; public class PrologShell extends AbstractProgram { @Option(name = "-s", metaVar = "FILE.pl", usage = "file to load") private List<String> fileName = new ArrayList<>(); @Option(name = "-q", usage = "quiet mode without banner") <|startfocus|> private boolean quiet = false; <|endfocus|> @Override public int run() { if (!quiet) { banner(); } BufferingPrologControl pcl = new BufferingPrologControl(); pcl.setPrologClassLoader(new PrologClassLoader(getClass().getClassLoader())); pcl.setEnabled(Prolog.Feature.IO, true); pcl.setEnabled(Prolog.Feature.STATISTICS, true); pcl.configureUserIO(System.in, System.out, System.err); pcl.initialize(Prolog.BUILTIN); for (String file : fileName) { String path; try { path = new File(file).getCanonicalPath(); } catch (IOException e) {
<|startcomment|> update TODO ? <|endcomment|>  * commit SHA-1, but in ReviewDb it was generated randomly. Taking the target message as an index * rather than an ID allowed us to delete the message from both NoteDb and ReviewDb. * * @param update change update. * @param targetMessageId the id of the target change message. * @param newMessage the new message which is going to replace the old. */ <|startfocus|> // TODO(xchangcheng): Reconsider implementation now that there is only a single ID. <|endfocus|> public void replaceChangeMessage(ChangeUpdate update, String targetMessageId, String newMessage) { update.deleteChangeMessageByRewritingHistory(targetMessageId, newMessage); } /** * @param tag value of a tag, or null. * @return whether the tag starts with the autogenerated prefix. */ public static boolean isAutogenerated(@Nullable String tag) { return tag != null && tag.startsWith(AUTOGENERATED_TAG_PREFIX); } public static ChangeMessageInfo createChangeMessageInfo( ChangeMessage message, AccountLoader accountLoader) { PatchSet.Id patchNum = message.getPatchSetId();
<|startcomment|> This can be inlined at L61 <|endcomment|>  @Singleton public class MultiSiteGitRepositoryManager implements GitRepositoryManager { private final GitRepositoryManager gitRepositoryManager; @Inject MultiSiteRepository.Factory multiSiteRepoFactory; @Inject public MultiSiteGitRepositoryManager(LocalDiskRepositoryManager localDiskRepositoryManager) { this.gitRepositoryManager = localDiskRepositoryManager; } public MultiSiteGitRepositoryManager(GitRepositoryManager gitRepositoryManager) { this.gitRepositoryManager = gitRepositoryManager; } @Override public Repository openRepository(NameKey name) throws RepositoryNotFoundException, IOException { <|startfocus|> Repository openRepository = gitRepositoryManager.openRepository(name); return multiSiteRepoFactory.create(name.get(), openRepository); <|endfocus|> } @Override public Repository createRepository(NameKey name) throws RepositoryCaseMismatchException, RepositoryNotFoundException, IOException { Repository createdRepository = gitRepositoryManager.createRepository(name); return multiSiteRepoFactory.create(name.get(), createdRepository); } @Override public SortedSet<NameKey> list() { return gitRepositoryManager.list(); } } 
<|startcomment|> This can be inlined at L69 <|endcomment|>  this.gitRepositoryManager = localDiskRepositoryManager; } public MultiSiteGitRepositoryManager(GitRepositoryManager gitRepositoryManager) { this.gitRepositoryManager = gitRepositoryManager; } @Override public Repository openRepository(NameKey name) throws RepositoryNotFoundException, IOException { Repository openRepository = gitRepositoryManager.openRepository(name); return multiSiteRepoFactory.create(name.get(), openRepository); } @Override public Repository createRepository(NameKey name) throws RepositoryCaseMismatchException, RepositoryNotFoundException, IOException { <|startfocus|> Repository createdRepository = gitRepositoryManager.createRepository(name); return multiSiteRepoFactory.create(name.get(), createdRepository); <|endfocus|> } @Override public SortedSet<NameKey> list() { return gitRepositoryManager.list(); } } 
<|startcomment|> This is now needed, because to take effect and replace the classes in gerrit core, that thus series is wrapping, this plugin is migrated to gerrit library. Gerrit library is not aware of plugin name and other plugin specific wiring. Would it make sense to extract these changes in its own change with a proper commit message? It would also help to explain why it's needed to move from plugin to gerrit library. <|endcomment|> import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.retry.BoundedExponentialBackoffRetry; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class Configuration { private static final Logger log = LoggerFactory.getLogger(Configuration.class); <|startfocus|> public static final String PLUGIN_NAME = "multi-site"; <|endfocus|> static final String INSTANCE_ID_FILE = "instanceId.data"; // common parameters to cache and index sections static final String THREAD_POOL_SIZE_KEY = "threadPoolSize"; static final int DEFAULT_INDEX_MAX_TRIES = 2; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; static final int DEFAULT_THREAD_POOL_SIZE = 4; static final String NUM_STRIPED_LOCKS = "numStripedLocks"; static final int DEFAULT_NUM_STRIPED_LOCKS = 10;
<|startcomment|> Do we need to build this here? We could just use the batchRefUpdate.getCommands() to get the latest list of ReceiveCommand. This would remove the extra logic in addCommand <|endcomment|> import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.ProgressMonitor; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.transport.PushCertificate; import org.eclipse.jgit.transport.ReceiveCommand; import org.eclipse.jgit.util.time.ProposedTimestamp; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { private final BatchRefUpdate batchRefUpdate; private final RefDatabase refDb; private final SharedRefDatabase sharedRefDb; <|startfocus|> private final List<ReceiveCommand> receiveCommands; <|endfocus|> private final String projectName; public static class RefPair { final Ref oldRef; final Ref newRef; final Exception exception; RefPair(Ref oldRef, Ref newRef) { this.oldRef = oldRef; this.newRef = newRef; this.exception = null; } RefPair(Ref newRef, Exception e) { this.newRef = newRef; this.oldRef = SharedRefDatabase.NULL_REF; this.exception = e; } public boolean hasFailed() { return exception != null; } } 
<|startcomment|> This will not work until you evoke load(), therefore content of the multi-site.config file is not being read. <|endcomment|>  private final Index index; private final KafkaSubscriber subscriber; private final Kafka kafka; private final ZookeeperConfig zookeeperConfig; @Inject Configuration(SitePaths sitePaths) { <|startfocus|> this( new FileBasedConfig( sitePaths.etc_dir.resolve(PLUGIN_NAME + ".config").toFile(), FS.DETECTED)); <|endfocus|>
<|startcomment|> Using @Singleton might be a problem in a context where multiple injectors are used as they will end up building different objects anyway. Perhaps the intention of the author was to make sure the singleton was the same for multiple injectors. <|endcomment|> <|startfocus|> protected void configure() { <|endfocus|> bind(ReplicationQueue.class).in(Scopes.SINGLETON); bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(ReplicationQueue.class); DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(ReplicationQueue.class); DynamicSet.bind(binder(), NewProjectCreatedListener.class).to(ReplicationQueue.class); DynamicSet.bind(binder(), ProjectDeletedListener.class).to(ReplicationQueue.class); DynamicSet.bind(binder(), HeadUpdatedListener.class).to(ReplicationQueue.class); bind(OnStartStop.class).in(Scopes.SINGLETON); bind(LifecycleListener.class).annotatedWith(UniqueAnnotations.create()).to(OnStartStop.class); bind(LifecycleListener.class) .annotatedWith(UniqueAnnotations.create()) .to(ReplicationLogFile.class); bind(CredentialsFactory.class) .to(AutoReloadSecureCredentialsFactoryDecorator.class) .in(Scopes.SINGLETON); bind(CapabilityDefinition.class) .annotatedWith(Exports.named(START_REPLICATION)) .to(StartReplicationCapability.class); install(new FactoryModuleBuilder().build(PushAll.Factory.class)); install(new FactoryModuleBuilder().build(ReplicationState.Factory.class)); bind(ReplicationConfig.class).to(AutoReloadConfigDecorator.class); DynamicSet.setOf(binder(), ReplicationStateListener.class);
<|startcomment|> {} <|endcomment|>  try { rateLimiterHolder = limitsPerAccount.get(accountId); } catch (ExecutionException e) { rateLimiterHolder = Holder.EMPTY; log.warn("Cannot get rate limits for account ''{}''", accountId, e); } } else { try { rateLimiterHolder = limitsPerRemoteHost.get(req.getRemoteHost()); } catch (ExecutionException e) { rateLimiterHolder = Holder.EMPTY; log.warn( <|startfocus|> "Cannot get rate limits for anonymous access from remote host ''%s''", req.getRemoteHost(), e); <|endfocus|> } } if (!rateLimiterHolder.hasGracePermits() && rateLimiterHolder.get() != null && !rateLimiterHolder.get().tryAcquire()) { String msg = MessageFormat.format( limitExceededMsg, rateLimiterHolder.get().getRate() * SECONDS_PER_HOUR, rateLimiterHolder.getBurstPermits()); ((HttpServletResponse) res).sendError(SC_TOO_MANY_REQUESTS, msg); return; } } chain.doFilter(req, res); } boolean isRest(ServletRequest req) {
<|startcomment|> {}, rather? <|endcomment|>  public void run() { try { dispatcher.get().postEvent(new HeartbeatEvent()); } catch (OrmException e) { <|startfocus|> logger.error("Failed to post heartbeat event: %s", e.getMessage(), e); <|endfocus|> }
<|startcomment|> %d <|endcomment|>  if (itemTs.isPresent()) { count++; newLastIndexTs = maxTimestamp(newLastIndexTs, itemTs.get()); } } catch (Exception e) { log.atSevere().withCause(e).log("Unable to reindex %s %s", itemNameString, c); errors++; } } long elapsedNanos = stopwatch.stop().elapsed(TimeUnit.NANOSECONDS); if (count > 0) { log.atInfo().log( <|startfocus|> "%s %ss reindexed in %d msec (%d/sec), %d failed", <|endfocus|> count, itemNameString, elapsedNanos / 1000000L, (count * 1000L) / (elapsedNanos / 1000000L), errors); } else if (errors > 0) { log.atInfo().log("%d %ss failed to reindex", errors, itemNameString); } else { log.atFine().log("Scanning finished"); } indexTs.update(itemName, newLastIndexTs.toLocalDateTime()); } catch (Exception e) { log.atSevere().withCause(e).log("Unable to scan %ss", itemNameString);
<|startcomment|> %s <|endcomment|>  try { ChangeChecker checker = changeCheckerFactory.create(id); Optional<ChangeNotes> changeNotes = checker.getChangeNotes(); if (changeNotes.isPresent()) { ChangeNotes notes = changeNotes.get(); reindex(notes); if (checker.isChangeUpToDate(indexEvent)) { if (retryCount > 0) { log.atWarning().log( "Change %s has been eventually indexed after %d attempt(s)", id, retryCount); } else { log.atFine().log("Change {} successfully indexed", id); } } else { <|startfocus|> log.atWarning().log( "Change %s seems too old compared to the event timestamp (event-Ts=%s >> change-Ts=%s)", id, indexEvent, checker); rescheduleIndex(id, indexEvent, retryCount + 1); <|endfocus|> } } else { indexer.delete(parseChangeId(id)); log.atWarning().log( "Change %s could not be found in the local Git repository (eventTs=%s), deleted from index", id, indexEvent); } } catch (Exception e) {
<|startcomment|> %s <|endcomment|>  setHeaders(rsp); try { List<String> params = Splitter.on('/').splitToList(req.getPathInfo()); String cacheName = params.get(CACHENAME_INDEX); String json = req.getReader().readLine(); forwardedCacheEvictionHandler.evict( CacheEntry.from(cacheName, GsonParser.fromJson(cacheName, json))); rsp.setStatus(SC_NO_CONTENT); } catch (CacheNotFoundException e) { <|startfocus|> log.atSevere().log("Failed to process eviction request: {}", e.getMessage()); <|endfocus|> sendError(rsp, SC_BAD_REQUEST, e.getMessage()); } catch (IOException e) { log.atSevere().withCause(e).log("Failed to process eviction request"); sendError(rsp, SC_BAD_REQUEST, e.getMessage()); }
<|startcomment|> %d <|endcomment|>  for (; ; ) { try { execCnt++; tryOnce(); log.atFine().log("%s %s towards %s OK", action, key, destination); return true; } catch (ForwardingException e) { int maxTries = cfg.http().maxTries(); log.atFine().withCause(e).log( <|startfocus|> "Failed to %s %s on %s [%d/%s]", action, key, destination, execCnt, maxTries); <|endfocus|> if (!e.isRecoverable()) { log.atSevere().withCause(e).log( "%s %s towards %s failed with unrecoverable error; giving up", action, key, destination); return false; } if (execCnt >= maxTries) { log.atSevere().log( "Failed to %s %s on %s after %d tries; giving up", action, key, destination, maxTries); return false; } log.atFine().log("Retrying to %s %s on %s", action, key, destination); try { Thread.sleep(cfg.http().retryInterval());
<|startcomment|> ie <|endcomment|>  action, key, destination); return false; } if (execCnt >= maxTries) { log.atSevere().log( "Failed to %s %s on %s after %d tries; giving up", action, key, destination, maxTries); return false; } log.atFine().log("Retrying to %s %s on %s", action, key, destination); try { Thread.sleep(cfg.http().retryInterval()); } catch (InterruptedException ie) { <|startfocus|> log.atSevere().withCause(e).log( <|endfocus|> "%s %s towards %s was interrupted; giving up", action, key, destination); Thread.currentThread().interrupt(); return false; } } }
<|startcomment|> %s <|endcomment|>  public void viewAccepted(View view) { log.atInfo().log("viewAccepted(view: %s) called", view); synchronized (this) { if (view.getMembers().size() > 2) { log.atWarning().log( "%d members joined the jgroups cluster %s (%s). " <|startfocus|> + " Only two members are supported. Members: {}", <|endfocus|> view.getMembers().size(), jgroupsConfig.clusterName(), channel.getName(), view.getMembers()); } if (peerAddress != null && !view.getMembers().contains(peerAddress)) { log.atInfo().log("viewAccepted(): removed peerInfo"); peerAddress = null; peerInfo = Optional.empty(); } } if (view.size() > 1) { try { channel.send(new Message(null, myUrl)); } catch (Exception e) { // channel communication caused an error. Can't do much about it. log.atSevere().withCause(e).log( "Sending a message over channel %s to cluster %s failed",
<|startcomment|> %s <|endcomment|>  public void connect() { try { channel = getChannel(); Optional<InetAddress> address = finder.findAddress(); if (address.isPresent()) { log.atFine().log("Protocol stack: %s", channel.getProtocolStack()); channel.getProtocolStack().getTransport().setBindAddress(address.get()); <|startfocus|> log.atFine().log("Channel bound to {}", address.get()); <|endfocus|> } else { log.atWarning().log("Channel not bound: address not present"); } channel.setReceiver(this); channel.setDiscardOwnMessages(true); channel.connect(jgroupsConfig.clusterName()); log.atInfo().log( "Channel %s successfully joined jgroups cluster %s", channel.getName(), jgroupsConfig.clusterName()); } catch (Exception e) { if (channel != null) { log.atSevere().withCause(e).log( "joining cluster %s (channel %s) failed", jgroupsConfig.clusterName(), channel.getName()); } else {
<|startcomment|> this should be instead [0-9][0-9] <|endcomment|>  @Override public Ref getTarget() { return null; } @Override public ObjectId getObjectId() { return null; } @Override public ObjectId getPeeledObjectId() { return null; } @Override public boolean isPeeled() { return false; } @Override public Storage getStorage() { return Storage.NEW; } }; ImmutableList<String> refsToIgnoreInSharedDb = <|startfocus|> ImmutableList.of("refs/draft-comments/.*", "refs/changes/.*/[0-9]+"); <|endfocus|> /** * Create a new in-memory Ref name associated with an objectId. * * @param refName ref name * @param objectId object id */ default Ref newRef(String refName, ObjectId objectId) { return new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, refName, objectId); } /** * Utility method for new refs. * * @param project project name of the ref * @param newRef new reference to store.
<|startcomment|> servletPath <|endcomment|> import javax.servlet.http.HttpServletResponse; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class RestApiRateLimiter extends AllRequestFilter { private static final Logger log = LoggerFactory.getLogger(RestApiRateLimiter.class); private static final int SECONDS_PER_HOUR = 3600; static final int SC_TOO_MANY_REQUESTS = 429; private final Provider<CurrentUser> user; private final LoadingCache<Account.Id, Holder> limitsPerAccount; private final LoadingCache<String, Holder> limitsPerRemoteHost; <|startfocus|> private final Pattern servletpath = <|endfocus|> Pattern.compile( "^/(?:a/)?" + "(access|accounts|changes|config|groups|plugins|projects|Documentation|tools)/(.*)$"); private final String limitExceededMsg; @Inject RestApiRateLimiter( Provider<CurrentUser> user, @Named(HttpModule.CACHE_NAME_RESTAPI_ACCOUNTID) LoadingCache<Account.Id, Holder> limitsPerAccount, @Named(HttpModule.CACHE_NAME_RESTAPI_REMOTEHOST) LoadingCache<String, Holder> limitsPerRemoteHost, @Named(RateMsgHelper.RESTAPI_CONFIGURABLE_MSG_ANNOTATION) String limitExceededMsg) { this.user = user;
<|startcomment|> Nit: unnecessary parens, in some but not all of the instances of this construction. <|endcomment|>  AdministrateCheckersPermission permission) { this.self = self; this.permissionBackend = permissionBackend; this.listCheckers = listCheckers; this.checkers = checkers; this.views = views; this.permission = permission; } @Override public RestView<TopLevelResource> list() throws RestApiException { return listCheckers; } @Override public CheckerResource parse(TopLevelResource parent, IdString id) throws AuthException, ResourceNotFoundException, PermissionBackendException, IOException, ConfigInvalidException { <|startfocus|> if (!(self.get().isIdentifiedUser())) { <|endfocus|> throw new AuthException("Authentication required"); } permissionBackend.currentUser().check(permission); Checker checker = checkers.getChecker(id.get()).orElseThrow(() -> new ResourceNotFoundException(id)); return new CheckerResource(checker); } @Override public DynamicMap<RestView<CheckerResource>> views() { return views; } } 
<|startcomment|> This is fine, however using regex seems overkill in terms of compiling and evaluating it at runtime for every call. <|endcomment|>  return null; } @Override public ObjectId getObjectId() { return null; } @Override public ObjectId getPeeledObjectId() { return null; } @Override public boolean isPeeled() { return false; } @Override public Storage getStorage() { return Storage.NEW; } }; <|startfocus|> ImmutableList<String> refsToIgnoreInSharedDb = ImmutableList.of("refs/draft-comments/.*", "refs/changes/[0-9]+/[0-9]+/[0-9]+"); <|endfocus|> /** * Create a new in-memory Ref name associated with an objectId. * * @param refName ref name * @param objectId object id */ default Ref newRef(String refName, ObjectId objectId) { return new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, refName, objectId); } /** * Utility method for new refs. * * @param project project name of the ref * @param newRef new reference to store.
<|startcomment|> This can be simply expressed as: String refName = ref.getName(); return refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); <|endcomment|>  */ boolean compareAndRemove(String project, Ref oldRef) throws IOException; /** * Some references should not be stored in the SharedRefDatabase. * * @param ref * @return true if it's to be ignore; false otherwise */ default boolean ignoreRefInSharedDb(Ref ref) { <|startfocus|> for (String ignoreRefRegex : refsToIgnoreInSharedDb) { if (ref.getName().matches(ignoreRefRegex)) { return true; } } return false; <|endfocus|> } } 
<|startcomment|> Just do '&&' <|endcomment|>  @Inject public ZkSharedRefDatabase( CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { <|startfocus|> if (newRef != NULL_REF) { if (ignoreRefInSharedDb(newRef)) { return true; } } <|endfocus|> final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(
<|startcomment|> We don't need this: we have it already in the SharedRefDatabase <|endcomment|>  static final ObjectId AN_OBJECT_ID_2 = new ObjectId(1, 2, 3, 4, 6); static final ObjectId AN_OBJECT_ID_3 = new ObjectId(1, 2, 3, 4, 7); static final String A_TEST_REF_NAME = "refs/heads/master"; default String aBranchRef() { return RefNames.REFS_HEADS + testBranch(); } <|startfocus|> default Ref newRef(String refName, ObjectId objectId) { return new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, refName, objectId); } <|endfocus|> String testBranch(); } 
<|startcomment|> We can add in the return refName == null || ... <|endcomment|>  * @return true if the remove was successful; false otherwise. * @throws java.io.IOException the reference could not be removed due to a system error. */ boolean compareAndRemove(String project, Ref oldRef) throws IOException; /** * Some references should not be stored in the SharedRefDatabase. * * @param ref * @return true if it's to be ignore; false otherwise */ default boolean ignoreRefInSharedDb(Ref ref) { String refName = ref.getName(); <|startfocus|> return refName.startsWith("refs/draft-comments") <|endfocus|> || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } } 
<|startcomment|> This is all a boolean expression with short-circuit: return ignoreRefInSharedDb(oldRef) || compareAndPut(project, oldRef, NULL_REF); <|endcomment|>  CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { final DistributedAtomicValue distributedRefValue = <|startfocus|> new DistributedAtomicValue(client, pathFor(projectName, oldRef), retryPolicy); <|endfocus|> try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet( writeObjectId(oldRef.getObjectId()), writeObjectId(newValue)); return newDistributedValue.succeeded(); } catch (Exception e) { logger.atWarning().withCause(e).log(
<|startcomment|> Why not using equality of ObjectIds? <|endcomment|>  new ZkSharedRefDatabase(zookeeperContainer.getCurator(), new RetryNTimes(5, 30)); } @After public void cleanup() { zookeeperContainer.cleanup(); } @Test public void shouldCompareAndCreateSuccessfully() throws Exception { Ref ref = refOf(AN_OBJECT_ID_1); assertThat(zkSharedRefDatabase.compareAndCreate(A_TEST_PROJECT_NAME, ref)).isTrue(); <|startfocus|> String data = zookeeperContainer.readRefValueFromZk(A_TEST_PROJECT_NAME, ref).getName(); assertThat(data).isEqualTo(ref.getObjectId().getName()); <|endfocus|> } @Test public void shouldCompareAndPutSuccessfully() throws Exception { Ref oldRef = refOf(AN_OBJECT_ID_1); Ref newRef = refOf(AN_OBJECT_ID_2); String projectName = A_TEST_PROJECT_NAME; zookeeperContainer.createRefInZk(projectName, oldRef); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRef, newRef)).isTrue(); } @Test public void shouldCompareAndPutWithNullOldRefSuccessfully() throws Exception { Ref oldRef = refOf(null); Ref newRef = refOf(AN_OBJECT_ID_2);
<|startcomment|> Needs to be DispatchCommand(PermissionBackend permissionBackend, @Assisted Map<String, CommandProvider> all, DynamicSet<SshCommandPreExecutionFilter> commandFilters) { <|endcomment|>  private final AtomicReference<Command> atomicCmd; private final DynamicSet<SshCommandPreExecutionFilter> commandFilters; @Argument(index = 0, required = false, metaVar = "COMMAND", handler = SubcommandHandler.class) private String commandName; @Argument(index = 1, multiValued = true, metaVar = "ARG") private List<String> args = new ArrayList<>(); @Inject <|startfocus|> DispatchCommand(PermissionBackend permissionBackend, @Assisted Map<String, CommandProvider> all, DynamicSet<SshCommandPreExecutionFilter> commandFilters) { <|endfocus|> this.permissionBackend = permissionBackend; commands = all; atomicCmd = Atomics.newReference(); this.commandFilters = commandFilters; } Map<String, CommandProvider> getMap() { return commands; } @Override public void start(Environment env) throws IOException { try { parseCommandLine(); if (Strings.isNullOrEmpty(commandName)) { StringWriter msg = new StringWriter(); msg.write(usage()); throw die(msg.toString()); } final CommandProvider p = commands.get(commandName); if (p == null) { String msg =
<|startcomment|> Should this be done conditionally? Otherwise it would try to update username even though it is already set? Or am I missing something? <|endcomment|>  Optional<ExternalId> other = null; try { other = externalIds.get(key); } catch (IOException | ConfigInvalidException e) { throw new IllegalArgumentException( "Internal error while fetching username='" + username + "'"); } try { accountsUpdateProvider .get() .update( "Set Username from GitHub", accountId, u -> u.addExternalId(ExternalId.create(key, accountId, null, null))); } catch (OrmDuplicateKeyException dupeErr) { <|startfocus|> // If we are using this identity, don't report the exception. if (!other.isPresent() || !other.get().accountId().equals(accountId)) { throw new IllegalArgumentException("username " + username + " already in use"); } <|endfocus|> } catch (Exception e) { throw new IllegalArgumentException( "Internal error while trying to set username='" + username + "'"); } log.debug( "Account {} updated with preferredEmail = {}, fullName = {}, username = {}", accountId, email,
<|startcomment|> Shouldn't access to this field be synchronized? I think it should be because: * it is not an immutable final set from constructor * writing into this field and reading the field will likely happen from different threads <|endcomment|> import java.util.Objects; import java.util.Set; import java.util.function.Predicate; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.transport.RefSpec; import org.eclipse.jgit.transport.RemoteConfig; import org.eclipse.jgit.transport.URIish; /** Collection of Git repositories destinations for replication. */ public class DestinationsCollection { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final ReplicationConfig replicationConfig; private final Destination.Factory destinationFactory; <|startfocus|> private List<Destination> allDestinations = Collections.emptyList(); <|endfocus|> @Inject DestinationsCollection( ReplicationConfig replicationConfig, Destination.Factory destinationFactory) { this.replicationConfig = replicationConfig; this.destinationFactory = destinationFactory; } /** * Get all destinations matching the specified type. * * @param filterType type of destination. * @return list of destinations matching the specified filter type. */ public List<Destination> getAll(FilterType filterType) { if (replicationConfig.reloadIfNeeded()) { try { load(); } catch (ConfigInvalidException e) {
<|startcomment|> This shouldn't be necessary, if the isEmpty() method is removed from this class. <|endcomment|> import java.util.Objects; import java.util.Set; import java.util.function.Predicate; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.transport.RefSpec; import org.eclipse.jgit.transport.RemoteConfig; import org.eclipse.jgit.transport.URIish; /** Collection of Git repositories destinations for replication. */ public class DestinationsCollection { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final ReplicationConfig replicationConfig; private final Destination.Factory destinationFactory; <|startfocus|> private List<Destination> allDestinations = Collections.emptyList(); <|endfocus|> @Inject DestinationsCollection( ReplicationConfig replicationConfig, Destination.Factory destinationFactory) { this.replicationConfig = replicationConfig; this.destinationFactory = destinationFactory; } /** * Get all destinations matching the specified type. * * @param filterType type of destination. * @return list of destinations matching the specified filter type. */ public List<Destination> getAll(FilterType filterType) { if (replicationConfig.reloadIfNeeded()) { try { load(); } catch (ConfigInvalidException e) {
<|startcomment|> invalidUuid, or just inline it. <|endcomment|>  CheckerUuid checkerUuid = createCheckerInServer(createArbitraryCheckerInput()); boolean exists = checkerOperations.checker(checkerUuid).exists(); assertThat(exists).isTrue(); } @Test public void notExistingCheckerCanBeCheckedForExistence() throws Exception { String notExistingCheckerUuid = "test:not-existing-checker"; boolean exists = checkerOperations.checker(notExistingCheckerUuid).exists(); assertThat(exists).isFalse(); } @Test public void retrievingCheckerForInvalidUuidFails() throws Exception { <|startfocus|> String notExistingCheckerUuid = CheckerTestData.INVALID_UUID; <|endfocus|> exception.expect(IllegalArgumentException.class); checkerOperations.checker(notExistingCheckerUuid).get(); } @Test public void retrievingNotExistingCheckerFails() throws Exception { String notExistingCheckerUuid = "foo:bar"; exception.expect(IllegalStateException.class); checkerOperations.checker(notExistingCheckerUuid).get(); } @Test public void checkerNotCreatedByTestApiCanBeRetrieved() throws Exception { CheckerInput input = createArbitraryCheckerInput(); input.uuid = "test:unique-checker-not-created-via-test-API"; CheckerUuid checkerUuid = createCheckerInServer(input); 
<|startcomment|> Really we don't need two readers. Either swap the order and do new RevWalk(reader), or extract rw.getObjectReader() into a var (not in the try header though). <|endcomment|>  } @Override public Check get() throws Exception { return checks .getCheck(key, GetCheckOptions.defaults()) .orElseThrow(() -> new IllegalStateException("Tried to get non-existing test check")); } @Override public ImmutableMap<RevId, String> notesAsText() throws Exception { try (Repository repo = repoManager.openRepository(key.repository()); <|startfocus|> RevWalk rw = new RevWalk(repo); ObjectReader reader = repo.newObjectReader()) { <|endfocus|> Ref checkRef = repo.getRefDatabase().exactRef(CheckerRef.checksRef(key.patchSet().changeId)); checkNotNull(checkRef); NoteMap notes = NoteMap.read(reader, rw.parseCommit(checkRef.getObjectId())); ImmutableMap.Builder<RevId, String> raw = ImmutableMap.builder(); for (Note note : notes) { raw.put( new RevId(note.name()), new String(notes.getCachedBytes(note.toObjectId(), Integer.MAX_VALUE))); } return raw.build(); } } @Override public CheckInfo asInfo(ListChecksOption... options) throws Exception {
<|startcomment|> nullRef? <|endcomment|>  Ref immutableChangeRef = zkSharedRefDatabase.newRef("refs/heads/stable-2.16", AN_OBJECT_ID_1); assertThat(zkSharedRefDatabase.ignoreRefInSharedDb(immutableChangeRef)).isFalse(); } @Test public void compareAndPutShouldAlwaysIngoreIgnoredRefs() throws Exception { Ref existingRef = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_1); Ref oldRefToIgnore = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_2); <|startfocus|> Ref newRef = SharedRefDatabase.NULL_REF; <|endfocus|> String projectName = A_TEST_PROJECT_NAME; assertThat( zkSharedRefDatabase.compareAndPut( A_TEST_PROJECT_NAME, existingRef, SharedRefDatabase.NULL_REF)) .isTrue(); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRefToIgnore, newRef)).isTrue(); } @Override public String testBranch() { return "branch_" + nameRule.getMethodName(); } } 
<|startcomment|> nullRef <|endcomment|>  } @Test public void compareAndPutShouldAlwaysIngoreIgnoredRefs() throws Exception { Ref existingRef = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_1); Ref oldRefToIgnore = zkSharedRefDatabase.newRef("refs/draft-comments/56/450756/1013728", AN_OBJECT_ID_2); Ref newRef = SharedRefDatabase.NULL_REF; String projectName = A_TEST_PROJECT_NAME; <|startfocus|> assertThat( zkSharedRefDatabase.compareAndPut( A_TEST_PROJECT_NAME, existingRef, SharedRefDatabase.NULL_REF)) <|endfocus|> .isTrue(); assertThat(zkSharedRefDatabase.compareAndPut(projectName, oldRefToIgnore, newRef)).isTrue(); } @Override public String testBranch() { return "branch_" + nameRule.getMethodName(); } } 
<|startcomment|> Remove these args and use the member variables instead. <|endcomment|>  } return predicate; } private static boolean hasStatusPredicate(Predicate<ChangeData> predicate) { if (predicate instanceof IndexPredicate) { return ((IndexPredicate<ChangeData>) predicate) .getField() .getName() .equals(ChangeField.STATUS.getName()); } return predicate.getChildren().stream().anyMatch(CheckerQuery::hasStatusPredicate); } // TODO(ekempin): Retrying the query should be done by ChangeQueryProcessor. <|startfocus|> private List<ChangeData> executeIndexQueryWithRetry( RetryHelper retryHelper, Provider<ChangeQueryProcessor> changeQueryProcessorProvider, Predicate<ChangeData> predicate) <|endfocus|> throws OrmException { try { return retryHelper.execute( ActionType.INDEX_QUERY, () -> changeQueryProcessorProvider.get().query(predicate).entities(), OrmException.class::isInstance); } catch (Exception e) { Throwables.throwIfUnchecked(e); Throwables.throwIfInstanceOf(e, OrmException.class); throw new OrmException(e); } } } 
<|startcomment|> Also document the other args <|endcomment|>  try { predicate = createQueryPredicate(checker); } catch (ConfigInvalidException e) { logger.atWarning().withCause(e).log( "skipping invalid query for checker %s", checker.getUuid()); return false; } return predicate.asMatchable().match(cd); } public List<ChangeData> queryMatchingChanges(Checker checker) throws ConfigInvalidException, OrmException { <|startfocus|> return executeIndexQueryWithRetry( retryHelper, changeQueryProcessorProvider, createQueryPredicate(checker)); <|endfocus|> } private Predicate<ChangeData> createQueryPredicate(Checker checker) throws ConfigInvalidException { Predicate<ChangeData> predicate = new ProjectPredicate(checker.getRepository().get()); if (checker.getQuery().isPresent()) { String query = checker.getQuery().get(); Predicate<ChangeData> predicateForQuery; try { predicateForQuery = queryBuilder.parse(query); } catch (QueryParseException e) { throw new ConfigInvalidException( String.format("change query of checker %s is invalid: %s", checker.getUuid(), query), e); } if (!predicateForQuery.isMatchable()) {
<|startcomment|> Should we add a test here that verifies that CheckerTestData#longQueryWithSupportedOperators(int) produces a query with n terms? <|endcomment|>  try { UrlValidator.clean(CheckerTestData.INVALID_URL); assert_().fail("expected BadRequestException"); } catch (BadRequestException e) { assertMessage(e, "only http/https URLs supported", CheckerTestData.INVALID_URL); } } @Test public void verifyTestQueries() throws Exception { assertInvalidQuery( CheckerTestData.QUERY_WITH_UNSUPPORTED_OPERATOR, "unsupported operator", CheckerTestData.UNSUPPORTED_OPERATOR); assertInvalidQuery(CheckerTestData.INVALID_QUERY, "invalid", CheckerTestData.INVALID_QUERY); } <|startfocus|> <|endfocus|> private static void assertInvalidQuery(String query, String... expectedMessageParts) { try { CheckerQuery.clean(query); assert_().fail("expected ConfigInvalidException"); } catch (ConfigInvalidException e) { assertMessage(e, expectedMessageParts); } } private static void assertMessage(Exception e, String... expectedMessageParts) { for (String expectedMessagePart : expectedMessageParts) { assertThat(e).hasMessageThat().ignoringCase().contains(expectedMessagePart); } } } 
<|startcomment|> Future<?> -to match the below comment. <|endcomment|>  private void queueEvaluationIfNecessary(String repositoryPath) { if (lastCheckExpired(repositoryPath)) { EvaluationTask evaluationTask = evaluationTaskFactory.create(repositoryPath); if (queuedEvaluationTasks.add(evaluationTask)) { <|startfocus|> Future future = executor.submit(evaluationTask); <|endfocus|> addTaskListener(future, evaluationTask); timestamps.put(repositoryPath, System.currentTimeMillis()); } }
<|startcomment|> Future<?> -to remove the IntelliJ warning about unchecked assignment below for 'future' at line 135. <|endcomment|> <|startfocus|> private void addTaskListener(Future future, EvaluationTask evaluationTask) { ListenableFuture listenableFuture = JdkFutureAdapters.listenInPoolThread(future); <|endfocus|> listenableFuture.addListener( new Runnable() { public void run() { queuedEvaluationTasks.remove(evaluationTask); } }, MoreExecutors.directExecutor());
<|startcomment|> ListenableFuture<?> -to remove the Eclipse warning about raw type to parameterize. <|endcomment|> <|startfocus|> private void addTaskListener(Future future, EvaluationTask evaluationTask) { ListenableFuture listenableFuture = JdkFutureAdapters.listenInPoolThread(future); <|endfocus|> listenableFuture.addListener( new Runnable() { public void run() { queuedEvaluationTasks.remove(evaluationTask); } }, MoreExecutors.directExecutor());
<|startcomment|> Dangling javadoc comments here and below. -Usually replaced with java comment. Or, may remove completely if redundant with the actual code right below. <|endcomment|>  public void createEvaluator() { when(event.getProjectName()).thenReturn(NAME_KEY.get()); <|startfocus|> /** Config */ <|endfocus|> when(config.getExpireTimeRecheck()).thenReturn(0L); when(gerritConfig.getInt( "receive", null, "threadPoolSize", Runtime.getRuntime().availableProcessors())) .thenReturn(1); /** Repositories */ when(repository.getDirectory()).thenReturn(new File(REPOSITORY_PATH)); when(repositoryOther.getDirectory()).thenReturn(new File(REPOSITORY_PATH_OTHER)); /** Tasks */ taskSamePathCompleted = new EvaluationTask(null, null, null, REPOSITORY_PATH); taskSamePathNotCompleted = new EvaluationTask(null, null, null, REPOSITORY_PATH); taskDifferentPath = new EvaluationTask(null, null, null, REPOSITORY_PATH_OTHER); /** Task factory */ Factory eventTaskFactory = mock(Factory.class); when(eventTaskFactory.create(REPOSITORY_PATH)) .thenReturn(taskSamePathNotCompleted) .thenReturn(taskSamePathCompleted); when(eventTaskFactory.create(REPOSITORY_PATH_OTHER)).thenReturn(taskDifferentPath); /** Executor */ when(executor.submit(taskSamePathCompleted)) .thenReturn(CompletableFuture.completedFuture(null));
<|startcomment|> CompletableFuture<>() -to remove the IntelliJ warning about unchecked assignment. <|endcomment|>  taskDifferentPath = new EvaluationTask(null, null, null, REPOSITORY_PATH_OTHER); /** Task factory */ Factory eventTaskFactory = mock(Factory.class); when(eventTaskFactory.create(REPOSITORY_PATH)) .thenReturn(taskSamePathNotCompleted) .thenReturn(taskSamePathCompleted); when(eventTaskFactory.create(REPOSITORY_PATH_OTHER)).thenReturn(taskDifferentPath); /** Executor */ when(executor.submit(taskSamePathCompleted)) .thenReturn(CompletableFuture.completedFuture(null)); <|startfocus|> when(executor.submit(taskSamePathNotCompleted)).thenReturn(new CompletableFuture()); <|endfocus|> when(executor.submit(taskDifferentPath)).thenReturn(CompletableFuture.completedFuture(null)); evaluator = new Evaluator(executor, eventTaskFactory, repoManager, config, gerritConfig);
<|startcomment|> Incomplete sentence. <|endcomment|>  public static final String GLOBAL_CAPABILITIES = "GLOBAL_CAPABILITIES"; /** Pattern that matches all references in a project. */ public static final String ALL = "refs/*"; /** Pattern that matches all branches in a project. */ public static final String HEADS = "refs/heads/*"; /** Prefix that triggers a regular expression pattern. */ public static final String REGEX_PREFIX = "^"; <|startfocus|> /** Name of the access section. It could be a ref pattern or else. */ <|endfocus|> private String name; private List<Permission> permissions; public AccessSection(String name) { this.name = name; this.permissions = new ArrayList<>(); } /** @return true if the name is likely to be a valid reference section name. */ public static boolean isValidRefSectionName(String name) { return name.startsWith("refs/") || name.startsWith("^refs/"); } public String getName() { return name; } public ImmutableList<Permission> getPermissions() {
<|startcomment|> Would it be clearer to keep this named "refPattern"? <|endcomment|>  public static final String GLOBAL_CAPABILITIES = "GLOBAL_CAPABILITIES"; /** Pattern that matches all references in a project. */ public static final String ALL = "refs/*"; /** Pattern that matches all branches in a project. */ public static final String HEADS = "refs/heads/*"; /** Prefix that triggers a regular expression pattern. */ public static final String REGEX_PREFIX = "^"; <|startfocus|> /** Name of the access section. It could be a ref pattern or else. */ <|endfocus|> private String name; private List<Permission> permissions; public AccessSection(String name) { this.name = name; this.permissions = new ArrayList<>(); } /** @return true if the name is likely to be a valid reference section name. */ public static boolean isValidRefSectionName(String name) { return name.startsWith("refs/") || name.startsWith("^refs/"); } public String getName() { return name; } public ImmutableList<Permission> getPermissions() {
<|startcomment|> Why do we need to initialize this field now? Can it just stay null as before? <|endcomment|>  public AccessSection(String name) { this.name = name; <|startfocus|> this.permissions = new ArrayList<>(); <|endfocus|>
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2013 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import org.eclipse.jgit.errors.ConfigInvalidException; /** Listener of the configuration loading events. */ public interface ReplicationConfigListener { /** Invoked just before replication.config is about to be loaded. */ void beforeLoad(); /** * Invoked just after replication.config is loaded into memory. * * @throws ConfigInvalidException if the loaded configuration is not valid */
<|startcomment|> Why is the explicit package specification added? <|endcomment|>  private void innerTest() throws Exception { try { outer(); fail("should throw"); } catch (IllegalStateException e) { StackTraceElement[] trimmed = <|startfocus|> com.googlesource.gerrit.plugins.supermanifest.SuperManifestRefUpdatedListener.trimStack( <|endfocus|> e.getStackTrace(), Thread.currentThread().getStackTrace()[1]); String str = Arrays.toString(trimmed); assertThat(str).doesNotContain("trimStackTrace"); assertThat(str).contains("innerTest"); }
<|startcomment|> Is this comment still correct now? <|endcomment|>  // Project name is scoped by test, so we need to get it from our initial change Project.NameKey projectNameKey = initialResult.getChange().project(); String projectName = projectNameKey.get(); createBranch(new Branch.NameKey(projectName, "ds_one")); createBranch(new Branch.NameKey(projectName, "ds_two")); initialResult.assertOkStatus(); merge(initialResult); <|startfocus|> // Create normalUserGroup, containing current user, and contextUserGroup, containing contextUser <|endfocus|> String normalUserGroup = groupOperations.newGroup().name("normalUserGroup").create().get(); gApi.groups().id(normalUserGroup).addMembers(user.id().toString()); AccountApi contextUserApi = gApi.accounts().create("someContextUser"); String contextUserGroup = groupOperations.newGroup().name("contextUserGroup").create().get(); gApi.groups().id(contextUserGroup).addMembers(contextUserApi.get().name); // Grant exclusive +2 to context user grantLabel( "Code-Review", -2, 2, projectNameKey, "refs/heads/ds_one", false,
<|startcomment|> is this comment still correct now? <|endcomment|>  // Project name is scoped by test, so we need to get it from our initial change Project.NameKey projectNameKey = initialResult.getChange().project(); String projectName = projectNameKey.get(); createBranch(new Branch.NameKey(projectName, "ds_one")); createBranch(new Branch.NameKey(projectName, "ds_two")); initialResult.assertOkStatus(); merge(initialResult); <|startfocus|> // Create normalUserGroup, containing current user, and contextUserGroup, containing contextUser <|endfocus|> String normalUserGroup = groupOperations.newGroup().name("normalUserGroup").create().get(); gApi.groups().id(normalUserGroup).addMembers(user.id().toString()); AccountApi contextUserApi = gApi.accounts().create("randomContextUser"); String contextUserGroup = groupOperations.newGroup().name("contextUserGroup").create().get(); gApi.groups().id(contextUserGroup).addMembers(contextUserApi.get().name); // Grant +2 to context user, since it doesn't have it by default grantLabel( "Code-Review", -2, 2, projectNameKey, "refs/heads/*", false,
<|startcomment|> nit: the @Assisted annotated argument(s) are usually declared last. <|endcomment|>  private final PermissionBackend permissionBackend; private final Map<String, CommandProvider> commands; private final AtomicReference<Command> atomicCmd; private final DynamicSet<SshExecuteCommandInterceptor> commandInterceptors; @Argument(index = 0, required = false, metaVar = "COMMAND", handler = SubcommandHandler.class) private String commandName; @Argument(index = 1, multiValued = true, metaVar = "ARG") private List<String> args = new ArrayList<>(); @Inject DispatchCommand( PermissionBackend permissionBackend, <|startfocus|> @Assisted Map<String, CommandProvider> all, DynamicSet<SshExecuteCommandInterceptor> commandInterceptors) { <|endfocus|> this.permissionBackend = permissionBackend; commands = all; atomicCmd = Atomics.newReference(); this.commandInterceptors = commandInterceptors; } Map<String, CommandProvider> getMap() { return commands; } @Override public void start(Environment env) throws IOException { try { parseCommandLine(); if (Strings.isNullOrEmpty(commandName)) { StringWriter msg = new StringWriter(); msg.write(usage()); throw die(msg.toString()); } 
<|startcomment|> Optional: Use String.format(), something like: throw new UnloggedFailure( 126, String.format("blocked by %s, contact gerrit administrators for more details", commandInterceptor.name())); <|endcomment|>  } bc.setName(actualCommandName); bc.setArguments(args.toArray(new String[args.size()])); } else if (!args.isEmpty()) { throw die(commandName + " does not take arguments"); } for (SshExecuteCommandInterceptor commandInterceptor : commandInterceptors) { if (!commandInterceptor.accept(actualCommandName, args)) { throw new UnloggedFailure( 126, <|startfocus|> "blocked by " + commandInterceptor.name() + ", contact gerrit administrators for more details"); <|endfocus|> } } provideStateTo(cmd); atomicCmd.set(cmd); cmd.start(env); } catch (UnloggedFailure e) { String msg = e.getMessage(); if (!msg.endsWith("\n")) { msg += "\n"; } err.write(msg.getBytes(ENC)); err.flush(); onExit(e.exitCode); } } private void checkRequiresCapability(Command cmd) throws UnloggedFailure { String pluginName = null; if (cmd instanceof BaseCommand) { pluginName = ((BaseCommand) cmd).getPluginName();
<|startcomment|> "these". Sorry, my suggestion was wrong. <|endcomment|> // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.sshd; import com.google.gerrit.extensions.annotations.ExtensionPoint; import java.util.List; @ExtensionPoint public interface SshExecuteCommandInterceptor { /** * Check the command and return false if this command must not be run. * * @param command the command * @param arguments the list of arguments <|startfocus|> * @return whether or not this command with this arguments can be executed <|endfocus|> */ boolean accept(String command, List<String> arguments); default String name() { return this.getClass().getSimpleName(); } } 
<|startcomment|> Optional: Add ", contact gerrit administrators for more details". What I would like to avoid, is that gerrit users show up on the mailing list and asking for help, because their command are blocked by some custom SSH command filters. <|endcomment|>  if (!getName().isEmpty()) { actualCommandName = getName() + " " + commandName; } bc.setName(actualCommandName); bc.setArguments(args.toArray(new String[args.size()])); } else if (!args.isEmpty()) { throw die(commandName + " does not take arguments"); } <|startfocus|> for (SshExecuteCommandInterceptor filter : commandFilters) { if (!filter.accept(actualCommandName, args)) { throw new UnloggedFailure(126, "blocked by " + filter.name()); <|endfocus|> } } provideStateTo(cmd); atomicCmd.set(cmd); cmd.start(env); } catch (UnloggedFailure e) { String msg = e.getMessage(); if (!msg.endsWith("\n")) { msg += "\n"; } err.write(msg.getBytes(ENC)); err.flush(); onExit(e.exitCode); } } private void checkRequiresCapability(Command cmd) throws UnloggedFailure { String pluginName = null; if (cmd instanceof BaseCommand) {
<|startcomment|> Should this rather be: "whether or not this command with this arguments can be executed". <|endcomment|> // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.sshd; import com.google.gerrit.extensions.annotations.ExtensionPoint; import java.util.List; @ExtensionPoint public interface SshExecuteCommandInterceptor { /** * Check the command and return false if this command must not be run. * * @param command the command * @param arguments the list of arguments <|startfocus|> * @return whether or not the filter can be executed <|endfocus|> */ boolean accept(String command, List<String> arguments); default String name() { return this.getClass().getSimpleName(); } } 
<|startcomment|> Will this gets set when necessary? <|endcomment|>  RevisionCreatedListener.Event event, Map<String, ImmutableList<Match>> findings) throws RestApiException { long startNanos = System.nanoTime(); metrics.reviewCount.increment(); metrics.reviewCountByProject.increment(project); try { boolean tpAllowed = scannerConfig.isThirdPartyAllowed(project); boolean reviewRequired = false; boolean hasAlwaysReview = false; for (Map.Entry<String, ImmutableList<Match>> entry : findings.entrySet()) { if (entry.getValue() == ALWAYS_REVIEW) { reviewRequired = true; <|startfocus|> hasAlwaysReview = true; <|endfocus|> break; } PartyType pt = partyType(entry.getValue()); if (pt.compareTo(THIRD_PARTY) > 0) { reviewRequired = true; break; } if (pt == THIRD_PARTY && !tpAllowed) { reviewRequired = true; break; } } ChangeResource change = getChange(event, scannerConfig.fromAccountId); ReviewInput ri = new ReviewInput() .message("Copyright scan") .label(scannerConfig.reviewLabel, reviewRequired ? -1 : +2); if (reviewRequired) {
<|startcomment|> This is very unusual to make a class outside of the file's primary class, is there a reason to not make this a static class inside the top class? <|endcomment|> <|startfocus|> public String toString() { return "FlatFile WebSession Cleaner"; <|endfocus|>
<|startcomment|> Did you forget to remove this? <|endcomment|>  batchUpdate.addCommand(new ReceiveCommand(ref.getObjectId(), ObjectId.zeroId(), refName)); } batchUpdate.execute(rw, NullProgressMonitor.INSTANCE); for (ReceiveCommand command : batchUpdate.getCommands()) { if (command.getResult() != ReceiveCommand.Result.OK) { throw new IOException( String.format( "Unstar change %d failed, ref %s could not be deleted: %s", changeId.get(), command.getRefName(), command.getResult())); } } <|startfocus|> indexer.index(project, changeId); } catch (IOException e) { throw new OrmException(String.format("Unstar change %d failed", changeId.get()), e); <|endfocus|> } } public ImmutableMap<Account.Id, StarRef> byChange(Change.Id changeId) throws OrmException { try (Repository repo = repoManager.openRepository(allUsers)) { ImmutableMap.Builder<Account.Id, StarRef> builder = ImmutableMap.builder(); for (String refPart : getRefNames(repo, RefNames.refsStarredChangesPrefix(changeId))) { Integer id = Ints.tryParse(refPart);
<|startcomment|> DfsRepository is not threadsafe. This *might* be ok if we can guarantee the repo is no longer used from the request thread at the point when we kick off the background update, since writes that happen-before the executor.submit call should be visible. But that seems difficult to reason about, and brittle if we later introduce writes to allUsersRepo in the request thread. Can you just collect ChangeDraftUpdates in the AllUsersAsyncUpdate, instead of holding on to an OpenRepo? Then reopen the repo and delete the comments. <|endcomment|>  void execute(PersonIdent refLogIdent, String refLogMessage, PushCertificate pushCert) { if (allUsersRepo == null || allUsersRepo.cmds.isEmpty()) { return; } // There are operations to be performed asynchronously, so we can't close this early. The async // operation will close the repo. canCloseEarly = false; @SuppressWarnings("unused") Future<?> possiblyIgnoredError = executor.submit( () -> { <|startfocus|> try { <|endfocus|> allUsersRepo.flush(); BatchRefUpdate bru = allUsersRepo.repo.getRefDatabase().newBatchUpdate(); bru.setPushCertificate(pushCert); if (refLogMessage != null) { bru.setRefLogMessage(refLogMessage, false); } else { bru.setRefLogMessage( firstNonNull(NoteDbUtil.guessRestApiHandler(), "Update NoteDb refs"), false); } bru.setRefLogIdent(refLogIdent != null ? refLogIdent : serverIdent.get()); bru.setAtomic(true); allUsersRepo.cmds.addTo(bru); bru.setAllowNonFastForwards(true); RefUpdateUtil.executeChecked(bru, allUsersRepo.rw);
<|startcomment|> Nit: allUsers for consistency with allProjects <|endcomment|>  import com.google.gerrit.server.config.AllProjectsName; import com.google.gerrit.server.config.AllUsersName; import com.google.gerrit.server.git.GitRepositoryManager; import com.google.inject.Inject; import com.google.inject.Singleton; /** * Schema upgrade implementation. * * <p>Implementations must have a single non-private constructor with no arguments (e.g. the default * constructor). */ interface NoteDbSchemaVersion { @Singleton class Arguments { final GitRepositoryManager repoManager; final AllProjectsName allProjects; <|startfocus|> final AllUsersName allUsersName; <|endfocus|> @Inject Arguments( GitRepositoryManager repoManager, AllProjectsName allProjects, AllUsersName allUsersName) { this.repoManager = repoManager; this.allProjects = allProjects; this.allUsersName = allUsersName; } } void upgrade(Arguments args, UpdateUI ui) throws Exception; } 
<|startcomment|> removed? Is this logic really works as is for deleting use case? <|endcomment|>  protected boolean shouldSendMessage() { <|startfocus|> if (sshKey == null && gpgKeys == null) { // Don't email if no keys were added. return false; } <|endfocus|> if (user.equals(callingUser)) { // Send email if the user self-added a key; this notification is necessary to alert // the user if their account was compromised and a key was unexpectedly added. return true; } try { // Don't email if an administrator added a key on behalf of the user. permissionBackend.user(callingUser).check(GlobalPermission.ADMINISTRATE_SERVER); return false; } catch (AuthException | PermissionBackendException e) { // Send email if a non-administrator modified the keys, e.g. by MODIFY_ACCOUNT. return true; }
<|startcomment|> removed? <|endcomment|>  protected boolean shouldSendMessage() { if (sshKey == null && gpgKeys == null) { // Don't email if no keys were added. return false; } if (user.equals(callingUser)) { // Send email if the user self-added a key; this notification is necessary to alert // the user if their account was compromised and a key was unexpectedly added. return true; } try { <|startfocus|> // Don't email if an administrator added a key on behalf of the user. <|endfocus|> permissionBackend.user(callingUser).check(GlobalPermission.ADMINISTRATE_SERVER); return false; } catch (AuthException | PermissionBackendException e) { // Send email if a non-administrator modified the keys, e.g. by MODIFY_ACCOUNT. return true; }
<|startcomment|> Use the `user` variable that was initialized on L73 <|endcomment|>  } @Override public Response<?> apply(AccountResource.SshKey rsrc, Input input) throws AuthException, OrmException, RepositoryNotFoundException, IOException, ConfigInvalidException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.user(self).check(GlobalPermission.ADMINISTRATE_SERVER); } IdentifiedUser user = rsrc.getUser(); authorizedKeys.deleteKey(user.getAccountId(), rsrc.getSshKey().getKey().get()); try { <|startfocus|> deleteKeyFactory.create(rsrc.getUser(), "SSH").send(); <|endfocus|> } catch (EmailException e) { log.error( "Cannot send SSH key deletion message to "" + user.getAccount().getPreferredEmail(), e); } sshKeyCache.evict(user.getUserName()); return Response.none(); } } 
<|startcomment|> Use the logger's string formatting instead of concatenation. <|endcomment|>  if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.user(self).check(GlobalPermission.ADMINISTRATE_SERVER); } IdentifiedUser user = rsrc.getUser(); authorizedKeys.deleteKey(user.getAccountId(), rsrc.getSshKey().getKey().get()); try { deleteKeyFactory.create(rsrc.getUser(), "SSH").send(); } catch (EmailException e) { log.error( <|startfocus|> "Cannot send SSH key deletion message to "" + user.getAccount().getPreferredEmail(), e); <|endfocus|> } sshKeyCache.evict(user.getUserName()); return Response.none(); } } 
<|startcomment|> nit: empty line <|endcomment|> import java.util.List; import java.util.stream.Collectors; import java.util.stream.Stream; import org.eclipse.jgit.lib.BatchRefUpdate; import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.ProgressMonitor; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.transport.PushCertificate; import org.eclipse.jgit.transport.ReceiveCommand; import org.eclipse.jgit.transport.ReceiveCommand.Result; import org.eclipse.jgit.util.time.ProposedTimestamp; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { <|startfocus|> private static final FluentLogger logger = FluentLogger.forEnclosingClass(); <|endfocus|> private final BatchRefUpdate batchRefUpdate; private final RefDatabase refDb; private final SharedRefDatabase<? extends AutoCloseable> sharedRefDb; private final String projectName; public static class RefPair { public final Ref oldRef; public final Ref newRef; public final Exception exception; RefPair(Ref oldRef, Ref newRef) { this.oldRef = oldRef; this.newRef = newRef; this.exception = null; } 
<|startcomment|> This method name is incorrect: this does actually three things: 1. Check for local vs. shared ref-db alignment 2. Execution of the batch-update 3. Update of the shared ref-db <|endcomment|>  } @Override public BatchRefUpdate addProposedTimestamp(ProposedTimestamp ts) { return batchRefUpdate.addProposedTimestamp(ts); } @Override public void execute(RevWalk walk, ProgressMonitor monitor, List<String> options) throws IOException { executeWrapper(walk, monitor, options); } @Override public void execute(RevWalk walk, ProgressMonitor monitor) throws IOException { executeWrapper(walk, monitor, Collections.EMPTY_LIST); } @Override public String toString() { return batchRefUpdate.toString(); } <|startfocus|> private void updateSharedRefDb( <|endfocus|> Stream<RefPair> oldRefs, RevWalk walk, ProgressMonitor monitor, List<String> options) throws Exception { List<RefPair> refsToUpdate = oldRefs.sorted(comparing(RefPair::hasFailed).reversed()).collect(Collectors.toList()); if (refsToUpdate.isEmpty()) { return; } if (refsToUpdate.get(0).hasFailed()) { RefPair failedRef = refsToUpdate.get(0); throw new IOException( "Failed to fetch ref entries" + failedRef.newRef.getName(), failedRef.exception); } 
<|startcomment|> This isn't necessarily true: you may have succeded with the batchUpdate and failed with the updateSharedDBForSuccessfulCommands. <|endcomment|>  } try (CloseableSet<AutoCloseable> locks = new CloseableSet()) { assertBatchCommandsAreInSync(refsToUpdate, locks); if (options.isEmpty()) { batchRefUpdate.execute(walk, monitor); } else { batchRefUpdate.execute(walk, monitor, options); } updateSharedDBForSuccessfulCommands(batchRefUpdate.getCommands().stream()); } catch (Exception e) { <|startfocus|> logger.atWarning().log("Failed to apply full batch %s", e.getMessage()); <|endfocus|> throw e; } } private void updateSharedDBForSuccessfulCommands(Stream<ReceiveCommand> commandStream) throws IOException { List<RefPair> successfulRefPairs = commandStream .filter(cmd -> cmd.getResult() == Result.OK) .map( cmd -> new RefPair( cmd.getOldId() == null ? sharedRefDb.NULL_REF : sharedRefDb.newRef(cmd.getRefName(), cmd.getOldId()), sharedRefDb.newRef(cmd.getRefName(), cmd.getNewId()))) .collect(Collectors.toList()); for (RefPair successfulRefPair : successfulRefPairs) {
<|startcomment|> This is wrong: we should not get the oldRef from the command but rather from the local refdb. Example: I am doing a forced-update, then the oldRef *is not* the one I have locally but I should process it anyway. It should be blocked *ONLY* if the local ref doesn't correspond to the shared ref. <|endcomment|>  logger.atWarning().log("Failed to apply full batch %s", e.getMessage()); throw e; } } private void updateSharedDBForSuccessfulCommands(Stream<ReceiveCommand> commandStream) throws IOException { List<RefPair> successfulRefPairs = commandStream .filter(cmd -> cmd.getResult() == Result.OK) .map( cmd -> new RefPair( <|startfocus|> cmd.getOldId() == null ? sharedRefDb.NULL_REF : sharedRefDb.newRef(cmd.getRefName(), cmd.getOldId()), <|endfocus|> sharedRefDb.newRef(cmd.getRefName(), cmd.getNewId()))) .collect(Collectors.toList()); for (RefPair successfulRefPair : successfulRefPairs) { sharedRefDb.compareAndPut(projectName, successfulRefPair.oldRef, successfulRefPair.newRef); } } private void assertBatchCommandsAreInSync( List<RefPair> refsToUpdate, CloseableSet<AutoCloseable> locks) throws Exception { for (RefPair refPair : refsToUpdate) { Ref nonNullRef = refPair.oldRef == sharedRefDb.NULL_REF || refPair.oldRef == null
<|startcomment|> Is this relevant? If yes, why don't we use the same path of the project/ref? If not, why do we bother talking about it? <|endcomment|>  } } private void assertBatchCommandsAreInSync( List<RefPair> refsToUpdate, CloseableSet<AutoCloseable> locks) throws Exception { for (RefPair refPair : refsToUpdate) { Ref nonNullRef = refPair.oldRef == sharedRefDb.NULL_REF || refPair.oldRef == null ? refPair.newRef : refPair.oldRef; <|startfocus|> // Doesn't have to be the actual Path we lock but just a unique identifier of the ref <|endfocus|> String resourceLockKey = String.format("%s-%s", projectName, nonNullRef.getName()); locks.addResourceIfNotExist( resourceLockKey, () -> sharedRefDb.lockRef(projectName, nonNullRef)); boolean isInnSync; if (refPair.oldRef != sharedRefDb.NULL_REF && refPair.oldRef != null) { isInnSync = sharedRefDb.isMostRecentRefVersion(projectName, refPair.oldRef); } else { isInnSync = !sharedRefDb.isPresent(projectName, refPair.getName()); } if (!isInnSync) { String errorMessage = String.format(
<|startcomment|> isInSync <|endcomment|>  Ref nonNullRef = refPair.oldRef == sharedRefDb.NULL_REF || refPair.oldRef == null ? refPair.newRef : refPair.oldRef; // Doesn't have to be the actual Path we lock but just a unique identifier of the ref String resourceLockKey = String.format("%s-%s", projectName, nonNullRef.getName()); locks.addResourceIfNotExist( resourceLockKey, () -> sharedRefDb.lockRef(projectName, nonNullRef)); <|startfocus|> boolean isInnSync; <|endfocus|> if (refPair.oldRef != sharedRefDb.NULL_REF && refPair.oldRef != null) { isInnSync = sharedRefDb.isMostRecentRefVersion(projectName, refPair.oldRef); } else { isInnSync = !sharedRefDb.isPresent(projectName, refPair.getName()); } if (!isInnSync) { String errorMessage = String.format( "Ref %s not in sync with sharedDb, aborting batch", refPair.oldRef.getName()); logger.atWarning().log(errorMessage); throw new Exception(errorMessage); } } }
<|startcomment|> Can we make it more specific as an exception? What about the locks? Should we release them? <|endcomment|>  if (refPair.oldRef != sharedRefDb.NULL_REF && refPair.oldRef != null) { isInnSync = sharedRefDb.isMostRecentRefVersion(projectName, refPair.oldRef); } else { isInnSync = !sharedRefDb.isPresent(projectName, refPair.getName()); } if (!isInnSync) { String errorMessage = String.format( "Ref %s not in sync with sharedDb, aborting batch", refPair.oldRef.getName()); logger.atWarning().log(errorMessage); <|startfocus|> throw new Exception(errorMessage); <|endfocus|> } } } private Stream<RefPair> getRefsPairs(List<ReceiveCommand> receivedCommands) { return receivedCommands.stream().map(this::getRefPairForCommand); } private RefPair getRefPairForCommand(ReceiveCommand command) { try { switch (command.getType()) { case CREATE: return new RefPair(SharedRefDatabase.NULL_REF, getNewRef(command)); case UPDATE: case UPDATE_NONFASTFORWARD: return new RefPair(refDb.getRef(command.getRefName()), getNewRef(command)); case DELETE:
<|startcomment|> This is an incorrect use of the exception logging: you should use the flogger withCause(e) <|endcomment|>  } } catch (IOException e) { return new RefPair(command.getRef(), e); } } private void executeWrapper(RevWalk walk, ProgressMonitor monitor, List<String> options) throws IOException { try { updateSharedRefDb(getRefsPairs(batchRefUpdate.getCommands()), walk, monitor, options); } catch (Exception e) { <|startfocus|> String errorMessage = String.format( "Failing batch executeWrapper in MultiSiteBatchRefUpdate with exception %s", e.getMessage()); logger.atWarning().log(errorMessage); <|endfocus|> throw new IOException(errorMessage); } } private Ref getNewRef(ReceiveCommand command) { return sharedRefDb.newRef(command.getRefName(), command.getNewId()); } public static class CloseableSet<T extends AutoCloseable> implements AutoCloseable { private final HashMap<String, AutoCloseable> elements; public CloseableSet() { this(new HashMap<String, AutoCloseable>()); } public CloseableSet(HashMap<String, AutoCloseable> elements) { this.elements = elements; } public void addResourceIfNotExist(
<|startcomment|> Create <|endcomment|>  if (refUpdateBase.getRef().getObjectId() == null || refUpdateBase.getRef().getObjectId().equals(ObjectId.zeroId())) { // If we are CREATING a new ref we don't want it to have been written by // any other instance if (sharedDb.isPresent(projectName, refUpdateBase.getName())) throw new IOException( String.format( <|startfocus|> "Unable to update ref '%s', trying to create a new ref but there is a value " <|endfocus|> + "already in the shared ref db", refUpdateBase.getName())); } else { if (!sharedDb.isMostRecentRefVersion(projectName, refUpdateBase.getRef())) throw new IOException( String.format( "Unable to update ref '%s', the local objectId '%s' is not equal to the one " + "in the shared ref datasuper", refUpdateBase.getName(), refUpdateBase.getOldObjectId())); } } private void checkSharedDbForRefDelete() throws IOException { Ref oldRef = this.getRef(); try {
<|startcomment|> Just return an auto-closeable here instead of a SharedDbLock <|endcomment|>  */ boolean compareAndRemove(String project, Ref oldRef) throws IOException; /** * Some references should not be stored in the SharedRefDatabase. * * @param ref * @return true if it's to be ignore; false otherwise */ default boolean ignoreRefInSharedDb(Ref ref) { String refName = ref.getName(); return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); <|startfocus|> } <|endfocus|> } 
<|startcomment|> Migration mode doesn't exist anymore: why should we include the wording in this message? Is this really a warning or a normal situation? <|endcomment|>  public ZkSharedRefDatabase( CuratorFramework client, @Named("ZkLockRetryPolicy") RetryPolicy retryPolicy) { this.client = client; this.retryPolicy = retryPolicy; } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return ignoreRefInSharedDb(oldRef) || compareAndPut(project, oldRef, NULL_REF); } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { <|startfocus|> if (newRef != NULL_REF && ignoreRefInSharedDb(newRef)) { <|endfocus|> return true; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId())); } final ObjectId newValue = newRef.getObjectId() == null ? ObjectId.zeroId() : newRef.getObjectId(); final AtomicValue<byte[]> newDistributedValue = distributedRefValue.compareAndSet(
<|startcomment|> Do we really need those comments? the Mockito doReturn(true/false) already tell if the validation was successful or not. <|endcomment|>  // When validation of status fails doReturn(false).when(sharedRefDb).isMostRecentRefVersion(A_TEST_PROJECT_NAME, oldRef); RefUpdate refUpdate = RefFixture.RefUpdateStub.forSuccessfulUpdate(oldRef, newRef.getObjectId()); MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate(sharedRefDb, A_TEST_PROJECT_NAME, refUpdate); multiSiteRefUpdate.update(); } @Test(expected = Exception.class) public void newUpdateShouldFailIfSharedDBUpdateFailsLeavingSystemInInconsistentStatus() throws Exception { <|startfocus|> // When validation succeeds <|endfocus|> doReturn(true).when(sharedRefDb).isMostRecentRefVersion(A_TEST_PROJECT_NAME, oldRef); // When compareAndPut fails doReturn(false).when(sharedRefDb).compareAndPut(A_TEST_PROJECT_NAME, oldRef, newRef); RefUpdate refUpdate = RefFixture.RefUpdateStub.forSuccessfulUpdate(oldRef, newRef.getObjectId()); MultiSiteRefUpdate multiSiteRefUpdate = new MultiSiteRefUpdate(sharedRefDb, A_TEST_PROJECT_NAME, refUpdate); multiSiteRefUpdate.update(); } @Test public void deleteShouldValidateAndSucceed() throws Exception { // When validation succeeds
<|startcomment|> We are not really using any curator-specific features in this test. Why is this needed? <|endcomment|> // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb; import static com.google.common.truth.Truth.assertThat; import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper.RefFixture; import java.io.IOException; <|startfocus|> import org.apache.curator.framework.recipes.locks.Locker; <|endfocus|> import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.Ref.Storage; import org.junit.Rule; import org.junit.Test; import org.junit.rules.TestName; public class RefSharedDatabaseTest implements RefFixture { @Rule public TestName nameRule = new TestName(); @Override public String testBranch() { return "branch_" + nameRule.getMethodName(); } @Test public void shouldCreateANewRef() { ObjectId objectId = AN_OBJECT_ID_1;
<|startcomment|> This is a unit-test, not end-to-end. Why do you need a full Gerrit daemon for that? <|endcomment|>  public void setup() { zookeeperContainer = new ZookeeperTestContainerSupport(false); zkSharedRefDatabase = <|startfocus|> new ZkSharedRefDatabase(zookeeperContainer.getCurator(), new RetryNTimes(5, 30)); <|endfocus|>
<|startcomment|> key <|endcomment|>  protected boolean shouldSendMessage() { if (user.equals(callingUser)) { // Send email if the user self-removed a key; this notification is necessary to alert // the user if their account was compromised and a key was unexpectedly deleted. return true; } try { <|startfocus|> // Don't email if an administrator removed a password on behalf of the user. <|endfocus|> permissionBackend.user(callingUser).check(GlobalPermission.ADMINISTRATE_SERVER); return false; } catch (AuthException | PermissionBackendException e) { // Send email if a non-administrator modified the keys, e.g. by MODIFY_ACCOUNT. return true; }
<|startcomment|> Use logger's formatting instead of concatenation. <|endcomment|>  if (extId == null) { throw new ResourceNotFoundException(); } ExternalId newExtId = ExternalId.createWithPassword(extId.key(), extId.accountId(), extId.email(), newPassword); externalIdsUpdate.create().upsert(newExtId); try { httpPasswordSenderFactory.create(user).send(); } catch (EmailException e) { log.error( <|startfocus|> "Cannot send HttpPassword added or changed message to " + user.getAccount().getPreferredEmail(), e); <|endfocus|> } return Strings.isNullOrEmpty(newPassword) ? Response.<String>none() : Response.ok(newPassword); } public static String generate() { byte[] rand = new byte[LEN]; rng.nextBytes(rand); byte[] enc = Base64.encodeBase64(rand, false); StringBuilder r = new StringBuilder(enc.length); for (int i = 0; i < enc.length; i++) { if (enc[i] == '=') { break; } r.append((char) enc[i]); } return r.toString(); } } 
<|startcomment|> This is no longer only the SHA1 (previously represented by a String). <|endcomment|>  /** First line of {@link #message}. */ protected String subject; /** The complete description of the change the patch set introduces. */ protected String message; /** Identity of who wrote the patch set. May differ from {@link #committer}. */ protected UserIdentity author; /** Identity of who committed the patch set to the VCS. */ protected UserIdentity committer; /** List of parents of the patch set. */ protected List<ParentInfo> parents; <|startfocus|> /** SHA-1 of commit */ <|endfocus|> protected ObjectId commitId; /** Optional user-supplied description for the patch set. */ protected String description; protected PatchSetInfo() {} public PatchSetInfo(PatchSet.Id k) { key = k; } public PatchSet.Id getKey() { return key; } public String getSubject() { return subject; } public void setSubject(String s) { if (s != null && s.length() > 255) { subject = s.substring(0, 255); } else {
<|startcomment|> Just "wraps an"? <|endcomment|>  public String message; public String parentUuid; public Range range; public String tag; // Hex commit SHA1 of the commit of the patchset to which this comment applies. Other classes call // this "commitId", but this class uses the old ReviewDb term "revId", and this field name is // serialized into JSON in NoteDb, so it can't easily be changed. Callers do not access this field <|startfocus|> // directly, and instead use the public getter/setter that wraps in an ObjectId. <|endfocus|> private String revId; public String serverId; public boolean unresolved; /** * Whether the comment was parsed from a JSON representation (false) or the legacy custom notes * format (true). */ public transient boolean legacyFormat; public Comment(Comment c) { this( new Key(c.key), c.author.getId(), new Timestamp(c.writtenOn.getTime()), c.side, c.message, c.serverId, c.unresolved); this.lineNbr = c.lineNbr; this.realAuthor = c.realAuthor;
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2018 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.reviewdb.converter; import com.google.gerrit.proto.Entities; import com.google.protobuf.Parser; import org.eclipse.jgit.lib.ObjectId; /** * Proto converter for {@code ObjectId}s. * * <p>This converter uses the hex representation of object IDs embedded in a wrapper proto type, * rather than a more parsimonious implementation (e.g. a raw byte array), for two reasons: * * <ul>
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2018 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.reviewdb.converter; import static com.google.common.truth.Truth.assertThat; import static com.google.gerrit.proto.testing.SerializedClassSubject.assertThatSerializedClass; import com.google.common.collect.ImmutableMap; import com.google.gerrit.proto.Entities; import com.google.gerrit.proto.testing.SerializedClassSubject; import com.google.protobuf.Parser; import org.eclipse.jgit.lib.ObjectId; import org.junit.Test; public class ObjectIdProtoConverterTest {
<|startcomment|> ABBREVIATED_STRING_LENGTH <|endcomment|>  public static String abbreviateName(AnyObjectId id) { <|startfocus|> return abbreviateName(id, 7); <|endfocus|>
<|startcomment|> Mention the valid range? <|endcomment|>  /** * Abbreviate an ID's hex string representation to 7 chars. * * @param id object ID. * @return abbreviated hex string representation, exactly 7 chars. */ public static String abbreviateName(AnyObjectId id) { return abbreviateName(id, 7); } /** * Abbreviate an ID's hex string representation to {@code n} chars. * * @param id object ID. <|startfocus|> * @param n number of hex chars. <|endfocus|> * @return abbreviated hex string representation, exactly {@code n} chars. */ public static String abbreviateName(AnyObjectId id, int n) { checkValidLength(n); return requireNonNull(id).abbreviate(n).name(); } /** * Abbreviate an ID's hex string representation uniquely to at least 7 chars. * * @param id object ID. * @param reader object reader for determining uniqueness. * @return abbreviated hex string representation, unique according to {@code reader} at least 7 * chars. */
<|startcomment|> Add @throws? I'm guessing this is going to throw IOException if it wasn't possible to generate a unique ID at the given length, or the object was invalid. <|endcomment|>  */ public static String abbreviateName(AnyObjectId id, int n) { checkValidLength(n); return requireNonNull(id).abbreviate(n).name(); } /** * Abbreviate an ID's hex string representation uniquely to at least 7 chars. * * @param id object ID. * @param reader object reader for determining uniqueness. * @return abbreviated hex string representation, unique according to {@code reader} at least 7 <|startfocus|> * chars. <|endfocus|> */ public static String abbreviateName(AnyObjectId id, ObjectReader reader) throws IOException { return abbreviateName(id, ABBREVIATED_STRING_LENGTH, reader); } /** * Abbreviate an ID's hex string representation uniquely to at least {@code n} chars. * * @param id object ID. * @param n minimum number of hex chars. * @param reader object reader for determining uniqueness. * @return abbreviated hex string representation, unique according to {@code reader} at least * {@code } chars. */
<|startcomment|> Mention the valid range? <|endcomment|>  * @param reader object reader for determining uniqueness. * @return abbreviated hex string representation, unique according to {@code reader} at least 7 * chars. */ public static String abbreviateName(AnyObjectId id, ObjectReader reader) throws IOException { return abbreviateName(id, ABBREVIATED_STRING_LENGTH, reader); } /** * Abbreviate an ID's hex string representation uniquely to at least {@code n} chars. * * @param id object ID. <|startfocus|> * @param n minimum number of hex chars. <|endfocus|> * @param reader object reader for determining uniqueness. * @return abbreviated hex string representation, unique according to {@code reader} at least * {@code } chars. */ public static String abbreviateName(AnyObjectId id, int n, ObjectReader reader) throws IOException { checkValidLength(n); return reader.abbreviate(id, n).name(); } private static void checkValidLength(int n) { checkArgument(n > 0); checkArgument(n <= Constants.OBJECT_ID_STRING_LENGTH); } private ObjectIds() {}
<|startcomment|> Add @throws? <|endcomment|>  return abbreviateName(id, ABBREVIATED_STRING_LENGTH, reader); } /** * Abbreviate an ID's hex string representation uniquely to at least {@code n} chars. * * @param id object ID. * @param n minimum number of hex chars. * @param reader object reader for determining uniqueness. * @return abbreviated hex string representation, unique according to {@code reader} at least <|startfocus|> * {@code } chars. <|endfocus|> */ public static String abbreviateName(AnyObjectId id, int n, ObjectReader reader) throws IOException { checkValidLength(n); return reader.abbreviate(id, n).name(); } private static void checkValidLength(int n) { checkArgument(n > 0); checkArgument(n <= Constants.OBJECT_ID_STRING_LENGTH); } private ObjectIds() {} } 
<|startcomment|> can be omitted <|endcomment|>  private static String implicitMergeOf(ObjectId commit) { <|startfocus|> return "implicit merge of " + abbreviateName(commit, 7); <|endfocus|>
<|startcomment|> Optional: add a link to the source if the URL is not too long? <|endcomment|>  } @FunctionalInterface private interface Func { void call() throws Exception; } private static void assertRuntimeException(Func func) throws Exception { try { func.call(); assert_().fail("Expected RuntimeException"); } catch (RuntimeException e) { // Expected. } } private static ObjectReader newReaderWithAmbiguousIds() throws Exception { <|startfocus|> // Recipe for creating ambiguous IDs courtesy of t1512-rev-parse-disambiguation.sh in git core. <|endfocus|> TestRepository<?> tr = new TestRepository<>(new InMemoryRepository(new DfsRepositoryDescription("repo"))); String blobData = "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\nb1rwzyc3\n"; RevBlob blob = tr.blob(blobData); assertThat(blob.name()).isEqualTo(AMBIGUOUS_BLOB_ID.name()); assertThat(tr.tree(tr.file("a0blgqsjc", blob)).name()).isEqualTo(AMBIGUOUS_TREE_ID.name()); return tr.getRevWalk().getObjectReader(); } } 
<|startcomment|> Omit the default value? <|endcomment|>  private static String implicitMergeOf(ObjectId commit) { <|startfocus|> return "implicit merge of " + abbreviateName(commit, 7); <|endfocus|>
<|startcomment|> would introduce a version that assumes ensure = true <|endcomment|> import com.googlesource.gerrit.plugins.lfs.LfsConfigurationFactory; import java.io.IOException; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; @Singleton public class LfsFsDataDirectoryManager { private static final String KEY_DIRECTORY = "directory"; private final LfsConfigurationFactory configFactory; private final Path defaultDataDir; @Inject LfsFsDataDirectoryManager( LfsConfigurationFactory configFactory, @PluginData Path defaultDataDir) { this.configFactory = configFactory; this.defaultDataDir = defaultDataDir; } <|startfocus|> <|endfocus|> public Path getForBackend(LfsBackend backend, boolean ensure) throws IOException { String dataDir = configFactory.getGlobalConfig().getString(backend.type.name(), backend.name, KEY_DIRECTORY); if (Strings.isNullOrEmpty(dataDir)) { return defaultDataDir; } if (ensure) { // note that the following method not only creates missing // directory/directories but throws exception when path // exists and points to file Path ensured = Files.createDirectories(Paths.get(dataDir.toString())); 
<|startcomment|> this is not needed <|endcomment|>  } public Path getForBackend(LfsBackend backend, boolean ensure) throws IOException { String dataDir = configFactory.getGlobalConfig().getString(backend.type.name(), backend.name, KEY_DIRECTORY); if (Strings.isNullOrEmpty(dataDir)) { return defaultDataDir; } if (ensure) { // note that the following method not only creates missing // directory/directories but throws exception when path // exists and points to file <|startfocus|> Path ensured = Files.createDirectories(Paths.get(dataDir.toString())); <|endfocus|> // we should at least make sure that directory is readable if (!Files.isReadable(ensured)) { throw new IOException("Path '" + ensured.toAbsolutePath() + "' cannot be accessed"); } return ensured; } return Paths.get(dataDir); } } 
<|startcomment|> of what? <|endcomment|>  Integer id = Ints.tryParse(email.substring(0, at)); if (id != null) { return Optional.of(Account.id(id)); } } } return Optional.empty(); } public static String formatTime(PersonIdent ident, Timestamp t) { GitDateFormatter dateFormatter = new GitDateFormatter(Format.DEFAULT); // TODO(dborowitz): Use a ThreadLocal or use Joda. PersonIdent newIdent = new PersonIdent(ident, t); return dateFormatter.formatDate(newIdent); } <|startfocus|> /** Returns the name of */ <|endfocus|> static String guessRestApiHandler() { StackTraceElement[] trace = Thread.currentThread().getStackTrace(); int i = findRestApiServlet(trace); if (i < 0) { return null; } try { for (i--; i >= 0; i--) { String cn = trace[i].getClassName(); Class<?> cls = Class.forName(cn); if (RestModifyView.class.isAssignableFrom(cls) && cls != RetryingRestModifyView.class) { return viewName(cn); } } return null;
<|startcomment|> A special reflog message for this would probably be nice. <|endcomment|>  Future<?> possiblyIgnoredError = executor.submit( () -> { try (OpenRepo allUsersRepo = OpenRepo.open(repoManager, allUsersName)) { allUsersRepo.addUpdates(draftUpdates); allUsersRepo.flush(); BatchRefUpdate bru = allUsersRepo.repo.getRefDatabase().newBatchUpdate(); bru.setPushCertificate(pushCert); if (refLogMessage != null) { bru.setRefLogMessage(refLogMessage, false); } else { bru.setRefLogMessage( <|startfocus|> firstNonNull(NoteDbUtil.guessRestApiHandler(), "Update NoteDb refs"), false); <|endfocus|> } bru.setRefLogIdent(refLogIdent != null ? refLogIdent : serverIdent.get()); bru.setAtomic(true); allUsersRepo.cmds.addTo(bru); bru.setAllowNonFastForwards(true); RefUpdateUtil.executeChecked(bru, allUsersRepo.rw); } catch (IOException e) { logger.atSevere().withCause(e).log( "Failed to delete draft comments asynchronously after publishing them"); } });
<|startcomment|> This reads oddly, it sounds like you're deleting a "published comment" from the ChangeDraftUpdate, but in fact all the Comment instances accessible via ChangeDraftUpdate have status == DRAFT. Maybe something like "markCommentPublished"? I dunno though. I don't feel too strongly. <|endcomment|> <|startfocus|> public void deletePublishedComment(Comment c) { <|endfocus|> verifyComment(c); delete.put(key(c), DeleteReason.PUBLISHED);
<|startcomment|> allMatch? <|endcomment|>  private void addCommands() throws IOException { changeRepo.addUpdates(changeUpdates, Optional.of(maxUpdates)); if (!draftUpdates.isEmpty()) { <|startfocus|> boolean publishOnly = draftUpdates.values().stream().anyMatch(ChangeDraftUpdate::isPublishOnly); <|endfocus|> if (publishOnly) { updateAllUsersAsync.setDraftUpdates(draftUpdates); } else { allUsersRepo.addUpdates(draftUpdates); } } if (!robotCommentUpdates.isEmpty()) { changeRepo.addUpdates(robotCommentUpdates); } if (!rewriters.isEmpty()) { addRewrites(rewriters, changeRepo); } for (Change.Id id : toDelete) { doDelete(id); }
<|startcomment|> This is not used. <|endcomment|> // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.mail.send; import com.google.gerrit.common.errors.EmailException; import com.google.gerrit.extensions.api.changes.RecipientType; import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.mail.Address; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; public class HttpPasswordUpdateSender extends OutgoingEmail { public interface Factory { HttpPasswordUpdateSender create(IdentifiedUser user); } <|startfocus|> private final IdentifiedUser callingUser; <|endfocus|> private final IdentifiedUser user; @AssistedInject public HttpPasswordUpdateSender( EmailArguments ea, IdentifiedUser callingUser, @Assisted IdentifiedUser user) { super(ea, "HttpPasswordUpdate"); this.callingUser = callingUser; this.user = user; } @Override protected void init() throws EmailException { super.init(); setHeader("Subject", "[Gerrit Code Review] HTTP password was either added, changed or deleted"); add(RecipientType.TO, new Address(getEmail())); } @Override protected boolean shouldSendMessage() {
<|startcomment|> Don't import this. <|endcomment|> // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.api.config; import com.google.gerrit.extensions.client.DiffPreferencesInfo; import com.google.gerrit.extensions.client.EditPreferencesInfo; import com.google.gerrit.extensions.client.GeneralPreferencesInfo; import com.google.gerrit.extensions.common.ServerInfo; import com.google.gerrit.extensions.restapi.NotImplementedException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.extensions.webui.TopMenu; <|startfocus|> import com.google.gerrit.extensions.webui.TopMenu.MenuEntry; <|endfocus|> import java.util.List; public interface Server { /** @return Version of server. */ String getVersion() throws RestApiException; ServerInfo getInfo() throws RestApiException; GeneralPreferencesInfo getDefaultPreferences() throws RestApiException; GeneralPreferencesInfo setDefaultPreferences(GeneralPreferencesInfo in) throws RestApiException; DiffPreferencesInfo getDefaultDiffPreferences() throws RestApiException; DiffPreferencesInfo setDefaultDiffPreferences(DiffPreferencesInfo in) throws RestApiException; EditPreferencesInfo getDefaultEditPreferences() throws RestApiException; EditPreferencesInfo setDefaultEditPreferences(EditPreferencesInfo in) throws RestApiException; 
<|startcomment|> Change to TopMenu.MenuEntry <|endcomment|>  throws RestApiException { throw new NotImplementedException(); } @Override public EditPreferencesInfo getDefaultEditPreferences() throws RestApiException { throw new NotImplementedException(); } @Override public EditPreferencesInfo setDefaultEditPreferences(EditPreferencesInfo in) throws RestApiException { throw new NotImplementedException(); } @Override public ConsistencyCheckInfo checkConsistency(ConsistencyCheckInput in) throws RestApiException { throw new NotImplementedException(); } @Override <|startfocus|> public List<MenuEntry> topMenus() throws RestApiException { <|endfocus|> throw new NotImplementedException(); } } } 
<|startcomment|> Are these throws still needed? IIRC the index implementations in core were change to not throw IOException any more; they only throw the unchecked StorageException <|endcomment|>  ChangeCheckerImpl.Factory changeCheckerFactory) { super(configuration.index().numStripedLocks()); this.indexer = indexer; this.indexExecutor = indexExecutor; this.oneOffCtx = oneOffCtx; this.changeCheckerFactory = changeCheckerFactory; Index indexConfig = configuration.index(); this.retryInterval = indexConfig != null ? indexConfig.retryInterval() : 0; this.maxTries = indexConfig != null ? indexConfig.maxTries() : 0; } @Override <|startfocus|> protected void doIndex(String id, Optional<ChangeIndexEvent> indexEvent) throws IOException { <|endfocus|> doIndex(id, indexEvent, 0); } private void doIndex(String id, Optional<ChangeIndexEvent> indexEvent, int retryCount) throws IOException { try { ChangeChecker checker = changeCheckerFactory.create(id); Optional<ChangeNotes> changeNotes = checker.getChangeNotes(); if (changeNotes.isPresent()) { ChangeNotes notes = changeNotes.get(); reindex(notes); if (checker.isChangeUpToDate(indexEvent)) { if (retryCount > 0) {
<|startcomment|> Is this change what's causing the code style check to fail? <|endcomment|>  ChangeNotesStateProto.newBuilder() .setMetaId(SHA_BYTES) .setChangeId(ID.get()) .setColumns(colsProto.toBuilder().setTopic("topic").setHasTopic(true)) .build()); } @Test public void serializeOriginalSubject() throws Exception { assertRoundTrip( newBuilder() .columns(cols.toBuilder().originalSubject("The first patch set").build()) .build(), ChangeNotesStateProto.newBuilder() .setMetaId(SHA_BYTES) .setChangeId(ID.get()) .setColumns( <|startfocus|> colsProto.toBuilder() <|endfocus|> .setOriginalSubject("The first patch set") .setHasOriginalSubject(true)) .build()); } @Test public void serializeSubmissionId() throws Exception { assertRoundTrip( newBuilder().columns(cols.toBuilder().submissionId("xyz").build()).build(), ChangeNotesStateProto.newBuilder() .setMetaId(SHA_BYTES) .setChangeId(ID.get()) .setColumns(colsProto.toBuilder().setSubmissionId("xyz").setHasSubmissionId(true)) .build()); } @Test public void serializeAssignee() throws Exception {
<|startcomment|> Should we make this Severe? In this case we are leaving the shared DB into an inconsistent state <|endcomment|>  public void onProjectDeleted(Event event) { String projectName = event.getProjectName(); logger.atInfo().log( "Deleting project '%s'. Will perform a cleanup in Shared-Ref database.", projectName); try { sharedDb.removeProject(projectName); } catch (IOException e) { // TODO: Add metrics for monitoring if it fails to delete <|startfocus|> logger.atWarning().log( <|endfocus|> String.format( "Project '%s' deleted from GIT but it was not able to fully cleanup" + " from Shared-Ref database", projectName), e); }
<|startcomment|> should this flagged as @Nullable? <|endcomment|>  } public void addChange(String id, Map<Change.Id, ChangeResource> changes) throws UnloggedFailure, OrmException, PermissionBackendException, IOException { addChange(id, changes, null); } public void addChange( String id, Map<Change.Id, ChangeResource> changes, ProjectState projectState) throws UnloggedFailure, OrmException, PermissionBackendException, IOException { addChange(id, changes, projectState, true); } public void addChange( String id, Map<Change.Id, ChangeResource> changes, <|startfocus|> ProjectState projectState, <|endfocus|> boolean useIndex) throws UnloggedFailure, OrmException, PermissionBackendException, IOException { List<ChangeNotes> matched = useIndex ? changeFinder.find(id) : changeFromNotesFactory(id); List<ChangeNotes> toAdd = new ArrayList<>(changes.size()); boolean canMaintainServer; try { permissionBackend.currentUser().check(GlobalPermission.MAINTAIN_SERVER); canMaintainServer = true; } catch (AuthException | PermissionBackendException e) { canMaintainServer = false; } for (ChangeNotes notes : matched) { if (!changes.containsKey(notes.getChangeId())
<|startcomment|> Optional: Do we need this constant to be public? <|endcomment|> import java.io.IOException; import java.util.concurrent.ExecutionException; import java.util.concurrent.TimeUnit; /** * Cache of {@link CombinedCheckState} per change. * * <p>In the absence of plugin-defined index fields, this cache is used to performantly populate the * {@code combinedState} field in {@code ChangeCheckInfo} in the query path. */ @Singleton public class CombinedCheckStateCache { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); <|startfocus|> public static final String NAME = "combined_check_state"; <|endfocus|> public static Module module() { return new CacheModule() { @Override public void configure() { persist(NAME, CombinedCheckStateCacheKeyProto.class, CombinedCheckState.class) .version(1) .maximumWeight(10000) .diskLimit(-1) .keySerializer(new ProtobufSerializer<>(CombinedCheckStateCacheKeyProto.parser())) .valueSerializer(new EnumCacheSerializer<>(CombinedCheckState.class)) .loader(Loader.class); } }; } @Singleton static class Metrics {
<|startcomment|> When I first looked at ChangeCheckInfoIT and quite a lot of this class, I was confused what "dirty" should mean. Could we maybe use a different expression? I'm rather thinking of something like "withUpdate" or "updated". <|endcomment|>  // Pair of metric and manual counters, to work around the fact that metric classes have no // getters. private final Timer1<Boolean> reloadLatency; private final AtomicLongMap<Boolean> reloadCount; @Inject Metrics(MetricMaker metricMaker) { reloadLatency = metricMaker.newTimer( "checks/reload_combined_check_state", new Description("Latency for reloading combined check state") .setCumulative() .setUnit(Units.MILLISECONDS), <|startfocus|> Field.ofBoolean("dirty", "whether reloading resulted in updating the cached value")); <|endfocus|> reloadCount = AtomicLongMap.create(); } void recordReload(boolean dirty, long elapsed, TimeUnit timeUnit) { reloadLatency.record(dirty, elapsed, timeUnit); reloadCount.incrementAndGet(dirty); } long getReloadCount(boolean dirty) { return reloadCount.get(dirty); } } private final LoadingCache<CombinedCheckStateCacheKeyProto, CombinedCheckState> cache; private final Loader loader; private final Metrics metrics; @Inject CombinedCheckStateCache( @Named(NAME) LoadingCache<CombinedCheckStateCacheKeyProto, CombinedCheckState> cache, Loader loader,
<|startcomment|> Optional: Use Duration as type and convert it to a pair of long/TimeUnit in this method. <|endcomment|> <|startfocus|> void recordReload(boolean dirty, long elapsed, TimeUnit timeUnit) { reloadLatency.record(dirty, elapsed, timeUnit); reloadCount.incrementAndGet(dirty); <|endfocus|>
<|startcomment|> I guess this is the only reason why 'dirty' is a Boolean instead of a boolean. Can't we just start with "boolean dirty = true" and include a comment saying that we arbitrarily assume that the cache needs an update except if we can determine for sure that it doesn't? <|endcomment|>  CombinedCheckState newState = loader.load(key); CombinedCheckState oldState = cache.getIfPresent(key); if (newState != oldState) { dirty = true; cache.put(key, newState); } else { dirty = false; } return newState; } finally { <|startfocus|> if (dirty == null) { // Exception while loading value, so we don't know if it's dirty. Record a metric anyway, // arbitrarily assuming dirty. dirty = true; } metrics.recordReload(dirty, sw.elapsed(NANOSECONDS), NANOSECONDS); <|endfocus|> } } /** * Update the state in the cache only if it changed. * * <p>This method does a cache lookup followed by a write, which is inherently racy. * Inconsistencies between the cache and the actual state should tend to get fixed up immediately * after a user views the change, since the read path calls {@link #reload(Project.NameKey, * PatchSet.Id)}. * * @param project project containing the change.
<|startcomment|> As this test intends to test the update path, we should rather use the official Java API instead of the test API. <|endcomment|>  assertThat(cache.getStats()).since(start).hasHitCount(1); assertThat(cache.getStats()).since(start).hasMissCount(0); assertThat(cache.getReloadCount(false) - startReloadsFalse).isEqualTo(0); assertThat(cache.getReloadCount(true) - startReloadsTrue).isEqualTo(0); // Set non-required checker to FAILED, updating combined check state to WARNING. <|startfocus|> checkOperations .newCheck(CheckKey.create(project, psId, checkerUuid)) .state(CheckState.FAILED) .upsert(); <|endfocus|> // Incurs reload after updating check state. assertThat(cache.getStats()).since(start).hasHitCount(2); assertThat(cache.getStats()).since(start).hasMissCount(0); assertThat(cache.getReloadCount(false) - startReloadsFalse).isEqualTo(0); assertThat(cache.getReloadCount(true) - startReloadsTrue).isEqualTo(1); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.WARNING)); assertThat(cache.getStats()).since(start).hasHitCount(3); assertThat(cache.getStats()).since(start).hasMissCount(0);
<|startcomment|> Optional: I guess ideally, we would either catch any type of error or none. I don't really see a reason why we would only catch OrmException/StorageException but not an IllegalStateException when trying to load the patch set. Since that aspect is unrelated to the rest of this change, it's probably best to touch this in another change. I would still be interested in your opinion. <|endcomment|> import org.easymock.EasyMock; import org.junit.Test; public class ChecksSubmitRuleTest extends GerritBaseTests { @Test public void loadingCurrentPatchSetFails() throws Exception { ChecksSubmitRule checksSubmitRule = new ChecksSubmitRule(EasyMock.createStrictMock(CombinedCheckStateCache.class)); ChangeData cd = EasyMock.createStrictMock(ChangeData.class); <|startfocus|> expect(cd.project()).andReturn(new Project.NameKey("My-Project")); expect(cd.getId()).andReturn(new Change.Id(1)); expect(cd.currentPatchSet()).andThrow(new OrmException("Fail for test")); <|endfocus|> replay(cd); Collection<SubmitRecord> submitRecords = checksSubmitRule.evaluate(cd, SubmitRuleOptions.defaults()); assertErrorRecord(submitRecords, "failed to load the current patch set of change 1"); } @Test public void getCombinedCheckStateFails() throws Exception { CombinedCheckStateCache cache = EasyMock.createStrictMock(CombinedCheckStateCache.class); expect(cache.reload(anyObject(), anyObject())).andThrow(new OrmException("Fail for test")); replay(cache); ChecksSubmitRule checksSubmitRule = new ChecksSubmitRule(cache); 
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2014 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.events; import com.google.gson.Gson; import com.google.gson.TypeAdapter; import com.google.gson.TypeAdapterFactory; import com.google.gson.reflect.TypeToken; public final class AutoValueAdapterFactory implements TypeAdapterFactory { @SuppressWarnings("unchecked") @Override public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) { Class<? super T> rawType = type.getRawType(); 
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2014 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.events; import com.google.common.base.Supplier; import com.google.gson.Gson; import com.google.gson.GsonBuilder; import com.google.inject.Provider; public class GsonEventDeserializerProvider implements Provider<Gson> { @Override public Gson get() { return new GsonBuilder() .registerTypeAdapter(Event.class, new EventDeserializer()) .registerTypeAdapter(Supplier.class, new SupplierSerializer()) .registerTypeAdapter(Supplier.class, new SupplierDeserializer())
<|startcomment|> You're using the same hard-coded ID for all changes; any reason not to just use the same hard-coded Change-Id as well, and drop this parameter? <|endcomment|> <|startfocus|> private Change newChange(String changeKey) { <|endfocus|> Change change = new Change( Change.key(changeKey), Change.id(1000), Account.id(1000), Branch.nameKey(Project.nameKey("myproject"), "mybranch"), new Timestamp(System.currentTimeMillis())); return change;
<|startcomment|> It would be useful to have all those literals as shared constant fixtures in the test. <|endcomment|>  public void refUpdatedEvent() { RefUpdatedEvent event = new RefUpdatedEvent(); RefUpdateAttribute refUpdatedAttribute = new RefUpdateAttribute(); refUpdatedAttribute.refName = "refs/heads/master"; event.refUpdate = createSupplier(refUpdatedAttribute); <|startfocus|> AccountAttribute accountAttribute = new AccountAttribute(); accountAttribute.email = "some.user@domain.com"; event.submitter = createSupplier(accountAttribute); <|endfocus|> assertThatJsonMap(event) .containsExactly( "submitter", ImmutableMap.of("email", "some.user@domain.com"), "refUpdate", ImmutableMap.of("refName", "refs/heads/master"), "type", "ref-updated", "eventCreatedOn", 1.2543444E9);
<|startcomment|> nit: This seems to be cut of. <|endcomment|>  * @return combined state. */ public static CombinedCheckState combine( ImmutableListMultimap<CheckState, Boolean> statesAndRequired) { CheckStateCount checkStateCount = CheckStateCount.create(statesAndRequired); return combine(checkStateCount); } /** * Combines multiple per-check states into a single combined state based on the count result of * each check state. * * <p>See documentation of specific enum values for precise semantics. * <|startfocus|> * @param checkStateCount count of <|endfocus|> * @return combined state. */ private static CombinedCheckState combine(CheckStateCount checkStateCount) { if (checkStateCount.failedRequiredCount() > 0) { return FAILED; } if (checkStateCount.inProgressOptionalCount() > 0 || checkStateCount.inProgressRequiredCount() > 0) { return IN_PROGRESS; } if (checkStateCount.failedOptionalCount() > 0) { return WARNING; } if (checkStateCount.successfulCount() > 0) { return SUCCESSFUL; } return NOT_RELEVANT; } private final boolean passing; 
<|startcomment|> nit: CheckStateCount <|endcomment|>  * @return whether the state represents a passing state. */ public boolean isPassing() { return passing; } @AutoValue public abstract static class CheckStateCount { /** * Get the count of each {@link CheckState}. * * @param statesAndRequired map of state to a list of booleans, one per check, indicating * whether that particular check is required in the context of a particular change. <|startfocus|> * @return the {@link CheckState} of the given state map. <|endfocus|> */ public static CheckStateCount create( ImmutableListMultimap<CheckState, Boolean> statesAndRequired) { int failedRequiredCount = 0; int failedOptionalCount = 0; int inProgressRequiredCount = 0; int inProgressOptionalCount = 0; int successfulCount = 0; for (Map.Entry<CheckState, Boolean> e : statesAndRequired.entries()) { CheckState state = e.getKey(); if (state.isInProgress()) { if (e.getValue()) { inProgressRequiredCount++; } else {
<|startcomment|> optional: I know that this code was copied but we should really not use 'e' as variable name for non-exceptions. <|endcomment|>  * whether that particular check is required in the context of a particular change. * @return the {@link CheckState} of the given state map. */ public static CheckStateCount create( ImmutableListMultimap<CheckState, Boolean> statesAndRequired) { int failedRequiredCount = 0; int failedOptionalCount = 0; int inProgressRequiredCount = 0; int inProgressOptionalCount = 0; int successfulCount = 0; <|startfocus|> for (Map.Entry<CheckState, Boolean> e : statesAndRequired.entries()) { CheckState state = e.getKey(); <|endfocus|> if (state.isInProgress()) { if (e.getValue()) { inProgressRequiredCount++; } else { inProgressOptionalCount++; } } else if (state == CheckState.FAILED) { if (e.getValue()) { failedRequiredCount++; } else { failedOptionalCount++; } } else if (state == CheckState.SUCCESSFUL) { successfulCount++; } else if (state != CheckState.NOT_RELEVANT) {
<|startcomment|> Optional: What about 'allRequiredChecksPass' as name instead? <|endcomment|>  public Collection<SubmitRecord> evaluate(ChangeData changeData, SubmitRuleOptions options) { Project.NameKey project = changeData.project(); Change.Id changeId = changeData.getId(); <|startfocus|> // Gets all check results of the given change. ImmutableMap<String, CheckInfo> checks; <|endfocus|> try { checks = listChecks .getAllChecks(project, changeData.notes(), changeData.currentPatchSet().getId()) .stream() .collect(ImmutableMap.toImmutableMap(c -> c.checkerUuid, c -> c)); } catch (OrmException | IOException e) { String errorMessage = String.format("failed to get all checks for change %s", changeId); logger.atSevere().withCause(e).log(errorMessage); return singletonRecordForRuleError(errorMessage); } // Gets all checkers applicable to the given change. ImmutableMap<String, Checker> appliedCheckers; try { appliedCheckers = checkers .checkersOf(project) .stream() .collect(ImmutableMap.toImmutableMap(c -> c.getUuid().toString(), c -> c)); } catch (IOException e) {
<|startcomment|> I think the name is not very clear. Probably something like "doesRefNeedClusterSynchronisation" would do (my name proposal will force you to revert the logic though) <|endcomment|>  * * @param projectName project to be enforced * @param refName ref name to be enforced * @return the {@link EnforcePolicy} value */ public EnforcePolicy getPolicy(String projectName, String refName); /** * Get the enforcement policy for a project * * @param projectName * @return the {@link EnforcePolicy} value */ public EnforcePolicy getPolicy(String projectName); <|startfocus|> default boolean ignoreRefInSharedDb(String refName) { <|endfocus|> return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } } 
<|startcomment|> Should this be LibModuleType.DB_MODULE? Like it was done in SiteProgram#createDbInjector() where LibModuleType.DB_MODULE was used: return Guice.createInjector( PRODUCTION, ModuleOverloader.override( modules, LibModuleLoader.loadModules(cfgInjector, LibModuleType.DB_MODULE))); <|endcomment|>  Module sitePathModule = new AbstractModule() { @Override protected void configure() { bind(Path.class).annotatedWith(SitePath.class).toInstance(sitePath); } }; modules.add(sitePathModule); Module configModule = new GerritServerConfigModule(); modules.add(configModule); } else { modules.add(new GerritServerConfigModule()); } modules.add(new DropWizardMetricMaker.ApiModule()); return Guice.createInjector( <|startfocus|> PRODUCTION, LibModuleLoader.loadModules(cfgInjector, LibModuleType.SYS_MODULE)); <|endfocus|>
<|startcomment|> Could be skipped or changed to "Gerrit server", because when WebAppInitializer is used, no daemon is used at all. <|endcomment|> // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server; <|startfocus|> /** Loadable module type for the different Gerrit daemon injectors. */ <|endfocus|> public enum LibModuleType { /** Module for the sysInjector. */ SYS_MODULE("Module"), /** Module for the dbInjector. */ DB_MODULE("DbModule"); private final String configKey; LibModuleType(String configKey) { this.configKey = configKey; } /** * Returns the module type for loading from gerrit.config. * * @return module type string */ public String getConfigKey() { return configKey; } } 
<|startcomment|> Better: "type for libModule loaded from <gerrit_site/lib> directory. <|endcomment|> // limitations under the License. package com.google.gerrit.server; /** Loadable module type for the different Gerrit daemon injectors. */ public enum LibModuleType { /** Module for the sysInjector. */ SYS_MODULE("Module"), /** Module for the dbInjector. */ DB_MODULE("DbModule"); private final String configKey; LibModuleType(String configKey) { this.configKey = configKey; } /** <|startfocus|> * Returns the module type for loading from gerrit.config. <|endfocus|> * * @return module type string */ public String getConfigKey() { return configKey; } } 
<|startcomment|> Is this still thrown? <|endcomment|>  * an infinite forwarding loop between the 2 nodes. It will also make sure no concurrent indexing is * done for the same account id */ @Singleton public class ForwardedIndexAccountHandler extends ForwardedIndexingHandler<Account.Id> { private final AccountIndexer indexer; @Inject ForwardedIndexAccountHandler(AccountIndexer indexer, Configuration config) { super(config.index()); this.indexer = indexer; } @Override <|startfocus|> protected void doIndex(Account.Id id, Optional<IndexEvent> indexEvent) throws IOException { <|endfocus|> indexer.index(id); log.atFine().log("Account %s successfully indexed", id); } @Override protected void doDelete(Account.Id id, Optional<IndexEvent> indexEvent) { throw new UnsupportedOperationException("Delete from account index not supported"); } } 
<|startcomment|> This cast is not needed. Eclipse warns on this line: "Unnecessary cast from int to double.". <|endcomment|> import com.google.gerrit.testing.TestTimeUtil; import com.google.gson.Gson; import com.google.gson.GsonBuilder; import com.google.gson.reflect.TypeToken; import java.util.Map; import java.util.concurrent.TimeUnit; import org.junit.Before; import org.junit.Test; public class EventJsonTest extends GerritBaseTests { private static final String BRANCH = "mybranch"; private static final String CHANGE_ID = "Ideadbeefdeadbeefdeadbeefdeadbeefdeadbeef"; private static final int CHANGE_NUM = 1000; <|startfocus|> private static final double CHANGE_NUM_DOUBLE = (double) CHANGE_NUM; <|endfocus|> private static final String COMMIT_MESSAGE = "This is a test commit message"; private static final String PROJECT = "myproject"; private static final String REF = "refs/heads/" + BRANCH; private static final double TS1 = 1.2543444E9; private static final double TS2 = 1.254344401E9; private static final String URL = "http://somewhere.com"; // Must match StreamEvents#gson. (In master, the definition is refactored to be hared.) private final Gson gson = new GsonBuilder()
<|startcomment|> should this be final? <|endcomment|> // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb; import com.google.common.base.MoreObjects; import com.google.common.collect.ImmutableMap; import com.google.common.flogger.FluentLogger; import java.util.HashMap; import java.util.List; import java.util.Map; public class CustomSharedRefEnforcementByProject implements SharedRefEnforcement { <|startfocus|> private static String ALL = ".*"; <|endfocus|> private final Map<String, Map<String, EnforcePolicy>> PREDEF_ENFORCEMENTS; private final FluentLogger logger = FluentLogger.forEnclosingClass(); public CustomSharedRefEnforcementByProject(List<String> enforcementRules) { logger.atInfo().log( String.format( "Running with Custom Shared Ref-Db Enforcement Policy with follosing rules %s", enforcementRules.toString())); this.PREDEF_ENFORCEMENTS = parseDryRunEnforcementsToMap(enforcementRules); } private Map<String, Map<String, EnforcePolicy>> parseDryRunEnforcementsToMap( List<String> dryRunRefEnforcement) {
<|startcomment|> Why are we catching 'e' and then throwing it again? Aren't AssertionError unchecked? they probably won't need handling... <|endcomment|>  assert (refAndPolicy.length == 2); String refName = refAndPolicy[0].trim().isEmpty() ? ALL : refAndPolicy[0].trim(); Map<String, EnforcePolicy> existingOrDefaultRef = projectAndRefsEnforcements.getOrDefault(projectName, new HashMap<>()); existingOrDefaultRef.put( refName, EnforcePolicy.valueOf(refAndPolicy[1].trim().toUpperCase())); <|startfocus|> projectAndRefsEnforcements.put(projectName, existingOrDefaultRef); } } catch (AssertionError e) { throw e; <|endfocus|> } return projectAndRefsEnforcements; } @Override public EnforcePolicy getPolicy(String projectName, String refName) { if (isRefToBeIgnoredBySharedRefDb(refName)) { return EnforcePolicy.IGNORED; } return getRefEnforcePolicy(projectName, refName); } private EnforcePolicy getRefEnforcePolicy(String projectName, String refName) { if (!PREDEF_ENFORCEMENTS.containsKey(projectName) && PREDEF_ENFORCEMENTS.containsKey(ALL)) { return PREDEF_ENFORCEMENTS.get(ALL).getOrDefault(refName, EnforcePolicy.REQUIRED); } EnforcePolicy policyFromProjectRefOrProjectAllRefs =
<|startcomment|> will projectName always exist in the map? Otherwise you'll get a NEP <|endcomment|>  private EnforcePolicy getRefEnforcePolicy(String projectName, String refName) { if (!PREDEF_ENFORCEMENTS.containsKey(projectName) && PREDEF_ENFORCEMENTS.containsKey(ALL)) { return PREDEF_ENFORCEMENTS.get(ALL).getOrDefault(refName, EnforcePolicy.REQUIRED); } EnforcePolicy policyFromProjectRefOrProjectAllRefs = <|startfocus|> PREDEF_ENFORCEMENTS.get(projectName).get(refName) == null ? PREDEF_ENFORCEMENTS.get(projectName).get(ALL) : PREDEF_ENFORCEMENTS.get(projectName).get(refName); <|endfocus|> return MoreObjects.firstNonNull(policyFromProjectRefOrProjectAllRefs, EnforcePolicy.REQUIRED);
<|startcomment|> perhaps is more readable? Optional.ofNullable(...).orElse(defaultValue); <|endcomment|>  private EnforcePolicy getRefEnforcePolicy(String projectName, String refName) { if (!PREDEF_ENFORCEMENTS.containsKey(projectName) && PREDEF_ENFORCEMENTS.containsKey(ALL)) { return PREDEF_ENFORCEMENTS.get(ALL).getOrDefault(refName, EnforcePolicy.REQUIRED); } EnforcePolicy policyFromProjectRefOrProjectAllRefs = <|startfocus|> PREDEF_ENFORCEMENTS.get(projectName).get(refName) == null ? PREDEF_ENFORCEMENTS.get(projectName).get(ALL) : PREDEF_ENFORCEMENTS.get(projectName).get(refName); <|endfocus|> return MoreObjects.firstNonNull(policyFromProjectRefOrProjectAllRefs, EnforcePolicy.REQUIRED);
<|startcomment|> isUpToDate? <|endcomment|>  * @throws IOException */ default boolean compareAndCreate(String project, Ref newRef) throws IOException { return compareAndPut(project, NULL_REF, newRef); } /** * Verify in shared db if Ref is the most recent * * @param project project name of the ref * @param ref to be checked against shared-ref db * @return true if it is; false otherwise */ <|startfocus|> boolean isMostRecentRefVersion(String project, Ref ref) throws IOException; <|endfocus|> /** * Compare a reference, and put if it matches. * * <p>Two reference match if and only if they satisfy the following: * * <ul> * <li>If one reference is a symbolic ref, the other one should be a symbolic ref. * <li>If both are symbolic refs, the target names should be same. * <li>If both are object ID refs, the object IDs should be same. * </ul> * * @param project project name of the ref
<|startcomment|> JavaDoc missing <|endcomment|>  /** * Compare a reference, and delete if it matches. * * @param project project name of the ref * @param oldRef the old reference information that was previously read. * @return true if the remove was successful; false otherwise. * @throws java.io.IOException the reference could not be removed due to a system error. */ boolean compareAndRemove(String project, Ref oldRef) throws IOException; <|startfocus|> AutoCloseable lockRef(String projectName, Ref ref) throws IOException; <|endfocus|> /** * Some references should not be stored in the SharedRefDatabase. * * @param refName * @return true if it's to be ignore; false otherwise */ default boolean ignoreRefInSharedDb(String refName) { return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } /** * Verify if the DB contains a value for the specific project and ref name *
<|startcomment|> use a consistent parameter name for the project's name, in other methods you name this "project" <|endcomment|>  /** * Compare a reference, and delete if it matches. * * @param project project name of the ref * @param oldRef the old reference information that was previously read. * @return true if the remove was successful; false otherwise. * @throws java.io.IOException the reference could not be removed due to a system error. */ boolean compareAndRemove(String project, Ref oldRef) throws IOException; <|startfocus|> AutoCloseable lockRef(String projectName, Ref ref) throws IOException; <|endfocus|> /** * Some references should not be stored in the SharedRefDatabase. * * @param refName * @return true if it's to be ignore; false otherwise */ default boolean ignoreRefInSharedDb(String refName) { return refName == null || refName.startsWith("refs/draft-comments") || (refName.startsWith("refs/changes") && !refName.endsWith("/meta")); } /** * Verify if the DB contains a value for the specific project and ref name *
<|startcomment|> nit: unreleated space change <|endcomment|> import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.recipes.atomic.AtomicValue; import org.apache.curator.framework.recipes.atomic.DistributedAtomicValue; import org.apache.curator.framework.recipes.locks.InterProcessMutex; import org.apache.curator.framework.recipes.locks.Locker; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; public class ZkSharedRefDatabase implements SharedRefDatabase { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final CuratorFramework client; private final RetryPolicy retryPolicy; <|startfocus|> private final SharedRefEnforcement refEnforcement; <|endfocus|> private final Long transactionLockTimeOut; @Inject public ZkSharedRefDatabase( CuratorFramework client, ZkConnectionConfig connConfig, SharedRefEnforcement refEnforcement) { this.client = client; this.retryPolicy = connConfig.curatorRetryPolicy; this.transactionLockTimeOut = connConfig.transactionLockTimeout; this.refEnforcement = refEnforcement; } @Override public boolean isMostRecentRefVersion(String project, Ref ref) throws IOException { if (!exists(project, ref.getName())) { logger.atWarning().log(
<|startcomment|> Can be inlined at L73 <|endcomment|>  "Checking if this ref %s is the most recent, but not present in sharedDb, assuming " + "this is an old reference in Gerrit. Returning true", ref.getName()); return true; } try { final byte[] valueInZk = client.getData().forPath(pathFor(project, ref.getName())); // Assuming this is a delete node NULL_REF if (valueInZk == null) return false; <|startfocus|> final ObjectId objectIdInZk = readObjectId(valueInZk); return objectIdInZk.equals(ref.getObjectId()); <|endfocus|> } catch (Exception e) { throw new IOException( String.format("Unable to read data for path %s", pathFor(project, ref.getName())), e); } } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean exists(String projectName, String refName) throws IOException { try {
<|startcomment|> Missing @Override annotation <|endcomment|>  } @Override public boolean compareAndRemove(String project, Ref oldRef) throws IOException { return compareAndPut(project, oldRef, NULL_REF); } @Override public boolean exists(String projectName, String refName) throws IOException { try { return client.checkExists().forPath(pathFor(projectName, refName)) != null; } catch (Exception e) { throw new IOException("Failed to check if path exists in Zookeeper", e); } } <|startfocus|> public Locker lockRef(String projectName, Ref ref) throws IOException { <|endfocus|> InterProcessMutex refPathMutex = new InterProcessMutex(client, "/locks" + pathFor(projectName, ref.getName())); try { return new Locker(refPathMutex, transactionLockTimeOut, MILLISECONDS); } catch (Exception e) { throw new IOException("Failed to create lock in ZK", e); } } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { EnforcePolicy enforcementPolicy = refEnforcement.getPolicy(
<|startcomment|> This is more a lock-related exception: can we find something more relevant? <|endcomment|>  } catch (Exception e) { throw new IOException("Failed to check if path exists in Zookeeper", e); } } public Locker lockRef(String projectName, Ref ref) throws IOException { InterProcessMutex refPathMutex = new InterProcessMutex(client, "/locks" + pathFor(projectName, ref.getName())); try { return new Locker(refPathMutex, transactionLockTimeOut, MILLISECONDS); } catch (Exception e) { <|startfocus|> throw new IOException("Failed to create lock in ZK", e); <|endfocus|> } } @Override public boolean compareAndPut(String projectName, Ref oldRef, Ref newRef) throws IOException { EnforcePolicy enforcementPolicy = refEnforcement.getPolicy( projectName, MoreObjects.firstNonNull(oldRef.getName(), newRef.getName())); if (enforcementPolicy == EnforcePolicy.IGNORED) { return true; } final DistributedAtomicValue distributedRefValue = new DistributedAtomicValue(client, pathFor(projectName, oldRef, newRef), retryPolicy); try { if (oldRef == NULL_REF) { return distributedRefValue.initialize(writeObjectId(newRef.getObjectId()));
<|startcomment|> /projectName/project ... for consistency <|endcomment|> import org.eclipse.jgit.lib.ProgressMonitor; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.transport.PushCertificate; import org.eclipse.jgit.transport.ReceiveCommand; import org.eclipse.jgit.util.time.ProposedTimestamp; public class MultiSiteBatchRefUpdate extends BatchRefUpdate { private final BatchRefUpdate batchRefUpdate; private final String projectName; private final RefUpdateValidator.Factory batchRefValidatorFactory; private final RefDatabase refDb; public static interface Factory { <|startfocus|> MultiSiteBatchRefUpdate create(String projectName, RefDatabase refDb); <|endfocus|> } @Inject public MultiSiteBatchRefUpdate( RefUpdateValidator.Factory batchRefValidatorFactory, @Assisted String projectName, @Assisted RefDatabase refDb) { super(refDb); this.refDb = refDb; this.projectName = projectName; this.batchRefUpdate = refDb.newBatchUpdate(); this.batchRefValidatorFactory = batchRefValidatorFactory; } @Override public int hashCode() { return batchRefUpdate.hashCode(); } @Override public boolean equals(Object obj) { return batchRefUpdate.equals(obj); } @Override
<|startcomment|> Why returning null? Let's just define a void functional interface instead. <|endcomment|>  } @Override public List<ProposedTimestamp> getProposedTimestamps() { return batchRefUpdate.getProposedTimestamps(); } @Override public BatchRefUpdate addProposedTimestamp(ProposedTimestamp ts) { return batchRefUpdate.addProposedTimestamp(ts); } @Override public void execute(RevWalk walk, ProgressMonitor monitor, List<String> options) throws IOException { batchRefValidatorFactory .create(projectName, refDb) .executeBatchUpdateWithValidation( <|startfocus|> batchRefUpdate, () -> { batchRefUpdate.execute(walk, monitor, options); return null; }); <|endfocus|> } @Override public void execute(RevWalk walk, ProgressMonitor monitor) throws IOException { batchRefValidatorFactory .create(projectName, refDb) .executeBatchUpdateWithValidation( batchRefUpdate, () -> { batchRefUpdate.execute(walk, monitor); return null; }); } @Override public String toString() { return batchRefUpdate.toString(); } } 
<|startcomment|> Same as above. <|endcomment|>  throws IOException { batchRefValidatorFactory .create(projectName, refDb) .executeBatchUpdateWithValidation( batchRefUpdate, () -> { batchRefUpdate.execute(walk, monitor, options); return null; }); } @Override public void execute(RevWalk walk, ProgressMonitor monitor) throws IOException { batchRefValidatorFactory .create(projectName, refDb) .executeBatchUpdateWithValidation( <|startfocus|> batchRefUpdate, () -> { batchRefUpdate.execute(walk, monitor); return null; }); <|endfocus|> } @Override public String toString() { return batchRefUpdate.toString(); } } 
<|startcomment|> Why nullable? <|endcomment|>  public RefUpdateValidator( SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, <|startfocus|> @Nullable @Assisted RefDatabase refDb) { <|endfocus|> this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement;
<|startcomment|> The code below tells the same story: comment is redundant. <|endcomment|>  } public String getName() { return MoreObjects.firstNonNull( oldRef == null ? null : oldRef.getName(), newRef == null ? null : newRef.getName()); } public boolean hasFailed() { return exception != null; } } protected void executeBatchUpdateWithPolicy( String errorMessage, BatchValidationWrapper delegateValidation, BatchRefUpdate batchRefUpdate, NoParameterVoidFunction gitUpdateFun) throws IOException { <|startfocus|> // If ignored we just do the GIT update <|endfocus|> if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } protected RefUpdate.Result executeRefUpdateWithPolicy( String errorMessage, RefValidationWrapper delegateValidation, RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> gitUpdateFun) throws IOException {
<|startcomment|> The batch refupdate could fail for a genuine JGit-related IOException and that *cannot be* ignored based on the enforcement policy. <|endcomment|>  String errorMessage, BatchValidationWrapper delegateValidation, BatchRefUpdate batchRefUpdate, NoParameterVoidFunction gitUpdateFun) throws IOException { // If ignored we just do the GIT update if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { <|startfocus|> delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } <|endfocus|> protected RefUpdate.Result executeRefUpdateWithPolicy( String errorMessage, RefValidationWrapper delegateValidation, RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> gitUpdateFun) throws IOException { // If ignored we just do the GIT update if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { return gitUpdateFun.apply(); } try { return delegateValidation.apply(gitUpdateFun, refUpdate); } catch (IOException e) { if (e.getClass() == SharedDbSplitBrainException.class) {
<|startcomment|> The code below tells the same story: comment is redundant. <|endcomment|>  return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } protected RefUpdate.Result executeRefUpdateWithPolicy( String errorMessage, RefValidationWrapper delegateValidation, RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> gitUpdateFun) throws IOException { <|startfocus|> // If ignored we just do the GIT update <|endfocus|> if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { return gitUpdateFun.apply(); } try { return delegateValidation.apply(gitUpdateFun, refUpdate); } catch (IOException e) { if (e.getClass() == SharedDbSplitBrainException.class) { validationMetrics.incrementSplitBrain(); } logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } return null; } 
<|startcomment|> This is a super-complex way to check for errors. Additionally, the warning and exception is only on the first problem, ignoring all the others. <|endcomment|>  List<RefPair> refsToUpdate = getRefsPairs(commands) .sorted(comparing(RefPair::hasFailed).reversed()) .collect(Collectors.toList()); if (refsToUpdate.isEmpty()) { return; } if (refsToUpdate.get(0).hasFailed()) { RefPair failedRef = refsToUpdate.get(0); logger.atWarning().withCause(failedRef.exception).log("Failed to fetch ref entries"); throw new IOException( "Failed to fetch ref entries" + failedRef.newRef.getName(), failedRef.exception); <|startfocus|> } <|endfocus|> Map<ObjectId, Ref> oldRefsMap = refsToUpdate.stream() .collect( Collectors.toMap( refPair -> refPair.newRef.getObjectId(), refPair -> refPair.oldRef)); try (CloseableSet<AutoCloseable> locks = new CloseableSet()) { assertRefPairsAreInSyncWithSharedDb(refsToUpdate, locks); delegateUpdate.apply(); updateSharedRefDbForSuccessfulCommands(batchRefUpdate.getCommands().stream(), oldRefsMap); } } private void updateSharedRefDbForSuccessfulCommands(
<|startcomment|> This is wrong, it should be the current ref in the local refdb <|endcomment|> <|startfocus|> protected RefPair newRefPairFrom(RefUpdate refUpdate) { return new RefPair( refUpdate.getRef(), sharedRefDb.newRef(refUpdate.getName(), refUpdate.getNewObjectId())); <|endfocus|>
<|startcomment|> Why creating a new ref? we already have the new ref that is refUpdate.getRef(). <|endcomment|> <|startfocus|> protected RefPair newRefPairFrom(RefUpdate refUpdate) { return new RefPair( refUpdate.getRef(), sharedRefDb.newRef(refUpdate.getName(), refUpdate.getNewObjectId())); <|endfocus|>
<|startcomment|> Is this really nullable? What's the point of doing a ref-update validator without a refdb? <|endcomment|>  public BatchRefUpdateValidator( SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, <|startfocus|> @Nullable @Assisted RefDatabase refDb) { <|endfocus|> super(sharedRefDb, validationMetrics, refEnforcement, projectName, refDb);
<|startcomment|> Is this really nullable? What's the point of having a refupdate validator without a refdb? <|endcomment|>  public RefUpdateValidator( SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, <|startfocus|> @Nullable @Assisted RefDatabase refDb) { <|endfocus|> this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement;
<|startcomment|> Public methods first, then protected and finally private. <|endcomment|>  protected final SharedRefEnforcement refEnforcement; public static interface Factory { RefUpdateValidator create(String projectName, RefDatabase refDb); } @Inject public RefUpdateValidator( SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Nullable @Assisted RefDatabase refDb) { this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement; } <|startfocus|> protected void executeBatchUpdateWithPolicy( String errorMessage, BatchValidationWrapper delegateValidation, BatchRefUpdate batchRefUpdate, NoParameterVoidFunction gitUpdateFun) <|endfocus|> throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } 
<|startcomment|> This method has only 1 caller and this is only 1 function: seems a bit of an abuse parameterising something that at the end is not changing at all. Inline the function into the method. <|endcomment|>  RefUpdateValidator create(String projectName, RefDatabase refDb); } @Inject public RefUpdateValidator( SharedRefDatabase sharedRefDb, ValidationMetrics validationMetrics, SharedRefEnforcement refEnforcement, @Assisted String projectName, @Nullable @Assisted RefDatabase refDb) { this.sharedRefDb = sharedRefDb; this.validationMetrics = validationMetrics; this.refDb = refDb; this.projectName = projectName; this.refEnforcement = refEnforcement; } <|startfocus|> protected void executeBatchUpdateWithPolicy( String errorMessage, BatchValidationWrapper delegateValidation, BatchRefUpdate batchRefUpdate, NoParameterVoidFunction gitUpdateFun) <|endfocus|> throws IOException { if (refEnforcement.getPolicy(projectName) == EnforcePolicy.IGNORED) { gitUpdateFun.apply(); return; } try { delegateValidation.apply(batchRefUpdate, gitUpdateFun); } catch (IOException e) { logger.atWarning().withCause(e).log(errorMessage); if (refEnforcement.getPolicy(projectName) == EnforcePolicy.REQUIRED) { throw e; } } } protected RefUpdate.Result executeRefUpdateWithPolicy( String errorMessage, RefValidationWrapper delegateValidation,
<|startcomment|> This is incorrect: we should check if the ref on the local refdb is uptodate with the one on the shared refdb. The ref of the old commit in the local repo of the Git push is irrelevant with regards to split-brain prevention. <|endcomment|>  try { locks.addResourceIfNotExist( resourceLockKey, () -> sharedRefDb.lockRef(projectName, nonNullRef)); } catch (Exception e) { throw new IOException( String.format( "Unable to prepare locks for project %s and reference %s", projectName, nonNullRef.getName()), e); } boolean isInSync; <|startfocus|> if (refPair.oldRef != sharedRefDb.NULL_REF && refPair.oldRef != null) { isInSync = sharedRefDb.isUpToDate(projectName, refPair.oldRef); <|endfocus|> } else { isInSync = !sharedRefDb.exists(projectName, refPair.getName()); } if (!isInSync) { failWith( new IOException( String.format( "Ref '%s' for project '%s' not in sync with shared Ref-Db." + "Trying to change the Ref-Db from oldRefId '%s'" + " to newRefId '%s'. Aborting batch update.", refPair.getName(), projectName, refPair.oldRef.getObjectId(),
<|startcomment|> This entire suite of tests is breaking when the code is correct, whilst is passing when it isn't, which isn't a great. These tests are half-e2e and half-mocked, which is also not great at all. To be refactored as IT-test and make it right. <|endcomment|> import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper.RefUpdateStub; import java.io.IOException; import org.eclipse.jgit.lib.ObjectIdRef; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.lib.RefUpdate; import org.eclipse.jgit.lib.RefUpdate.Result; import org.junit.Before; import org.junit.Rule; import org.junit.Test; import org.junit.rules.TestName; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.junit.MockitoJUnitRunner; <|startfocus|> @RunWith(MockitoJUnitRunner.class) <|endfocus|> public class MultiSiteRefUpdateTest implements RefFixture { @Mock SharedRefDatabase sharedRefDb; @Mock ValidationMetrics validationMetrics; private final Ref oldRef = new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, A_TEST_REF_NAME, AN_OBJECT_ID_1); private final Ref newRef = new ObjectIdRef.Unpeeled(Ref.Storage.NETWORK, A_TEST_REF_NAME, AN_OBJECT_ID_2); @Rule public TestName nameRule = new TestName(); @Override public String testBranch() { return "branch_" + nameRule.getMethodName(); } @Before
<|startcomment|> We can't read the refPairt again *after* the operation, because the local ref has been modified and thus won't reflect the current status in shared-refdb. We need to get the pair at the beginning, after the lock, and stick with it. <|endcomment|>  if (policy == EnforcePolicy.REQUIRED) { throw e; } } protected RefUpdate.Result doExecuteRefUpdate( RefUpdate refUpdate, NoParameterFunction<RefUpdate.Result> refUpdateFunction) throws IOException { try (CloseableSet<AutoCloseable> locks = new CloseableSet<>()) { checkIfLocalRefIsUpToDateWithSharedRefDb(newRefPairFrom(refUpdate).getName(), locks); RefUpdate.Result result = refUpdateFunction.invoke(); if (isSuccessful(result)) { <|startfocus|> updateSharedDbOrThrowExceptionFor(newRefPairFrom(refUpdate)); <|endfocus|> } return result; } } protected void updateSharedDbOrThrowExceptionFor(RefPair refPair) throws IOException { // We are not checking refs that should be ignored final EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refPair.getName()); if (refEnforcementPolicy == EnforcePolicy.IGNORED) return; String errorMessage = String.format( "Not able to persist the data in Zookeeper for project '%s' and ref '%s'," + "the cluster is now in Split Brain since the commit has been "
<|startcomment|> This looks wrong, errMsg is no longer checked. <|endcomment|>  assertThat(created.ref).isEqualTo(branch.branch()); } private void assertCreateFails( BranchNameKey branch, Class<? extends RestApiException> errType, String errMsg) throws Exception { assertCreateFails(branch, null, errType, errMsg); } private void assertCreateFails( BranchNameKey branch, String revision, Class<? extends RestApiException> errType, String errMsg) throws Exception { BranchInput in = new BranchInput(); in.revision = revision; <|startfocus|> if (errMsg != null) {} assertThrows(errType, () -> branch(branch).create(in)); <|endfocus|> } private void assertCreateFails(BranchNameKey branch, Class<? extends RestApiException> errType) throws Exception { assertCreateFails(branch, errType, null); } } 
<|startcomment|> This is also a post submit review (submit is done above in l. 262) <|endcomment|>  } @Test public void customLabel_DisallowPostSubmit() throws Exception { label.setFunction(NO_OP); label.setAllowPostSubmit(false); P.setFunction(NO_OP); saveLabelConfig(); PushOneCommit.Result r = createChange(); revision(r).review(ReviewInput.approve()); revision(r).submit(); ChangeInfo info = getWithLabels(r); assertPermitted(info, "Code-Review", 2); assertPermitted(info, P.getName(), 0, 1); assertPermitted(info, label.getName()); <|startfocus|> ReviewInput preSubmitReview = new ReviewInput(); preSubmitReview.label(P.getName(), P.getMax().getValue()); revision(r).review(preSubmitReview); <|endfocus|> ReviewInput postSubmitReview = new ReviewInput(); postSubmitReview.label(label.getName(), label.getMax().getValue()); ResourceConflictException thrown = assertThrows(ResourceConflictException.class, () -> revision(r).review(postSubmitReview)); assertThat(thrown) .hasMessageThat() .contains("Voting on labels disallowed after submit: " + label.getName()); } @Test public void customLabelWithUserPermissionChange() throws Exception {
<|startcomment|> missing parenthesis <|endcomment|>  staticPath = cdnPath; } else if (canonicalPath != null) { staticPath = canonicalPath; } // The resource path must be typed as safe for use in a script src. // TODO(wyatta): Upgrade this to use an appropriate safe URL type. SanitizedContent sanitizedStaticPath = UnsafeSanitizedContentOrdainer.ordainAsSafe( staticPath, SanitizedContent.ContentKind.TRUSTED_RESOURCE_URI); Map data = new HashMap<>(); data.put("canonicalPath", canonicalPath); <|startfocus|> data.put("staticResourcePath", sanitizedStaticPath; <|endfocus|> data.put("faviconPath", faviconPath); return data; } } 
<|startcomment|> This will cause a warning about generic types. Can this be Map<String, Object> or Map<String, ?> instead? <|endcomment|>  String staticPath = ""; if (cdnPath != null) { staticPath = cdnPath; } else if (canonicalPath != null) { staticPath = canonicalPath; } // The resource path must be typed as safe for use in a script src. // TODO(wyatta): Upgrade this to use an appropriate safe URL type. SanitizedContent sanitizedStaticPath = UnsafeSanitizedContentOrdainer.ordainAsSafe( staticPath, SanitizedContent.ContentKind.TRUSTED_RESOURCE_URI); <|startfocus|> Map data = new HashMap<>(); <|endfocus|> data.put("canonicalPath", canonicalPath); data.put("staticResourcePath", sanitizedStaticPath); data.put("faviconPath", faviconPath); return data; } } 
<|startcomment|> Why do we need sandboxed tests? <|endcomment|> // implied. // See the License for the specific language governing permissions and // limitations under the License. package com.vmware.gerrit.owners.common; import static org.junit.Assert.assertEquals; import com.google.gerrit.acceptance.LightweightPluginDaemonTest; import com.google.gerrit.acceptance.Sandboxed; import com.google.gerrit.acceptance.TestPlugin; import com.google.gerrit.extensions.events.GitReferenceUpdatedListener; import com.google.gerrit.reviewdb.client.RefNames; import com.google.inject.AbstractModule; import org.eclipse.jgit.transport.ReceiveCommand.Type; import org.junit.Test; <|startfocus|> @Sandboxed <|endfocus|> @TestPlugin( name = "owners-autoassign", sysModule = "com.vmware.gerrit.owners.common.GitRefListenerIT$TestModule") public class GitRefListenerIT extends LightweightPluginDaemonTest { public static class TestModule extends AbstractModule { @Override protected void configure() { bind(GitReferenceUpdatedListener.class).to(TestGitRefListener.class); } } @Test public void shouldNotProcessNoteDbOnlyRefs() { TestGitRefListener gitRefListener = getPluginInstance(TestGitRefListener.class); String aRefChange = RefNames.REFS_CHANGES + "01/01" + RefNames.META_SUFFIX;
<|startcomment|> Optional: Use a ternary here, like at L79 and L83 <|endcomment|>  builder.setGroups(PatchSet.joinGroups(groups)); } patchSet.getPushCertificate().ifPresent(builder::setPushCertificate); patchSet.getDescription().ifPresent(builder::setDescription); return builder.build(); } @Override public PatchSet fromProto(Entities.PatchSet proto) { <|startfocus|> PatchSet.Builder builder = PatchSet.builder().id(patchSetIdConverter.fromProto(proto.getId())); if (proto.hasGroups()) { builder.groups(PatchSet.splitGroups(proto.getGroups())); } else { builder.groups(ImmutableList.of()); } <|endfocus|> if (proto.hasPushCertificate()) { builder.pushCertificate(proto.getPushCertificate()); } if (proto.hasDescription()) { builder.description(proto.getDescription()); } // The following fields used to theoretically be nullable in PatchSet, but in practice no // production codepath should have ever serialized an instance that was missing one of these // fields. // // However, since some protos may theoretically be missing these fields, we need to support // them. Populate specific sentinel values for each field as documented in the PatchSet javadoc.
<|startcomment|> Various scenarios should be separate tests. <|endcomment|> // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.manager; import static com.google.common.truth.Truth.assertThat; import static com.googlesource.gerrit.plugins.manager.GerritVersionBranch.getBranch; import org.junit.Test; public class GerritVersionBranchTest { @Test <|startfocus|> public void getBranchReturnsCorrectBranchForVersion() throws Exception { <|endfocus|> // Regular 2.x versions assertBranch("2.13", "stable-2.13"); assertBranch("2.14", "stable-2.14"); assertBranch("2.15", "stable-2.15"); assertBranch("2.16", "stable-2.16"); // 2.x.y version assertBranch("2.16.10", "stable-2.16"); // 2.x-rcx version assertBranch("2.16-rc1", "stable-2.16"); // 3.0.0 version assertBranch("3.0.0", "stable-3.0"); 
<|startcomment|> s/delegate/delegate.doFilter/ <|endcomment|>  * } * * public int getHttpStatusCode() { * return httpStatusCode; * } * } * * public class MyErrorHandlingFilter extends AbstractHttpFilter { * private static final DefaultErrorHandlingFilter delegate = * new DefaultErrorHandlingFilter(); * * {@literal @}Override * public void doFilter(HttpServletRequest req, HttpServletResponse res, FilterChain chain) * throws IOException, ServletException { * try { <|startfocus|> * delegate(req, res, chain); <|endfocus|> * } catch (MyRequestFailureException e) { * res.setHeader(DefaultErrorHandlingFilter.GITILES_ERROR, e.getReason().toString()); * res.sendError(e.getReason().getHttpStatusCode()); * } * } * } * </code></pre> * * <p>{@code RepositoryResolver} can throw {@code MyRequestFailureException} and {@code * MyErrorHandlingFilter} will handle that. You can control how the error should be surfaced. */ public final class GitilesRequestFailureException extends RuntimeException {
<|startcomment|> Is SC_BAD_REQUEST a better fit? <|endcomment|>  BLAME_REGION_NOT_FOUND(SC_NOT_FOUND), /** Cannot parse URL as a Gitiles URL. */ CANNOT_PARSE_GITILES_VIEW(SC_NOT_FOUND), /** URL parameters are not valid. */ INCORECT_PARAMETER(SC_BAD_REQUEST), /** * The object specified by the URL is not suitable for the view (e.g. trying to show a blob as a * tree). */ <|startfocus|> INCORRECT_OBJECT_TYPE(SC_NOT_FOUND), <|endfocus|> /** Markdown rendering is not enabled. */ MARKDOWN_NOT_ENABLED(SC_NOT_FOUND), /** Request is not authorized. */ NOT_AUTHORIZED(SC_UNAUTHORIZED), /** Object is not found. */ OBJECT_NOT_FOUND(SC_NOT_FOUND), /** Object is too large to show. */ OBJECT_TOO_LARGE(SC_INTERNAL_SERVER_ERROR), /** Repository is not found. */ REPOSITORY_NOT_FOUND(SC_NOT_FOUND), /** Gitiles is not enabled for the repository. */ SERVICE_NOT_ENABLED(SC_FORBIDDEN), /** GitWeb URL cannot be converted to Gitiles URL. */ UNSUPPORTED_GITWEB_URL(SC_GONE),
<|startcomment|> Please add JavaDoc <|endcomment|> // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // https://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gitiles; <|startfocus|> <|endfocus|> public class MoreAssert { private MoreAssert() {} /** Simple version of assertThrows that will be introduced in JUnit 4.13. */ public static <T extends Throwable> T assertThrows(Class<T> expected, ThrowingRunnable r) { try { r.run(); throw new AssertionError("Expected " + expected.getSimpleName() + " to be thrown"); } catch (Throwable actual) { if (expected.isAssignableFrom(actual.getClass())) { return (T) actual; } throw new AssertionError(
<|startcomment|> This is bad, instances should be created by Guice and not directly instantiated in this way. If a singleton is needed, then use the Scopes.SINGLETON. <|endcomment|>  factory(MultiSiteBatchRefUpdate.Factory.class); factory(RefUpdateValidator.Factory.class); factory(BatchRefUpdateValidator.Factory.class); if (!disableGitRepositoryValidation) { bind(GitRepositoryManager.class).to(MultiSiteGitRepositoryManager.class); } if (cfg.getZookeeperConfig().getEnforcementRules().isEmpty()) { bind(SharedRefEnforcement.class).to(DefaultSharedRefEnforcement.class).in(Scopes.SINGLETON); } else { bind(SharedRefEnforcement.class) <|startfocus|> .toInstance( new CustomSharedRefEnforcementByProject( cfg.getZookeeperConfig().getEnforcementRules())); <|endfocus|> } install(new ZkValidationModule(cfg));
<|startcomment|> Strings.isNullOrEmpty should be removed. Does this even compile? It's passing a boolean into a method that expects a string. <|endcomment|>  // and then query the secondary index for each user but this way is less // efficient. queryPredicate = Predicate.or(AccountPredicates.isActive(), AccountPredicates.isNotActive()); } for (AccountState accountState : accountQueryProvider.get().query(queryPredicate)) { Account account = accountState.getAccount(); String out = new StringBuilder() .append(account.getId().toString()) .append(" |") .append( <|startfocus|> Strings.isNullOrEmpty(accountState.getUserName().isPresent()) <|endfocus|> ? "" : " " + accountState.getUserName().get()) .append(" |") .append( Strings.isNullOrEmpty(account.getFullName()) ? "" : " " + account.getFullName()) .append(" |") .append( Strings.isNullOrEmpty(account.getPreferredEmail()) ? "" : " " + account.getPreferredEmail()) .append(" |") .append(account.isActive() ? " active" : " inactive") .toString();
<|startcomment|> Replacing line 744 with 745 does not pass the aforementioned test, either. <|endcomment|>  if (args.getSchema().hasField(ChangeField.EXTENSION)) { FileExtensionPredicate extensionPredicate = new FileExtensionPredicate(ext); if (ext.isEmpty()) { RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate("^.{0}$"); // RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate("^()$"); // cf. https://www.brics.dk/automaton/doc/index.html?dk/brics/automaton/RegExp.html return emptyExtPredicate; // return Predicate.or(extensionPredicate, emptyExtPredicate); } <|startfocus|> return extensionPredicate; <|endfocus|> } throw new QueryParseException("'extension' operator is not supported by change index version"); } @Operator public Predicate<ChangeData> onlyexts(String extList) throws QueryParseException { return onlyextensions(extList); } @Operator public Predicate<ChangeData> onlyextensions(String extList) throws QueryParseException { if (args.getSchema().hasField(ChangeField.ONLY_EXTENSIONS)) { return new FileExtensionListPredicate(extList); } throw new QueryParseException( "'onlyextensions' operator is not supported by change index version"); } @Operator
<|startcomment|> Should this be in a separate change? <|endcomment|>  public void disablePlugins(Set<String> names) { if (!isRemoteAdminEnabled()) { logger.atWarning().log( "Remote plugin administration is disabled, ignoring disablePlugins(%s)", names); return; } synchronized (this) { for (String name : names) { Plugin active = running.get(name); if (active == null) { continue; } <|startfocus|> if (mandatoryPlugins.contains(name)) { logger.atInfo().log("Mandatory plugin %s cannot be disabled", name); continue; } <|endfocus|> logger.atInfo().log("Disabling plugin %s", active.getName()); Path off = active.getSrcFile().resolveSibling(active.getSrcFile().getFileName() + ".disabled"); try { Files.move(active.getSrcFile(), off); } catch (IOException e) { logger.atSevere().withCause(e).log("Failed to disable plugin"); // In theory we could still unload the plugin even if the rename // failed. However, it would be reloaded on the next server startup,
<|startcomment|> I don't think it's good that we change this but I see that it will need some time to re-adjust this. As populating the cache on update was just a side-effect up to now and we need the other aspects of this change, I think we should go forward and merge this change. Can you please add a TODO comment somewhere so that we don't forget about? Please also mention this behavior change in the commit message. <|endcomment|>  .state(CheckState.FAILED) .upsert(); assertThat(getChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.FAILED)); } @Test public void combinedCheckStateViaQuery() throws Exception { CacheStats start = cloneStats(cache.getStats()); long startReloadsFalse = cache.getReloadCount(false); long startReloadsTrue = cache.getReloadCount(true); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.NOT_RELEVANT)); <|startfocus|> // Cache hasn't yet populated during update. <|endfocus|> assertThat(cache.getStats()).since(start).hasHitCount(0); assertThat(cache.getStats()).since(start).hasMissCount(1); assertThat(cache.getReloadCount(false) - startReloadsFalse).isEqualTo(0); assertThat(cache.getReloadCount(true) - startReloadsTrue).isEqualTo(0); assertThat(queryChangeCheckInfo(changeId)) .hasValue(new ChangeCheckInfo("checks", CombinedCheckState.NOT_RELEVANT)); assertThat(cache.getStats()).since(start).hasHitCount(1); assertThat(cache.getStats()).since(start).hasMissCount(1);
<|startcomment|> Reviewers: can this call stay here, or should it move outside of this method, for potential performance reasons? <|endcomment|>  } return EqualsFilePredicate.create(args, file); } @Operator public Predicate<ChangeData> path(String path) { if (path.startsWith("^")) { return new RegexPathPredicate(path); } return new EqualsPathPredicate(FIELD_PATH, path); } @Operator public Predicate<ChangeData> ext(String ext) throws QueryParseException { return extension(ext); } @Operator public Predicate<ChangeData> extension(String ext) throws QueryParseException { <|startfocus|> if (args.getSchema().hasField(ChangeField.EXTENSION)) { <|endfocus|> return new FileExtensionPredicate(ext); } throw new QueryParseException("'extension' operator is not supported by change index version"); } @Operator public Predicate<ChangeData> onlyexts(String extList) throws QueryParseException { return onlyextensions(extList); } @Operator public Predicate<ChangeData> onlyextensions(String extList) throws QueryParseException { if (args.getSchema().hasField(ChangeField.ONLY_EXTENSIONS)) { return new FileExtensionListPredicate(extList); } throw new QueryParseException( "'onlyextensions' operator is not supported by change index version"); } 
<|startcomment|> This should rather be a Collection, we shouldn't assume which collection type will be used by the PluginLoader. <|endcomment|> <|startfocus|> public MissingMandatoryPluginsException(Set<String> pluginNames) { <|endfocus|> super(getMessage(pluginNames));
<|startcomment|> Unused constructor. <|endcomment|> // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.plugins; import java.util.Set; /** Raised when one or more mandatory plugins are missing. */ public class MissingMandatoryPluginsException extends RuntimeException { private static final long serialVersionUID = 1L; public MissingMandatoryPluginsException(Set<String> pluginNames) { super(getMessage(pluginNames)); } <|startfocus|> public MissingMandatoryPluginsException(Set<String> pluginNames, Throwable why) { super(getMessage(pluginNames), why); } private static String getMessage(Set<String> pluginNames) { <|endfocus|> return String.format("Cannot find or load the following mandatory plugins: %s", pluginNames); } } 
<|startcomment|> This should be more specific Plugin loader exception that encapsulates the list of missing plugins and the cause of the failed load. <|endcomment|>  "%s plugin %s, version %s", active == null ? "Loaded" : "Reloaded", loadedPlugin.getName(), loadedPlugin.getVersion()); } } catch (PluginInstallException e) { logger.atWarning().withCause(e.getCause()).log("Cannot load plugin %s", name); } } } Set<String> missingMandatory = Sets.difference(mandatoryPlugins, loadedPlugins); if (!missingMandatory.isEmpty()) { <|startfocus|> throw new ProvisionException("Failed to load mandatory plugins: " + missingMandatory); <|endfocus|> } cleanInBackground(); } private void addAllEntries(Map<String, Path> from, TreeSet<Map.Entry<String, Path>> to) { Iterator<Map.Entry<String, Path>> it = from.entrySet().iterator(); while (it.hasNext()) { Map.Entry<String, Path> entry = it.next(); to.add(new AbstractMap.SimpleImmutableEntry<>(entry.getKey(), entry.getValue())); } } private TreeSet<Map.Entry<String, Path>> jarsFirstSortedPluginsSet( Map<String, Path> activePlugins) {
<|startcomment|> Do we need to pass this as parameter? Another possibility is to inject the ChangeCleanupConfig into this class and use it to get this parameter <|endcomment|>  * should use the batch instead of abandoning one by one. * * <p>It's the caller's responsibility to ensure that all jobs inside the same batch have the * matching project from its ChangeData. Violations will result in a ResourceConflictException. */ public void batchAbandon( BatchUpdate.Factory updateFactory, Project.NameKey project, CurrentUser user, Collection<ChangeData> changes, String msgTxt, <|startfocus|> boolean cleanupAccountPatchReview, <|endfocus|> NotifyResolver.Result notify) throws RestApiException, UpdateException { if (changes.isEmpty()) { return; } AccountState accountState = user.isIdentifiedUser() ? user.asIdentifiedUser().state() : null; try (BatchUpdate u = updateFactory.create(project, user, TimeUtil.nowTs())) { u.setNotify(notify); for (ChangeData change : changes) { if (!project.equals(change.project())) { throw new ResourceConflictException( String.format( "Project name \"%s\" doesn't match \"%s\"",
<|startcomment|> This can be inlined. return getIndexType(injector.getInstance(Key.get(Config.class, GerritServerConfig.class))); <|endcomment|>  public static IndexType getIndexType(Injector injector) { <|startfocus|> Config cfg = injector.getInstance(Key.get(Config.class, GerritServerConfig.class)); return cfg.getEnum("index", null, "type", IndexType.LUCENE); <|endfocus|>
<|startcomment|> Need to handle cfg == null case <|endcomment|>  public static IndexType getIndexType(@Nullable Config cfg) { <|startfocus|> return cfg.getEnum("index", null, "type", IndexType.LUCENE); <|endfocus|>
<|startcomment|> I don't think this should be separately injected here. Separately meaning separate from the injection in the constructor. Maybe it would be better to include the index type in the IndexConfig which is then included in the Arguments instance that is already injected? <|endcomment|>  } } CurrentUser getUser() throws QueryRequiresAuthException { try { return self.get(); } catch (ProvisionException e) { throw new QueryRequiresAuthException(NotSignedInException.MESSAGE, e); } } Schema<ChangeData> getSchema() { return index != null ? index.getSchema() : null; } } private final Arguments args; @Inject ChangeQueryBuilder(Arguments args) { super(mydef); this.args = args; setupDynamicOperators(); } @VisibleForTesting <|startfocus|> protected ChangeQueryBuilder( Definition<ChangeData, ? extends QueryBuilder<ChangeData>> def, Arguments args) { super(def); <|endfocus|> this.args = args; } private void setupDynamicOperators() { for (Extension<ChangeOperatorFactory> e : args.opFactories) { String name = e.getExportName() + "_" + e.getPluginName(); opFactories.put(name, e.getProvider().get()); } } public Arguments getArgs() { return args; } public ChangeQueryBuilder asUser(CurrentUser user) {
<|startcomment|> IIUC the purpose of using field injection is so that it's easier to not pass the field in tests, in which case you have to deal with config being null. How about: IndexType indexType = config != null ? config.getEnum("index", null, "type", IndexType.LUCENE) : IndexType.LUCENE; You could also move this to a static method in IndexModule like: public static IndexType getIndexType(@Nullable Config cfg) like the existing getIndexType method. <|endcomment|>  return new RegexPathPredicate(path); } return new EqualsPathPredicate(FIELD_PATH, path); } @Operator public Predicate<ChangeData> ext(String ext) throws QueryParseException { return extension(ext); } @Operator public Predicate<ChangeData> extension(String ext) throws QueryParseException { if (args.getSchema().hasField(ChangeField.EXTENSION)) { <|startfocus|> if (ext.isEmpty()) { String indexType = config.getString("index", null, "type"); if (indexType.equalsIgnoreCase(IndexType.ELASTICSEARCH.name())) { return new FileWithNoExtensionPredicate(); } <|endfocus|> } return new FileExtensionPredicate(ext); } throw new QueryParseException("'extension' operator is not supported by change index version"); } @Operator public Predicate<ChangeData> onlyexts(String extList) throws QueryParseException { return onlyextensions(extList); } @Operator public Predicate<ChangeData> onlyextensions(String extList) throws QueryParseException { if (args.getSchema().hasField(ChangeField.ONLY_EXTENSIONS)) { return new FileExtensionListPredicate(extList); } throw new QueryParseException(
<|startcomment|> The documentation (which is also part of this change) says that the default is false. <|endcomment|>  private final DynamicItem<UrlFormatter> urlFormatter; private final Optional<Schedule> schedule; private final long abandonAfter; private final boolean abandonIfMergeable; private final String abandonMessage; @Inject ChangeCleanupConfig(@GerritServerConfig Config cfg, DynamicItem<UrlFormatter> urlFormatter) { this.urlFormatter = urlFormatter; schedule = ScheduleConfig.createSchedule(cfg, SECTION); abandonAfter = readAbandonAfter(cfg); <|startfocus|> abandonIfMergeable = cfg.getBoolean(SECTION, null, KEY_ABANDON_IF_MERGEABLE, true); <|endfocus|> abandonMessage = readAbandonMessage(cfg); } private long readAbandonAfter(Config cfg) { long abandonAfter = ConfigUtil.getTimeUnit(cfg, SECTION, null, KEY_ABANDON_AFTER, 0, TimeUnit.MILLISECONDS); return abandonAfter >= 0 ? abandonAfter : 0; } private String readAbandonMessage(Config cfg) { String abandonMessage = cfg.getString(SECTION, null, KEY_ABANDON_MESSAGE); return Strings.isNullOrEmpty(abandonMessage) ? DEFAULT_ABANDON_MESSAGE : abandonMessage; } public Optional<Schedule> getSchedule() { return schedule; } public long getAbandonAfter() { return abandonAfter; } 
<|startcomment|> I'm not sure that we should check this here. It means that we expect the cache to always return the same instance from the cache, which is not what this test is about (as far as I understood). Wouldn't it be sufficient to test that the description of cachedProjectState1 is still empty and that the description of a new value from the cache (cacheProjectState2) is also empty (as done in the next line)? <|endcomment|>  Project.NameKey key = projectOperations.newProject().create(); ProjectConfig projectConfig = projectOperations.project(key).getProjectConfig(); ProjectState cachedProjectState1 = projectCache.checkedGet(key); assertThat(cachedProjectState1).isNotNull(); assertThat(cachedProjectState1.getProject().getDescription()).isEmpty(); assertThat(projectConfig.getProject().getDescription()).isEmpty(); projectConfig.getProject().setDescription("my fancy project"); <|startfocus|> ProjectState cachedProjectState2 = projectCache.checkedGet(key); assertThat(cachedProjectState2).isSameInstanceAs(cachedProjectState1); assertThat(cachedProjectState2.getProject().getDescription()).isEmpty(); <|endfocus|> } @Test public void getProjectConfigNoRefsMetaConfig() throws Exception { Project.NameKey key = projectOperations.newProject().create(); deleteRefsMetaConfig(key); ProjectConfig projectConfig = projectOperations.project(key).getProjectConfig(); assertThat(projectConfig.getName()).isEqualTo(key); assertThat(projectConfig.getRevision()).isNull(); } @Test public void getConfig() throws Exception { Project.NameKey key = projectOperations.newProject().create();
<|startcomment|> This will break Truth's validation chain. Instead, please use check("getSections()").that(config.getSections()). <|endcomment|>  public IterableSubject sections() { isNotNull(); <|startfocus|> return Truth.assertThat(config.getSections()); <|endfocus|>
<|startcomment|> or it's visibility is increased to public <|endcomment|> // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.common; import static java.lang.annotation.ElementType.FIELD; import static java.lang.annotation.ElementType.METHOD; import static java.lang.annotation.ElementType.TYPE; import static java.lang.annotation.RetentionPolicy.RUNTIME; import java.lang.annotation.Retention; import java.lang.annotation.Target; /** <|startfocus|> * A marker to say a method/type/field is added or public solely because it is called from inside a * project or an organisation using Gerrit. <|endfocus|> */ @Target({METHOD, TYPE, FIELD}) @Retention(RUNTIME) public @interface UsedAt { /** Enumeration of projects that call a method/type/field. */ enum Project { GOOGLE, PLUGIN_CHECKS, PLUGIN_DELETE_PROJECT, PLUGIN_SERVICEUSER, PLUGINS_ALL, // Use this project if a method/type is generally made available to all plugins. } /** Reference to the project that uses the method annotated with this annotation. */ Project value(); } 
<|startcomment|> This is not mentioned in the commit message, and it was indeed a misleading log. We were telling the user that there was an in-flight push but, actually, it wasn't the case. <|endcomment|>  ? NON_EXISTING : REJECTED_OTHER_REASON; postReplicationFailedEvent(pushOp, status); if (pushOp.setToRetry()) { postReplicationScheduledEvent(pushOp); pool.schedule(pushOp, config.getRetryDelay(), TimeUnit.MINUTES); } else { pushOp.canceledByReplication(); pending.remove(uri); stateLog.error( "Push to " + pushOp.getURI() + " cancelled after maximum number of retries", pushOp.getStatesAsArray()); } break; } } } } <|startfocus|> boolean requestRunway(PushOne op) { <|endfocus|> synchronized (stateLock) { if (op.wasCanceled()) { return false; } pending.remove(op.getURI()); if (inFlight.containsKey(op.getURI())) { return false; } inFlight.put(op.getURI(), op); } return true; } void notifyFinished(PushOne op) { synchronized (stateLock) { inFlight.remove(op.getURI()); } } boolean wouldPushProject(Project.NameKey project) { if (!shouldReplicate(project)) {
<|startcomment|> Rename this to deleteKeySenderFactory (or just senderFactory) to have the intent more obvious. <|endcomment|>  public class DeleteGpgKey implements RestModifyView<GpgKey, Input> { private static final Logger log = LoggerFactory.getLogger(DeleteGpgKey.class); public static class Input {} private final Provider<PersonIdent> serverIdent; private final Provider<PublicKeyStore> storeProvider; private final ExternalIdsUpdate.User externalIdsUpdateFactory; private final DeleteKeySender.Factory deleteKeyFactory; @Inject DeleteGpgKey( @GerritPersonIdent Provider<PersonIdent> serverIdent, Provider<PublicKeyStore> storeProvider, ExternalIdsUpdate.User externalIdsUpdateFactory, <|startfocus|> DeleteKeySender.Factory deleteKeyFactory) { <|endfocus|> this.serverIdent = serverIdent; this.storeProvider = storeProvider; this.externalIdsUpdateFactory = externalIdsUpdateFactory; this.deleteKeyFactory = deleteKeyFactory; } @Override public Response<?> apply(GpgKey rsrc, Input input) throws ResourceConflictException, PGPException, OrmException, IOException, ConfigInvalidException { PGPPublicKey key = rsrc.getKeyRing().getPublicKey(); externalIdsUpdateFactory .create() .delete( rsrc.getUser().getAccountId(), ExternalId.Key.create( SCHEME_GPGKEY, BaseEncoding.base16().encode(key.getFingerprint()))); 
<|startcomment|> Same here: deleteKeySenderFactory (or just senderFactory). <|endcomment|> import org.slf4j.LoggerFactory; @Singleton public class PostGpgKeys implements RestModifyView<AccountResource, Input> { public static class Input { public List<String> add; public List<String> delete; } private final Logger log = LoggerFactory.getLogger(getClass()); private final Provider<PersonIdent> serverIdent; private final Provider<CurrentUser> self; private final Provider<PublicKeyStore> storeProvider; private final GerritPublicKeyChecker.Factory checkerFactory; <|startfocus|> private final AddKeySender.Factory addKeyFactory; private final DeleteKeySender.Factory deleteKeyFactory; <|endfocus|> private final Provider<InternalAccountQuery> accountQueryProvider; private final ExternalIds externalIds; private final ExternalIdsUpdate.User externalIdsUpdateFactory; @Inject PostGpgKeys( @GerritPersonIdent Provider<PersonIdent> serverIdent, Provider<CurrentUser> self, Provider<PublicKeyStore> storeProvider, GerritPublicKeyChecker.Factory checkerFactory, AddKeySender.Factory addKeyFactory, DeleteKeySender.Factory deleteKeyFactory, Provider<InternalAccountQuery> accountQueryProvider, ExternalIds externalIds, ExternalIdsUpdate.User externalIdsUpdateFactory) { this.serverIdent = serverIdent; this.self = self;
<|startcomment|> Use method reference: map(Fingerprint::toString). <|endcomment|>  case NEW: case FAST_FORWARD: case FORCED: if (!addedKeys.isEmpty()) { try { addKeyFactory.create(user, addedKeys).send(); } catch (EmailException e) { log.error( "Cannot send GPG key added message to " + user.getAccount().getPreferredEmail(), e); } } if (!toRemove.isEmpty()) { try { <|startfocus|> deleteKeyFactory .create(user, toRemove.stream().map(k -> k.toString()).collect(toList())) <|endfocus|> .send(); } catch (EmailException e) { log.error( "Cannot send GPG key deleted message to " + user.getAccount().getPreferredEmail(), e); } } break; case NO_CHANGE: break; case IO_FAILURE: case LOCK_FAILURE: case NOT_ATTEMPTED: case REJECTED: case REJECTED_CURRENT_BRANCH: case RENAMED: case REJECTED_MISSING_OBJECT: case REJECTED_OTHER_REASON: default: // TODO(dborowitz): Backoff and retry on LOCK_FAILURE.
<|startcomment|> Same here: deleteKeySenderFactory (or just senderFactory). <|endcomment|> import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.errors.RepositoryNotFoundException; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class DeleteSshKey implements RestModifyView<AccountResource.SshKey, Input> { private static final Logger log = LoggerFactory.getLogger(DeleteSshKey.class); public static class Input {} private final Provider<CurrentUser> self; private final PermissionBackend permissionBackend; private final VersionedAuthorizedKeys.Accessor authorizedKeys; private final SshKeyCache sshKeyCache; <|startfocus|> private final DeleteKeySender.Factory deleteKeyFactory; <|endfocus|> @Inject DeleteSshKey( Provider<CurrentUser> self, PermissionBackend permissionBackend, VersionedAuthorizedKeys.Accessor authorizedKeys, SshKeyCache sshKeyCache, DeleteKeySender.Factory deleteKeyFactory) { this.self = self; this.permissionBackend = permissionBackend; this.authorizedKeys = authorizedKeys; this.sshKeyCache = sshKeyCache; this.deleteKeyFactory = deleteKeyFactory; } @Override public Response<?> apply(AccountResource.SshKey rsrc, Input input) throws AuthException, OrmException, RepositoryNotFoundException, IOException, ConfigInvalidException, PermissionBackendException {
<|startcomment|> Nit: not needed new line? <|endcomment|> import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.reviewdb.client.AccountSshKey; import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.mail.Address; import com.google.gerrit.server.permissions.GlobalPermission; import com.google.gerrit.server.permissions.PermissionBackend; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; import java.util.List; public class DeleteKeySender extends OutgoingEmail { public interface Factory { DeleteKeySender create(IdentifiedUser user, AccountSshKey sshKey); <|startfocus|> DeleteKeySender create(IdentifiedUser user, List<String> gpgKeys); <|endfocus|> } private final PermissionBackend permissionBackend; private final IdentifiedUser callingUser; private final IdentifiedUser user; private final AccountSshKey sshKey; private final List<String> gpgKeys; @AssistedInject public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted AccountSshKey sshKey) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user;
<|startcomment|> Better: gpgKeyFingeprints. <|endcomment|> import com.google.gerrit.server.IdentifiedUser; import com.google.gerrit.server.mail.Address; import com.google.gerrit.server.permissions.GlobalPermission; import com.google.gerrit.server.permissions.PermissionBackend; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.assistedinject.Assisted; import com.google.inject.assistedinject.AssistedInject; import java.util.List; public class DeleteKeySender extends OutgoingEmail { public interface Factory { DeleteKeySender create(IdentifiedUser user, AccountSshKey sshKey); <|startfocus|> DeleteKeySender create(IdentifiedUser user, List<String> gpgKeys); <|endfocus|> } private final PermissionBackend permissionBackend; private final IdentifiedUser callingUser; private final IdentifiedUser user; private final AccountSshKey sshKey; private final List<String> gpgKeys; @AssistedInject public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted AccountSshKey sshKey) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeys = null; this.sshKey = sshKey; } @AssistedInject
<|startcomment|> It is considered to be a bad practice to use null values for collection types. Use Collections.emptyList() instead? This would also allow you to check gpgKeys.isEmpty() below. <|endcomment|>  public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted AccountSshKey sshKey) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; <|startfocus|> this.gpgKeys = null; <|endfocus|> this.sshKey = sshKey;
<|startcomment|> Nit: gpgKeyFingeprints. In any event this should be gpgKeys. <|endcomment|>  public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, <|startfocus|> @Assisted List<String> gpgKey) { <|endfocus|> super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; this.gpgKeys = gpgKey; this.sshKey = null;
<|startcomment|> Carnality mismatch. <|endcomment|>  public DeleteKeySender( EmailArguments ea, PermissionBackend permissionBackend, IdentifiedUser callingUser, @Assisted IdentifiedUser user, @Assisted List<String> gpgKey) { super(ea, "deletekey"); this.permissionBackend = permissionBackend; this.callingUser = callingUser; this.user = user; <|startfocus|> this.gpgKeys = gpgKey; <|endfocus|> this.sshKey = null;
<|startcomment|> Throw ISE or IAE instead? <|endcomment|>  public String getKeyType() { if (sshKey != null) { return "SSH"; } else if (gpgKeys != null) { return "GPG"; } <|startfocus|> return "Unknown"; <|endfocus|>
<|startcomment|> gpgKeyFingeprints. <|endcomment|> <|startfocus|> public String getGpgKeys() { if (gpgKeys != null) { return Joiner.on("\n").join(gpgKeys); <|endfocus|> } return null;
<|startcomment|> Twice "to be updated". <|endcomment|>  return TestPermission.builder().name(name).action(PermissionRule.Action.ALLOW); } /** Start a builder for denying a permission. */ public static TestPermission.Builder deny(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.DENY); } /** Start a builder for blocking a permission. */ public static TestPermission.Builder block(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.BLOCK); } /** <|startfocus|> * Records a permission to be updated to be updated. <|endfocus|> * * <p>Not used for permissions that have ranges (label permissions) or global capabilities. */ @AutoValue public abstract static class TestPermission { private static Builder builder() { return new AutoValue_TestProjectUpdate_TestPermission.Builder().force(false); } abstract String name(); abstract String ref(); abstract AccountGroup.UUID group(); abstract PermissionRule.Action action(); abstract boolean force(); /** Builder for {@link TestPermission}. */ @AutoValue.Builder public abstract static class Builder {
<|startcomment|> Name is pre-filled by the static factory methods. Hence, can we remove the public modifier? <|endcomment|>  */ @AutoValue public abstract static class TestPermission { private static Builder builder() { return new AutoValue_TestProjectUpdate_TestPermission.Builder().force(false); } abstract String name(); abstract String ref(); abstract AccountGroup.UUID group(); abstract PermissionRule.Action action(); abstract boolean force(); /** Builder for {@link TestPermission}. */ @AutoValue.Builder public abstract static class Builder { <|startfocus|> /** Sets the name of the permission. */ public abstract Builder name(String name); <|endfocus|> /** Sets the ref pattern used on the permission. */ public abstract Builder ref(String ref); /** Sets the group to which the permission applies. */ public abstract Builder group(AccountGroup.UUID groupUuid); abstract Builder action(PermissionRule.Action action); /** Sets whether the permission is a force permission. */ public abstract Builder force(boolean force); /** Builds the {@link TestPermission}. */ public abstract TestPermission build(); } } 
<|startcomment|> Shouldn't those two lines be deleted now (as they are replaced with the new code)? <|endcomment|>  public void deleteUserBranch_Conflict() throws Exception { projectOperations .project(allUsers) .forUpdate() .add( TestProjectUpdate.allow(Permission.CREATE) .ref(RefNames.REFS_USERS + "*") .group(REGISTERED_USERS)) .add( TestProjectUpdate.allow(Permission.PUSH) .ref(RefNames.REFS_USERS + "*") .group(REGISTERED_USERS)) .update(); <|startfocus|> allow(allUsers, RefNames.REFS_USERS + "*", Permission.CREATE, REGISTERED_USERS); allow(allUsers, RefNames.REFS_USERS + "*", Permission.PUSH, REGISTERED_USERS); <|endfocus|> ResourceConflictException thrown = assertThrows( ResourceConflictException.class, () -> branch(BranchNameKey.create(allUsers, RefNames.refsUsers(admin.id()))).delete()); assertThat(thrown).hasMessageThat().contains("Not allowed to delete user branch."); } @Test public void deleteGroupBranch_Conflict() throws Exception { allow(allUsers, RefNames.REFS_GROUPS + "*", Permission.CREATE, REGISTERED_USERS); allow(allUsers, RefNames.REFS_GROUPS + "*", Permission.PUSH, REGISTERED_USERS); ResourceConflictException thrown = assertThrows(
<|startcomment|> Test method's name is already explicit enough to remove this comment line. <|endcomment|>  @NoHttpd public class PluginLoaderIT extends AbstractDaemonTest { Description testDescription; @Override protected void beforeTest(Description description) throws Exception { this.testDescription = description; } @Override protected void afterTest() throws Exception {} @Test(expected = MissingMandatoryPluginsException.class) @GerritConfig(name = "plugins.mandatory", value = "my-mandatory-plugin") public void shouldFailToStartGerritWhenMandatoryPluginsAreMissing() throws Exception { <|startfocus|> // This should try to start Gerrit and fail because of missing mandatory plugins <|endfocus|> super.beforeTest(testDescription); } } 
<|startcomment|> atWarning, as this is valuable feedback for an unaware admin. Also similar in scope with above L224's own message, which is a warning. <|endcomment|>  public void disablePlugins(Set<String> names) { if (!isRemoteAdminEnabled()) { logger.atWarning().log( "Remote plugin administration is disabled, ignoring disablePlugins(%s)", names); return; } synchronized (this) { for (String name : names) { Plugin active = running.get(name); if (active == null) { continue; } <|startfocus|> if (mandatoryPlugins.contains(name)) { logger.atInfo().log("Mandatory plugin %s cannot be disabled", name); continue; } <|endfocus|> logger.atInfo().log("Disabling plugin %s", active.getName()); Path off = active.getSrcFile().resolveSibling(active.getSrcFile().getFileName() + ".disabled"); try { Files.move(active.getSrcFile(), off); } catch (IOException e) { logger.atSevere().withCause(e).log("Failed to disable plugin"); // In theory we could still unload the plugin even if the rename // failed. However, it would be reloaded on the next server startup,
<|startcomment|> Should a test be added to cover this new flow? <|endcomment|>  public void disablePlugins(Set<String> names) { if (!isRemoteAdminEnabled()) { logger.atWarning().log( "Remote plugin administration is disabled, ignoring disablePlugins(%s)", names); return; } synchronized (this) { for (String name : names) { Plugin active = running.get(name); if (active == null) { continue; } <|startfocus|> if (mandatoryPlugins.contains(name)) { logger.atInfo().log("Mandatory plugin %s cannot be disabled", name); continue; } <|endfocus|> logger.atInfo().log("Disabling plugin %s", active.getName()); Path off = active.getSrcFile().resolveSibling(active.getSrcFile().getFileName() + ".disabled"); try { Files.move(active.getSrcFile(), off); } catch (IOException e) { logger.atSevere().withCause(e).log("Failed to disable plugin"); // In theory we could still unload the plugin even if the rename // failed. However, it would be reloaded on the next server startup,
<|startcomment|> Why we have removed invalid value assertions without moving it to separate test? <|endcomment|>  public void setUp() { globalPluginConfig = new Config(); replicationConfig = new Config(); } private Configuration getConfiguration() { return new Configuration(globalPluginConfig, replicationConfig); } @Test public void testGetIndexThreadPoolSize() throws Exception { assertThat(getConfiguration().index().threadPoolSize()).isEqualTo(DEFAULT_THREAD_POOL_SIZE); globalPluginConfig.setInt(INDEX_SECTION, null, THREAD_POOL_SIZE_KEY, THREAD_POOL_SIZE); assertThat(getConfiguration().index().threadPoolSize()).isEqualTo(THREAD_POOL_SIZE); } <|startfocus|> <|endfocus|> @Test public void testGetIndexSynchronize() throws Exception { assertThat(getConfiguration().index().synchronize()).isEqualTo(DEFAULT_SYNCHRONIZE); globalPluginConfig.setBoolean(INDEX_SECTION, null, SYNCHRONIZE_KEY, false); assertThat(getConfiguration().index().synchronize()).isFalse(); globalPluginConfig.setBoolean(INDEX_SECTION, null, SYNCHRONIZE_KEY, true); assertThat(getConfiguration().index().synchronize()).isTrue(); } @Test public void testGetCacheThreadPoolSize() throws Exception {
<|startcomment|> should we save sharedDirConfig as well? <|endcomment|>  drainQueue(droppedEventsQueue); ChangeData change = createChange().getChange(); String project = change.project().get(); int changeNum = change.getId().get(); String changeNotesRef = change.notes().getRefName(); int patchsetNum = change.currentPatchSet().getPatchSetId(); String patchsetRevision = change.currentPatchSet().getRevision().get(); String patchsetRef = change.currentPatchSet().getRefName(); <|startfocus|> Map<String, List<Event>> eventsByType = receiveEventsByType(droppedEventsQueue); <|endfocus|> assertThat(eventsByType.get("change-index")) .containsExactly(createChangeIndexEvent(project, changeNum, getParentCommit(change))); assertThat( eventsByType .get("ref-updated") .stream() .map(e -> ((RefUpdatedEvent) e).getRefName()) .collect(toSet())) .containsAllOf( changeNotesRef, patchsetRef); // 'refs/sequences/changes' not always updated thus not checked List<Event> patchSetCreatedEvents = eventsByType.get("patchset-created"); assertThat(patchSetCreatedEvents).hasSize(1); assertPatchSetAttributes(
<|startcomment|> Not used <|endcomment|> import java.util.Arrays; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.commons.lang.StringUtils; import org.apache.curator.RetryPolicy; import org.apache.curator.framework.CuratorFramework; import org.apache.curator.framework.CuratorFrameworkFactory; import org.apache.curator.retry.BoundedExponentialBackoffRetry; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; <|startfocus|> import org.eclipse.jgit.util.FS; <|endfocus|> import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class Configuration { private static final Logger log = LoggerFactory.getLogger(Configuration.class); public static final String PLUGIN_NAME = "multi-site"; static final String INSTANCE_ID_FILE = "instanceId.data"; // common parameters to cache and index sections static final String THREAD_POOL_SIZE_KEY = "threadPoolSize"; static final int DEFAULT_INDEX_MAX_TRIES = 2; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000;
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2015 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import static com.google.common.base.Suppliers.memoize; import static com.googlesource.gerrit.plugins.multisite.ConfigurationHelper.getString; import com.google.common.annotations.VisibleForTesting; import com.google.common.base.CaseFormat; import com.google.common.base.Supplier; import com.google.common.collect.ImmutableMap; import com.google.gerrit.server.config.SitePaths; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.util.HashMap;
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2015 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import static com.google.common.truth.Truth.assertThat; import static com.googlesource.gerrit.plugins.multisite.Configuration.ENABLE_KEY; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KAFKA_PROPERTY_PREFIX; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KAFKA_SECTION; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KafkaPublisher.KAFKA_PUBLISHER_SUBSECTION; import static com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KafkaSubscriber.KAFKA_SUBSCRIBER_SUBSECTION; import org.eclipse.jgit.lib.Config;
<|startcomment|> Is there a reason for switching to 'capability' here but not in the other Javadocs? <|endcomment|> // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.acceptance.testsuite.project; import com.google.auto.value.AutoValue; import com.google.common.collect.ImmutableList; import com.google.gerrit.acceptance.testsuite.ThrowingConsumer; import com.google.gerrit.common.data.PermissionRule; import com.google.gerrit.reviewdb.client.AccountGroup; @AutoValue public abstract class TestProjectUpdate { <|startfocus|> /** Starts a builder for allowing a capability. */ <|endfocus|> public static TestPermission.Builder allow(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.ALLOW); } /** Starts a builder for denying a permission. */ public static TestPermission.Builder deny(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.DENY); } /** Starts a builder for blocking a permission. */ public static TestPermission.Builder block(String name) { return TestPermission.builder().name(name).action(PermissionRule.Action.BLOCK); } /**
<|startcomment|> Can you add more text here to describe when this should be used? I think using this instead of request tokens is rather the exceptional case, so we should explicitly say so. <|endcomment|>  * request, implementations should not deduct tokens from a bucket, yet. */ QuotaResponse requestNoDeduction(String quotaGroup, QuotaRequestContext ctx, long numTokens); /** * A previously requested and deducted quota has to be refilled (if possible) because the request * failed other quota checks. Implementations can choose to leave this a no-op in case they are * the first line of defence (e.g. always deduct HTTP quota even if the request failed for other <|startfocus|> * quota issues so that the user gets throttled). <|endfocus|> */ void refill(String quotaGroup, QuotaRequestContext ctx, long numTokens); } 
<|startcomment|> I don't think we typically use this package in gerrit. <|endcomment|> import com.google.gerrit.reviewdb.client.RefNames; import com.google.gerrit.reviewdb.server.ReviewDb; import com.google.gerrit.server.GerritPersonIdent; import com.google.gerrit.server.config.AllUsersName; import com.google.gerrit.server.git.GitRepositoryManager; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Provider; import java.io.IOException; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; import java.sql.Timestamp; import java.util.HashMap; import java.util.Map; <|startfocus|> import java.util.logging.Logger; <|endfocus|> import org.eclipse.jgit.lib.CommitBuilder; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectInserter; import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefUpdate; import org.eclipse.jgit.lib.RefUpdate.Result; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevSort; import org.eclipse.jgit.revwalk.RevWalk; /**
<|startcomment|> Use the UI object that gets passed in to the method? <|endcomment|>  String refName = RefNames.refsUsers(e.getKey()); Ref ref = repo.exactRef(refName); if (ref != null) { rewriteUserBranch(repo, rw, oi, emptyTree, ref, e.getValue()); } else { createUserBranch(repo, oi, emptyTree, e.getKey(), e.getValue()); } i++; if (i % 100 == 0) { <|startfocus|> LOG.info(String.format("Migrated %d users to schema 146", i)); <|endfocus|> } } } catch (IOException e) { throw new OrmException("Failed to rewrite user branches.", e); } } private void rewriteUserBranch( Repository repo, RevWalk rw, ObjectInserter oi, ObjectId emptyTree, Ref ref, Timestamp registeredOn) throws IOException { ObjectId current = createInitialEmptyCommit(oi, emptyTree, registeredOn); rw.reset(); rw.sort(RevSort.TOPO); rw.sort(RevSort.REVERSE, true); rw.markStart(rw.parseCommit(ref.getObjectId())); RevCommit c;
<|startcomment|> Same here, in Daemon.java it is: indexType = IndexModule.getIndexType(cfgInjector); <|endcomment|>  // and the start() methods of each such listener are executed in the // order they are declared. // Makes sure that PluginLoader.start() is executed before the // LuceneIndexModule.start() so that plugins get loaded and the respective // Guice modules installed so that the on-line reindexing will happen // with the proper classes (e.g. group backends, custom Prolog // predicates) and the associated rules ready to be evaluated. modules.add(new PluginModule()); <|startfocus|> <|endfocus|> modules.add(new RestApiModule()); modules.add(new GpgModule(config)); modules.add(new StartupChecks.Module()); // Index module shutdown must happen before work queue shutdown, otherwise // work queue can get stuck waiting on index futures that will never return. modules.add(createIndexModule()); modules.add(new WorkQueue.Module()); modules.add(new GerritInstanceNameModule()); modules.add( new CanonicalWebUrlModule() { @Override protected Class<? extends Provider<String>> provider() { return HttpCanonicalWebUrlProvider.class; } });
<|startcomment|> If already on it, fix it to WORKSPACE? <|endcomment|>  try { u = new URL(p.substring(0, p.indexOf('!'))); } catch (MalformedURLException e) { FileNotFoundException fnfe = new FileNotFoundException("Not a valid jar file: " + u); fnfe.initCause(e); throw fnfe; } } if (!"file".equals(u.getProtocol())) { throw new FileNotFoundException("Cannot extract path from " + u); } <|startfocus|> // Pop up to the top-level source folder by looking for .buckconfig. <|endfocus|> dir = Paths.get(u.getPath()); while (!Files.isRegularFile(dir.resolve("WORKSPACE"))) { Path parent = dir.getParent(); if (parent == null) { throw new FileNotFoundException("Cannot find source root from " + u); } dir = parent; } } Path ret = dir.resolve(name); if (!Files.exists(ret)) { throw new FileNotFoundException(name + " not found in source root " + dir); } return ret; } 
<|startcomment|> Consider introducing a getType() method equivalent. <|endcomment|> <|startfocus|> protected String getDeleteActions(Id c) { if (!client.adapter().useType()) { return delete(client.adapter().getType(""), c); } return delete(OPEN_CHANGES, c) + delete(CLOSED_CHANGES, c); <|endfocus|>
<|startcomment|> Consider renaming these associated members more accurately, getters down below included. <|endcomment|>  private final boolean useV6Type; <|startfocus|> private final boolean omitTypeFromSearch; <|endfocus|> private final String searchFilteringName; private final String indicesExistParam; private final String exactFieldType; private final String stringFieldType; private final String indexProperty; private final String versionDiscoveryUrl; private final String includeTypeNameParam; ElasticQueryAdapter(ElasticVersion version) { this.ignoreUnmapped = false; this.useType = !version.isV6OrLater(); this.useV6Type = version.isV6(); this.omitTypeFromSearch = version.isV7OrLater(); this.versionDiscoveryUrl = version.isV6OrLater() ? "/%s*" : "/%s*/_aliases"; this.searchFilteringName = "_source"; this.indicesExistParam = "?allow_no_indices=false"; this.exactFieldType = "keyword"; this.stringFieldType = "text"; this.indexProperty = "true"; this.includeTypeNameParam = version.isV6() ? "?include_type_name=true" : "";
<|startcomment|> Always 6 currently (above lines [61-62]; refactor? <|endcomment|>  } public static String supportedVersions() { return Joiner.on(", ").join(ElasticVersion.values()); } public boolean isV6() { return isVersion(6); } public boolean isV6OrLater() { return isAtLeastVersion(6); } public boolean isV7OrLater() { return isAtLeastVersion(7); } private boolean isAtLeastVersion(int v) { return Integer.valueOf(version.split("\\.")[0]) >= v; } <|startfocus|> private boolean isVersion(int v) { return Integer.valueOf(version.split("\\.")[0]) == v; <|endfocus|> } @Override public String toString() { return version; } } 
<|startcomment|> remove this <|endcomment|>  RawInputUtil.create(HTML_PLUGIN.getBytes(UTF_8)); private static final ImmutableList<String> PLUGINS = ImmutableList.of( "plugin-a.js", "plugin-b.html", "plugin-c.js", "plugin-d.html", "plugin_e.js"); @Inject private RequestScopeOperations requestScopeOperations; @Inject private MandatoryPluginsCollection mandatoryPluginsCollection; @Test @GerritConfig(name = "plugins.allowRemoteAdmin", value = "true") <|startfocus|> // @GerritConfig(name = "plugins.mandatory", value = "plugin_e.js") <|endfocus|> public void pluginManagement() throws Exception { // No plugins are loaded assertThat(list().get()).isEmpty(); assertThat(list().all().get()).isEmpty(); PluginApi api; // Install all the plugins InstallPluginInput input = new InstallPluginInput(); for (String plugin : PLUGINS) { input.raw = plugin.endsWith(".js") ? JS_PLUGIN_CONTENT : HTML_PLUGIN_CONTENT; api = gApi.plugins().install(plugin, input); assertThat(api).isNotNull(); PluginInfo info = api.get();
<|startcomment|> Unnecessary here as this is also part of checkLabelName(..). <|endcomment|>  public TestLabelPermission build() { TestLabelPermission result = autoBuild(); <|startfocus|> checkArgument( !Permission.isLabel(result.name()), "expected label name, got permission name: %s", result.name()); LabelType.checkName(result.name()); <|endfocus|> return result;
<|startcomment|> Nit: Here and in other tests, wouldn't it be sufficient to just check that the key is present? (This test doesn't really care about the format and content of the value and I would like to minimize the number of tests which break when we modify something. In theory, we wouldn't need this assertion at all as we should have other tests which ensure that projectOperations does the correct thing when adding permissions.) <|endcomment|>  "queryLimit", "+0..+" + DEFAULT_MAX_QUERY_LIMIT + " group global:Registered-Users"); } @Test public void removePermission() throws Exception { Project.NameKey key = projectOperations.newProject().create(); projectOperations .project(key) .forUpdate() .add(TestProjectUpdate.allow(Permission.ABANDON).ref("refs/foo").group(REGISTERED_USERS)) .update(); assertThat(projectOperations.project(key).getConfig()) .subsectionValues("access", "refs/foo") <|startfocus|> .containsEntry("abandon", "group global:Registered-Users"); <|endfocus|> projectOperations .project(key) .forUpdate() .remove( TestProjectUpdate.permissionKey(Permission.ABANDON) .ref("refs/foo") .group(REGISTERED_USERS)) .update(); assertThat(projectOperations.project(key).getConfig()) .subsectionValues("access", "refs/foo") .doesNotContainKey("abandon"); } @Test public void removeLabelPermission() throws Exception { Project.NameKey key = projectOperations.newProject().create(); projectOperations .project(key) .forUpdate() .add( TestProjectUpdate.allowLabel("Code-Review")
<|startcomment|> We should additionally output the map of recipients here. <|endcomment|>  private void rcpt(@Nullable RecipientType type, String email, boolean expected) { if (recipients.get(type).contains(email) != expected) { failWithoutActual( fact( <|startfocus|> expected ? "should notify" : "shouldn't notify", type + ": " + users.emailToName(email))); <|endfocus|> } if (expected) { accountedFor.add(email); }
<|startcomment|> Is this reformatting necessary? <|endcomment|>  r.assertNoContent(); assertThat(projectDir.exists()).isFalse(); } @Test @UseLocalDisk public void testSshDeleteProjectWithoutOptions() throws Exception { createChange(); String cmd = Joiner.on(" ").join(PLUGIN, "delete", project.get()); String expected = String.format( "Really delete '%s'?\n" + "This is an operation which permanently deletes data. This cannot be undone!\n" <|startfocus|> + "If you are sure you wish to delete this project, re-run with the" + " --yes-really-delete flag.\n\n", <|endfocus|> project.get()); adminSshSession.exec(cmd); assertThat(projectDir.exists()).isTrue(); assertThat(adminSshSession.getError()).isEqualTo(expected); } @Test @UseLocalDisk public void testSshDeleteProjYesReallyDelete() throws Exception { createChange(); String cmd = createDeleteCommand(project.get()); String expected = String.format( "Project '%s' has open changes. - To really delete '%s', re-run with the --force"
<|startcomment|> Don't import this explicitly; reference it as Account.Id in the code below. <|endcomment|> // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.schema; import com.google.common.collect.Iterables; import com.google.common.collect.Sets; import com.google.gerrit.reviewdb.client.Account; <|startfocus|> import com.google.gerrit.reviewdb.client.Account.Id; <|endfocus|> import com.google.gerrit.reviewdb.client.RefNames; import com.google.gerrit.reviewdb.server.ReviewDb; import com.google.gerrit.server.GerritPersonIdent; import com.google.gerrit.server.config.AllUsersName; import com.google.gerrit.server.git.GitRepositoryManager; import com.google.gwtorm.server.OrmException; import com.google.inject.Inject; import com.google.inject.Provider; import java.io.IOException; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; import java.sql.Timestamp; import java.time.Duration; import java.time.Instant; import java.util.Date; import java.util.HashMap; import java.util.List;
<|startcomment|> remove this? Here and everywhere else. <|endcomment|>  assertThat(accountState.getAccount().getFullName()).isEqualTo(fullName); AccountInfo info = gApi.accounts().id(accountId.get()).get(); assertThat(info.name).isEqualTo(fullName); List<EmailInfo> emails = gApi.accounts().id(accountId.get()).getEmails(); assertThat(emails.stream().map(e -> e.email).collect(toSet())).containsExactly(extId.email()); RevCommit commitUserBranch = <|startfocus|> this.projectOperations.project(allUsers).getHead(RefNames.refsUsers(accountId)); <|endfocus|> RevCommit commitRefsMetaExternalIds = this.projectOperations.project(allUsers).getHead(RefNames.REFS_EXTERNAL_IDS); assertThat(commitUserBranch.getCommitTime()) .isEqualTo(commitRefsMetaExternalIds.getCommitTime()); } finally { TestTimeUtil.useSystemTime(); } } @Test public void updateNonExistingAccount() throws Exception { Account.Id nonExistingAccountId = Account.id(999999); AtomicBoolean consumerCalled = new AtomicBoolean(); Optional<AccountState> accountState = accountsUpdateProvider .get() .update(
<|startcomment|> Duplicate code, same as line 143 - line 148 above. Remove this? <|endcomment|>  projectOperations .project(allUsers) .forUpdate() .add(allow(Permission.CREATE).ref(RefNames.REFS_USERS + "*").group(REGISTERED_USERS)) .add(allow(Permission.PUSH).ref(RefNames.REFS_USERS + "*").group(REGISTERED_USERS)) .update(); <|startfocus|> projectOperations .project(allUsers) .forUpdate() .add(allow(Permission.CREATE).ref(RefNames.REFS_USERS + "*").group(REGISTERED_USERS)) .add(allow(Permission.PUSH).ref(RefNames.REFS_USERS + "*").group(REGISTERED_USERS)) .update(); <|endfocus|> ResourceConflictException thrown = assertThrows( ResourceConflictException.class, () -> branch(BranchNameKey.create(allUsers, RefNames.refsUsers(admin.id()))).delete()); assertThat(thrown).hasMessageThat().contains("Not allowed to delete user branch."); } @Test public void deleteGroupBranch_Conflict() throws Exception { projectOperations .project(allUsers) .forUpdate() .add(allow(Permission.CREATE).ref(RefNames.REFS_GROUPS + "*").group(REGISTERED_USERS))
<|startcomment|> drop this? <|endcomment|>  assertThat(gApi.accounts().id(user.username()).get().name).isEqualTo("User McUserface"); } @Test public void userCannotSetNameOfOtherUser() throws Exception { requestScopeOperations.setApiUser(user.id()); assertThrows( AuthException.class, () -> gApi.accounts().id(admin.username()).setName("Admin McAdminface")); } @Test @Sandboxed public void userCanSetNameOfOtherUserWithModifyAccountPermission() throws Exception { <|startfocus|> AccountIT.this .projectOperations <|endfocus|> .project(allProjects) .forUpdate() .add(allowCapability(GlobalCapability.MODIFY_ACCOUNT).group(REGISTERED_USERS)) .update(); gApi.accounts().id(admin.username()).setName("Admin McAdminface"); assertThat(gApi.accounts().id(admin.username()).get().name).isEqualTo("Admin McAdminface"); } @Test public void fetchUserBranch() throws Exception { requestScopeOperations.setApiUser(user.id()); TestRepository<InMemoryRepository> allUsersRepo = cloneProject(allUsers, user); String userRefName = RefNames.refsUsers(user.id()); // remove default READ permissions
<|startcomment|> Is it intentional that these permissions are now set on 'allProjects' instead of on 'project'? <|endcomment|>  metaRef3, "refs/heads/master", "refs/tags/master-tag", "refs/users/00/1000000/edit-" + cd3.getId() + "/1", "refs/users/01/1000001/edit-" + cd3.getId() + "/1"); } @Test public void uploadPackSubsetOfRefsVisibleWithAccessDatabase() throws Exception { projectOperations .project(allProjects) .forUpdate() <|startfocus|> .add(allowCapability(GlobalCapability.ACCESS_DATABASE).group(REGISTERED_USERS)) <|endfocus|> .add(deny(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(allow(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update(); requestScopeOperations.setApiUser(admin.id()); gApi.changes().id(cd3.getId().get()).edit().create(); requestScopeOperations.setApiUser(user.id()); assertUploadPackRefs( // Change 1 is visible due to accessDatabase capability, even though // refs/heads/master is not. psRef1, metaRef1, psRef2, metaRef2, psRef3, metaRef3, psRef4, metaRef4,
<|startcomment|> Should this be projectConfigFactory? <|endcomment|>  ProjectConfig allProjectsConfig = projectConfigFactory.create(allProjectsName); allProjectsConfig.load(md); LabelType cr = Util.codeReview(); allProjectsConfig.getLabelSections().put(cr.getName(), cr); allProjectsConfig.commit(md); } } repoManager.createRepository(parentKey).close(); repoManager.createRepository(localKey).close(); try (MetaDataUpdate md = metaDataUpdateFactory.create(localKey)) { <|startfocus|> ProjectConfig newLocal = injector.getInstance(ProjectConfig.Factory.class).create(localKey); <|endfocus|> newLocal.load(md); newLocal.getProject().setParentName(parentKey); newLocal.commit(md); } requestContext.setContext(() -> null); } @After public void tearDown() throws Exception { requestContext.setContext(null); } @Test public void ownerProject() throws Exception { projectOperations .project(localKey) .forUpdate() .add(allow(OWNER).ref("refs/*").group(ADMIN)) .update(); assertAdminsAreOwnersAndDevsAreNot(); } @Test public void denyOwnerProject() throws Exception { projectOperations .project(localKey) .forUpdate()
<|startcomment|> In the old code this permission was set on the child project. <|endcomment|>  projectOperations .project(localKey) .forUpdate() .add(block(PUSH).ref("refs/heads/*").group(ANONYMOUS_USERS)) .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .update(); ProjectControl u = user(localKey, DEVS); assertCannotUpdate("refs/heads/master", u); } @Test public void unblockMoreSpecificRefInLocal_Fails() throws Exception { projectOperations .project(parentKey) .forUpdate() <|startfocus|> .add(block(PUSH).ref("refs/heads/*").group(ANONYMOUS_USERS)) <|endfocus|> .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .update(); ProjectControl u = user(localKey, DEVS); assertCannotUpdate("refs/heads/master", u); } @Test public void unblockMoreSpecificRefWithExclusiveFlag() throws Exception { projectOperations .project(localKey) .forUpdate() .add(block(PUSH).ref("refs/heads/*").group(ANONYMOUS_USERS)) .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .setExclusiveGroup(permissionKey(PUSH).ref("refs/heads/master"), true) .update(); 
<|startcomment|> In the old code the exclusive flag was set in the parent project. <|endcomment|>  assertCanVote(-2, range); } @Test public void unblockFromParentDoesNotAffectChild() throws Exception { projectOperations .project(parentKey) .forUpdate() .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .update(); projectOperations .project(localKey) .forUpdate() .add(block(PUSH).ref("refs/heads/master").group(DEVS)) <|startfocus|> .setExclusiveGroup(permissionKey(PUSH).ref("refs/heads/master"), true) <|endfocus|> .update(); ProjectControl u = user(localKey, DEVS); assertCannotUpdate("refs/heads/master", u); } @Test public void unblockFromParentDoesNotAffectChildDifferentGroups() throws Exception { projectOperations .project(parentKey) .forUpdate() .add(allow(PUSH).ref("refs/heads/master").group(DEVS)) .setExclusiveGroup(permissionKey(PUSH).ref("refs/heads/master"), true) .update(); projectOperations .project(localKey) .forUpdate() .add(block(PUSH).ref("refs/heads/master").group(ANONYMOUS_USERS)) .update(); ProjectControl u = user(localKey, DEVS);
<|startcomment|> broken sentence? <|endcomment|>  package com.google.gerrit.index.query; import static com.google.common.base.Preconditions.checkNotNull; import com.google.common.collect.ImmutableList; import java.util.Iterator; import java.util.function.Supplier; /** * Result set that allows for asynchronous execution of the actual query. Callers should dispatch * the query and call the constructor of this class with a supplier that fetches the result and * blocks on it if necessary. * <|startfocus|> * <p>If the execution is synchronous or the results are know a-priori, consider using {@link <|endfocus|> * ListResultSet}. */ public class LazyResultSet<T> implements ResultSet<T> { private final Supplier<ImmutableList<T>> resultsCallback; private boolean resultsReturned = false; public LazyResultSet(Supplier<ImmutableList<T>> r) { resultsCallback = checkNotNull(r, "results can't be null"); } @Override public Iterator<T> iterator() { return toList().iterator(); } @Override public ImmutableList<T> toList() { if (resultsReturned) { throw new IllegalStateException("Results already obtained");
<|startcomment|> Since [1] we prefer requireNonNull. [1] https://gerrit-review.googlesource.com/c/gerrit/+/223975 <|endcomment|>  public LazyResultSet(Supplier<ImmutableList<T>> r) { <|startfocus|> resultsCallback = checkNotNull(r, "results can't be null"); <|endfocus|>
<|startcomment|> requireNonNull <|endcomment|>  public ListResultSet(List<T> r) { <|startfocus|> results = ImmutableList.copyOf(checkNotNull(r, "results can't be null")); <|endfocus|>
<|startcomment|> Should this be a capability that supports a range? <|endcomment|>  } @Test public void testCapabilityAllowsZeroRangeOnCapabilityThatHasRange() throws Exception { TestCapability c = allowCapability(QUERY_LIMIT).group(REGISTERED_USERS).range(0, 0).build(); assertThat(c.min()).isEqualTo(0); assertThat(c.max()).isEqualTo(0); } @Test public void testCapabilityDisallowsInvertedRange() throws Exception { assertThrows( RuntimeException.class, <|startfocus|> () -> allowCapability(ADMINISTRATE_SERVER).group(REGISTERED_USERS).range(1, 0).build()); <|endfocus|> } @Test public void testCapabilityDisallowsRangeIfCapabilityDoesNotSupportRange() throws Exception { assertThrows( RuntimeException.class, () -> allowCapability(ADMINISTRATE_SERVER).group(REGISTERED_USERS).range(-1, 1).build()); } @Test public void testCapabilityRangeIsZeroIfCapabilityDoesNotSupportRange() throws Exception { TestCapability c = allowCapability(ADMINISTRATE_SERVER).group(REGISTERED_USERS).build(); assertThat(c.min()).isEqualTo(0); assertThat(c.max()).isEqualTo(0); } @Test public void testCapabilityUsesDefaultRangeIfUnspecified() throws Exception {
<|startcomment|> Keep? <|endcomment|> // limitations under the License. package com.ericsson.gerrit.plugins.highavailability.forwarder.rest; import com.ericsson.gerrit.plugins.highavailability.cache.Constants; import com.google.common.base.Strings; import com.google.common.base.Supplier; import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.reviewdb.client.AccountGroup; import com.google.gerrit.server.events.Event; import com.google.gerrit.server.events.EventDeserializer; import com.google.gerrit.server.events.SupplierDeserializer; import com.google.gson.Gson; import com.google.gson.GsonBuilder; import com.google.inject.Singleton; @Singleton <|startfocus|> final class GsonParser { private final Gson gson = new GsonBuilder() .registerTypeAdapter(Event.class, new EventDeserializer()) .registerTypeAdapter(Supplier.class, new SupplierDeserializer()) .create(); <|endfocus|> public Gson gson() { return gson; } Object fromJson(String cacheName, String json) { Object key; // Need to add a case for 'adv_bases' switch (cacheName) { case Constants.ACCOUNTS: key = gson.fromJson(Strings.nullToEmpty(json).trim(), Account.Id.class); break; case Constants.GROUPS:
<|startcomment|> nit: this can be package-private <|endcomment|> public class BranchCommitValidator { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final CommitValidators.Factory commitValidatorsFactory; private final IdentifiedUser user; private final PermissionBackend.ForProject permissions; private final Project project; private final BranchNameKey branch; private final SshInfo sshInfo; interface Factory { BranchCommitValidator create( ProjectState projectState, BranchNameKey branch, IdentifiedUser user); } /** A boolean validation status and a list of additional messages. */ @AutoValue <|startfocus|> public static abstract class Result { static Result create(boolean isValid, List<CommitValidationMessage> messages) { <|endfocus|> return new AutoValue_BranchCommitValidator_Result(isValid, messages); } /** Whether the commit is valid. */ abstract boolean isValid(); /** * A list of messages related to the validation. Messages may be present regardless of the * {@link #isValid()} status. */ abstract List<CommitValidationMessage> messages(); } @Inject BranchCommitValidator( CommitValidators.Factory commitValidatorsFactory, PermissionBackend permissionBackend, SshInfo sshInfo,
<|startcomment|> nit: ImmutableList Optionally you could accept a ImmutableList.Builder instead, this sometimes comes in handy (in this case as well I believe) <|endcomment|> <|startfocus|> static Result create(boolean isValid, List<CommitValidationMessage> messages) { <|endfocus|> return new AutoValue_BranchCommitValidator_Result(isValid, messages);
<|startcomment|> nit: ImmutableList <|endcomment|>  @AutoValue public static abstract class Result { static Result create(boolean isValid, List<CommitValidationMessage> messages) { return new AutoValue_BranchCommitValidator_Result(isValid, messages); } /** Whether the commit is valid. */ abstract boolean isValid(); /** * A list of messages related to the validation. Messages may be present regardless of the * {@link #isValid()} status. */ <|startfocus|> abstract List<CommitValidationMessage> messages(); <|endfocus|> } @Inject BranchCommitValidator( CommitValidators.Factory commitValidatorsFactory, PermissionBackend permissionBackend, SshInfo sshInfo, @Assisted ProjectState projectState, @Assisted BranchNameKey branch, @Assisted IdentifiedUser user) { this.sshInfo = sshInfo; this.user = user; this.branch = branch; this.commitValidatorsFactory = commitValidatorsFactory; project = projectState.getProject(); permissions = permissionBackend.user(user).project(project.getNameKey()); } /** * Validates a single commit. If the commit does not validate, the command is rejected. *
<|startcomment|> For Lucene tests, I saw that there's a mismatch between 'lucene' in the config and 'LUCENE' as enum name. I'm pretty sure that you need equalsIgnoreCase() here. <|endcomment|>  if (args.getSchema().hasField(ChangeField.EXTENSION)) { FileExtensionPredicate extensionPredicate = new FileExtensionPredicate(ext); if (ext.isEmpty()) { RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate("^.{0}$"); // RegexFileExtensionPredicate emptyExtPredicate = new RegexFileExtensionPredicate("^()$"); // cf. https://www.brics.dk/automaton/doc/index.html?dk/brics/automaton/RegExp.html return emptyExtPredicate; // return Predicate.or(extensionPredicate, emptyExtPredicate); } <|startfocus|> return extensionPredicate; <|endfocus|> } throw new QueryParseException("'extension' operator is not supported by change index version"); } @Operator public Predicate<ChangeData> onlyexts(String extList) throws QueryParseException { return onlyextensions(extList); } @Operator public Predicate<ChangeData> onlyextensions(String extList) throws QueryParseException { if (args.getSchema().hasField(ChangeField.ONLY_EXTENSIONS)) { return new FileExtensionListPredicate(extList); } throw new QueryParseException( "'onlyextensions' operator is not supported by change index version"); } @Operator
<|startcomment|> For all error messages: A kind of feel this should rather say "on an edit" to highlight that we are talking about a thing (a change edit) and not an action (e.g. during an edit action of something). <|endcomment|>  ChecksCollection( Checks checks, DynamicMap<RestView<CheckResource>> views, ListChecks listChecks) { this.checks = checks; this.views = views; this.listChecks = listChecks; } @Override public RestReadView<RevisionResource> list() throws RestApiException { return listChecks; } @Override public CheckResource parse(RevisionResource parent, IdString id) throws RestApiException, PermissionBackendException, IOException, StorageException { if (parent.getEdit().isPresent()) { <|startfocus|> throw new ResourceConflictException("checks are not supported on edit"); <|endfocus|> } CheckerUuid checkerUuid = CheckerUuid.tryParse(id.get()) .orElseThrow( () -> new BadRequestException(String.format("invalid checker UUID: %s", id.get()))); CheckKey checkKey = CheckKey.create(parent.getProject(), parent.getPatchSet().id(), checkerUuid); Optional<Check> check = checks.getCheck(checkKey, GetCheckOptions.withBackfilling()); return new CheckResource( parent, check.orElseThrow( () -> new ResourceNotFoundException( String.format(
<|startcomment|> Swap the two lines (101 and 102) so that scanAccounts happens first? This reduces the risk of the database connection timing out before the gc finishes. <|endcomment|>  @Inject Schema_146( Provider<Schema_145> prior, GitRepositoryManager repoManager, AllUsersName allUsersName, @GerritPersonIdent PersonIdent serverIdent) { super(prior); this.repoManager = repoManager; this.allUsersName = allUsersName; this.serverIdent = serverIdent; } @Override protected void migrateData(ReviewDb db, UpdateUI ui) throws OrmException, SQLException { ui.message("Migrating accounts"); gc(ui); <|startfocus|> Set<Entry<Account.Id, Timestamp>> accounts = scanAccounts(db, ui).entrySet(); <|endfocus|> Set<List<Entry<Account.Id, Timestamp>>> batches = Sets.newHashSet(Iterables.partition(accounts, 500)); ExecutorService pool = createExecutor(ui); try { batches.stream().forEach(batch -> pool.submit(() -> processBatch(batch, ui))); pool.shutdown(); pool.awaitTermination(Long.MAX_VALUE, TimeUnit.DAYS); } catch (InterruptedException e) { throw new RuntimeException(e); } ui.message( String.format("... (%.3f s) Migrated all %d accounts to schema 146", elapsed(), i.get())); } 
<|startcomment|> visibility (and likewise below) <|endcomment|>  return CacheBuilder.newBuilder().maximumSize(1 << 10).expireAfterWrite(30, TimeUnit.MINUTES); } public VisibilityCache(boolean topoSort) { this(topoSort, defaultBuilder()); } public VisibilityCache(boolean topoSort, CacheBuilder<Object, Object> builder) { this(new VisibilityChecker(topoSort), builder); } /** * Use the constructors with a boolean parameter (e.g. {@link #VisibilityCache(boolean)}). The <|startfocus|> * default visitiliby checker should cover all common use cases. <|endfocus|> * * <p>This constructor is useful to set e.g. an instrumented checker. */ public VisibilityCache(VisibilityChecker checker) { this(checker, defaultBuilder()); } /** * Use the constructors with a boolean parameter (e.g. {@link #VisibilityCache(boolean)}). The * default visitiliby checker should cover all common use cases. * * <p>This constructor is useful to set e.g. an instrumented checker. */ public VisibilityCache(VisibilityChecker checker, CacheBuilder<Object, Object> builder) { this.cache = builder.build();
<|startcomment|> optional: can spell this out more ---e.g. /** * @param topoSort whether to use a more thorough reachability check * by sorting in topological order */ <|endcomment|> import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.RefDatabase; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevSort; import org.eclipse.jgit.revwalk.RevWalk; /** * Checks for object visibility * * <p>Objects are visible if they are reachable from any of the references visible to the user. */ public class VisibilityChecker { private boolean topoSort; <|startfocus|> /** @param topoSort if the walk for reachability must follow topological order */ <|endfocus|> public VisibilityChecker(boolean topoSort) { this.topoSort = topoSort; } /** * Check if any of the refs in {@code refDb} points to the object {@code id}. * * @param refDb a reference database * @param id object we are looking for * @return true if the any of the references in the db points directly to the id * @throws IOException the reference space cannot be accessed */
<|startcomment|> Why this change? Looks like this used to have a helpful diagram, but it should use <pre>. In any event, it looks orthogonal to this change. <|endcomment|> import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.junit.runners.JUnit4; @RunWith(JUnit4.class) public class VisibilityCacheTest { private InMemoryRepository repo; private GitilesAccess access = new FakeGitilesAccess(); private RevCommit baseCommit; private RevCommit commit1; private RevCommit commit2; private RevCommit commitA; private RevCommit commitB; private RevCommit commitC; private VisibilityCache visibilityCache; private RevWalk walk; @Before <|startfocus|> public void setUp() throws Exception { <|endfocus|> repo = new InMemoryRepository(new DfsRepositoryDescription()); TestRepository<InMemoryRepository> git = new TestRepository<>(repo); baseCommit = git.commit().message("baseCommit").create(); commit1 = git.commit().parent(baseCommit).message("commit1").create(); commit2 = git.commit().parent(commit1).message("commit2").create(); commitA = git.commit().parent(baseCommit).message("commitA").create(); commitB = git.commit().parent(commitA).message("commitB").create();
<|startcomment|> Add "TODO" in these comments? <|endcomment|>  public void diffOfNonExistentFileIsAnEmptyDiffResult() throws Exception { addModifiedPatchSet(changeId, FILE_NAME, content -> content.replace("Line 2\n", "Line two\n")); DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, "a_non-existent_file.txt") .withBase(initialPatchSetId) .withContext(DiffPreferencesInfo.WHOLE_FILE_CONTEXT) .get(); assertThat(diffInfo).content().isEmpty(); } <|startfocus|> // This behavior is likely a bug. A fix might not be easy as it might break syntax highlighting. <|endfocus|> @Test public void contextParameterIsIgnored() throws Exception { addModifiedPatchSet( changeId, FILE_NAME, content -> content.replace("Line 20\n", "Line twenty\n")); DiffInfo diffInfo = getDiffRequest(changeId, CURRENT, FILE_NAME) .withBase(initialPatchSetId) .withContext(5) .get(); assertThat(diffInfo).content().element(0).commonLines().hasSize(19); assertThat(diffInfo).content().element(1).linesOfA().containsExactly("Line 20");
<|startcomment|> This should be preserved. This was done in: [1] and should stay as is. On stable branches it was done differently, because GsonEventDeserializer was only added in gerrit core on master in: [2] and renamed to EventGson in: [3]. * [1] https://gerrit-review.googlesource.com/c/plugins/high-availability/+/225264 * [2] https://gerrit-review.googlesource.com/c/gerrit/+/222306 * [3] https://gerrit-review.googlesource.com/c/gerrit/+/222713 <|endcomment|>  package com.ericsson.gerrit.plugins.highavailability.forwarder.rest; import com.ericsson.gerrit.plugins.highavailability.cache.Constants; import com.google.common.base.Strings; import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.reviewdb.client.AccountGroup; import com.google.gson.Gson; import com.google.gson.JsonElement; import com.google.gson.JsonObject; import com.google.inject.Inject; import com.google.inject.Singleton; @Singleton class GsonParser { private final Gson gson; @Inject <|startfocus|> GsonParser(GsonProvider gson) { this.gson = gson.get(); <|endfocus|> } public Object fromJson(String cacheName, String jsonString) { JsonElement json = gson.fromJson(Strings.nullToEmpty(jsonString), JsonElement.class); Object key; // Need to add a case for 'adv_bases' if (!json.isJsonObject()) { return json.getAsString(); } JsonObject asJsonObject = json.getAsJsonObject(); switch (cacheName) { case Constants.ACCOUNTS: key = asJsonObject.has("id") ? Account.id(asJsonObject.get("id").getAsInt()) : null; break;
<|startcomment|> can you move this to a local var where it is used? This otherwise looks suspect due to potential threading issues. <|endcomment|>  * file constructed to trigger excessive backtracking. */ public class CheckConfig { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); public static final String toolName = "check_new_config"; private static final String ACCESS = "access"; private static final String LABEL = "label"; private static final String PLUGIN = "plugin"; private static final int BUFFER_SIZE = 2048; <|startfocus|> private static final char[] BUFFER = new char[BUFFER_SIZE]; <|endfocus|> private String pluginName; private Config configProject; ScannerConfig scannerConfig; public CheckConfig(String pluginName, String projectConfigContents) throws ConfigInvalidException { this.pluginName = pluginName; configProject = new Config(); configProject.fromText(projectConfigContents); Config config = new Config(); for (String name : configProject.getNames(PLUGIN, pluginName)) { config.setStringList( PLUGIN, pluginName, name, Arrays.asList(configProject.getStringList(PLUGIN, pluginName, name))); } PluginConfig pluginConfig = new PluginConfig(pluginName, config);
<|startcomment|> document what this is. is it the project.config file? If so, from which repository? (They inherit from each other.) <|endcomment|>  * file constructed to trigger excessive backtracking. */ public class CheckConfig { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); public static final String toolName = "check_new_config"; private static final String ACCESS = "access"; private static final String LABEL = "label"; private static final String PLUGIN = "plugin"; private static final int BUFFER_SIZE = 2048; private static final char[] BUFFER = new char[BUFFER_SIZE]; <|startfocus|> private String pluginName; <|endfocus|> private Config configProject; ScannerConfig scannerConfig; public CheckConfig(String pluginName, String projectConfigContents) throws ConfigInvalidException { this.pluginName = pluginName; configProject = new Config(); configProject.fromText(projectConfigContents); Config config = new Config(); for (String name : configProject.getNames(PLUGIN, pluginName)) { config.setStringList( PLUGIN, pluginName, name, Arrays.asList(configProject.getStringList(PLUGIN, pluginName, name))); } PluginConfig pluginConfig = new PluginConfig(pluginName, config);
<|startcomment|> signature <|endcomment|>  * * <p>When a new commit alters the configured scanner patterns, the push will fail with a message * to download the plugin source, to run a shell script that runs {@code main} below, and to copy * the output on success into the commit message. * * <p>This method scans the commit message to find the copied text. If the text was created for <|startfocus|> * the same pattern signagure, this method returns a single valid finding with the number of <|endfocus|> * microseconds it took to scan a large file, which can be used to block patterns that cause * excessive backtracking. * * <p>If the commit message contains one or more copied texts for other pattern signatures, this * method retuns an invalid finding for each. * * <p>If the commit message contains no copied texts, this method returns an empty list of * findings, which {@link com.googlesource.gerrit.plugins.copyright.CopyrightConfig} uses as a
<|startcomment|> add comment. This is a timeout for what operation exactly? <|endcomment|> import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Constants; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectLoader; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevTree; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.treewalk.TreeWalk; /** Listener to manage configuration for enforcing review of copyright declarations and licenses. */ @Singleton class CopyrightConfig implements CommitValidationListener, RevisionCreatedListener, GitReferenceUpdatedListener { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); <|startfocus|> <|endfocus|> private final long DEFAULT_MAX_ELAPSED_SECONDS = 8; private final Metrics metrics; private final AllProjectsName allProjectsName; private final String pluginName; private final GitRepositoryManager repoManager; private final ProjectCache projectCache; private final PluginConfigFactory pluginConfigFactory; private final CopyrightReviewApi reviewApi; private PluginConfig gerritConfig; private CheckConfig checkConfig; static AbstractModule module() { return new AbstractModule() { @Override protected void configure() { DynamicSet.bind(binder(), CommitValidationListener.class).to(CopyrightConfig.class);
<|startcomment|> this will clear out an existing error-free configuration. Is that what you want? <|endcomment|>  if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { clearConfig(); checkConfig = readConfig(event.getNewObjectId()); } catch (IOException | ConfigInvalidException e) { logger.atSevere().withCause(e).log("%s plugin unable to load configuration", pluginName); <|startfocus|> checkConfig = null; <|endfocus|> return; } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); }
<|startcomment|> inspecting all these log events requires looking at server logs, which you can't do, and we don't unless if there is a problem. Can you add a metric that will let you monitor for problems proactively? <|endcomment|>  "%s plugin revision %s: error posting review: %s", pluginName, event.getChange().currentRevision, result.error); } for (Map.Entry<String, AddReviewerResult> entry : result.reviewers.entrySet()) { AddReviewerResult arr = entry.getValue(); if (!Strings.isNullOrEmpty(arr.error)) { logger.atSevere().log( "%s plugin revision %s: error adding reviewer %s: %s", <|startfocus|> pluginName, event.getChange().currentRevision, entry.getKey(), arr.error); <|endfocus|> } }
<|startcomment|> injecting postReview looks like overkill. Can't this use the extension API? In particular, RevisionApi#review <|endcomment|>  * * @throws RestApiException if an error occurs updating the review thread */ private ReviewResult review(ChangeResource change, ReviewInput ri) throws RestApiException { try { PatchSet ps = psUtil.current(change.getNotes()); if (ps == null) { throw new ResourceNotFoundException(IdString.fromDecoded("current")); } RevisionResource revision = RevisionResource.createNonCacheable(change, ps); return postReview.apply(revision, ri).value(); } catch (Exception e) { Throwables.throwIfUnchecked(e); throw e instanceof RestApiException <|startfocus|> ? (RestApiException) e : new RestApiException("Cannot post review", e); <|endfocus|> } } /** Returns true if {@code priorComments} already includes a comment identical to {@code ci}. */ @VisibleForTesting boolean containsComment(Iterable<? extends Comment> priorComments, CommentInput ci) { if (priorComments == null) { return false; } for (Comment prior : priorComments) { if (Objects.equals(prior.line, ci.line)
<|startcomment|> this seems superfluous given the 2 metrics below. <|endcomment|>  * @param event describes the newly created revision triggering the scan * @throws IOException if an error occurred reading the repository * @throws RestApiException if an error occured reporting findings to the review thread */ private void scanRevision(String project, String branch, RevisionCreatedListener.Event event) throws IOException, RestApiException { Map<String, ImmutableList<Match>> findings = new HashMap<>(); ArrayList<String> containedPaths = new ArrayList<>(); long scanStart = System.nanoTime(); <|startfocus|> metrics.scanCount.increment(); <|endfocus|> metrics.scanCountByProject.increment(project); metrics.scanCountByBranch.increment(branch); try (Repository repo = repoManager.openRepository(Project.nameKey(project)); RevWalk revWalk = new RevWalk(repo); TreeWalk tw = new TreeWalk(revWalk.getObjectReader())) { RevCommit commit = repo.parseCommit(ObjectId.fromString(event.getRevision().commit.commit)); tw.setRecursive(true); tw.setFilter(TreeFilter.ANY_DIFF); tw.addTree(commit.getTree()); if (commit.getParentCount() > 0) {
<|startcomment|> this state is tied to what exactly? <|endcomment|> import com.google.gerrit.server.git.validators.ValidationMessage; import com.google.gerrit.server.project.ProjectConfig; import com.googlesource.gerrit.plugins.copyright.lib.CopyrightPatterns; import com.googlesource.gerrit.plugins.copyright.lib.CopyrightPatterns.UnknownPatternName; import com.googlesource.gerrit.plugins.copyright.lib.CopyrightScanner; import java.util.ArrayList; import java.util.Collection; import java.util.LinkedHashSet; import java.util.Objects; import java.util.function.Consumer; import java.util.regex.Pattern; import java.util.regex.PatternSyntaxException; <|startfocus|> /** Configuration state for {@link CopyrightValidator}. */ <|endfocus|> class ScannerConfig { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); public static final String KEY_ENABLE = "enable"; static final String KEY_TIME_TEST_MAX = "timeTestMax"; static final String DEFAULT_REVIEW_LABEL = "Copyright-Review"; static final String KEY_REVIEWER = "reviewer"; static final String KEY_CC = "cc"; static final String KEY_FROM = "fromAccountId"; static final String KEY_REVIEW_LABEL = "reviewLabel"; static final String KEY_EXCLUDE = "exclude";
<|startcomment|> How about inlining (collapsing) the major check, to also simplify these checks overall?: return isAtLeastVersion(version.getMajor()) && getMinor() >= version.getMinor()); <|endcomment|>  } public boolean isV6() { return isVersion(6); } public boolean isV6OrLater() { return isAtLeastVersion(6); } public boolean isV7OrLater() { return isAtLeastVersion(7); } private boolean isAtLeastVersion(int v) { return Integer.valueOf(version.split("\\.")[0]) >= v; } <|startfocus|> private boolean isVersion(int v) { return Integer.valueOf(version.split("\\.")[0]) == v; <|endfocus|> } @Override public String toString() { return version; } } 
<|startcomment|> I think we shouldn't restore any old state but throw (or log) instead: If you run a Runnable on a thread it can't be preempted in itself. So it would be safe to expect that: When we start processing it, all thread locals are null. If they are not, a prior action has leaked state. Before we leave, we clean up by un-setting all thread locals. <|endcomment|>  boolean oldForceLogging = loggingCtx.isLoggingForced(); boolean oldPerformanceLogging = loggingCtx.isPerformanceLogging(); ImmutableList<PerformanceLogRecord> oldPerformanceLogRecords = loggingCtx.getPerformanceLogEntries(); loggingCtx.setTags(tags); loggingCtx.forceLogging(forceLogging); loggingCtx.performanceLogging(performanceLogging); loggingCtx.setPerformanceLogEntries(performanceLogRecords); try { runnable.run(); } finally { loggingCtx.setTags(oldTags); loggingCtx.forceLogging(oldForceLogging); loggingCtx.performanceLogging(oldPerformanceLogging); <|startfocus|> loggingCtx.setPerformanceLogEntries(oldPerformanceLogRecords); <|endfocus|> } } } 
<|startcomment|> Please seem my comment above <|endcomment|>  public void close() { if (LoggingContext.getInstance().isPerformanceLogging()) { runEach(performanceLoggers, LoggingContext.getInstance().getPerformanceLogEntries()); } // Restore old state. LoggingContext.getInstance().performanceLogging(oldPerformanceLogging); <|startfocus|> LoggingContext.getInstance().setPerformanceLogEntries(oldPerformanceLogRecords); <|endfocus|>
<|startcomment|> Rename this to make it clearer what we're testing? I.e something like grantReadOnRefsTagsDoesNothing? <|endcomment|>  .forUpdate() .add(allow(Permission.READ).ref("refs/*").group(REGISTERED_USERS)) .add(allow(Permission.READ).ref(RefNames.REFS_CONFIG).group(REGISTERED_USERS)) .update(); assertUploadPackRefs( "HEAD", psRef1, metaRef1, psRef2, metaRef2, psRef3, metaRef3, psRef4, metaRef4, "refs/heads/branch", "refs/heads/master", RefNames.REFS_CONFIG, "refs/tags/branch-tag", <|startfocus|> "refs/tags/master-tag"); <|endfocus|> } @Test public void uploadPackSubsetOfBranchesVisibleIncludingHead() throws Exception { projectOperations .project(project) .forUpdate() .add(allow(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(deny(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update(); requestScopeOperations.setApiUser(user.id()); assertUploadPackRefs( "HEAD", psRef1, metaRef1, psRef3, metaRef3, "refs/heads/master", "refs/tags/master-tag"); } @Test
<|startcomment|> Add a comment here to make it clear we expect nothing to be visible? <|endcomment|>  metaRef4, "refs/heads/branch", "refs/heads/master", RefNames.REFS_CONFIG, "refs/tags/branch-tag", "refs/tags/master-tag"); } @Test public void uploadPackSubsetOfBranchesVisibleIncludingHead() throws Exception { projectOperations .project(project) .forUpdate() .add(allow(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(deny(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update(); requestScopeOperations.setApiUser(user.id()); assertUploadPackRefs( <|startfocus|> "HEAD", psRef1, metaRef1, psRef3, metaRef3, "refs/heads/master", "refs/tags/master-tag"); <|endfocus|> } @Test public void uploadPackSubsetOfBranchesVisibleNotIncludingHead() throws Exception { projectOperations .project(project) .forUpdate() .add(deny(Permission.READ).ref("refs/heads/master").group(REGISTERED_USERS)) .add(allow(Permission.READ).ref("refs/heads/branch").group(REGISTERED_USERS)) .update(); requestScopeOperations.setApiUser(user.id()); assertUploadPackRefs( psRef2, metaRef2,
<|startcomment|> Both standalone and in-tree tests fail to build for me locally, as this package "does not exist". Stable-2.15 works (double-checked). <|endcomment|> // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.readonly; import static com.google.common.truth.Truth.assertThat; import com.google.gerrit.acceptance.RestResponse; import com.google.gerrit.server.config.GerritServerConfig; <|startfocus|> import com.google.gerrit.testutil.ConfigSuite; <|endfocus|> import com.google.inject.Inject; import org.eclipse.jgit.lib.Config; public class ReadOnlyByHttpIT extends AbstractReadOnlyTest { @ConfigSuite.Default public static Config withPluginNamePrefix() { Config cfg = new Config(); cfg.setString("readonly", "test", "endpoint", "readonly~readonly"); return cfg; } @ConfigSuite.Config public static Config withoutPluginNamePrefix() { Config cfg = new Config(); cfg.setString("readonly", "test", "endpoint", "readonly"); return cfg; } 
<|startcomment|> Cannot resolve; WIP. <|endcomment|>  } else if (input.httpPassword == null) { newPassword = null; } else { // Only administrators can explicitly set the password. permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); newPassword = input.httpPassword; } return apply(rsrc.getUser(), newPassword); } // Used by the admin console plugin // TODO(dpursehouse): Replace comment with @UsedAt public Response<String> apply(IdentifiedUser user, String newPassword) <|startfocus|> throws ResourceNotFoundException, ResourceConflictException, OrmException, IOException, <|endfocus|> ConfigInvalidException { String userName = user.getUserName().orElseThrow(() -> new ResourceConflictException("username must be set")); Optional<ExternalId> optionalExtId = externalIds.get(ExternalId.Key.create(SCHEME_USERNAME, userName)); ExternalId extId = optionalExtId.orElseThrow(ResourceNotFoundException::new); accountsUpdateProvider .get() .update( "Set HTTP Password via API", extId.accountId(), u -> u.updateExternalId( ExternalId.createWithPassword(
<|startcomment|> Can you please add a comment here (assuming I understand this test case correctly) that says that the only OWNERS listed will be from the readable OWNERS files/includes. <|endcomment|>  // included: pA:d2/OWNERS, pA:d2/../f1, pA:d1/f1 // inherited: pA:OWNERS String owners = "owners:[ " + concat(ownerJson("pAd1f1@g"), ", ") + concat(ownerJson("pAd2@g"), ", ") + concat(ownerJson("pAf1@g"), ", ") <|startfocus|> + concat(ownerJson("pA@g", 0, 1, 0), " ]"); <|endfocus|> assertThat(getOwnersResponse(c1)).contains(owners); } } 
<|startcomment|> It's not necessary to use String.format. Just use the Logger's built-in formatting. <|endcomment|>  private void handleGitReferenceUpdatedAsUser(Event event, Account.Id updaterAccountId) { try (ManualRequestContext ctx = oneOffReqCtx.openAs(updaterAccountId)) { handleGitReferenceUpdated(event); } catch (OrmException e) { <|startfocus|> logger.warn( String.format("Unable to process event %s on project %s", event, event.getProjectName()), e); <|endfocus|> }
<|startcomment|> GitReferenceUpdatedListener interface states that AccountInfo getUpdater() could be nullable. This code would silently do nothing, if that was the case. Is that the wanted behaviour? Should we not handle the null case as well? <|endcomment|>  public void onGitReferenceUpdated(Event event) { AccountInfo updaterAccountInfo = event.getUpdater(); CurrentUser currentUser = currentUserProvider.get(); if (currentUser.isIdentifiedUser()) { handleGitReferenceUpdated(event); } else if (updaterAccountInfo != null) { <|startfocus|> handleGitReferenceUpdatedAsUser(event, new Account.Id(updaterAccountInfo._accountId)); <|endfocus|> }
<|startcomment|> This is sharing a list (the ArrayList object) between two threads. However, the object isn't thread safe. <|endcomment|>  // For the performance log records use the list instance from the logging context of the calling // thread in the logging context of the new thread. This way performance log records that are // created from the new thread are available from the logging context of the calling thread. // This is important since performance log records are processed only at the end of the request // and performance log records that are created in another thread should not get lost. <|startfocus|> loggingCtx.setMutablePerformanceLogRecordList(mutablePerformanceLogRecords); <|endfocus|> try { return callable.call(); } finally { loggingCtx.setTags(oldTags); loggingCtx.forceLogging(oldForceLogging); loggingCtx.performanceLogging(oldPerformanceLogging); loggingCtx.setPerformanceLogRecords(oldPerformanceLogRecords); } } } 
<|startcomment|> Doing work in a constructor is strongly discouraged. Doing work which throws exceptions such as these and additionally having Guice for DI might cause serious issues (e.g. server can't even start if one of the exceptions is thrown). Please find a different way or tell me if you need further ideas. <|endcomment|>  .setRate() .setUnit("errors"), project); errors = metricMaker.newCounter( "error_count", new Description("Number of errors of any kind").setRate().setUnit("errors")); } } @Inject CopyrightConfig( Metrics metrics, AllProjectsName allProjectsName, @PluginName String pluginName, GitRepositoryManager repoManager, ProjectCache projectCache, PluginConfigFactory pluginConfigFactory, <|startfocus|> CopyrightReviewApi reviewApi) throws IOException, ConfigInvalidException { <|endfocus|> this.metrics = metrics; this.allProjectsName = allProjectsName; this.pluginName = pluginName; this.repoManager = repoManager; this.projectCache = projectCache; this.pluginConfigFactory = pluginConfigFactory; this.reviewApi = reviewApi; long nanoStart = System.nanoTime(); try { checkConfig = readConfig(projectCache.getAllProjects().getProject().getConfigRefState()); } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); } } private CopyrightConfig(
<|startcomment|> I didn't find any (Java) test path which uses these methods. Can you please point me to the code? (If we do need this code for some tests, could we rather move it close to the tests?) <|endcomment|>  throws ConfigInvalidException { metrics = new Metrics(metricMaker); allProjectsName = new AllProjectsName("All-Projects"); pluginName = "copyright"; repoManager = null; projectCache = null; pluginConfigFactory = null; this.reviewApi = reviewApi; checkConfig = new CheckConfig(pluginName, projectConfigContents); } @VisibleForTesting static CopyrightConfig createTestInstance( MetricMaker metricMaker, CopyrightReviewApi reviewApi, String projectConfigContents) throws ConfigInvalidException { return new CopyrightConfig(metricMaker, reviewApi, projectConfigContents); } <|startfocus|> ScannerConfig getScannerConfig() { return checkConfig.scannerConfig; } <|endfocus|> /** Listens for merges to /refs/meta/config on All-Projects to reload plugin configuration. */ @Override public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try {
<|startcomment|> Any log statements: Please only use the 'severe' level for severe errors. We typically don't want most of these log statements in our production logs except if we explicitly choose a finer log level. <|endcomment|>  public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { logger.atSevere().log("\n\nonGitRefUpdated\n\n"); checkConfig = readConfig(event.getNewObjectId()); <|startfocus|> logger.atSevere().log("\n\nonGitRefUpdated: '%s'\n\n", checkConfig); <|endfocus|> } catch (IOException | ConfigInvalidException e) { logger.atSevere().withCause(e).log("%s plugin unable to load configuration", pluginName); metrics.configurationErrors.increment(allProjectsName.get()); metrics.errors.increment(); return; } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); }
<|startcomment|> Here and everywhere else this occurs: I see why those four \n might be helpful when debugging the plugin while implementing it but we don't want to have four empty lines in our production logs. <|endcomment|>  public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { logger.atSevere().log("\n\nonGitRefUpdated\n\n"); checkConfig = readConfig(event.getNewObjectId()); <|startfocus|> logger.atSevere().log("\n\nonGitRefUpdated: '%s'\n\n", checkConfig); <|endfocus|> } catch (IOException | ConfigInvalidException e) { logger.atSevere().withCause(e).log("%s plugin unable to load configuration", pluginName); metrics.configurationErrors.increment(allProjectsName.get()); metrics.errors.increment(); return; } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); }
<|startcomment|> When will this log statement be helpful? Are you thinking of a specific failure case you want to have more details on? If there's a reasonable failure case where this statement would be helpful, please use a more descriptive message. <|endcomment|>  public void onGitReferenceUpdated(GitReferenceUpdatedListener.Event event) { if (!event.getRefName().equals(RefNames.REFS_CONFIG)) { return; } if (!event.getProjectName().equals(allProjectsName.get())) { return; } long nanoStart = System.nanoTime(); try { logger.atSevere().log("\n\nonGitRefUpdated\n\n"); checkConfig = readConfig(event.getNewObjectId()); <|startfocus|> logger.atSevere().log("\n\nonGitRefUpdated: '%s'\n\n", checkConfig); <|endfocus|> } catch (IOException | ConfigInvalidException e) { logger.atSevere().withCause(e).log("%s plugin unable to load configuration", pluginName); metrics.configurationErrors.increment(allProjectsName.get()); metrics.errors.increment(); return; } finally { long elapsedMicros = (System.nanoTime() - nanoStart) / 1000; metrics.readConfigTimer.record(elapsedMicros, TimeUnit.MICROSECONDS); }
<|startcomment|> This makes it sound like the behavior is not expected, however I would say that it is expected. If I have a draft comment with ID 123 and then publish a comment with the same ID, I would expect the draft to be deleted. Maybe change the comment to "DraftHandling.KEEP is ignored on publishing a comment"? <|endcomment|>  CommentInfo draftInfo = Iterables.getOnlyElement(drafts.get(draft.path)); ReviewInput reviewInput = new ReviewInput(); reviewInput.drafts = DraftHandling.KEEP; reviewInput.message = "foo"; CommentInput comment = newComment(file, Side.REVISION, 0, "comment", false); // Replace the existing draft. comment.id = draftInfo.id; reviewInput.comments = new HashMap<>(); reviewInput.comments.put(comment.path, ImmutableList.of(comment)); revision(r).review(reviewInput); <|startfocus|> // The draft was deleted despite DraftHandling.KEEP. <|endfocus|> drafts = getDraftComments(changeId, revId); assertThat(drafts).isEmpty(); } @Test public void listComments() throws Exception { String file = "file"; PushOneCommit push = pushFactory.create(admin.newIdent(), testRepo, "first subject", file, "contents"); PushOneCommit.Result r = push.to("refs/for/master"); String changeId = r.getChangeId(); String revId = r.getCommit().getName(); assertThat(getPublishedComments(changeId, revId)).isEmpty(); 
<|startcomment|> Nit: Without the type parameters, the cast is unnecessary and this can simply be: StandardSubjectBuilder::that <|endcomment|>  (metadata, value) -> elementAssertThatFunction.apply(value); return assertThat(optional, valueSubjectFactory); } public static <S extends Subject, T> OptionalSubject<S, T> assertThat( Optional<T> optional, Subject.Factory<S, T> valueSubjectFactory) { return assertAbout(optionals()).thatCustom(optional, valueSubjectFactory); } public static OptionalSubject<Subject, ?> assertThat(Optional<?> optional) { <|startfocus|> return assertAbout(optionals()) .that(optional, (builder, value) -> (DefaultSubject) builder.that(value)); <|endfocus|> } public static CustomSubjectBuilder.Factory<OptionalSubjectBuilder> optionals() { return OptionalSubjectBuilder::new; } private OptionalSubject( FailureMetadata failureMetadata, Optional<T> optional, BiFunction<StandardSubjectBuilder, ? super T, ? extends S> valueSubjectCreator) { super(failureMetadata, optional); this.optional = optional; this.valueSubjectCreator = valueSubjectCreator; } public void isPresent() { isNotNull(); if (!optional.isPresent()) { failWithoutActual(fact("expected to have", "value")); } } public void isAbsent() {
<|startcomment|> Nit: Same as above. StandardSubjectBuilder::that <|endcomment|>  } public static class OptionalSubjectBuilder extends CustomSubjectBuilder { OptionalSubjectBuilder(FailureMetadata failureMetadata) { super(failureMetadata); } public <S extends Subject, T> OptionalSubject<S, T> thatCustom( Optional<T> optional, Subject.Factory<S, T> valueSubjectFactory) { return that(optional, (builder, value) -> builder.about(valueSubjectFactory).that(value)); } public OptionalSubject<Subject, ?> that(Optional<?> optional) { <|startfocus|> return that(optional, (builder, value) -> (DefaultSubject) builder.that(value)); <|endfocus|> } public <S extends Subject, T> OptionalSubject<S, T> that( Optional<T> optional, BiFunction<StandardSubjectBuilder, ? super T, ? extends S> valueSubjectCreator) { return new OptionalSubject<>(metadata(), optional, valueSubjectCreator); } } } 
<|startcomment|> Both of these parameters can be null. Please mark them with the com.google.gerrit.common.Nullable annotation so that IDEs and other systems have a chance to automatically mark unsafe usages. In addition, can you please check that all usages are guarded against null values? (I at least saw a usage of checkConfig which might run into a NullPointerException.) <|endcomment|>  GitReferenceUpdatedListener, LifecycleListener { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); /** Default value of timeTestMax configuration parameter for avoiding excessive backtracking. */ private final long DEFAULT_MAX_ELAPSED_SECONDS = 8; private final Metrics metrics; private final AllProjectsName allProjectsName; private final String pluginName; private final GitRepositoryManager repoManager; private final ProjectCache projectCache; private final PluginConfigFactory pluginConfigFactory; private final CopyrightReviewApi reviewApi; <|startfocus|> private PluginConfig gerritConfig; private CheckConfig checkConfig; <|endfocus|> static AbstractModule module() { return new AbstractModule() { @Override protected void configure() { DynamicSet.bind(binder(), CommitValidationListener.class).to(CopyrightConfig.class); DynamicSet.bind(binder(), LifecycleListener.class).to(CopyrightConfig.class); DynamicSet.bind(binder(), RevisionCreatedListener.class).to(CopyrightConfig.class); DynamicSet.bind(binder(), GitReferenceUpdatedListener.class).to(CopyrightConfig.class); } }; } @Inject CopyrightConfig( Metrics metrics, AllProjectsName allProjectsName, @PluginName String pluginName,
<|startcomment|> Here and for other CommitValidationExceptions: Reading the relevant code paths correctly, this is the message presented to the user upon a failing git push. Was the message formulated with this in mind? Here, it might also make sense to add the plugin name (if you don't consider it PII and don't need to hide the name from users) as it's not automatically added. This would help in failure cases when users complain about a failing pushes and just mention "project.config", which could also apply to other Gerrit functionality. <|endcomment|>  } } boolean pluginEnabled = gerritConfig != null && gerritConfig.getBoolean(ScannerConfig.KEY_ENABLE, false); CheckConfig.checkProjectConfig(reviewApi, pluginEnabled, trialConfig); return trialConfig == null || trialConfig.scannerConfig == null ? Collections.emptyList() : trialConfig.scannerConfig.messages; } } catch (IOException e) { logger.atSevere().withCause(e).log("failed to read new project.config"); <|startfocus|> throw new CommitValidationException("failed to read new project.config", e); <|endfocus|> } catch (ConfigInvalidException e) { logger.atSevere().withCause(e).log("unable to parse plugin config"); if (trialConfig != null && trialConfig.scannerConfig != null) { trialConfig.scannerConfig.messages.add(ScannerConfig.errorMessage(e.getMessage())); metrics.configurationErrors.increment(allProjectsName.get()); metrics.errors.increment(); return trialConfig.scannerConfig.messages; } else { throw new CommitValidationException("unable to parse new project.config", e); } } finally { if (trialConfig != null && trialConfig.scannerConfig != null
<|startcomment|> This method should be marked with @Nullable. <|endcomment|>  return scannerConfig.defaultEnable; } return pluginConfig.getBoolean(ScannerConfig.KEY_ENABLE, scannerConfig.defaultEnable); } /** * Loads and compiles configured patterns from {@code ref/meta/All-Projects/project.config} and * {@code gerrit.config}. * * @param projectConfigObjectId identifies the version of project.config to load and to compile * @return the new scanner configuration to check * @throws IOException if accessing the repository fails <|startfocus|> */ <|endfocus|> private CheckConfig readConfig(String projectConfigObjectId) throws IOException, ConfigInvalidException { CheckConfig checkConfig = null; // new All-Projects project.config not yet in cache -- read from repository ObjectId id = ObjectId.fromString(projectConfigObjectId); if (ObjectId.zeroId().equals(id)) { return checkConfig; } try (Repository repo = repoManager.openRepository(allProjectsName)) { checkConfig = new CheckConfig(pluginName, readFileContents(repo, id, ProjectConfig.PROJECT_CONFIG)); } gerritConfig = pluginConfigFactory.getFromGerritConfig(pluginName, true);
<|startcomment|> This depends on which kind of error and message should be reported to the user. IllegalStateException would be an internal server error, represented by a 500. The kind of chosen RestApiException would determine the HTTP error code and the specified message would be sent to the user. <|endcomment|>  // new All-Projects project.config not yet in cache -- read from repository ObjectId id = ObjectId.fromString(projectConfigObjectId); if (ObjectId.zeroId().equals(id)) { return checkConfig; } try (Repository repo = repoManager.openRepository(allProjectsName)) { checkConfig = new CheckConfig(pluginName, readFileContents(repo, id, ProjectConfig.PROJECT_CONFIG)); } gerritConfig = pluginConfigFactory.getFromGerritConfig(pluginName, true); if (gerritConfig == null) { <|startfocus|> // throw IllegalStateException? RestApiException? <|endfocus|> checkConfig.scannerConfig.messages.add( ScannerConfig.hintMessage( "missing [plugin \"" + pluginName + "\"] section in gerrit.config")); } else { checkConfig.scannerConfig.defaultEnable = gerritConfig.getBoolean(ScannerConfig.KEY_ENABLE, false); } return checkConfig; } private void logReviewResultErrors(RevisionCreatedListener.Event event, ReviewResult result) { if (!Strings.isNullOrEmpty(result.error)) { logger.atSevere().log(
<|startcomment|> RevWalks must be closed after use. Please use a try-with-resources statement. <|endcomment|>  AddReviewerResult arr = entry.getValue(); if (!Strings.isNullOrEmpty(arr.error)) { logger.atSevere().log( "revision %s: error adding reviewer %s: %s", event.getChange().currentRevision, entry.getKey(), arr.error); metrics.addReviewerErrors.increment(event.getChange().project); metrics.errors.increment(); } } } private String readFileContents(Repository repo, ObjectId objectId, String filename) throws IOException { <|startfocus|> RevWalk rw = new RevWalk(repo); RevTree tree = rw.parseTree(objectId); try (TreeWalk tw = TreeWalk.forPath(rw.getObjectReader(), filename, tree)) { <|endfocus|> ObjectLoader loader = repo.open(tw.getObjectId(0), Constants.OBJ_BLOB); return new String(loader.getCachedBytes(), UTF_8); } } } 
<|startcomment|> I don't know if this can happen for real but TreeWalk#forPath can return a null object if the file wasn't found, which would result in a NPE with the current code. <|endcomment|>  "revision %s: error adding reviewer %s: %s", event.getChange().currentRevision, entry.getKey(), arr.error); metrics.addReviewerErrors.increment(event.getChange().project); metrics.errors.increment(); } } } private String readFileContents(Repository repo, ObjectId objectId, String filename) throws IOException { <|startfocus|> RevWalk rw = new RevWalk(repo); RevTree tree = rw.parseTree(objectId); try (TreeWalk tw = TreeWalk.forPath(rw.getObjectReader(), filename, tree)) { <|endfocus|> ObjectLoader loader = repo.open(tw.getObjectId(0), Constants.OBJ_BLOB); return new String(loader.getCachedBytes(), UTF_8); } } } 
<|startcomment|> Zookeeper-specific stuff shouldn't be in the common Module as injected members. <|endcomment|> import com.googlesource.gerrit.plugins.multisite.validation.dfsrefdb.zookeeper.ZkValidationModule; import java.io.BufferedReader; import java.io.BufferedWriter; import java.io.IOException; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; import java.util.Collection; import java.util.UUID; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class Module extends LifecycleModule { private static final Logger log = LoggerFactory.getLogger(Module.class); private Configuration config; <|startfocus|> private ZookeeperConfig zkConfig; <|endfocus|> private NoteDbStatus noteDb; private final boolean disableGitRepositoryValidation; @Inject public Module(Configuration config, ZookeeperConfig zkConfig, NoteDbStatus noteDb) { this(config, zkConfig, noteDb, false); } // TODO: It is not possible to properly test the libModules in Gerrit. // Disable the Git repository validation during integration test and then build the necessary // support // in Gerrit for it. @VisibleForTesting public Module( Configuration config, ZookeeperConfig zkConfig, NoteDbStatus noteDb, boolean disableGitRepositoryValidation) {
<|startcomment|> Just pass the global configuration here, the ZkValidationModule will be responsible to get its specific one. <|endcomment|>  install(new IndexModule()); } if (config.kafkaSubscriber().enabled()) { install(new KafkaConsumerModule(config.kafkaSubscriber())); install(new ForwardedEventRouterModule()); } if (config.kafkaPublisher().enabled()) { install(new BrokerForwarderModule(config.kafkaPublisher())); } install( new MultiSiteValidationModule( config, disableGitRepositoryValidation || !config.getSharedRefDb().isEnabled())); <|startfocus|> if (config.getSharedRefDb().isEnabled()) { install(new ZkValidationModule(zkConfig)); } <|endfocus|> bind(Gson.class) .annotatedWith(BrokerGson.class) .toProvider(GsonProvider.class) .in(Singleton.class);
<|startcomment|> Is there any value in redefining the multi-site.config here? <|endcomment|> import org.apache.curator.retry.BoundedExponentialBackoffRetry; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class ZookeeperConfig { private static final Logger log = LoggerFactory.getLogger(ZookeeperConfig.class); <|startfocus|> // TODO Read from different config file when moving it into a plugin public static final String ZOOKEEPER_MS_CONFIG = "multi-site.config"; <|endfocus|> public static final int defaultSessionTimeoutMs; public static final int defaultConnectionTimeoutMs; public static final String DEFAULT_ZK_CONNECT = "localhost:2181"; private final int DEFAULT_RETRY_POLICY_BASE_SLEEP_TIME_MS = 1000; private final int DEFAULT_RETRY_POLICY_MAX_SLEEP_TIME_MS = 3000; private final int DEFAULT_RETRY_POLICY_MAX_RETRIES = 3; private final int DEFAULT_CAS_RETRY_POLICY_BASE_SLEEP_TIME_MS = 100; private final int DEFAULT_CAS_RETRY_POLICY_MAX_SLEEP_TIME_MS = 300; private final int DEFAULT_CAS_RETRY_POLICY_MAX_RETRIES = 3;
<|startcomment|> This module should be in charge to get its configuration based on the global MultiSite config. <|endcomment|> <|startfocus|> public ZkValidationModule(ZookeeperConfig cfg) { this.cfg = cfg; <|endfocus|>
<|startcomment|> do we really rename this test variable in this change? Changing tests and refactoring code at the same time is risky because you never know who broke what. <|endcomment|>  static { System.setProperty("gerrit.notedb", "ON"); } public static class KafkaTestContainerModule extends LifecycleModule { public static class KafkaStopAtShutdown implements LifecycleListener { private final KafkaContainer kafka; public KafkaStopAtShutdown(KafkaContainer kafka) { this.kafka = kafka; } @Override public void stop() { kafka.stop(); } @Override public void start() { // Do nothing } } <|startfocus|> private final FileBasedConfig multiSiteConfig; <|endfocus|> private final FileBasedConfig sharedRefConfig; private final Module multiSiteModule; @Inject public KafkaTestContainerModule(SitePaths sitePaths, NoteDbStatus noteDb) { this.multiSiteConfig = new FileBasedConfig( sitePaths.etc_dir.resolve(Configuration.MULTI_SITE_CONFIG).toFile(), FS.DETECTED); this.sharedRefConfig = new FileBasedConfig( sitePaths.etc_dir.resolve(ZookeeperConfig.ZOOKEEPER_MS_CONFIG).toFile(), FS.DETECTED); this.multiSiteModule = new Module( new Configuration(multiSiteConfig, new Config()), new ZookeeperConfig(sharedRefConfig),
<|startcomment|> No Need to inject this, just use gApi.changes().id(<the id you want>) <|endcomment|> import com.google.gerrit.server.change.ChangeResource; import com.google.gerrit.server.change.RevisionResource; import com.google.gerrit.server.update.CommentsRejectedException; import com.google.gerrit.server.update.UpdateException; import com.google.inject.Inject; import com.google.inject.Module; import com.google.inject.Provider; import java.sql.Timestamp; import org.junit.Before; import org.junit.Test; /** Tests for comment validation in {@link PostReview}. */ @NoHttpd public class PostReviewIT extends AbstractDaemonTest { <|startfocus|> @Inject private Provider<ChangesCollection> changes; @Inject private Provider<PostReview> postReview; @Inject private RequestScopeOperations requestScopeOperations; <|endfocus|> @Override public Module createModule() { return new FactoryModule() { @Override public void configure() { bind(CommentValidationListener.class) .annotatedWith(Exports.named("TestCommentValidationListener")) .to(TestCommentValidationListener.class) .asEagerSingleton(); } }; } @Before public void setUp() { requestScopeOperations.setApiUser(admin.id()); getValidationCalls().clear(); } @Test public void validateCommentsInInput_commentOK() throws Exception {
<|startcomment|> Just use: gApi.changes().id(someid).current().review(ent) <|endcomment|> import com.google.gerrit.server.change.RevisionResource; import com.google.gerrit.server.update.CommentsRejectedException; import com.google.gerrit.server.update.UpdateException; import com.google.inject.Inject; import com.google.inject.Module; import com.google.inject.Provider; import java.sql.Timestamp; import org.junit.Before; import org.junit.Test; /** Tests for comment validation in {@link PostReview}. */ @NoHttpd public class PostReviewIT extends AbstractDaemonTest { <|startfocus|> @Inject private Provider<ChangesCollection> changes; @Inject private Provider<PostReview> postReview; @Inject private RequestScopeOperations requestScopeOperations; <|endfocus|> @Override public Module createModule() { return new FactoryModule() { @Override public void configure() { bind(CommentValidationListener.class) .annotatedWith(Exports.named("TestCommentValidationListener")) .to(TestCommentValidationListener.class) .asEagerSingleton(); } }; } @Before public void setUp() { requestScopeOperations.setApiUser(admin.id()); getValidationCalls().clear(); } @Test public void validateCommentsInInput_commentOK() throws Exception { String file = "file";
<|startcomment|> this should not be necessary <|endcomment|>  public void configure() { <|startfocus|> bind(CommentValidationListener.class) .annotatedWith(Exports.named("TestCommentValidationListener")) .to(TestCommentValidationListener.class) .asEagerSingleton(); <|endfocus|>
<|startcomment|> Here and below: PushOneCommit.Result r = createChange(); r.getChange() then has all change details <|endcomment|>  } }; } @Before public void setUp() { requestScopeOperations.setApiUser(admin.id()); getValidationCalls().clear(); } @Test public void validateCommentsInInput_commentOK() throws Exception { String file = "file"; PushOneCommit push = pushFactory.create(admin.newIdent(), testRepo, "first subject", file, "contents"); PushOneCommit.Result r = push.to("refs/for/master"); String changeId = r.getChangeId(); String revId = r.getCommit().getName(); <|startfocus|> <|endfocus|> ReviewInput input = new ReviewInput(); String commentText = "this comment is OK"; CommentInput comment = newComment(file, commentText); comment.updated = new Timestamp(0); input.comments = ImmutableMap.of(comment.path, Lists.newArrayList(comment)); ChangeResource changeResource = changes.get().parse(TopLevelResource.INSTANCE, IdString.fromDecoded(changeId)); RevisionResource revisionResource = revisions.parse(changeResource, IdString.fromDecoded(revId)); assertThat(getPublishedComments(changeId)).isEmpty();
<|startcomment|> The plugin is called multi-site already: what would be the value of repeating it in the module name? <|endcomment|>  private UUID tryToLoadSavedInstanceId(String serverIdFile) { if (Files.exists(Paths.get(serverIdFile))) { try (BufferedReader br = new BufferedReader(new FileReader(serverIdFile))) { return UUID.fromString(br.readLine()); } catch (IOException e) { <|startfocus|> multisiteLog.warn( <|endfocus|> String.format( "Cannot read instance ID from path '%s', deleting the old file and generating a new ID: (%s)", serverIdFile, e.getMessage())); try { Files.delete(Paths.get(serverIdFile)); } catch (IOException e1) { multisiteLog.warn( String.format( "Cannot delete old instance ID file at path '%s' with instance ID while generating a new one: (%s)", serverIdFile, e1.getMessage())); } } } return null;
<|startcomment|> nit: empty line. <|endcomment|>  protected void configure() { <|startfocus|> <|endfocus|> bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class); bind(CuratorFramework.class).toInstance(cfg.getZookeeperConfig().buildCurator()); bind(ZkConnectionConfig.class) .toInstance( new ZkConnectionConfig( cfg.getZookeeperConfig().buildCasRetryPolicy(), cfg.getZookeeperConfig().getZkInterProcessLockTimeOut())); DynamicSet.bind(binder(), ProjectDeletedListener.class).to(ProjectDeletedSharedDbCleanup.class);
<|startcomment|> In Gerrit's world, this would rather be a BAD_REQUEST. 403 indicates a permission issue (from Wikipedia): "HTTP 403 is returned when the client is not permitted access to the resource despite providing authentication such as insufficient permissions of the authenticated account." However, this isn't a permission issue or an issue that can be fixed with more powerful permissions. We just don't want to have these comments published. Hence the request asking for that as invalid. Aside from that, can we do this conversion in PostReview instead? RestApiServlet tries to be generic and it looks like this case can only ever happen in code paths originating from PostReview. This has the benefit that you can test it using only the Java API and don't have to do write and REST tests. <|endcomment|>  Throwable t = e.getCause(); if (t instanceof LockFailureException) { logger.atSevere().withCause(t).log("Error in %s %s", req.getMethod(), uriForLogging(req)); responseBytes = replyError( req, res, status = SC_SERVICE_UNAVAILABLE, messageOr(t, "Lock failure"), e); <|startfocus|> } else if (t instanceof CommentsRejectedException) { responseBytes = replyError(req, res, status = SC_FORBIDDEN, messageOr(t, "Comments rejected"), e); <|endfocus|> } else { status = SC_INTERNAL_SERVER_ERROR; responseBytes = handleException(e, req, res); } } catch (QuotaException e) { responseBytes = replyError(req, res, status = 429, messageOr(e, "Quota limit reached"), e.caching(), e); } catch (Exception e) { status = SC_INTERNAL_SERVER_ERROR; responseBytes = handleException(e, req, res); } finally { String metric = viewData != null && viewData.view != null ? globals.metrics.view(viewData) : "_unknown";
<|startcomment|> nit: response could be immutable <|endcomment|> <|startfocus|> public static List<CommentValidationFailure> findInvalidComments( <|endfocus|> PluginSetContext<CommentValidator> commentValidators, ImmutableList<CommentForValidation> commentsForValidation) { List<CommentValidationFailure> commentValidationFailures = new ArrayList<>(); commentValidators.runEach( listener -> commentValidationFailures.addAll(listener.validateComments(commentsForValidation))); return commentValidationFailures;
<|startcomment|> nit: all callers are converting to a stream before calling validateComments. Should we accept a Collection<Comment> instead? <|endcomment|>  comments.addAll(toPublish); return !toPublish.isEmpty(); } private boolean insertRobotComments(ChangeContext ctx) throws OrmException, PatchListNotAvailableException { if (in.robotComments == null) { return false; } List<RobotComment> newRobotComments = getNewRobotComments(ctx); commentsUtil.putRobotComments(ctx.getUpdate(psId), newRobotComments); comments.addAll(newRobotComments); return !newRobotComments.isEmpty(); } private List<RobotComment> getNewRobotComments(ChangeContext ctx) <|startfocus|> throws OrmException, PatchListNotAvailableException { <|endfocus|> List<RobotComment> toAdd = new ArrayList<>(in.robotComments.size()); Set<CommentSetEntry> existingIds = in.omitDuplicateComments ? readExistingRobotComments(ctx) : Collections.emptySet(); for (Map.Entry<String, List<RobotCommentInput>> ent : in.robotComments.entrySet()) { String path = ent.getKey(); for (RobotCommentInput c : ent.getValue()) { RobotComment e = createRobotCommentFromInput(ctx, path, c); if (existingIds.contains(CommentSetEntry.create(e))) { continue;
<|startcomment|> Can you add javadoc that this method is thread safe? <|endcomment|>  name); this.refName = RefNames.REFS_SEQUENCES + name; this.seed = requireNonNull(seed, "seed"); this.floor = floor; checkArgument(batchSize > 0, "expected batchSize > 0, got: %s", batchSize); this.batchSize = batchSize; this.afterReadRef = requireNonNull(afterReadRef, "afterReadRef"); this.retryer = requireNonNull(retryer, "retryer"); counterLock = new ReentrantLock(true); } <|startfocus|> <|endfocus|> public int next() { return Iterables.getOnlyElement(next(1)); } public ImmutableList<Integer> next(int count) { if (count == 0) { return ImmutableList.of(); } checkArgument(count > 0, "count is negative: %s", count); try { return retryer.call( () -> { counterLock.lock(); try { if (count == 1) { if (counter >= limit) { acquire(batchSize); } return ImmutableList.of(counter++); } List<Integer> ids = new ArrayList<>(count); while (counter < limit) {
<|startcomment|> Wouldn't it be easier to just have a block strategy that blocks forever? Then you can dispatch a normal call after that with no lock failure and see if that makes it through. Maybe it's not easier coding-wise but I would argue that it is easier to understand than a block strategy that itself dispatches a call (which is something block strategies aren't supposed to do). <|endcomment|>  // from the sequence. Creating an ID requires the RepoSequence.counterLock, if it's not free // (because we forgot to release it before blocking) the call in the other thread would hang and // the test would time out. // We can set the runnable that consumes the ID from another thread only after RepoSequence was // created, because we need the RepoSequence instance to get the next ID. BlockStrategyThatTriggersRunnable blockStrategy = new BlockStrategyThatTriggersRunnable(); <|startfocus|> <|endfocus|> // Use batch size = 1 to make each call go to NoteDb. RepoSequence s = newSequence( "id", 1, 1, bgUpdate, RepoSequence.retryerBuilder().withBlockStrategy(blockStrategy).build()); blockStrategy.runOnBlock = () -> { try { Executors.newFixedThreadPool(1) .submit( () -> { // This call hangs if we don't release the RepoSequence.counterLock while we // are blocking until the next try. If this happens we block until the test // times // out.
<|startcomment|> Looks like this is unneeded, since the counter is not checked below? Maybe this test doesn't need to verify index events at all? <|endcomment|>  assertThat(getEmails()).containsExactly(previous); assertThat(gApi.accounts().self().get().email).isNull(); } @Test @Sandboxed public void deleteAllEmails() throws Exception { EmailInput input = new EmailInput(); input.email = "foo.bar@example.com"; input.noConfirmation = true; gApi.accounts().self().addEmail(input); accountIndexedCounter.assertReindexOf(admin); resetCurrentApiUser(); Set<String> allEmails = getEmails(); assertThat(allEmails).hasSize(2); <|startfocus|> accountIndexedCounter.clear(); <|endfocus|> for (String email : allEmails) { gApi.accounts().self().deleteEmail(email); } resetCurrentApiUser(); assertThat(getEmails()).isEmpty(); assertThat(gApi.accounts().self().get().email).isNull(); } @Test public void deleteEmailFromCustomExternalIdSchemes() throws Exception { String email = "foo.bar@example.com"; String extId1 = "foo:bar"; String extId2 = "foo:baz"; List<ExternalId> extIds = ImmutableList.of(
<|startcomment|> I am not sure this is the right approach. If sharedRefDb is disabled then I would expect no validation to be performed, not even the noOp one. I thought the noOp validation was going to be automatically bound as DynamicItem and then overridden *if* a Ref-DB plugin was installed. Is that not the case? perhaps I got the wrong side of the stick here, in which case apologies. <|endcomment|>  multisiteLog.warn( String.format( "Cannot read instance ID from path '%s', deleting the old file and generating a new ID: (%s)", serverIdFile, e.getMessage())); try { Files.delete(Paths.get(serverIdFile)); } catch (IOException e1) { <|startfocus|> multisiteLog.warn( <|endfocus|> String.format( "Cannot delete old instance ID file at path '%s' with instance ID while generating a new one: (%s)", serverIdFile, e1.getMessage())); } } } return null;
<|startcomment|> nit: missing summary fragment <|endcomment|>  * and executing the callable do not apply. * * <p>See {@link LoggingContextAwareRunnable} for an example. * * @see LoggingContextAwareRunnable */ class LoggingContextAwareCallable<T> implements Callable<T> { private final Callable<T> callable; private final Thread callingThread; private final ImmutableSetMultimap<String, String> tags; private final boolean forceLogging; private final boolean performanceLogging; private final MutablePerformanceLogRecords mutablePerformanceLogRecords; <|startfocus|> /** <|endfocus|> * @param callable Callable that should be wrapped. * @param mutablePerformanceLogRecords instance of {@link MutablePerformanceLogRecords} to which * performance log records that are created from the runnable are added */ LoggingContextAwareCallable( Callable<T> callable, MutablePerformanceLogRecords mutablePerformanceLogRecords) { this.callable = callable; this.callingThread = Thread.currentThread(); this.tags = LoggingContext.getInstance().getTagsAsMap(); this.forceLogging = LoggingContext.getInstance().isLoggingForced(); this.performanceLogging = LoggingContext.getInstance().isPerformanceLogging(); this.mutablePerformanceLogRecords = mutablePerformanceLogRecords; } @Override
<|startcomment|> BadRequestException here and below <|endcomment|>  .andReturn(ImmutableList.of(commentForValidation.failValidation("Oh no!"))); EasyMock.replay(mockCommentValidator); PushOneCommit.Result r = createChange(); ReviewInput input = new ReviewInput(); CommentInput comment = newComment(r.getChange().currentFilePaths().get(0)); comment.updated = new Timestamp(0); input.comments = ImmutableMap.of(comment.path, ImmutableList.of(comment)); <|startfocus|> assertThat(testCommentUtil.getPublishedComments(r.getChangeId())).isEmpty(); RestApiException restApiException = <|endfocus|> assertThrows( RestApiException.class, () -> gApi.changes().id(r.getChangeId()).current().review(input)); assertThat(restApiException.getCause()).isInstanceOf(CommentsRejectedException.class); assertThat( Iterables.getOnlyElement( ((CommentsRejectedException) restApiException.getCause()) .getCommentValidationFailures()) .getComment() .getText()) .isEqualTo(COMMENT_TEXT); assertThat(restApiException.getCause()).hasMessageThat().contains("Oh no!"); assertThat(testCommentUtil.getPublishedComments(r.getChangeId())).isEmpty(); } @Test
<|startcomment|> And 14 other cases, according to [1] from the commit message. Should this comment be changed, and most importantly, is it OK to handle them all (15 potential cases) through an OrmDuplicateKeyException? -As many of those 23000 cases seem to differ from the previous duplicate-key overall case. <|endcomment|>  public OrmException convertError(String op, SQLException err) { <|startfocus|> switch (getSQLStateInt(err)) { case 23000: // ER_DUP_KEY <|endfocus|> return new OrmDuplicateKeyException("ACCOUNT_PATCH_REVIEWS", err); default: if (err.getCause() == null && err.getNextException() != null) { err.initCause(err.getNextException()); } return new OrmException(op + " failure on ACCOUNT_PATCH_REVIEWS", err); }
<|startcomment|> nit: Remove new line <|endcomment|> // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import static com.google.common.base.Preconditions.checkArgument; import static com.google.common.base.Suppliers.memoize; import static com.google.common.base.Suppliers.ofInstance; import com.google.common.annotations.VisibleForTesting; import com.google.common.base.CaseFormat; import com.google.common.base.Strings; <|startfocus|> import com.google.common.base.Supplier; import com.google.common.collect.ImmutableList; <|endfocus|> import com.google.common.collect.ImmutableMap; import com.google.gerrit.server.config.SitePaths; import com.google.inject.Inject; import com.google.inject.Singleton; import com.google.inject.spi.Message; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.io.IOException; import java.util.Arrays; import java.util.Collection; import java.util.Collections; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.commons.lang.StringUtils; import org.apache.curator.RetryPolicy;
<|startcomment|> nit: Remove space <|endcomment|>  private final boolean enabled; private final Map<EventFamily, Boolean> eventsEnabled; private KafkaPublisher(Supplier<Config> cfg) { enabled = <|startfocus|> cfg.get() .getBoolean( KAFKA_SECTION, KAFKA_PUBLISHER_SUBSECTION, ENABLE_KEY, DEFAULT_BROKER_ENABLED); <|endfocus|> eventsEnabled = eventsEnabled(cfg, KAFKA_PUBLISHER_SUBSECTION); if (enabled) { setDefaults(); applyKafkaConfig(cfg, KAFKA_PUBLISHER_SUBSECTION, this); }
<|startcomment|> Not used anymore <|endcomment|> import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import com.google.common.base.CaseFormat; import com.google.common.base.Strings; import com.google.common.base.Supplier; import com.google.common.collect.ImmutableMap; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); <|startfocus|> public static final String KAFKA_CONFIG = "multi-site.config"; public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; <|endfocus|> static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; public KafkaConfiguration(Config kafkaConfig) { Supplier<Config> lazyCfg = lazyLoad(kafkaConfig);
<|startcomment|> else if -To save one check if this instanceof IndexTask is true. <|endcomment|>  ProvisionException pe = new ProvisionException("error opening ReviewDb"); pe.initCause(e); throw pe; } dbRef.set(db); } return db; } @Override public CurrentUser getUser() { throw new OutOfScopeException("No user during ChangeIndexer"); } }; RequestContext oldCtx = context.setContext(newCtx); try { <|startfocus|> if (this instanceof IndexTask) { queuedIndexTasks.remove(this); } if (this instanceof ReindexIfStaleTask) { queuedReindexIfStaleTasks.remove(this); } <|endfocus|> return callImpl(newCtx.getReviewDbProvider()); } finally { context.setContext(oldCtx); Provider<ReviewDb> db = dbRef.get(); if (db != null) { db.get().close(); } } } catch (Exception e) { log.error("Failed to execute " + this, e); throw e; }
<|startcomment|> Can the above removals be moved to their respective class implementation? This would allow 1. no need to check for this instanceof, and 2. the ability to do the removal at a more accurate location, timing-wise. Removal could also be enforced by means of an abstract method for implementing classes to absolutely override. <|endcomment|>  pe.initCause(e); throw pe; } dbRef.set(db); } return db; } @Override public CurrentUser getUser() { throw new OutOfScopeException("No user during ChangeIndexer"); } }; RequestContext oldCtx = context.setContext(newCtx); try { <|startfocus|> if (this instanceof IndexTask) { queuedIndexTasks.remove(this); } if (this instanceof ReindexIfStaleTask) { queuedReindexIfStaleTasks.remove(this); } <|endfocus|> return callImpl(newCtx.getReviewDbProvider()); } finally { context.setContext(oldCtx); Provider<ReviewDb> db = dbRef.get(); if (db != null) { db.get().close(); } } } catch (Exception e) { log.error("Failed to execute " + this, e); throw e; }
<|startcomment|> Same comments as in the other changed file. <|endcomment|>  } } @Override public void onFailure(Throwable ignored) { // Logged by {@link GetChanges#call()}. } }, directExecutor()); } private abstract class Task<V> implements Callable<V> { protected Event event; protected Task(Event event) { this.event = event; } @Override public final V call() throws Exception { try (ManualRequestContext ctx = requestContext.open()) { <|startfocus|> if (this instanceof Index) { queuedIndexTasks.remove(this); } <|endfocus|> return impl(ctx); } catch (Exception e) { log.error("Failed to reindex changes after " + event, e); throw e; } } protected abstract V impl(RequestContext ctx) throws Exception; } private class GetChanges extends Task<List<Change>> { private GetChanges(Event event) { super(event); } @Override protected List<Change> impl(RequestContext ctx) throws OrmException { String ref = event.getRefName(); Project.NameKey project = new Project.NameKey(event.getProjectName());
<|startcomment|> Why are you moving those imports around? <|endcomment|> import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import java.util.HashMap; import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); <|startfocus|> public static final String PLUGIN_NAME = "kafka"; public static final String KAFKA_CONFIG = PLUGIN_NAME + ".config"; <|endfocus|> public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject
<|startcomment|> @Singleton missing? <|endcomment|> import java.util.Map; import java.util.Properties; import java.util.UUID; import org.apache.kafka.common.serialization.StringSerializer; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); <|startfocus|> public static final String PLUGIN_NAME = "kafka"; public static final String KAFKA_CONFIG = PLUGIN_NAME + ".config"; <|endfocus|> public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject KafkaConfiguration(SitePaths sitePaths) { this(getConfigFile(sitePaths, KAFKA_CONFIG)); }
<|startcomment|> Is this useful? That isn't the kafka configuration but the multi-site.config: why don't you just use the existing constant? <|endcomment|> import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); <|startfocus|> public static final String PLUGIN_NAME = "kafka"; public static final String KAFKA_CONFIG = PLUGIN_NAME + ".config"; <|endfocus|> public static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; static final String ENABLE_KEY = "enabled"; static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; static final boolean DEFAULT_ENABLE_PROCESSING = true; private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject KafkaConfiguration(SitePaths sitePaths) { this(getConfigFile(sitePaths, KAFKA_CONFIG)); } @VisibleForTesting public KafkaConfiguration(Config kafkaConfig) { Supplier<Config> lazyCfg = ConfigurationHelper.lazyLoad(kafkaConfig);
<|startcomment|> Can we keep the 'properties' name for now, so that this change can be minimal? <|endcomment|> import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.InstanceId; import com.googlesource.gerrit.plugins.multisite.KafkaConfiguration; import com.googlesource.gerrit.plugins.multisite.broker.BrokerSession; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; public class KafkaSession implements BrokerSession { private static final Logger LOGGER = LoggerFactory.getLogger(KafkaSession.class); <|startfocus|> private KafkaConfiguration kafkaConfig; <|endfocus|> private final UUID instanceId; private volatile Producer<String, String> producer; @Inject public KafkaSession(KafkaConfiguration kafkaConfig, @InstanceId UUID instanceId) { this.kafkaConfig = kafkaConfig; this.instanceId = instanceId; } @Override public boolean isOpen() { if (producer != null) { return true; } return false; } @Override public void connect() { if (isOpen()) { LOGGER.debug("Already connected."); return; } 
<|startcomment|> Why are you moving those imports around? <|endcomment|> // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.kafka.consumer; <|startfocus|> import java.util.concurrent.Executor; import java.util.concurrent.Executors; import org.apache.kafka.common.serialization.ByteArrayDeserializer; import org.apache.kafka.common.serialization.Deserializer; <|endfocus|> import com.google.gerrit.extensions.registration.DynamicSet; import com.google.gerrit.lifecycle.LifecycleModule; import com.google.inject.TypeLiteral; import com.googlesource.gerrit.plugins.multisite.KafkaConfiguration.KafkaSubscriber; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; import com.googlesource.gerrit.plugins.multisite.forwarder.events.MultiSiteEvent; public class KafkaConsumerModule extends LifecycleModule { private final KafkaSubscriber kafkaSubscriber; public KafkaConsumerModule(KafkaSubscriber kafkaSubscriber) { this.kafkaSubscriber = kafkaSubscriber; } @Override protected void configure() { MultiSiteEvent.registerEventTypes();
<|startcomment|> Why are you moving those imports around? <|endcomment|> // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import static com.google.common.truth.Truth.assertThat; <|startfocus|> import static com.googlesource.gerrit.plugins.multisite.Configuration.DEFAULT_THREAD_POOL_SIZE; import static com.googlesource.gerrit.plugins.multisite.Configuration.THREAD_POOL_SIZE_KEY; <|endfocus|> import static com.googlesource.gerrit.plugins.multisite.Configuration.Cache.CACHE_SECTION; import static com.googlesource.gerrit.plugins.multisite.Configuration.Cache.PATTERN_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Event.EVENT_SECTION; import static com.googlesource.gerrit.plugins.multisite.Configuration.Forwarding.DEFAULT_SYNCHRONIZE; import static com.googlesource.gerrit.plugins.multisite.Configuration.Forwarding.SYNCHRONIZE_KEY; import static com.googlesource.gerrit.plugins.multisite.Configuration.Index.INDEX_SECTION; import org.eclipse.jgit.lib.Config; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.junit.MockitoJUnitRunner; 
<|startcomment|> Should this be in the Configuration class? <|endcomment|>  static final int DEFAULT_INDEX_MAX_TRIES = 2; static final int DEFAULT_INDEX_RETRY_INTERVAL = 30000; static final int DEFAULT_THREAD_POOL_SIZE = 4; static final String NUM_STRIPED_LOCKS = "numStripedLocks"; static final int DEFAULT_NUM_STRIPED_LOCKS = 10; static final String ENABLE_KEY = "enabled"; private final Supplier<Cache> cache; private final Supplier<Event> event; private final Supplier<Index> index; <|startfocus|> private final Supplier<Collection<Message>> replicationConfigValidation; <|endfocus|> @Inject Configuration(SitePaths sitePaths) { this(getConfigFile(sitePaths, MULTI_SITE_CONFIG), getConfigFile(sitePaths, REPLICATION_CONFIG)); } @VisibleForTesting public Configuration(Config multiSiteConfig, Config replicationConfig) { Supplier<Config> lazyMultiSiteCfg = lazyLoad(multiSiteConfig); replicationConfigValidation = lazyValidateReplicatioConfig(replicationConfig); cache = memoize(() -> new Cache(lazyMultiSiteCfg)); event = memoize(() -> new Event(lazyMultiSiteCfg)); index = memoize(() -> new Index(lazyMultiSiteCfg)); } public Cache cache() { return cache.get(); } 
<|startcomment|> All of those should be the responsibility of the KafkaConfiguration, WDYT? <|endcomment|>  private final int threadPoolSize; private final List<String> patterns; private Cache(Supplier<Config> cfg) { super(cfg, CACHE_SECTION); threadPoolSize = getInt(cfg, CACHE_SECTION, null, THREAD_POOL_SIZE_KEY, DEFAULT_THREAD_POOL_SIZE); <|startfocus|> patterns = getList(cfg, CACHE_SECTION, null, PATTERN_KEY); <|endfocus|>
<|startcomment|> This constant exists already in Configuration, why not reusing it? <|endcomment|> import com.google.common.base.Strings; import com.google.common.base.Supplier; import com.google.common.collect.ImmutableMap; import com.google.gerrit.server.config.SitePaths; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; public class KafkaConfiguration { private static final Logger log = LoggerFactory.getLogger(KafkaConfiguration.class); static final String KAFKA_PROPERTY_PREFIX = "KafkaProp-"; static final String KAFKA_SECTION = "kafka"; <|startfocus|> private static final String KAFKA_CONFIG = "multi-site.config"; private static final String ENABLE_KEY = "enabled"; private static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"; private static final boolean DEFAULT_ENABLE_PROCESSING = true; <|endfocus|> private static final int DEFAULT_POLLING_INTERVAL_MS = 1000; private final Supplier<KafkaSubscriber> subscriber; private final Supplier<Kafka> kafka; private final Supplier<KafkaPublisher> publisher; @Inject KafkaConfiguration(SitePaths sitePaths) { this(getConfigFile(sitePaths, KAFKA_CONFIG)); } @VisibleForTesting KafkaConfiguration(Config kafkaConfig) { Supplier<Config> lazyCfg = lazyLoad(kafkaConfig);
<|startcomment|> this can be removed? <|endcomment|>  projectOperations .allProjectsForUpdate() .add(allow(Permission.READ).ref("refs/*").group(admins)) .update(); // Remove all read permissions on All-Users. try (ProjectConfigUpdate u = updateProject(allUsers)) { for (AccessSection sec : u.getConfig().getAccessSections()) { sec.removePermission(Permission.READ); } u.save(); } } <|startfocus|> <|endfocus|> private void setUpChanges() throws Exception { gApi.projects().name(project.get()).branch("branch").create(new BranchInput()); // First 2 changes are merged, which means the tags pointing to them are // visible. projectOperations .project(project) .forUpdate() .add(allow(Permission.SUBMIT).ref("refs/for/refs/heads/*").group(admins)) .update(); PushOneCommit.Result mr = pushFactory.create(admin.newIdent(), testRepo).to("refs/for/master%submit"); mr.assertOkStatus(); cd1 = mr.getChange(); rc1 = mr.getCommit(); psRef1 = cd1.currentPatchSet().id().toRefName();
<|startcomment|> Normally, branching in Git graphs starts from a commit and not from a relation. IMHO, this would be more readable: // rcMaster (c1 master master-tag) <-- rcBranch (c2 branch branch-tag) <- // \ \ // (c3_open) (c4_open) Same for other ascii graphs below. <|endcomment|>  // Remove all read permissions on All-Users. try (ProjectConfigUpdate u = updateProject(allUsers)) { for (AccessSection sec : u.getConfig().getAccessSections()) { sec.removePermission(Permission.READ); } u.save(); } } private void setUpChanges() throws Exception { gApi.projects().name(project.get()).branch("branch").create(new BranchInput()); // First 2 changes are merged, which means the tags pointing to them are // visible. projectOperations .project(project) .forUpdate() .add(allow(Permission.SUBMIT).ref("refs/for/refs/heads/*").group(admins)) <|startfocus|> .update(); <|endfocus|> PushOneCommit.Result mr = pushFactory.create(admin.newIdent(), testRepo).to("refs/for/master%submit"); mr.assertOkStatus(); cd1 = mr.getChange(); rc1 = mr.getCommit(); psRef1 = cd1.currentPatchSet().id().toRefName(); metaRef1 = RefNames.changeMetaRef(cd1.getId()); PushOneCommit.Result br =
<|startcomment|> its <|endcomment|>  * .haves}. This is a heuristical approach that aims at scaling down the number of unnecessary * objects that client sends to the server. Unnecessary here refers to objects that the server * already has. * * <p>For some code paths in {@link com.google.gerrit.server.git.DefaultAdvertiseRefsHook}, we * already removed refs/changes, so the logic to skip these in this class become a no-op. * <|startfocus|> * <p>TODO(hiesel): Instrument this heuristic and proof it's value. <|endfocus|> */ public class ReceiveCommitsAdvertiseRefsHook implements AdvertiseRefsHook { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); private final Provider<InternalChangeQuery> queryProvider; private final Project.NameKey projectName; public ReceiveCommitsAdvertiseRefsHook( Provider<InternalChangeQuery> queryProvider, Project.NameKey projectName) { this.queryProvider = queryProvider; this.projectName = projectName; } @Override public void advertiseRefs(UploadPack us) { throw new UnsupportedOperationException( "ReceiveCommitsAdvertiseRefsHook cannot be used for UploadPack"); } @Override
<|startcomment|> Maybe annotate with @VisibleForTesting <|endcomment|>  Project.NameKey projectName) { return create(allRefsWatcher, perm, queryProvider, projectName, false); } /** * Returns a single {@link AdvertiseRefsHook} that encompasses a chain of {@link * AdvertiseRefsHook} to be used for advertising when processing a Git push. Omits {@link * HackPushNegotiateHook} as that does not advertise refs on it's own but adds {@code .have} based * on history which is not relevant for the tests we have. <|startfocus|> */ <|endfocus|> public static AdvertiseRefsHook createForTest( PermissionBackend.ForProject perm, Provider<InternalChangeQuery> queryProvider, Project.NameKey projectName) { return create(new AllRefsWatcher(), perm, queryProvider, projectName, true); } private static AdvertiseRefsHook create( AllRefsWatcher allRefsWatcher, PermissionBackend.ForProject perm, Provider<InternalChangeQuery> queryProvider, Project.NameKey projectName, boolean skipHackPushNegotiateHook) { List<AdvertiseRefsHook> advHooks = new ArrayList<>(); advHooks.add(allRefsWatcher); advHooks.add(
<|startcomment|> to a section of the (Reintroduce the previous javadoc before this change?) <|endcomment|>  } /** Returns the URL for viewing a comment in a file in a given patch set of a change. */ default Optional<String> getInlineCommentView( Change change, int patchsetId, String filename, short side, int startLine) { return getPatchFileView(change, patchsetId, filename) .map(url -> url + String.format("@%s%d", side == 0 ? "a" : "", startLine)); } <|startfocus|> /** Returns a URL pointing to the settings page. */ <|endfocus|> default Optional<String> getSettingsUrl(@Nullable String section) { return getWebUrl() .map(url -> url + "settings" + (Strings.isNullOrEmpty(section) ? "" : "#" + section)); } /** Returns a URL pointing to a documentation page, at a given named anchor. */ default Optional<String> getDocUrl(String page, String anchor) { return getWebUrl().map(url -> url + "Documentation/" + page + "#" + anchor); } 
<|startcomment|> Why are you removing logs in the change for introducing new metrics? <|endcomment|>  public void connect() { if (isOpen()) { multisiteLog.debug("Already connected."); return; } multisiteLog.info("Connect to {}...", properties.getKafka().getBootstrapServers()); /* Need to make sure that the thread of the running connection uses * the correct class loader otherwize you can endup with hard to debug * ClassNotFoundExceptions */ setConnectionClassLoader(); <|startfocus|> producer = new KafkaProducer<>(properties.kafkaPublisher()); multisiteLog.info("Connection established."); <|endfocus|>
<|startcomment|> Is this change related to the metrics? <|endcomment|>  public void connect() { if (isOpen()) { LOGGER.debug("Already connected."); return; } /* Need to make sure that the thread of the running connection uses * the correct class loader otherwize you can endup with hard to debug * ClassNotFoundExceptions */ setConnectionClassLoader(); <|startfocus|> producer = producerProvider.get(); <|endfocus|> LOGGER.info("Connection established.");
<|startcomment|> Honestly, if I didn't know the background context, both the name of the enum value and the comment wouldn't help me. I think we should discuss a different name, especially one which isn't directly tied to specific field names (e.g. what should we do if we added another field in the future which needed a diff computation but which would also not be computed if this option was specified?). <|endcomment|>  COMMIT_FOOTERS(17), /** Include push certificate information along with any patch sets. */ PUSH_CERTIFICATES(18), /** Include change's reviewer updates. */ REVIEWER_UPDATES(19), /** Set the submittable boolean. */ SUBMITTABLE(20), /** If tracking Ids are included, include detailed tracking Ids info. */ TRACKING_IDS(21), /** Skip mergeability data */ SKIP_MERGEABLE(22), <|startfocus|> /**Skip unnecessary insertions and deletions calculations*/ SKIP_INSERT_DELETE(23); <|endfocus|> private final int value; ListChangesOption(int v) { this.value = v; } @Override public int getValue() { return value; } } 
<|startcomment|> The documentation for the REST API needs to be updated for this behavior. <|endcomment|>  out.hashtags = cd.hashtags(); out.changeId = in.getKey().get(); if (in.isNew()) { SubmitTypeRecord str = cd.submitTypeRecord(); if (str.isOk()) { out.submitType = str.type; } if (!excludeMergeableInChangeInfo && !has(SKIP_MERGEABLE)) { out.mergeable = cd.isMergeable(); } if (has(SUBMITTABLE)) { out.submittable = submittable(cd); } } <|startfocus|> if(!has(SKIP_INSERT_DELETE)) { <|endfocus|> Optional<ChangedLines> changedLines = cd.changedLines(); if (changedLines.isPresent()) { out.insertions = changedLines.get().insertions; out.deletions = changedLines.get().deletions; } } out.isPrivate = in.isPrivate() ? true : null; out.workInProgress = in.isWorkInProgress() ? true : null; out.hasReviewStarted = in.hasReviewStarted(); out.subject = in.getSubject(); out.status = in.getStatus().asChangeStatus(); out.owner = accountLoader.get(in.getOwner());
<|startcomment|> can you put this in PermissionRange instead? I don't think it makes sense that it automatically swaps min and max. <|endcomment|>  if (pr.getAction() == PermissionRule.Action.ALLOW && projectControl.match(pr, isChangeOwner)) { // For votes, contrary to normal permissions, we aggregate all applicable rules. voteMin = Math.min(voteMin, pr.getMin()); voteMax = Math.max(voteMax, pr.getMax()); } } <|startfocus|> voteMin = Math.max(voteMin, blockAllowMin); voteMax = Math.min(voteMax, blockAllowMax); if (voteMin > voteMax) { voteMin = 0; voteMax = 0; } return new PermissionRange(permissionName, voteMin, voteMax); <|endfocus|>
<|startcomment|> Requires a pluginName in stable-2.16 beside this. <|endcomment|>  public TestRefValidator(ReceiveCommand.Type rejectType) { this.rejectType = rejectType; this.rejectRef = TEST_REF; <|startfocus|> this.handle = validators.add(this); <|endfocus|>
<|startcomment|> Here and above/below: I didn't see those details and warnings in the new code. Don't we need them anymore? <|endcomment|>  if (valueType == String.class) { return s -> (String) s; } else if (valueType == Integer.class || valueType == Boolean.class) { return Object::toString; } else if (Enum.class.isAssignableFrom(valueType)) { return in -> ((Enum<?>) in).name(); } throw new IllegalStateException("unsupported type " + valueType.getName()); } @AutoValue.Builder public abstract static class Builder<T> { abstract Builder<T> name(String name); abstract Builder<T> valueType(Class<T> type); <|startfocus|> <|endfocus|> public abstract Builder<T> description(String description); abstract Field<T> autoBuild(); public Field<T> build() { Field<T> field = autoBuild(); checkArgument(field.name().matches("^[a-z_]+$"), "name must match [a-z_]"); return field; } } } 
<|startcomment|> Can we use @Memoized instead? (See https://github.com/google/auto/blob/master/value/userguide/howto.md#memoize) <|endcomment|>  } private Function<T, String> formatter; /** @return name of this field within the metric. */ public abstract String name(); /** @return type of value used within the field. */ public abstract Class<T> valueType(); /** @return description text for the field explaining its range of values. */ public abstract Optional<String> description(); <|startfocus|> public Function<T, String> formatter() { if (formatter == null) { formatter = initFormatter(valueType()); } return formatter; } <|endfocus|> private static <T> Function<T, String> initFormatter(Class<T> valueType) { if (valueType == String.class) { return s -> (String) s; } else if (valueType == Integer.class || valueType == Boolean.class) { return Object::toString; } else if (Enum.class.isAssignableFrom(valueType)) { return in -> ((Enum<?>) in).name(); } throw new IllegalStateException("unsupported type " + valueType.getName()); } @AutoValue.Builder
<|startcomment|> Unrelated to this change, but should this check be moved up to before this method is called? Actually, it looks like this whole method could be inlined since it's only called from L997? <|endcomment|>  reject(cmd, "not valid ref"); return; } if (RefNames.isNoteDbMetaRef(cmd.getRefName())) { // Reject pushes to NoteDb refs without a special option and permission. Note that this // prohibition doesn't depend on NoteDb being enabled in any way, since all sites will // migrate to NoteDb eventually, and we don't want garbage data waiting there when the // migration finishes. <|startfocus|> logger.atFine().log( <|endfocus|> "%s NoteDb ref %s with %s=%s", cmd.getType(), cmd.getRefName(), NoteDbPushOption.OPTION_NAME, noteDbPushOption); if (!Optional.of(NoteDbPushOption.ALLOW).equals(noteDbPushOption)) { // Only reject this command, not the whole push. This supports the use case of "git clone // --mirror" followed by "git push --mirror", when the user doesn't really intend to clone // or mirror the NoteDb data; there is no single refspec that describes all refs *except* // NoteDb refs. reject( cmd,
<|startcomment|> Here and in doRecord() as well as in the other TimerX implementations: To avoid confusion, I would rename this parameter, too. <|endcomment|> <|startfocus|> public Context start(F1 field1) { return new Context(this, field1); <|endfocus|>
<|startcomment|> Optional: Could be a method reference (Enum::name). <|endcomment|>  .valueType(Boolean.class) .formatter(Object::toString) .name(name); } /** * Break down metrics by cases of an enum. * * @param enumType type of enum * @param name field name * @return builder for the enum field */ public static <E extends Enum<E>> Field.Builder<E> ofEnum(Class<E> enumType, String name) { <|startfocus|> return new AutoValue_Field.Builder<E>() .valueType(enumType) .formatter(fieldValue -> fieldValue.name()) .name(name); <|endfocus|> } /** * Break down metrics by integer. * * <p>Each unique integer will allocate a new submetric. <b>Do not use user content as a field * value</b> as field values are never reclaimed. * * @param name field name * @return builder for the integer field */ public static Field.Builder<Integer> ofInteger(String name) { return new AutoValue_Field.Builder<Integer>() .valueType(Integer.class) .formatter(Object::toString)
<|startcomment|> Here and similar other usages: This could be a method reference, which is much shorter/simpler code. <|endcomment|>  public RequestMetrics(MetricMaker metricMaker) { Field<Integer> statusCodeField = <|startfocus|> Field.ofInteger( "status", (metadataBuilder, fieldValue) -> metadataBuilder.httpStatus(fieldValue)) <|endfocus|> .description("HTTP status code") .build(); errors = metricMaker.newCounter( "http/server/error_count", new Description("Rate of REST API error responses").setRate().setUnit("errors"), statusCodeField); successes = metricMaker.newCounter( "http/server/success_count", new Description("Rate of REST API success responses").setRate().setUnit("successes"), statusCodeField);
<|startcomment|> Was it a deliberate choice to go for a new functional interface instead of a BiConsumer to have a nicer method (map()) for interactions? <|endcomment|>  package com.google.gerrit.metrics; import static com.google.common.base.Preconditions.checkArgument; import com.google.auto.value.AutoValue; import java.util.Optional; import java.util.function.Function; /** * Describes a bucketing field used by a metric. * * @param <T> type of field */ @AutoValue public abstract class Field<T> { /** * Break down metrics by boolean true/false. * * @param name field name * @return builder for the boolean field */ <|startfocus|> public static Field.Builder<Boolean> ofBoolean(String name) { <|endfocus|> return new AutoValue_Field.Builder<Boolean>() .valueType(Boolean.class) .formatter(Object::toString) .name(name); } /** * Break down metrics by cases of an enum. * * @param enumType type of enum * @param name field name * @return builder for the enum field */ public static <E extends Enum<E>> Field.Builder<E> ofEnum(Class<E> enumType, String name) {
<|startcomment|> Considering that all of the other methods have Javadoc descriptions, could you add one here too? <|endcomment|>  public abstract Class<T> valueType(); /** @return description text for the field explaining its range of values. */ public abstract Optional<String> description(); /** @return formatter to format field values. */ public abstract Function<T, String> formatter(); @AutoValue.Builder public abstract static class Builder<T> { abstract Builder<T> name(String name); abstract Builder<T> valueType(Class<T> type); abstract Builder<T> formatter(Function<T, String> formatter); <|startfocus|> <|endfocus|> public abstract Builder<T> description(String description); abstract Field<T> autoBuild(); public Field<T> build() { Field<T> field = autoBuild(); checkArgument(field.name().matches("^[a-z_]+$"), "name must match [a-z_]"); return field; } } } 
<|startcomment|> Optional: If we want to switch to a method reference, it might be better to just rely on the toString() method, which for enums delegates to the name. <|endcomment|>  @Singleton public class UploadPackMetricsHook implements PostUploadHook { enum Operation { CLONE, FETCH; } private final Counter1<Operation> requestCount; private final Timer1<Operation> counting; private final Timer1<Operation> compressing; private final Timer1<Operation> writing; private final Histogram1<Operation> packBytes; @Inject UploadPackMetricsHook(MetricMaker metricMaker) { Field<Operation> operationField = <|startfocus|> Field.ofEnum( Operation.class, "operation", (metadataBuilder, fieldValue) -> metadataBuilder.gitOperation(fieldValue.name())) .build(); <|endfocus|> requestCount = metricMaker.newCounter( "git/upload-pack/request_count", new Description("Total number of git-upload-pack requests") .setRate() .setUnit("requests"), operationField); counting = metricMaker.newTimer( "git/upload-pack/phase_counting", new Description("Time spent in the 'Counting...' phase") .setCumulative() .setUnit(Units.MILLISECONDS), operationField); compressing = metricMaker.newTimer( "git/upload-pack/phase_compressing", new Description("Time spent in the 'Compressing...' phase")
<|startcomment|> Why do we need the type if the above field changeId() is an Integer and hence the numeric ID? <|endcomment|>  // The name of a branch. public abstract Optional<String> branchName(); // Key of an entity in a cache. public abstract Optional<String> cacheKey(); // The name of a cache. public abstract Optional<String> cacheName(); // The name of the implementation class. public abstract Optional<String> className(); // The numeric ID of a change. public abstract Optional<Integer> changeId(); <|startfocus|> // The type of change ID (e.g. numeric ID, triplet etc.). <|endfocus|> public abstract Optional<String> changeIdType(); // The type of an event. public abstract Optional<String> eventType(); // The name under which a plugin extension was registered. public abstract Optional<String> exportName(); // Garbage collector name. public abstract Optional<String> garbageCollectorName(); // Git operation (CLONE, FETCH). public abstract Optional<String> gitOperation(); // The numeric ID of an internal group. public abstract Optional<Integer> groupId(); // The name of a group. public abstract Optional<String> groupName();
<|startcomment|> Reading this and also having seen the pluginName() field, I don't understand what this is for. Is this a distinction between plugin and extension names? If so, could we find another name for this field? <|endcomment|>  public abstract Optional<String> cacheName(); // The name of the implementation class. public abstract Optional<String> className(); // The numeric ID of a change. public abstract Optional<Integer> changeId(); // The type of change ID (e.g. numeric ID, triplet etc.). public abstract Optional<String> changeIdType(); // The type of an event. public abstract Optional<String> eventType(); <|startfocus|> // The name under which a plugin extension was registered. public abstract Optional<String> exportName(); <|endfocus|> // Garbage collector name. public abstract Optional<String> garbageCollectorName(); // Git operation (CLONE, FETCH). public abstract Optional<String> gitOperation(); // The numeric ID of an internal group. public abstract Optional<Integer> groupId(); // The name of a group. public abstract Optional<String> groupName(); // The UUID of a group. public abstract Optional<String> groupUuid(); // HTTP status response code. public abstract Optional<Integer> httpStatus(); // The name of a secondary index.
<|startcomment|> Would it maybe make sense to rather call this authDomainName (or authenticationDomainName) so that it is re-usable for other authentication types? <|endcomment|>  public abstract Optional<Integer> groupId(); // The name of a group. public abstract Optional<String> groupName(); // The UUID of a group. public abstract Optional<String> groupUuid(); // HTTP status response code. public abstract Optional<Integer> httpStatus(); // The name of a secondary index. public abstract Optional<String> indexName(); // The version of a secondary index. public abstract Optional<Integer> indexVersion(); <|startfocus|> // An LDAP domain name. public abstract Optional<String> ldapDomainName(); <|endfocus|> // The name of the implementation method. public abstract Optional<String> methodName(); // Boolean: one or more public abstract Optional<Boolean> multiple(); // Name of a metadata file in NoteDb. public abstract Optional<String> noteDbFileName(); // Name of a metadata ref in NoteDb. public abstract Optional<String> noteDbRefName(); // Type of a sequence in NoteDb (ACCOUNTS, CHANGES, GROUPS). public abstract Optional<String> noteDbSequenceType(); 
<|startcomment|> Here and below: Do we have calling code where we don't know whether the passed String is null or not? <|endcomment|>  public abstract Optional<String> restViewName(); // The SHA1 of Git commit. public abstract Optional<String> revision(); // The username of an account. public abstract Optional<String> username(); public static Metadata.Builder builder() { return new AutoValue_Metadata.Builder(); } public static Metadata empty() { return builder().build(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder accountId(int accountId); public abstract Builder actionType(@Nullable String actionType); <|startfocus|> <|endfocus|> public abstract Builder branchName(@Nullable String branchName); public abstract Builder cacheKey(@Nullable String cacheKey); public abstract Builder cacheName(@Nullable String cacheName); public abstract Builder className(@Nullable String className); public abstract Builder changeId(int changeId); public abstract Builder changeIdType(@Nullable String changeIdType); public abstract Builder eventType(@Nullable String eventType); public abstract Builder exportName(@Nullable String exportName); public abstract Builder garbageCollectorName(@Nullable String garbageCollectorName); public abstract Builder gitOperation(@Nullable String gitOperation); 
<|startcomment|> This is not accurate anymore. <|endcomment|> // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.logging; import static java.util.Objects.requireNonNull; import com.google.auto.value.AutoValue; import com.google.gerrit.common.Nullable; /** * The record of an operation for which the execution time was measured. * <|startfocus|> * <p>Meta data is stored in separate key/value fields to avoid expensive instantiations of Map * objects. <|endfocus|> */ @AutoValue public abstract class PerformanceLogRecord { /** * Creates a performance log record without meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs) { return new AutoValue_PerformanceLogRecord(operation, durationMs, null); } /** * Creates a performance log record with meta data. *
<|startcomment|> Could we use Optional instead? <|endcomment|>  } /** * Creates a performance log record with meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @param metadata metadata * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs, Metadata metadata) { return new AutoValue_PerformanceLogRecord(operation, durationMs, requireNonNull(metadata)); } public abstract String operation(); public abstract long durationMs(); <|startfocus|> @Nullable public abstract Metadata metadata(); <|endfocus|> void writeTo(PerformanceLogger performanceLogger) { if (metadata() != null) { performanceLogger.log(operation(), durationMs(), metadata()); } else { performanceLogger.log(operation(), durationMs()); } } } 
<|startcomment|> Test are failing because of this change, updateSharedDbOrThrowExceptionFor method is called after updating local ref so getLatestLocalRef in this place is going to return new object id exactly one which we are trying to insert to zk. <|endcomment|>  if (refEnforcementPolicy == EnforcePolicy.IGNORED) return; String errorMessage = String.format( "Not able to persist the data in Zookeeper for project '%s' and ref '%s'," + "the cluster is now in Split Brain since the commit has been " + "persisted locally but not in SharedRef the value %s", projectName, refPair.getName(), refPair.putValue); boolean succeeded; try { <|startfocus|> succeeded = sharedRefDb.compareAndPut(projectName, getLatestLocalRef(refPair), refPair.putValue); <|endfocus|> } catch (IOException e) { throw new SharedDbSplitBrainException(errorMessage, e); } if (!succeeded) { throw new SharedDbSplitBrainException(errorMessage); } } protected void checkIfLocalRefIsUpToDateWithSharedRefDb( RefPair refPair, CloseableSet<AutoCloseable> locks) throws SharedLockException, OutOfSyncException, IOException { String refName = refPair.getName(); EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return; } 
<|startcomment|> This isn't working either, because we get the latest SHA1 of the ref, which is already the updated value. <|endcomment|>  } } private void updateSharedRefDb(Stream<ReceiveCommand> commandStream, List<RefPair> refsToUpdate) throws IOException { if (commandStream .filter(cmd -> cmd.getResult() != ReceiveCommand.Result.OK) .findFirst() .isPresent()) { return; } List<RefPair> updatedRefPairs = refsToUpdate .stream() .filter(distinctByKey(BatchRefUpdateValidator::getName)) .map( p -> { try { <|startfocus|> Ref current = getLatestLocalRef(p); return new RefPair(p.compareRef, current.getObjectId()); <|endfocus|> } catch (IOException e) { throw new RuntimeException(e); } }) .collect(Collectors.toList()); for (RefPair refPair : updatedRefPairs) { updateSharedDbOrThrowExceptionFor(refPair); } } public static String getName(RefPair p) { return p.compareRef.getName(); } public static <T> Predicate<T> distinctByKey(Function<? super T, ?> keyExtractor) { Set<Object> seen = ConcurrentHashMap.newKeySet();
<|startcomment|> skip <|endcomment|>  return get(Arrays.asList(options)); } /** * {@link #get(ListChangesOption...)} with all options included, except for the following. * * <ul> * <li>{@code CHECK} is omitted, to skip consistency checks. * <li>{@code SKIP_MERGEABLE} is omitted, so the {@code mergeable} bit <em>is</em> set. <|startfocus|> * <li>{@code SKIP_DIFFSTAT} is omitted to ensure diffstat calculations. <|endfocus|> * </ul> */ default ChangeInfo get() throws RestApiException { return get( EnumSet.complementOf( EnumSet.of( ListChangesOption.CHECK, ListChangesOption.SKIP_MERGEABLE, ListChangesOption.SKIP_DIFFSTAT))); } /** {@link #get(ListChangesOption...)} with no options included. */ default ChangeInfo info() throws RestApiException { return get(EnumSet.noneOf(ListChangesOption.class)); } /** * Retrieve change edit when exists. * * @deprecated Replaced by {@link ChangeApi#edit()} in combination with {@link
<|startcomment|> This name is no longer appropriate, how about renaming it to getRefPairsToUpdate? <|endcomment|>  case DELETE: return new RefPair(getCurrentRef(command.getRefName()), ObjectId.zeroId()); default: return new RefPair( command.getRef(), new IllegalArgumentException("Unsupported command type " + command.getType())); } } catch (IOException e) { return new RefPair(command.getRef(), e); } } private ObjectId getNewRef(ReceiveCommand command) { return command.getNewId(); } <|startfocus|> private List<RefPair> checkIfLocalRefIsUpToDateWithSharedRefDb( <|endfocus|> List<RefPair> refsToUpdate, CloseableSet<AutoCloseable> locks) throws IOException { List<RefPair> latestRefsToUpdate = new ArrayList<>(); for (RefPair refPair : refsToUpdate) { latestRefsToUpdate.add(checkIfLocalRefIsUpToDateWithSharedRefDb(refPair, locks)); } return latestRefsToUpdate; } } 
<|startcomment|> This name is no longer appropriate, how about renaming it to getRefPairToUpdate? <|endcomment|>  + "persisted locally but not in SharedRef the value %s", projectName, refPair.getName(), refPair.putValue); boolean succeeded; try { succeeded = sharedRefDb.compareAndPut(projectName, refPair.compareRef, refPair.putValue); } catch (IOException e) { throw new SharedDbSplitBrainException(errorMessage, e); } if (!succeeded) { throw new SharedDbSplitBrainException(errorMessage); } } <|startfocus|> protected RefPair checkIfLocalRefIsUpToDateWithSharedRefDb( <|endfocus|> RefPair refPair, CloseableSet<AutoCloseable> locks) throws SharedLockException, OutOfSyncException, IOException { String refName = refPair.getName(); EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return refPair; } locks.addResourceIfNotExist( String.format("%s-%s", projectName, refName), () -> sharedRefDb.lockRef(projectName, refName)); RefPair latestRefPair = getLatestLocalRef(refPair); boolean isInSync =
<|startcomment|> Should it be reflected in the change-message that the change was WIP prior to being "push-merged"? <|endcomment|>  info = getPatchSetInfo(ctx); ChangeUpdate update = ctx.getUpdate(psId); Change.Status status = change.getStatus(); if (status == Change.Status.MERGED) { return true; } change.setCurrentPatchSet(info); change.setStatus(Change.Status.MERGED); // we cannot reconstruct the submit records for when this change was // submitted, this is why we must fix the status update.fixStatus(Change.Status.MERGED); update.setCurrentPatchSet(); if (change.isWorkInProgress()) { <|startfocus|> change.setWorkInProgress(false); <|endfocus|> update.setWorkInProgress(false); } StringBuilder msgBuf = new StringBuilder(); msgBuf.append("Change has been successfully pushed"); if (!refName.equals(change.getDest().get())) { msgBuf.append(" into "); if (refName.startsWith(Constants.R_HEADS)) { msgBuf.append("branch "); msgBuf.append(Repository.shortenRefName(refName)); } else { msgBuf.append(refName); } } msgBuf.append("."); ChangeMessage msg = ChangeMessagesUtil.newMessage(
<|startcomment|> render() is deprecated. Should we split into multiple methods like renderText / renderHtml / etc? Probably out of scope for this change, though. More importantly: the old code streamed its output and the new code builds a single string. Should this use render(AdvisingAppendable) instead? <|endcomment|>  fields = config.getBoolean("logFormat", pretty, "verbose", false) ? VERBOSE_FIELDS : FIELDS; variant = firstNonNull(config.getString("logFormat", pretty, "variant"), pretty); } public void renderStreaming( Paginator paginator, @Nullable String revision, Renderer renderer, Writer out, DateFormatter df, FooterBehavior footerBehavior) throws IOException { out.write( renderer .newRenderer("gitiles.logEntriesHeader") .setData(toHeaderSoyData(paginator, revision)) <|startfocus|> .render() .get()); <|endfocus|> SoySauce.Renderer entryRenderer = renderer.newRenderer("gitiles.logEntryWrapper"); boolean renderedEntries = false; for (RevCommit c : paginator) { out.write(entryRenderer.setData(toEntrySoyData(paginator, c, df)).render().get()); out.flush(); renderedEntries = true; } if (!renderedEntries) { renderer.newRenderer("gitiles.emptyLog").render().get(); } out.write( renderer .newRenderer("gitiles.logEntriesFooter") .setData(toFooterSoyData(paginator, revision, footerBehavior)) .render()
<|startcomment|> Maybe use RefNames.isGerritRef(String) or RefNames.isNoteDbMetaRef(String) instead? <|endcomment|>  private boolean isInternalRef(String refName) { <|startfocus|> return refName.startsWith(RefNames.REFS_STARRED_CHANGES) || refName.startsWith(RefNames.REFS_SEQUENCES); <|endfocus|>
<|startcomment|> Note: on later branches we can use RefNames.isGerritRef instead. It includes some more internal refs. <|endcomment|>  private boolean isInternalRef(String refName) { <|startfocus|> return refName.startsWith(RefNames.REFS_STARRED_CHANGES) || refName.startsWith(RefNames.REFS_SEQUENCES); <|endfocus|>
<|startcomment|> This condition should actually cover the tombstone case already, do we really need an extra method and to make this check so complicated? Why not saying instead: a) sharedRefDb.isUpToDate => then return true b) if(latestRefPair.compareRef.getObjectId().equals(ObjectId.zeroId())) => then return !sharedRefDb.exists(projectName, refName) c) otherwise return false <|endcomment|>  EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return refPair; } locks.addResourceIfNotExist( String.format("%s-%s", projectName, refName), () -> sharedRefDb.lockRef(projectName, refName)); Ref localRef = getLatestLocalRef(refPair); boolean isInSync = <|startfocus|> (localRef != null) ? sharedRefDb.isUpToDate(projectName, localRef) : !sharedRefDb.exists(projectName, refName); <|endfocus|> if (!isInSync) { validationMetrics.incrementSplitBrainPrevention(); softFailBasedOnEnforcement( new OutOfSyncException(projectName, localRef), refEnforcementPolicy); } return new RefPair(localRef == null ? nullRef(refName) : localRef, refPair.putValue); } private Ref getLatestLocalRef(RefPair refPair) throws IOException { return refDb.exactRef(refPair.getName()); } protected boolean isSuccessful(RefUpdate.Result result) { switch (result) { case NEW: case FORCED: case FAST_FORWARD: case NO_CHANGE:
<|startcomment|> I think it is always useful to surface the API error, so why not always logging at warning? i.e: logger.atWarning().withCause(err).log("REST call failed: %d", statusCode); Floggerâs API accepts âno-opâ parameters, hence you don't need to care about checking if "err" is null. <|endcomment|>  HttpServletResponse res, int statusCode, String msg, CacheControl c, @Nullable Throwable err) throws IOException { if (err != null) { RequestUtil.setErrorTraceAttribute(req, err); } configureCaching(req, res, null, null, c); checkArgument(statusCode >= 400, "non-error status: %s", statusCode); res.setStatus(statusCode); <|startfocus|> (err == null ? logger.atFinest() : logger.atWarning().withCause(err)) .log("REST call failed: %d", statusCode); <|endfocus|> return replyText(req, res, true, msg); } /** * Sets a text reply on the given HTTP servlet response. * * @param req the HTTP servlet request * @param res the HTTP servlet response on which the reply should be set * @param allowTracing whether it is allowed to log the reply if tracing is enabled, must not be * set to {@code true} if the reply may contain sensitive data * @param text the text reply
<|startcomment|> Why set the limit to 2 but then expect only 1 result? Can't we set the limit to 1, and then check if changeData.isEmpty()? <|endcomment|>  } return Optional.empty(); } private Optional<Project.NameKey> getProjectNameForChangeId(String changeId) { Optional<Project.NameKey> projectName = extractProjectNameFromChangeId(changeId); if (projectName.isPresent()) { return projectName; } try { List<ChangeData> changeData = globals .queryProvider .get() .setRequestedFields(ChangeField.PROJECT) .setLimit(2) .query(globals.changeQueryBuilder.change(changeId)); <|startfocus|> if (changeData.size() != 1) { <|endfocus|> return Optional.empty(); } return Optional.of(changeData.get(0).project()); } catch (QueryParseException e) { return Optional.empty(); } } @VisibleForTesting static Optional<Project.NameKey> extractProjectNameFromChangeId(String changeId) { int projectEndPosition = changeId.indexOf('~'); if (projectEndPosition <= 0) { return Optional.empty(); } return Optional.of( Project.nameKey(IdString.fromUrl(changeId.substring(0, projectEndPosition)).get())); } private boolean isDelete(HttpServletRequest req) {
<|startcomment|> refer to the enum instead? Then if more types are added later, this doesn't need to be updated too. <|endcomment|> package com.google.gerrit.server; import com.google.auto.value.AutoValue; import com.google.gerrit.reviewdb.client.Project; import com.google.gerrit.server.logging.TraceContext; import java.util.Optional; /** Information about a request that was received from a user. */ @AutoValue public abstract class RequestInfo { public enum RequestType { GIT_RECEIVE, GIT_UPLOAD, REST, SSH } /** <|startfocus|> * Type of the request, telling through which channel the request was coming in (REST, Git * receive, git upload, SSH). <|endfocus|> */ public abstract RequestType requestType(); /** The user that has sent the request. */ public abstract CurrentUser callingUser(); /** The trace context of the request. */ public abstract TraceContext traceContext(); /** * The name of the project for which the request is being done. Only available if the request is * tied to a project or change. If a project is available it's not guaranteed that it actually
<|startcomment|> Don't explicitly import this; instead only import Project (the previous line) and then consistently explicitly refer to Project.NameKey in the code below. <|endcomment|> import com.google.common.hash.Hashing; import com.google.gerrit.common.data.GroupReference; import com.google.gerrit.extensions.annotations.PluginCanonicalWebUrl; import com.google.gerrit.extensions.annotations.PluginName; import com.google.gerrit.extensions.api.groups.Groups; import com.google.gerrit.extensions.common.GroupInfo; import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.extensions.restapi.ResourceConflictException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.reviewdb.client.AccountGroup; import com.google.gerrit.reviewdb.client.Project; <|startfocus|> import com.google.gerrit.reviewdb.client.Project.NameKey; <|endfocus|> import com.google.gerrit.server.CurrentUser; import com.google.gerrit.server.account.GroupMembership; import com.google.gerrit.server.config.AllProjectsNameProvider; import com.google.gerrit.server.config.PluginConfigFactory; import com.google.gerrit.server.permissions.GlobalPermission; import com.google.gerrit.server.permissions.PermissionBackend; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.gerrit.server.permissions.ProjectPermission; import com.google.gerrit.server.project.CreateProjectArgs; import com.google.gerrit.server.project.NoSuchProjectException; import com.google.gerrit.server.validators.ProjectCreationValidationListener; import com.google.gerrit.server.validators.ValidationException;
<|startcomment|> Project.NameKey <|endcomment|> <|startfocus|> private boolean isOwner(NameKey project) { <|endfocus|> try { permissionBackend.user(self.get()).project(project).check(ProjectPermission.WRITE_CONFIG); } catch (AuthException | PermissionBackendException noWriter) { try { permissionBackend.user(self.get()).check(GlobalPermission.ADMINISTRATE_SERVER); } catch (AuthException | PermissionBackendException noAdmin) { return false; } } return true;
<|startcomment|> If the SKIP_DIFFSTAT option is omitted, the diffstat calculations are not skipped. ;-) <|endcomment|>  return get(Arrays.asList(options)); } /** * {@link #get(ListChangesOption...)} with all options included, except for the following. * * <ul> * <li>{@code CHECK} is omitted, to skip consistency checks. * <li>{@code SKIP_MERGEABLE} is omitted, so the {@code mergeable} bit <em>is</em> set. <|startfocus|> * <li>{@code SKIP_DIFFSTAT} is omitted to skip diffstat calculations. <|endfocus|> * </ul> */ default ChangeInfo get() throws RestApiException { return get( EnumSet.complementOf( EnumSet.of( ListChangesOption.CHECK, ListChangesOption.SKIP_MERGEABLE, ListChangesOption.SKIP_DIFFSTAT))); } /** {@link #get(ListChangesOption...)} with no options included. */ default ChangeInfo info() throws RestApiException { return get(EnumSet.noneOf(ListChangesOption.class)); } /** * Retrieve change edit when exists. * * @deprecated Replaced by {@link ChangeApi#edit()} in combination with {@link
<|startcomment|> You could provide more details here: "(total number of inserted/deleted lines of the latest patch set)" <|endcomment|>  /** Include a copy of commit messages including review footers. */ COMMIT_FOOTERS(17), /** Include push certificate information along with any patch sets. */ PUSH_CERTIFICATES(18), /** Include change's reviewer updates. */ REVIEWER_UPDATES(19), /** Set the submittable boolean. */ SUBMITTABLE(20), /** If tracking Ids are included, include detailed tracking Ids info. */ TRACKING_IDS(21), /** Skip mergeability data */ SKIP_MERGEABLE(22), <|startfocus|> /** Skip diffstat computation */ <|endfocus|> SKIP_DIFFSTAT(23); private final int value; ListChangesOption(int v) { this.value = v; } @Override public int getValue() { return value; } } 
<|startcomment|> also mention emails here? <|endcomment|> // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.api.changes; import java.util.List; /** Detailed information about who should be notified about an update. */ public class NotifyInfo { public List<String> accounts; /** <|startfocus|> * @param accounts may be either just a list of: account IDs, Full names, or usernames. Also could * be list of those: "Full name <email@example.com>" or "Full name (<ID>)" <|endfocus|> */ public NotifyInfo(List<String> accounts) { this.accounts = accounts; } } 
<|startcomment|> nit: a list <|endcomment|> // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.extensions.api.changes; import java.util.List; /** Detailed information about who should be notified about an update. */ public class NotifyInfo { public List<String> accounts; /** <|startfocus|> * @param accounts may be either just a list of: account IDs, Full names, or usernames. Also could * be list of those: "Full name <email@example.com>" or "Full name (<ID>)" <|endfocus|> */ public NotifyInfo(List<String> accounts) { this.accounts = accounts; } } 
<|startcomment|> Refactored. <|endcomment|>  addDraft(changeId, revId, comment); assertThat(gApi.changes().query("change:" + changeId + " has:draft").get()).hasSize(1); } } @Test public void publishCommentsAllRevisions() throws Exception { PushOneCommit.Result result = createChange(); String changeId = result.getChangeId(); pushFactory <|startfocus|> .create(db, admin.getIdent(), testRepo, SUBJECT, FILE_NAME, "initial content\n", changeId) <|endfocus|> .to("refs/heads/master"); PushOneCommit.Result r1 = pushFactory .create(admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "old boring content\n") .to("refs/for/master"); PushOneCommit.Result r2 = pushFactory .create( admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "new interesting\ncntent\n", r1.getChangeId()) .to("refs/for/master"); addDraft( r1.getChangeId(), r1.getCommit().getName(),
<|startcomment|> Remove(d). <|endcomment|>  addDraft(changeId, revId, comment); assertThat(gApi.changes().query("change:" + changeId + " has:draft").get()).hasSize(1); } } @Test public void publishCommentsAllRevisions() throws Exception { PushOneCommit.Result result = createChange(); String changeId = result.getChangeId(); pushFactory <|startfocus|> .create(db, admin.getIdent(), testRepo, SUBJECT, FILE_NAME, "initial content\n", changeId) <|endfocus|> .to("refs/heads/master"); PushOneCommit.Result r1 = pushFactory .create(admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "old boring content\n") .to("refs/for/master"); PushOneCommit.Result r2 = pushFactory .create( admin.newIdent(), testRepo, SUBJECT, FILE_NAME, "new interesting\ncntent\n", r1.getChangeId()) .to("refs/for/master"); addDraft( r1.getChangeId(), r1.getCommit().getName(),
<|startcomment|> nit: space. Did you run the GJF 1.7 on the files? <|endcomment|>  protected void configure() { if (!noteDb.enabled()) { throw new ProvisionException( "Gerrit is still running on ReviewDb: please migrate to NoteDb " + "and then reload the multi-site plugin."); } Collection<Message> validationErrors = config.validate(); if (!validationErrors.isEmpty()) { throw new CreationException(validationErrors); } listener().to(Log4jMessageLogger.class); bind(MessageLogger.class).to(Log4jMessageLogger.class); <|startfocus|> <|endfocus|> DynamicItem.itemOf(binder(), BrokerSession.class); DynamicItem.bind(binder(), BrokerSession.class).to(BrokerSessionNoOp.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } install(kafkaForwardedEventRouterModule); install(kafkaBrokerForwarderModule); install( new ValidationModule( config, disableGitRepositoryValidation || !config.getSharedRefDb().isEnabled())); 
<|startcomment|> What about the other exception? <|endcomment|>  "Kafka consumer subscribing to topic [%s] for event family [%s]", topic, getEventFamily()); consumer.subscribe(Collections.singleton(topic)); while (!closed.get()) { ConsumerRecords<byte[], byte[]> consumerRecords = consumer.poll(Duration.ofMillis(configuration.kafkaSubscriber().getPollingInterval())); consumerRecords.forEach(this::processRecord); } } catch (WakeupException e) { // Ignore exception if closing if (!closed.get()) throw e; <|startfocus|> } catch (KafkaException e) { <|endfocus|> subscriberMetrics.incrementSubscriberFailedToPollMessages(); throw e; } finally { consumer.close(); }
<|startcomment|> This looks wrong to me, because the message was received but Gerrit, for some reasons, failed to process because of permissions or persistent issues. <|endcomment|>  subscriberMetrics.incrementSubscriberConsumedMessage(); } catch (IOException e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", event.getHeader().getEventType()); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } catch (PermissionBackendException | OrmException e) { logger.atSevere().withCause(e).log( "Cannot handle message %s: [Exception: %s]", event.getHeader().getEventType()); <|startfocus|> subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); <|endfocus|> } } } catch (Exception e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", new String(consumerRecord.value(), UTF_8)); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); }
<|startcomment|> Would be best IMHO to avoid the two return points. What about: remoteUpdatesList = pushFilter == null ? remoteUpdateList : pushFilter.filter(projectName.get(), remoteUpdatesList); return remoteUpdatesList; <|endcomment|>  for (String src : delta) { Ref r = local.get(src); if (r != null) { n.put(src, r); } } local = n; } local = forProject.filter(local, git, RefFilterOptions.builder().setFilterMeta(true).build()); } List<RemoteRefUpdate> remoteUpdatesList = pushAllRefs ? doPushAll(tn, local) : doPushDelta(local); ReplicationPushFilter pushFilter = replicationPushFilter.get(); <|startfocus|> if (pushFilter == null) { return remoteUpdatesList; } <|endfocus|> return pushFilter.filter(projectName.get(), remoteUpdatesList); } private List<RemoteRefUpdate> doPushAll(Transport tn, Map<String, Ref> local) throws NotSupportedException, TransportException, IOException { List<RemoteRefUpdate> cmds = new ArrayList<>(); boolean noPerms = !pool.isReplicatePermissions(); Map<String, Ref> remote = listRemote(tn); for (Ref src : local.values()) { if (!canPushRef(src.getName(), noPerms)) { continue; } 
<|startcomment|> Not needed. <|endcomment|>  protected void configure() { <|startfocus|> DynamicItem.itemOf(binder(), BeforeReplicationPushFilter.class); DynamicItem.bind(binder(), BeforeReplicationPushFilter.class) .to(BeforeReplicationPushFilterNoOP.class); <|endfocus|>
<|startcomment|> Make the assertion more precise? I.e. assert that it contains exactly one entry with the "foo" remote that was set at L181? <|endcomment|>  return java.nio.file.Files.createTempDirectory(prefix); } @Test public void shouldLoadNotEmptyInitialReplicationConfig() throws Exception { FileBasedConfig replicationConfig = newReplicationConfig(); replicationConfig.setString("remote", "foo", "url", "ssh://git@git.somewhere.com/${name}"); replicationConfig.save(); autoReloadConfig = new AutoReloadConfigDecorator( sitePaths, destinationFactoryMock, Providers.of(replicationQueueMock), pluginDataPath, "replication", workQueueMock); <|startfocus|> assertThat(autoReloadConfig.getDestinations(FilterType.ALL)).isNotEmpty(); <|endfocus|> } @Test public void shouldAutoReloadReplicationConfig() throws Exception { FileBasedConfig replicationConfig = newReplicationConfig(); replicationConfig.setBoolean("gerrit", null, "autoReload", true); replicationConfig.setString("remote", "foo", "url", "ssh://git@git.foo.com/${name}"); replicationConfig.save(); autoReloadConfig = new AutoReloadConfigDecorator( sitePaths, destinationFactoryMock, Providers.of(replicationQueueMock), pluginDataPath, "replication", workQueueMock); autoReloadConfig.startup(workQueueMock); 
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2010 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.index; import java.util.Optional; public class OnlineReindexMode { private static ThreadLocal<Boolean> isOnlineReindex = new ThreadLocal<>(); public static boolean get() { return Optional.ofNullable(isOnlineReindex.get()).orElse(Boolean.FALSE); } public static void begin() { isOnlineReindex.set(Boolean.TRUE); } public static void end() { isOnlineReindex.set(Boolean.FALSE); } } 
<|startcomment|> Can we call this isActive or something similar? I believe it would read better in conditional statements: if ((!opts.allowClosed() || OnlineReindexMode.isActive()) .... VS if ((!opts.allowClosed() || OnlineReindexMode.get()) .... <|endcomment|> <|startfocus|> public static boolean get() { <|endfocus|> return Optional.ofNullable(isOnlineReindex.get()).orElse(Boolean.FALSE);
<|startcomment|> objectId <|endcomment|> import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class JgitWrapper { private static final Logger log = LoggerFactory.getLogger(JgitWrapper.class); public static Optional<byte[]> getBlobAsBytes(Repository repository, String revision, String path) throws IOException { ObjectId objectId = repository.resolve(revision); if (objectId == null) { return Optional.empty(); } try (final TreeWalk w = TreeWalk.forPath( <|startfocus|> repository, path, parseCommit(repository, repository.resolve(revision)).getTree())) { <|endfocus|> return Optional.ofNullable(w) .filter(walk -> (walk.getRawMode(0) & TYPE_MASK) == TYPE_FILE) .map(walk -> walk.getObjectId(0)) .flatMap(id -> readBlob(repository, id)); } } private static RevCommit parseCommit(Repository repository, ObjectId commit) throws IOException { try (final RevWalk walk = new RevWalk(repository)) { walk.setRetainBody(true); return walk.parseCommit(commit); } } private static Optional<byte[]> readBlob(Repository repository, ObjectId id) {
<|startcomment|> nit: Missing JavaDoc <|endcomment|> // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.quota; <|startfocus|> public class QuotaGroupDefinitions { <|endfocus|> public static final String REPOSITORY_SIZE_GROUP = "/repository:size"; private QuotaGroupDefinitions() {} } 
<|startcomment|> int lines = 0; int nl = -1; while (true) { nl = nextLineBreak(content, nl + 1, content.length()); if (nl < 0) { return false; } else if (++lines == MAX_LINE_COUNT) { return true; } } <|endcomment|>  private static boolean isContentTooLargeForDisplay(String content) { int lines = 0; int start = 0; while (lines <= MAX_LINE_COUNT) { int nl = nextLineBreak(content, start, content.length()); if (nl < 0) { break; } lines++; start = nl + 1; } <|startfocus|> if (lines <= MAX_LINE_COUNT) { return false; } return true; <|endfocus|>
<|startcomment|> Since this is looping anyway, maybe using nextLineBreak()? <|endcomment|>  private static boolean isContentTooLargeForDisplay(String content) { <|startfocus|> Matcher m = Pattern.compile("\r\n|\r|\n").matcher(content); <|endfocus|> int lines = 0; while (m.find() && lines < MAX_LINE_COUNT) { lines++; } if (lines < MAX_LINE_COUNT) { return false; } return true;
<|startcomment|> Please set the default to false so that we can proctor the rollout. <|endcomment|>  at, Duration.ofMillis( cfg.getTimeUnit( "retry", at.name(), "timeout", SECONDS.toMillis(defaultTimeout.getSeconds()), MILLISECONDS)))); this.waitStrategy = WaitStrategies.join( WaitStrategies.exponentialWait( cfg.getTimeUnit("retry", null, "maxWait", SECONDS.toMillis(5), MILLISECONDS), MILLISECONDS), WaitStrategies.randomWait(50, MILLISECONDS)); this.overwriteDefaultRetryerStrategySetup = overwriteDefaultRetryerStrategySetup; <|startfocus|> this.retryWithTraceOnFailure = cfg.getBoolean("retry", "retryWithTraceOnFailure", true); <|endfocus|>
<|startcomment|> providing <|endcomment|> // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.server.logging; import com.google.auto.value.AutoValue; import java.util.Optional; /** * The record of an operation for which the execution time was measured. * <|startfocus|> * <p>Metadata to provide additional context can be included by provided a {@link Metadata} <|endfocus|> * instance. */ @AutoValue public abstract class PerformanceLogRecord { /** * Creates a performance log record without meta data. * * @param operation the name of operation the is was performed * @param durationMs the execution time in milliseconds * @return the performance log record */ public static PerformanceLogRecord create(String operation, long durationMs) { return new AutoValue_PerformanceLogRecord(operation, durationMs, Optional.empty()); } /** * Creates a performance log record with meta data. *
<|startcomment|> For enums, we always to the mapping from fieldValue to fieldValue.name(). I'm wondering if we shouldn't change the method signature of Field#ofEnum to allow to specify BiConsumer<Metadata.Builder, String> instead and do the mapping to the BiConsumer<Metadata.Builder, E> within the implementation via: BiConsumer<Metadata.Builder, E> mapper = (metadataBuilder, fieldValue) -> metadataMapper.accept(metadataBuilder, fieldValue.name()); What do you think? <|endcomment|>  public abstract static class Builder { public abstract Builder listener(RetryListener listener); public abstract Builder timeout(Duration timeout); public abstract Options build(); } } @VisibleForTesting @Singleton public static class Metrics { final Counter1<ActionType> attemptCounts; final Counter1<ActionType> timeoutCount; @Inject Metrics(MetricMaker metricMaker) { Field<ActionType> actionTypeField = <|startfocus|> Field.ofEnum( ActionType.class, "action_type", (metadataBuilder, fieldValue) -> metadataBuilder.actionType(fieldValue.name())) .build(); <|endfocus|> attemptCounts = metricMaker.newCounter( "action/retry_attempt_count", new Description( "Number of retry attempts made by RetryHelper to execute an action" + " (0 == single attempt, no retry)") .setCumulative() .setUnit("attempts"), actionTypeField); timeoutCount = metricMaker.newCounter( "action/retry_timeout_count", new Description( "Number of action executions of RetryHelper that ultimately timed out") .setCumulative()
<|startcomment|> Why is indexing changes relevant here? <|endcomment|>  public void setup() { projectCreationListener = new TraceValidatingProjectCreationValidationListener(); projectCreationListenerRegistrationHandle = projectCreationValidationListeners.add("gerrit", projectCreationListener); commitValidationListener = new TraceValidatingCommitValidationListener(); commitValidationRegistrationHandle = commitValidationListeners.add("gerrit", commitValidationListener); <|startfocus|> changeIndexedListener = new TraceChangeIndexedListener(); changeIndexedListenerRegistrationHandle = changeIndexedListeners.add("gerrit", changeIndexedListener); <|endfocus|> testPerformanceLogger = new TestPerformanceLogger(); performanceLoggerRegistrationHandle = performanceLoggers.add("gerrit", testPerformanceLogger);
<|startcomment|> option <|endcomment|> // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.google.gerrit.util.cli; import java.util.Optional; /** * Classes that define command-line options by using the {@link org.kohsuke.args4j.Option} * annotation can implement this class to accept and handle unknown options. * <|startfocus|> * <p>If a user specifies an unknown option and this unknown options doesn't get accepted, the <|endfocus|> * parsing of the command-line options fails and the user gets an error (this is the default * behavior if classes do not implement this interface). */ public interface UnknownOptionHandler { /** * Whether an unknown option should be accepted. * * <p>If an unknown option is not accepted, the parsing of the command-line options fails and the * user gets an error. * * <p>This method can be used to ignore unknown options (without failure for the user) or to
<|startcomment|> Nit: I'm wondering whether we should use an Optional here. For return values, the official recommendation would be to use an Optional but for method parameters, the general opinion is less clear. Personally, I use Optional method parameters when I already have an Optional object and need to pass it to a private method. For externally facing methods, I typically prefer @Nullable as callers shouldn't need to explicitly construct an Optional instance. Most of the time, it's also better to rather use overloading (e.g. one method which accepts the parameter, another one without). In addition, you would in theory also need to check whether the passed Optional is null and hence you don't gain anything. Anyway, these are just some inputs for thought. If you want to keep the Optional as method parameter, it's also fine with me. <|endcomment|>  * user gets an error. * * <p>This method can be used to ignore unknown options (without failure for the user) or to * handle them. * * @param name the name of an unknown option that was provided by the user * @param value the value of the unknown option that was provided by the user * @return whether this unknown options is accepted */ <|startfocus|> boolean accept(String name, Optional<String> value); <|endfocus|> } 
<|startcomment|> staleness <|endcomment|>  .buildRepeatable( a -> { if (a.getAccount().getMetaId() == null) { return ImmutableList.of(); } return ImmutableList.of( RefState.create( RefNames.refsUsers(a.getAccount().getId()), ObjectId.fromString(a.getAccount().getMetaId())) // We use the default AllUsers name to avoid having to pass around that // variable just for indexing. <|startfocus|> // This field is only used for stalness detection which will discover the <|endfocus|> // default name and replace it with the actually configured name. .toByteArray(new AllUsersName(AllUsersNameProvider.DEFAULT))); }); /** * All note values of all external IDs that were used in the course of indexing this document. * * <p>Emitted as UTF-8 encoded strings of the form {@code [hex sha of external ID]:[hex sha of * note blob]}, or with other words {@code [note ID]:[note data ID]}. */
<|startcomment|> nit: looks like this should fit in one line <|endcomment|>  Ref ref = repo.exactRef(RefNames.refsUsers(id)); // Stale if the account actually exists. return ref != null; } } for (Map.Entry<Project.NameKey, RefState> e : RefState.parseStates(result.get().getValue(AccountField.REF_STATE)).entries()) { // Custom All-Users repository names are not indexed. Instead, the default name is used. <|startfocus|> // Therefore, // defer to the currently configured All-Users name. <|endfocus|> Project.NameKey repoName = e.getKey().get().equals(AllUsersNameProvider.DEFAULT) ? allUsersName : e.getKey(); try (Repository repo = repoManager.openRepository(repoName)) { if (!e.getValue().match(repo)) { // Ref was modified since the account was indexed. return true; } } } Set<ExternalId> extIds = externalIds.byAccount(id); ListMultimap<ObjectId, ObjectId> extIdStates = parseExternalIdStates(result.get().getValue(AccountField.EXTERNAL_ID_STATE)); if (extIdStates.size() != extIds.size()) {
<|startcomment|> Replication events were already persisted from the GitReferenceUpdateListener implementation, which is the ReplicationQueue.onGitReferenceUpdated. Why do we need to persist events also from here? <|endcomment|>  stateLog.error(String.format("source project %s not available", project), err, state); return; } } } synchronized (stateLock) { PushOne e = pending.get(uri); if (e == null) { e = opFactory.create(project, uri); addRef(e, ref); e.addState(ref, state); pool.schedule(e, now ? 0 : config.getDelay(), TimeUnit.SECONDS); pending.put(uri, e); <|startfocus|> eventsStorage.persist(project.get(), ref, e.getURI()); <|endfocus|> } else if (!e.getRefs().contains(ref)) { addRef(e, ref); e.addState(ref, state); } state.increasePushTaskCount(project.get(), ref); repLog.info("scheduled {}:{} => {} to run after {}s", project, ref, e, config.getDelay()); }
<|startcomment|> I don't like that these refactorings are combined with this change. What should have been just one line delta: + r.uri = uri.toASCIIString(); Is now 12 changed lines. If this is necessary then please do it before or after this change. <|endcomment|> <|startfocus|> public String persist(String project, String ref, URIish uri) { String json = getEventJson(project, ref, uri); <|endfocus|> String eventKey = getEventKey(json); Path file = refUpdates().resolve(eventKey); if (Files.exists(file)) { return eventKey; } try { logger.atFiner().log("**CREATE** %s:%s => %s", project, ref, uri); Files.write(file, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().log("Couldn't persist event %s", json); } return eventKey;
<|startcomment|> In the base version we expected the event key here and I believe this was a good design: * the caller doesn't have to know how event key is built (which components) * the persist method returns the eventKey and the caller was supposed to keep it and use for calling the delete method In this change, the return value of the persist is ignored. <|endcomment|> <|startfocus|> public void delete(String project, String ref, URIish uri) { String eventKey = getEventKey(getEventJson(project, ref, uri)); <|endfocus|> try { logger.atFiner().log("**DELETE** %s:%s => %s", project, ref, uri); Files.delete(refUpdates().resolve(eventKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", eventKey); }
<|startcomment|> Don't we want to log the exception stack with the withCause(e)? <|endcomment|>  if (watchedTypes.contains(type)) { matching.bcc.accounts.add(accountId); } logger.atFine().log("Added account %s as watcher", accountId); return true; } logger.atFine().log("The filter did not match for account %s; skip notification", accountId); } catch (QueryParseException e) { // Ignore broken filter expressions. <|startfocus|> logger.atWarning().log( "Account %s has invalid filter in project watch %s: %s", accountId, key, e.getMessage()); <|endfocus|> } return false;
<|startcomment|> @VisibleForTesting <|endcomment|>  private ImmutableList<RefUpdatedEvent> getRefUpdatedEvents( String project, String refName, int expectedSize) { String key = refEventKey(RefUpdatedEvent.TYPE, project, refName); if (expectedSize == 0) { assertThat(recordedEvents).doesNotContainKey(key); return ImmutableList.of(); } assertThat(recordedEvents).containsKey(key); ImmutableList<RefUpdatedEvent> events = FluentIterable.from(recordedEvents.get(key)) .transform(RefUpdatedEvent.class::cast) .toList(); assertThat(events).hasSize(expectedSize); return events; } <|startfocus|> <|endfocus|> public ImmutableList<ChangeMergedEvent> getChangeMergedEvents( String project, String branch, int expectedSize) { String key = refEventKey(ChangeMergedEvent.TYPE, project, branch); if (expectedSize == 0) { assertThat(recordedEvents).doesNotContainKey(key); return ImmutableList.of(); } assertThat(recordedEvents).containsKey(key); ImmutableList<ChangeMergedEvent> events = FluentIterable.from(recordedEvents.get(key)) .transform(ChangeMergedEvent.class::cast) .toList(); assertThat(events).hasSize(expectedSize); return events; } 
<|startcomment|> Unused (Eclipse warning; WIP). <|endcomment|>  assertThat(cd.change().getStatus()).isEqualTo(Change.Status.MERGED); assertSubmitApproval(psId); assertThat(cd.patchSets()).hasSize(1); assertThat(cd.patchSet(psId).getRevision().get()).isEqualTo(c.name()); } @Test public void correctNewRevOnMergeByPushToBranch() throws Exception { grant(project, "refs/heads/master", Permission.PUSH); <|startfocus|> PushOneCommit.Result r1 = push("refs/for/master", PushOneCommit.SUBJECT, "one.txt", "One"); PushOneCommit.Result r2 = push("refs/for/master", PushOneCommit.SUBJECT, "two.txt", "Two"); <|endfocus|> startEventRecorder(); git().push().setRefSpecs(new RefSpec(r2.getCommit().name() + ":refs/heads/master")).call(); List<ChangeMergedEvent> changeMergedEvents = eventRecorder.getChangeMergedEvents(project.get(), "refs/heads/master", 2); assertThat(changeMergedEvents.get(0).newRev).isEqualTo(r2.getPatchSet().getRevision().get());
<|startcomment|> printStackTrace? A leftover of some debugging session? <|endcomment|>  uri); } } else { if (canceledWhileRunning.get()) { logCanceledWhileRunningException(e); } else { repLog.error("Cannot replicate to {}", uri, e); // The remote push operation should be retried. pool.reschedule(this, Destination.RetryReason.TRANSPORT_ERROR); } } } catch (IOException e) { stateLog.error("Cannot replicate to " + uri, e, getStatesAsArray()); } catch (PermissionBackendException | RuntimeException | Error e) { <|startfocus|> e.printStackTrace(); <|endfocus|> stateLog.error("Unexpected error during replication to " + uri, e, getStatesAsArray()); } finally { pool.notifyFinished(this); if (git != null) { git.close(); } }
<|startcomment|> Newline and then leave an empty one between the header and the body. <|endcomment|> // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import com.google.gerrit.extensions.annotations.ExtensionPoint; import java.util.List; import org.eclipse.jgit.transport.RemoteRefUpdate; /** <|startfocus|> * Filter that is invoked before list of remote ref updates is pushed to remote instance. It can be * used to filter out unwanted updates. <|endfocus|> */ @ExtensionPoint public interface ReplicationPushFilter { public List<RemoteRefUpdate> filter(String projectName, List<RemoteRefUpdate> remoteUpdatesList); } 
<|startcomment|> This is unnecessary as all the access to this variable is synchronized. <|endcomment|>  private final DestinationFactory destinationFactory; private final Path pluginDataDir; private final Provider<ReplicationQueue> replicationQueue; @Inject public AutoReloadConfigDecorator( SitePaths site, DestinationFactory destinationFactory, Provider<ReplicationQueue> replicationQueue, @PluginData Path pluginDataDir) throws ConfigInvalidException, IOException { this.site = site; this.destinationFactory = destinationFactory; this.pluginDataDir = pluginDataDir; this.currentConfig = loadConfig(); this.currentConfigTs = getLastModified(currentConfig); <|startfocus|> this.replicationQueue = replicationQueue; <|endfocus|> } private static long getLastModified(ReplicationFileBasedConfig cfg) { return FileUtil.lastModified(cfg.getCfgPath()); } private ReplicationFileBasedConfig loadConfig() throws ConfigInvalidException, IOException { return new ReplicationFileBasedConfig(site, destinationFactory, pluginDataDir); } private synchronized boolean isAutoReload() { return currentConfig.getConfig().getBoolean("gerrit", "autoReload", false); } @Override public synchronized List<Destination> getDestinations(FilterType filterType) { reloadIfNeeded(); return currentConfig.getDestinations(filterType); } private void reloadIfNeeded() {
<|startcomment|> I already had a change ready for this class but was waiting for the release to reach maven central. It's https://gerrit-review.googlesource.com/c/gerrit/+/231001. I like the implementation suggested in there a bit better (e.g. it has Javadoc descriptions) but I can also throw it away if you think that's easier. <|endcomment|> <|startfocus|> private Renderer renderer(String templateName) { <|endfocus|> return args.soySauce .renderTemplate("com.google.gerrit.server.mail.template." + templateName) .setData(soyContext);
<|startcomment|> All Gerrit log filenames are lowercase. What about 'sharedref_log'? <|endcomment|> // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import com.google.gerrit.server.util.SystemLog; import com.google.inject.Inject; import com.google.inject.Singleton; import org.apache.log4j.PatternLayout; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.Ref; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Singleton public class Log4jSharedRefLogger extends LibModuleLogFile implements SharedRefLogger { <|startfocus|> private static final String LOG_NAME = "sharedRefDB_log"; <|endfocus|> private final Logger sharedRefDBLog; @Inject public Log4jSharedRefLogger(SystemLog systemLog) { super(systemLog, LOG_NAME, new PatternLayout("[%d{ISO8601}] [%t] %-5p : %m%n")); sharedRefDBLog = LoggerFactory.getLogger(LOG_NAME); } @Override public void log(String project, Ref currRef, ObjectId newRefValue) { sharedRefDBLog.info( "project:{}|ref:{}|oldId:{}|newId:{}", project, currRef.getName(), currRef.getObjectId().getName(), newRefValue.getName()); } 
<|startcomment|> logRefUpdate <|endcomment|> <|startfocus|> public void log(String project, Ref currRef, ObjectId newRefValue) { <|endfocus|> sharedRefDBLog.info( "project:{}|ref:{}|oldId:{}|newId:{}", project, currRef.getName(), currRef.getObjectId().getName(), newRefValue.getName());
<|startcomment|> logProjectDelete <|endcomment|> <|startfocus|> public void logDeletion(String project) { <|endfocus|> sharedRefDBLog.info("project:{}|DELETED", project);
<|startcomment|> This could go *inside* the sharedDb.removeProject() <|endcomment|>  public void onProjectDeleted(Event event) { String projectName = event.getProjectName(); logger.atInfo().log( "Deleting project '%s'. Will perform a cleanup in Shared-Ref database.", projectName); try { sharedDb.removeProject(projectName); <|startfocus|> sharedRefLogger.logDeletion(projectName); <|endfocus|> } catch (IOException e) { validationMetrics.incrementSplitBrain(); logger.atSevere().withCause(e).log( "Project '%s' deleted from GIT but it was not able to cleanup" + " from Shared-Ref database", projectName); }
<|startcomment|> This could go *inside* the sharedRefDb.compareAndPut() <|endcomment|>  String errorMessage = String.format( "Not able to persist the data in Zookeeper for project '%s' and ref '%s'," + "the cluster is now in Split Brain since the commit has been " + "persisted locally but not in SharedRef the value %s", projectName, refPair.getName(), refPair.putValue); boolean succeeded; try { <|startfocus|> succeeded = sharedRefDb.compareAndPut(projectName, refPair.compareRef, refPair.putValue); sharedRefLogger.log(projectName, refPair.compareRef, refPair.putValue); <|endfocus|> } catch (IOException e) { throw new SharedDbSplitBrainException(errorMessage, e); } if (!succeeded) { throw new SharedDbSplitBrainException(errorMessage); } } protected RefPair compareAndGetLatestLocalRef(RefPair refPair, CloseableSet<AutoCloseable> locks) throws SharedLockException, OutOfSyncException, IOException { String refName = refPair.getName(); EnforcePolicy refEnforcementPolicy = refEnforcement.getPolicy(projectName, refName); if (refEnforcementPolicy == EnforcePolicy.IGNORED) { return refPair; } locks.addResourceIfNotExist(
<|startcomment|> nit: missing space after 'if' <|endcomment|>  private String replaceInUrl(String placeholder, String url, String replacement, boolean lowerCase) { if (url == null || replacement == null || !url.contains(placeholder)) { return url; } <|startfocus|> if(lowerCase) { <|endfocus|> replacement = replacement.toLowerCase(); } // as we can't assume anything of 'replacement', we're URL encoding it return url.replace(placeholder, Url.encode(replacement));
<|startcomment|> HexFormat.fromInt <|endcomment|>  public void cancel() { <|startfocus|> repLog.info("Replication [{}] to {} was canceled", IdGenerator.format(id), getURI()); <|endfocus|> canceledByReplication(); pool.pushWasCanceled(this);
<|startcomment|> HexFormat.fromInt <|endcomment|>  public void setCanceledWhileRunning() { <|startfocus|> repLog.info( "Replication [{}] to {} was canceled while being executed", IdGenerator.format(id), getURI()); <|endfocus|> canceledWhileRunning.set(true);
<|startcomment|> The opening of the repo and walk can be put inside the positive branch of the if. <|endcomment|>  public void logRefUpdate(String project, Ref currRef, ObjectId newRefValue) { <|startfocus|> try (Repository repository = gitRepositoryManager.openRepository(new Project.NameKey(project)); RevWalk walk = new RevWalk(repository)) { if (!ObjectId.zeroId().equals(newRefValue)) { <|endfocus|> RevCommit commit = walk.parseCommit(newRefValue); sharedRefDBLog.info( gson.toJson( new SharedRefLogEntry.UpdateRef( project, currRef.getName(), currRef.getObjectId().getName(), newRefValue.getName(), CommonConverters.toGitPerson(commit.getCommitterIdent()), commit.getFullMessage()))); } else { sharedRefDBLog.info( gson.toJson( new SharedRefLogEntry.DeleteRef( project, currRef.getName(), currRef.getObjectId().getName()))); } } catch (IOException e) { logger.atSevere().withCause(e).log( "Cannot log sharedRefDB interaction for ref %s on project %s", currRef.getName(), project); }
<|startcomment|> DELETE_PROJECT <|endcomment|>  String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; this.newId = newId; this.committer = committer; this.comment = comment; } } public static class DeleteProject extends SharedRefLogEntry { public String refName; public String oldId; DeleteProject(String projectName) { <|startfocus|> this.type = Type.DELETE_REF; <|endfocus|> this.projectName = projectName; } } public static class DeleteRef extends SharedRefLogEntry { public String refName; public String oldId; DeleteRef(String projectName, String refName, String oldId) { this.type = Type.DELETE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; } } } 
<|startcomment|> Before the default (and hardcoded) value was 2 minutes: we should keep that value as the default for people that upgrade the code without setting any value in here. <|endcomment|>  } replicateAllOnPluginStart = config.getBoolean("gerrit", "replicateOnStartup", true); defaultForceUpdate = config.getBoolean("gerrit", "defaultForceUpdate", false); sshCommandTimeout = (int) ConfigUtil.getTimeUnit(config, "gerrit", null, "sshCommandTimeout", 30, SECONDS); sshConnectionTimeout = (int) SECONDS.toMillis( <|startfocus|> ConfigUtil.getTimeUnit( config, "gerrit", null, "sshConnectionTimeout", 30, SECONDS)); <|endfocus|> ImmutableList.Builder<Destination> dest = ImmutableList.builder(); for (RemoteConfig c : allRemotes(config)) { if (c.getURIs().isEmpty()) { continue; } // If destination for push is not set assume equal to source. for (RefSpec ref : c.getPushRefSpecs()) { if (ref.getDestination() == null) { ref.setDestination(ref.getSource()); } } if (c.getPushRefSpecs().isEmpty()) { c.addPushRefSpec( new RefSpec() .setSourceDestination("refs/*", "refs/*") .setForceUpdate(defaultForceUpdate)); } 
<|startcomment|> At first I that that this is dangerous because it would prevent Gerrit from starting up when it fires but then I saw that you are catching this exception in the caller. I am a tiny bit worried that this code might get worked on in the future and the aforementioned catch will go away without us noticing. Would it make sense to use a checked excetption here instead? (e.g. JGit's ConfigInvalidException) <|endcomment|>  private ImmutableSet<String> parseRequestTypes(String traceId) { return ImmutableSet.copyOf(cfg.getStringList("tracing", traceId, "requestType")); } private ImmutableSet<Account.Id> parseAccounts(String traceId) { ImmutableSet.Builder<Account.Id> accountIds = ImmutableSet.builder(); String[] accounts = cfg.getStringList("tracing", traceId, "account"); for (String account : accounts) { Optional<Account.Id> accountId = Account.Id.tryParse(account); if (!accountId.isPresent()) { <|startfocus|> throw new IllegalArgumentException( <|endfocus|> String.format( "Invalid tracing config ('tracing.%s.account = %s'): invalid account ID", traceId, account)); } accountIds.add(accountId.get()); } return accountIds.build(); } private ImmutableSet<Pattern> parseProjectPatterns(String traceId) { ImmutableSet.Builder<Pattern> projectPatterns = ImmutableSet.builder(); String[] projectPatternRegExs = cfg.getStringList("tracing", traceId, "projectPattern"); for (String projectPatternRegEx : projectPatternRegExs) { try {
<|startcomment|> nit: !anymatch == nonematch !(at least one) == is zero <|endcomment|>  boolean matches(RequestInfo requestInfo) { if (!requestTypes().isEmpty() <|startfocus|> && !requestTypes().stream() .anyMatch(type -> type.equalsIgnoreCase(requestInfo.requestType()))) { <|endfocus|> return false; } if (!accountIds().isEmpty()) { try { if (!accountIds().stream() .anyMatch(id -> id.equals(requestInfo.callingUser().getAccountId()))) { return false; } } catch (UnsupportedOperationException e) { // calling user is not logged in return false; } } if (!projectPatterns().isEmpty()) { if (!requestInfo.project().isPresent()) { // request is not for a project return false; } if (!projectPatterns().stream() .anyMatch(p -> p.matcher(requestInfo.project().get().get()).matches())) { return false; } } return true;
<|startcomment|> It would be good to use "{@link CheckInfo}" as the other Javaodc descriptions in this file do. <|endcomment|>  /** Java API to interact with single {@code Check}s. */ public interface CheckApi { /** Returns a {@link CheckInfo} for the scoped resource with the given options. */ CheckInfo get(ListChecksOption... options) throws RestApiException; /** Updates a check and returns the {@link CheckInfo} for the updated resource. */ CheckInfo update(CheckInput input) throws RestApiException; <|startfocus|> /** reruns the check and returns the CheckInfo for the updated check. Input ignores "state". */ CheckInfo rerun(CheckInput input) throws RestApiException; <|endfocus|> /** * A default implementation which allows source compatibility when adding new methods to the * interface. */ class NotImplemented implements CheckApi { @Override public CheckInfo get(ListChecksOption... options) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo update(CheckInput input) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo rerun(CheckInput input) throws RestApiException { throw new NotImplementedException(); } } }
<|startcomment|> Nit: Javadoc descriptions typically start with a capital letter. <|endcomment|>  /** Java API to interact with single {@code Check}s. */ public interface CheckApi { /** Returns a {@link CheckInfo} for the scoped resource with the given options. */ CheckInfo get(ListChecksOption... options) throws RestApiException; /** Updates a check and returns the {@link CheckInfo} for the updated resource. */ CheckInfo update(CheckInput input) throws RestApiException; <|startfocus|> /** reruns the check and returns the CheckInfo for the updated check. Input ignores "state". */ CheckInfo rerun(CheckInput input) throws RestApiException; <|endfocus|> /** * A default implementation which allows source compatibility when adding new methods to the * interface. */ class NotImplemented implements CheckApi { @Override public CheckInfo get(ListChecksOption... options) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo update(CheckInput input) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo rerun(CheckInput input) throws RestApiException { throw new NotImplementedException(); } } }
<|startcomment|> Specifying a CheckInput shouldn't be necessary. All necessary details are contained in the CheckResource. Without CheckInput, the code below would also be simpler as lines 45-52 would never happen. <|endcomment|> import com.google.gerrit.extensions.restapi.BadRequestException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.extensions.restapi.RestModifyView; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import org.eclipse.jgit.errors.ConfigInvalidException; @Singleton public class RerunCheck implements RestModifyView<CheckResource, CheckInput> { private final PostCheck postCheck; @Inject RerunCheck(PostCheck postCheck) { this.postCheck = postCheck; } <|startfocus|> @Override <|endfocus|> public CheckInfo apply(CheckResource checkResource, CheckInput input) throws RestApiException, IOException, StorageException, PermissionBackendException, ConfigInvalidException { if (input == null) { input = new CheckInput(); } if (input.checkerUuid == null) { input.checkerUuid = checkResource.getCheckerUuid().get(); } else if (!checkResource.getCheckerUuid().get().equals(input.checkerUuid)) { throw new BadRequestException( String.format( "checker UUID in input must either be null or the same as on the resource:\n"
<|startcomment|> This variable is never used and could be removed. <|endcomment|> import com.google.gerrit.plugins.checks.api.CheckInfo; import com.google.gerrit.plugins.checks.api.CheckInput; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.gerrit.testing.TestTimeUtil; import com.google.inject.Inject; import java.sql.Timestamp; import java.time.Instant; import java.util.concurrent.TimeUnit; import org.junit.After; import org.junit.Before; import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { <|startfocus|> @Inject private RequestScopeOperations requestScopeOperations; <|endfocus|> private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test
<|startcomment|> Is there a specific reason why we need this for the test? Other tests might have it as they are verifying time stamps and this code helps to make them deterministic for the tests. For the rerun tests, I would guess that we don't need it but I'm happy to be proven differently. <|endcomment|> import com.google.gerrit.testing.TestTimeUtil; import com.google.inject.Inject; import java.sql.Timestamp; import java.time.Instant; import java.util.concurrent.TimeUnit; import org.junit.After; import org.junit.Before; import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { <|startfocus|> TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); <|endfocus|> patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void RerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING; 
<|startcomment|> It would be better if this operation is part of each test where we need it as we might have different starting situations as described in another comment below. For most tests, it might not be even necessary. I know that other test classes have it too but this was an oversight. Background why we don't need it in most cases: Updating a check on a change is always possible (minus some specific corner cases). It doesn't need to be created first. If the checker applies to a change, the check exists virtually even when no updates happened in the past. <|endcomment|> public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); <|startfocus|> checkOperations.newCheck(checkKey).upsert(); <|endfocus|> } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void RerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING; CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(input); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } } 
<|startcomment|> Nit: According to the style guide, method names should start with lower case letters in Java. <|endcomment|>  @Before public void setUp() throws Exception { TestTimeUtil.resetWithClockStep(1, TimeUnit.SECONDS); TestTimeUtil.setClock(Timestamp.from(Instant.EPOCH)); patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test <|startfocus|> public void RerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING; <|endfocus|> CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(input); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } } 
<|startcomment|> Currently, this test verifies that a check which was in state NOT_STARTED is still in state NOT_STARTED after executing rerun. It's a test we should also have. It would just be better to make this clear (e.g. via the name of the test). Of course, the test that a check which hadn't been in the NOT_STARTED state and is reset upon rerun will also be necessary. Ideally, we also have two versions of this test here: one where the check originally didn't exist and one where the check existed with NOT_STARTED state) <|endcomment|>  CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); checkOperations.newCheck(checkKey).upsert(); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void RerunCheck() throws Exception { CheckInput input = new CheckInput(); input.state = CheckState.RUNNING; <|startfocus|> CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(input); <|endfocus|> assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } } 
<|startcomment|> optional: replace all these with just RestApiException <|endcomment|>  PermissionBackend permissionBackend, ExternalIds externalIds, @ServerInitiated Provider<AccountsUpdate> accountsUpdateProvider, SshKeyCache sshKeyCache, Realm realm) { this.self = self; this.permissionBackend = permissionBackend; this.externalIds = externalIds; this.accountsUpdateProvider = accountsUpdateProvider; this.sshKeyCache = sshKeyCache; this.realm = realm; } @Override public String apply(AccountResource rsrc, UsernameInput input) <|startfocus|> throws AuthException, BadRequestException, MethodNotAllowedException, UnprocessableEntityException, ResourceConflictException, IOException, ConfigInvalidException, PermissionBackendException { <|endfocus|> if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); } if (!realm.allowsEdit(AccountFieldName.USER_NAME)) { throw new MethodNotAllowedException("realm does not allow editing username"); } Account.Id accountId = rsrc.getUser().getAccountId(); if (!externalIds.byAccount(accountId, SCHEME_USERNAME).isEmpty()) { throw new MethodNotAllowedException("Username cannot be changed."); } 
<|startcomment|> Should the method just return here, or even throw an exception, when the input is not given? If we just create a new input here its username member will always be null and it will return null at L97. Then it's not necessary to have checked if the username is already set (L89-92). <|endcomment|>  } @Override public String apply(AccountResource rsrc, UsernameInput input) throws AuthException, MethodNotAllowedException, UnprocessableEntityException, ResourceConflictException, IOException, ConfigInvalidException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); } if (!realm.allowsEdit(AccountFieldName.USER_NAME)) { throw new MethodNotAllowedException("realm does not allow editing username"); } <|startfocus|> if (input == null) { input = new UsernameInput(); } <|endfocus|> Account.Id accountId = rsrc.getUser().getAccountId(); if (!externalIds.byAccount(accountId, SCHEME_USERNAME).isEmpty()) { throw new MethodNotAllowedException("Username cannot be changed."); } if (Strings.isNullOrEmpty(input.username)) { // A username is not set yet and in the input no username was specified. Hence there is // nothing to do. return input.username; } if (!ExternalId.isValidUsername(input.username)) {
<|startcomment|> nit: better "that produced this check" (the same description that is used for the fields above) <|endcomment|>  @Nullable public Timestamp finished; /** Timestamp of when this check was created. */ public Timestamp created; /** Timestamp of when this check was last updated. */ public Timestamp updated; /** Name of the checker that produced this check. */ public String checkerName; /** Status of the checker that produced this check. */ public CheckerStatus checkerStatus; /** Blocking conditions that apply to this check. */ public Set<BlockingCondition> blocking; <|startfocus|> /** Description of the checker for this check */ public String description; <|endfocus|> @Override public boolean equals(Object o) { if (!(o instanceof CheckInfo)) { return false; } CheckInfo other = (CheckInfo) o; return Objects.equals(other.repository, repository) && Objects.equals(other.changeNumber, changeNumber) && Objects.equals(other.patchSetId, patchSetId) && Objects.equals(other.checkerUuid, checkerUuid) && Objects.equals(other.state, state) && Objects.equals(other.message, message) && Objects.equals(other.url, url) && Objects.equals(other.started, started)
<|startcomment|> Nit: I think it would be better if this field was named "checkerDescription" to make a clear distinction between it and "message". This also follows the naming pattern applied above to the other checker fields. I would also move this field a bit closer to them (e.g. above "blocking"). <|endcomment|>  /** Timestamp of when this check was created. */ public Timestamp created; /** Timestamp of when this check was last updated. */ public Timestamp updated; /** Name of the checker that produced this check. */ public String checkerName; /** Status of the checker that produced this check. */ public CheckerStatus checkerStatus; /** Blocking conditions that apply to this check. */ public Set<BlockingCondition> blocking; <|startfocus|> /** Description of the checker for this check */ public String description; <|endfocus|> @Override public boolean equals(Object o) { if (!(o instanceof CheckInfo)) { return false; } CheckInfo other = (CheckInfo) o; return Objects.equals(other.repository, repository) && Objects.equals(other.changeNumber, changeNumber) && Objects.equals(other.patchSetId, patchSetId) && Objects.equals(other.checkerUuid, checkerUuid) && Objects.equals(other.state, state) && Objects.equals(other.message, message) && Objects.equals(other.url, url) && Objects.equals(other.started, started) && Objects.equals(other.finished, finished)
<|startcomment|> nit: drop this <|endcomment|>  } if (options.contains(FillOptions.STATUS)) { info.status = account.getStatus(); } if (options.contains(FillOptions.AVATARS)) { AvatarProvider ap = avatar.get(); if (ap != null) { info.avatars = new ArrayList<>(); IdentifiedUser user = userFactory.create(account.getId()); // PolyGerrit UI uses the following sizes for avatars: <|startfocus|> // - 32px for avatars on next to names e.g. on the dashboard. This is also Gerrit's default. <|endfocus|> // - 56px for the user's own avatar in the menu // - 100ox for other user's avatars on dashboards // - 120px for the user's own profile settings page addAvatar(ap, info, user, AvatarInfo.DEFAULT_SIZE); if (!info.avatars.isEmpty()) { addAvatar(ap, info, user, 56); addAvatar(ap, info, user, 100); addAvatar(ap, info, user, 120); } } }
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2013 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import org.eclipse.jgit.errors.NotSupportedException; import org.eclipse.jgit.errors.TransportException; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.transport.Transport; import org.eclipse.jgit.transport.URIish; public interface TransportFactory { Transport open(Repository local, URIish uri) throws NotSupportedException, TransportException; } 
<|startcomment|> 2019 <|endcomment|> <|startfocus|> Copyright (C) 2013 The Android Open Source Project <|endfocus|> // // Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import org.eclipse.jgit.errors.NotSupportedException; import org.eclipse.jgit.errors.TransportException; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.transport.Transport; import org.eclipse.jgit.transport.URIish; public class TransportFactoryImpl implements TransportFactory { @Override public Transport open(Repository git, URIish uri) throws NotSupportedException, TransportException { return Transport.open(git, uri); } } 
<|startcomment|> All these variables could be private <|endcomment|> import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.transport.FetchConnection; import org.eclipse.jgit.transport.PushConnection; import org.eclipse.jgit.transport.PushResult; import org.eclipse.jgit.transport.RefSpec; import org.eclipse.jgit.transport.RemoteConfig; import org.eclipse.jgit.transport.RemoteRefUpdate; import org.eclipse.jgit.transport.Transport; import org.eclipse.jgit.transport.URIish; import org.eclipse.jgit.util.FS; import org.junit.Before; import org.junit.Test; public class PushOneTest { <|startfocus|> GitRepositoryManager gitRepositoryManagerMock; Repository repositoryMock; PermissionBackend permissionBackendMock; PermissionBackend.WithUser withUserMock; PermissionBackend.ForProject forProjectMock; <|endfocus|> Destination destinationMock; RemoteConfig remoteConfigMock; RefSpec refSpecMock; CredentialsFactory credentialsFactory; PerThreadRequestScope.Scoper threadRequestScoperMock; ReplicationQueue replicationQueueMock; IdGenerator idGeneratorMock; ReplicationStateListeners replicationStateListenersMock; ReplicationMetrics replicationMetricsMock; Timer1.Context timerContextMock; ProjectCache projectCacheMock; RunwayStatus statusMock; TransportFactory transportFactoryMock; Transport transportMock; FetchConnection fetchConnection; PushConnection pushConnection; ProjectState projectStateMock;
<|startcomment|> isCallFinished.get() is already a boolean, no need to compare it with truth <|endcomment|>  verify(transportMock); } private PushOne createPushOne(DynamicItem<ReplicationPushFilter> replicationPushFilter) { PushOne push = new PushOne( gitRepositoryManagerMock, permissionBackendMock, destinationMock, remoteConfigMock, credentialsFactory, threadRequestScoperMock, replicationQueueMock, idGeneratorMock, replicationStateListenersMock, replicationMetricsMock, projectCacheMock, transportFactoryMock, projectNameKey, urish); push.setReplicationPushFilter(replicationPushFilter); return push; } private void waitUntilFinished() throws InterruptedException { <|startfocus|> while (isCallFinished.get() != true) { <|endfocus|> Thread.sleep(100); } } private void setupProjectCacheMock() throws IOException { projectCacheMock = createNiceMock(ProjectCache.class); expect(projectCacheMock.checkedGet(projectNameKey)).andReturn(projectStateMock); } private void setupTransportMock() throws NotSupportedException, TransportException { transportMock = createNiceMock(Transport.class); expect(transportMock.openFetch()).andReturn(fetchConnection); transportFactoryMock = createNiceMock(TransportFactory.class); expect(transportFactoryMock.open(repositoryMock, urish)).andReturn(transportMock).anyTimes(); } private void setupReplicationMetricsMock() {
<|startcomment|> RepositoryNotFoundException is also IOException and thus can be removed <|endcomment|>  private void setupDestinationMock() { destinationMock = createNiceMock(Destination.class); expect(destinationMock.requestRunway(anyObject())).andReturn(RunwayStatus.allowed()); } private void setupPermissionBackedMock() { permissionBackendMock = createNiceMock(PermissionBackend.class); expect(permissionBackendMock.currentUser()).andReturn(withUserMock); } private void setupWithUserMock() { withUserMock = createNiceMock(WithUser.class); expect(withUserMock.project(projectNameKey)).andReturn(forProjectMock); } <|startfocus|> private void setupGitRepoManagerMock() throws RepositoryNotFoundException, IOException { <|endfocus|> gitRepositoryManagerMock = createNiceMock(GitRepositoryManager.class); expect(gitRepositoryManagerMock.openRepository(projectNameKey)).andReturn(repositoryMock); } private void setupRepositoryMock(FileBasedConfig config) throws IOException { repositoryMock = createNiceMock(Repository.class); expect(repositoryMock.getConfig()).andReturn(config).anyTimes(); expect(repositoryMock.getAllRefs()).andReturn(localRefs); expect(repositoryMock.updateRef("fooProject")).andReturn(refUpdateMock); } private void setupRefUpdateMock() { refUpdateMock = createNiceMock(RefUpdate.class);
<|startcomment|> do we need this? can't we just use object comparison? Or even toString[1] [1]https://github.com/eclipse/jgit/blob/master/org.eclipse.jgit/src/org/eclipse/jgit/transport/RemoteRefUpdate.java#L514 <|endcomment|>  && compareField(ref.getStatus(), expectedRef.getStatus()) && compareField(ref.getExpectedOldObjectId(), expectedRef.getExpectedOldObjectId()) && compareField(ref.getNewObjectId(), expectedRef.getNewObjectId()) && compareField(ref.isFastForward(), expectedRef.isFastForward()) && compareField(ref.getSrcRef(), expectedRef.getSrcRef()) && compareField(ref.isForceUpdate(), expectedRef.isForceUpdate()) && compareField(ref.getMessage(), expectedRef.getMessage()); } <|startfocus|> private boolean compareField(Object obj, Object expectedObj) { return obj != null ? obj.equals(expectedObj) : expectedObj == null; } <|endfocus|> } } 
<|startcomment|> This is not needed, right ? <|endcomment|>  public GitPerson committer; public String comment; UpdateRef( String projectName, String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; this.newId = newId; this.committer = committer; this.comment = comment; } } public static class DeleteProject extends SharedRefLogEntry { <|startfocus|> public String refName; public String oldId; <|endfocus|> DeleteProject(String projectName) { this.type = Type.DELETE_PROJECT; this.projectName = projectName; } } public static class DeleteRef extends SharedRefLogEntry { public String refName; public String oldId; DeleteRef(String projectName, String refName, String oldId) { this.type = Type.DELETE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; } } } 
<|startcomment|> This is not needed, right? <|endcomment|>  public String comment; UpdateRef( String projectName, String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; this.newId = newId; this.committer = committer; this.comment = comment; } } public static class DeleteProject extends SharedRefLogEntry { <|startfocus|> public String refName; public String oldId; <|endfocus|> DeleteProject(String projectName) { this.type = Type.DELETE_PROJECT; this.projectName = projectName; } } public static class DeleteRef extends SharedRefLogEntry { public String refName; public String oldId; DeleteRef(String projectName, String refName, String oldId) { this.type = Type.DELETE_REF; this.projectName = projectName; this.refName = refName; this.oldId = oldId; } } } 
<|startcomment|> When you add a new REST endpoint, please also test it in ChecksRestApiBindingsIT. <|endcomment|> // limitations under the License. package com.google.gerrit.plugins.checks.api; import com.google.gerrit.exceptions.StorageException; import com.google.gerrit.extensions.restapi.BadRequestException; import com.google.gerrit.extensions.restapi.RestApiException; import com.google.gerrit.extensions.restapi.RestModifyView; import com.google.gerrit.server.permissions.PermissionBackendException; import com.google.inject.Inject; import com.google.inject.Singleton; import java.io.IOException; import org.eclipse.jgit.errors.ConfigInvalidException; @Singleton public class RerunCheck implements RestModifyView<CheckResource, CheckInput> { <|startfocus|> private final PostCheck postCheck; <|endfocus|> @Inject RerunCheck(PostCheck postCheck) { this.postCheck = postCheck; } @Override public CheckInfo apply(CheckResource checkResource, CheckInput input) throws RestApiException, IOException, StorageException, PermissionBackendException, ConfigInvalidException { if (input == null) { input = new CheckInput(); } if (input.checkerUuid == null) { input.checkerUuid = checkResource.getCheckerUuid().get(); } else if (!checkResource.getCheckerUuid().get().equals(input.checkerUuid)) { throw new BadRequestException(
<|startcomment|> should this be @singleton, or are cache loader a special case? <|endcomment|> import org.eclipse.jgit.diff.DiffEntry; import org.eclipse.jgit.diff.DiffFormatter; import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.ObjectReader; import org.eclipse.jgit.lib.Ref; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.util.io.DisabledOutputStream; <|startfocus|> /** Loads cache values for the external ID cache using either a full or a partial reload. */ <|endfocus|> public class ExternalIdCacheLoader extends CacheLoader<ObjectId, AllExternalIds> { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); // Maximum number of prior states we inspect to find a base for differential. If no cached state // is found within this number of parents, , we fall back to reading everything from scratch. private static final int MAX_HISTORY_LOOKBACK = 10; // Maximum number of changes we perform using the differential approach. If more updates need to
<|startcomment|> drop <|endcomment|> import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.util.io.DisabledOutputStream; /** Loads cache values for the external ID cache using either a full or a partial reload. */ public class ExternalIdCacheLoader extends CacheLoader<ObjectId, AllExternalIds> { private static final FluentLogger logger = FluentLogger.forEnclosingClass(); // Maximum number of prior states we inspect to find a base for differential. If no cached state <|startfocus|> // is found within this number of parents, , we fall back to reading everything from scratch. <|endfocus|> private static final int MAX_HISTORY_LOOKBACK = 10; // Maximum number of changes we perform using the differential approach. If more updates need to // be applied, we fall back to reading everything from scratch. private static final int MAX_DIFF_UPDATES = 50; private final ExternalIdReader externalIdReader; private final Provider<Cache<ObjectId, AllExternalIds>> externalIdCache; private final GitRepositoryManager gitRepositoryManager; private final AllUsersName allUsersName; private final Counter1<Boolean> reloadCounter; private final Timer0 reloadDifferential;
<|startcomment|> should this be false for a smooth rollout ? <|endcomment|>  new Description("Total number of external ID cache reloads from Git.") .setRate() .setUnit("updates"), Field.ofBoolean("partial", Metadata.Builder::partial).build()); this.reloadDifferential = metricMaker.newTimer( "notedb/external_id_partial_read_latency", new Description( "Latency for generating a new external ID cache state from a prior state.") .setCumulative() .setUnit(Units.MILLISECONDS)); this.enablePartialReloads = <|startfocus|> config.getBoolean("cache", ExternalIdCacheImpl.CACHE_NAME, "enablePartialReloads", true); <|endfocus|> } @Override public AllExternalIds load(ObjectId notesRev) throws IOException, ConfigInvalidException { if (!enablePartialReloads) { logger.atInfo().log( "Partial reloads of " + ExternalIdCacheImpl.CACHE_NAME + " disabled. Falling back to full reload."); return reloadAllExternalIdsAndCachePersistently(notesRev); } // We failed to load the requested value from both the in-memory cache (hence, this loader was
<|startcomment|> I propose to leave this renaming or refactoring to a follow-up change instead. <|endcomment|> import com.googlesource.gerrit.plugins.renameproject.monitor.ProgressMonitor; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.List; import org.kohsuke.args4j.Argument; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @CommandMetaData(name = "rename", description = "Rename project") public final class RenameCommand extends SshCommand { @Argument(index = 0, required = true, metaVar = "OLDPROJECT", usage = "project to rename") <|startfocus|> private String existingProjectName; <|endfocus|> @Argument(index = 1, required = true, metaVar = "NEWNAME", usage = "new name for the project") private String newProjectName; private static final Logger log = LoggerFactory.getLogger(RenameCommand.class); private final RenameProject renameProject; private final ProjectCache projectCache; private final Provider<CurrentUser> self; @Inject protected RenameCommand( RenameProject renameProject, ProjectCache projectCache, Provider<CurrentUser> self) { this.renameProject = renameProject; this.projectCache = projectCache; this.self = self; } @Override
<|startcomment|> Why not just allow to pass null and annotate the parameter with @Nullable? <|endcomment|>  public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); /** <|startfocus|> * @param started - set the time the check started. Time can be reset to "null" if passed new * Timestamp(0). <|endfocus|> */ public abstract Builder setStarted(Timestamp started); /** * @param finished - set the time the check finished. Time can be reset to "null" if passed new * Timestamp(0). */ public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); } } 
<|startcomment|> [optional] I wonder if these should be configurable for fine-tuning <|endcomment|>  private static final FluentLogger logger = FluentLogger.forEnclosingClass(); // Maximum number of prior states we inspect to find a base for differential. If no cached state <|startfocus|> // is found within this number of parents, , we fall back to reading everything from scratch. <|endfocus|> private static final int MAX_HISTORY_LOOKBACK = 10; // Maximum number of changes we perform using the differential approach. If more updates need to // be applied, we fall back to reading everything from scratch. private static final int MAX_DIFF_UPDATES = 50; private final ExternalIdReader externalIdReader; private final Provider<Cache<ObjectId, AllExternalIds>> externalIdCache; private final GitRepositoryManager gitRepositoryManager; private final AllUsersName allUsersName; private final Counter1<Boolean> reloadCounter; private final Timer0 reloadDifferential; private final boolean enablePartialReloads; @Inject ExternalIdCacheLoader( GitRepositoryManager gitRepositoryManager, AllUsersName allUsersName, ExternalIdReader externalIdReader, @Named(ExternalIdCacheImpl.CACHE_NAME) Provider<Cache<ObjectId, AllExternalIds>> externalIdCache, MetricMaker metricMaker,
<|startcomment|> RevWalk must be closed. <|endcomment|>  // state. try (Repository repo = gitRepositoryManager.openRepository(allUsersName)) { long start = System.nanoTime(); Ref extId = repo.exactRef(RefNames.REFS_EXTERNAL_IDS); if (extId == null) { logger.atInfo().log( RefNames.REFS_EXTERNAL_IDS + " not initialized, falling back to full reload."); return reloadAllExternalIdsAndCachePersistently(notesRev); } <|startfocus|> RevWalk rw = new RevWalk(repo); RevCommit currentCommit = rw.parseCommit(extId.getObjectId()); <|endfocus|> rw.markStart(currentCommit); RevCommit parentWithCacheValue = null; AllExternalIds oldExternalIds = null; for (int i = 0; i < MAX_HISTORY_LOOKBACK; i++) { parentWithCacheValue = rw.next(); oldExternalIds = externalIdCache.get().getIfPresent(parentWithCacheValue.getId()); if (oldExternalIds != null) { break; } if (parentWithCacheValue.getParentCount() != 1) { logger.atWarning().log(
<|startcomment|> This returns null if there are no more commits to traverse. I see that cannot happen here, because below we fall back to loading all ext ids if there is no parent commit, but when I read the code top-down, I stumble over this. Can you add a comment, or rewrite this part to make it more readable? <|endcomment|>  logger.atInfo().log( RefNames.REFS_EXTERNAL_IDS + " not initialized, falling back to full reload."); return reloadAllExternalIdsAndCachePersistently(notesRev); } RevWalk rw = new RevWalk(repo); RevCommit currentCommit = rw.parseCommit(extId.getObjectId()); rw.markStart(currentCommit); RevCommit parentWithCacheValue = null; AllExternalIds oldExternalIds = null; <|startfocus|> for (int i = 0; i < MAX_HISTORY_LOOKBACK; i++) { parentWithCacheValue = rw.next(); <|endfocus|> oldExternalIds = externalIdCache.get().getIfPresent(parentWithCacheValue.getId()); if (oldExternalIds != null) { break; } if (parentWithCacheValue.getParentCount() != 1) { logger.atWarning().log( "Unable to find an old ExternalId cache state because %s doesn't have exactly " + "one parent, falling back to full reload", parentWithCacheValue); return reloadAllExternalIdsAndCachePersistently(notesRev); } } if (oldExternalIds == null) { logger.atWarning().log(
<|startcomment|> Instead of measuring the time manually use reloadDifferential.start() to open a context. <|endcomment|>  nameToBlob.getValue()); } catch (ConfigInvalidException | RuntimeException e) { logger.atSevere().withCause(e).log( "Ignoring invalid external ID note %s", nameToBlob.getKey().name()); continue; } byAccount.put(parsedExternalId.accountId(), parsedExternalId); if (parsedExternalId.email() != null) { byEmail.put(parsedExternalId.email(), parsedExternalId); } } <|startfocus|> reloadCounter.increment(true); reloadDifferential.record(System.nanoTime() - start, TimeUnit.NANOSECONDS); return new AutoValue_AllExternalIds(byAccount.build(), byEmail.build()); <|endfocus|> } } private static ObjectId fileNameToObjectId(String path) { int lastSlash = path.lastIndexOf('/'); return ObjectId.fromString(lastSlash > 0 ? path.substring(lastSlash) : path); } private AllExternalIds reloadAllExternalIdsAndCachePersistently(ObjectId notesRev) throws IOException, ConfigInvalidException { try (TraceTimer ignored = TraceContext.newTimer( "Loading external IDs from scratch",
<|startcomment|> I think this is wrong. If the SHA1 of the external ID is e4599d9d6d0676b20d1ae9f8f1021e723d6af917 and it's stored sharded with 2 levels the path is: e4/59/9d9d6d0676b20d1ae9f8f1021e723d6af917 To get the ObjectId, you need to remove all slashes of the path, and not just take the last path segment, don't you? <|endcomment|>  private static ObjectId fileNameToObjectId(String path) { <|startfocus|> int lastSlash = path.lastIndexOf('/'); return ObjectId.fromString(lastSlash > 0 ? path.substring(lastSlash) : path); <|endfocus|>
<|startcomment|> Is this needed? externalIdCache is injected and is the cache that uses this loader to load missing values, so when the loader is invoked isn't the result automatically added to the cache? I guess this is about persistence, but externalIdCache is an in-memory cache without persistence, isn't it? <|endcomment|>  } private AllExternalIds reloadAllExternalIdsAndCachePersistently(ObjectId notesRev) throws IOException, ConfigInvalidException { try (TraceTimer ignored = TraceContext.newTimer( "Loading external IDs from scratch", Metadata.builder().revision(notesRev.name()).build())) { ImmutableSet<ExternalId> externalIds = externalIdReader.all(notesRev); externalIds.forEach(ExternalId::checkThatBlobIdIsSet); AllExternalIds allExternalIds = AllExternalIds.create(externalIds); <|startfocus|> externalIdCache.get().put(notesRev, allExternalIds); <|endfocus|> reloadCounter.increment(false); return allExternalIds; } } } 
<|startcomment|> I actually did regret that "Boolean: one or more" comment because the return type already tells you that it's Boolean. This is why internally I changed it to "One or more resources." but I was too lazy to clean it up here. But before we are now applying this comment pattern to further metadata fields, I would prefer to get it fixed. Could you do that? <|endcomment|>  // The UUID of a group. public abstract Optional<String> groupUuid(); // HTTP status response code. public abstract Optional<Integer> httpStatus(); // The name of a secondary index. public abstract Optional<String> indexName(); // The version of a secondary index. public abstract Optional<Integer> indexVersion(); // The name of the implementation method. public abstract Optional<String> methodName(); // Boolean: one or more public abstract Optional<Boolean> multiple(); <|startfocus|> // Boolean: partial or full <|endfocus|> public abstract Optional<Boolean> partial(); // Path of a metadata file in NoteDb. public abstract Optional<String> noteDbFilePath(); // Name of a metadata ref in NoteDb. public abstract Optional<String> noteDbRefName(); // Type of a sequence in NoteDb (ACCOUNTS, CHANGES, GROUPS). public abstract Optional<String> noteDbSequenceType(); // Name of a "table" in NoteDb (if set, always CHANGES). public abstract Optional<String> noteDbTable(); // The ID of a patch set.
<|startcomment|> Don't you want max? <|endcomment|>  package com.google.gerrit.server.config; import com.google.inject.Inject; import com.google.inject.Singleton; import org.eclipse.jgit.lib.Config; @Singleton public class ThreadSettingsConfig { private final int sshdThreads; private final int httpdMaxThreads; private final int sshdBatchThreads; private final int databasePoolLimit; @Inject ThreadSettingsConfig(@GerritServerConfig Config cfg) { int cores = Runtime.getRuntime().availableProcessors(); <|startfocus|> sshdThreads = cfg.getInt("sshd", "threads", Math.min(4, 2 * cores)); <|endfocus|> httpdMaxThreads = cfg.getInt("httpd", "maxThreads", 25); int defaultDatabasePoolLimit = sshdThreads + httpdMaxThreads + 2; databasePoolLimit = cfg.getInt("database", "poolLimit", defaultDatabasePoolLimit); sshdBatchThreads = cores == 1 ? 1 : 2; } public int getDatabasePoolLimit() { return databasePoolLimit; } public int getHttpdMaxThreads() { return httpdMaxThreads; } public int getSshdThreads() { return sshdThreads; } public int getSshdBatchTreads() { return sshdBatchThreads; } }
<|startcomment|> I think it would be easier to understand that this method updates the given account if the parameter was changed to Account.Builder. This means you would need getters on the builder, but those should be useful also in other cases see [1]. [1] https://gerrit-review.googlesource.com/c/gerrit/+/232014/1/javatests/com/google/gerrit/server/index/account/AccountFieldTest.java <|endcomment|> import org.eclipse.jgit.lib.RefUpdate.Result; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.lib.RepositoryCache.FileKey; import org.eclipse.jgit.util.FS; public class AccountsOnInit { private final InitFlags flags; private final SitePaths site; private final String allUsers; @Inject public AccountsOnInit(InitFlags flags, SitePaths site, AllUsersNameOnInitProvider allUsers) { this.flags = flags; this.site = site; this.allUsers = allUsers.get(); } <|startfocus|> public Account insert(Account account) throws IOException { <|endfocus|> File path = getPath(); if (path != null) { try (Repository repo = new FileRepository(path); ObjectInserter oi = repo.newObjectInserter()) { PersonIdent ident = new PersonIdent(new GerritPersonIdentProvider(flags.cfg).get(), account.registeredOn()); Config accountConfig = new Config(); AccountProperties.writeToAccountConfig( InternalAccountUpdate.builder() .setActive(account.isActive()) .setFullName(account.fullName()) .setPreferredEmail(account.preferredEmail()) .setStatus(account.status()) .build(),
<|startcomment|> It would be nicer to have a getter for the id on the builder. The same in the files that follow. <|endcomment|>  AllUsersName allUsersName = new AllUsersName(AllUsersNameProvider.DEFAULT); Account.Builder account = Account.builder(Account.id(1), TimeUtil.nowTs()); String metaId = "0e39795bb25dc914118224995c53c5c36923a461"; account.setMetaId(metaId); List<String> values = toStrings(AccountField.REF_STATE.get(AccountState.forAccount(account.build()))); assertThat(values).hasSize(1); String expectedValue = <|startfocus|> allUsersName.get() + ":" + RefNames.refsUsers(Account.id(1)) + ":" + metaId; <|endfocus|> assertThat(Iterables.getOnlyElement(values)).isEqualTo(expectedValue); } @Test public void externalIdStateFieldValues() throws Exception { Account.Id id = Account.id(1); Account account = Account.create(id, TimeUtil.nowTs()); ExternalId extId1 = ExternalId.create( ExternalId.Key.create(ExternalId.SCHEME_MAILTO, "foo.bar@example.com"), id, "foo.bar@example.com", null, ObjectId.fromString("1b9a0cf038ea38a0ab08617c39aa8e28413a27ca")); ExternalId extId2 =
<|startcomment|> Provider<ProjectCache>, rather? <|endcomment|>  @CommandMetaData(name = "rename", description = "Rename project") public final class RenameCommand extends SshCommand { @Argument(index = 0, required = true, metaVar = "OLDPROJECT", usage = "project to rename") private String projectControl; @Argument(index = 1, required = true, metaVar = "NEWNAME", usage = "new name for the project") private String newProjectName; private static final Logger log = LoggerFactory.getLogger(RenameCommand.class); private final RenameProject renameProject; <|startfocus|> private final ProjectCache projectCache; <|endfocus|> private final Provider<CurrentUser> self; @Inject protected RenameCommand( RenameProject renameProject, ProjectCache projectCache, Provider<CurrentUser> self) { this.renameProject = renameProject; this.projectCache = projectCache; this.self = self; } @Override public void run() throws Exception { try { RenameProject.Input input = new RenameProject.Input(); input.name = newProjectName; ProjectResource rsrc = new ProjectResource(projectCache.get(new Project.NameKey(projectControl)), self.get());
<|startcomment|> Here and also in other files: This is still 'description'. For this reason, this change fails to compile. To change the name with minimal effort for all usages, it's best to use the refactoring tools of an IDE. If this didn't work for you previously for some reason, please tell me and we'll do it together. <|endcomment|>  && Objects.equals(other.checkerUuid, checkerUuid) && Objects.equals(other.state, state) && Objects.equals(other.message, message) && Objects.equals(other.url, url) && Objects.equals(other.started, started) && Objects.equals(other.finished, finished) && Objects.equals(other.created, created) && Objects.equals(other.updated, updated) && Objects.equals(other.checkerName, checkerName) && Objects.equals(other.checkerStatus, checkerStatus) && Objects.equals(other.blocking, blocking) <|startfocus|> && Objects.equals(other.description, description); <|endfocus|>
<|startcomment|> nit: the Javadoc format doesn't use a separator here <|endcomment|>  public abstract Optional<Timestamp> started(); public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); /** <|startfocus|> * @param started - set the time the check started. Time can be reset to "null" if passed new * Timestamp(0). <|endfocus|> */ public abstract Builder setStarted(Timestamp started); /** * @param finished - set the time the check finished. Time can be reset to "null" if passed new * Timestamp(0). */ public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); } } 
<|startcomment|> maybe format this as code for better readability: {@code new Timestamp(0)} <|endcomment|>  public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); /** <|startfocus|> * @param started - set the time the check started. Time can be reset to "null" if passed new * Timestamp(0). <|endfocus|> */ public abstract Builder setStarted(Timestamp started); /** * @param finished - set the time the check finished. Time can be reset to "null" if passed new * Timestamp(0). */ public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); } } 
<|startcomment|> This should be enclosed by curly braces: {@code new Timestamp(0)} <|endcomment|>  public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); /** <|startfocus|> * @param started Set the time the check started. Time can be reset to "null" if passed @code * new Timestamp(0) <|endfocus|> */ public abstract Builder setStarted(Timestamp started); /** * @param finished Set the time the check finished. Time can be reset to "null" if passed @code * new Timestamp(0) */ public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); } } 
<|startcomment|> Thanks for changing this, but I think it's nicer if the created account would be returned by the insert method. Something like: Account account = accounts.insert(Account.builder(id, TimeUtil.nowTs()).setFullName(name).setPreferredEmail(email)); Sorry if my previous comment about this was confusing. <|endcomment|>  String email = readEmail(sshKey); List<ExternalId> extIds = new ArrayList<>(2); extIds.add(ExternalId.createUsername(username, id, httpPassword)); if (email != null) { extIds.add(ExternalId.createEmail(id, email)); } externalIds.insert("Add external IDs for initial admin user", extIds); <|startfocus|> Account.Builder a = Account.builder(id, TimeUtil.nowTs()).setFullName(name).setPreferredEmail(email); accounts.insert(a); Account persistedAccount = a.build(); <|endfocus|> // Only two groups should exist at this point in time and hence iterating over all of them // is cheap. Optional<GroupReference> adminGroupReference = groupsOnInit .getAllGroupReferences() .filter(group -> group.getName().equals("Administrators")) .findAny(); if (!adminGroupReference.isPresent()) { throw new NoSuchGroupException("Administrators"); } GroupReference adminGroup = adminGroupReference.get(); groupsOnInit.addGroupMember(adminGroup.getUUID(), persistedAccount); if (sshKey != null) {
<|startcomment|> It should only do this when requireChangeId is true. <|endcomment|>  CommitMessageUtil.checkAndSanitizeCommitMessage(revCommit.getShortMessage()); List<String> changeIdFooters = revCommit.getFooterLines(FooterConstants.CHANGE_ID); if (!changeIdFooters.isEmpty() && !changeIdFooters.get(0).equals(currentChangeId)) { throw new ResourceConflictException("wrong Change-Id footer"); } if (revCommit.getFooterLines().isEmpty()) { // sanitization always adds '\n' at the end. newCommitMessage += "\n"; } <|startfocus|> if (changeIdFooters.isEmpty()) { <|endfocus|> newCommitMessage += FooterConstants.CHANGE_ID.getName() + ": " + currentChangeId + "\n"; } else if (changeIdFooters.size() > 1) { throw new ResourceConflictException("multiple Change-Id footers"); } return newCommitMessage; } } 
<|startcomment|> As the method parameter doesn't exist anymore, this part is unnecessary. Please remove it. <|endcomment|>  /** Java API to interact with single {@code Check}s. */ public interface CheckApi { /** Returns a {@link CheckInfo} for the scoped resource with the given options. */ CheckInfo get(ListChecksOption... options) throws RestApiException; /** Updates a check and returns the {@link CheckInfo} for the updated resource. */ CheckInfo update(CheckInput input) throws RestApiException; <|startfocus|> /** * Reruns the check and returns the {@link CheckInfo} for the updated check. Input ignores * "state". */ <|endfocus|> CheckInfo rerun() throws RestApiException; /** * A default implementation which allows source compatibility when adding new methods to the * interface. */ class NotImplemented implements CheckApi { @Override public CheckInfo get(ListChecksOption... options) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo update(CheckInput input) throws RestApiException { throw new NotImplementedException(); } @Override public CheckInfo rerun() throws RestApiException { throw new NotImplementedException();
<|startcomment|> The @Override annotation is missing and we typically try to use it where it applies. <|endcomment|>  private final Checks checks; private final Provider<ChecksUpdate> checksUpdate; private final CheckJson.Factory checkJsonFactory; @Inject RerunCheck( Provider<CurrentUser> self, PermissionBackend permissionBackend, AdministrateCheckersPermission permission, Checks checks, @UserInitiated Provider<ChecksUpdate> checksUpdate, CheckJson.Factory checkJsonFactory) { this.self = self; this.permissionBackend = permissionBackend; this.permission = permission; this.checks = checks; this.checksUpdate = checksUpdate; this.checkJsonFactory = checkJsonFactory; } <|startfocus|> <|endfocus|> public CheckInfo apply(CheckResource checkResource, Input input) throws RestApiException, IOException, StorageException, PermissionBackendException, ConfigInvalidException { if (!self.get().isIdentifiedUser()) { throw new AuthException("Authentication required"); } permissionBackend.currentUser().check(permission); if (checkResource.getRevisionResource().getEdit().isPresent()) { throw new ResourceConflictException("checks are not supported on a change edit"); } CheckKey key = CheckKey.create( checkResource.getRevisionResource().getProject(),
<|startcomment|> No test currently verifies that the timestamps are reset. Could you please add this? In addition, it would be good to check that 'created' is not touched and 'updated' is updated. <|endcomment|> import com.google.gerrit.extensions.restapi.AuthException; import com.google.gerrit.extensions.restapi.UnprocessableEntityException; import com.google.gerrit.plugins.checks.CheckKey; import com.google.gerrit.plugins.checks.CheckerUuid; import com.google.gerrit.plugins.checks.acceptance.AbstractCheckersTest; import com.google.gerrit.plugins.checks.api.CheckInfo; import com.google.gerrit.plugins.checks.api.CheckState; import com.google.gerrit.reviewdb.client.PatchSet; import com.google.inject.Inject; import org.junit.Before; import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { <|startfocus|> @Inject private RequestScopeOperations requestScopeOperations; <|endfocus|> private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); } @Test public void rerunNotStartedCheck() throws Exception { checkOperations.newCheck(checkKey).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun();
<|startcomment|> The test implicitly assumes that a check starts in the NOT_STARTED state. However, tests should not rely on default values (see TotT 511) except if they test exactly the default behavior of a system. Since the name of the test method indicates that we want to have the NOT_STARTED state, we should be explicit about it. <|endcomment|> import org.junit.Test; public class RerunCheckIT extends AbstractCheckersTest { @Inject private RequestScopeOperations requestScopeOperations; private PatchSet.Id patchSetId; private CheckKey checkKey; @Before public void setUp() throws Exception { patchSetId = createChange().getPatchSetId(); CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); } @Test public void rerunNotStartedCheck() throws Exception { <|startfocus|> checkOperations.newCheck(checkKey).upsert(); <|endfocus|> CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunFinishedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.SUCCESSFUL).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunNotExistingCheckThrowsError() throws Exception { assertThrows(
<|startcomment|> It's good that we have this test case now as it shows that the system behaves in a way which is actually not desired. Even though the check does not exist in our storage (because nobody/nothing sent data for it yet), it virtually already exists as it's backfilled. (I think I mentioned this before. If you need more details about this 'virtual' state and backfilling, please tell me.) So, we actually need to distinguish two cases: 1) The check does not exit in the storage but is backfilled. -> No error should be thrown. For the calling user, this should return exactly the same results as if the check existed in the storage. Internally, we don't create an entry in the storage. 2) The check does not exist in the storage and is also not backfilled. -> An error should be thrown. (In fact, the user would already get an error earlier when accessing the check resource in the URL path but there's a small corner case in which they could run into this.) <|endcomment|>  CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunFinishedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.SUCCESSFUL).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test <|startfocus|> public void rerunNotExistingCheckThrowsError() throws Exception { <|endfocus|> assertThrows( UnprocessableEntityException.class, () -> checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun()); } @Test public void cannotUpdateCheckWithoutAdministrateCheckers() throws Exception { requestScopeOperations.setApiUser(user.id()); checkOperations.newCheck(checkKey).state(CheckState.SUCCESSFUL).upsert(); AuthException thrown = assertThrows( AuthException.class, () -> checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun()); assertThat(thrown).hasMessageThat().contains("not permitted"); } @Test
<|startcomment|> This should also be 'checkerDescription'. <|endcomment|>  .add("repository", repository) .add("changeNumber", changeNumber) .add("patchSetId", patchSetId) .add("checkerUuid", checkerUuid) .add("state", state) .add("message", message) .add("url", url) .add("started", started) .add("finished", finished) .add("created", created) .add("updated", updated) .add("checkerName", checkerName) .add("checkerStatus", checkerStatus) .add("blocking", blocking) <|startfocus|> .add("description", checkerDescription) <|endfocus|> .toString();
<|startcomment|> I think it would be better to offer a dedicated method (with a descriptive name) for this within this builder. Thus, the code using the method is more readable and understandable. In addition, it would also be good to adjust the test API (-> CheckOperations) to have this convenience method as well. <|endcomment|>  public abstract Optional<Timestamp> finished(); public abstract Builder toBuilder(); public static Builder builder() { return new AutoValue_CheckUpdate.Builder(); } @AutoValue.Builder public abstract static class Builder { public abstract Builder setState(CheckState state); public abstract Builder setMessage(String message); public abstract Builder setUrl(String url); <|startfocus|> /** * @param started Set the time the check started. Time can be reset to "null" if passed {@code * new Timestamp(0)} */ <|endfocus|> public abstract Builder setStarted(Timestamp started); /** * @param finished Set the time the check finished. Time can be reset to "null" if passed {@code * new Timestamp(0)} */ public abstract Builder setFinished(Timestamp finished); public abstract CheckUpdate build(); } } 
<|startcomment|> should you have a test that creates 15 updates, so we have coverage for the code path where you can't find the thing? <|endcomment|>  assertThat(loader.load(head)).isEqualTo(allFromGit(head)); verify(externalIdReaderSpy, times(1)).all(head); } @Test public void fallsBackToFullReloadOnManyUpdatesOnBranch() throws Exception { insertExternalId(1, 1); ObjectId head = null; for (int i = 2; i < 20; i++) { head = insertExternalId(i, i); } assertThat(loader.load(head)).isEqualTo(allFromGit(head)); verify(externalIdReaderSpy, times(1)).all(head); } <|startfocus|> @Test <|endfocus|> public void handlesDeletionInPartialReload() throws Exception { ObjectId firstState = insertExternalId(1, 1); ObjectId head = deleteExternalId(1, 1); assertThat(allFromGit(head).byAccount().size()).isEqualTo(0); when(externalIdCache.getIfPresent(firstState)).thenReturn(allFromGit(firstState)); assertThat(loader.load(head)).isEqualTo(allFromGit(head)); verifyZeroInteractions(externalIdReaderSpy); } @Test public void handlesModifyInPartialReload() throws Exception { ObjectId firstState = insertExternalId(1, 1);
<|startcomment|> nit: We usually import this static. <|endcomment|>  public void emptyStringIsDeserializedToMagicTimestamp() { Timestamp timestamp = deserializer.deserialize(new JsonPrimitive(""), Timestamp.class, null); <|startfocus|> Truth.assertThat(timestamp).isEqualTo(TimeUtil.never()); <|endfocus|>
<|startcomment|> I think this should be calls to commitId() instead. <|endcomment|>  .add(allow(Permission.PUSH).ref(other).group(adminGroupUuid())) .update(); RevCommit masterRev = projectOperations.project(project).getHead("master"); pushCommitTo(masterRev, other); PushOneCommit.Result r = createChange(); r.assertOkStatus(); RevCommit commit = r.getCommit(); pushCommitTo(commit, master); assertCommit(project, master); ChangeData cd = <|startfocus|> Iterables.getOnlyElement(queryProvider.get().byKey(Change.key(r.getChangeId()))); assertThat(cd.change().isMerged()).isTrue(); <|endfocus|> RemoteRefUpdate.Status status = pushCommitTo(commit, "refs/for/other"); assertThat(status).isEqualTo(RemoteRefUpdate.Status.OK); pushCommitTo(commit, other); assertCommit(project, other); for (ChangeData c : queryProvider.get().byKey(Change.key(r.getChangeId()))) { if (c.change().getDest().branch().equals(other)) { assertThat(c.change().isMerged()).isTrue(); } } } private RemoteRefUpdate.Status pushCommitTo(RevCommit commit, String ref)
<|startcomment|> duplicated line? <|endcomment|>  // from the cache. Extend the cache size by 1 to cover this case, but expire the extra // object after a short period of time, since it may be a potentially large amount of // memory. // When loading a new value because the primary data advanced, we want to leverage the old // cache state to recompute only what changed. This doesn't affect cache size though as // Guava calls the loader first and evicts later on. <|startfocus|> // memory. <|endfocus|> .maximumWeight(2) .expireFromMemoryAfterAccess(Duration.ofMinutes(5)) .loader(ExternalIdCacheLoader.class) .diskLimit(-1) .version(1) .keySerializer(ObjectIdCacheSerializer.INSTANCE) .valueSerializer(AllExternalIds.Serializer.INSTANCE); bind(ExternalIdCacheImpl.class); bind(ExternalIdCache.class).to(ExternalIdCacheImpl.class);
<|startcomment|> Re-use the existing ctor? this(add); <|endcomment|>  public HashtagsInput(Set<String> add, Set<String> remove) { <|startfocus|> this.add = add; <|endfocus|> this.remove = remove;
<|startcomment|> This is also not what I meant when I asked to verify that "'created' is not touched and 'updated' is updated". Both can be checked by remembering the initial value for them and verifying the new value against them after the rerun call. <|endcomment|>  CheckerUuid checkerUuid = checkerOperations.newChecker().repository(project).create(); checkKey = CheckKey.create(project, patchSetId, checkerUuid); } @After public void resetTime() { TestTimeUtil.useSystemTime(); } @Test public void rerunNotStartedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.NOT_STARTED).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); <|startfocus|> assertSuccessfulRerun(info); assertThat(info.updated).isGreaterThan(info.created); <|endfocus|> } @Test public void rerunFinishedCheck() throws Exception { checkOperations.newCheck(checkKey).state(CheckState.SUCCESSFUL).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertSuccessfulRerun(info); assertThat(info.updated).isGreaterThan(info.created); } @Test public void rerunCheckNotExistingButBackfilled() throws Exception { CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertSuccessfulRerun(info); } @Test
<|startcomment|> could use a short javadoc. Or better, can we use DelegatingAppendable (via SoySauceTemplate#render(Appendable, String, ContentKind, Map<String, ?>)) instead? A Writer is already an Appendable. <|endcomment|>  private final String variant; private CommitSoyData csd; public LogSoyData(HttpServletRequest req, GitilesAccess access, String pretty) throws IOException { this.req = checkNotNull(req); this.view = checkNotNull(ViewFilter.getView(req)); checkNotNull(pretty); Config config = access.getConfig(); fields = config.getBoolean("logFormat", pretty, "verbose", false) ? VERBOSE_FIELDS : FIELDS; variant = firstNonNull(config.getString("logFormat", pretty, "variant"), pretty); } <|startfocus|> <|endfocus|> private static class LogSoyDataAppendable implements AdvisingAppendable { private final Writer writer; LogSoyDataAppendable(Writer writer) { this.writer = writer; } @Override public AdvisingAppendable append(CharSequence csq) throws IOException { writer.append(csq); return this; } @Override public AdvisingAppendable append(CharSequence csq, int start, int end) throws IOException { writer.append(csq, start, end); return this; } @Override public AdvisingAppendable append(char c) throws IOException { writer.append(c); return this; } @Override
<|startcomment|> logEntriesHeader is indeed always HTML. Good. <|endcomment|>  // don't do something with the result, so just wrap it in a dummy method. } public void renderStreaming( Paginator paginator, @Nullable String revision, Renderer renderer, Writer writer, DateFormatter df, FooterBehavior footerBehavior) throws IOException { LogSoyDataAppendable out = new LogSoyDataAppendable(writer); swallowResult( renderer .newRenderer("gitiles.logEntriesHeader") <|startfocus|> .setData(toHeaderSoyData(paginator, revision)) .renderHtml(out)); <|endfocus|> SoySauce.Renderer entryRenderer = renderer.newRenderer("gitiles.logEntryWrapper"); boolean renderedEntries = false; for (RevCommit c : paginator) { swallowResult(entryRenderer.setData(toEntrySoyData(paginator, c, df)).renderHtml(out)); out.flush(); renderedEntries = true; } if (!renderedEntries) { swallowResult(renderer.newRenderer("gitiles.emptyLog").renderHtml(out)); } swallowResult( renderer .newRenderer("gitiles.logEntriesFooter") .setData(toFooterSoyData(paginator, revision, footerBehavior)) .renderHtml(out)); } 
<|startcomment|> Do all callers want HTML, or do some want text? E.g. renaming to renderHtml would make it easier to audit the callers. <|endcomment|>  checkState(u != null, "Missing Soy template %s", soyFile); Hasher h = Hashing.murmur3_128().newHasher(); try (InputStream is = u.openStream(); OutputStream os = Funnels.asOutputStream(h)) { ByteStreams.copy(is, os); } catch (IOException e) { throw new IllegalStateException("Missing Soy template " + soyFile, e); } return h.hash(); } <|startfocus|> public String render(String templateName, Map<String, ?> soyData) { <|endfocus|> return newRenderer(templateName).setData(soyData).renderHtml().get().toString(); } void render( HttpServletRequest req, HttpServletResponse res, String templateName, Map<String, ?> soyData) throws IOException { res.setContentType("text/html"); res.setCharacterEncoding("UTF-8"); byte[] data = newRenderer(templateName).setData(soyData).renderHtml().get().toString().getBytes(UTF_8); if (BaseServlet.acceptsGzipEncoding(req)) { res.addHeader(HttpHeaders.VARY, HttpHeaders.ACCEPT_ENCODING);
<|startcomment|> stray parens <|endcomment|>  o.write(tail); } } }; } SoySauce.Renderer newRenderer(String templateName) { ImmutableMap.Builder<String, Object> staticUrls = ImmutableMap.builder(); for (String key : STATIC_URL_GLOBALS.keySet()) { staticUrls.put( key.replaceFirst("^gitiles\\.", ""), LegacyConversions.riskilyAssumeTrustedResourceUrl(globals.get(key))); } return getSauce() .renderTemplate(templateName) <|startfocus|> .setIj((ImmutableMap.of("staticUrls", staticUrls.build()))); <|endfocus|> } protected abstract SoySauce getSauce(); } 
<|startcomment|> Maybe rephrase this a bit, we didn't fail in the sense that there was an error, the value was just not available in the cache (which is not a failure). <|endcomment|>  config.getBoolean("cache", ExternalIdCacheImpl.CACHE_NAME, "enablePartialReloads", false); } @Override public AllExternalIds load(ObjectId notesRev) throws IOException, ConfigInvalidException { if (!enablePartialReloads) { logger.atInfo().log( "Partial reloads of " + ExternalIdCacheImpl.CACHE_NAME + " disabled. Falling back to full reload."); return reloadAllExternalIds(notesRev); } <|startfocus|> // We failed to load the requested value from the cache (hence, this loader was invoked). // Therefore, try to create this entry from a past value using the minimal amount of Git // operations possible to reduce latency. <|endfocus|> // // First, try to find the most recent state we have in the persistent cache. Most of the time, // this will be the state before the last update happened, but it can also date further back. We // try a best effort approach and check the last 10 states. If nothing is found, we default to // loading the value from scratch. //
<|startcomment|> nit: one space too much <|endcomment|>  config.getBoolean("cache", ExternalIdCacheImpl.CACHE_NAME, "enablePartialReloads", false); } @Override public AllExternalIds load(ObjectId notesRev) throws IOException, ConfigInvalidException { if (!enablePartialReloads) { logger.atInfo().log( "Partial reloads of " + ExternalIdCacheImpl.CACHE_NAME + " disabled. Falling back to full reload."); return reloadAllExternalIds(notesRev); } <|startfocus|> // We failed to load the requested value from the cache (hence, this loader was invoked). // Therefore, try to create this entry from a past value using the minimal amount of Git // operations possible to reduce latency. <|endfocus|> // // First, try to find the most recent state we have in the persistent cache. Most of the time, // this will be the state before the last update happened, but it can also date further back. We // try a best effort approach and check the last 10 states. If nothing is found, we default to // loading the value from scratch. //
<|startcomment|> looks like it can be static? <|endcomment|>  * were performed since then. * * <p>Removals are applied before additions. * * @param repo open repository * @param oldExternalIds prior state that is used as base * @param additions map of name to blob ID for each external ID that should be added * @param removals set of name {@link ObjectId}s that should be removed */ <|startfocus|> private AllExternalIds buildAllExternalIds( <|endfocus|> Repository repo, AllExternalIds oldExternalIds, Map<ObjectId, ObjectId> additions, Set<ObjectId> removals) throws IOException { ImmutableSetMultimap.Builder<Account.Id, ExternalId> byAccount = ImmutableSetMultimap.builder(); ImmutableSetMultimap.Builder<String, ExternalId> byEmail = ImmutableSetMultimap.builder(); // Copy over old ExternalIds but exclude deleted ones for (ExternalId externalId : oldExternalIds.byAccount().values()) { if (removals.contains(externalId.blobId())) { continue; } byAccount.put(externalId.accountId(), externalId); if (externalId.email() != null) {
<|startcomment|> AllUsersNameProvider.DEFAULT <|endcomment|> import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.ObjectId; import org.eclipse.jgit.lib.PersonIdent; import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevWalk; import org.eclipse.jgit.treewalk.TreeWalk; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.mockito.Mock; import org.mockito.Mockito; import org.mockito.junit.MockitoJUnitRunner; @RunWith(MockitoJUnitRunner.class) public class ExternalIDCacheLoaderTest { <|startfocus|> private static AllUsersName ALL_USERS = new AllUsersName("All-Users"); <|endfocus|> @Mock Cache<ObjectId, AllExternalIds> externalIdCache; private ExternalIdCacheLoader loader; private GitRepositoryManager repoManager = new InMemoryRepositoryManager(); private ExternalIdReader externalIdReader; private ExternalIdReader externalIdReaderSpy; @Before public void setUp() throws Exception { repoManager.createRepository(ALL_USERS).close(); externalIdReader = new ExternalIdReader(repoManager, ALL_USERS, new DisabledMetricMaker()); externalIdReaderSpy = Mockito.spy(externalIdReader); loader = createLoader(true); } @Test public void worksOnSingleCommit() throws Exception {
<|startcomment|> Can this exception message include the name of the enum, and the invalid value that was given? I.e. something like: Invalid value 'THREE' for enum TestEnum <|endcomment|>  private final TypeAdapter<T> defaultEnumAdapter; public EnumTypeAdapter(TypeAdapter<T> defaultEnumAdapter) { this.defaultEnumAdapter = defaultEnumAdapter; } @Override public T read(JsonReader in) throws IOException { // Still handle null values. -> Check them first. if (in.peek() == JsonToken.NULL) { in.nextNull(); return null; } T enumValue = defaultEnumAdapter.read(in); if (enumValue == null) { <|startfocus|> throw new JsonSyntaxException("Expected an existing enum value."); <|endfocus|> } return enumValue; } @Override public void write(JsonWriter out, T value) throws IOException { defaultEnumAdapter.write(out, value); } } } 
<|startcomment|> What happens to our existing traffic if this starts triggering? Is this 500? I'm worried that might trigger a fire drill and rollback. Could we start with logging and make sure there aren't too many misbehaving customers? <|endcomment|> <|startfocus|> public void emptyEnumValueIsRejectedOnParse() { assertThrows( JsonSyntaxException.class, () -> gson.fromJson("{\"value\":\"\"}", TestData.class)); <|endfocus|>
<|startcomment|> Infinite loop? We would potentially cause Gerrit builds to wait for ever. <|endcomment|>  } private PushOne createPushOne(DynamicItem<ReplicationPushFilter> replicationPushFilter) { PushOne push = new PushOne( gitRepositoryManagerMock, permissionBackendMock, destinationMock, remoteConfigMock, credentialsFactory, threadRequestScoperMock, replicationQueueMock, idGeneratorMock, replicationStateListenersMock, replicationMetricsMock, projectCacheMock, transportFactoryMock, projectNameKey, urish); push.setReplicationPushFilter(replicationPushFilter); return push; } private void waitUntilFinished() throws InterruptedException { while (!isCallFinished.get()) { <|startfocus|> Thread.sleep(100); <|endfocus|> } } private void setupProjectCacheMock() throws IOException { projectCacheMock = createNiceMock(ProjectCache.class); expect(projectCacheMock.checkedGet(projectNameKey)).andReturn(projectStateMock); } private void setupTransportMock() throws NotSupportedException, TransportException { transportMock = createNiceMock(Transport.class); expect(transportMock.openFetch()).andReturn(fetchConnection); transportFactoryMock = createNiceMock(TransportFactory.class); expect(transportFactoryMock.open(repositoryMock, urish)).andReturn(transportMock).anyTimes(); } private void setupReplicationMetricsMock() {
<|startcomment|> The text above mentions that typically 204 is returned, which would be Response.None. That implementation doesn't support caching. <|endcomment|>  * Found} for a redirect). * * <p>The returned response usually does not have any value (status code {code 204 No Content}). * If a value in the returned response is set it is automatically converted to JSON unless it is a * {@link BinaryResult}. * <|startfocus|> * <p>Further properties like caching behavior (see {@link CacheControl}) can be optionally set on * the returned response. * <|endfocus|> * <p>Throwing a subclass of {@link RestApiException} results in a 4XX response to the client. For * any other exception the client will get a {@code 500 Internal Server Error} response. * * @param parentResource parent resource of the resource that should be deleted * @param id the ID of the child resource that should be deleted * @param input input after parsing from request * @return response to return to the client * @throws RestApiException if the resource creation is rejected
<|startcomment|> Maybe add: "if the response type allows this" as quite a few implementations (like None and Redirect) throw an UnsupportedOperationException? This section also seems a bit problematic in the other Javadoc descriptions. Alternatively, we could leave it out. <|endcomment|>  * RestCollectionModifyViews this is usually {code 200 OK}, but other 2XX or 3XX status codes are * also possible (e.g. {code 201 Created} if a resource was created, {code 202 Accepted} if a * background task was scheduled, {@code 204 No Content} if no content is returned, {@code 302 * Found} for a redirect). * <|startfocus|> * <p>Further properties like caching behavior (see {@link CacheControl}) can be optionally set on * the returned response. * <|endfocus|> * <p>Throwing a subclass of {@link RestApiException} results in a 4XX response to the client. For * any other exception the client will get a {@code 500 Internal Server Error} response. * * @param parentResource the collection resource on which the modification is done * @return response to return to the client * @throws Exception the implementation of the view failed. The exception will be logged and HTTP * 500 Internal Server Error will be returned to the client.
<|startcomment|> Can we directly forward the response object? <|endcomment|>  throws RestApiException, IOException, ConfigInvalidException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { permissionBackend.currentUser().check(GlobalPermission.ADMINISTRATE_SERVER); } Map<ProjectWatchKey, Set<NotifyType>> projectWatches = asMap(input); accountsUpdateProvider .get() .update( "Update Project Watches via API", rsrc.getUser().getAccountId(), u -> u.updateProjectWatches(projectWatches)); <|startfocus|> return Response.ok(getWatchedProjects.apply(rsrc).value()); <|endfocus|> } private Map<ProjectWatchKey, Set<NotifyType>> asMap(List<ProjectWatchInfo> input) throws RestApiException, IOException, PermissionBackendException { Map<ProjectWatchKey, Set<NotifyType>> m = new HashMap<>(); for (ProjectWatchInfo info : input) { if (info.project == null) { throw new BadRequestException("project name must be specified"); } ProjectWatchKey key = ProjectWatchKey.create(projectsCollection.parse(info.project).getNameKey(), info.filter); if (m.containsKey(key)) { throw new BadRequestException(
<|startcomment|> As mentioned somewhere else, I would directly use the returned Response object instead of creating a new one. In this specific case, it doesn't seem to work, though, as we would need to do a cast which the compiler objects to. Honestly, considering the implementation of QueryChanges#apply, I'm not even sure why we are allowed to do the cast here. The value could also be a List<List<ChangeInfo>>. <|endcomment|>  this.self = self; this.changes = changes; } @Override @SuppressWarnings("unchecked") public Response<List<ChangeInfo>> apply(AccountResource rsrc) throws BadRequestException, AuthException, PermissionBackendException { if (!self.get().hasSameAccountId(rsrc.getUser())) { throw new AuthException("not allowed to list stars of another account"); } QueryChanges query = changes.list(); query.addQuery("has:stars"); <|startfocus|> return Response.ok((List<ChangeInfo>) query.apply(TopLevelResource.INSTANCE).value()); <|endfocus|> } } @Singleton public static class Get implements RestReadView<AccountResource.Star> { private final Provider<CurrentUser> self; private final StarredChangesUtil starredChangesUtil; @Inject Get(Provider<CurrentUser> self, StarredChangesUtil starredChangesUtil) { this.self = self; this.starredChangesUtil = starredChangesUtil; } @Override public Response<SortedSet<String>> apply(AccountResource.Star rsrc) throws AuthException { if (!self.get().hasSameAccountId(rsrc.getUser())) {
<|startcomment|> Could be the wildcard '?'. <|endcomment|> <|startfocus|> public Response<Object> apply(ProjectResource rsrc, Input input) { <|endfocus|> Project.NameKey project = rsrc.getNameKey(); if (input.async) { return applyAsync(project, input); } return Response.ok(applySync(project, input));
<|startcomment|> In theory, we could re-use the above response object. <|endcomment|>  : String.format("Changed default dashboard to %s.\n", input.id)); if (!msg.endsWith("\n")) { msg += "\n"; } md.setAuthor(rsrc.getUser().asIdentifiedUser()); md.setMessage(msg); config.commit(md); cache.evict(rsrc.getProjectState().getProject()); if (target != null) { <|startfocus|> DashboardInfo info = get.get().apply(target).value(); info.isDefault = true; return Response.ok(info); <|endfocus|> } return Response.none(); } catch (RepositoryNotFoundException notFound) { throw new ResourceNotFoundException(rsrc.getProjectState().getProject().getName()); } catch (ConfigInvalidException e) { throw new ResourceConflictException( String.format("invalid project.config: %s", e.getMessage())); } } } 
<|startcomment|> Here and in other changes: Could be Response<?>. <|endcomment|>  private final Configuration cfg; private final HideProject hideProject; @Inject DeleteProject( FilesystemDeleteHandler fsHandler, CacheDeleteHandler cacheHandler, Provider<CurrentUser> userProvider, DeleteLog deleteLog, DeletePreconditions preConditions, Configuration cfg, HideProject hideProject) { this.fsHandler = fsHandler; this.cacheHandler = cacheHandler; this.userProvider = userProvider; this.deleteLog = deleteLog; this.preConditions = preConditions; this.cfg = cfg; this.hideProject = hideProject; } @Override <|startfocus|> public Object apply(ProjectResource rsrc, Input input) throws OrmException, IOException, RestApiException { <|endfocus|> preConditions.assertDeletePermission(rsrc); preConditions.assertCanBeDeleted(rsrc, input); doDelete(rsrc, input); return Response.none(); } public void doDelete(ProjectResource rsrc, Input input) throws IOException, RestApiException { Project project = rsrc.getProjectState().getProject(); boolean preserve = input != null && input.preserve; Exception ex = null; try { if (!preserve || !cfg.projectOnPreserveHidden()) { try {
<|startcomment|> This is no longer used and can be removed. <|endcomment|>  private void savePluginSections(Config rc, Set<AccountGroup.UUID> keepGroups) { unsetSection(rc, PLUGIN); <|startfocus|> List<String> existing = new ArrayList<>(rc.getSubsections(PLUGIN)); <|endfocus|> for (Map.Entry<String, Config> e : pluginConfigs.entrySet()) { String plugin = e.getKey(); Config pluginConfig = e.getValue(); for (String name : pluginConfig.getNames(PLUGIN, plugin)) { String value = pluginConfig.getString(PLUGIN, plugin, name); String groupName = GroupReference.extractGroupName(value); if (groupName != null) { GroupReference ref = groupsByName.get(groupName); if (ref != null && ref.getUUID() != null) { keepGroups.add(ref.getUUID()); pluginConfig.setString(PLUGIN, plugin, name, "group " + ref.getName()); } } rc.setStringList( PLUGIN, plugin, name, Arrays.asList(pluginConfig.getStringList(PLUGIN, plugin, name))); } }
<|startcomment|> This is not needed. <|endcomment|>  this.accountInfoFactory = infoFactory; this.projectCache = projectCache; this.prologRule = prologRule; } @Override public Response<List<TestSubmitRuleInfo>> apply(RevisionResource rsrc, TestSubmitRuleInput input) throws AuthException, PermissionBackendException, BadRequestException { if (input == null) { input = new TestSubmitRuleInput(); } if (input.rule == null) { throw new BadRequestException("rule is required"); } <|startfocus|> if (input.rule == null) { throw new BadRequestException("rule is required"); } <|endfocus|> if (!rules.isProjectRulesEnabled()) { throw new AuthException("project rules are disabled"); } input.filters = MoreObjects.firstNonNull(input.filters, filters); SubmitRuleOptions opts = SubmitRuleOptions.builder() .skipFilters(input.filters == Filters.SKIP) .rule(input.rule) .logErrors(false) .build(); ProjectState projectState = projectCache.get(rsrc.getProject()); if (projectState == null) { throw new BadRequestException("project not found"); }
<|startcomment|> JavaDoc missing. This is a public module that is intended to be used in the Gerrit.config in libModules. It should be documented here. <|endcomment|> // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import com.google.gerrit.extensions.registration.DynamicItem; import com.google.inject.AbstractModule; <|startfocus|> <|endfocus|> public class ReplicationExtensionPointModule extends AbstractModule { @Override protected void configure() { DynamicItem.itemOf(binder(), ReplicationPushFilter.class); } } 
<|startcomment|> This test is identical to the one at L185: just define a single test with a parameter. <|endcomment|>  throw new RuntimeException(e); } }) .collect(Collectors.toList()); PushResult pushResult = new PushResult(); expect(transportMock.push(anyObject(), compareRemoteRef(expectedUpdates))) .andReturn(pushResult) .once(); replay(transportMock); PushOne pushOne = createPushOne(replicationPushFilter); pushOne.addRef(PushOne.ALL_REFS); pushOne.run(); isCallFinished.await(10, TimeUnit.SECONDS); verify(transportMock); } @Test <|startfocus|> public void shouldPushAllRefsWhenNoFiltersSetup() throws InterruptedException, IOException { <|endfocus|> List<RemoteRefUpdate> expectedUpdates = localRefs.values().stream() .map( ref -> { try { return new RemoteRefUpdate( repositoryMock, ref.getName(), ref.getObjectId(), "fooProject", false, "fooProject", null); } catch (IOException e) { throw new RuntimeException(e); } }) .collect(Collectors.toList()); PushResult pushResult = new PushResult(); expect(transportMock.push(anyObject(), compareRemoteRef(expectedUpdates)))
<|startcomment|> This is really testing that replication doesn't happen at all: it should be more explicit in his name. <|endcomment|>  throw new RuntimeException(e); } }) .collect(Collectors.toList()); PushResult pushResult = new PushResult(); expect(transportMock.push(anyObject(), compareRemoteRef(expectedUpdates))) .andReturn(pushResult) .once(); replay(transportMock); PushOne pushOne = createPushOne(null); pushOne.addRef(PushOne.ALL_REFS); pushOne.run(); isCallFinished.await(10, TimeUnit.SECONDS); verify(transportMock); } @Test <|startfocus|> public void shouldApplyReplicationPushFilter() throws InterruptedException, IOException { <|endfocus|> DynamicItem<ReplicationPushFilter> replicationPushFilter = DynamicItem.itemOf( ReplicationPushFilter.class, new ReplicationPushFilter() { @Override public List<RemoteRefUpdate> filter( String projectName, List<RemoteRefUpdate> remoteUpdatesList) { remoteUpdatesList.remove(0); return remoteUpdatesList; } }); // easymock way to check if method was never called expect(transportMock.push(anyObject(), anyObject())) .andThrow(new AssertionFailedError()) .anyTimes(); replay(transportMock); PushOne pushOne = createPushOne(replicationPushFilter); 
<|startcomment|> remoteUpdatesList contains a single element: just return the empty list. <|endcomment|>  public List<RemoteRefUpdate> filter( String projectName, List<RemoteRefUpdate> remoteUpdatesList) { <|startfocus|> remoteUpdatesList.remove(0); return remoteUpdatesList; <|endfocus|>
<|startcomment|> This is common to the apply() method and can be factored out. <|endcomment|>  throw new AuthException("Authentication required"); } return commentJson .get() .setFillAccounts(includeAuthorInfo()) .setFillPatchSet(true) .newCommentFormatter() .format(listComments(rsrc)); } public List<CommentInfo> getComments(ChangeResource rsrc) throws AuthException, OrmException { if (requireAuthentication() && !rsrc.getUser().isIdentifiedUser()) { throw new AuthException("Authentication required"); } return commentJson .get() .setFillAccounts(includeAuthorInfo()) .setFillPatchSet(true) <|startfocus|> .newCommentFormatter() .formatAsList(listComments(rsrc)); <|endfocus|> } } 
<|startcomment|> config <|endcomment|>  static final String MAX_CACHE_AGE = "maxCacheAge"; // seconds to stay in cache static final String MAX_CACHE_SIZE = "maxCacheSize"; // number of OwnersDb in cache static final String MIN_OWNER_VOTE_LEVEL = "minOwnerVoteLevel"; // default +1 static final String REPORT_SYNTAX_ERROR = "reportSyntaxError"; // only for tests // "alwaysShowButton" is obsolete, new UI design always shows the [Find Owners] button <|startfocus|> // Name of config parameters that can be defined in project.config or gerrit.confg: <|endfocus|> static final String OWNERS_FILE_NAME = "ownersFileName"; // config key for file name static final String REJECT_ERROR_IN_OWNERS = "rejectErrorInOwners"; // enable upload validator static final String OWNERS = "OWNERS"; // default OWNERS file name // Name of plugin and namespace. static final String PLUGIN_NAME = "find-owners"; static final String PROLOG_NAMESPACE = "find_owners"; private final PluginConfigFactory configFactory; // Each call to API entry point creates one new Config and parses gerrit.config.
<|startcomment|> empty <|endcomment|>  String getOwnersFileName(Project project) { String defaultName = getDefaultOwnersFileName(); try { String name = getProjectConfig(project).getString(OWNERS_FILE_NAME, defaultName); if (name.trim().isEmpty()) { <|startfocus|> logger.atSevere().log("Project %s has emptry %s", project, OWNERS_FILE_NAME); <|endfocus|> return defaultName; } return name; } catch (NoSuchProjectException e) { logger.atSevere().withCause(e).log( "Exception in getOwnersFileName for %s", project.getName()); return defaultName; }
<|startcomment|> nit: missing period at the end of the sentence. <|endcomment|>  * * <p>In addition accounts are included that have the given email as preferred email even if they * have no external ID for the preferred email. Having accounts with a preferred email that does * not exist as external ID is an inconsistency, but existing functionality relies on still * getting those accounts, which is why they are included. Accounts by preferred email are fetched * from the account index as a fallback for email addresses that could not be resolved using <|startfocus|> * {@link ExternalIds} <|endfocus|> * * @see #getAccountsFor(String...) */ public ImmutableSet<Account.Id> getAccountFor(String email) throws IOException { ImmutableSet<Account.Id> accounts = externalIds.byEmail(email).stream().map(ExternalId::accountId).collect(toImmutableSet()); if (!accounts.isEmpty()) { return accounts; } return executeIndexQuery(() -> queryProvider.get().byPreferredEmail(email).stream()) .map(a -> a.getAccount().id()) .collect(toImmutableSet()); } /**
<|startcomment|> nit: do not import Account.Id <|endcomment|> // limitations under the License. package com.google.gerrit.server.account; import static com.google.common.collect.ImmutableList.toImmutableList; import static com.google.common.collect.ImmutableSet.toImmutableSet; import com.google.common.base.Throwables; import com.google.common.collect.ImmutableSet; import com.google.common.collect.ImmutableSetMultimap; import com.google.common.collect.MultimapBuilder; import com.google.common.collect.SetMultimap; import com.google.gerrit.exceptions.StorageException; import com.google.gerrit.reviewdb.client.Account; <|startfocus|> import com.google.gerrit.reviewdb.client.Account.Id; <|endfocus|> import com.google.gerrit.server.account.externalids.ExternalId; import com.google.gerrit.server.account.externalids.ExternalIds; import com.google.gerrit.server.query.account.InternalAccountQuery; import com.google.gerrit.server.update.RetryHelper; import com.google.gerrit.server.update.RetryHelper.Action; import com.google.gerrit.server.update.RetryHelper.ActionType; import com.google.inject.Inject; import com.google.inject.Provider; import com.google.inject.Singleton; import java.io.IOException; import java.util.Arrays; import java.util.List; /** Class to access accounts by email. */ @Singleton public class Emails { private final ExternalIds externalIds;
<|startcomment|> Updating a blob means still updating a ref, isn't it? <|endcomment|> // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite; import com.google.gerrit.extensions.common.GitPerson; public class SharedRefLogEntry { public enum Type { <|startfocus|> UPDATE_BLOB, <|endfocus|> UPDATE_REF, DELETE_REF, DELETE_PROJECT } public String projectName; public Type type; public static class UpdateRef extends SharedRefLogEntry { public String refName; public String oldId; public String newId; public GitPerson committer; public String comment; UpdateRef( String projectName, String refName, String oldId, String newId, GitPerson committer, String comment) { this.type = Type.UPDATE_REF; this.projectName = projectName; this.refName = refName;
<|startcomment|> Not sure this is correct: when the DynamicItem gets re-bound the wrapper will still use a stable shared-refdb. <|endcomment|>  public SharedRefDatabaseWrapper( <|startfocus|> DynamicItem<SharedRefDatabase> sharedRefDatabase, SharedRefLogger sharedRefLogger) { this.sharedRefDb = sharedRefDatabase.get(); <|endfocus|> this.sharedRefLogger = sharedRefLogger;
<|startcomment|> Small hint here, in 10829 I was struggling with similar situation. sharedRefDatabase.get was called before DynamicItem was replaced from NoOp to proper implementation so I was always using NoOP, solution is to not use get() in constructor but in runtime <|endcomment|>  public SharedRefDatabaseWrapper( <|startfocus|> DynamicItem<SharedRefDatabase> sharedRefDatabase, SharedRefLogger sharedRefLogger) { this.sharedRefDb = sharedRefDatabase.get(); <|endfocus|> this.sharedRefLogger = sharedRefLogger;
<|startcomment|> does this have the right toString() method? should use %s , no? <|endcomment|>  logger.atFiner().log("Create new OwnersDb, key=%s", key); return new OwnersDb( permissionBackend, projectState, accountCache, emails, key, repoManager, config, changeData, branch, files); } try { logger.atFiner().log( "Get from cache %s, key=%s, cache size=%d", dbCache, key, dbCache.size()); <|startfocus|> logger.atFine().log("FindOwnersCacheStats: " + dbCache.stats()); <|endfocus|> return dbCache.get( key, new Callable<OwnersDb>() { @Override public OwnersDb call() { logger.atFiner().log("Create new OwnersDb, key=%s", key); return new OwnersDb( permissionBackend, projectState, accountCache, emails, key, repoManager, config, changeData, branch, files); } }); } catch (ExecutionException e) { logger.atSevere().withCause(e).log(
<|startcomment|> ContributorAgreement is set <|endcomment|>  .create(); update(rev); ProjectConfig cfg = read(rev); cfg.getAccountsSection().setSameGroupVisibility(ImmutableList.of()); rev = commit(cfg); assertThat(text(rev, "project.config")) .isEqualTo( "[commentlink \"bugzilla\"]\n\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n"); } @Test <|startfocus|> public void contributorSectionIsUnsetIfNoPermissionsAreSet() throws Exception { <|endfocus|> RevCommit rev = tr.commit() .add( "project.config", "[commentlink \"bugzilla\"]\n" + "\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n" + "\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n" + "[contributor-agreement \"Individual\"]\n" + " accepted = group Developers\n" + " accepted = group Staff\n") .create(); update(rev); ProjectConfig cfg = read(rev); ContributorAgreement section = cfg.getContributorAgreement("Individual");
<|startcomment|> NotificationsAreSet <|endcomment|>  .create(); update(rev); ProjectConfig cfg = read(rev); ContributorAgreement section = cfg.getContributorAgreement("Individual"); section.setAccepted(ImmutableList.of()); rev = commit(cfg); assertThat(text(rev, "project.config")) .isEqualTo( "[commentlink \"bugzilla\"]\n\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n"); } @Test <|startfocus|> public void notifySectionIsUnsetIfNoPermissionsAreSet() throws Exception { <|endfocus|> RevCommit rev = tr.commit() .add( "project.config", "[commentlink \"bugzilla\"]\n" + "\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n" + "\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n" + "[notify \"name\"]\n" + " email = example@example.com\n") .create(); update(rev); ProjectConfig cfg = read(rev); cfg.getNotifyConfigs().clear(); rev = commit(cfg);
<|startcomment|> CommentLinksAreSet <|endcomment|>  + " email = example@example.com\n") .create(); update(rev); ProjectConfig cfg = read(rev); cfg.getNotifyConfigs().clear(); rev = commit(cfg); assertThat(text(rev, "project.config")) .isEqualTo( "[commentlink \"bugzilla\"]\n\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n"); } @Test <|startfocus|> public void commentLinkSectionIsUnsetIfNoPermissionsAreSet() throws Exception { <|endfocus|> RevCommit rev = tr.commit() .add( "project.config", "[commentlink \"bugzilla\"]\n" + "\tmatch = \"(bug\\\\s+#?)(\\\\d+)\"\n" + "\tlink = http://bugs.example.com/show_bug.cgi?id=$2\n" + "[notify \"name\"]\n" + " email = example@example.com\n") .create(); update(rev); ProjectConfig cfg = read(rev); cfg.getCommentLinkSections().clear(); rev = commit(cfg);
<|startcomment|> Use Truth8 assertion. <|endcomment|> @NoHttpd public class NoUnresolvedCommentsRuleIT extends LightweightPluginDaemonTest { private static final String FILENAME = "my.file"; @Before public void enableRuleBeforeTest() throws Exception { enableRule(true); } @Test public void blocksWithUnresolvedComments() throws Exception { ReviewInput.CommentInput comment = newFileComment(); comment.unresolved = true; PushOneCommit.Result r = createChangeWithComment(comment); Optional<SubmitRecord> submitRecords = evaluate(r.getChange()); <|startfocus|> assertThat(submitRecords.isPresent()).isTrue(); <|endfocus|> SubmitRecord result = submitRecords.get(); assertThat(result.status).isEqualTo(SubmitRecord.Status.NOT_READY); assertThat(result.labels).isNull(); assertThat(result.requirements).hasSize(1); } @Test public void doesNotBlockWithNoComments() throws Exception { ReviewInput.CommentInput comment = newFileComment(); comment.unresolved = false; PushOneCommit.Result r = createChangeWithComment(comment); Optional<SubmitRecord> submitRecords = evaluate(r.getChange()); assertThat(submitRecords.isPresent()).isTrue(); SubmitRecord result = submitRecords.get();
<|startcomment|> This part also needs to be changed. <|endcomment|> package com.google.gerrit.server.rules; import com.google.gerrit.common.data.SubmitRecord; import com.google.gerrit.extensions.annotations.ExtensionPoint; import com.google.gerrit.server.query.change.ChangeData; import java.util.Optional; /** * Allows plugins to decide whether a change is ready to be submitted or not. * * <p>For a given {@link ChangeData}, each plugin is called and returns a {@link Optional} of {@link <|startfocus|> * SubmitRecord}. This collection can be empty, or contain one or several values. <|endfocus|> * * <p>A Change can only be submitted if all the plugins give their consent. * * <p>Each {@link SubmitRecord} represents a decision made by the plugin. If the plugin rejects a * change, it should hold valuable informations to help the end user understand and correct the * blocking points. * * <p>It should be noted that each plugin can handle rules inheritance. * * <p>This interface should be used to write pre-submit validation rules. This includes both simple
<|startcomment|> Change to submitRecord (singular) since it's no longer a collection. Same below. <|endcomment|> import java.util.Map; import java.util.Optional; import org.eclipse.jgit.internal.storage.dfs.InMemoryRepository; import org.eclipse.jgit.junit.TestRepository; import org.junit.Test; @NoHttpd public class IgnoreSelfApprovalRuleIT extends AbstractDaemonTest { @Inject private IgnoreSelfApprovalRule rule; @Test public void blocksWhenUploaderIsOnlyApprover() throws Exception { enableRule("Code-Review", true); PushOneCommit.Result r = createChange(); approve(r.getChangeId()); <|startfocus|> Optional<SubmitRecord> submitRecords = rule.evaluate(r.getChange()); <|endfocus|> assertThat(submitRecords.isPresent()).isTrue(); SubmitRecord result = submitRecords.get(); assertThat(result.status).isEqualTo(SubmitRecord.Status.NOT_READY); assertThat(result.labels).isNotEmpty(); assertThat(result.requirements) .containsExactly( SubmitRequirement.builder() .setFallbackText("Approval from non-uploader required") .setType("non_uploader_approval") .build()); } @Test public void allowsSubmissionWhenChangeHasNonUploaderApproval() throws Exception { enableRule("Code-Review", true); // Create change as user
<|startcomment|> assertThat(submitRecords).isEmpty(); and the same below <|endcomment|>  } @Test public void allowsSubmissionWhenChangeHasNonUploaderApproval() throws Exception { enableRule("Code-Review", true); // Create change as user TestRepository<InMemoryRepository> userTestRepo = cloneProject(project, user); PushOneCommit push = pushFactory.create(user.newIdent(), userTestRepo); PushOneCommit.Result r = push.to("refs/for/master"); // Approve as admin approve(r.getChangeId()); <|startfocus|> Optional<SubmitRecord> submitRecords = rule.evaluate(r.getChange()); assertThat(submitRecords.isPresent()).isFalse(); <|endfocus|> } @Test public void doesNothingByDefault() throws Exception { enableRule("Code-Review", false); PushOneCommit.Result r = createChange(); approve(r.getChangeId()); Optional<SubmitRecord> submitRecords = rule.evaluate(r.getChange()); assertThat(submitRecords.isPresent()).isFalse(); } private void enableRule(String labelName, boolean newState) throws Exception { try (ProjectConfigUpdate u = updateProject(project)) { Map<String, LabelType> localLabelSections = u.getConfig().getLabelSections();
<|startcomment|> Using the truth java 8 extension this can be just: assertThat(record).isPresent(); <|endcomment|>  public void convertsPrologToSubmitRecord() { PrologRuleEvaluator evaluator = makeEvaluator(); StructureTerm verifiedLabel = makeLabel("Verified", "may"); StructureTerm labels = new StructureTerm("label", verifiedLabel); List<Term> terms = ImmutableList.of(makeTerm("ok", labels)); Optional<SubmitRecord> record = evaluator.resultsToSubmitRecord(null, terms); <|startfocus|> assertThat(record.isPresent()).isTrue(); <|endfocus|>
<|startcomment|> assertThat(record).isPresent() <|endcomment|>  terms.add(makeTerm("ok", makeLabels(label2))); terms.add(makeTerm("not_ready", makeLabels(label3))); // When Optional<SubmitRecord> record = evaluator.resultsToSubmitRecord(null, terms); // assert that SubmitRecord expectedRecord = new SubmitRecord(); expectedRecord.status = SubmitRecord.Status.OK; expectedRecord.labels = new ArrayList<>(); expectedRecord.labels.add(submitRecordLabel2); expectedRecord.labels.add(submitRecordLabel3); <|startfocus|> assertThat(record.isPresent()).isTrue(); assertThat(record.get()).isEqualTo(expectedRecord); <|endfocus|>
<|startcomment|> I think, but I'm not 100% sure, that the truth library also provides a specific API for asserting that an optional has the expected value. <|endcomment|>  terms.add(makeTerm("ok", makeLabels(label2))); terms.add(makeTerm("not_ready", makeLabels(label3))); // When Optional<SubmitRecord> record = evaluator.resultsToSubmitRecord(null, terms); // assert that SubmitRecord expectedRecord = new SubmitRecord(); expectedRecord.status = SubmitRecord.Status.OK; expectedRecord.labels = new ArrayList<>(); expectedRecord.labels.add(submitRecordLabel2); expectedRecord.labels.add(submitRecordLabel3); <|startfocus|> assertThat(record.isPresent()).isTrue(); assertThat(record.get()).isEqualTo(expectedRecord); <|endfocus|>
<|startcomment|> This was moved in Change-Id: I785bfd33a5b to the global Module: why does the merge need to move it to GitModule? <|endcomment|>  protected void configure() { if (config.getSharedRefDb().isEnabled()) { <|startfocus|> DynamicSet.bind(binder(), ProjectDeletedListener.class) .to(ProjectDeletedSharedDbCleanup.class); <|endfocus|> install(new ValidationModule(config)); }
<|startcomment|> This isn't needed. <|endcomment|>  protected void configure() { <|startfocus|> <|endfocus|> bind(SharedRefDatabase.class).to(ZkSharedRefDatabase.class); bind(CuratorFramework.class).toInstance(cfg.getZookeeperConfig().buildCurator()); bind(ZkConnectionConfig.class) .toInstance( new ZkConnectionConfig( cfg.getZookeeperConfig().buildCasRetryPolicy(), cfg.getZookeeperConfig().getZkInterProcessLockTimeOut())); DynamicSet.bind(binder(), ProjectDeletedListener.class).to(ProjectDeletedSharedDbCleanup.class);
<|startcomment|> This is 99.9% identical to the one at L42: can we DRY it out? <|endcomment|>  metadataBuilder.addPluginMetadata( PluginMetadata.create(PUBLISHER_SUCCESS_COUNTER, fieldValue))) .description("Broker message published count") .build()); this.brokerPublisherFailureCounter = metricMaker.newCounter( "multi_site/broker/broker_message_publisher_failure_counter", new Description("Number of messages failed to publish by the broker publisher") .setRate() .setUnit("errors"), <|startfocus|> Field.ofString( PUBLISHER_FAILURE_COUNTER, (metadataBuilder, fieldValue) -> metadataBuilder.addPluginMetadata( PluginMetadata.create(PUBLISHER_FAILURE_COUNTER, fieldValue))) <|endfocus|> .description("Broker failed to publish message count") .build());
<|startcomment|> Wow, that is super-complex for a very simple problem IMHO. KISS by simply passing the metadataKey as a parameter and returning the whole metrics? <|endcomment|>  new Description("Number of messages failed to publish by the broker publisher") .setRate() .setUnit("errors"), Field.ofString(PUBLISHER_FAILURE_COUNTER, metadataMapper(PUBLISHER_FAILURE_COUNTER)) .description("Broker failed to publish message count") .build()); } public void incrementBrokerPublishedMessage() { brokerPublisherSuccessCounter.increment(PUBLISHER_SUCCESS_COUNTER); } public void incrementBrokerFailedToPublishMessage() { brokerPublisherFailureCounter.increment(PUBLISHER_FAILURE_COUNTER); } <|startfocus|> private BiConsumer<Metadata.Builder, String> metadataMapper(String metadataKey) { return (metadataBuilder, fieldValue) -> metadataBuilder.addPluginMetadata(PluginMetadata.create(metadataKey, fieldValue)); <|endfocus|> } } 
<|startcomment|> Why only catching KafkaException and not Exception instead? <|endcomment|>  "Kafka consumer subscribing to topic [%s] for event family [%s]", topic, getEventFamily()); consumer.subscribe(Collections.singleton(topic)); while (!closed.get()) { ConsumerRecords<byte[], byte[]> consumerRecords = consumer.poll(Duration.ofMillis(configuration.kafkaSubscriber().getPollingInterval())); consumerRecords.forEach(this::processRecord); } } catch (WakeupException e) { // Ignore exception if closing if (!closed.get()) throw e; <|startfocus|> } catch (KafkaException e) { <|endfocus|> subscriberMetrics.incrementSubscriberFailedToPollMessages(); throw e; } finally { consumer.close(); }
<|startcomment|> I believe we should increment the failures count here also? <|endcomment|>  eventRouter.route(event.getEventBody(gson)); subscriberMetrics.incrementSubscriberConsumedMessage(); } catch (IOException e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", event.getHeader().getEventType()); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); } catch (PermissionBackendException | OrmException e) { logger.atSevere().withCause(e).log( <|startfocus|> "Cannot handle message %s: [Exception: %s]", event.getHeader().getEventType()); <|endfocus|> } } } catch (Exception e) { logger.atSevere().withCause(e).log( "Malformed event '%s': [Exception: %s]", new String(consumerRecord.value(), UTF_8)); subscriberMetrics.incrementSubscriberFailedToConsumeMessage(); }
<|startcomment|> subscriberMetrics <|endcomment|>  public IndexEventSubscriber( KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, IndexEventRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gsonProvider, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, <|startfocus|> SubscriberMetrics kafkaSubscriberMetrics) { <|endfocus|> super( configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gsonProvider, instanceId, oneOffCtx, msgLog, kafkaSubscriberMetrics);
<|startcomment|> subscriberMetrics <|endcomment|>  public KafkaCacheEvictionEventSubscriber( KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, StreamEventRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gsonProvider, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, <|startfocus|> SubscriberMetrics kafkaSubscriberMetrics) { <|endfocus|> super( configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gsonProvider, instanceId, oneOffCtx, msgLog, kafkaSubscriberMetrics);
<|startcomment|> subscriberMetrics <|endcomment|>  public ProjectUpdateEventSubscriber( KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, ProjectListUpdateRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gson, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, <|startfocus|> SubscriberMetrics kafkaSubscriberMetrics) { <|endfocus|> super( configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gson, instanceId, oneOffCtx, msgLog, kafkaSubscriberMetrics);
<|startcomment|> subscriberMetrics <|endcomment|>  public StreamEventSubscriber( KafkaConfiguration configuration, KafkaConsumerFactory consumerFactory, Deserializer<byte[]> keyDeserializer, Deserializer<SourceAwareEventWrapper> valueDeserializer, StreamEventRouter eventRouter, DynamicSet<DroppedEventListener> droppedEventListeners, @BrokerGson Gson gson, @InstanceId UUID instanceId, OneOffRequestContext oneOffCtx, MessageLogger msgLog, <|startfocus|> SubscriberMetrics kafkaSubscriberMetrics) { <|endfocus|> super( configuration, consumerFactory, keyDeserializer, valueDeserializer, eventRouter, droppedEventListeners, gson, instanceId, oneOffCtx, msgLog, kafkaSubscriberMetrics);
<|startcomment|> Do we need this parameter? Can't the class variable be used? <|endcomment|>  private String replaceInUrl(String placeholder, String url, <|startfocus|> String replacement, boolean lowerCase) { <|endfocus|> if (url == null || replacement == null || !url.contains(placeholder)) { return url; } if (lowerCase) { replacement = replacement.toLowerCase(); } // as we can't assume anything of 'replacement', we're URL encoding it return url.replace(placeholder, Url.encode(replacement));
<|startcomment|> These two methods seem a bit out of place. In my view the BrokerSession should just handle/check the connectivity to the broker, ie. isOpen, connect and disconnect. <|endcomment|> // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.multisite.broker; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventFamily; public interface BrokerSession { boolean isOpen(); void connect(); void disconnect(); <|startfocus|> boolean publishEvent(EventFamily eventFamily, String payload); boolean publishEventToTopic(String topic, String payload); <|endfocus|> } 
<|startcomment|> Nit: As you noticed, it's currently not possible to ever end up in this state as some earlier code already filters out that case. It might make sense to additionally mention this here to avoid confusion, especially as the test case for this behaves differently. <|endcomment|>  CheckUpdate.Builder builder = CheckUpdate.builder(); builder .setState(CheckState.NOT_STARTED) .unsetFinished() .unsetStarted() .setMessage("") .setUrl(""); Check updatedCheck; if (!check.isPresent()) { Checker checker = checkers .getChecker(checkerUuid) .orElseThrow( () -> new ResourceNotFoundException( String.format("checker %s not found", checkerUuid))); <|startfocus|> // Also return a backfilled check for checkers that are do not apply to the change. <|endfocus|> updatedCheck = Check.newBackfilledCheck( checkResource.getRevisionResource().getProject(), checkResource.getRevisionResource().getPatchSet(), checker); } else { updatedCheck = checksUpdate.get().updateCheck(key, builder.build()); } return checkJsonFactory.noOptions().format(updatedCheck); } } 
<|startcomment|> Nit: Word too much. <|endcomment|>  CheckUpdate.Builder builder = CheckUpdate.builder(); builder .setState(CheckState.NOT_STARTED) .unsetFinished() .unsetStarted() .setMessage("") .setUrl(""); Check updatedCheck; if (!check.isPresent()) { Checker checker = checkers .getChecker(checkerUuid) .orElseThrow( () -> new ResourceNotFoundException( String.format("checker %s not found", checkerUuid))); <|startfocus|> // Also return a backfilled check for checkers that are do not apply to the change. <|endfocus|> updatedCheck = Check.newBackfilledCheck( checkResource.getRevisionResource().getProject(), checkResource.getRevisionResource().getPatchSet(), checker); } else { updatedCheck = checksUpdate.get().updateCheck(key, builder.build()); } return checkJsonFactory.noOptions().format(updatedCheck); } } 
<|startcomment|> Here and below: I don't know why other tests of the checks plugin use this method but any new code should use ProjectOperations instead. <|endcomment|>  assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); assertThat(info.updated).isGreaterThan(info.created); } @Test public void rerunCheckNotExistingButBackfilled() throws Exception { CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunExistingCheckWithCheckerNotAppliedToChange() throws Exception { <|startfocus|> Project.NameKey otherProject = createProjectOverAPI("other", null, true, null); <|endfocus|> checkerOperations.checker(checkKey.checkerUuid()).forUpdate().repository(otherProject).update(); checkOperations.newCheck(checkKey).upsert(); CheckInfo info = checksApiFactory.revision(patchSetId).id(checkKey.checkerUuid()).rerun(); assertThat(info.state).isEqualTo(CheckState.NOT_STARTED); } @Test public void rerunNonExistingCheckWithCheckerNotAppliedToChange() throws Exception { Project.NameKey otherProject = createProjectOverAPI("other", null, true, null); checkerOperations.checker(checkKey.checkerUuid()).forUpdate().repository(otherProject).update(); assertThrows( ResourceNotFoundException.class,
<|startcomment|> This is intended to be used by other plugins as an external API, it should have its JavaDoc as documentation IMHO. <|endcomment|> // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an "AS IS" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. package com.googlesource.gerrit.plugins.replication; import com.google.inject.Inject; import com.google.inject.Singleton; import java.util.Optional; import org.eclipse.jgit.transport.URIish; <|startfocus|> <|endfocus|> public interface AdminApiFactory { Optional<AdminApi> create(URIish uri); @Singleton static class DefaultAdminApiFactory implements AdminApiFactory { protected final SshHelper sshHelper; @Inject public DefaultAdminApiFactory(SshHelper sshHelper) { this.sshHelper = sshHelper; } @Override public Optional<AdminApi> create(URIish uri) { if (isGerrit(uri)) { return Optional.of(new GerritSshApi(sshHelper, uri)); } else if (!uri.isRemote()) { return Optional.of(new LocalFS(uri));
<|startcomment|> note that this is inconsistent with error messages in other classes where the first letter is capitalised. <|endcomment|>  if (destRef == null) { throw new ResourceConflictException( "can't rebase onto tip of branch " + destRefKey.get() + "; branch doesn't exist"); } return destRef.getObjectId(); } Base base = rebaseUtil.parseBase(rsrc, str); if (base == null) { <|startfocus|> throw new ResourceConflictException("base revision is missing from the destination branch: " + str); <|endfocus|> } PatchSet.Id baseId = base.patchSet().getId(); if (change.getId().equals(baseId.getParentKey())) { throw new ResourceConflictException("cannot rebase change onto itself"); } permissionBackend .user(rsrc.getUser()) .database(dbProvider) .change(base.notes()) .check(ChangePermission.READ); Change baseChange = base.notes().getChange(); if (!baseChange.getProject().equals(change.getProject())) { throw new ResourceConflictException( "base change is in wrong project: " + baseChange.getProject()); } else if (!baseChange.getDest().equals(change.getDest())) {
<|startcomment|> This is wrong: previously there was one subscriber per receiver whilst now it is one across all receivers, causing concurrency issues. <|endcomment|>  package com.googlesource.gerrit.plugins.multisite.kafka; import com.google.gerrit.server.events.Event; import com.google.inject.Inject; import com.googlesource.gerrit.plugins.multisite.broker.BrokerApi; import com.googlesource.gerrit.plugins.multisite.broker.kafka.BrokerPublisher; import com.googlesource.gerrit.plugins.multisite.consumer.SourceAwareEventWrapper; import com.googlesource.gerrit.plugins.multisite.forwarder.events.EventTopic; import com.googlesource.gerrit.plugins.multisite.kafka.consumer.KafkaEventSubscriber; import java.util.function.Consumer; public class KafkaBrokerApi implements BrokerApi { private final BrokerPublisher publisher; <|startfocus|> private final KafkaEventSubscriber subscriber; <|endfocus|> @Inject public KafkaBrokerApi(BrokerPublisher publisher, KafkaEventSubscriber subscriber) { this.publisher = publisher; this.subscriber = subscriber; } @Override public boolean send(String topic, Event event) { return publisher.publish(topic, event); } @Override public void receiveAync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { subscriber.subscribe(EventTopic.of(topic), eventConsumer); } } 
<|startcomment|> This should create one scriber per receiver. <|endcomment|> <|startfocus|> public void receiveAync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { <|endfocus|> subscriber.subscribe(EventTopic.of(topic), eventConsumer);
<|startcomment|> Why SINGLETON has been removed? <|endcomment|>  } listener().to(Log4jMessageLogger.class); bind(MessageLogger.class).to(Log4jMessageLogger.class); install(new ForwarderModule()); if (config.cache().synchronize()) { install(new CacheModule()); } if (config.event().synchronize()) { install(new EventModule()); } if (config.index().synchronize()) { install(new IndexModule()); } install(new BrokerModule()); DynamicItem.bind(binder(), BrokerApi.class).to(KafkaBrokerApi.class); <|startfocus|> install(kafkaForwardedEventRouterModule); <|endfocus|> install(kafkaBrokerForwarderModule); install( new ValidationModule( config, disableGitRepositoryValidation || !config.getSharedRefDb().isEnabled())); bind(Gson.class) .annotatedWith(BrokerGson.class) .toProvider(GsonProvider.class) .in(Singleton.class);
<|startcomment|> good catch, but it should be a separate change IMHO. <|endcomment|> <|startfocus|> public void receiveAsync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { apiDelegate.get().receiveAsync(topic, eventConsumer); <|endfocus|>
<|startcomment|> This access to subscribers should be synchronized. <|endcomment|>  public void receiveAync(String topic, Consumer<SourceAwareEventWrapper> eventConsumer) { KafkaEventSubscriber subscriber = subscriberProvider.get(); <|startfocus|> subscribers.add(subscriber); <|endfocus|> subscriber.subscribe(EventTopic.of(topic), eventConsumer);
<|startcomment|> Remove the blank line <|endcomment|> import com.google.gerrit.reviewdb.client.Account; import com.google.gerrit.reviewdb.server.ReviewDb; import com.google.gerrit.server.CurrentUser; import com.google.gerrit.server.config.SitePaths; import com.google.gerrit.server.util.ManualRequestContext; import com.google.gerrit.server.util.OneOffRequestContext; import com.google.gerrit.server.util.RequestContext; import com.google.gerrit.testing.ConfigSuite; import com.google.inject.Injector; import com.google.inject.Module; import com.google.inject.Provider; import java.io.File; import java.io.IOException; import java.util.Arrays; import java.util.Collections; <|startfocus|> <|endfocus|> import org.eclipse.jgit.errors.ConfigInvalidException; import org.eclipse.jgit.lib.Config; import org.eclipse.jgit.lib.StoredConfig; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.eclipse.jgit.util.SystemReader; import org.junit.Rule; import org.junit.rules.RuleChain; import org.junit.rules.TemporaryFolder; import org.junit.rules.TestRule; import org.junit.runner.Description; import org.junit.runner.RunWith; import org.junit.runners.model.Statement; @RunWith(ConfigSuite.class) @UseLocalDisk public abstract class StandaloneSiteTest {
<|startcomment|> Use spaces instead of tabs. <|endcomment|>  return new FileBasedConfig(parent, new File(tempDir, "user.config"), FS.detect()); } @Override public FileBasedConfig openSystemConfig(Config parent, FS fs) { return new FileBasedConfig(parent, new File(tempDir, "system.config"), FS.detect()); } @Override public long getCurrentTime() { return oldSystemReader.getCurrentTime(); } @Override public int getTimezone(long when) { return oldSystemReader.getTimezone(when); } <|startfocus|> @Override public StoredConfig getUserConfig() throws IOException, ConfigInvalidException { return oldSystemReader.getUserConfig(); } <|endfocus|> @Override public StoredConfig getSystemConfig() throws IOException, ConfigInvalidException { return oldSystemReader.getSystemConfig(); }
<|startcomment|> I would rename this to replicationTaskStorage since now we are storing replication tasks and no longer events <|endcomment|>  private final Map<URIish, PushOne> pending = new HashMap<>(); private final Map<URIish, PushOne> inFlight = new HashMap<>(); private final PushOne.Factory opFactory; private final GitRepositoryManager gitManager; private final PermissionBackend permissionBackend; private final Provider<CurrentUser> userProvider; private final ProjectCache projectCache; private volatile ScheduledExecutorService pool; private final PerThreadRequestScope.Scoper threadScoper; private final DestinationConfiguration config; private final DynamicItem<EventDispatcher> eventDispatcher; <|startfocus|> private final ReplicationTasksStorage eventsStorage; <|endfocus|> protected enum RetryReason { TRANSPORT_ERROR, COLLISION, REPOSITORY_MISSING; } public static class QueueInfo { public final Map<URIish, PushOne> pending; public final Map<URIish, PushOne> inFlight; public QueueInfo(Map<URIish, PushOne> pending, Map<URIish, PushOne> inFlight) { this.pending = ImmutableMap.copyOf(pending); this.inFlight = ImmutableMap.copyOf(inFlight); } } @Inject protected Destination( Injector injector, PluginUser pluginUser, GitRepositoryManager gitRepositoryManager, PermissionBackend permissionBackend,
<|startcomment|> change name as well here ? e.g. rts or ts <|endcomment|>  protected Destination( Injector injector, PluginUser pluginUser, GitRepositoryManager gitRepositoryManager, PermissionBackend permissionBackend, Provider<CurrentUser> userProvider, ProjectCache projectCache, GroupBackend groupBackend, ReplicationStateListeners stateLog, GroupIncludeCache groupIncludeCache, DynamicItem<EventDispatcher> eventDispatcher, <|startfocus|> ReplicationTasksStorage es, <|endfocus|> @Assisted DestinationConfiguration cfg) { this.eventDispatcher = eventDispatcher; gitManager = gitRepositoryManager; this.permissionBackend = permissionBackend; this.userProvider = userProvider; this.projectCache = projectCache; this.stateLog = stateLog; this.eventsStorage = es; config = cfg; CurrentUser remoteUser; if (!cfg.getAuthGroupNames().isEmpty()) { ImmutableSet.Builder<AccountGroup.UUID> builder = ImmutableSet.builder(); for (String name : cfg.getAuthGroupNames()) { GroupReference g = GroupBackends.findExactSuggestion(groupBackend, name); if (g != null) { builder.add(g.getUUID()); addRecursiveParents(g.getUUID(), builder, groupIncludeCache); } else {
<|startcomment|> So the persist method translates the PushOne event to potentially multiple replication tasks ? Maybe this method should be named differently, I'd expect a persist method to simply persist 1-1 the objects passed to it, this method has the side effect to generate 1 or multiple replication tasks from a single event. Maybe we should add another method "Set<task> tasks(event)" to compute the replication tasks to spawn for the event and then call persist on this set of tasks. <|endcomment|>  return; } } } synchronized (stateLock) { PushOne e = getPendingPush(uri); if (e == null) { e = opFactory.create(project, uri); addRef(e, ref); e.addState(ref, state); @SuppressWarnings("unused") ScheduledFuture<?> ignored = pool.schedule(e, now ? 0 : config.getDelay(), TimeUnit.SECONDS); pending.put(uri, e); <|startfocus|> eventsStorage.persist(project.get(), ref, e.getURI(), getRemoteConfigName()); <|endfocus|> } else if (!e.getRefs().contains(ref)) { addRef(e, ref); e.addState(ref, state); } state.increasePushTaskCount(project.get(), ref); repLog.info("scheduled {}:{} => {} to run after {}s", project, ref, e, config.getDelay()); }
<|startcomment|> see comment above, this is a similar translation from a single event to multiple tasks to be deleted <|endcomment|>  void notifyFinished(PushOne op) { synchronized (stateLock) { inFlight.remove(op.getURI()); if (!op.wasCanceled()) { for (String ref : op.getRefs()) { if (!refHasPendingPush(op.getURI(), ref)) { <|startfocus|> eventsStorage.delete( <|endfocus|> op.getProjectNameKey().get(), ref, op.getURI(), getRemoteConfigName()); } } } }
<|startcomment|> replicationTasksStorage or taskStorage <|endcomment|>  String key = "${name}"; int n = in.indexOf(key); if (0 <= n) { return in.substring(0, n) + name + in.substring(n + key.length()); } if (keyIsOptional) { return in; } return null; } private final WorkQueue workQueue; private final DynamicItem<EventDispatcher> dispatcher; private final ReplicationConfig config; private final AdminApiFactory adminApiFactory; private final ReplicationState.Factory replicationStateFactory; <|startfocus|> private final ReplicationTasksStorage eventsStorage; <|endfocus|> private volatile boolean running; private volatile boolean replaying; @Inject ReplicationQueue( WorkQueue wq, AdminApiFactory aaf, ReplicationConfig rc, DynamicItem<EventDispatcher> dis, ReplicationStateListeners sl, ReplicationState.Factory rsf, ReplicationTasksStorage es) { workQueue = wq; dispatcher = dis; config = rc; stateLog = sl; adminApiFactory = aaf; replicationStateFactory = rsf; eventsStorage = es; } @Override public void start() { if (!running) { config.startup(workQueue);
<|startcomment|> find a better name <|endcomment|>  return in; } return null; } private final WorkQueue workQueue; private final DynamicItem<EventDispatcher> dispatcher; private final ReplicationConfig config; private final AdminApiFactory adminApiFactory; private final ReplicationState.Factory replicationStateFactory; private final ReplicationTasksStorage eventsStorage; private volatile boolean running; private volatile boolean replaying; @Inject ReplicationQueue( WorkQueue wq, AdminApiFactory aaf, ReplicationConfig rc, DynamicItem<EventDispatcher> dis, ReplicationStateListeners sl, ReplicationState.Factory rsf, <|startfocus|> ReplicationTasksStorage es) { <|endfocus|> workQueue = wq; dispatcher = dis; config = rc; stateLog = sl; adminApiFactory = aaf; replicationStateFactory = rsf; eventsStorage = es; } @Override public void start() { if (!running) { config.startup(workQueue); running = true; firePendingEvents(); } } @Override public void stop() { running = false; int discarded = config.shutdown(); if (discarded > 0) {
<|startcomment|> tasksReplayed <|endcomment|>  private void firePendingEvents() { try { <|startfocus|> Set<String> eventsReplayed = new HashSet<>(); <|endfocus|> replaying = true; for (ReplicationTasksStorage.ReplicateRefUpdate e : eventsStorage.list()) { String eventKey = String.format("%s:%s", e.project, e.ref); if (!eventsReplayed.contains(eventKey)) { repLog.info("Firing pending event {}", eventKey); onGitReferenceUpdated(e.project, e.ref); eventsReplayed.add(eventKey); } } } finally { replaying = false; }
<|startcomment|> rename this to t(ask) ? <|endcomment|>  && head.isSymbolic() && RefNames.REFS_CONFIG.equals(head.getLeaf().getName())) { return; } } catch (IOException err) { stateLog.error(String.format("cannot check type of project %s", project), err, state); return; } } catch (IOException err) { stateLog.error(String.format("source project %s not available", project), err, state); return; } } } synchronized (stateLock) { <|startfocus|> PushOne e = getPendingPush(uri); if (e == null) { e = opFactory.create(project, uri); addRef(e, ref); e.addState(ref, state); <|endfocus|> @SuppressWarnings("unused") ScheduledFuture<?> ignored = pool.schedule(e, now ? 0 : config.getDelay(), TimeUnit.SECONDS); pending.put(uri, e); replicationTasksStorage.persist(project.get(), ref, e.getURI(), getRemoteConfigName()); } else if (!e.getRefs().contains(ref)) { addRef(e, ref); e.addState(ref, state); }
<|startcomment|> task ? <|endcomment|> <|startfocus|> void notifyFinished(PushOne op) { <|endfocus|> synchronized (stateLock) { inFlight.remove(op.getURI()); if (!op.wasCanceled()) { for (String ref : op.getRefs()) { if (!refHasPendingPush(op.getURI(), ref)) { replicationTasksStorage.delete( op.getProjectNameKey().get(), ref, op.getURI(), getRemoteConfigName()); } } } }
<|startcomment|> taskJson ? <|endcomment|>  public void delete(String project, String ref, URIish uri, String remote) { ReplicateRefUpdate r = new ReplicateRefUpdate(); r.project = project; r.ref = ref; r.uri = uri.toASCIIString(); r.remote = remote; <|startfocus|> String eventJson = GSON.toJson(r) + "\n"; String eventKey = sha1(eventJson).name(); <|endfocus|> try { logger.atFiner().log("DELETE %s:%s => %s", project, ref, uri); Files.delete(refUpdates().resolve(eventKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", eventKey); }
<|startcomment|> taskKey ? <|endcomment|>  public void delete(String project, String ref, URIish uri, String remote) { ReplicateRefUpdate r = new ReplicateRefUpdate(); r.project = project; r.ref = ref; r.uri = uri.toASCIIString(); r.remote = remote; <|startfocus|> String eventJson = GSON.toJson(r) + "\n"; String eventKey = sha1(eventJson).name(); <|endfocus|> try { logger.atFiner().log("DELETE %s:%s => %s", project, ref, uri); Files.delete(refUpdates().resolve(eventKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", eventKey); }
<|startcomment|> If I follow the code well both 151 and 152 statements will reach the ReplicationTasksStorage.persist method for each task. The call from 151 is obvious. The line 152 will call: ReplicationTasksStorage.persist Destination.schedule:403 Destination.schedule:358 ReplicationQueue:152 Can we avoid persisting each task twice? <|endcomment|>  if (!running) { stateLog.warn("Replication plugin did not finish startup before event", state); return; } Project.NameKey project = new Project.NameKey(projectName); for (Destination cfg : config.getDestinations(FilterType.ALL)) { if (cfg.wouldPushProject(project) && cfg.wouldPushRef(refName)) { for (URIish uri : cfg.getURIs(project, null)) { <|startfocus|> replicationTasksStorage.persist(projectName, refName, uri, cfg.getRemoteConfigName()); <|endfocus|> cfg.schedule(project, refName, uri, state); } } } state.markAllPushTasksScheduled();
<|startcomment|> Tasks <|endcomment|> <|startfocus|> private void firePendingEvents() { <|endfocus|> try { Set<String> tasksReplayed = new HashSet<>(); replaying = true; for (ReplicationTasksStorage.ReplicateRefUpdate t : replicationTasksStorage.list()) { String taskKey = String.format("%s:%s", t.project, t.ref); if (!tasksReplayed.contains(taskKey)) { repLog.info("Firing pending task {}", taskKey); onGitReferenceUpdated(t.project, t.ref); tasksReplayed.add(taskKey); } } } finally { replaying = false; }
<|startcomment|> Why is this needed? Isn't every task key representing one unique push operation? Why do we limit to project+ref here? <|endcomment|>  private void firePendingEvents() { try { Set<String> tasksReplayed = new HashSet<>(); replaying = true; for (ReplicationTasksStorage.ReplicateRefUpdate t : replicationTasksStorage.list()) { <|startfocus|> String taskKey = String.format("%s:%s", t.project, t.ref); if (!tasksReplayed.contains(taskKey)) { repLog.info("Firing pending task {}", taskKey); <|endfocus|> onGitReferenceUpdated(t.project, t.ref); tasksReplayed.add(taskKey); } } } finally { replaying = false; }
<|startcomment|> Should this quadruple rather be replaced with one parameter of ReplicationRefUpdate type? same for the delete method (line 83) <|endcomment|> <|startfocus|> public String persist(String project, String ref, URIish uri, String remote) { ReplicateRefUpdate r = new ReplicateRefUpdate(); r.project = project; r.ref = ref; r.uri = uri.toASCIIString(); r.remote = remote; <|endfocus|> String json = GSON.toJson(r) + "\n"; String eventKey = sha1(json).name(); Path file = refUpdates().resolve(eventKey); if (Files.exists(file)) { return eventKey; } try { logger.atFine().log("CREATE %s:%s => %s", project, ref, uri); Files.write(file, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().log("Couldn't persist event %s", json, e); } return eventKey;
<|startcomment|> This should be included in the log by calling withCause(e) <|endcomment|>  String json = GSON.toJson(r) + "\n"; String eventKey = sha1(json).name(); Path file = refUpdates().resolve(eventKey); if (Files.exists(file)) { return eventKey; } try { logger.atFine().log("CREATE %s:%s => %s", project, ref, uri); Files.write(file, json.getBytes(UTF_8)); } catch (IOException e) { <|startfocus|> logger.atWarning().log("Couldn't persist event %s", json, e); <|endfocus|> } return eventKey;
<|startcomment|> I don't know why we deleted it from here but now with the replication tasks it makes even less sense to delete the task from here. A task should only be deleted once it is done. <|endcomment|>  public List<ReplicateRefUpdate> list() { ArrayList<ReplicateRefUpdate> result = new ArrayList<>(); try (DirectoryStream<Path> events = Files.newDirectoryStream(refUpdates())) { for (Path e : events) { if (Files.isRegularFile(e)) { String json = new String(Files.readAllBytes(e), UTF_8); result.add(GSON.fromJson(json, ReplicateRefUpdate.class)); <|startfocus|> Files.delete(e); <|endfocus|> } } } catch (IOException e) { logger.atSevere().withCause(e).log("Error when firing pending events"); } return result;
<|startcomment|> private? <|endcomment|> import org.eclipse.jgit.lib.Repository; import org.eclipse.jgit.revwalk.RevCommit; import org.eclipse.jgit.storage.file.FileBasedConfig; import org.eclipse.jgit.util.FS; import org.junit.Test; @UseLocalDisk @TestPlugin( name = "replication", sysModule = "com.googlesource.gerrit.plugins.replication.ReplicationModule") public class ReplicationIT extends LightweightPluginDaemonTest { private static final int TEST_REPLICATION_DELAY = 2; private static final Duration TEST_TIMEMOUT = Duration.ofSeconds(TEST_REPLICATION_DELAY * 10); @Inject private SitePaths sitePaths; <|startfocus|> Path pluginDataDir; <|endfocus|> private Path gitPath; private Path storagePath; private FileBasedConfig config; @Override public void setUpTestPlugin() throws Exception { config = new FileBasedConfig(sitePaths.etc_dir.resolve("replication.config").toFile(), FS.DETECTED); config.save(); gitPath = sitePaths.site_path.resolve("git"); super.setUpTestPlugin(); pluginDataDir = plugin.getSysInjector().getInstance(Key.get(Path.class, PluginData.class)); storagePath = pluginDataDir.resolve("ref-updates"); } @Test
<|startcomment|> We usually import methods from Collectors as static <|endcomment|>  e.printStackTrace(); return null; } } private void setReplicationDestination( String remoteName, String replicaSuffix, int replicationDelay) throws IOException { setReplicationDestination(remoteName, Arrays.asList(replicaSuffix), replicationDelay); } private void setReplicationDestination( String remoteName, List<String> replicaSuffixes, int replicationDelay) throws IOException { List<String> replicaUrls = replicaSuffixes.stream() .map(suffix -> gitPath.resolve("${name}" + suffix + ".git").toString()) <|startfocus|> .collect(Collectors.toList()); <|endfocus|> config.setStringList("remote", remoteName, "url", replicaUrls); config.setInt("remote", remoteName, "replicationDelay", replicationDelay); config.save(); reloadConfig(); } private void waitUntil(Supplier<Boolean> waitCondition) throws InterruptedException { Stopwatch stopwatch = Stopwatch.createStarted(); while (!waitCondition.get() && stopwatch.elapsed().compareTo(TEST_TIMEMOUT) < 0) { TimeUnit.SECONDS.sleep(1); } } private void reloadConfig() { plugin.getSysInjector().getInstance(AutoReloadConfigDecorator.class).forceReload(); } }
<|startcomment|> Does this still need to be @AssistedInject now that it's not getting the EventsStorage injected? <|endcomment|>  private static class RefReplicationStatus { private final String project; private final String ref; private int nodesToReplicateCount; private int replicatedNodesCount; RefReplicationStatus(String project, String ref) { this.project = project; this.ref = ref; } public boolean allDone() { return replicatedNodesCount == nodesToReplicateCount; } } private final Table<String, String, RefReplicationStatus> statusByProjectRef; private int totalPushTasksCount; private int finishedPushTasksCount; <|startfocus|> @AssistedInject ReplicationState(@Assisted PushResultProcessing processing) { <|endfocus|> pushResultProcessing = processing; statusByProjectRef = HashBasedTable.create(); } public void increasePushTaskCount(String project, String ref) { countingLock.lock(); try { getRefStatus(project, ref).nodesToReplicateCount++; totalPushTasksCount++; } finally { countingLock.unlock(); } } public boolean hasPushTask() { return totalPushTasksCount != 0; } public void notifyRefReplicated( String project, String ref, URIish uri, RefPushResult status,
<|startcomment|> this is not quite what you want: you want to delete the change edits for all users at the same time. You should test this by creating the change + changeedit as a user, and then deleting it as the admin (the normal order of things.) Also, since this is in the repo (rather than All-Users), maybe this should go into DeleteChangeOp#updateRepo. <|endcomment|>  super(retryHelper); this.opFactory = opFactory; this.editUtil = editUtil; } @Override protected Response<Object> applyImpl( BatchUpdate.Factory updateFactory, ChangeResource rsrc, Input input) throws RestApiException, UpdateException, PermissionBackendException, IOException { if (!isChangeDeletable(rsrc)) { throw new MethodNotAllowedException("delete not permitted"); } rsrc.permissions().check(ChangePermission.DELETE); <|startfocus|> Optional<ChangeEdit> edit = editUtil.byChange(rsrc.getNotes(), rsrc.getUser()); <|endfocus|> try (BatchUpdate bu = updateFactory.create(rsrc.getProject(), rsrc.getUser(), TimeUtil.nowTs())) { Change.Id id = rsrc.getChange().getId(); bu.addOp(id, opFactory.create(id)); if (edit.isPresent()) { bu.addOp( id, new BatchUpdateOp() { @Override public boolean updateChange(ChangeContext ctx) throws Exception { editUtil.delete(edit.get()); return true; } }); } bu.execute(); } return Response.none(); } @Override
<|startcomment|> nit: use an optional (fits better into the Stream you use in the caller) <|endcomment|> <|startfocus|> public Change getUpdatedChange() { return updatedChange; <|endfocus|>
<|startcomment|> This is most likely going to cause a warning that the resource should be managed by try-with-resource. <|endcomment|>  Project.NameKey key = new Project.NameKey(projectName); // Remove from the jgit cache cleanCache(key); FileUtils.deleteDirectory(gitDirectory); projectCache.remove(key); sendProjectDeletedEvent(projectName); return true; } catch (IOException e) { LOG.error("Cannot clean-up output Git directory " + gitDirectory); return false; } } private void cleanCache(Project.NameKey key) throws IOException { <|startfocus|> Repository repository = repoManager.openRepository(key); repository.close(); RepositoryCache.close(repository); <|endfocus|> } private void sendProjectDeletedEvent(String projectName) { ProjectDeletedListener.Event event = new ProjectDeletedListener.Event() { @Override public String getProjectName() { return projectName; } @Override public NotifyHandling getNotify() { return NotifyHandling.NONE; } }; for (ProjectDeletedListener l : deletedListeners) { try { l.onProjectDeleted(event); } catch (RuntimeException e) { LOG.warn("Failure in ProjectDeletedListener", e); } } } } 
<|startcomment|> Instead of commenting it, just rename cleanCache to cleanJGitCache, so that you don't need a comment on it. <|endcomment|>  public boolean rollback() { File gitDirectory = destinationDirectory; if (!gitDirectory.exists()) { return false; } try { String projectName = organisation + "/" + repository; Project.NameKey key = new Project.NameKey(projectName); <|startfocus|> // Remove from the jgit cache cleanCache(key); <|endfocus|> FileUtils.deleteDirectory(gitDirectory); projectCache.remove(key); sendProjectDeletedEvent(projectName); return true; } catch (IOException e) { LOG.error("Cannot clean-up output Git directory " + gitDirectory); return false; }
<|startcomment|> Why was this split to a variable? Local debugging? <|endcomment|>  this.currentConfig = loadConfig(); this.currentConfigTs = getLastModified(currentConfig); this.replicationQueue = replicationQueue; } private static long getLastModified(ReplicationFileBasedConfig cfg) { return FileUtil.lastModified(cfg.getCfgPath()); } private ReplicationFileBasedConfig loadConfig() throws ConfigInvalidException, IOException { return new ReplicationFileBasedConfig(site, destinationFactory, pluginDataDir); } private synchronized boolean isAutoReload() { <|startfocus|> boolean autoReload = currentConfig.getConfig().getBoolean("gerrit", "autoReload", false); return autoReload; <|endfocus|> } @Override public synchronized List<Destination> getDestinations(FilterType filterType) { reloadIfNeeded(); return currentConfig.getDestinations(filterType); } private void reloadIfNeeded() { reload(false); } @VisibleForTesting public void forceReload() { reload(true); } private void reload(boolean force) { if (force || isAutoReload()) { ReplicationQueue queue = replicationQueue.get(); long lastModified = getLastModified(currentConfig); try { if (force || (lastModified > currentConfigTs
<|startcomment|> Are you sure this condition is right? If GWT is disabled, this condition would always be false, and thus you would not set the XsrfCookie for any index path, is that what you want? I understood your CL description and this comment such that you wanted !options.enableGwtUi() || !p.equals("/") <|endcomment|>  public void configureServlets() { for (String p : POLYGERRIT_INDEX_PATHS) { // Skip XsrfCookieFilter for /, since that is already done in the GWT UI // path (UrlModule) if it is enabled. <|startfocus|> if (!p.equals("/") && options.enableGwtUi()) { <|endfocus|> filter(p).through(XsrfCookieFilter.class); } } filter("/*").through(PolyGerritFilter.class);
<|startcomment|> nits: Looks like you were in a hurry today morning :-) <|endcomment|> <|startfocus|> public ReplicateRefUpdate (String project, String ref, URIish uri, String remote) { this.project = project; this.ref = ref; this.uri = uri.toASCIIString(); this.remote = remote; <|endfocus|>
<|startcomment|> This variable rename is unnecessary in the context of this change. I will revert it. <|endcomment|>  public String persist(ReplicateRefUpdate r) { String json = GSON.toJson(r) + "\n"; String eventKey = sha1(json).name(); <|startfocus|> Path path = refUpdates().resolve(eventKey); <|endfocus|> if (Files.exists(path)) { return eventKey; } try { logger.atFine().log("CREATE %s (%s)", path, r); Files.write(path, json.getBytes(UTF_8)); } catch (IOException e) { logger.atWarning().withCause(e).log("Couldn't persist event %s", json); } return eventKey;
<|startcomment|> The ReplicateRefUpdate doesn't implement the toString() method, therefore the output of this log will be useless. Either log as in the previous PS and unpack r here (preferred) or implement the toString() method. <|endcomment|>  public String persist(ReplicateRefUpdate r) { String json = GSON.toJson(r) + "\n"; String eventKey = sha1(json).name(); Path path = refUpdates().resolve(eventKey); if (Files.exists(path)) { return eventKey; } try { <|startfocus|> logger.atFine().log("CREATE %s (%s)", path, r); Files.write(path, json.getBytes(UTF_8)); <|endfocus|> } catch (IOException e) { logger.atWarning().withCause(e).log("Couldn't persist event %s", json); } return eventKey;
<|startcomment|> Use also variable name 'file' here to be consistent with the (reverted) variable name at line 69. <|endcomment|>  public void delete(ReplicateRefUpdate r) { String taskJson = GSON.toJson(r) + "\n"; String taskKey = sha1(taskJson).name(); <|startfocus|> Path path = refUpdates().resolve(taskKey); <|endfocus|> try { logger.atFine().log("DELETE %s (%s)", path, r); Files.delete(refUpdates().resolve(taskKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", taskKey); }
<|startcomment|> trailing spaces <|endcomment|>  public void delete(ReplicateRefUpdate r) { String taskJson = GSON.toJson(r) + "\n"; String taskKey = sha1(taskJson).name(); <|startfocus|> Path path = refUpdates().resolve(taskKey); <|endfocus|> try { logger.atFine().log("DELETE %s (%s)", path, r); Files.delete(refUpdates().resolve(taskKey)); } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", taskKey); }
<|startcomment|> Reuse the path variable from the line 87 <|endcomment|>  public void delete(ReplicateRefUpdate r) { String taskJson = GSON.toJson(r) + "\n"; String taskKey = sha1(taskJson).name(); Path path = refUpdates().resolve(taskKey); try { <|startfocus|> logger.atFine().log("DELETE %s (%s)", path, r); Files.delete(refUpdates().resolve(taskKey)); <|endfocus|> } catch (IOException e) { logger.atSevere().withCause(e).log("Error while deleting event %s", taskKey); }
<|startcomment|> This line should not have been removed. Although it's a correct revert of the original change, there was a followup change that uses it, so removing it breaks the build. <|endcomment|> import static com.google.gerrit.gpg.testutil.TestKeys.validKeyWithExpiration; import static com.google.gerrit.gpg.testutil.TestKeys.validKeyWithSecondUserId; import static com.google.gerrit.gpg.testutil.TestKeys.validKeyWithoutExpiration; import static com.google.gerrit.server.StarredChangesUtil.DEFAULT_LABEL; import static com.google.gerrit.server.StarredChangesUtil.IGNORE_LABEL; import static com.google.gerrit.server.account.externalids.ExternalId.SCHEME_GPGKEY; import static com.google.gerrit.server.group.SystemGroupBackend.ANONYMOUS_USERS; <|startfocus|> import static com.google.gerrit.server.group.SystemGroupBackend.REGISTERED_USERS; <|endfocus|> import static java.nio.charset.StandardCharsets.UTF_8; import static java.util.stream.Collectors.toList; import static java.util.stream.Collectors.toSet; import static org.eclipse.jgit.lib.Constants.OBJ_BLOB; import static org.junit.Assert.fail; import com.google.common.collect.FluentIterable; import com.google.common.collect.ImmutableList; import com.google.common.collect.ImmutableMap; import com.google.common.collect.ImmutableSet; import com.google.common.collect.ImmutableSetMultimap; import com.google.common.collect.Iterables; import com.google.common.io.BaseEncoding; import com.google.common.util.concurrent.AtomicLongMap; import com.google.gerrit.acceptance.AbstractDaemonTest;
<|startcomment|> nit: you could inline this as we did for eventTopic.topic() <|endcomment|>  } return fileConfig; }); } return ofInstance(config); } public static class Kafka { private final Map<EventTopic, String> eventTopics; private final String bootstrapServers; Kafka(Supplier<Config> config) { this.bootstrapServers = getString( config, KAFKA_SECTION, null, "bootstrapServers", DEFAULT_KAFKA_BOOTSTRAP_SERVERS); this.eventTopics = new HashMap<>(); for (EventTopic eventTopic : EventTopic.values()) { <|startfocus|> String topicConfigKey = eventTopic.topicAliasKey(); <|endfocus|> eventTopics.put( eventTopic, getString(config, KAFKA_SECTION, null, topicConfigKey, eventTopic.topic())); } } public String getTopicAlias(EventTopic topic) { return eventTopics.get(topic); } public String getBootstrapServers() { return bootstrapServers; } private static String getString( Supplier<Config> cfg, String section, String subsection, String name, String defaultValue) { String value = cfg.get().getString(section, subsection, name); if (!Strings.isNullOrEmpty(value)) { return value; }
<|startcomment|> nit: tab indention <|endcomment|>  reloadConfig(); waitForEmptyTasks(); Project.NameKey targetProject = createProject("projectreplica"); String newBranch = "refs/heads/mybranch"; String master = "refs/heads/master"; BranchInput input = new BranchInput(); input.revision = master; gApi.projects().name(project.get()).branch(newBranch).create(input); assertThat(listReplicationTasks("refs/heads/(mybranch|master)")).hasSize(2); try (Repository repo = repoManager.openRepository(targetProject); <|startfocus|> Repository sourceRepo = repoManager.openRepository(project)) { <|endfocus|> waitUntil(() -> checkedGetRef(repo, newBranch) != null); Ref masterRef = getRef(sourceRepo, master); Ref targetBranchRef = getRef(repo, newBranch); assertThat(targetBranchRef).isNotNull(); assertThat(targetBranchRef.getObjectId()).isEqualTo(masterRef.getObjectId()); } } @Test public void shouldReplicateNewBranchToTwoRemotes() throws Exception { Project.NameKey targetProject1 = createProject("projectreplica1"); Project.NameKey targetProject2 = createProject("projectreplica2"); 
<|startcomment|> optional: the message in the log and the exception could be extracted to a string and reused (unless the exception message intentionally omits the project name that is included in the log.) <|endcomment|>  Change updatedChange = op.merge(change, submitter, true, input, false); if (updatedChange.isMerged()) { return change; } logger.atWarning().log( "change %s of project %s unexpectedly had status %s after submit attempt", updatedChange.getId(), updatedChange.getProject(), updatedChange.getStatus()); throw new RestApiException( String.format( <|startfocus|> "change %s unexpectedly had status %s after submit attempt", updatedChange.getId(), updatedChange.getStatus())); <|endfocus|> } } /** * Returns a message describing what prevents the current change from being submitted - or null. * This method only considers parent changes, and changes in the same topic. The caller is * responsible for making sure the current change to be submitted can indeed be submitted * (permissions, submit rules, is not a WIP...) * * @param cd the change the user is currently looking at * @param cs set of changes to be submitted at once
<|startcomment|> I would prefer to factor this out to a method. It will make this easier to read, and can also potentially be reused in future tests. <|endcomment|>  config.save(); super.setUpTestPlugin(); pluginDataDir = plugin.getSysInjector().getInstance(Key.get(Path.class, PluginData.class)); storagePath = pluginDataDir.resolve("ref-updates"); } @Test public void shouldReplicateNewProject() throws Exception { setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Project.NameKey sourceProject = createProject("foo"); assertThat(listReplicationTasks("refs/meta/config")).hasSize(1); <|startfocus|> waitUntil(() -> gitPath.resolve(sourceProject + "replica.git").toFile().isDirectory()); <|endfocus|> ProjectInfo replicaProject = gApi.projects().name(sourceProject + "replica").get(); assertThat(replicaProject).isNotNull(); } @Test public void shouldReplicateNewChangeRef() throws Exception { Project.NameKey targetProject = createProject("projectreplica"); setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Result pushResult = createChange(); RevCommit sourceCommit = pushResult.getCommit();
<|startcomment|> Add a new method: private boolean projectExists(Project.NameKey name) { try (Repository r = repoManager.openRepository(name)) { return true; } catch (Exception e) { return false; } } and then this line can be just: waitUntil(() -> projectExists(new Project.NameKey(sourceProject + "replica.git"))); <|endcomment|>  } @Test public void shouldReplicateNewProject() throws Exception { setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Project.NameKey sourceProject = createProject("foo"); assertThat(listReplicationTasks("refs/meta/config")).hasSize(1); <|startfocus|> waitUntil(() -> gitPath.resolve(sourceProject + "replica.git").toFile().isDirectory()); <|endfocus|> ProjectInfo replicaProject = gApi.projects().name(sourceProject + "replica").get(); assertThat(replicaProject).isNotNull(); } @Test public void shouldReplicateNewChangeRef() throws Exception { Project.NameKey targetProject = createProject("projectreplica"); setReplicationDestination("foo", "replica", ALL_PROJECTS); reloadConfig(); waitForEmptyTasks(); Result pushResult = createChange(); RevCommit sourceCommit = pushResult.getCommit(); String sourceRef = pushResult.getPatchSet().getRefName(); assertThat(listReplicationTasks("refs/changes/\\d*/\\d*/\\d*")).hasSize(1); try (Repository repo = repoManager.openRepository(targetProject)) {
<|startcomment|> static variable convention should be followed. <|endcomment|>  private static final String CONFIG_FILE_PATH = "/data/local/tmp/"; private static final String CLOUD_PROPERTY_FILE = "cloud.properties"; private static boolean mIsCbInvoked = CALLBACK_NOT_INVOKED; private enum CloudAuth { SIGNUP, SIGNIN, SIGNOUT }; private enum LogLevel { INFO, ERROR, DEBUG }; private static Properties props; private static String filePath; private static String fileName; private static File file; public static CloudAuth mMethodName; <|startfocus|> public static String s_CloudUid; public static String s_CloudAccesstoken; public static String authCode; public static String mErrorMessage; <|endfocus|> public static void init(String fileDir) { props = new Properties(); ReadConfigPropFile.readConfigFile(CONFIG_FILE_PATH); file = new File(fileDir + CLOUD_PROPERTY_FILE); if (!file.exists()) { getAuthCode(); } } private static void getAuthCode() { Log.d(TAG, "getAuthCode IN"); GetAuthCode getContent = new GetAuthCode(); try {
<|startcomment|> static variable convention should be followed. <|endcomment|>  private static final String CLOUD_PROPERTY_FILE = "cloud.properties"; private static boolean mIsCbInvoked = CALLBACK_NOT_INVOKED; private enum CloudAuth { SIGNUP, SIGNIN, SIGNOUT }; private enum LogLevel { INFO, ERROR, DEBUG }; private static Properties props; private static String filePath; private static String fileName; private static File file; public static CloudAuth mMethodName; <|startfocus|> public static String s_CloudUid; public static String s_CloudAccesstoken; public static String authCode; public static String mErrorMessage; <|endfocus|> public static void init(String fileDir) { props = new Properties(); ReadConfigPropFile.readConfigFile(CONFIG_FILE_PATH); file = new File(fileDir + CLOUD_PROPERTY_FILE); if (!file.exists()) { getAuthCode(); } } private static void getAuthCode() { Log.d(TAG, "getAuthCode IN"); GetAuthCode getContent = new GetAuthCode(); try { OcAccountManagerHelper.authCode = getContent.execute().get();
<|startcomment|> private / protected or default? <|endcomment|>  + JUSTWORKS_SERVER_UNOWNED_CBOR_02 + " 1"; public static final String START_PRE_CONFIG_SERVER_01 = "./iotivity_pm_server " + PRECONFIG_SERVER_UNOWNED_CBOR_01 + " 3"; public static final String START_RE_SERVER = "./iotivity_re_server"; public static final String PROVISION_DB_FILE = "./Pdm.db"; public static final String DEVICE_PROP_CBOR_FILE = "./device_properties.dat"; <|startfocus|> TestBroadCast mTestBroadCast; <|endfocus|> protected RIHelperCommon(IoTivityTc iotivityTcObj) { s_helperContext = iotivityTcObj.getInstrumentation().getTargetContext(); s_filePath = s_helperContext.getFilesDir().getPath(); s_sqLPath = s_helperContext.getFilesDir().getAbsolutePath() .replace(FILES, DATABASES) + File.separator; mTestBroadCast = new TestBroadCast(s_helperContext); } public boolean configClientServerPlatform() { PlatformConfig cfg = new PlatformConfig(s_helperContext, ServiceType.IN_PROC, ModeType.CLIENT_SERVER, "0.0.0.0", 0, QualityOfService.HIGH); OcPlatform.Configure(cfg);
<|startcomment|> space <|endcomment|>  * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. ******************************************************************/ package org.iotivity.testcase; import android.util.Log; public class IoTivityLog{ <|startfocus|> <|endfocus|> public static void v(String tag, String format) { Log.v(tag, format); } public static void d(String tag, String format) { Log.d(tag, format); } public static void i(String tag, String format) { Log.i(tag, format); } public static void w(String tag, String format) { Log.w(tag, format); } public static void e(String tag, String format) { Log.e(tag, format); } } 
<|startcomment|> space to be removed <|endcomment|>  * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. ******************************************************************/ package org.iotivity.testcase; import java.util.logging.Logger; public class IoTivityLog{ <|startfocus|> <|endfocus|> public static void v(String tag, String format) { System.out.println(tag + " : " + format); } public static void d(String tag, String format) { System.out.println(tag + " : " + format); } public static void i(String tag, String format) { System.out.println(tag + " : " + format); } public static void w(String tag, String format) { System.out.println(tag + " : " + format); } public static void e(String tag, String format) {
<|startcomment|> spaces in file to be removed <|endcomment|>  public void testConfigureServerInProc_SRC_P() { try { <|startfocus|> PlatformConfig cfg = new PlatformConfig(ServiceType.IN_PROC, <|endfocus|> ModeType.SERVER, "0.0.0.0", 0, QualityOfService.HIGH); OcPlatform.Configure(cfg); } catch (Exception e) { e.printStackTrace(); fail("Exception occured"); }
<|startcomment|> static variable convention should be followed. <|endcomment|> import org.iotivity.base.QualityOfService; import org.iotivity.base.RequestHandlerFlag; import org.iotivity.base.RequestType; import org.iotivity.base.ResourceProperty; import org.iotivity.base.ServiceType; import org.iotivity.base.OcRepresentation; import org.iotivity.base.OcResource; import org.iotivity.base.OcResource.OnObserveListener; import org.iotivity.base.OcResourceHandle; import org.iotivity.testcase.IoTivityLog; import org.iotivity.testcase.IoTivityTc; import org.iotivity.test.ri.common.RIHelperCommon; public class RIHelper extends RIHelperCommon implements IRIConstants { <|startfocus|> private static RIHelper riHelperInstance = null; <|endfocus|> private final String LOG_TAG = this .getClass().getSimpleName(); private OcResourceHandle m_resourceHandle = null; public EnumSet<ResourceProperty> m_resourceProperty; public static final String TEMPERATURE_RESOURCE_QUERY = OcPlatform.WELL_KNOWN_QUERY + "?rt=" + RESOURCE_TYPE_TEMPERATURE; private OcRepresentation m_representation = null; // new OcRepresentation(); public int m_temp; public int m_hour; public static boolean s_isServerOk; public static String s_errorMsg;
<|startcomment|> Tab to be removed <|endcomment|>  * Map<String, String> queryParamsMap, * OnPostListener onPostListener, * QualityOfService qualityOfService) * @test_data 1. resourceUri "/test/ri/android/temperature" * 2. resourceTypeName "oic.r.temperature" * 3. resourceInterface DEFAULT_INTERFACE * 4. entityHandler entity handler * 5. resourcePropertySet indicates property of the resource * 6. representation representation to set * 7. queryParamsMap map with query paramter and value <|startfocus|> * ` 8. onPostListener event handler <|endfocus|> * 9. qualityOfService High * @pre_condition Configure platform for client server mode * @procedure 1. Perform registerResource() API * 2. Perform findResource() API with resource type in query * 3. Check if callback is called * 4. Check if temperature resource is found * 5. Perform post() API(with qos) on the found temperature resource * 6. Check if server can get the post request and send response correctly
<|startcomment|> unwanted space to be removed <|endcomment|>  public void onReceive(Context context, Intent intent) { Log.d(TAG, "BroadcastReceiver Invoked"); Log.d(TAG, "Recieved Braodcasted MSG : " + intent.getStringExtra("key")); <|startfocus|> <|endfocus|> if (mTcpClient != null) { mTcpClient.sendMessage(intent.getStringExtra("key")); } else { Log.e(TAG, "TCP Client is not initialized"); }
<|startcomment|> space needs to be removed <|endcomment|>  (byte) 0x66, (byte) 0x11, (byte) 0xa5, (byte) 0x84, (byte) 0x99, (byte) 0x8d, (byte) 0x0d, (byte) 0xbd, (byte) 0xb1, (byte) 0x54, (byte) 0xbb, (byte) 0xc5, (byte) 0x4f, (byte) 0xed, (byte) 0x86, (byte) 0x9a, (byte) 0x66, (byte) 0x11 }; PMConstants.mErrorMessage = PMConstants.EMPTY_STRING; <|startfocus|> mPMHelper.clearAll(); <|endfocus|> mPMHelper.stopServers(); mPMHelper.startSecuredServer(mPMHelper.START_JUSTWORKS_SERVER_01); mPMHelper.startSecuredServer(mPMHelper.START_JUSTWORKS_SERVER_02); PMHelper.delay(5); // create platform config mPMHelper.copyCborFromAsset(PMConstants.OIC_CLIENT_CBOR_DB_FILE); mPMHelper.configClientServerPlatform( PMConstants.OIC_CLIENT_CBOR_DB_FILE); mPMHelper.initOICStack(PMHelper.s_sqLPath, PMConstants.OIC_SQL_DB_FILE); } protected void tearDown() throws Exception { mPMHelper.stopServers(); mPMHelper.clearAll(); super.tearDown(); } /**
<|startcomment|> space needs to be removed in the file <|endcomment|>  public static final String OIC_JWSERVER_CBOR_DB_FILE_2 = "oic_svr_db_server.dat"; public static final String OIC_DP_CLIENT_CBOR_DB_FILE = "oic_svr_db_client_directpairing.dat"; public static final String OIC_CLOUD_CLIENT = "cloud.dat"; public static final String OIC_SQL_DB_FILE = "Pdm.db"; public static final String OIC_MOT_SQL_DB_FILE = "MOT_Pdm.db"; public static final String SERVER_SQL_DB_FILE = "ServerPdm.db"; <|startfocus|> <|endfocus|> //Cloud Resource public static final String CERT_SERIAL_ONE = "1"; // ACL Related Resource public static final String DEFAULT_ROWNER_ID = "61646d69-6e44-6576-6963-655555494430"; public static final String DEFAULT_RESOURCES = "*"; public static final String HREF_RESOURCES_1A = "/a/device1a"; public static final String HREF_RESOURCES_1B = "/a/device1b"; public static final String HREF_RESOURCES_2A = "/a/device2a"; public static final String HREF_RESOURCES_2B = "/a/device2b";
<|startcomment|> Tab needs to be removed <|endcomment|>  try { m_resource.put(m_rep, qpMap, onPut); } catch (Exception e) { e.printStackTrace(); fail("Exception occured"); } } /** * @objective Test put function with negative basic way using null representation * @target put(OcRepresentation representation, *Map<String, String> queryParamsMap, *OnPutListener onPutListener) * @test_data 1. representation null <|startfocus|> * 2. queryParamsMap map with query paramter and value * ` 3. OnPutListener event handler <|endfocus|> * @pre_condition 1. configure platform * 2. construct resource object * @procedure Call put() API using resource * @post_condition None * @expected OcException should occur * @see void Configure(PlatformConfig platformConfig) * @see OcResource constructResourceObject( * String host, * String uri, * EnumSet<OcConnectivityType> connectivityTypeSet, * boolean isObservable, * List<String> resourceTypeList, * List<String> interfaceList) * @since 2016-09-05 **/
<|startcomment|> space needs to be removed in file <|endcomment|>  public void testConfigureServerNon_SRC_P() { try { <|startfocus|> PlatformConfig cfg = new PlatformConfig(ServiceType.IN_PROC, <|endfocus|> ModeType.SERVER, "0.0.0.0", 0, QualityOfService.LOW); OcPlatform.Configure(cfg); } catch (Exception e) { e.printStackTrace(); fail("Exception occured"); }
<|startcomment|> Is the IP hardcoding necessary or this needs to be changed on machine we run? <|endcomment|>  String DEVICE_TYPE_AC = "AirCondition"; String RESOURCE_URI_TEMPERATURE = "/test/ri/android/temperature"; String RESOURCE_TYPE_TEMPERATURE = "oic.r.temperature"; String RESOURCE_URI_LIGHT = "/a/light"; String RESOURCE_TYPE_LIGHT = "core.light"; String RESOURCE_URI_FAN = "/a/fan"; String RESOURCE_TYPE_FAN = "core.fan"; <|startfocus|> String HOST = "coap://192.168.1.2:5000"; <|endfocus|> int INT_ZERO = 0; int INT_ONE = 1; int INT_TWO = 2; int INT_MINUS_ONE = -1; int CALLBACK_WAIT_DEFAULT = 5; int CALLBACK_WAIT_MAX = 10; int CALLBACK_WAIT_MIN = 1; int SUCCESS_RESPONSE = 0; int COAP_RESPONSE_CODE_SUCCESS = 205; int COAP_RESPONSE_CODE_CREATED = 201; int COAP_RESPONSE_CODE_DELETED = 202;
<|startcomment|> space needs to be removed <|endcomment|>  public static RIHelper getInstance(IoTivityTc iotivityTcObj) { new OcRepresentation(); <|startfocus|> <|endfocus|> Lock mutex = new ReentrantLock(); if (s_mRiHelperInstance == null) { mutex.lock(); if (s_mRiHelperInstance == null) { IoTivityLog.i("RIHelper", "Inside Helper"); s_mRiHelperInstance = new RIHelper(iotivityTcObj); } mutex.unlock(); } return s_mRiHelperInstance;
<|startcomment|> Should any new files have 2018 <|endcomment|>  * //****************************************************************** * // <|startfocus|> * // Copyright 2016 Intel Corporation All Rights Reserved. <|endfocus|> * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= * // * // Licensed under the Apache License, Version 2.0 (the "License"); * // you may not use this file except in compliance with the License. * // You may obtain a copy of the License at * // * // http://www.apache.org/licenses/LICENSE-2.0 * // * // Unless required by applicable law or agreed to in writing, software * // distributed under the License is distributed on an "AS IS" BASIS, * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * // See the License for the specific language governing permissions and * // limitations under the License. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import org.iotivity.base.OcException;
<|startcomment|> 2018 <|endcomment|>  * //****************************************************************** * // <|startfocus|> * // Copyright 2016 Intel Corporation All Rights Reserved. <|endfocus|> * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= * // * // Licensed under the Apache License, Version 2.0 (the "License"); * // you may not use this file except in compliance with the License. * // You may obtain a copy of the License at * // * // http://www.apache.org/licenses/LICENSE-2.0 * // * // Unless required by applicable law or agreed to in writing, software * // distributed under the License is distributed on an "AS IS" BASIS, * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * // See the License for the specific language governing permissions and * // limitations under the License. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import org.iotivity.base.OcException;
<|startcomment|> Any older files 2016-2018 <|endcomment|>  * //****************************************************************** * // <|startfocus|> * // Copyright 2016 Intel Corporation All Rights Reserved. <|endfocus|> * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= * // * // Licensed under the Apache License, Version 2.0 (the "License"); * // you may not use this file except in compliance with the License. * // You may obtain a copy of the License at * // * // http://www.apache.org/licenses/LICENSE-2.0 * // * // Unless required by applicable law or agreed to in writing, software * // distributed under the License is distributed on an "AS IS" BASIS, * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * // See the License for the specific language governing permissions and * // limitations under the License. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import android.graphics.Bitmap; 
<|startcomment|> Any older files 2016-2018 <|endcomment|>  * //****************************************************************** * // <|startfocus|> * // Copyright 2016 Intel Corporation All Rights Reserved. <|endfocus|> * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= * // * // Licensed under the Apache License, Version 2.0 (the "License"); * // you may not use this file except in compliance with the License. * // You may obtain a copy of the License at * // * // http://www.apache.org/licenses/LICENSE-2.0 * // * // Unless required by applicable law or agreed to in writing, software * // distributed under the License is distributed on an "AS IS" BASIS, * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * // See the License for the specific language governing permissions and * // limitations under the License. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import org.iotivity.base.OcException;
<|startcomment|> Should this be media/control or mediaControl instead dash <|endcomment|>  /** * MediaControl * * This class is used by UpnpAvClientActivity to create an object representation of a remote media control resource * and update the values depending on the server response */ public class MediaControl extends Service { public static final String OIC_TYPE_MEDIA_CONTROL = "oic.r.media.control"; <|startfocus|> public static final String OCF_OIC_URI_PREFIX_MEDIA_CONTROL = "/ocf/media-control/"; public static final String UPNP_OIC_URI_PREFIX_MEDIA_CONTROL = "/upnp/media-control/"; <|endfocus|> public static final String STATE_KEY = "playState"; public static final boolean DEFAULT_STATE = false; public static final String SPEED_KEY = "mediaSpeed"; public static final double DEFAULT_SPEED = 1.0; public static final String LOCATION_KEY = "mediaLocation"; public static final String DEFAULT_LOCATION = "0"; public static final String LAST_ACTION_KEY = "lastAction"; public static final String DEFAULT_LAST_ACTION = "stop"; public static final String ACTIONS_KEY = "actions"; private boolean mPlayState;
<|startcomment|> Any older files 2016-2018 <|endcomment|>  * //****************************************************************** * // <|startfocus|> * // Copyright 2016 Intel Corporation All Rights Reserved. <|endfocus|> * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= * // * // Licensed under the Apache License, Version 2.0 (the "License"); * // you may not use this file except in compliance with the License. * // You may obtain a copy of the License at * // * // http://www.apache.org/licenses/LICENSE-2.0 * // * // Unless required by applicable law or agreed to in writing, software * // distributed under the License is distributed on an "AS IS" BASIS, * // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * // See the License for the specific language governing permissions and * // limitations under the License. * // * //-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import android.app.Activity;
<|startcomment|> I would use call this RESOURCE_TYPE <|endcomment|>  * limitations under the License. * *-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= */ package org.iotivity.base.examples; import org.iotivity.base.OcException; import org.iotivity.base.OcPlatform; import org.iotivity.base.PayloadType; /** * Light * * This class represents a light resource */ public class Light { <|startfocus|> static public final String RES_TYPE = "oic.d.light"; static public final String DEVICE_RES_TYPE = "oic.wk.d"; <|endfocus|> private Switch switchRes; private Brightness brightnessRes; private String deviceName; public Light(String name, String uuid, boolean powerOn, int brightness, LightControlPanel ui) { deviceName = name; switchRes = new Switch(uuid); switchRes.setValue(powerOn); switchRes.addObserver(ui); ui.addObserver(switchRes); OcfLightServer.msg("Created switch resource: " + switchRes); brightnessRes = new Brightness(uuid); brightnessRes.setBrightness(brightness); brightnessRes.addObserver(ui); ui.addObserver(brightnessRes);
<|startcomment|> for some reason this does not feel like it belongs in the brightness resource. Brightness does not have a power option so it feels like this should go some place that knows about the power option. <|endcomment|> <|startfocus|> public void update(boolean powerOn, int brightness) { <|endfocus|> setBrightness(brightness); notifyObservers(null);
<|startcomment|> tab <|endcomment|>  public void testUri() { OCResource r = new OCResource(); assertNotNull(r); r.setUri("/foo/bar"); assertEquals("/foo/bar", r.getUri()); } @Test public void testTypes() { OCResource r = new OCResource(); assertNotNull(r); //TODO properly encode/decode the OCResource oc_string_array_t types. //r.setTypes(value); // failure purposely done till the setTypes/getProperties methods are updated with non SWIG type values. fail("Not yet implemented"); } <|startfocus|> <|endfocus|> @Test public void testInterfaces() { OCResource r = new OCResource(); assertNotNull(r); r.setInterfaces(OCInterfaceMask.RW); assertEquals(OCInterfaceMask.RW, r.getInterfaces()); } @Test public void testDefaultInterface() { OCResource r = new OCResource(); assertNotNull(r); r.setDefaultInterface(OCInterfaceMask.BASELINE); assertEquals(OCInterfaceMask.BASELINE, r.getDefaultInterface()); } @Test public void testProperties(){ OCResource r = new OCResource(); assertNotNull(r);
<|startcomment|> StopObserveTriggerHandler does not exist <|endcomment|>  } else if (response.getCode() == OCStatus.OC_STATUS_CREATED) { System.out.println("\tPUT response: CREATED"); } else { System.out.println("\tPUT response code " + response.getCode().toString() + "(" + response.getCode() + ")"); } ObserveLightResponseHandler observerLight = new ObserveLightResponseHandler(); OCMain.doObserve(Light.server_uri, Light.server, null, OCQos.LOW_QOS, observerLight); StopObserveTriggerHandler stopObserve = new StopObserveTriggerHandler(); <|startfocus|> OCMain.setDelayedCallback(stopObserve, 5); <|endfocus|> System.out.println("Sent OBSERVE request");
<|startcomment|> i assume you are sure the clock time is always returned in Nanos so no need to do extra calculations. <|endcomment|>  private void eventLoop() { while (!quit) { long nextEvent = OCMain.mainPoll(); lock.lock(); try { if (nextEvent == 0) { cv.await(); } else { long now = OCClock.clockTime(); <|startfocus|> long timeToWait = nextEvent - now; <|endfocus|> cv.awaitNanos(timeToWait); } } catch (InterruptedException e) { Log.d(TAG, e.getMessage()); } finally { lock.unlock(); } }
<|startcomment|> maybe we should have the platform Android and the device "Kishen's Android Phone" :) not really critical. <|endcomment|>  public int initialize() { Log.d(TAG, "inside MyInitHandler.initialize()"); <|startfocus|> int ret = OCMain.initPlatform("Apple"); ret |= OCMain.addDevice("/oic/d", "oic.d.phone", "Kishen's IPhone", "ocf.1.0.0", "ocf.res.1.0.0"); <|endfocus|> return ret;
<|startcomment|> repOpenObject() might be more intuative (at least for me) <|endcomment|>  public void testValueObject() { OCMain.repNewBuffer(1024); /* * { * "my_object": { * "a": 1, * "b": false, * "c": "three" * } * } */ CborEncoder root = OCMain.repBeginRootObject(); assertEquals(0, OCMain.repGetCborErrno()); <|startfocus|> CborEncoder myObject = OCMain.repSetObject(root, "my_object"); <|endfocus|> assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetInt(myObject, "a", 1); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetBoolean(myObject, "b", false); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetTextString(myObject, "c", "three"); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repCloseObject(root, myObject); OCMain.repEndRootObject(); assertEquals(0, OCMain.repGetCborErrno()); OCMain.repSetPool(new OCMemoryBuffer()); OCRepresentation rep = OCMain.repGetOCRepresentaionFromRootObject(); assertNotNull(rep); OCValue v = new OCValue(); assertNotNull(v);
<|startcomment|> "... .initialize()" <|endcomment|>  public int initialize() { <|startfocus|> System.out.println("inside ObtInitHandler.initiliaze()"); <|endfocus|> int ret = OCMain.initPlatform("OCF"); ret |= OCMain.addDevice("/oic/d", "oic.d.phone", "OBT", "ocf.1.0.0", "ocf.res.1.0.0"); return ret;
<|startcomment|> -1 is retuned if failed or nothing found, should be '>' (as above) or '!=' <|endcomment|>  System.out.println("################################################"); System.out.println("\nSelect option: "); } private static void discoverUnownedDevices() { System.out.println("Discovering un-owned devices"); appSyncLock.lock(); if ( 0 > OCObt.discoverUnownedDevices(unownedDeviceHandler)) { System.err.println("ERROR discovering un-owned Devices."); } appSyncLock.unlock(); } private static void discoverOwnedDevices() { appSyncLock.lock(); <|startfocus|> if (0 < OCObt.discoverOwnedDevices(ownedDeviceHandler)) { <|endfocus|> System.err.println("ERROR discovering owned Devices."); } appSyncLock.unlock(); } public static void main(String[] args) { quit = false; mainThread = Thread.currentThread(); Runtime.getRuntime().addShutdownHook(shutdownHook); String osName = System.getProperty("os.name"); boolean isLinux = (osName != null) && osName.toLowerCase().contains("linux"); System.out.println("OS Name = " + osName + ", isLinux = " + isLinux); String creds_path = "./onboarding_tool_creds/";
<|startcomment|> need parens around j+1 otherwise each is taken a string concat, ie "Enter resource type: (j + 1) + " " <|endcomment|>  break; case 3: OCObt.aceResourceSetWc(res, OCAceWildcard.OC_ACE_WC_ALL_NON_DISCOVERABLE); break; default: break; } } } System.out.print("Enter number of resource types [0-None]: "); c = scanner.nextInt(); if (c > 0 && c <= MAX_NUM_RT) { OCObt.aceResoruceSetNumRt(res, c); int j = 0; while (j < c) { <|startfocus|> System.out.print("Enter resource type : " + j + 1); <|endfocus|> String rt = scanner.next(); if (rt.length() > 127) { rt = rt.substring(0, 127); } OCObt.aceResoruceBindRt(res, rt); j++; } } System.out.print("Enter number of interfaces [0-None] : "); c = scanner.nextInt(); if (c > 0 && c <= 7) { int j = 0; while (j < c) { int k; System.out.println("\n[1]: oic.if.baseline");
<|startcomment|> "...initialize()" <|endcomment|>  public int initialize() { <|startfocus|> System.out.println("inside ObtInitHandler.initiliaze()"); <|endfocus|> int ret = OCMain.initPlatform("OCF"); ret |= OCMain.addDevice("/oic/d", "oic.d.phone", "OBT", "ocf.1.0.0", "ocf.res.1.0.0"); return ret;
<|startcomment|> Should be under success case below <|endcomment|>  public void handler(OCUuid uuid, int status, Object userData) { <|startfocus|> ObtMain.ownedDevices.remove(uuid); <|endfocus|> if (status >= 0) { System.out.println("\nSuccessfully performed hard RESET to device " + OCUuidUtil.uuidToString(uuid)); } else { System.out.println("\nERROR performing hard RESET to device " + OCUuidUtil.uuidToString(uuid)); }
<|startcomment|> needs to be: long timeToWait = (NANOS_PER_SECOND / OCClock.clockSeconds()) * (nextEvent - now); <|endcomment|>  private void eventLoop() { while (!quit) { long nextEvent = OCMain.mainPoll(); lock.lock(); try { if (nextEvent == 0) { cv.await(); } else { long now = OCClock.clockTime(); <|startfocus|> long timeToWait = (NANOS_PER_SECOND / OCClock.OC_CLOCK_SECOND) * (next_event - now); <|endfocus|> cv.awaitNanos(timeToWait); } } catch (InterruptedException e) { Log.d(TAG, e.getMessage()); } finally { lock.unlock(); } }
<|startcomment|> userData is undefined here ? <|endcomment|>  public void handler(OCRequest request, int interfaces) { Log.d(TAG, "inside Put Light Request Handler"); <|startfocus|> new PostLightRequestHandler(activity).handler(request, interfaces, userData); <|endfocus|>
<|startcomment|> move to top of file with the other member variables. <|endcomment|>  OCMain.resourceSetRequestHandler(resource, OCMethod.OC_POST, new PostLightRequestHandler(activity, light)); OCMain.addResource(resource); } @Override public void requestEntry() { Log.d(TAG, "inside MyInitHandler.requestEntry()"); } @Override public void signalEventLoop() { Log.d(TAG, "inside MyInitHandler.signalEventLoop()"); activity.lock.lock(); try { activity.cv.signalAll(); } finally { activity.lock.unlock(); } } <|startfocus|> private Light light; <|endfocus|> } 
<|startcomment|> do we want this to read "systemInit"? <|endcomment|>  String creds_path = "./simpleserver_creds/"; java.io.File directory = new java.io.File(creds_path); if (!directory.exists()) { directory.mkdir(); } System.out.println("Storage Config PATH : " + directory.getPath()); if (0 != OCStorage.storageConfig(directory.getPath())) { System.err.println("Failed to setup Storage Config."); } // Note: If using a factory presets handler, <|startfocus|> // the factory presets handler must be set prior to calling init(). // The init() function will call the factory presets handler when set. <|endfocus|> OcUtils.setFactoryPresetsHandler(new FactoryPresetsHandler()); MyInitHandler handler = new MyInitHandler(platform); platform.systemInit(handler); try { Thread.sleep(Long.MAX_VALUE); } catch (InterruptedException e) { System.err.println(e); } System.exit(0);
<|startcomment|> do we want this to read "systemInit"? <|endcomment|>  if (!directory.exists()) { directory.mkdir(); } System.out.println("Storage Config PATH : " + directory.getPath()); if (0 != OCStorage.storageConfig(directory.getPath())) { System.err.println("Failed to setup Storage Config."); } // Note: If using a factory presets handler, <|startfocus|> // the factory presets handler must be set prior to calling init(). // The init() function will call the factory presets handler when set. <|endfocus|> OcUtils.setFactoryPresetsHandler(new FactoryPresetsHandler()); MyInitHandler handler = new MyInitHandler(platform); platform.systemInit(handler); try { Thread.sleep(Long.MAX_VALUE); } catch (InterruptedException e) { System.err.println(e); } System.exit(0);
<|startcomment|> "Get Owned Device Name Response Handler" <|endcomment|>  public void handler(OCClientResponse response) { <|startfocus|> System.out.println("Get Light Response Handler:"); <|endfocus|> OCRepresentation rep = response.getPayload(); String n = null; String di = null; while (rep != null) { switch (rep.getType()) { case OC_REP_STRING: if ("n".equals(rep.getName())) { n = rep.getValue().getString(); } if ("di".equals(rep.getName())) { di = rep.getValue().getString(); } break; default: break; } rep = rep.getNext(); } if (di != null) { ObtMain.ownedDevices.add(new OCFDeviceInfo(OCUuidUtil.stringToUuid(di), n)); }
<|startcomment|> "Get Unowned Device Name Handler" <|endcomment|>  public void handler(OCClientResponse response) { <|startfocus|> System.out.println("Get Light Response Handler:"); <|endfocus|> OCRepresentation rep = response.getPayload(); String n = null; String di = null; while (rep != null) { switch (rep.getType()) { case OC_REP_STRING: if ("n".equals(rep.getName())) { n = rep.getValue().getString(); } if ("di".equals(rep.getName())) { di = rep.getValue().getString(); } break; default: break; } rep = rep.getNext(); } if (di != null) { ObtMain.unownedDevices.add(new OCFDeviceInfo(OCUuidUtil.stringToUuid(di), n)); }
<|startcomment|> return boolean not Boolean see getBoolean(key) bellow. <|endcomment|>  } // for unit testing only static public OcRepresentation createOcRepresentaionFromRoot() throws OcCborException { OCRep.clearCborErrno(); OCRepresentation nativeRep = OCRep.getOCRepresentaionFromRootObject(); if ((nativeRep != null) && (OCRep.getCborErrno() == 0)) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to create OcRepresentation from root object"); } public String getKey() { OCRep.clearCborErrno(); return nativeRepresentation.getName(); } <|startfocus|> public Boolean getBoolean() throws OcCborException { <|endfocus|> Boolean returnValue = getValue().getBool(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get boolean"); } public Long getLong() throws OcCborException { Long returnValue = getValue().getInteger(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get long"); } public Double getDouble() throws OcCborException { Double returnValue = getValue().getDouble();
<|startcomment|> return long not Long see comment on getBoolean bellow. <|endcomment|>  return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to create OcRepresentation from root object"); } public String getKey() { OCRep.clearCborErrno(); return nativeRepresentation.getName(); } public Boolean getBoolean() throws OcCborException { Boolean returnValue = getValue().getBool(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get boolean"); } <|startfocus|> public Long getLong() throws OcCborException { <|endfocus|> Long returnValue = getValue().getInteger(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get long"); } public Double getDouble() throws OcCborException { Double returnValue = getValue().getDouble(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get double"); } public String getString() throws OcCborException { String returnValue = getValue().getString(); if (returnValue != null) { return returnValue; }
<|startcomment|> return double not Double see comment on getBoolean bellow. <|endcomment|>  } public Boolean getBoolean() throws OcCborException { Boolean returnValue = getValue().getBool(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get boolean"); } public Long getLong() throws OcCborException { Long returnValue = getValue().getInteger(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get long"); } <|startfocus|> public Double getDouble() throws OcCborException { <|endfocus|> Double returnValue = getValue().getDouble(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get double"); } public String getString() throws OcCborException { String returnValue = getValue().getString(); if (returnValue != null) { return returnValue; } throw new OcCborException("Failed to get string"); } public OCArray getArray() throws OcCborException { OCArray returnValue = getValue().getArray(); if (returnValue != null) {
<|startcomment|> After some checking none of the OCRep.get* methods use CborErrno so we can removed it. We still want the null check however. <|endcomment|>  OCRepresentation nativeRep = getValue().getObject(); if (nativeRep != null) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to get object"); } public OcRepresentation getObjectArray() throws OcCborException { OCRepresentation nativeRep = getValue().getObjectArray(); if (nativeRep != null) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to get object array"); } public OCValue getValue() throws OcCborException { <|startfocus|> OCRep.clearCborErrno(); <|endfocus|> OCValue returnValue = nativeRepresentation.getValue(); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get value"); } public Boolean getBoolean(String key) throws OcCborException { OCRep.clearCborErrno(); Boolean returnValue = OCRep.getBoolean(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get boolean for key " + key);
<|startcomment|> since we are checking for null and throwing an exception we no longer need this to be class of class type Boolean but can be the keyword boolean. the return would be return returnValue.getBoolean(); <|endcomment|>  if (nativeRep != null) { return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to get object array"); } public OCValue getValue() throws OcCborException { OCRep.clearCborErrno(); OCValue returnValue = nativeRepresentation.getValue(); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get value"); } <|startfocus|> public Boolean getBoolean(String key) throws OcCborException { OCRep.clearCborErrno(); <|endfocus|> Boolean returnValue = OCRep.getBoolean(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get boolean for key " + key); } public Long getLong(String key) throws OcCborException { OCRep.clearCborErrno(); Long returnValue = OCRep.getLong(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; }
<|startcomment|> return long not Long see comments on getBoolean <|endcomment|>  return returnValue; } throw new OcCborException("Failed to get value"); } public Boolean getBoolean(String key) throws OcCborException { OCRep.clearCborErrno(); Boolean returnValue = OCRep.getBoolean(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get boolean for key " + key); } <|startfocus|> public Long getLong(String key) throws OcCborException { OCRep.clearCborErrno(); <|endfocus|> Long returnValue = OCRep.getLong(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get long for key " + key); } public Double getDouble(String key) throws OcCborException { OCRep.clearCborErrno(); Double returnValue = OCRep.getDouble(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; }
<|startcomment|> return double not Double see comments on getBoolean <|endcomment|>  return returnValue; } throw new OcCborException("Failed to get boolean for key " + key); } public Long getLong(String key) throws OcCborException { OCRep.clearCborErrno(); Long returnValue = OCRep.getLong(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get long for key " + key); } <|startfocus|> public Double getDouble(String key) throws OcCborException { OCRep.clearCborErrno(); <|endfocus|> Double returnValue = OCRep.getDouble(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; } throw new OcCborException("Failed to get double for key " + key); } public String getString(String key) throws OcCborException { OCRep.clearCborErrno(); String returnValue = OCRep.getString(nativeRepresentation, key); if ((returnValue != null) && (OCRep.getCborErrno() == 0)) { return returnValue; }
<|startcomment|> This is not checking the CBorErrno. I would add if (null != nativeRep && OCRep.getCborErrno() == 0) { return ... } if we are not checking the CborErrno then there is not reason to clear the error before each call. This applies to basically all of the OcRepresentation calls. <|endcomment|>  static public OcRepresentation createOcRepresentaionFromRoot() throws OcCborException { OCRep.clearCborErrno(); OCRepresentation nativeRep = OCRep.getOCRepresentaionFromRootObject(); <|startfocus|> if (nativeRep != null) { <|endfocus|> return new OcRepresentation(nativeRep); } throw new OcCborException("Failed to create OcRepresentation from root object");
<|startcomment|> Underneath his line, please the refreshState call like is done in handleLongClick. This will help avoid repetitive calls <|endcomment|>  break; case R.id.radio_recovery: mRebootMode = 2; Settings.System.putInt(mContext.getContentResolver(), Settings.System.STATUS_BAR_LAST_NOTIFICATION_STYLE, mRebootMode); mTileMode = 2; refreshState(); break; case R.id.radio_bootloader: mRebootMode = 3; Settings.System.putInt(mContext.getContentResolver(), Settings.System.STATUS_BAR_LAST_NOTIFICATION_STYLE, mRebootMode); mTileMode = 2; refreshState(); break; default: break; <|startfocus|> } <|endfocus|> 
<|startcomment|> LOL - but here you MUST use getIntForUser :) Wait a second I will fix all in one <|endcomment|>  public void update() { int showNavBar = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_SHOW, -1, mCurrentUserId); <|startfocus|> int qsQuickPulldownValue = Settings.System.getInt( mContext.getContentResolver(), Settings.System.STATUS_BAR_QUICK_QS_PULLDOWN, 0); <|endfocus|> if (showNavBar != -1){ boolean showNavBarBool = showNavBar == 1; if (showNavBarBool != mShowNavBar){ updateNavigationBar(); } } mRecentsStyle = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_RECENTS, 0, mCurrentUserId); mOmniSwitchRecents = mRecentsStyle == 1; mLongPressOnAppSwitchBehavior = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.BUTTON_LONG_PRESS_RECENTS, 0, mCurrentUserId); if (mStatusBarWindow != null) { mStatusBarWindow.updateSettings(); } if (mNavigationBar != null) { mNavigationBar.setRecentsOptions(mRecentsStyle, mLongPressOnAppSwitchBehavior); } if (mStatusBarWindowManager != null) {
<|startcomment|> you still need to register for it! And just small nitpick - indentation is 2x4 for continues lines <|endcomment|>  public void update() { int showNavBar = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_SHOW, -1, mCurrentUserId); <|startfocus|> int qsQuickPulldownValue = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.STATUS_BAR_QUICK_QS_PULLDOWN, 0, UserHandle.USER_CURRENT); <|endfocus|> if (showNavBar != -1){ boolean showNavBarBool = showNavBar == 1; if (showNavBarBool != mShowNavBar){ updateNavigationBar(); } } mRecentsStyle = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.NAVIGATION_BAR_RECENTS, 0, mCurrentUserId); mOmniSwitchRecents = mRecentsStyle == 1; mLongPressOnAppSwitchBehavior = Settings.System.getIntForUser( mContext.getContentResolver(), Settings.System.BUTTON_LONG_PRESS_RECENTS, 0, mCurrentUserId); if (mStatusBarWindow != null) { mStatusBarWindow.updateSettings(); } if (mNavigationBar != null) { mNavigationBar.setRecentsOptions(mRecentsStyle, mLongPressOnAppSwitchBehavior); }
<|startcomment|> guess you could also have reused the app_grid_item layout - but thats just minor <|endcomment|>  public void onBindViewHolder(PreferenceViewHolder holder) { super.onBindViewHolder(holder); LinearLayout linearLayout = (LinearLayout) holder.findViewById(R.id.selected_apps); if (linearLayout.getChildCount() > 0) linearLayout.removeAllViews(); for (String value : mValues) { try { <|startfocus|> ImageView v = new ImageView(mContext); <|endfocus|> ComponentName componentName = ComponentName.unflattenFromString(value); Drawable icon = mPm.getActivityIcon(componentName); v.setImageDrawable(icon); v.setPadding(0, 0, 15, 0); v.setScaleType(ImageView.ScaleType.CENTER_CROP); linearLayout.addView(v); } catch (PackageManager.NameNotFoundException e) { Log.e(TAG, "Set app icon", e); } }
<|startcomment|> System <|endcomment|>  public void onKeyguardShowingChanged() { <|startfocus|> mShowIndicator = Settings.Secure.getIntForUser(mContext.getContentResolver(), Settings.Secure.LOCK_HIDE_INDICATOR_DISPLAY, 0, UserHandle.USER_CURRENT) == 0; <|endfocus|> updateLeftAffordance(); updateRightAffordance(); inflateCameraPreview(); mIndicationController.setVisibleOverwrite(mShowIndicator);
<|startcomment|> I think default value should be 255 <|endcomment|>  private void updateSettings() { int mQsBackGroundAlpha = Settings.System.getIntForUser(getContext().getContentResolver(), <|startfocus|> Settings.System.QS_PANEL_BG_ALPHA, 216, <|endfocus|> UserHandle.USER_CURRENT); mQsBackGround.setAlpha(mQsBackGroundAlpha); setBackground(mQsBackGround);
<|startcomment|> you dont need mContext - you can use getActivity() <|endcomment|>  mMusicActive.setOnPreferenceChangeListener(this); mAutorun = (SwitchPreference) findPreference(EVENT_AUTORUN_SINGLE); mAutorun.setChecked(getPrefs().getBoolean(EventServiceSettings.EVENT_AUTORUN_SINGLE, true)); mAutorun.setOnPreferenceChangeListener(this); mChooserTimeout = (SeekBarPreference) findPreference(APP_CHOOSER_TIMEOUT); mChooserTimeout.setValue(getPrefs().getInt(EventServiceSettings.APP_CHOOSER_TIMEOUT, 15)); mChooserTimeout.setOnPreferenceChangeListener(this); <|startfocus|> boolean locationDisabled = Settings.Secure.getInt(mContext.getContentResolver(), <|endfocus|> Settings.Secure.LOCATION_MODE, -1) == 0; mDisableWifi = (SeekBarPreference) findPreference(DISABLE_WIFI_THRESHOLD); mDisableWifi.setValue(getPrefs().getInt(EventServiceSettings.DISABLE_WIFI_THRESHOLD, 0)); mDisableWifi.setOnPreferenceChangeListener(this); mDisableWifi.setEnabled(!locationDisabled); homeWifi = findPreference(HOME_WIFI_PREFERENCE_SCREEN); homeWifi.setEnabled(!locationDisabled); workWifi = findPreference(WORK_WIFI_PREFERENCE_SCREEN); workWifi.setEnabled(!locationDisabled); if (locationDisabled){ mDisableWifi.setSummary(R.string.wifi_location_disabled); homeWifi.setSummary(R.string.wifi_location_disabled);
<|startcomment|> huh? ... android:defaultValue="true" android:key="media_player_music_active" ... <|endcomment|>  public void onReceive(Context context, Intent intent) { String action = intent.getAction(); mWakeLock.acquire(); try { if (DEBUG) Log.d(TAG, "onReceive " + action); <|startfocus|> boolean disableIfMusicActive = getPrefs(context).getBoolean(EventServiceSettings.EVENT_MUSIC_ACTIVE, false); <|endfocus|> boolean autoRun = getPrefs(context).getBoolean(EventServiceSettings.EVENT_AUTORUN_SINGLE, true); boolean closeApp = getPrefs(context).getBoolean(EventServiceSettings.EVENT_DISCONNECT_HEADSET_OR_A2DP, false); switch (action) { case BluetoothAdapter.ACTION_STATE_CHANGED: if (intent.getIntExtra(BluetoothAdapter.EXTRA_STATE, -1) == BluetoothAdapter.STATE_OFF) { mA2DPConnected = false; } break; case BluetoothA2dp.ACTION_CONNECTION_STATE_CHANGED: int state = intent.getIntExtra(BluetoothProfile.EXTRA_STATE, BluetoothProfile.STATE_CONNECTED); if (state == BluetoothProfile.STATE_CONNECTED && !mA2DPConnected) { mA2DPConnected = true; if (DEBUG) Log.d(TAG, "BluetoothProfile.STATE_CONNECTED = true"); 
<|startcomment|> FYI you can express such deps also in the xml file android:dependency="<other key>" <|endcomment|>  private static final int KEY_MASK_BACK = 0x02; private static final int KEY_MASK_MENU = 0x04; private static final int KEY_MASK_ASSIST = 0x08; private static final int KEY_MASK_APP_SWITCH = 0x10; private CheckBoxPreference mVolumeWake; // private CheckBoxPreference mVolumeMusicControl; private CheckBoxPreference mSwapVolumeButtons; // private ListPreference mVolumeKeyCursorControl; private SwitchPreference mEnableCustomBindings; private ListPreference mBackPressAction; private ListPreference mBackLongPressAction; private ListPreference mHomePressAction; private ListPreference mHomeLongPressAction; private ListPreference mHomeDoubleTapAction; <|startfocus|> private CheckBoxPreference mHomeAnswerCall; <|endfocus|> private ListPreference mMenuPressAction; private ListPreference mMenuLongPressAction; private ListPreference mAssistPressAction; private ListPreference mAssistLongPressAction; private ListPreference mAppSwitchPressAction; private ListPreference mAppSwitchLongPressAction; private Map<String, Integer> mKeySettings = new HashMap<String, Integer>(); // private ListPreference mVolumeDefault; // private CheckBoxPreference mHeadsetHookLaunchVoice; // private CheckBoxPreference mVirtualKeyHapticFeedback; // private CheckBoxPreference mForceShowOverflowMenu;
<|startcomment|> whitespace <|endcomment|>  mGestureButtonHandler.sendEmptyMessageDelayed(MSG_SEND_SWITCH_KEY, (long) GESTURE_KEY_DISTANCE_TIMEOUT); } } mLastX = rawX; mLastY = rawY; break; } else if (mLongClick && mPreparedKeycode == 3) { mGestureButtonHandler.removeMessages(MSG_SEND_SWITCH_KEY); mGestureButtonHandler.sendEmptyMessageDelayed(MSG_SEND_SWITCH_KEY, (long) GESTURE_KEY_DISTANCE_TIMEOUT); mPreparedKeycode = 0; mLongClick = false; } break; <|startfocus|> case 3: <|endfocus|> break; default: break; } //mSwipeStartFromEdge = false; //mSwipeLongFireable = false; } }
<|startcomment|> I would keep those as variables - less changes - just remove the static final and set in initDimens <|endcomment|>  /** * The animation property used for the icon when its isolation ends. * This animates the translation back to the right position. */ private static final AnimationProperties UNISOLATION_PROPERTY = new AnimationProperties() { private AnimationFilter mAnimationFilter = new AnimationFilter().animateX(); @Override public AnimationFilter getAnimationFilter() { return mAnimationFilter; } }.setDuration(CONTENT_FADE_DURATION); <|startfocus|> //public static final int MAX_VISIBLE_ICONS_WHEN_DARK = 5; //public static final int MAX_STATIC_ICONS = 4; <|endfocus|> private static final int MAX_DOTS = 1; private boolean mIsStaticLayout = true; private final HashMap<View, IconState> mIconStates = new HashMap<>(); private int mDotPadding; private int mMaxVisibleIconsWhenDark; private int mMaxStaticIcons; private int mStaticDotRadius; private int mStaticDotDiameter; private int mOverflowWidth; private int mActualLayoutWidth = NO_VALUE; private float mActualPaddingEnd = NO_VALUE; private float mActualPaddingStart = NO_VALUE; private boolean mDark;
<|startcomment|> never ever initialize a resource variable like that! you can do it in initDimens. <|endcomment|>  * This animates the translation back to the right position. */ private static final AnimationProperties UNISOLATION_PROPERTY = new AnimationProperties() { private AnimationFilter mAnimationFilter = new AnimationFilter().animateX(); @Override public AnimationFilter getAnimationFilter() { return mAnimationFilter; } }.setDuration(CONTENT_FADE_DURATION); <|startfocus|> public final int MAX_VISIBLE_ICONS_WHEN_DARK = getResources().getInteger(R.integer.config_maxVisibleNotificationIconsWhenDark); public final int MAX_STATIC_ICONS = getResources().getInteger(R.integer.config_maxVisibleNotificationIcons); <|endfocus|> private static final int MAX_DOTS = 1; private boolean mIsStaticLayout = true; private final HashMap<View, IconState> mIconStates = new HashMap<>(); private int mDotPadding; private int mStaticDotRadius; private int mStaticDotDiameter; private int mOverflowWidth; private int mActualLayoutWidth = NO_VALUE; private float mActualPaddingEnd = NO_VALUE; private float mActualPaddingStart = NO_VALUE; private boolean mDark; private boolean mChangingViewPositions; private int mAddAnimationStartIndex = -1;
<|startcomment|> holy mother of weired code changes .... <|endcomment|> <|startfocus|> private void initDimens() { public final int MAX_VISIBLE_ICONS_WHEN_DARK = getResources().getInteger(R.integer.config_maxVisibleNotificationIconsWhenDark); public final int MAX_STATIC_ICONS = getResources().getInteger(R.integer.config_maxVisibleNotificationIcons); <|endfocus|> private static final int MAX_DOTS = 1;
<|startcomment|> Usually android classes that are under the server scope initialise the SystemUI context in a proper class variable, but in this case I think we only need this context just for the Toast so it gets properly themed according to the theme used (Dark or Light). <|endcomment|>  toastText = com.android.internal.R.string.volume_dialog_ringer_guidance_silent_no_media; break; case VOLUME_HUSH_VIBRATE: effect = VibrationEffect.get(VibrationEffect.EFFECT_HEAVY_CLICK); ringerMode = AudioManager.RINGER_MODE_VIBRATE; toastText = com.android.internal.R.string.volume_dialog_ringer_guidance_vibrate; break; } maybeVibrate(effect); setRingerModeInternal(ringerMode, reason); <|startfocus|> // Use the SystemUI context, so it gets themed properly. Toast.makeText(ActivityThread.currentActivityThread().getSystemUiContext(), toastText, Toast.LENGTH_SHORT).show(); <|endfocus|>
<|startcomment|> please use {} instead of + <|endcomment|>  boolean result = false; try { logger.info("provisionONT begin"); AddOntMessage request = AddOntMessage.newBuilder() .setCLLI(clli) .setPortNumber(portNumber) .setSlotNumber(slotNumber) .setOntNumber(ontNumber) .setSerialNumber(serialNumber) .build(); AddOntReturn response = blockingStub.provisionOnt(request); result = response.getSuccess(); <|startfocus|> logger.info("provisionONT with device id : " + serialNumber + " success : " + result); <|endfocus|> } catch (RuntimeException e) { logger.log(Level.WARNING, "provisionONT RPC failed", e); } return result;
<|startcomment|> please use {} instead of + <|endcomment|>  private static final Logger logger = Logger.getLogger(AbstractOLTServer.class.getName()); @Override public void echo(EchoMessage request, StreamObserver<EchoReplyMessage> responseObserver) { } @Override public void createChassis(AddChassisMessage request, StreamObserver<AddChassisReturn> responseObserver) { AddChassisReturn response = AddChassisReturn.newBuilder() .setDeviceID(request.getCLLI()) .build(); responseObserver.onNext(response); responseObserver.onCompleted(); <|startfocus|> logger.info("createChassis with clli : " + request.getCLLI()); <|endfocus|> } @Override public void createOLTChassis(AddOLTChassisMessage request, StreamObserver<AddOLTChassisReturn> responseObserver) { AddOLTChassisReturn response = AddOLTChassisReturn.newBuilder() .setDeviceID(UUID.randomUUID().toString()) .setChassisDeviceID(request.getCLLI()).build(); responseObserver.onNext(response); responseObserver.onCompleted(); logger.info("createOLTChassis with clli : " + request.getCLLI()); } @Override public void provisionOnt(AddOntMessage request, StreamObserver<AddOntReturn> responseObserver) { AddOntReturn response = AddOntReturn.newBuilder().setSuccess(true).build();
<|startcomment|> empty line <|endcomment|>  public void removeSubscriber(ConnectPoint port) { AccessDeviceData olt = oltData.get(port.deviceId()); if (olt == null) { log.warn("No data found for OLT device {}", port.deviceId()); return; } <|startfocus|> VlanId subscriberVlan = subscribers.remove(port); if (subscriberVlan == null) { log.warn("Unknown subscriber at location {}", port); <|endfocus|> return; } if (enableDhcpIgmpOnProvisioning) { processDhcpFilteringObjectives(olt.deviceId(), port.port(), false); } unprovisionSubscriber(olt.deviceId(), olt.uplink(), port.port(), subscriberVlan, olt.vlan(), olt.defaultVlan()); if (enableDhcpIgmpOnProvisioning) { processIgmpFilteringObjectives(olt.deviceId(), port.port(), false); }
<|startcomment|> Why is this comment still present? <|endcomment|>  for (FunctionalExchange anExchange : getAvailableFunctionalExchangesToInsert(functionView)) { AbstractFunction targetFunction = null; if (EcoreUtil.isAncestor(function, anExchange.getSource()) && anExchange.getTarget().eContainer() instanceof AbstractFunction) { targetFunction = (AbstractFunction) anExchange.getTarget().eContainer(); } else if (anExchange.getSource().eContainer() instanceof AbstractFunction) { targetFunction = (AbstractFunction) anExchange.getSource().eContainer(); } <|startfocus|> // TODO: add this function to the cache <|endfocus|> DNodeContainer visibleFunctionInDiagram = getDisplayedFunctionContainer(targetFunction, functionContainersInDiagram); if (visibleFunctionInDiagram != null) { if (isValidCreationCategoryBetweenViews(anExchange, functionView, visibleFunctionInDiagram)) { targetFunction = (AbstractFunction) visibleFunctionInDiagram.getTarget(); } else { targetFunction = null; } } if (targetFunction != null) { for (ExchangeCategory aCategory : anExchange.getCategories()) { returnedMap.put(aCategory, targetFunction); } } } return returnedMap; } 
<|startcomment|> It seems that you should format the class with the Capella formatter. <|endcomment|> import org.polarsys.capella.core.model.handler.command.CapellaResourceHelper; /** * An {@link ECrossReferenceAdapter} that only takes capella resources into account. */ public class CapellaECrossReferenceAdapter extends SiriusCrossReferenceAdapter { class CapellaInverseCrossReferencer extends InverseCrossReferencer { /** * Generated serial UID. */ private static final long serialVersionUID = -3473829340961544993L; @Override protected void addProxy(EObject proxy, EObject context) { // Do nothing to avoid keeping EObjects turn into proxies during the whole application life. } <|startfocus|> /** * {@inheritDoc} */ @Override protected boolean resolve() { return CapellaECrossReferenceAdapter.this.resolve(); } <|endfocus|> } WeakReference<EditingDomain> _editingDomain; public CapellaECrossReferenceAdapter(EditingDomain editingDomain, Session session, ResourceSet set) { super(set, (DAnalysisSessionImpl) session); _editingDomain = new WeakReference<EditingDomain>(editingDomain); } /** * Adapt all references of specified object against the inverse cross referencer.<br>
<|startcomment|> I think it is better to have this as a internal field and just create a instance of this class. This would avoid a NPE if the static method 'getValidFilterNameCandidate' is called before a instance of this class is created. <|endcomment|>  private static final String MIGRATED_FITLER_EXT = ".filter"; private static final String FRAGMENT_SEPARATOR = "\\@"; private static final String FILTER_SEPARATOR = "\\'"; private static final String FRAGMENT_FILTER_KEY = "filters"; private static final String PLUGIN_TYPE = "plugin"; private static final String VALID_PLUGIN = "org.polarsys.capella.core.sirius.analysis"; private static final String DESCRIPTION_TYPE = "description"; private Map<DiagramDescription, Set<String>> validFilterNames; <|startfocus|> private static Map<String, String> filterNameExceptions; <|endfocus|> public FilterMigrationContribution() { validFilterNames = new HashMap<>(); filterNameExceptions = new HashMap<>(); filterNameExceptions.put("ShowEIExchangeContext", "show.ei.exchange.context.filter"); filterNameExceptions.put("CEParam", "show.ce.param.filter"); filterNameExceptions.put("CEEIParam", "show.ce.ei.param.filter"); filterNameExceptions.put("ShowFEExchangeContex", "show.fe.exchange.context.filter"); filterNameExceptions.put("ShowCEExchangeContext", "show.ce.exchange.context.filter"); } @Override
<|startcomment|> The name is already long, No reason to have the "Is" prefix and the "Boolean". 'HumanCheckbox' or 'HumanPropertiesCheckbox' is enough to understand that this is a boolean checkbox for the 'human' attribute :) <|endcomment|> import org.polarsys.capella.core.model.helpers.BlockArchitectureExt; import org.polarsys.capella.core.model.helpers.ComponentExt; import org.polarsys.capella.core.ui.properties.fields.AbstractSemanticField; import org.polarsys.capella.core.ui.properties.fields.MultipleSemanticField; /** * The Component section. */ public abstract class ComponentSection extends GeneralizableElementSection { private boolean showIsHuman; private boolean showIsActor; private boolean showImplementedInterfaces; private boolean showUsedInterfaces; private boolean showAllocatedFunctions; <|startfocus|> protected IsHumanBooleanPropertiesCheckbox isHumanCheckbox; protected IsActorBooleanPropertiesCheckbox isActorCheckbox; <|endfocus|> private MultipleSemanticField implementedInterfaces; private MultipleSemanticField usedInterfaces; protected MultipleSemanticField allocatedFunctions; /** * Default constructor. */ public ComponentSection() { this(true, true, true, true, true, true, true); } /** * Constructor. * @param showImplementedInterfaces * @param showUsedInterfaces * @param showAllocatedFunctions * @param showSuperTypes * @param showIsAbstract */
<|startcomment|> Instead of having 3 conditions named condition1, 2, 3 each with a comment, what do you think about having the same 3 conditions with a symbolic name and with no comments. condition1 => isOperationaEntity or isOE condition2 => isSystem etc <|endcomment|>  if (null != propertiesCheckbox) { propertiesCheckbox.setEnabled(component.isActor()); } if (null != isHumanCheckbox) { isHumanCheckbox.loadData(component); // if the component is an OE, // if the component is a system, // if the component has children, boolean condition1 = block instanceof OperationalAnalysis && !component.isActor(); boolean condition2 = component == block.getSystem(); boolean condition3 = ComponentExt.isComposite(component); // then the IsHuman checkbox must be disabled <|startfocus|> if (isHumanCheckbox.isEnabled() && (condition1 || condition2 || condition3)) { <|endfocus|> isHumanCheckbox.setEnabled(false); } } if (null != isActorCheckbox) { isActorCheckbox.loadData(component); // if the component is in SA level, // if the component is a system, // if the component is an actor and its container cannot have a component, // if the component is a component and its container cannot have an actor, boolean condition1 = block instanceof SystemAnalysis;
<|startcomment|> Same remark as above <|endcomment|>  boolean condition1 = block instanceof SystemAnalysis; boolean condition2 = component == block.getSystem(); boolean condition3 = component.isActor() && !ComponentExt.canCreateABComponent(component.eContainer()); boolean condition4 = !component.isActor() && !ComponentExt.canCreateABActor(component.eContainer()); // then the IsActor checkbox must be disabled <|startfocus|> if (isActorCheckbox.isEnabled() && (condition1 || condition2 || condition3 || condition4)) { <|endfocus|> isActorCheckbox.setEnabled(false); } } if (null != implementedInterfaces) { implementedInterfaces.loadData(component, CsPackage.Literals.COMPONENT__OWNED_INTERFACE_IMPLEMENTATIONS); } if (null != usedInterfaces) { usedInterfaces.loadData(component, CsPackage.Literals.COMPONENT__OWNED_INTERFACE_USES); } if (null != allocatedFunctions) { allocatedFunctions.loadData(component, FaPackage.Literals.ABSTRACT_FUNCTIONAL_BLOCK__OWNED_FUNCTIONAL_ALLOCATION); }
<|startcomment|> Please, update copyright header <|endcomment|> ***************************************************************************** <|startfocus|> * Copyright (c) 2006, 2015 THALES GLOBAL SERVICES. <|endfocus|> * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Thales - initial API and implementation ******************************************************************************/ package org.polarsys.capella.docgen.util.pattern.helper; import java.util.ArrayList; import java.util.Collection; import org.polarsys.capella.core.data.fa.FunctionalExchange; import org.polarsys.capella.core.data.oa.CommunicationMean; import org.polarsys.capella.core.data.oa.Entity; import org.polarsys.capella.common.data.modellingcore.AbstractInformationFlow; import org.polarsys.capella.common.data.modellingcore.InformationsExchanger; import org.polarsys.capella.docgen.util.CapellaServices; import org.polarsys.capella.docgen.util.StringUtil; public class CapellaEntityHelper { public static Collection<String> getIncomingCommunicationMeansLines(Entity entity, String projectName, String outputFolder) { Collection<String> ret = new ArrayList<String>(); 
<|startcomment|> Please, update copyright header <|endcomment|> ***************************************************************************** <|startfocus|> * Copyright (c) 2006, 2018 THALES GLOBAL SERVICES. <|endfocus|> * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Thales - initial API and implementation ******************************************************************************/ package org.polarsys.capella.docgen.util; import java.util.ArrayList; import java.util.Collection; import java.util.HashSet; import java.util.Iterator; import java.util.List; import java.util.Set; import org.eclipse.emf.common.util.EList; import org.eclipse.emf.ecore.EObject; import org.polarsys.capella.core.data.cs.Component; import org.polarsys.capella.core.data.cs.Interface; import org.polarsys.capella.core.data.fa.AbstractFunction; import org.polarsys.capella.core.data.fa.ComponentExchange; import org.polarsys.capella.core.data.fa.ComponentExchangeEnd; import org.polarsys.capella.core.data.fa.ComponentExchangeKind; import org.polarsys.capella.core.data.fa.ComponentPort; import org.polarsys.capella.core.data.fa.FunctionalExchange;
<|startcomment|> Please, update copyright header <|endcomment|> ***************************************************************************** <|startfocus|> * Copyright (c) 2006, 2017 THALES GLOBAL SERVICES. <|endfocus|> * All rights reserved. This program and the accompanying materials * are made available under the terms of the Eclipse Public License v1.0 * which accompanies this distribution, and is available at * http://www.eclipse.org/legal/epl-v10.html * * Contributors: * Thales - initial API and implementation ******************************************************************************/ package org.polarsys.capella.docgen.util.pattern.helper; import java.util.ArrayList; import java.util.Collection; import java.util.HashMap; import java.util.Map; import org.polarsys.capella.common.data.modellingcore.ModelElement; import org.polarsys.capella.core.data.cs.Interface; import org.polarsys.capella.core.data.fa.ComponentExchange; import org.polarsys.capella.core.data.fa.ComponentExchangeKind; import org.polarsys.capella.core.data.fa.ComponentPort; import org.polarsys.capella.core.data.information.ExchangeItem; import org.polarsys.capella.docgen.util.CapellaServices; import org.polarsys.capella.docgen.util.StringUtil; public class CapellaComponentPortHelper { /** * Get the provided interfaces of a ComponentPort as html * 
<|startcomment|> Please fix this merge issue <|endcomment|>  EList<EObject> objects = new BasicEList<EObject>(); objects.add(repTarget); if (repTarget instanceof Part) { objects.addAll(resolveReferencedElements(((Part) repTarget).getAbstractType())); } if (repTarget instanceof InstanceRole) { objects.addAll(resolveReferencedElements(((InstanceRole) repTarget).getRepresentedInstance())); } if (repTarget instanceof StateFragment) { objects.addAll(resolveReferencedElements(((StateFragment) repTarget).getRelatedAbstractFunction())); } return objects; } /** <|startfocus|> <<<<<<< HEAD <|endfocus|> * Scrutinize all EOI (element of interest: See * {@link org.polarsys.capella.core.diagram.helpers.naming.DAnnotationSourceConstants.CAPELLA_ELEMENT_OF_INTEREST}) * annotation of all representation descriptors to find all representations * which are interested by the semantic element * * @param semanticElement * to find all representation interested by it * @return a collection of representations interested by semantic element. If * there are no representation, empty collection is returned */ public static Collection<DDiagram> getAllInterestedRepresentationsFor(EObject semanticElement) {
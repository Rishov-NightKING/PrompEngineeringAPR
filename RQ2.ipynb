{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Requirements\n"
      ],
      "metadata": {
        "id": "Gc8B6TqviEzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "7bGOe4JjiNaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4B-U24zhXgq"
      },
      "source": [
        "# Import Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_jzdquwahXgw"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "from utils import (\n",
        "    apply_heuristics,\n",
        "    apply_heuristic_in_file,\n",
        "    heuristic_adjust_spaces,\n",
        "    get_bleu_and_codebleu,\n",
        "    get_env_variable,\n",
        "    get_predictions_from_openai_and_write_to_file,\n",
        "    read_raw_tufano_dataset_from_csv,\n",
        "    write_list_to_file,\n",
        "    read_dataset,\n",
        "    get_EM_R4R,\n",
        "    format_file,\n",
        "    transfer_content_to_another_file,\n",
        "    get_predictions_from_edit_api_and_write_to_file,\n",
        "    get_few_shot_predictions_from_openai_and_write_to_file\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUrL4Gr4hXg2"
      },
      "source": [
        "## Set OpenAI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxwpo3xhhXg2"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"<YOUR_OPEN_API_KEY>\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPIAsiJBhXg2"
      },
      "source": [
        "# Zero-Shot Inference and Evaluation using GPT-3.5-Turbo Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Path Definition"
      ],
      "metadata": {
        "id": "mUfG6JYyodZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIRECTORY = \"zero_shot_outputs\"\n",
        "TUFANO_SOURCE_FILE_PATH = \"datasets/tufano/test_CC_src.txt\"\n",
        "TUFANO_TARGET_FILE_PATH = \"datasets/tufano/test_CC_tgt.txt\"\n",
        "TUFANO_RAW_DATASET_FILE_PATH = \"datasets/tufano/raw_test.csv\"\n",
        "R4R_SOURCE_FILE_PATH = \"datasets/R4R/test_CC_src.txt\"\n",
        "R4R_TARGET_FILE_PATH = \"datasets/R4R/test_CC_tgt.txt\""
      ],
      "metadata": {
        "id": "ZHuHx6eNogvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btBkamQ1hXg0"
      },
      "source": [
        "## Inference and Evaluation on Review4Repair Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data load"
      ],
      "metadata": {
        "id": "83G5pZ4HlGqa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "P48lOolOhXg0",
        "outputId": "91eb5d23-33d6-4f20-8424-9ba70c7c5f57"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3ce99dda324d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m code_reviews, buggy_codes, target_codes = read_dataset(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"R4R\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR4R_SOURCE_FILE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR4R_TARGET_FILE_PATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'R4R_SOURCE_FILE_PATH' is not defined"
          ]
        }
      ],
      "source": [
        "code_reviews, buggy_codes, target_codes = read_dataset(\n",
        "    dataset_name=\"R4R\", source_file_path=R4R_SOURCE_FILE_PATH, target_file_path=R4R_TARGET_FILE_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sGNSfixhXg3"
      },
      "source": [
        "### inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7b0_QUUhXg3"
      },
      "outputs": [],
      "source": [
        "get_predictions_from_openai_and_write_to_file(\n",
        "    f\"{OUTPUT_DIRECTORY}/zero_shot_r4r_predictions_raw_no_heuristic.txt\",\n",
        "    f\"{OUTPUT_DIRECTORY}/zero_shot_r4r_ground_truths_raw_no_heuristic.txt\",\n",
        "    code_reviews,\n",
        "    buggy_codes,\n",
        "    target_codes\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before applying heuristics"
      ],
      "metadata": {
        "id": "lPSE_SNYusZj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### accuracy (EM) calculation"
      ],
      "metadata": {
        "id": "BhH_xk--usZr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X9uyNPfRusZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BLEU and CodeBLEU calculation"
      ],
      "metadata": {
        "id": "QYLe2VmvusZt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3jOzHBEpusZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After applying heuristics"
      ],
      "metadata": {
        "id": "F5XdI-U_usZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### accuracy (EM) calculation"
      ],
      "metadata": {
        "id": "okDiZj8LusZu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3vW8g_7QusZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BLEU and CodeBLEU calculation"
      ],
      "metadata": {
        "id": "C6gqhgVgusZv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X80vbJk3usZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference and Evaluation on Tufano Dataset"
      ],
      "metadata": {
        "id": "o3iKMpmBlzBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data load"
      ],
      "metadata": {
        "id": "N06D324-l3yl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRODuW4hhXg1"
      },
      "outputs": [],
      "source": [
        "code_reviews, buggy_codes, target_codes = read_raw_tufano_dataset_from_csv(TUFANO_RAW_DATASET_FILE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcH6retjhXg4"
      },
      "source": [
        "### inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qMiJkSchXg4"
      },
      "outputs": [],
      "source": [
        "get_predictions_from_openai_and_write_to_file(\n",
        "    f\"{OUTPUT_DIRECTORY}/zero_shot_tufano_predictions_raw_no_heuristic.txt\",\n",
        "    f\"{OUTPUT_DIRECTORY}/zero_shot_tufano_ground_truths_raw_no_heuristic.txt\",\n",
        "    code_reviews,\n",
        "    buggy_codes,\n",
        "    target_codes\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before applying heuristics"
      ],
      "metadata": {
        "id": "EXUpZEKIuzrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### accuracy (EM) calculation"
      ],
      "metadata": {
        "id": "AFrNZiGLuzrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GWbivmczuzrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BLEU and CodeBLEU calculation"
      ],
      "metadata": {
        "id": "BJ3T2gOWuzrS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5DiokjfGuzrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After applying heuristics"
      ],
      "metadata": {
        "id": "ICGsJzFduzrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### accuracy (EM) calculation"
      ],
      "metadata": {
        "id": "Iat3-inhuzrV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U2eDuDJZuzrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BLEU and CodeBLEU calculation"
      ],
      "metadata": {
        "id": "APk6EH9auzrW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Axmt8joLuzrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmwfcT5wn0HQ"
      },
      "source": [
        "# Few Shot Inference and Evaluation using GPT-3.5-Turbo Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset path definition"
      ],
      "metadata": {
        "id": "zbKgYrNHoUN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIRECTORY = \"few_shot_outputs\"\n",
        "TUFANO_RAW_TRAIN_DATASET_FILE_PATH = \"datasets/tufano/raw_train.csv\"\n",
        "TUFANO_RAW_TEST_DATASET_FILE_PATH = \"datasets/tufano/raw_test.csv\"\n",
        "\n",
        "R4R_TRAIN_DATASET_SRC_FILE_PATH = \"datasets/R4R/train_CC_src.txt\"\n",
        "R4R_TRAIN_DATASET_TGT_FILE_PATH = \"datasets/R4R/train_CC_tgt.txt\"\n",
        "R4R_TEST_DATASET_SRC_FILE_PATH = \"datasets/R4R/test_CC_src.txt\"\n",
        "R4R_TEST_DATASET_TGT_FILE_PATH = \"datasets/R4R/test_CC_tgt.txt\""
      ],
      "metadata": {
        "id": "G-B-BATcoYGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD025EtFn0HT"
      },
      "source": [
        "## Inference and Evaluation on Review4Repair Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data load"
      ],
      "metadata": {
        "id": "SLHbf9jZn0HU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2G67qJWn0HV"
      },
      "outputs": [],
      "source": [
        "train_code_reviews, train_buggy_codes, train_target_codes = read_dataset(\n",
        "    dataset_name=\"R4R\",\n",
        "    source_file_path=R4R_TRAIN_DATASET_SRC_FILE_PATH,\n",
        "    target_file_path=R4R_TRAIN_DATASET_TGT_FILE_PATH\n",
        ")\n",
        "\n",
        "test_code_reviews, test_buggy_codes, test_target_codes = read_dataset(\n",
        "    dataset_name=\"R4R\",\n",
        "    source_file_path=R4R_TEST_DATASET_SRC_FILE_PATH,\n",
        "    target_file_path=R4R_TEST_DATASET_TGT_FILE_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVDzo5ton0HW"
      },
      "source": [
        "### inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mzolr8Wn0HX"
      },
      "outputs": [],
      "source": [
        "get_few_shot_predictions_from_openai_and_write_to_file(\n",
        "    prediction_file_path=f\"{OUTPUT_DIRECTORY}/few_shot_r4r_predictions_raw_no_heuristic.txt\",\n",
        "    ground_truth_path=f\"{OUTPUT_DIRECTORY}/few_shot_r4r_ground_truths_raw_no_heuristic.txt\",\n",
        "    train_dataset=(train_code_reviews, train_buggy_codes, train_target_codes),\n",
        "    test_dataset=(test_code_reviews, test_buggy_codes, test_target_codes),\n",
        "    top_k=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before applying heuristics"
      ],
      "metadata": {
        "id": "MbXvMeVVthl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### accuracy (EM) calculation"
      ],
      "metadata": {
        "id": "NXJE7o5Kthl8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jy3RguC6thl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BLEU and CodeBLEU calculation"
      ],
      "metadata": {
        "id": "m_wvjImjthl-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "htgI6Chithl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After applying heuristics"
      ],
      "metadata": {
        "id": "Tb2SvENhthl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### accuracy (EM) calculation"
      ],
      "metadata": {
        "id": "3zqI4UjNthl_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_2zl4Hu-thmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BLEU and CodeBLEU calculation"
      ],
      "metadata": {
        "id": "agLOFY_qthmA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ntg9GqPthmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference and Evaluation on Tufano Dataset"
      ],
      "metadata": {
        "id": "MFtd-ZuXn0HZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data load"
      ],
      "metadata": {
        "id": "EFxDXGdDn0HZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMoZrc16n0Ha"
      },
      "outputs": [],
      "source": [
        "test_code_reviews, test_buggy_codes, test_target_codes = read_raw_tufano_dataset_from_csv(\n",
        "    TUFANO_RAW_TEST_DATASET_FILE_PATH\n",
        ")\n",
        "train_code_reviews, train_buggy_codes, train_target_codes = read_raw_tufano_dataset_from_csv(\n",
        "    TUFANO_RAW_TRAIN_DATASET_FILE_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZj5qw7Fn0Ha"
      },
      "source": [
        "### inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUfXtuqGn0Ha"
      },
      "outputs": [],
      "source": [
        "get_few_shot_predictions_from_openai_and_write_to_file(\n",
        "    prediction_file_path=f\"{OUTPUT_DIRECTORY}/few_shot_tufano_predictions_raw_no_heuristic.txt\",\n",
        "    ground_truth_path=f\"{OUTPUT_DIRECTORY}/few_shot_tufano_ground_truths_raw_no_heuristic.txt\",\n",
        "    train_dataset=(train_code_reviews, train_buggy_codes, train_target_codes),\n",
        "    test_dataset=(test_code_reviews, test_buggy_codes, test_target_codes),\n",
        "    top_k=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before applying heuristics"
      ],
      "metadata": {
        "id": "yjssPVKItn9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### accuracy (EM) calculation"
      ],
      "metadata": {
        "id": "XXM8Mfq5tn9G"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iNLWwWy0tn9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BLEU and CodeBLEU calculation"
      ],
      "metadata": {
        "id": "msw0uQ9vtn9H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zTN4cHi0tn9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After applying heuristics"
      ],
      "metadata": {
        "id": "5fgzDf2Ltn9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### accuracy (EM) calculation"
      ],
      "metadata": {
        "id": "QEAAIAGptn9I"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsVdlg2Btn9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BLEU and CodeBLEU calculation"
      ],
      "metadata": {
        "id": "7cne1BFqtn9J"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nv9IT8qYtn9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dPcplQ_qPD8"
      },
      "source": [
        "# Code-DaVinci-Edit-001 Inference and Evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Path Definition"
      ],
      "metadata": {
        "id": "MegNvKWZqPD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIRECTORY = \"outputs\"\n",
        "TUFANO_SOURCE_FILE_PATH = \"datasets/tufano/test_CC_src.txt\"\n",
        "TUFANO_TARGET_FILE_PATH = \"datasets/tufano/test_CC_tgt.txt\"\n",
        "TUFANO_RAW_DATASET_FILE_PATH = \"datasets/tufano/raw_test.csv\"\n",
        "R4R_SOURCE_FILE_PATH = \"datasets/R4R/test_CC_src.txt\"\n",
        "R4R_TARGET_FILE_PATH = \"datasets/R4R/test_CC_tgt.txt\""
      ],
      "metadata": {
        "id": "-WEEa11yqPEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxN7iGFeqPEB"
      },
      "source": [
        "## Inference and Evaluation on Review4Repair Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data load"
      ],
      "metadata": {
        "id": "7DQ8yHp2qPEB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "91eb5d23-33d6-4f20-8424-9ba70c7c5f57",
        "id": "p11hMWvVqPEB"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3ce99dda324d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m code_reviews, buggy_codes, target_codes = read_dataset(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"R4R\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR4R_SOURCE_FILE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR4R_TARGET_FILE_PATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'R4R_SOURCE_FILE_PATH' is not defined"
          ]
        }
      ],
      "source": [
        "code_reviews, buggy_codes, target_codes = read_dataset(\n",
        "    dataset_name=\"R4R\", source_file_path=R4R_SOURCE_FILE_PATH, target_file_path=R4R_TARGET_FILE_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udk_O-h3qPEC"
      },
      "source": [
        "### inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tg5N7Jn8qPED"
      },
      "outputs": [],
      "source": [
        "get_predictions_from_edit_api_and_write_to_file(\n",
        "    f\"{OUTPUT_DIRECTORY}/edit_r4r_predictions.txt\",\n",
        "    f\"{OUTPUT_DIRECTORY}/edit_r4r_ground_truths.txt\",\n",
        "    code_reviews,\n",
        "    buggy_codes,\n",
        "    target_codes\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### accuracy (EM) calculation"
      ],
      "metadata": {
        "id": "zXZVk53JqPED"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5x4HYKxfqPED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BLEU and CodeBLEU calculation"
      ],
      "metadata": {
        "id": "0YSU4tyiqPEE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rlDWyf4wqPEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference and Evaluation on Tufano Dataset"
      ],
      "metadata": {
        "id": "aw0f3jdTqPEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data load"
      ],
      "metadata": {
        "id": "rephClEbqPEF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQwoFJVfqPEF"
      },
      "outputs": [],
      "source": [
        "code_reviews, buggy_codes, target_codes = read_raw_tufano_dataset_from_csv(TUFANO_RAW_DATASET_FILE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OJJ4gb-qPEF"
      },
      "source": [
        "### inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfVDlUo2qPEG"
      },
      "outputs": [],
      "source": [
        "get_predictions_from_edit_api_and_write_to_file(\n",
        "    f\"{OUTPUT_DIRECTORY}/edit_tufano_predictions.txt\",\n",
        "    f\"{OUTPUT_DIRECTORY}/edit_tufano_ground_truths.txt\",\n",
        "    code_reviews,\n",
        "    buggy_codes,\n",
        "    target_codes\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### accuracy (EM) calculation"
      ],
      "metadata": {
        "id": "P9Cxj0l6qPEG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vtAQYjhYqPEG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BLEU and CodeBLEU calculation"
      ],
      "metadata": {
        "id": "_B49hv2bqPEH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DTHlKFzUqPEH"
      },
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}